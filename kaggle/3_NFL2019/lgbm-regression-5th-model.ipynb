{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold,TimeSeriesSplit,KFold,GroupKFold\n",
    "from sklearn.metrics import roc_auc_score,mean_squared_error,mean_absolute_error\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "import gc\n",
    "from bayes_opt import BayesianOptimization\n",
    "from kaggle.competitions import nflrush\n",
    "import math\n",
    "import tqdm\n",
    "from scipy.spatial import Delaunay, delaunay_plot_2d, Voronoi, voronoi_plot_2d, ConvexHull\n",
    "pd.set_option(\"display.max_columns\",1000)\n",
    "env = nflrush.make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cdf_df(yards_array):\n",
    "    pdf, edges = np.histogram(yards_array, bins=199,\n",
    "                 range=(-99,100), density=True)\n",
    "    cdf = pdf.cumsum().clip(0, 1)\n",
    "    cdf_df = pd.DataFrame(data=cdf.reshape(-1, 1).T, \n",
    "                            columns=['Yards'+str(i) for i in range(-99,100)])\n",
    "    return cdf_df\n",
    "\n",
    "def get_score(y_pred,cdf,w,dist_to_end):\n",
    "    y_pred = int(y_pred)\n",
    "    if y_pred ==w:\n",
    "        y_pred_array = cdf.copy()\n",
    "    elif y_pred - w >0:\n",
    "        y_pred_array = np.zeros(199)\n",
    "        y_pred_array[(y_pred-w):] = cdf[:(-(y_pred-w))].copy()\n",
    "    elif w - y_pred >0:\n",
    "        y_pred_array = np.ones(199)\n",
    "        y_pred_array[:(y_pred-w)] = cdf[(w-y_pred):].copy()\n",
    "    y_pred_array[-1]=1\n",
    "    y_pred_array[(dist_to_end+99):]=1\n",
    "    return y_pred_array    \n",
    "\n",
    "def get_score_pingyi1(y_pred,y_true,cdf,w,dist_to_end):\n",
    "    y_pred = int(y_pred)\n",
    "    if y_pred ==w:\n",
    "        y_pred_array = cdf.copy()\n",
    "    elif y_pred - w >0:\n",
    "        y_pred_array = np.zeros(199)\n",
    "        y_pred_array[(y_pred-w):] = cdf[:(-(y_pred-w))].copy()\n",
    "    elif w - y_pred >0:\n",
    "        y_pred_array = np.ones(199)\n",
    "        y_pred_array[:(y_pred-w)] = cdf[(w-y_pred):].copy()\n",
    "    y_pred_array[-1]=1\n",
    "    y_pred_array[(dist_to_end+99):]=1\n",
    "    y_true_array = np.zeros(199)\n",
    "    y_true_array[(y_true+99):]=1\n",
    "    return np.mean((y_pred_array - y_true_array)**2)\n",
    "\n",
    "def CRPS_pingyi1(y_preds,y_trues,w,cdf,dist_to_ends):\n",
    "    if len(y_preds) != len(y_trues):\n",
    "        print('length does not match')\n",
    "        return None\n",
    "    n = len(y_preds)\n",
    "    tmp = []\n",
    "    for a,b,c in zip(y_preds, y_trues,dist_to_ends):\n",
    "        tmp.append(get_score_pingyi1(a,b,cdf,w,c))\n",
    "    return np.mean(tmp)\n",
    "\n",
    "def crps_score(y_pred, y_true):\n",
    "    y_pred = np.array(y_pred).astype(\"int\")\n",
    "    y_pred_cdf = np.zeros([y_pred.shape[0], 199])\n",
    "    for i, y in enumerate(y_pred):\n",
    "        y_pred_cdf[i, 99+y] = 1\n",
    "    y_true_cdf = np.zeros([y_true.shape[0], 199])\n",
    "    for i, y in enumerate(y_true):\n",
    "        y_true_cdf[i, 99+y] = 1\n",
    "    y_true_cdf = np.clip(np.cumsum(y_true_cdf, axis=1), 0, 1)\n",
    "    y_pred_cdf = np.clip(np.cumsum(y_pred_cdf, axis=1), 0, 1)\n",
    "    return ((y_true_cdf - y_pred_cdf) ** 2).sum(axis=1).sum(axis=0) / (199 * y_true_cdf.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/nfl-big-data-bowl-2020/train.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess and feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_time_quarter(str1):\n",
    "    return int(str1[:2])*60 + int(str1[3:5])\n",
    "  \n",
    "def transform_time_all(str1,quarter):\n",
    "    if quarter<=4:\n",
    "        return 15*60 - (int(str1[:2])*60 + int(str1[3:5])) + (quarter-1)*15*60\n",
    "    if quarter ==5:\n",
    "        return 10*60 - (int(str1[:2])*60 + int(str1[3:5])) + (quarter-1)*15*60\n",
    "      \n",
    "def back_direction(orientation):\n",
    "    if orientation > 180.0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "      \n",
    "def transform_height(te):\n",
    "    return (int(te.split('-')[0])*12 + int(te.split('-')[1]))*2.54/100\n",
    "\n",
    "def voronoi_volumes(points, selected_index):\n",
    "    v = Voronoi(points)\n",
    "    vol = np.zeros(v.npoints)\n",
    "      \n",
    "    for i, reg_num in enumerate(v.point_region):\n",
    "        if reg_num == v.point_region[selected_index]:\n",
    "            indices = v.regions[reg_num]\n",
    "            if -1 in indices: # some regions can be opened\n",
    "                vol = -999 ## insert missing value when the area is open\n",
    "            else:\n",
    "                vol = ConvexHull(v.vertices[indices]).volume      \n",
    "            break\n",
    "    return vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_features = ['PlayId','DisplayName','GameClock','TimeHandoff','TimeSnap', 'PlayDirection', 'TeamOnOffense', \n",
    "                   'Turf', 'PlayerBirthDate', 'is_run', 'NflIdRusher', 'date_game', 'FieldPosition', \n",
    "                   'HomeTeamAbbr', 'VisitorTeamAbbr', 'PlayerHeight', 'own_field']#'GameId','PossessionTeam','JerseyNumber', \"PlayerWeight\",\"WindSpeed\", \"WindDirection\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df):\n",
    "    df.loc[df.VisitorTeamAbbr == \"ARI\",'VisitorTeamAbbr'] = \"ARZ\"\n",
    "    df.loc[df.HomeTeamAbbr == \"ARI\",'HomeTeamAbbr'] = \"ARZ\"\n",
    "\n",
    "    df.loc[df.VisitorTeamAbbr == \"BAL\",'VisitorTeamAbbr'] = \"BLT\"\n",
    "    df.loc[df.HomeTeamAbbr == \"BAL\",'HomeTeamAbbr'] = \"BLT\"\n",
    "\n",
    "    df.loc[df.VisitorTeamAbbr == \"CLE\",'VisitorTeamAbbr'] = \"CLV\"\n",
    "    df.loc[df.HomeTeamAbbr == \"CLE\",'HomeTeamAbbr'] = \"CLV\"\n",
    "\n",
    "    df.loc[df.VisitorTeamAbbr == \"HOU\",'VisitorTeamAbbr'] = \"HST\"\n",
    "    df.loc[df.HomeTeamAbbr == \"HOU\",'HomeTeamAbbr'] = \"HST\"\n",
    "\n",
    "    df['is_run'] = df.NflId == df.NflIdRusher\n",
    "\n",
    "    if 2017 in list(df[\"Season\"].unique()):\n",
    "        df.loc[df['Season'] == 2017, 'S'] = (df['S'][df['Season'] == 2017] - 2.4355) / 1.2930 * 1.4551 + 2.7570\n",
    "\n",
    "    # standardization -----------------------------\n",
    "    df['ToLeft'] = df.PlayDirection == \"left\"\n",
    "    df['TeamOnOffense'] = \"home\"\n",
    "    df.loc[df.PossessionTeam != df.HomeTeamAbbr, 'TeamOnOffense'] = \"away\"\n",
    "    df['OnOffense'] = df.Team == df.TeamOnOffense # Is player on offense?\n",
    "    df['YardLine_std'] = 100 - df.YardLine.copy()\n",
    "    df.loc[df.FieldPosition.fillna('') == df.PossessionTeam,  \n",
    "            'YardLine_std'\n",
    "             ] = df.loc[df.FieldPosition.fillna('') == df.PossessionTeam,  \n",
    "              'YardLine']\n",
    "    df['X_std'] = df.X.copy()\n",
    "    df.loc[df.ToLeft, 'X_std'] = 120 - df.loc[df.ToLeft, 'X'] \n",
    "    df['Y_std'] = df.Y.copy()\n",
    "    df.loc[df.ToLeft, 'Y_std'] = 53.3 - df.loc[df.ToLeft, 'Y'] \n",
    "    df['Orientation_std'] = df.Orientation.copy()\n",
    "    df.loc[df.ToLeft, 'Orientation_std'] = np.mod(180 + df.loc[df.ToLeft, 'Orientation_std'], 360)\n",
    "    df['Dir_std'] = df.Dir.copy()\n",
    "    df.loc[df.ToLeft, 'Dir_std'] = np.mod(180 + df.loc[df.ToLeft, 'Dir_std'], 360)\n",
    "    df.loc[df['Season'] == 2017, 'Orientation_std'] = np.mod(90 + df.loc[df['Season'] == 2017, 'Orientation_std'], 360) \n",
    "    df.drop([\"X\", \"Y\", \"Orientation\", \"YardLine\", \"Dir\", \"ToLeft\"], axis=1, inplace=True)\n",
    "    df.rename(columns={'X_std': 'X', 'Y_std': 'Y', 'Orientation_std': 'Orientation', 'Dir_std': 'Dir', \"YardLine_std\": \"YardLine\"}, inplace=True)\n",
    "    # standardization -----------------------------\n",
    "    \n",
    "    df['date_game'] = df.GameId.map(lambda x:pd.to_datetime(str(x)[:8]))\n",
    "    df['age'] = (df.date_game.map(pd.to_datetime) - df.PlayerBirthDate.map(pd.to_datetime)).map(lambda x:x.days)/365\n",
    "\n",
    "    df[\"Momentum\"] = df[\"S\"] * df[\"PlayerWeight\"]\n",
    "\n",
    "    #df[\"F\"] = df[\"A\"] * df[\"PlayerWeight\"]\n",
    "\n",
    "    rusher_x = np.array(df.groupby([\"PlayId\", \"is_run\"])[\"X\"].agg(np.mean)[1::2])\n",
    "    rusher_x = np.repeat(rusher_x, 22) # repeat each elemnt 22 times df[\"RusherX\"]\n",
    "    rusher_y = np.array(df.groupby([\"PlayId\", \"is_run\"])[\"Y\"].agg(np.mean)[1::2])\n",
    "    rusher_y = np.repeat(rusher_y, 22) # df[\"RusherY\"]\n",
    "    df[\"DisToRusher\"] = np.sqrt((df[\"X\"] - rusher_x) ** 2 + (df[\"Y\"] - rusher_y) ** 2)\n",
    "    df[\"TackleTimeToRusher\"] = df[\"DisToRusher\"] / df[\"S\"] # includes nan when the speed of rusher is 0\n",
    "    #df.loc[df.is_run==True, \"TackleTimeToRusher\"] = 0\n",
    "\n",
    "    #df[\"Dir_sin\"] = df[\"Dir\"].apply(lambda x : np.sin((450-x) * np.pi/ 180))\n",
    "    df[\"Dir_cos\"] = df[\"Dir\"].apply(lambda x : np.cos((450-x) * np.pi/ 180))\n",
    "    #df[\"Orientation_sin\"] = df[\"Orientation\"].apply(lambda x : np.cos((450-x) * np.pi/ 180))\n",
    "    #df[\"Orientation_cos\"] = df[\"Orientation\"].apply(lambda x : np.sin((450-x) * np.pi/ 180))\n",
    "    \n",
    "    df[\"Momentum_cos\"] = df[\"Momentum\"] * df[\"Dir_cos\"]\n",
    "    #df[\"Momentum_sin\"] = df[\"Momentum\"] * df[\"Dir_sin\"]\n",
    "\n",
    "    rusher_s = np.array(df.groupby([\"PlayId\", \"is_run\"]).agg(np.mean)[\"S\"][1::2])\n",
    "    #rusher_s[rusher_s == 0] = 1e-15 # replace velocity 0 with very small values\n",
    "    rusher_s = np.repeat(rusher_s, 22)\n",
    "    df[\"RatioSToRusher\"] = df[\"S\"] / rusher_s\n",
    "    #df.loc[df.is_run==True, \"RatioSToRusher\"] = 1\n",
    "\n",
    "    df_single = df[df.is_run==True].copy()\n",
    "    \n",
    "    #df_single[\"NecDisPerDown\"] = df_single[\"Distance\"] / (5 - df_single[\"Down\"])\n",
    "        \n",
    "    df_single['time_quarter'] = df_single.GameClock.map(lambda x:transform_time_quarter(x))\n",
    "    df_single['time_end'] = df_single.apply(lambda x:transform_time_all(x.loc['GameClock'],x.loc['Quarter']),axis=1)\n",
    "\n",
    "    df_single['TimeHandoff'] = df_single['TimeHandoff'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    df_single['TimeSnap'] = df_single['TimeSnap'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    df_single['handoff_snap_diff'] = (df_single['TimeHandoff'] - df_single['TimeSnap']).map(lambda x:x.seconds)\n",
    "\n",
    "    df_single[\"Stadium\"] = df_single[\"Stadium\"].map(lambda x: \"Broncos Stadium at Mile High\" if x==\"Broncos Stadium At Mile High\" \n",
    "                                             else (\"CenturyLink Field\" if x == \"CenturyField\" or x == x==\"CenturyLink\"\n",
    "                                             else (\"Everbank Field\" if x == \"EverBank Field\"\n",
    "                                             else (\"FirstEnergy Stadium\" if x ==\"First Energy Stadium\" or x==\"FirstEnergy\" or x == \"FirstEnergyStadium\"\n",
    "                                             else (\"Lambeau Field\" if x == \"Lambeau field\"\n",
    "                                             else (\"Los Angeles Memorial Coliseum\" if x == \"Los Angeles Memorial Coliesum\"\n",
    "                                             else (\"M&T Bank Stadium\" if x == \"M & T Bank Stadium\" or x == \"M&T Stadium\"\n",
    "                                             else (\"Mercedes-Benz Superdome\" if x == \"Mercedes-Benz Dome\"\n",
    "                                             else (\"MetLife Stadium\" if x == \"MetLife\" or x == \"Metlife Stadium\"\n",
    "                                             else (\"NRG Stadium\" if x == \"NRG\"\n",
    "                                             else (\"Oakland-Alameda County Coliseum\" if x == \"Oakland Alameda-County Coliseum\"\n",
    "                                             else (\"Paul Brown Stadium\" if x == \"Paul Brown Stdium\"\n",
    "                                             else (\"Twickenham Stadium\" if x == \"Twickenham\" else x)))))))))))))\n",
    "\n",
    "    df_single[\"Location\"] = df_single[\"Location\"].map(lambda x: \"Arlington, TX\" if x == \"Arlington, Texas\"\n",
    "                                            else (\"Baltimore, MD\" if x == \"Baltimore, Maryland\" or x == \"Baltimore, Md.\"\n",
    "                                            else (\"Charlotte, NC\" if x == \"Charlotte, North Carolina\"\n",
    "                                            else (\"Chicago, IL\" if x == \"Chicago. IL\"\n",
    "                                            else (\"Cincinnati, OH\" if x == \"Cincinnati, Ohio\"\n",
    "                                            else (\"Cleveland, OH\" if x == \"Cleveland\" or x == \"Cleveland Ohio\" or x == \"Cleveland, Ohio\" or x == \"Cleveland,Ohio\"\n",
    "                                            else (\"Detroit, MI\" if x == \"Detroit\"\n",
    "                                            else (\"East Rutherford, NJ\" if x == \"E. Rutherford, NJ\" or x == \"East Rutherford, N.J.\"\n",
    "                                            else (\"Foxborough, MA\" if x == \"Foxborough, Ma\"\n",
    "                                            else (\"Houston, TX\" if x == \"Houston, Texas\"\n",
    "                                            else (\"Jacksonville, FL\" if x == \"Jacksonville Florida\" or x == \"Jacksonville, Fl\" or x == \"Jacksonville, Florida\"\n",
    "                                            else (\"London\" if x == \"London, England\"\n",
    "                                            else (\"Los Angeles, CA\" if x == \"Los Angeles, Calif.\"\n",
    "                                            else (\"Miami Gardens, FLA\" if x == \"Miami Gardens, Fla.\"\n",
    "                                            else (\"New Orleans, LA\" if x == \"New Orleans\" or x == \"New Orleans, La.\"\n",
    "                                            else (\"Orchard Park, NY\" if x == \"Orchard Park NY\"\n",
    "                                            else (\"Philadelphia, PA\" if x == \"Philadelphia, Pa.\"\n",
    "                                            else (\"Pittsburgh, PA\" if x == \"Pittsburgh\"\n",
    "                                            else (\"Seattle, WA\" if x == \"Seattle\" else x)))))))))))))))))))\n",
    "\n",
    "    grass_labels = ['grass', 'natural grass', 'natural', 'naturall grass']\n",
    "    df_single['Grass'] = np.where(df_single.Turf.str.lower().isin(grass_labels), \"Natural\", \"Artificial\")\n",
    "                                                                 \n",
    "    #top20_weather = list(df.GameWeather.value_counts(normalize=True, dropna=False).cumsum().head(20).index)\n",
    "    #df_single[\"GameWeather\"] = df_single[\"GameWeather\"].apply(lambda x: \"Others\" if x not in top20_weather else x)\n",
    "    \n",
    "    #df_single['WindSpeed'] = df_single['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n",
    "    #df_single['WindSpeed'] = df_single['WindSpeed'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n",
    "    #df_single['WindSpeed'] = df_single['WindSpeed'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n",
    "    #df_single['WindSpeed'] = df_single['WindSpeed'].apply(str_to_float)\n",
    "    \n",
    "    #df_single['WindDirection'] = df_single['WindDirection'].apply(lambda x: \"north\" if x == \"N\" or x == \"FROM S\"\n",
    "    #                                                   else (\"south\" if x == 'S' or x== 'FROM N'\n",
    "    #                                                   else (\"west\" if x == 'W' or x == 'FROM E'\n",
    "    #                                                   else (\"east\" if x == 'E' or x == 'FROM W'\n",
    "    #                                                   else (\"north east\" if x == 'FROM SW' or x == 'FROM SSW' or x == 'FROM WSW'\n",
    "    #                                                   else (\"north west\" if x == 'FROM SE' or x == 'FROM SSE' or x == 'FROM ESE'\n",
    "    #                                                   else (\"south east\" if x == 'FROM NW' or x == 'FROM NNW' or x == 'FROM WNW'\n",
    "    #                                                   else (\"south west\" if x == 'FROM NE' or x == 'FROM NNE' or x == 'FROM ENE'\n",
    "    #                                                   else (\"north west\" if x == 'NW' or x == 'NORTHWEST'\n",
    "    #                                                   else (\"north east\" if x == 'NE' or x == 'NORTH EAST'\n",
    "    #                                                   else (\"south west\" if x == 'SW' or x == 'SOUTHWEST'\n",
    "    #                                                   else (\"south east\" if x == 'SE' or x == 'SOUTHEAST' else \"unknown\"))))))))))))\n",
    "\n",
    "    #outdoor =['Outdoor', 'Outdoors', 'Cloudy', 'Heinz Field', 'Outdor', 'Ourdoor', 'Outside', 'Outddors', \n",
    "    #         'Outdoor Retr Roof-Open', 'Oudoor', 'Bowl']\n",
    "    #indoor_closed = ['Indoors', 'Indoor', 'Indoor, Roof Closed', 'Indoor, Roof Closed',\n",
    "    #                   'Retractable Roof', 'Retr. Roof-Closed', 'Retr. Roof - Closed', 'Retr. Roof Closed']\n",
    "    #indoor_open = ['Indoor, Open Roof', 'Open', 'Retr. Roof-Open', 'Retr. Roof - Open']\n",
    "    #dome_closed = ['Dome', 'Domed, closed', 'Closed Dome', 'Domed', 'Dome, closed']\n",
    "    #dome_open = ['Domed, Open', 'Domed, open']\n",
    "\n",
    "    #df_single['StadiumType'] = df_single['StadiumType'].apply(lambda x: \"outdoor\" if x in outdoor \n",
    "    #                                                        else (\"indoor closed\" if x in indoor_closed\n",
    "    #                                                        else (\"indoor open\" if x in indoor_open\n",
    "    #                                                        else (\"dome_closed\" if x in dome_closed\n",
    "    #                                                        else (\"dome_open\" if x in dome_open else \"unknown\")))))\n",
    "    \n",
    "    #rain = ['Rainy', 'Rain Chance 40%', 'Showers',\n",
    "    #          'Cloudy with periods of rain, thunder possible. Winds shifting to WNW, 10-20 mph.',\n",
    "    #          'Scattered Showers', 'Cloudy, Rain', 'Rain shower', 'Light Rain', 'Rain']\n",
    "    #overcast = ['Cloudy, light snow accumulating 1-3\"', 'Party Cloudy', 'Cloudy, chance of rain',\n",
    "    #              'Coudy', 'Cloudy, 50% change of rain', 'Rain likely, temps in low 40s.',\n",
    "    #              'Cloudy and cold', 'Cloudy, fog started developing in 2nd quarter',\n",
    "    #              'Partly Clouidy', '30% Chance of Rain', 'Mostly Coudy', 'Cloudy and Cool',\n",
    "    #              'cloudy', 'Partly cloudy', 'Overcast', 'Hazy', 'Mostly cloudy', 'Mostly Cloudy',\n",
    "    #              'Partly Cloudy', 'Cloudy']\n",
    "    #clear = ['Partly clear', 'Sunny and clear', 'Sun & clouds', 'Clear and Sunny',\n",
    "    #           'Sunny and cold', 'Sunny Skies', 'Clear and Cool', 'Clear and sunny',\n",
    "    #           'Sunny, highs to upper 80s', 'Mostly Sunny Skies', 'Cold',\n",
    "    #           'Clear and warm', 'Sunny and warm', 'Clear and cold', 'Mostly sunny',\n",
    "    #           'T: 51; H: 55; W: NW 10 mph', 'Clear Skies', 'Clear skies', 'Partly sunny',\n",
    "    #           'Fair', 'Partly Sunny', 'Mostly Sunny', 'Clear', 'Sunny']\n",
    "    #snow = ['Heavy lake effect snow', 'Snow']\n",
    "    #none = ['N/A Indoor', 'Indoors', 'Indoor', 'N/A (Indoors)', 'Controlled Climate']\n",
    "\n",
    "    #df_single['GameWeather'] = train_df['GameWeather'].apply(lambda x: \"rain\" if x in rain \n",
    "    #                                                         else (\"overcast\" if x in overcast\n",
    "    #                                                        else (\"clear\" if x in clear\n",
    "    #                                                        else (\"snow\" if x in snow\n",
    "    #                                                        else (\"indoor\" if x in none else \"unknown\")))))\n",
    "                                                                 \n",
    "    df_single[\"OffenseFormation\"] = df_single[\"OffenseFormation\"].fillna(\"Unknown\") \n",
    "    df_single['DefendersInTheBox_vs_Distance'] = df_single['DefendersInTheBox'] / df_single['Distance']\n",
    "                                                                 \n",
    "    #df_single['back_oriented_down_field'] = df_single['Orientation'].apply(lambda x: back_direction(x))\n",
    "    #df_single['back_moving_down_field'] = df_single['Dir'].apply(lambda x: back_direction(x))\n",
    "\n",
    "    #arr = [[int(s[0]) for s in t.split(\", \")] for t in df_single[\"DefensePersonnel\"]]\n",
    "    #df_single[\"DefenseDL\"] = np.array([a[0] for a in arr])\n",
    "    #df_single[\"DefenseLB\"] = np.array([a[1] for a in arr])\n",
    "    #df_single[\"DefenseDB\"] = np.array([a[2] for a in arr])\n",
    "    #df_single[\"DefenseOL\"] = np.array([a[3] if len(a) == 4 else 0 for a in arr])\n",
    "  \n",
    "    #df_single[\"OffenseRB\"] = df_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "    #                        int(x.replace(\",\", \"\").split(\" RB\")[0][-1]) if \"RB\" in x else 0)\n",
    "    #df_single[\"OffenseTE\"] = df_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "    #                        int(x.replace(\",\", \"\").split(\" TE\")[0][-1]) if \"TE\" in x else 0)\n",
    "    #df_single[\"OffenseWR\"] = df_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "    #                        int(x.replace(\",\", \"\").split(\" WR\")[0][-1]) if \"WR\" in x else 0)\n",
    "    #df_single[\"OffenseOL\"] = df_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "    #                        int(x.replace(\",\", \"\").split(\" OL\")[0][-1]) if \"OL\" in x else 0)\n",
    "    #df_single[\"OffenseDL\"] = df_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "    #                        int(x.replace(\",\", \"\").split(\" DL\")[0][-1]) if \"DL\" in x else 0)\n",
    "    #df_single[\"OffenseQB\"] = df_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "    #                        int(x.replace(\",\", \"\").split(\" QB\")[0][-1]) if \"QB\" in x else 0)\n",
    "  \n",
    "    #df_single[\"DisToQB\"] = np.array(df[(df.Position==\"QB\") | (df.Position==\"C\")].groupby([\"PlayId\"]).agg(np.mean)[\"DisToRusher\"])\n",
    "\n",
    "    #df_single[\"OffenseFormation\"] = df_single[\"OffenseFormation\"].apply(lambda x: \"SHOTGUN\" if x== \"ACE\" else x)\n",
    "\n",
    "    #df_single[\"Margin\"] = df_single[\"HomeScoreBeforePlay\"] - df_single[\"VisitorScoreBeforePlay\"]\n",
    "    #df_single.loc[df_single['Team'] == \"away\", 'Margin'] = (df_single['VisitorScoreBeforePlay'][df_single['Team'] == \"away\"] - df_single['HomeScoreBeforePlay'][df_single['Team'] == \"away\"])\n",
    "\n",
    "    df_single['runner_height'] = df_single.PlayerHeight.map(transform_height)\n",
    "    df_single['own_field'] = (df_single['FieldPosition'] == df_single['PossessionTeam']).astype(int)\n",
    "    dist_to_end = df_single.apply(lambda x:(100 - x.loc['YardLine']) if x.loc['own_field']==1 else x.loc['YardLine'],axis=1)\n",
    "    df_single.drop(remove_features,axis=1,inplace=True) \n",
    "\n",
    "    tmp = df.groupby([\"PlayId\", \"OnOffense\"]).agg(np.mean)[[\"X\", \"Y\"]]\n",
    "    df_single[\"DefenseAveX\"] = np.array(tmp[0::2][\"X\"])\n",
    "    df_single[\"OffenseAveX\"] = np.array(tmp[1::2][\"X\"])\n",
    "\n",
    "    df_single[\"DefenseAveY\"] = np.array(tmp[0::2][\"Y\"]) \n",
    "    df_single[\"OffenseAveY\"] = np.array(tmp[1::2][\"Y\"]) \n",
    "    \n",
    "    #df_single[\"DefenseAveAge\"] = np.array(tmp[0::2][\"age\"])\n",
    "    #df_single[\"OffenseAveAge\"] = np.array(tmp[1::2][\"age\"])\n",
    "\n",
    "    tmp = df.groupby([\"PlayId\", \"OnOffense\"]).agg([\"std\"])[[\"X\", \"Y\"]]\n",
    "    df_single[\"DefenseStdX\"] = np.array(tmp[0::2][\"X\"])\n",
    "    df_single[\"OffenseStdX\"] = np.array(tmp[1::2][\"X\"])\n",
    "\n",
    "    df_single[\"DefenseStdY\"] = np.array(tmp[0::2][\"Y\"])\n",
    "    df_single[\"OffenseStdY\"] = np.array(tmp[1::2][\"Y\"])\n",
    "\n",
    "    df_single[\"RunnerToDefenseCentoid\"] = np.sqrt((df_single[\"X\"] - df_single[\"DefenseAveX\"]) ** 2 + (df_single[\"Y\"] - df_single[\"DefenseAveY\"]) ** 2)\n",
    "    df_single[\"RunnerToOffenseCentoid\"] = np.sqrt((df_single[\"X\"] - df_single[\"OffenseAveX\"]) ** 2 + (df_single[\"Y\"] - df_single[\"OffenseAveY\"]) ** 2)\n",
    "\n",
    "    tmp_max = df.groupby([\"PlayId\", \"OnOffense\"])[\"X\"].max()\n",
    "    tmp_min = df.groupby([\"PlayId\", \"OnOffense\"])[\"X\"].min()\n",
    "    df_single[\"DefenseSpreadX\"] = np.array(tmp_max[0::2]- tmp_min[0::2])\n",
    "    df_single[\"OffenseSpreadX\"] = np.array(tmp_max[1::2]- tmp_min[1::2])\n",
    "\n",
    "    df_single[\"RunnerToScrimmage\"] = df_single[\"X\"] - df_single[\"YardLine\"]\n",
    "\n",
    "    df_single[\"MinTackleTime\"] = np.array(df.groupby([\"PlayId\", \"OnOffense\"])[\"TackleTimeToRusher\"].min()[0::2])\n",
    "    #df_single[\"1stDefender_Momentum_cos\"] = np.array(df.loc[df.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].idxmin()[0::2]][\"Momentum_cos\"])\n",
    "    #df_single[\"1stDefender_Momentum_sin\"] = np.array(df.loc[df.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].idxmin()[0::2]][\"Momentum_sin\"])\n",
    "    #df_single[\"1stDefender_A\"] = np.array(df.loc[df.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].idxmin()[0::2]][\"A\"])\n",
    "\n",
    "    #df_single[\"Rusher1stDefSpeedRatio\"] = df.loc[df.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].idxmin()[0::2]][\"RatioSToRusher\"]\n",
    "\n",
    "    pts = np.array(df[[\"X\", \"Y\"]]).reshape(df.shape[0]//22, 22, 2) # plays * players * (X, Y, rusher)\n",
    "    rusher_index = list(df[df.is_run==True].index % 22) \n",
    "    closest_def_index = list(df.loc[df.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].idxmin()[0::2]].index % 22)\n",
    "    rusher_voronoi = []\n",
    "    closest_def_voronoi = []\n",
    "\n",
    "    for i in range(0, df.shape[0] //22):\n",
    "        rusher_voronoi.append(voronoi_volumes(pts[i], rusher_index[i]))\n",
    "        closest_def_voronoi.append(voronoi_volumes(pts[i], closest_def_index[i]))\n",
    "    df_single[\"RusherVoronoi\"] = rusher_voronoi    \n",
    "    df_single[\"FirstDefenderVoronoi\"] = closest_def_voronoi \n",
    "    df_single.fillna(-999,inplace=True) \n",
    "    #remove_features2 = [\"OnOffense\", \"DisToRusher\"], \"TackleTimeToRusher\", \"RatioSToRusher\"]\n",
    "    #df_single.drop(remove_features2, axis=1, inplace=True)\n",
    "    \n",
    "    if \"Yards\" not in df_single.columns:\n",
    "        df_single.drop([\"GameId\", 'PossessionTeam'], axis=1, inplace=True)\n",
    "\n",
    "    return df_single, dist_to_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_single, dist_to_end_train = transform_data(train)\n",
    "y_train = train_single.Yards\n",
    "X_train = train_single.drop(['Yards'],axis=1)\n",
    "for f in X_train.columns:\n",
    "    if X_train[f].dtype=='object': \n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(X_train[f])+[-999])\n",
    "        X_train[f] = lbl.transform(list(X_train[f]))\n",
    "X_train_first = X_train.drop(['GameId', 'PossessionTeam'],axis=1)\n",
    "cdf = get_cdf_df(y_train).values.reshape(-1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l1: 3.78148\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's l1: 3.71156\n",
      "[3]\tvalid_0's l1: 3.66778\n",
      "[4]\tvalid_0's l1: 3.61949\n",
      "[5]\tvalid_0's l1: 3.58954\n",
      "[6]\tvalid_0's l1: 3.55798\n",
      "[7]\tvalid_0's l1: 3.53686\n",
      "[8]\tvalid_0's l1: 3.5046\n",
      "[9]\tvalid_0's l1: 3.49249\n",
      "[10]\tvalid_0's l1: 3.47322\n",
      "[11]\tvalid_0's l1: 3.46322\n",
      "[12]\tvalid_0's l1: 3.44233\n",
      "[13]\tvalid_0's l1: 3.43283\n",
      "[14]\tvalid_0's l1: 3.42673\n",
      "[15]\tvalid_0's l1: 3.42046\n",
      "[16]\tvalid_0's l1: 3.40599\n",
      "[17]\tvalid_0's l1: 3.3993\n",
      "[18]\tvalid_0's l1: 3.39573\n",
      "[19]\tvalid_0's l1: 3.38556\n",
      "[20]\tvalid_0's l1: 3.38305\n",
      "[21]\tvalid_0's l1: 3.37774\n",
      "[22]\tvalid_0's l1: 3.37616\n",
      "[23]\tvalid_0's l1: 3.37354\n",
      "[24]\tvalid_0's l1: 3.36849\n",
      "[25]\tvalid_0's l1: 3.35857\n",
      "[26]\tvalid_0's l1: 3.35757\n",
      "[27]\tvalid_0's l1: 3.3566\n",
      "[28]\tvalid_0's l1: 3.3562\n",
      "[29]\tvalid_0's l1: 3.35795\n",
      "[30]\tvalid_0's l1: 3.36093\n",
      "[31]\tvalid_0's l1: 3.35562\n",
      "[32]\tvalid_0's l1: 3.35187\n",
      "[33]\tvalid_0's l1: 3.35352\n",
      "[34]\tvalid_0's l1: 3.35093\n",
      "[35]\tvalid_0's l1: 3.35554\n",
      "[36]\tvalid_0's l1: 3.35606\n",
      "[37]\tvalid_0's l1: 3.35312\n",
      "[38]\tvalid_0's l1: 3.3549\n",
      "[39]\tvalid_0's l1: 3.35276\n",
      "[40]\tvalid_0's l1: 3.35199\n",
      "[41]\tvalid_0's l1: 3.35055\n",
      "[42]\tvalid_0's l1: 3.35007\n",
      "[43]\tvalid_0's l1: 3.35339\n",
      "[44]\tvalid_0's l1: 3.35453\n",
      "[45]\tvalid_0's l1: 3.35239\n",
      "[46]\tvalid_0's l1: 3.35036\n",
      "[47]\tvalid_0's l1: 3.34822\n",
      "[48]\tvalid_0's l1: 3.35053\n",
      "[49]\tvalid_0's l1: 3.3538\n",
      "[50]\tvalid_0's l1: 3.35085\n",
      "[51]\tvalid_0's l1: 3.35035\n",
      "[52]\tvalid_0's l1: 3.35043\n",
      "[53]\tvalid_0's l1: 3.34925\n",
      "[54]\tvalid_0's l1: 3.35398\n",
      "[55]\tvalid_0's l1: 3.35479\n",
      "[56]\tvalid_0's l1: 3.35453\n",
      "[57]\tvalid_0's l1: 3.35493\n",
      "[58]\tvalid_0's l1: 3.35645\n",
      "[59]\tvalid_0's l1: 3.35617\n",
      "[60]\tvalid_0's l1: 3.35764\n",
      "[61]\tvalid_0's l1: 3.35909\n",
      "[62]\tvalid_0's l1: 3.35983\n",
      "[63]\tvalid_0's l1: 3.36104\n",
      "[64]\tvalid_0's l1: 3.3614\n",
      "[65]\tvalid_0's l1: 3.3622\n",
      "[66]\tvalid_0's l1: 3.36318\n",
      "[67]\tvalid_0's l1: 3.36356\n",
      "[68]\tvalid_0's l1: 3.36154\n",
      "[69]\tvalid_0's l1: 3.35867\n",
      "[70]\tvalid_0's l1: 3.35881\n",
      "[71]\tvalid_0's l1: 3.35788\n",
      "[72]\tvalid_0's l1: 3.35694\n",
      "[73]\tvalid_0's l1: 3.35642\n",
      "[74]\tvalid_0's l1: 3.35723\n",
      "[75]\tvalid_0's l1: 3.35676\n",
      "[76]\tvalid_0's l1: 3.35473\n",
      "[77]\tvalid_0's l1: 3.35601\n",
      "[78]\tvalid_0's l1: 3.35631\n",
      "[79]\tvalid_0's l1: 3.35586\n",
      "[80]\tvalid_0's l1: 3.35787\n",
      "[81]\tvalid_0's l1: 3.35691\n",
      "[82]\tvalid_0's l1: 3.3592\n",
      "[83]\tvalid_0's l1: 3.36184\n",
      "[84]\tvalid_0's l1: 3.36313\n",
      "[85]\tvalid_0's l1: 3.36345\n",
      "[86]\tvalid_0's l1: 3.36303\n",
      "[87]\tvalid_0's l1: 3.36473\n",
      "[88]\tvalid_0's l1: 3.36543\n",
      "[89]\tvalid_0's l1: 3.36603\n",
      "[90]\tvalid_0's l1: 3.3664\n",
      "[91]\tvalid_0's l1: 3.36864\n",
      "[92]\tvalid_0's l1: 3.36889\n",
      "[93]\tvalid_0's l1: 3.37099\n",
      "[94]\tvalid_0's l1: 3.369\n",
      "[95]\tvalid_0's l1: 3.37049\n",
      "[96]\tvalid_0's l1: 3.37136\n",
      "[97]\tvalid_0's l1: 3.37235\n",
      "[98]\tvalid_0's l1: 3.37206\n",
      "[99]\tvalid_0's l1: 3.37293\n",
      "[100]\tvalid_0's l1: 3.37364\n",
      "[101]\tvalid_0's l1: 3.37475\n",
      "[102]\tvalid_0's l1: 3.37374\n",
      "[103]\tvalid_0's l1: 3.37521\n",
      "[104]\tvalid_0's l1: 3.3777\n",
      "[105]\tvalid_0's l1: 3.37985\n",
      "[106]\tvalid_0's l1: 3.38095\n",
      "[107]\tvalid_0's l1: 3.38099\n",
      "[108]\tvalid_0's l1: 3.37962\n",
      "[109]\tvalid_0's l1: 3.38075\n",
      "[110]\tvalid_0's l1: 3.38147\n",
      "[111]\tvalid_0's l1: 3.38135\n",
      "[112]\tvalid_0's l1: 3.38223\n",
      "[113]\tvalid_0's l1: 3.38377\n",
      "[114]\tvalid_0's l1: 3.38405\n",
      "[115]\tvalid_0's l1: 3.38417\n",
      "[116]\tvalid_0's l1: 3.38511\n",
      "[117]\tvalid_0's l1: 3.38424\n",
      "[118]\tvalid_0's l1: 3.38291\n",
      "[119]\tvalid_0's l1: 3.3832\n",
      "[120]\tvalid_0's l1: 3.3839\n",
      "[121]\tvalid_0's l1: 3.38373\n",
      "[122]\tvalid_0's l1: 3.38451\n",
      "[123]\tvalid_0's l1: 3.38454\n",
      "[124]\tvalid_0's l1: 3.38592\n",
      "[125]\tvalid_0's l1: 3.38456\n",
      "[126]\tvalid_0's l1: 3.38609\n",
      "[127]\tvalid_0's l1: 3.38738\n",
      "[128]\tvalid_0's l1: 3.38803\n",
      "[129]\tvalid_0's l1: 3.38892\n",
      "[130]\tvalid_0's l1: 3.38806\n",
      "[131]\tvalid_0's l1: 3.38941\n",
      "[132]\tvalid_0's l1: 3.38932\n",
      "[133]\tvalid_0's l1: 3.38919\n",
      "[134]\tvalid_0's l1: 3.39005\n",
      "[135]\tvalid_0's l1: 3.39247\n",
      "[136]\tvalid_0's l1: 3.39432\n",
      "[137]\tvalid_0's l1: 3.39442\n",
      "[138]\tvalid_0's l1: 3.39648\n",
      "[139]\tvalid_0's l1: 3.3957\n",
      "[140]\tvalid_0's l1: 3.39574\n",
      "[141]\tvalid_0's l1: 3.39441\n",
      "[142]\tvalid_0's l1: 3.39571\n",
      "[143]\tvalid_0's l1: 3.39862\n",
      "[144]\tvalid_0's l1: 3.39834\n",
      "[145]\tvalid_0's l1: 3.39861\n",
      "[146]\tvalid_0's l1: 3.3992\n",
      "[147]\tvalid_0's l1: 3.40059\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's l1: 3.34822\n",
      "0.0128628146866134\n",
      "[1]\tvalid_0's l1: 3.77994\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's l1: 3.71915\n",
      "[3]\tvalid_0's l1: 3.66474\n",
      "[4]\tvalid_0's l1: 3.62629\n",
      "[5]\tvalid_0's l1: 3.58131\n",
      "[6]\tvalid_0's l1: 3.55039\n",
      "[7]\tvalid_0's l1: 3.51726\n",
      "[8]\tvalid_0's l1: 3.49174\n",
      "[9]\tvalid_0's l1: 3.4717\n",
      "[10]\tvalid_0's l1: 3.45792\n",
      "[11]\tvalid_0's l1: 3.442\n",
      "[12]\tvalid_0's l1: 3.42581\n",
      "[13]\tvalid_0's l1: 3.40925\n",
      "[14]\tvalid_0's l1: 3.39486\n",
      "[15]\tvalid_0's l1: 3.38758\n",
      "[16]\tvalid_0's l1: 3.38258\n",
      "[17]\tvalid_0's l1: 3.37917\n",
      "[18]\tvalid_0's l1: 3.37369\n",
      "[19]\tvalid_0's l1: 3.37018\n",
      "[20]\tvalid_0's l1: 3.35936\n",
      "[21]\tvalid_0's l1: 3.35534\n",
      "[22]\tvalid_0's l1: 3.35235\n",
      "[23]\tvalid_0's l1: 3.34907\n",
      "[24]\tvalid_0's l1: 3.34802\n",
      "[25]\tvalid_0's l1: 3.34219\n",
      "[26]\tvalid_0's l1: 3.33708\n",
      "[27]\tvalid_0's l1: 3.33578\n",
      "[28]\tvalid_0's l1: 3.33466\n",
      "[29]\tvalid_0's l1: 3.33276\n",
      "[30]\tvalid_0's l1: 3.32597\n",
      "[31]\tvalid_0's l1: 3.32658\n",
      "[32]\tvalid_0's l1: 3.32716\n",
      "[33]\tvalid_0's l1: 3.32825\n",
      "[34]\tvalid_0's l1: 3.32287\n",
      "[35]\tvalid_0's l1: 3.3228\n",
      "[36]\tvalid_0's l1: 3.32263\n",
      "[37]\tvalid_0's l1: 3.32021\n",
      "[38]\tvalid_0's l1: 3.31897\n",
      "[39]\tvalid_0's l1: 3.31886\n",
      "[40]\tvalid_0's l1: 3.31931\n",
      "[41]\tvalid_0's l1: 3.31807\n",
      "[42]\tvalid_0's l1: 3.31731\n",
      "[43]\tvalid_0's l1: 3.31483\n",
      "[44]\tvalid_0's l1: 3.31581\n",
      "[45]\tvalid_0's l1: 3.31538\n",
      "[46]\tvalid_0's l1: 3.31718\n",
      "[47]\tvalid_0's l1: 3.31651\n",
      "[48]\tvalid_0's l1: 3.31522\n",
      "[49]\tvalid_0's l1: 3.31735\n",
      "[50]\tvalid_0's l1: 3.31657\n",
      "[51]\tvalid_0's l1: 3.31619\n",
      "[52]\tvalid_0's l1: 3.31731\n",
      "[53]\tvalid_0's l1: 3.31845\n",
      "[54]\tvalid_0's l1: 3.32004\n",
      "[55]\tvalid_0's l1: 3.32039\n",
      "[56]\tvalid_0's l1: 3.3227\n",
      "[57]\tvalid_0's l1: 3.32336\n",
      "[58]\tvalid_0's l1: 3.32471\n",
      "[59]\tvalid_0's l1: 3.32726\n",
      "[60]\tvalid_0's l1: 3.32786\n",
      "[61]\tvalid_0's l1: 3.32841\n",
      "[62]\tvalid_0's l1: 3.32979\n",
      "[63]\tvalid_0's l1: 3.32894\n",
      "[64]\tvalid_0's l1: 3.32827\n",
      "[65]\tvalid_0's l1: 3.33078\n",
      "[66]\tvalid_0's l1: 3.3322\n",
      "[67]\tvalid_0's l1: 3.33268\n",
      "[68]\tvalid_0's l1: 3.33435\n",
      "[69]\tvalid_0's l1: 3.33346\n",
      "[70]\tvalid_0's l1: 3.33444\n",
      "[71]\tvalid_0's l1: 3.33613\n",
      "[72]\tvalid_0's l1: 3.33469\n",
      "[73]\tvalid_0's l1: 3.33614\n",
      "[74]\tvalid_0's l1: 3.33572\n",
      "[75]\tvalid_0's l1: 3.33613\n",
      "[76]\tvalid_0's l1: 3.33748\n",
      "[77]\tvalid_0's l1: 3.33553\n",
      "[78]\tvalid_0's l1: 3.33675\n",
      "[79]\tvalid_0's l1: 3.33797\n",
      "[80]\tvalid_0's l1: 3.3374\n",
      "[81]\tvalid_0's l1: 3.33768\n",
      "[82]\tvalid_0's l1: 3.33797\n",
      "[83]\tvalid_0's l1: 3.33895\n",
      "[84]\tvalid_0's l1: 3.34106\n",
      "[85]\tvalid_0's l1: 3.34225\n",
      "[86]\tvalid_0's l1: 3.34199\n",
      "[87]\tvalid_0's l1: 3.34277\n",
      "[88]\tvalid_0's l1: 3.34325\n",
      "[89]\tvalid_0's l1: 3.34456\n",
      "[90]\tvalid_0's l1: 3.34517\n",
      "[91]\tvalid_0's l1: 3.34582\n",
      "[92]\tvalid_0's l1: 3.34689\n",
      "[93]\tvalid_0's l1: 3.34768\n",
      "[94]\tvalid_0's l1: 3.3484\n",
      "[95]\tvalid_0's l1: 3.3496\n",
      "[96]\tvalid_0's l1: 3.35126\n",
      "[97]\tvalid_0's l1: 3.35157\n",
      "[98]\tvalid_0's l1: 3.35095\n",
      "[99]\tvalid_0's l1: 3.35087\n",
      "[100]\tvalid_0's l1: 3.35092\n",
      "[101]\tvalid_0's l1: 3.35248\n",
      "[102]\tvalid_0's l1: 3.35139\n",
      "[103]\tvalid_0's l1: 3.35232\n",
      "[104]\tvalid_0's l1: 3.35427\n",
      "[105]\tvalid_0's l1: 3.35525\n",
      "[106]\tvalid_0's l1: 3.35614\n",
      "[107]\tvalid_0's l1: 3.35671\n",
      "[108]\tvalid_0's l1: 3.3576\n",
      "[109]\tvalid_0's l1: 3.35716\n",
      "[110]\tvalid_0's l1: 3.35737\n",
      "[111]\tvalid_0's l1: 3.35717\n",
      "[112]\tvalid_0's l1: 3.35575\n",
      "[113]\tvalid_0's l1: 3.35503\n",
      "[114]\tvalid_0's l1: 3.35531\n",
      "[115]\tvalid_0's l1: 3.35392\n",
      "[116]\tvalid_0's l1: 3.35437\n",
      "[117]\tvalid_0's l1: 3.35444\n",
      "[118]\tvalid_0's l1: 3.35444\n",
      "[119]\tvalid_0's l1: 3.35519\n",
      "[120]\tvalid_0's l1: 3.35607\n",
      "[121]\tvalid_0's l1: 3.35607\n",
      "[122]\tvalid_0's l1: 3.35587\n",
      "[123]\tvalid_0's l1: 3.35647\n",
      "[124]\tvalid_0's l1: 3.35686\n",
      "[125]\tvalid_0's l1: 3.3573\n",
      "[126]\tvalid_0's l1: 3.35738\n",
      "[127]\tvalid_0's l1: 3.35771\n",
      "[128]\tvalid_0's l1: 3.35795\n",
      "[129]\tvalid_0's l1: 3.35806\n",
      "[130]\tvalid_0's l1: 3.35921\n",
      "[131]\tvalid_0's l1: 3.36155\n",
      "[132]\tvalid_0's l1: 3.36087\n",
      "[133]\tvalid_0's l1: 3.36267\n",
      "[134]\tvalid_0's l1: 3.36411\n",
      "[135]\tvalid_0's l1: 3.36454\n",
      "[136]\tvalid_0's l1: 3.36362\n",
      "[137]\tvalid_0's l1: 3.36422\n",
      "[138]\tvalid_0's l1: 3.3638\n",
      "[139]\tvalid_0's l1: 3.36436\n",
      "[140]\tvalid_0's l1: 3.36561\n",
      "[141]\tvalid_0's l1: 3.36638\n",
      "[142]\tvalid_0's l1: 3.36565\n",
      "[143]\tvalid_0's l1: 3.36463\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's l1: 3.31483\n",
      "0.012534147736735184\n",
      "[1]\tvalid_0's l1: 3.59584\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's l1: 3.55566\n",
      "[3]\tvalid_0's l1: 3.52028\n",
      "[4]\tvalid_0's l1: 3.48852\n",
      "[5]\tvalid_0's l1: 3.46459\n",
      "[6]\tvalid_0's l1: 3.44704\n",
      "[7]\tvalid_0's l1: 3.42762\n",
      "[8]\tvalid_0's l1: 3.41131\n",
      "[9]\tvalid_0's l1: 3.3954\n",
      "[10]\tvalid_0's l1: 3.38174\n",
      "[11]\tvalid_0's l1: 3.37357\n",
      "[12]\tvalid_0's l1: 3.36807\n",
      "[13]\tvalid_0's l1: 3.36193\n",
      "[14]\tvalid_0's l1: 3.35468\n",
      "[15]\tvalid_0's l1: 3.34604\n",
      "[16]\tvalid_0's l1: 3.33895\n",
      "[17]\tvalid_0's l1: 3.33909\n",
      "[18]\tvalid_0's l1: 3.33575\n",
      "[19]\tvalid_0's l1: 3.33386\n",
      "[20]\tvalid_0's l1: 3.32994\n",
      "[21]\tvalid_0's l1: 3.32866\n",
      "[22]\tvalid_0's l1: 3.32697\n",
      "[23]\tvalid_0's l1: 3.32306\n",
      "[24]\tvalid_0's l1: 3.31925\n",
      "[25]\tvalid_0's l1: 3.31749\n",
      "[26]\tvalid_0's l1: 3.31718\n",
      "[27]\tvalid_0's l1: 3.31675\n",
      "[28]\tvalid_0's l1: 3.31592\n",
      "[29]\tvalid_0's l1: 3.31231\n",
      "[30]\tvalid_0's l1: 3.30913\n",
      "[31]\tvalid_0's l1: 3.30892\n",
      "[32]\tvalid_0's l1: 3.30857\n",
      "[33]\tvalid_0's l1: 3.30818\n",
      "[34]\tvalid_0's l1: 3.30863\n",
      "[35]\tvalid_0's l1: 3.31018\n",
      "[36]\tvalid_0's l1: 3.31139\n",
      "[37]\tvalid_0's l1: 3.31261\n",
      "[38]\tvalid_0's l1: 3.31358\n",
      "[39]\tvalid_0's l1: 3.3144\n",
      "[40]\tvalid_0's l1: 3.31409\n",
      "[41]\tvalid_0's l1: 3.31615\n",
      "[42]\tvalid_0's l1: 3.31417\n",
      "[43]\tvalid_0's l1: 3.31413\n",
      "[44]\tvalid_0's l1: 3.31622\n",
      "[45]\tvalid_0's l1: 3.31551\n",
      "[46]\tvalid_0's l1: 3.31624\n",
      "[47]\tvalid_0's l1: 3.31444\n",
      "[48]\tvalid_0's l1: 3.3129\n",
      "[49]\tvalid_0's l1: 3.31317\n",
      "[50]\tvalid_0's l1: 3.31368\n",
      "[51]\tvalid_0's l1: 3.31366\n",
      "[52]\tvalid_0's l1: 3.31453\n",
      "[53]\tvalid_0's l1: 3.3144\n",
      "[54]\tvalid_0's l1: 3.31368\n",
      "[55]\tvalid_0's l1: 3.31262\n",
      "[56]\tvalid_0's l1: 3.3145\n",
      "[57]\tvalid_0's l1: 3.31327\n",
      "[58]\tvalid_0's l1: 3.3133\n",
      "[59]\tvalid_0's l1: 3.31253\n",
      "[60]\tvalid_0's l1: 3.3134\n",
      "[61]\tvalid_0's l1: 3.31524\n",
      "[62]\tvalid_0's l1: 3.31534\n",
      "[63]\tvalid_0's l1: 3.31647\n",
      "[64]\tvalid_0's l1: 3.31801\n",
      "[65]\tvalid_0's l1: 3.31488\n",
      "[66]\tvalid_0's l1: 3.31504\n",
      "[67]\tvalid_0's l1: 3.31457\n",
      "[68]\tvalid_0's l1: 3.31512\n",
      "[69]\tvalid_0's l1: 3.31522\n",
      "[70]\tvalid_0's l1: 3.31517\n",
      "[71]\tvalid_0's l1: 3.31528\n",
      "[72]\tvalid_0's l1: 3.31651\n",
      "[73]\tvalid_0's l1: 3.31803\n",
      "[74]\tvalid_0's l1: 3.31899\n",
      "[75]\tvalid_0's l1: 3.31991\n",
      "[76]\tvalid_0's l1: 3.32022\n",
      "[77]\tvalid_0's l1: 3.32026\n",
      "[78]\tvalid_0's l1: 3.32059\n",
      "[79]\tvalid_0's l1: 3.3201\n",
      "[80]\tvalid_0's l1: 3.32003\n",
      "[81]\tvalid_0's l1: 3.32053\n",
      "[82]\tvalid_0's l1: 3.3233\n",
      "[83]\tvalid_0's l1: 3.3231\n",
      "[84]\tvalid_0's l1: 3.3234\n",
      "[85]\tvalid_0's l1: 3.3239\n",
      "[86]\tvalid_0's l1: 3.32399\n",
      "[87]\tvalid_0's l1: 3.32392\n",
      "[88]\tvalid_0's l1: 3.32505\n",
      "[89]\tvalid_0's l1: 3.32617\n",
      "[90]\tvalid_0's l1: 3.32694\n",
      "[91]\tvalid_0's l1: 3.32766\n",
      "[92]\tvalid_0's l1: 3.3297\n",
      "[93]\tvalid_0's l1: 3.32869\n",
      "[94]\tvalid_0's l1: 3.32978\n",
      "[95]\tvalid_0's l1: 3.32871\n",
      "[96]\tvalid_0's l1: 3.32942\n",
      "[97]\tvalid_0's l1: 3.3302\n",
      "[98]\tvalid_0's l1: 3.33013\n",
      "[99]\tvalid_0's l1: 3.32998\n",
      "[100]\tvalid_0's l1: 3.33157\n",
      "[101]\tvalid_0's l1: 3.33092\n",
      "[102]\tvalid_0's l1: 3.33127\n",
      "[103]\tvalid_0's l1: 3.33199\n",
      "[104]\tvalid_0's l1: 3.33233\n",
      "[105]\tvalid_0's l1: 3.33307\n",
      "[106]\tvalid_0's l1: 3.33369\n",
      "[107]\tvalid_0's l1: 3.33463\n",
      "[108]\tvalid_0's l1: 3.33486\n",
      "[109]\tvalid_0's l1: 3.33623\n",
      "[110]\tvalid_0's l1: 3.33665\n",
      "[111]\tvalid_0's l1: 3.33544\n",
      "[112]\tvalid_0's l1: 3.33506\n",
      "[113]\tvalid_0's l1: 3.33426\n",
      "[114]\tvalid_0's l1: 3.33501\n",
      "[115]\tvalid_0's l1: 3.33362\n",
      "[116]\tvalid_0's l1: 3.33399\n",
      "[117]\tvalid_0's l1: 3.33331\n",
      "[118]\tvalid_0's l1: 3.3336\n",
      "[119]\tvalid_0's l1: 3.33468\n",
      "[120]\tvalid_0's l1: 3.33547\n",
      "[121]\tvalid_0's l1: 3.33632\n",
      "[122]\tvalid_0's l1: 3.33527\n",
      "[123]\tvalid_0's l1: 3.33681\n",
      "[124]\tvalid_0's l1: 3.33649\n",
      "[125]\tvalid_0's l1: 3.33654\n",
      "[126]\tvalid_0's l1: 3.33705\n",
      "[127]\tvalid_0's l1: 3.33779\n",
      "[128]\tvalid_0's l1: 3.33873\n",
      "[129]\tvalid_0's l1: 3.33979\n",
      "[130]\tvalid_0's l1: 3.34154\n",
      "[131]\tvalid_0's l1: 3.34148\n",
      "[132]\tvalid_0's l1: 3.34279\n",
      "[133]\tvalid_0's l1: 3.3399\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's l1: 3.30818\n",
      "0.012364225927698466\n",
      "[1]\tvalid_0's l1: 4.02163\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's l1: 4.01615\n",
      "[3]\tvalid_0's l1: 4.01622\n",
      "[4]\tvalid_0's l1: 4.00658\n",
      "[5]\tvalid_0's l1: 4.0054\n",
      "[6]\tvalid_0's l1: 4.00834\n",
      "[7]\tvalid_0's l1: 4.00428\n",
      "[8]\tvalid_0's l1: 4.00237\n",
      "[9]\tvalid_0's l1: 4.00137\n",
      "[10]\tvalid_0's l1: 3.99757\n",
      "[11]\tvalid_0's l1: 3.9997\n",
      "[12]\tvalid_0's l1: 3.99252\n",
      "[13]\tvalid_0's l1: 3.99658\n",
      "[14]\tvalid_0's l1: 3.9967\n",
      "[15]\tvalid_0's l1: 3.99523\n",
      "[16]\tvalid_0's l1: 3.99602\n",
      "[17]\tvalid_0's l1: 3.99583\n",
      "[18]\tvalid_0's l1: 4.00003\n",
      "[19]\tvalid_0's l1: 4.00109\n",
      "[20]\tvalid_0's l1: 3.99939\n",
      "[21]\tvalid_0's l1: 3.99935\n",
      "[22]\tvalid_0's l1: 4.00407\n",
      "[23]\tvalid_0's l1: 4.00566\n",
      "[24]\tvalid_0's l1: 4.0059\n",
      "[25]\tvalid_0's l1: 4.00575\n",
      "[26]\tvalid_0's l1: 4.00714\n",
      "[27]\tvalid_0's l1: 4.00618\n",
      "[28]\tvalid_0's l1: 4.00591\n",
      "[29]\tvalid_0's l1: 4.00579\n",
      "[30]\tvalid_0's l1: 4.00618\n",
      "[31]\tvalid_0's l1: 4.00899\n",
      "[32]\tvalid_0's l1: 4.00643\n",
      "[33]\tvalid_0's l1: 4.00683\n",
      "[34]\tvalid_0's l1: 4.01022\n",
      "[35]\tvalid_0's l1: 4.01338\n",
      "[36]\tvalid_0's l1: 4.01546\n",
      "[37]\tvalid_0's l1: 4.01565\n",
      "[38]\tvalid_0's l1: 4.01513\n",
      "[39]\tvalid_0's l1: 4.01288\n",
      "[40]\tvalid_0's l1: 4.00826\n",
      "[41]\tvalid_0's l1: 4.00855\n",
      "[42]\tvalid_0's l1: 4.01069\n",
      "[43]\tvalid_0's l1: 4.00952\n",
      "[44]\tvalid_0's l1: 4.01146\n",
      "[45]\tvalid_0's l1: 4.01002\n",
      "[46]\tvalid_0's l1: 4.00642\n",
      "[47]\tvalid_0's l1: 4.00922\n",
      "[48]\tvalid_0's l1: 4.01069\n",
      "[49]\tvalid_0's l1: 4.00953\n",
      "[50]\tvalid_0's l1: 4.01168\n",
      "[51]\tvalid_0's l1: 4.01101\n",
      "[52]\tvalid_0's l1: 4.01221\n",
      "[53]\tvalid_0's l1: 4.01012\n",
      "[54]\tvalid_0's l1: 4.01168\n",
      "[55]\tvalid_0's l1: 4.01202\n",
      "[56]\tvalid_0's l1: 4.01188\n",
      "[57]\tvalid_0's l1: 4.0127\n",
      "[58]\tvalid_0's l1: 4.01067\n",
      "[59]\tvalid_0's l1: 4.01181\n",
      "[60]\tvalid_0's l1: 4.01223\n",
      "[61]\tvalid_0's l1: 4.01481\n",
      "[62]\tvalid_0's l1: 4.01443\n",
      "[63]\tvalid_0's l1: 4.01578\n",
      "[64]\tvalid_0's l1: 4.01743\n",
      "[65]\tvalid_0's l1: 4.01872\n",
      "[66]\tvalid_0's l1: 4.01756\n",
      "[67]\tvalid_0's l1: 4.01852\n",
      "[68]\tvalid_0's l1: 4.02199\n",
      "[69]\tvalid_0's l1: 4.02051\n",
      "[70]\tvalid_0's l1: 4.021\n",
      "[71]\tvalid_0's l1: 4.02114\n",
      "[72]\tvalid_0's l1: 4.02173\n",
      "[73]\tvalid_0's l1: 4.02027\n",
      "[74]\tvalid_0's l1: 4.02082\n",
      "[75]\tvalid_0's l1: 4.02139\n",
      "[76]\tvalid_0's l1: 4.02033\n",
      "[77]\tvalid_0's l1: 4.02157\n",
      "[78]\tvalid_0's l1: 4.02241\n",
      "[79]\tvalid_0's l1: 4.02184\n",
      "[80]\tvalid_0's l1: 4.02291\n",
      "[81]\tvalid_0's l1: 4.02329\n",
      "[82]\tvalid_0's l1: 4.02282\n",
      "[83]\tvalid_0's l1: 4.02219\n",
      "[84]\tvalid_0's l1: 4.02292\n",
      "[85]\tvalid_0's l1: 4.023\n",
      "[86]\tvalid_0's l1: 4.02077\n",
      "[87]\tvalid_0's l1: 4.02215\n",
      "[88]\tvalid_0's l1: 4.02178\n",
      "[89]\tvalid_0's l1: 4.02045\n",
      "[90]\tvalid_0's l1: 4.02118\n",
      "[91]\tvalid_0's l1: 4.02221\n",
      "[92]\tvalid_0's l1: 4.02223\n",
      "[93]\tvalid_0's l1: 4.02272\n",
      "[94]\tvalid_0's l1: 4.02457\n",
      "[95]\tvalid_0's l1: 4.0215\n",
      "[96]\tvalid_0's l1: 4.02156\n",
      "[97]\tvalid_0's l1: 4.02247\n",
      "[98]\tvalid_0's l1: 4.02143\n",
      "[99]\tvalid_0's l1: 4.02131\n",
      "[100]\tvalid_0's l1: 4.02143\n",
      "[101]\tvalid_0's l1: 4.02297\n",
      "[102]\tvalid_0's l1: 4.02258\n",
      "[103]\tvalid_0's l1: 4.0224\n",
      "[104]\tvalid_0's l1: 4.0241\n",
      "[105]\tvalid_0's l1: 4.02336\n",
      "[106]\tvalid_0's l1: 4.02414\n",
      "[107]\tvalid_0's l1: 4.02465\n",
      "[108]\tvalid_0's l1: 4.02651\n",
      "[109]\tvalid_0's l1: 4.02687\n",
      "[110]\tvalid_0's l1: 4.02657\n",
      "[111]\tvalid_0's l1: 4.02659\n",
      "[112]\tvalid_0's l1: 4.0271\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's l1: 3.99252\n",
      "0.014729496485824134\n",
      "[1]\tvalid_0's l1: 3.929\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's l1: 3.92311\n",
      "[3]\tvalid_0's l1: 3.91936\n",
      "[4]\tvalid_0's l1: 3.9127\n",
      "[5]\tvalid_0's l1: 3.90396\n",
      "[6]\tvalid_0's l1: 3.89887\n",
      "[7]\tvalid_0's l1: 3.8974\n",
      "[8]\tvalid_0's l1: 3.89629\n",
      "[9]\tvalid_0's l1: 3.89416\n",
      "[10]\tvalid_0's l1: 3.89695\n",
      "[11]\tvalid_0's l1: 3.90307\n",
      "[12]\tvalid_0's l1: 3.90582\n",
      "[13]\tvalid_0's l1: 3.91484\n",
      "[14]\tvalid_0's l1: 3.91605\n",
      "[15]\tvalid_0's l1: 3.91199\n",
      "[16]\tvalid_0's l1: 3.90888\n",
      "[17]\tvalid_0's l1: 3.91278\n",
      "[18]\tvalid_0's l1: 3.90926\n",
      "[19]\tvalid_0's l1: 3.90625\n",
      "[20]\tvalid_0's l1: 3.91135\n",
      "[21]\tvalid_0's l1: 3.91371\n",
      "[22]\tvalid_0's l1: 3.91591\n",
      "[23]\tvalid_0's l1: 3.91845\n",
      "[24]\tvalid_0's l1: 3.91818\n",
      "[25]\tvalid_0's l1: 3.91791\n",
      "[26]\tvalid_0's l1: 3.92005\n",
      "[27]\tvalid_0's l1: 3.925\n",
      "[28]\tvalid_0's l1: 3.92732\n",
      "[29]\tvalid_0's l1: 3.93117\n",
      "[30]\tvalid_0's l1: 3.93464\n",
      "[31]\tvalid_0's l1: 3.93693\n",
      "[32]\tvalid_0's l1: 3.93916\n",
      "[33]\tvalid_0's l1: 3.9461\n",
      "[34]\tvalid_0's l1: 3.94705\n",
      "[35]\tvalid_0's l1: 3.9488\n",
      "[36]\tvalid_0's l1: 3.95639\n",
      "[37]\tvalid_0's l1: 3.95994\n",
      "[38]\tvalid_0's l1: 3.96182\n",
      "[39]\tvalid_0's l1: 3.96143\n",
      "[40]\tvalid_0's l1: 3.95742\n",
      "[41]\tvalid_0's l1: 3.95818\n",
      "[42]\tvalid_0's l1: 3.95975\n",
      "[43]\tvalid_0's l1: 3.96294\n",
      "[44]\tvalid_0's l1: 3.96259\n",
      "[45]\tvalid_0's l1: 3.96346\n",
      "[46]\tvalid_0's l1: 3.96255\n",
      "[47]\tvalid_0's l1: 3.96496\n",
      "[48]\tvalid_0's l1: 3.96196\n",
      "[49]\tvalid_0's l1: 3.9673\n",
      "[50]\tvalid_0's l1: 3.97128\n",
      "[51]\tvalid_0's l1: 3.97369\n",
      "[52]\tvalid_0's l1: 3.97312\n",
      "[53]\tvalid_0's l1: 3.97445\n",
      "[54]\tvalid_0's l1: 3.97439\n",
      "[55]\tvalid_0's l1: 3.97442\n",
      "[56]\tvalid_0's l1: 3.97731\n",
      "[57]\tvalid_0's l1: 3.9817\n",
      "[58]\tvalid_0's l1: 3.9827\n",
      "[59]\tvalid_0's l1: 3.98378\n",
      "[60]\tvalid_0's l1: 3.98285\n",
      "[61]\tvalid_0's l1: 3.98445\n",
      "[62]\tvalid_0's l1: 3.98731\n",
      "[63]\tvalid_0's l1: 3.98644\n",
      "[64]\tvalid_0's l1: 3.98839\n",
      "[65]\tvalid_0's l1: 3.98782\n",
      "[66]\tvalid_0's l1: 3.99048\n",
      "[67]\tvalid_0's l1: 3.98964\n",
      "[68]\tvalid_0's l1: 3.98867\n",
      "[69]\tvalid_0's l1: 3.98964\n",
      "[70]\tvalid_0's l1: 3.99159\n",
      "[71]\tvalid_0's l1: 3.99418\n",
      "[72]\tvalid_0's l1: 3.99364\n",
      "[73]\tvalid_0's l1: 3.99299\n",
      "[74]\tvalid_0's l1: 3.99485\n",
      "[75]\tvalid_0's l1: 3.99434\n",
      "[76]\tvalid_0's l1: 3.9938\n",
      "[77]\tvalid_0's l1: 3.99478\n",
      "[78]\tvalid_0's l1: 3.99549\n",
      "[79]\tvalid_0's l1: 3.99598\n",
      "[80]\tvalid_0's l1: 3.99708\n",
      "[81]\tvalid_0's l1: 4.0007\n",
      "[82]\tvalid_0's l1: 3.99891\n",
      "[83]\tvalid_0's l1: 4.00116\n",
      "[84]\tvalid_0's l1: 4.0034\n",
      "[85]\tvalid_0's l1: 4.00391\n",
      "[86]\tvalid_0's l1: 4.00785\n",
      "[87]\tvalid_0's l1: 4.00634\n",
      "[88]\tvalid_0's l1: 4.00908\n",
      "[89]\tvalid_0's l1: 4.01059\n",
      "[90]\tvalid_0's l1: 4.01334\n",
      "[91]\tvalid_0's l1: 4.01593\n",
      "[92]\tvalid_0's l1: 4.01687\n",
      "[93]\tvalid_0's l1: 4.01789\n",
      "[94]\tvalid_0's l1: 4.02299\n",
      "[95]\tvalid_0's l1: 4.02381\n",
      "[96]\tvalid_0's l1: 4.0253\n",
      "[97]\tvalid_0's l1: 4.02505\n",
      "[98]\tvalid_0's l1: 4.03873\n",
      "[99]\tvalid_0's l1: 4.03826\n",
      "[100]\tvalid_0's l1: 4.03903\n",
      "[101]\tvalid_0's l1: 4.03827\n",
      "[102]\tvalid_0's l1: 4.03675\n",
      "[103]\tvalid_0's l1: 4.03737\n",
      "[104]\tvalid_0's l1: 4.04069\n",
      "[105]\tvalid_0's l1: 4.04057\n",
      "[106]\tvalid_0's l1: 4.04016\n",
      "[107]\tvalid_0's l1: 4.04125\n",
      "[108]\tvalid_0's l1: 4.04291\n",
      "[109]\tvalid_0's l1: 4.04475\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's l1: 3.89416\n",
      "0.014518250430727688\n",
      "mean mse: 38.10053688049719\n",
      "oof mse: 38.10054085120537\n",
      "mean mae: 3.571582438119051\n",
      "oof mae: 3.571572798415677\n",
      "mean cprs: 0.013401787053519775\n",
      "oof cprs: 0.013401763792876432\n"
     ]
    }
   ],
   "source": [
    "# validation 1\n",
    "n_folds=5\n",
    "kf=KFold(n_splits = n_folds, random_state=1108)\n",
    "resu1 = 0\n",
    "resu2_cprs = 0\n",
    "resu3_mae=0\n",
    "stack_train = np.zeros([X_train.shape[0],])\n",
    "models = []\n",
    "lgbm_params = {\n",
    "    \"objective\" : \"regression\",\n",
    "    \"metric\" : \"mae\", \n",
    "    \"tree_learner\": \"serial\",\n",
    "    \"max_depth\" : -1,\n",
    "    \"boosting\": 'gbdt',\n",
    "    #\"num_leaves\" : 13,\n",
    "    \"learning_rate\" : 0.1,\n",
    "    #\"bagging_freq\": 5,\n",
    "    #\"bagging_fraction\" : 0.4,\n",
    "    #\"feature_fraction\" : 0.05,\n",
    "    #\"min_data_in_leaf\": 80,\n",
    "}\n",
    "feature_importance_df = pd.DataFrame(list(X_train_first.columns), columns=[\"Feature\"])\n",
    "for i , (train_index, test_index) in enumerate(kf.split(X_train_first, y_train)):\n",
    "    X_train2= X_train_first.iloc[train_index,:]\n",
    "    y_train2= y_train.iloc[train_index]\n",
    "    X_test2= X_train_first.iloc[test_index,:]\n",
    "    y_test2= y_train.iloc[test_index]\n",
    "    lgb_train = lgb.Dataset(X_train2, y_train2)\n",
    "    lgb_eval = lgb.Dataset(X_test2, y_test2, reference=lgb_train)\n",
    "    \n",
    "    clf = lgb.train(\n",
    "        lgbm_params, lgb_train,\n",
    "        valid_sets=lgb_eval,\n",
    "        num_boost_round=100000,\n",
    "        early_stopping_rounds=100,\n",
    "    )\n",
    "    \n",
    "    models.append(clf)\n",
    "    temp_predict = clf.predict(X_test2)\n",
    "    stack_train[test_index] = temp_predict\n",
    "    mse = mean_squared_error(y_test2, temp_predict)\n",
    "    crps = CRPS_pingyi1(temp_predict,y_test2,4,cdf,dist_to_end_train.iloc[test_index])\n",
    "    mae = mean_absolute_error(y_test2, temp_predict)\n",
    "    print(crps)\n",
    "    #print(crps_score(temp_predict,y_test2))\n",
    "    \n",
    "    resu1 += mse/n_folds\n",
    "    resu2_cprs += crps/n_folds\n",
    "    resu3_mae += mae/n_folds\n",
    "    feature_importance_df[\"Fold_\"+str(i+1)] = clf.feature_importance()\n",
    "    gc.collect()\n",
    "print('mean mse:',resu1)\n",
    "print('oof mse:',mean_squared_error(y_train,stack_train))\n",
    "print('mean mae:',resu3_mae)\n",
    "print('oof mae:',mean_absolute_error(y_train,stack_train))\n",
    "print('mean cprs:',resu2_cprs)\n",
    "print('oof cprs:',CRPS_pingyi1(stack_train,y_train,4,cdf,dist_to_end_train))\n",
    "feature_importance_df[\"Average\"] = np.mean(feature_importance_df.iloc[:,1:n_folds+1], axis=1)\n",
    "feature_importance_df[\"Std\"] = np.std(feature_importance_df.iloc[:,1:n_folds+1], axis=1)\n",
    "feature_importance_df[\"Cv\"] = feature_importance_df[\"Std\"] / feature_importance_df[\"Average\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Team', 'S', 'A', 'Dis', 'NflId', 'JerseyNumber', 'Season', 'Quarter',\n",
       "       'Down', 'Distance', 'HomeScoreBeforePlay', 'VisitorScoreBeforePlay',\n",
       "       'OffenseFormation', 'OffensePersonnel', 'DefendersInTheBox',\n",
       "       'DefensePersonnel', 'PlayerWeight', 'PlayerCollegeName', 'Position',\n",
       "       'Week', 'Stadium', 'Location', 'StadiumType', 'GameWeather',\n",
       "       'Temperature', 'Humidity', 'WindSpeed', 'WindDirection', 'OnOffense',\n",
       "       'YardLine', 'X', 'Y', 'Orientation', 'Dir', 'age', 'Momentum',\n",
       "       'DisToRusher', 'TackleTimeToRusher', 'Dir_cos', 'Momentum_cos',\n",
       "       'RatioSToRusher', 'time_quarter', 'time_end', 'handoff_snap_diff',\n",
       "       'Grass', 'DefendersInTheBox_vs_Distance', 'runner_height',\n",
       "       'DefenseAveX', 'OffenseAveX', 'DefenseAveY', 'OffenseAveY',\n",
       "       'DefenseStdX', 'OffenseStdX', 'DefenseStdY', 'OffenseStdY',\n",
       "       'RunnerToDefenseCentoid', 'RunnerToOffenseCentoid', 'DefenseSpreadX',\n",
       "       'OffenseSpreadX', 'RunnerToScrimmage', 'MinTackleTime', 'RusherVoronoi',\n",
       "       'FirstDefenderVoronoi'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_first.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Fold_1</th>\n",
       "      <th>Fold_2</th>\n",
       "      <th>Fold_3</th>\n",
       "      <th>Fold_4</th>\n",
       "      <th>Fold_5</th>\n",
       "      <th>Average</th>\n",
       "      <th>Std</th>\n",
       "      <th>Cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>RunnerToOffenseCentoid</td>\n",
       "      <td>44</td>\n",
       "      <td>34</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>23.2</td>\n",
       "      <td>15.210523</td>\n",
       "      <td>0.655626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Season</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>23.4</td>\n",
       "      <td>4.363485</td>\n",
       "      <td>0.186474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Dir_cos</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.197561</td>\n",
       "      <td>0.315291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>30.6</td>\n",
       "      <td>11.603448</td>\n",
       "      <td>0.379198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>RunnerToScrimmage</td>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>31.8</td>\n",
       "      <td>21.562931</td>\n",
       "      <td>0.678080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>DefenseSpreadX</td>\n",
       "      <td>38</td>\n",
       "      <td>42</td>\n",
       "      <td>46</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>32.0</td>\n",
       "      <td>12.899612</td>\n",
       "      <td>0.403113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>DefenseStdX</td>\n",
       "      <td>59</td>\n",
       "      <td>51</td>\n",
       "      <td>49</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>39.0</td>\n",
       "      <td>17.652195</td>\n",
       "      <td>0.452620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>MinTackleTime</td>\n",
       "      <td>76</td>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.612497</td>\n",
       "      <td>0.582102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Momentum_cos</td>\n",
       "      <td>68</td>\n",
       "      <td>64</td>\n",
       "      <td>58</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>45.8</td>\n",
       "      <td>21.766029</td>\n",
       "      <td>0.475241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>99</td>\n",
       "      <td>87</td>\n",
       "      <td>78</td>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "      <td>69.8</td>\n",
       "      <td>23.438430</td>\n",
       "      <td>0.335794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Feature  Fold_1  Fold_2  Fold_3  Fold_4  Fold_5  Average  \\\n",
       "56  RunnerToOffenseCentoid      44      34      26       8       4     23.2   \n",
       "6                   Season      28      28      24      20      17     23.4   \n",
       "38                 Dir_cos      33      33      32      17      15     26.0   \n",
       "1                        S      41      41      38      15      18     30.6   \n",
       "59       RunnerToScrimmage      57      53      35       7       7     31.8   \n",
       "57          DefenseSpreadX      38      42      46      22      12     32.0   \n",
       "51             DefenseStdX      59      51      49      22      14     39.0   \n",
       "60           MinTackleTime      76      62      54      18      10     44.0   \n",
       "39            Momentum_cos      68      64      58      22      17     45.8   \n",
       "2                        A      99      87      78      47      38     69.8   \n",
       "\n",
       "          Std        Cv  \n",
       "56  15.210523  0.655626  \n",
       "6    4.363485  0.186474  \n",
       "38   8.197561  0.315291  \n",
       "1   11.603448  0.379198  \n",
       "59  21.562931  0.678080  \n",
       "57  12.899612  0.403113  \n",
       "51  17.652195  0.452620  \n",
       "60  25.612497  0.582102  \n",
       "39  21.766029  0.475241  \n",
       "2   23.438430  0.335794  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df.sort_values(\"Average\").tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l1: 3.92733\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's l1: 3.91904\n",
      "[3]\tvalid_0's l1: 3.92\n",
      "[4]\tvalid_0's l1: 3.91672\n",
      "[5]\tvalid_0's l1: 3.90693\n",
      "[6]\tvalid_0's l1: 3.89935\n",
      "[7]\tvalid_0's l1: 3.89671\n",
      "[8]\tvalid_0's l1: 3.89991\n",
      "[9]\tvalid_0's l1: 3.89619\n",
      "[10]\tvalid_0's l1: 3.89935\n",
      "[11]\tvalid_0's l1: 3.89581\n",
      "[12]\tvalid_0's l1: 3.89865\n",
      "[13]\tvalid_0's l1: 3.89717\n",
      "[14]\tvalid_0's l1: 3.89169\n",
      "[15]\tvalid_0's l1: 3.89904\n",
      "[16]\tvalid_0's l1: 3.90305\n",
      "[17]\tvalid_0's l1: 3.9003\n",
      "[18]\tvalid_0's l1: 3.89805\n",
      "[19]\tvalid_0's l1: 3.90364\n",
      "[20]\tvalid_0's l1: 3.90379\n",
      "[21]\tvalid_0's l1: 3.9077\n",
      "[22]\tvalid_0's l1: 3.90871\n",
      "[23]\tvalid_0's l1: 3.91265\n",
      "[24]\tvalid_0's l1: 3.91397\n",
      "[25]\tvalid_0's l1: 3.91272\n",
      "[26]\tvalid_0's l1: 3.91538\n",
      "[27]\tvalid_0's l1: 3.91777\n",
      "[28]\tvalid_0's l1: 3.91672\n",
      "[29]\tvalid_0's l1: 3.91432\n",
      "[30]\tvalid_0's l1: 3.9143\n",
      "[31]\tvalid_0's l1: 3.91717\n",
      "[32]\tvalid_0's l1: 3.91905\n",
      "[33]\tvalid_0's l1: 3.92375\n",
      "[34]\tvalid_0's l1: 3.92596\n",
      "[35]\tvalid_0's l1: 3.92784\n",
      "[36]\tvalid_0's l1: 3.92987\n",
      "[37]\tvalid_0's l1: 3.93365\n",
      "[38]\tvalid_0's l1: 3.93618\n",
      "[39]\tvalid_0's l1: 3.93819\n",
      "[40]\tvalid_0's l1: 3.94001\n",
      "[41]\tvalid_0's l1: 3.94225\n",
      "[42]\tvalid_0's l1: 3.94304\n",
      "[43]\tvalid_0's l1: 3.94555\n",
      "[44]\tvalid_0's l1: 3.94736\n",
      "[45]\tvalid_0's l1: 3.94471\n",
      "[46]\tvalid_0's l1: 3.94221\n",
      "[47]\tvalid_0's l1: 3.94374\n",
      "[48]\tvalid_0's l1: 3.94489\n",
      "[49]\tvalid_0's l1: 3.94714\n",
      "[50]\tvalid_0's l1: 3.95117\n",
      "[51]\tvalid_0's l1: 3.95236\n",
      "[52]\tvalid_0's l1: 3.9536\n",
      "[53]\tvalid_0's l1: 3.95392\n",
      "[54]\tvalid_0's l1: 3.9541\n",
      "[55]\tvalid_0's l1: 3.95643\n",
      "[56]\tvalid_0's l1: 3.95698\n",
      "[57]\tvalid_0's l1: 3.95922\n",
      "[58]\tvalid_0's l1: 3.95658\n",
      "[59]\tvalid_0's l1: 3.95885\n",
      "[60]\tvalid_0's l1: 3.95787\n",
      "[61]\tvalid_0's l1: 3.96988\n",
      "[62]\tvalid_0's l1: 3.96873\n",
      "[63]\tvalid_0's l1: 3.96921\n",
      "[64]\tvalid_0's l1: 3.97562\n",
      "[65]\tvalid_0's l1: 3.97352\n",
      "[66]\tvalid_0's l1: 3.98168\n",
      "[67]\tvalid_0's l1: 3.9841\n",
      "[68]\tvalid_0's l1: 3.98892\n",
      "[69]\tvalid_0's l1: 3.98595\n",
      "[70]\tvalid_0's l1: 3.98623\n",
      "[71]\tvalid_0's l1: 3.98645\n",
      "[72]\tvalid_0's l1: 3.98693\n",
      "[73]\tvalid_0's l1: 3.98635\n",
      "[74]\tvalid_0's l1: 3.9876\n",
      "[75]\tvalid_0's l1: 3.98922\n",
      "[76]\tvalid_0's l1: 3.99022\n",
      "[77]\tvalid_0's l1: 3.98706\n",
      "[78]\tvalid_0's l1: 3.98514\n",
      "[79]\tvalid_0's l1: 3.98542\n",
      "[80]\tvalid_0's l1: 3.98316\n",
      "[81]\tvalid_0's l1: 3.98363\n",
      "[82]\tvalid_0's l1: 3.98409\n",
      "[83]\tvalid_0's l1: 3.98351\n",
      "[84]\tvalid_0's l1: 3.98259\n",
      "[85]\tvalid_0's l1: 3.98243\n",
      "[86]\tvalid_0's l1: 3.98432\n",
      "[87]\tvalid_0's l1: 3.98722\n",
      "[88]\tvalid_0's l1: 3.98798\n",
      "[89]\tvalid_0's l1: 3.98833\n",
      "[90]\tvalid_0's l1: 3.98844\n",
      "[91]\tvalid_0's l1: 3.98812\n",
      "[92]\tvalid_0's l1: 3.98971\n",
      "[93]\tvalid_0's l1: 3.9926\n",
      "[94]\tvalid_0's l1: 3.99\n",
      "[95]\tvalid_0's l1: 3.9892\n",
      "[96]\tvalid_0's l1: 3.98878\n",
      "[97]\tvalid_0's l1: 3.9906\n",
      "[98]\tvalid_0's l1: 3.99112\n",
      "[99]\tvalid_0's l1: 3.99085\n",
      "[100]\tvalid_0's l1: 3.98896\n",
      "[101]\tvalid_0's l1: 3.98918\n",
      "[102]\tvalid_0's l1: 3.98748\n",
      "[103]\tvalid_0's l1: 3.98829\n",
      "[104]\tvalid_0's l1: 3.98748\n",
      "[105]\tvalid_0's l1: 3.98735\n",
      "[106]\tvalid_0's l1: 3.9901\n",
      "[107]\tvalid_0's l1: 3.99146\n",
      "[108]\tvalid_0's l1: 3.99103\n",
      "[109]\tvalid_0's l1: 3.99158\n",
      "[110]\tvalid_0's l1: 3.99148\n",
      "[111]\tvalid_0's l1: 3.99229\n",
      "[112]\tvalid_0's l1: 3.99292\n",
      "[113]\tvalid_0's l1: 3.99341\n",
      "[114]\tvalid_0's l1: 3.99167\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's l1: 3.89169\n",
      "0.01437327894202716\n"
     ]
    }
   ],
   "source": [
    "# validation 2 from https://www.kaggle.com/c/nfl-big-data-bowl-2020/discussion/113861#latest-658998\n",
    "def NFL_validation_split(df):\n",
    "    games = df[['GameId', 'PossessionTeam']].drop_duplicates()\n",
    "\n",
    "    # Sort so the latest games are first and label the games with cumulative counter\n",
    "    games = games.sort_values(['PossessionTeam', 'GameId'], ascending=[True, False])\n",
    "    games['row_number'] = games.groupby(['PossessionTeam']).cumcount() + 1\n",
    "\n",
    "    # Use last 5 games for each team as validation. There will be overlap since two teams will have the same\n",
    "    # GameId\n",
    "    game_set = set([1, 2, 3, 4, 5])\n",
    "\n",
    "    # Set of unique game ids\n",
    "    game_ids = set(games[games['row_number'].isin(game_set)]['GameId'].unique().tolist())\n",
    "\n",
    "    return game_ids\n",
    "\n",
    "game_ids = NFL_validation_split(X_train)\n",
    "X_train_second = X_train[~X_train['GameId'].isin(game_ids)].copy()\n",
    "X_test_second = X_train[X_train['GameId'].isin(game_ids)].copy()\n",
    "X_train_second.drop([\"GameId\", 'PossessionTeam'],axis=1, inplace=True)\n",
    "X_test_second.drop([\"GameId\", 'PossessionTeam'],axis=1, inplace=True)\n",
    "train_inds, test_inds = X_train_second.index, X_test_second.index\n",
    "y_train_second, y_test_second = y_train[train_inds], y_train[test_inds]\n",
    "\n",
    "lgbm_params = {\n",
    "    \"objective\" : \"regression\",\n",
    "    \"metric\" : \"mae\", \n",
    "    \"tree_learner\": \"serial\",\n",
    "    \"max_depth\" : -1,\n",
    "    \"boosting\": 'gbdt',\n",
    "    #\"num_leaves\" : 13,\n",
    "    \"learning_rate\" : 0.1,\n",
    "    #\"bagging_freq\": 5,\n",
    "    #\"bagging_fraction\" : 0.4,\n",
    "    #\"feature_fraction\" : 0.05,\n",
    "    #\"min_data_in_leaf\": 80,\n",
    "}\n",
    "feature_importance_df = pd.DataFrame(list(X_train_second.columns), columns=[\"Feature\"])\n",
    "lgb_train = lgb.Dataset(X_train_second, y_train_second)\n",
    "lgb_eval = lgb.Dataset(X_test_second, y_test_second, reference=lgb_train)\n",
    "clf = lgb.train(\n",
    "        lgbm_params, lgb_train,\n",
    "        valid_sets=lgb_eval,\n",
    "        num_boost_round=100000,\n",
    "        early_stopping_rounds=100,\n",
    "    )\n",
    "temp_predict = clf.predict(X_test2)\n",
    "feature_importance_df[\"Importance\"] = clf.feature_importance()\n",
    "stack_train[test_index] = temp_predict\n",
    "mse = mean_squared_error(y_test2, temp_predict)\n",
    "crps = CRPS_pingyi1(temp_predict,y_test2,4,cdf,dist_to_end_train.iloc[test_index])\n",
    "mae = mean_absolute_error(y_test2, temp_predict)\n",
    "print(crps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>DefenseSpreadX</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>RunnerToScrimmage</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DefendersInTheBox</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Momentum_cos</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Dir_cos</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>MinTackleTime</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Season</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>DefenseStdX</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Feature  Importance\n",
       "57     DefenseSpreadX          13\n",
       "59  RunnerToScrimmage          14\n",
       "14  DefendersInTheBox          18\n",
       "39       Momentum_cos          22\n",
       "38            Dir_cos          22\n",
       "60      MinTackleTime          22\n",
       "6              Season          23\n",
       "51        DefenseStdX          23\n",
       "1                   S          26\n",
       "2                   A          56"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df.sort_values(\"Importance\").tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission file has been saved!  Once you `Commit` your Notebook and it finishes running, you can submit the file to the competition from the Notebook Viewer `Output` tab.\n"
     ]
    }
   ],
   "source": [
    "for (test_df, sample_prediction_df) in env.iter_test():\n",
    "    X_test, dist_to_end_test = transform_data(test_df)\n",
    "    if set(X_test.columns) != set(X_train_first.columns):\n",
    "        print(\"columns are different\")\n",
    "        break\n",
    "    for f in X_test.columns:\n",
    "        if X_test[f].dtype=='object':\n",
    "            X_test[f] = X_test[f].map(lambda x:x if x in set(X_train_first[f]) else -999)\n",
    "    for f in X_test.columns:\n",
    "        if X_test[f].dtype=='object': \n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(X_train_first[f])+[-999])\n",
    "            X_test[f] = lbl.transform(list(X_test[f])) \n",
    "    pred_value = 0\n",
    "    for model in models:\n",
    "        pred_value += model.predict(X_test)[0]/5\n",
    "    pred_data = list(get_score(pred_value,cdf,4,dist_to_end_test.values[0]))\n",
    "    pred_data = np.array(pred_data).reshape(1,199)\n",
    "    pred_target = pd.DataFrame(index = sample_prediction_df.index, \\\n",
    "                               columns = sample_prediction_df.columns, \\\n",
    "                               #data = np.array(pred_data))\n",
    "                               data = pred_data)\n",
    "    env.predict(pred_target)\n",
    "env.write_submission_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
