{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "### Explanation\n",
    "\n",
    "This kernel used LGBM and treated it as a regression problem. I only did a little feature engineering so far.(just transform some date format features into numeric)\n",
    "\n",
    "The ideas is that:\n",
    "- if we treated it as a regression problem, it's better to do some smooth operation. See the [kernel](https://www.kaggle.com/hukuda222/nfl-simple-evluation-trick).\n",
    "- I used the distribution in [kernel](https://www.kaggle.com/jpmiller/simple-distribution) as my smooth distribution.\n",
    "- We can see the simple distribution in [kernel](https://www.kaggle.com/jpmiller/simple-distribution) get the 1436 LB. If we use LGBM to do regression prediction and shift the distribution based on the yards we predicte, we should get a better LB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold,TimeSeriesSplit,KFold,GroupKFold\n",
    "from sklearn.metrics import roc_auc_score,mean_squared_error,mean_absolute_error\n",
    "import sqlite3\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import pearsonr\n",
    "import gc\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from bayes_opt import BayesianOptimization\n",
    "from kaggle.competitions import nflrush\n",
    "import math\n",
    "import tqdm\n",
    "from scipy.spatial import Delaunay, delaunay_plot_2d, Voronoi, voronoi_plot_2d, ConvexHull\n",
    "env = nflrush.make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/nfl-big-data-bowl-2020/train.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train.VisitorTeamAbbr == \"ARI\",'VisitorTeamAbbr'] = \"ARZ\"\n",
    "train.loc[train.HomeTeamAbbr == \"ARI\",'HomeTeamAbbr'] = \"ARZ\"\n",
    "\n",
    "train.loc[train.VisitorTeamAbbr == \"BAL\",'VisitorTeamAbbr'] = \"BLT\"\n",
    "train.loc[train.HomeTeamAbbr == \"BAL\",'HomeTeamAbbr'] = \"BLT\"\n",
    "\n",
    "train.loc[train.VisitorTeamAbbr == \"CLE\",'VisitorTeamAbbr'] = \"CLV\"\n",
    "train.loc[train.HomeTeamAbbr == \"CLE\",'HomeTeamAbbr'] = \"CLV\"\n",
    "\n",
    "train.loc[train.VisitorTeamAbbr == \"HOU\",'VisitorTeamAbbr'] = \"HST\"\n",
    "train.loc[train.HomeTeamAbbr == \"HOU\",'HomeTeamAbbr'] = \"HST\"\n",
    "\n",
    "train['is_run'] = train.NflId == train.NflIdRusher\n",
    "\n",
    "tmp_handoff = train['TimeHandoff'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "tmp_snap = train['TimeSnap'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "train['handoff_snap_diff'] = (tmp_handoff - tmp_snap).map(lambda x:x.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my original idea for feature engineering---------------------------------------------------\n",
    "def str_to_float(txt):\n",
    "    try:\n",
    "        return float(txt)\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "# modify orientation\n",
    "# train.loc[train.Season == 2017, 'Orientation'] = train['Orientation'][train.Season == 2017].apply(lambda x: x+ 90 - 360 if x>270 else x + 90)\n",
    "\n",
    "# age #\n",
    "FMT_birth = '%m/%d/%Y'\n",
    "FMT_gamedate = '%Y-%m-%d'\n",
    "train[\"Age\"] = train[\"TimeSnap\"].apply(lambda t: t.split(\"T\")[0])\n",
    "train[\"Age\"] = train[\"Age\"].apply(lambda t: datetime.strptime(t, FMT_gamedate))\n",
    "tmp_birth = train[\"PlayerBirthDate\"].apply(lambda t: datetime.strptime(t, FMT_birth))\n",
    "train[\"Age\"] = train[\"Age\"] - tmp_birth\n",
    "train[\"Age\"] = train[\"Age\"].apply(lambda t: t.days//365)\n",
    "\n",
    "# momentum \n",
    "train[\"Momentum\"] = train[\"S\"] * train[\"PlayerWeight\"]\n",
    "\n",
    "# on offense\n",
    "def func(row):\n",
    "    if row[\"PossessionTeam\"] == row[\"HomeTeamAbbr\"]:\n",
    "        return \"home\"\n",
    "    else:\n",
    "        return \"away\"\n",
    "train[\"OnOffense\"] = train[[\"PossessionTeam\", \"HomeTeamAbbr\"]].apply(func, axis=1)\n",
    "train[\"OnOffense\"] = train[\"OnOffense\"] == train[\"Team\"]\n",
    "\n",
    "train[\"Margin\"] = (train[\"HomeScoreBeforePlay\"] - \n",
    "                train[\"VisitorScoreBeforePlay\"]) + 2 * (1 - (train[\"PossessionTeam\"] == \n",
    "                                                                      train[\"HomeTeamAbbr\"]).astype(int)) * (train[\"VisitorScoreBeforePlay\"] \n",
    "                                                                                                                - train[\"HomeScoreBeforePlay\"])\n",
    "\n",
    "#train['ToLeft'] = train.PlayDirection == \"left\"\n",
    "#train['Dir_rad'] = np.mod(90 - train.Dir, 360) * math.pi/180.0\n",
    "#train['YardLine_std'] = 100 - train.YardLine\n",
    "#train.loc[train.FieldPosition.fillna('') == train.PossessionTeam,  \n",
    "#          'YardLine_std'\n",
    "#         ] = train.loc[train.FieldPosition.fillna('') == train.PossessionTeam,  \n",
    "#          'YardLine']\n",
    "#train['X_std'] = train.X\n",
    "#train.loc[train.ToLeft, 'X_std'] = 120 - train.loc[train.ToLeft, 'X'] \n",
    "#train['Y_std'] = train.Y\n",
    "#train.loc[train.ToLeft, 'Y_std'] = 160/3 - train.loc[train.ToLeft, 'Y'] \n",
    " #train['Orientation_std'] = -90 + train.Orientation\n",
    " #train.loc[train.ToLeft, 'Orientation_std'] = np.mod(180 + train.loc[train.ToLeft, 'Orientation_std'], 360)\n",
    "#train['Dir_std'] = train.Dir_rad\n",
    "#train.loc[train.ToLeft, 'Dir_std'] = np.mod(np.pi + train.loc[train.ToLeft, 'Dir_rad'], 2*np.pi)\n",
    "\n",
    "# exercise energy\n",
    "train[\"ExerciseEnergy\"] = 0.5 * train[\"PlayerWeight\"] * (train[\"S\"]**2)\n",
    "\n",
    "rusher_x = np.array(train.groupby([\"PlayId\", \"is_run\"])[\"X\"].agg(np.mean)[1::2])\n",
    "rusher_x = np.repeat(rusher_x, 22) # repeat each elemnt 22 times train[\"RusherX\"]\n",
    "rusher_y = np.array(train.groupby([\"PlayId\", \"is_run\"])[\"Y\"].agg(np.mean)[1::2])\n",
    "rusher_y = np.repeat(rusher_y, 22) # train[\"RusherY\"]\n",
    "train[\"DisToRusher\"] = np.sqrt((train[\"X\"] - rusher_x) ** 2 + (train[\"Y\"] - rusher_y) ** 2)\n",
    "train[\"TackleTimeToRusher\"] = train[\"DisToRusher\"] / train[\"S\"] \n",
    "\n",
    "rusher_s = np.array(train.groupby([\"PlayId\", \"is_run\"]).agg(np.mean)[\"S\"][1::2])\n",
    "rusher_s = np.repeat(rusher_s, 22)\n",
    "train[\"RatioSToRusher\"] = train[\"S\"] / rusher_s\n",
    "\n",
    "# distance without no restriction if the difference between distance is large, the player is restricted by defenders\n",
    "train[\"MoveDist\"] = train[\"S\"] * train[\"handoff_snap_diff\"] + 0.5 * train[\"A\"] * (train[\"handoff_snap_diff\"] **2)\n",
    "\n",
    "# ratio of real movement distance to theoretical movement distance\n",
    "train[\"RealToTheoryDis\"] = train[\"Dis\"] / train[\"MoveDist\"]\n",
    "# my original idea end ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_single = train[train.is_run==True].copy()\n",
    "\n",
    "def transform_time_quarter(str1):\n",
    "    return int(str1[:2])*60 + int(str1[3:5])\n",
    "def transform_time_all(str1,quarter):\n",
    "    if quarter<=4:\n",
    "        return 15*60 - (int(str1[:2])*60 + int(str1[3:5])) + (quarter-1)*15*60\n",
    "    if quarter ==5:\n",
    "        return 10*60 - (int(str1[:2])*60 + int(str1[3:5])) + (quarter-1)*15*60\n",
    "train_single['time_quarter'] = train_single.GameClock.map(lambda x:transform_time_quarter(x))\n",
    "train_single['time_end'] = train_single.apply(lambda x:transform_time_all(x.loc['GameClock'],x.loc['Quarter']),axis=1)\n",
    "\n",
    "# my original idea -----------------------\n",
    "#train_single['WindSpeed'] = train_single['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n",
    "#train_single['WindSpeed'] = train_single['WindSpeed'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n",
    "#train_single['WindSpeed'] = train_single['WindSpeed'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n",
    "#train_single['WindSpeed'] = train_single['WindSpeed'].apply(str_to_float)\n",
    "\n",
    "#train_single['WindDirection'] = train_single['WindDirection'].apply(lambda x: \"north\" if x == \"N\" or x == \"FROM S\"\n",
    "#                                                   else (\"south\" if x == 'S' or x== 'FROM N'\n",
    "#                                                   else (\"west\" if x == 'W' or x == 'FROM E'\n",
    "#                                                   else (\"east\" if x == 'E' or x == 'FROM W'\n",
    "#                                                   else (\"north east\" if x == 'FROM SW' or x == 'FROM SSW' or x == 'FROM WSW'\n",
    "#                                                   else (\"north west\" if x == 'FROM SE' or x == 'FROM SSE' or x == 'FROM ESE'\n",
    "#                                                   else (\"south east\" if x == 'FROM NW' or x == 'FROM NNW' or x == 'FROM WNW'\n",
    "#                                                   else (\"south west\" if x == 'FROM NE' or x == 'FROM NNE' or x == 'FROM ENE'\n",
    "#                                                   else (\"north west\" if x == 'NW' or x == 'NORTHWEST'\n",
    "#                                                   else (\"north east\" if x == 'NE' or x == 'NORTH EAST'\n",
    "#                                                   else (\"south west\" if x == 'SW' or x == 'SOUTHWEST'\n",
    "#                                                   else (\"south east\" if x == 'SE' or x == 'SOUTHEAST' else \"unknown\"))))))))))))\n",
    "\n",
    "#rain = ['Rainy', 'Rain Chance 40%', 'Showers', 'Cloudy with periods of rain, thunder possible. Winds shifting to WNW, 10-20 mph.',\n",
    "#          'Scattered Showers', 'Cloudy, Rain', 'Rain shower', 'Light Rain', 'Rain']\n",
    "#overcast = ['Cloudy, light snow accumulating 1-3\"', 'Party Cloudy', 'Cloudy, chance of rain','Coudy', 'Cloudy, 50% change of rain', \n",
    "#            'Rain likely, temps in low 40s.', 'Cloudy and cold', 'Cloudy, fog started developing in 2nd quarter', 'Partly Clouidy', \n",
    "#            '30% Chance of Rain', 'Mostly Coudy', 'Cloudy and Cool', 'cloudy', 'Partly cloudy', 'Overcast', 'Hazy', 'Mostly cloudy', \n",
    "#            'Mostly Cloudy', 'Partly Cloudy', 'Cloudy']\n",
    "#clear = ['Partly clear', 'Sunny and clear', 'Sun & clouds', 'Clear and Sunny', 'Sunny and cold', 'Sunny Skies', 'Clear and Cool', 'Clear and sunny',\n",
    "#        'Sunny, highs to upper 80s', 'Mostly Sunny Skies', 'Cold', 'Clear and warm', 'Sunny and warm', 'Clear and cold', 'Mostly sunny',\n",
    "#        'T: 51; H: 55; W: NW 10 mph', 'Clear Skies', 'Clear skies', 'Partly sunny', 'Fair', 'Partly Sunny', 'Mostly Sunny', 'Clear', 'Sunny']\n",
    "#snow = ['Heavy lake effect snow', 'Snow']\n",
    "#none = ['N/A Indoor', 'Indoors', 'Indoor', 'N/A (Indoors)', 'Controlled Climate']\n",
    "\n",
    "#train_single['GameWeather'] = train_single['GameWeather'].apply(lambda x: \"rain\" if x in rain \n",
    "#                                                        else (\"overcast\" if x in overcast\n",
    "#                                                        else (\"clear\" if x in clear\n",
    "#                                                        else (\"snow\" if x in snow\n",
    "#                                                        else (\"indoor\" if x in none else \"unknown\")))))\n",
    "\n",
    "outdoor =['Outdoor', 'Outdoors', 'Cloudy', 'Heinz Field', 'Outdor', 'Ourdoor', \n",
    "          'Outside', 'Outddors', 'Outdoor Retr Roof-Open', 'Oudoor', 'Bowl']\n",
    "indoor_closed = ['Indoors', 'Indoor', 'Indoor, Roof Closed', 'Indoor, Roof Closed', \n",
    "                 'Retractable Roof', 'Retr. Roof-Closed', 'Retr. Roof - Closed', 'Retr. Roof Closed']\n",
    "indoor_open = ['Indoor, Open Roof', 'Open', 'Retr. Roof-Open', 'Retr. Roof - Open']\n",
    "dome_closed = ['Dome', 'Domed, closed', 'Closed Dome', 'Domed', 'Dome, closed']\n",
    "dome_open = ['Domed, Open', 'Domed, open']\n",
    "\n",
    "train_single['StadiumType'] = train_single['StadiumType'].apply(lambda x: \"outdoor\" if x in outdoor \n",
    "                                                    else (\"indoor closed\" if x in indoor_closed\n",
    "                                                    else (\"indoor open\" if x in indoor_open\n",
    "                                                    else (\"dome_closed\" if x in dome_closed\n",
    "                                                    else (\"dome_open\" if x in dome_open else \"unknown\")))))\n",
    "\n",
    "train_single[\"Location\"] = train_single[\"Location\"].map(lambda x: \"Arlington, TX\" if x == \"Arlington, Texas\"\n",
    "                        else (\"Baltimore, MD\" if x == \"Baltimore, Maryland\" or x == \"Baltimore, Md.\"\n",
    "                        else (\"Charlotte, NC\" if x == \"Charlotte, North Carolina\"\n",
    "                        else (\"Chicago, IL\" if x == \"Chicago. IL\"\n",
    "                        else (\"Cincinnati, OH\" if x == \"Cincinnati, Ohio\"\n",
    "                        else (\"Cleveland, OH\" if x == \"Cleveland\" or x == \"Cleveland Ohio\" or x == \"Cleveland, Ohio\" or x == \"Cleveland,Ohio\"\n",
    "                        else (\"Detroit, MI\" if x == \"Detroit\"\n",
    "                        else (\"East Rutherford, NJ\" if x == \"E. Rutherford, NJ\" or x == \"East Rutherford, N.J.\"\n",
    "                        else (\"Foxborough, MA\" if x == \"Foxborough, Ma\"\n",
    "                        else (\"Houston, TX\" if x == \"Houston, Texas\"\n",
    "                        else (\"Jacksonville, FL\" if x == \"Jacksonville Florida\" or x == \"Jacksonville, Fl\" or x == \"Jacksonville, Florida\"\n",
    "                        else (\"London\" if x == \"London, England\"\n",
    "                        else (\"Los Angeles, CA\" if x == \"Los Angeles, Calif.\"\n",
    "                        else (\"Miami Gardens, FLA\" if x == \"Miami Gardens, Fla.\"\n",
    "                        else (\"New Orleans, LA\" if x == \"New Orleans\" or x == \"New Orleans, La.\"\n",
    "                        else (\"Orchard Park, NY\" if x == \"Orchard Park NY\"\n",
    "                        else (\"Philadelphia, PA\" if x == \"Philadelphia, Pa.\"\n",
    "                        else (\"Pittsburgh, PA\" if x == \"Pittsburgh\"\n",
    "                        else (\"Seattle, WA\" if x == \"Seattle\" else x)))))))))))))))))))\n",
    "\n",
    "train_single[\"Stadium\"] = train_single[\"Stadium\"].map(lambda x: \"Broncos Stadium at Mile High\" if x==\"Broncos Stadium At Mile High\" \n",
    "                                             else (\"CenturyLink Field\" if x == \"CenturyField\" or x == x==\"CenturyLink\"\n",
    "                                             else (\"Everbank Field\" if x == \"EverBank Field\"\n",
    "                                             else (\"FirstEnergy Stadium\" if x ==\"First Energy Stadium\" or x==\"FirstEnergy\" or x == \"FirstEnergyStadium\"\n",
    "                                             else (\"Lambeau Field\" if x == \"Lambeau field\"\n",
    "                                             else (\"Los Angeles Memorial Coliseum\" if x == \"Los Angeles Memorial Coliesum\"\n",
    "                                             else (\"M&T Bank Stadium\" if x == \"M & T Bank Stadium\" or x == \"M&T Stadium\"\n",
    "                                             else (\"Mercedes-Benz Superdome\" if x == \"Mercedes-Benz Dome\"\n",
    "                                             else (\"MetLife Stadium\" if x == \"MetLife\" or x == \"Metlife Stadium\"\n",
    "                                             else (\"NRG Stadium\" if x == \"NRG\"\n",
    "                                             else (\"Oakland-Alameda County Coliseum\" if x == \"Oakland Alameda-County Coliseum\"\n",
    "                                             else (\"Paul Brown Stadium\" if x == \"Paul Brown Stdium\"\n",
    "                                             else (\"Twickenham Stadium\" if x == \"Twickenham\" else x)))))))))))))\n",
    "\n",
    "train_single[\"OffenseFormation\"] = train_single[\"OffenseFormation\"].fillna(\"Unknown\") \n",
    "train_single['DefendersInTheBox_vs_Distance'] = train_single['DefendersInTheBox'] / train_single['Distance']\n",
    "\n",
    "grass_labels = ['grass', 'natural grass', 'natural', 'naturall grass']\n",
    "train_single['Turf'] = np.where(train_single.Turf.str.lower().isin(grass_labels), \"Natural\", \"Artificial\")\n",
    "\n",
    "arr = [[int(s[0]) for s in t.split(\", \")] for t in train_single[\"DefensePersonnel\"]]\n",
    "train_single[\"DefenseDL\"] = np.array([a[0] for a in arr])\n",
    "train_single[\"DefenseLB\"] = np.array([a[1] for a in arr])\n",
    "train_single[\"DefenseDB\"] = np.array([a[2] for a in arr])\n",
    "train_single[\"DefenseOL\"] = np.array([a[3] if len(a) == 4 else 0 for a in arr])\n",
    "\n",
    "train_single[\"OffenseRB\"] = train_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "                        int(x.replace(\",\", \"\").split(\" RB\")[0][-1]) if \"RB\" in x else 0)\n",
    "train_single[\"OffenseTE\"] = train_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "                        int(x.replace(\",\", \"\").split(\" TE\")[0][-1]) if \"TE\" in x else 0)\n",
    "train_single[\"OffenseWR\"] = train_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "                        int(x.replace(\",\", \"\").split(\" WR\")[0][-1]) if \"WR\" in x else 0)\n",
    "train_single[\"OffenseOL\"] = train_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "                        int(x.replace(\",\", \"\").split(\" OL\")[0][-1]) if \"OL\" in x else 0)\n",
    "train_single[\"OffenseDL\"] = train_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "                        int(x.replace(\",\", \"\").split(\" DL\")[0][-1]) if \"DL\" in x else 0)\n",
    "train_single[\"OffenseQB\"] = train_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "                        int(x.replace(\",\", \"\").split(\" QB\")[0][-1]) if \"QB\" in x else 0)\n",
    "\n",
    "train_single[\"Distance10\"] = train_single[\"Distance\"].apply(lambda x: 1 if x > 10 else 0)\n",
    "\n",
    "# train_single[\"DownQuarter\"] = train_single[[\"Down\", \"Quarter\"]].apply(lambda x: \"D{}_Q{}\".format(x[0], x[1]), axis=1)\n",
    "\n",
    "\n",
    "# necessary yard per remaining down \n",
    "train_single[\"NecDisPerDown\"] = train_single[\"Distance\"] / (5 - train_single[\"Down\"])\n",
    "# my original idea end -----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_features = ['GameId','PlayId','DisplayName','GameClock','TimeHandoff','TimeSnap', 'OffensePersonnel', 'DefensePersonnel']#, 'X', 'Y', 'Dir', \"YardLine\"]\n",
    "train_single['date_game'] = train_single.GameId.map(lambda x:pd.to_datetime(str(x)[:8]))\n",
    "remove_features.append('HomeTeamAbbr')\n",
    "remove_features.append('VisitorTeamAbbr')\n",
    "remove_features.append('PlayerBirthDate')\n",
    "remove_features.append('is_run')\n",
    "def transform_height(te):\n",
    "    return (int(te.split('-')[0])*12 + int(te.split('-')[1]))*2.54/100\n",
    "train_single['runner_height'] = train_single.PlayerHeight.map(transform_height)\n",
    "remove_features.append('PossessionTeam')\n",
    "remove_features.append('FieldPosition')\n",
    "remove_features.append('PlayerHeight')\n",
    "remove_features.append('NflIdRusher')\n",
    "remove_features.append('date_game')\n",
    "train_single['own_field'] = (train_single['FieldPosition'] == train_single['PossessionTeam']).astype(int)\n",
    "dist_to_end_train = train_single.apply(lambda x:(100 - x.loc['YardLine']) if x.loc['own_field']==1 else x.loc['YardLine'],axis=1)\n",
    "remove_features.append('own_field')\n",
    "train_single.drop(remove_features,axis=1,inplace=True)\n",
    "train_single.fillna(-999,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_single.Yards\n",
    "X_train = train_single.drop(['Yards'],axis=1)\n",
    "for f in X_train.columns:\n",
    "    if X_train[f].dtype=='object': \n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(X_train[f])+[-999])\n",
    "        X_train[f] = lbl.transform(list(X_train[f]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional feature engineering -----------------------------------------------------------\n",
    "def voronoi_volumes(points, selected_index):\n",
    "    v = Voronoi(points)\n",
    "    vol = np.zeros(v.npoints)\n",
    "    \n",
    "    for i, reg_num in enumerate(v.point_region):\n",
    "        indices = v.regions[reg_num]\n",
    "        if -1 in indices: # some regions can be opened\n",
    "            vol[i] = -999 ## insert missing value when the area is open\n",
    "        else:\n",
    "            vol[i] = ConvexHull(v.vertices[indices]).volume\n",
    "        \n",
    "        if reg_num == v.point_region[selected_index]: # in the case of rusher or 1st defender etc...\n",
    "            index = i\n",
    "            rusher_reg_num = reg_num         \n",
    "        \n",
    "    return vol[index]\n",
    "\n",
    "tmp = train.groupby([\"PlayId\", \"OnOffense\"]).agg(np.mean)[[\"S\", \"X\", \"Y\", \"Age\"]]\n",
    "X_train[\"DefenseAveSpeed\"] = np.array(tmp[0::2][\"S\"])\n",
    "X_train[\"OffenseAveSpeed\"] = np.array(tmp[1::2][\"S\"])\n",
    "\n",
    "X_train[\"DefenseAveX\"] = np.array(tmp[0::2][\"X\"])\n",
    "X_train[\"OffenseAveX\"] = np.array(tmp[1::2][\"X\"])\n",
    "\n",
    "X_train[\"DefenseAveY\"] = np.array(tmp[0::2][\"Y\"]) \n",
    "X_train[\"OffenseAveY\"] = np.array(tmp[1::2][\"Y\"]) \n",
    "\n",
    "X_train[\"DefenseAveAge\"] = np.array(tmp[0::2][\"Age\"])\n",
    "X_train[\"OffenseAveAge\"] = np.array(tmp[1::2][\"Age\"])\n",
    "\n",
    "tmp = train.groupby([\"PlayId\", \"OnOffense\"]).agg([\"std\"])[[\"X\", \"Y\"]]\n",
    "X_train[\"DefenseStdX\"] = np.array(tmp[0::2][\"X\"])\n",
    "X_train[\"OffenseStdX\"] = np.array(tmp[1::2][\"X\"])\n",
    "\n",
    "X_train[\"DefenseStdY\"] = np.array(tmp[0::2][\"Y\"])\n",
    "X_train[\"OffenseStdY\"] = np.array(tmp[1::2][\"Y\"])\n",
    "\n",
    "X_train[\"RunnerToDefenseCentoid\"] = np.sqrt((X_train[\"X\"] - X_train[\"DefenseAveX\"]) ** 2 + (X_train[\"Y\"] - X_train[\"DefenseAveY\"]) ** 2)\n",
    "X_train[\"RunnerToOffenseCentoid\"] = np.sqrt((X_train[\"X\"] - X_train[\"OffenseAveX\"]) ** 2 + (X_train[\"Y\"] - X_train[\"OffenseAveY\"]) ** 2)\n",
    "\n",
    "# defense x spread, offense x spread\n",
    "tmp_max = train.groupby([\"PlayId\", \"OnOffense\"])[\"X\"].max()\n",
    "tmp_min = train.groupby([\"PlayId\", \"OnOffense\"])[\"X\"].min()\n",
    "X_train[\"DefenseSpreadX\"] = np.array(tmp_max[0::2]- tmp_min[0::2])\n",
    "X_train[\"OffenseSpreadX\"] = np.array(tmp_max[1::2]- tmp_min[1::2])\n",
    "\n",
    "X_train[\"RunnerToScrimmage\"] = X_train[\"X\"] - X_train[\"YardLine\"]\n",
    "\n",
    "# runner horizontal and vertical speed\n",
    "radian_angle = (90 - X_train['Dir']) * np.pi / 180.0\n",
    "X_train['v_horizontal'] = np.abs(X_train['S'] * np.cos(radian_angle))\n",
    "X_train['v_vertical'] = np.abs(X_train['S'] * np.sin(radian_angle))\n",
    "\n",
    "# runner horizontal and vertical momentum\n",
    "X_train['m_horizontal'] = np.abs(X_train['Momentum'] * np.cos(radian_angle))\n",
    "X_train['m_vertical'] = np.abs(X_train['Momentum'] * np.sin(radian_angle))\n",
    "\n",
    "# minimum distance to rusher from defenders\n",
    "X_train[\"MinDisFromRushToDef\"] = np.array(train.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].min()[0::2])\n",
    "\n",
    "# tackle time from closest defender to rusher\n",
    "X_train[\"MinTackleTime\"] = np.array(train.groupby([\"PlayId\", \"OnOffense\"])[\"TackleTimeToRusher\"].min()[0::2])\n",
    "\n",
    "# average tackle time from all defenders to rusher\n",
    "X_train[\"AveTackleTime\"] = np.array(train.groupby([\"PlayId\", \"OnOffense\"]).agg(np.mean)[\"TackleTimeToRusher\"][0::2])\n",
    "\n",
    "# runner vs 1st defender speed: runner's velocity divided by closest defender's speed\n",
    "X_train[\"RatioSRusherToCloseDef\"] = np.array(train.loc[train.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].idxmin()[0::2]][\"RatioSToRusher\"])\n",
    "\n",
    "# runner horizontal and vertical distance\n",
    "X_train[\"dis_horizontal\"] = np.abs(X_train['Dis'] * np.cos(radian_angle))\n",
    "X_train[\"dis_vertical\"] = np.abs(X_train['Dis'] * np.sin(radian_angle))\n",
    "X_train[\"RunnerMoveRatio\"] = X_train[\"dis_horizontal\"] / X_train[\"dis_vertical\"]\n",
    "\n",
    "# the momentum of 1st closest defender to rusher, horizontal momentum, vertical momentum\n",
    "X_train[\"DefMomentumCloToRusher\"] = np.array(train.loc[train.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].idxmin()[0::2]][\"Momentum\"])\n",
    "X_train[\"DefMomentumCloToRusher_horizontal\"] = np.abs(X_train['DefMomentumCloToRusher'] * np.cos(radian_angle))\n",
    "X_train[\"DefMomentumCloToRusher_vertical\"] = np.abs(X_train['DefMomentumCloToRusher'] * np.sin(radian_angle))\n",
    "\n",
    "# the horizontal, vertical mometum of rusher\n",
    "X_train[\"RusherMomentum_horizontal\"] =  np.abs(X_train['Momentum'] * np.cos(radian_angle))\n",
    "X_train[\"RusherMomentum_vertical\"] =  np.abs(X_train['Momentum'] * np.sin(radian_angle))\n",
    "\n",
    "# difference of horizontal momentum \n",
    "X_train[\"hMomentum_rusher_vs_defender\"] = X_train[\"RusherMomentum_horizontal\"] - X_train[\"DefMomentumCloToRusher_horizontal\"]\n",
    "\n",
    "# voronoi area\n",
    "pts = np.array(train[[\"X\", \"Y\"]]).reshape(train.shape[0]//22, 22, 2) # plays * players * (X, Y, rusher)\n",
    "# index of row where rusher data is included when separated by each play\n",
    "rusher_index = list(train[train.is_run==True].index % 22) \n",
    "closest_def_index = list(train.loc[train.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].idxmin()[0::2]].index % 22)\n",
    "rusher_voronoi = []\n",
    "closest_def_voronoi = []\n",
    "for i in range(0, train.shape[0] //22):\n",
    "    rusher_voronoi.append(voronoi_volumes(pts[i], rusher_index[i]))\n",
    "    closest_def_voronoi.append(voronoi_volumes(pts[i], closest_def_index[i]))\n",
    "X_train[\"RusherVoronoi\"] = rusher_voronoi    \n",
    "X_train[\"FirstDefenderVoronoi\"] = closest_def_voronoi \n",
    "# additional feature engineering end ---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cdf_df(yards_array):\n",
    "    pdf, edges = np.histogram(yards_array, bins=199,\n",
    "                 range=(-99,100), density=True)\n",
    "    cdf = pdf.cumsum().clip(0, 1)\n",
    "    cdf_df = pd.DataFrame(data=cdf.reshape(-1, 1).T, \n",
    "                            columns=['Yards'+str(i) for i in range(-99,100)])\n",
    "    return cdf_df\n",
    "cdf = get_cdf_df(y_train).values.reshape(-1,)\n",
    "\n",
    "def get_score(y_pred,cdf,w,dist_to_end):\n",
    "    y_pred = int(y_pred)\n",
    "    if y_pred ==w:\n",
    "        y_pred_array = cdf.copy()\n",
    "    elif y_pred - w >0:\n",
    "        y_pred_array = np.zeros(199)\n",
    "        y_pred_array[(y_pred-w):] = cdf[:(-(y_pred-w))].copy()\n",
    "    elif w - y_pred >0:\n",
    "        y_pred_array = np.ones(199)\n",
    "        y_pred_array[:(y_pred-w)] = cdf[(w-y_pred):].copy()\n",
    "    y_pred_array[-1]=1\n",
    "    y_pred_array[(dist_to_end+99):]=1\n",
    "    return y_pred_array    \n",
    "\n",
    "def get_score_pingyi1(y_pred,y_true,cdf,w,dist_to_end):\n",
    "    y_pred = int(y_pred)\n",
    "    if y_pred ==w:\n",
    "        y_pred_array = cdf.copy()\n",
    "    elif y_pred - w >0:\n",
    "        y_pred_array = np.zeros(199)\n",
    "        y_pred_array[(y_pred-w):] = cdf[:(-(y_pred-w))].copy()\n",
    "    elif w - y_pred >0:\n",
    "        y_pred_array = np.ones(199)\n",
    "        y_pred_array[:(y_pred-w)] = cdf[(w-y_pred):].copy()\n",
    "    y_pred_array[-1]=1\n",
    "    y_pred_array[(dist_to_end+99):]=1\n",
    "    y_true_array = np.zeros(199)\n",
    "    y_true_array[(y_true+99):]=1\n",
    "    return np.mean((y_pred_array - y_true_array)**2)\n",
    "\n",
    "def CRPS_pingyi1(y_preds,y_trues,w,cdf,dist_to_ends):\n",
    "    if len(y_preds) != len(y_trues):\n",
    "        print('length does not match')\n",
    "        return None\n",
    "    n = len(y_preds)\n",
    "    tmp = []\n",
    "    for a,b,c in zip(y_preds, y_trues,dist_to_ends):\n",
    "        tmp.append(get_score_pingyi1(a,b,cdf,w,c))\n",
    "    return np.mean(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Team', 'X', 'Y', 'S', 'A', 'Dis', 'Orientation', 'Dir', 'NflId',\n",
       "       'JerseyNumber', 'Season', 'YardLine', 'Quarter', 'Down', 'Distance',\n",
       "       'HomeScoreBeforePlay', 'VisitorScoreBeforePlay', 'OffenseFormation',\n",
       "       'DefendersInTheBox', 'PlayDirection', 'PlayerWeight',\n",
       "       'PlayerCollegeName', 'Position', 'Week', 'Stadium', 'Location',\n",
       "       'StadiumType', 'Turf', 'GameWeather', 'Temperature', 'Humidity',\n",
       "       'WindSpeed', 'WindDirection', 'handoff_snap_diff', 'Age', 'Momentum',\n",
       "       'OnOffense', 'Margin', 'ExerciseEnergy', 'DisToRusher',\n",
       "       'TackleTimeToRusher', 'RatioSToRusher', 'MoveDist', 'RealToTheoryDis',\n",
       "       'time_quarter', 'time_end', 'DefendersInTheBox_vs_Distance',\n",
       "       'DefenseDL', 'DefenseLB', 'DefenseDB', 'DefenseOL', 'OffenseRB',\n",
       "       'OffenseTE', 'OffenseWR', 'OffenseOL', 'OffenseDL', 'OffenseQB',\n",
       "       'Distance10', 'NecDisPerDown', 'runner_height', 'DefenseAveSpeed',\n",
       "       'OffenseAveSpeed', 'DefenseAveX', 'OffenseAveX', 'DefenseAveY',\n",
       "       'OffenseAveY', 'DefenseAveAge', 'OffenseAveAge', 'DefenseStdX',\n",
       "       'OffenseStdX', 'DefenseStdY', 'OffenseStdY', 'RunnerToDefenseCentoid',\n",
       "       'RunnerToOffenseCentoid', 'DefenseSpreadX', 'OffenseSpreadX',\n",
       "       'RunnerToScrimmage', 'v_horizontal', 'v_vertical', 'm_horizontal',\n",
       "       'm_vertical', 'MinDisFromRushToDef', 'MinTackleTime', 'AveTackleTime',\n",
       "       'RatioSRusherToCloseDef', 'dis_horizontal', 'dis_vertical',\n",
       "       'RunnerMoveRatio', 'DefMomentumCloToRusher',\n",
       "       'DefMomentumCloToRusher_horizontal', 'DefMomentumCloToRusher_vertical',\n",
       "       'RusherMomentum_horizontal', 'RusherMomentum_vertical',\n",
       "       'hMomentum_rusher_vs_defender', 'RusherVoronoi',\n",
       "       'FirstDefenderVoronoi'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's l1: 3.77951\tvalid_1's l1: 3.69452\n",
      "[100]\ttraining's l1: 3.70541\tvalid_1's l1: 3.58711\n",
      "[150]\ttraining's l1: 3.64661\tvalid_1's l1: 3.51495\n",
      "[200]\ttraining's l1: 3.60256\tvalid_1's l1: 3.46614\n",
      "[250]\ttraining's l1: 3.56676\tvalid_1's l1: 3.4311\n",
      "[300]\ttraining's l1: 3.53648\tvalid_1's l1: 3.40575\n",
      "[350]\ttraining's l1: 3.50854\tvalid_1's l1: 3.38858\n",
      "[400]\ttraining's l1: 3.48252\tvalid_1's l1: 3.37248\n",
      "[450]\ttraining's l1: 3.45923\tvalid_1's l1: 3.35902\n",
      "[500]\ttraining's l1: 3.43795\tvalid_1's l1: 3.35107\n",
      "[550]\ttraining's l1: 3.41819\tvalid_1's l1: 3.34369\n",
      "[600]\ttraining's l1: 3.3999\tvalid_1's l1: 3.33781\n",
      "[650]\ttraining's l1: 3.38132\tvalid_1's l1: 3.33181\n",
      "[700]\ttraining's l1: 3.36326\tvalid_1's l1: 3.3274\n",
      "[750]\ttraining's l1: 3.34617\tvalid_1's l1: 3.3239\n",
      "[800]\ttraining's l1: 3.33047\tvalid_1's l1: 3.32277\n",
      "[850]\ttraining's l1: 3.31529\tvalid_1's l1: 3.32141\n",
      "[900]\ttraining's l1: 3.30039\tvalid_1's l1: 3.32124\n",
      "[950]\ttraining's l1: 3.28622\tvalid_1's l1: 3.31992\n",
      "[1000]\ttraining's l1: 3.27198\tvalid_1's l1: 3.31994\n",
      "[1050]\ttraining's l1: 3.25836\tvalid_1's l1: 3.31982\n",
      "[1100]\ttraining's l1: 3.24504\tvalid_1's l1: 3.31963\n",
      "[1150]\ttraining's l1: 3.23246\tvalid_1's l1: 3.32006\n",
      "[1200]\ttraining's l1: 3.21993\tvalid_1's l1: 3.32108\n",
      "[1250]\ttraining's l1: 3.20733\tvalid_1's l1: 3.32134\n",
      "Early stopping, best iteration is:\n",
      "[1087]\ttraining's l1: 3.24854\tvalid_1's l1: 3.31928\n",
      "0.012739885570347931\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's l1: 3.79593\tvalid_1's l1: 3.69129\n",
      "[100]\ttraining's l1: 3.72155\tvalid_1's l1: 3.57494\n",
      "[150]\ttraining's l1: 3.66335\tvalid_1's l1: 3.49752\n",
      "[200]\ttraining's l1: 3.61779\tvalid_1's l1: 3.44374\n",
      "[250]\ttraining's l1: 3.58012\tvalid_1's l1: 3.40178\n",
      "[300]\ttraining's l1: 3.5483\tvalid_1's l1: 3.37512\n",
      "[350]\ttraining's l1: 3.52054\tvalid_1's l1: 3.35378\n",
      "[400]\ttraining's l1: 3.49471\tvalid_1's l1: 3.33807\n",
      "[450]\ttraining's l1: 3.47151\tvalid_1's l1: 3.32616\n",
      "[500]\ttraining's l1: 3.44919\tvalid_1's l1: 3.31591\n",
      "[550]\ttraining's l1: 3.42762\tvalid_1's l1: 3.30666\n",
      "[600]\ttraining's l1: 3.40748\tvalid_1's l1: 3.30123\n",
      "[650]\ttraining's l1: 3.38884\tvalid_1's l1: 3.29513\n",
      "[700]\ttraining's l1: 3.37107\tvalid_1's l1: 3.29125\n",
      "[750]\ttraining's l1: 3.35378\tvalid_1's l1: 3.28752\n",
      "[800]\ttraining's l1: 3.33751\tvalid_1's l1: 3.28375\n",
      "[850]\ttraining's l1: 3.32127\tvalid_1's l1: 3.28217\n",
      "[900]\ttraining's l1: 3.30593\tvalid_1's l1: 3.28101\n",
      "[950]\ttraining's l1: 3.29099\tvalid_1's l1: 3.27967\n",
      "[1000]\ttraining's l1: 3.27627\tvalid_1's l1: 3.27922\n",
      "[1050]\ttraining's l1: 3.26229\tvalid_1's l1: 3.27894\n",
      "[1100]\ttraining's l1: 3.24909\tvalid_1's l1: 3.27843\n",
      "[1150]\ttraining's l1: 3.23617\tvalid_1's l1: 3.27788\n",
      "[1200]\ttraining's l1: 3.22324\tvalid_1's l1: 3.27766\n",
      "[1250]\ttraining's l1: 3.20992\tvalid_1's l1: 3.277\n",
      "[1300]\ttraining's l1: 3.19617\tvalid_1's l1: 3.2781\n",
      "[1350]\ttraining's l1: 3.18335\tvalid_1's l1: 3.27896\n",
      "[1400]\ttraining's l1: 3.17015\tvalid_1's l1: 3.27973\n",
      "Early stopping, best iteration is:\n",
      "[1244]\ttraining's l1: 3.21137\tvalid_1's l1: 3.27692\n",
      "0.012388019799774677\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's l1: 3.82636\tvalid_1's l1: 3.53122\n",
      "[100]\ttraining's l1: 3.74221\tvalid_1's l1: 3.45395\n",
      "[150]\ttraining's l1: 3.67825\tvalid_1's l1: 3.40009\n",
      "[200]\ttraining's l1: 3.62899\tvalid_1's l1: 3.36585\n",
      "[250]\ttraining's l1: 3.58958\tvalid_1's l1: 3.34226\n",
      "[300]\ttraining's l1: 3.55564\tvalid_1's l1: 3.3255\n",
      "[350]\ttraining's l1: 3.52563\tvalid_1's l1: 3.31187\n",
      "[400]\ttraining's l1: 3.49921\tvalid_1's l1: 3.30156\n",
      "[450]\ttraining's l1: 3.47392\tvalid_1's l1: 3.29218\n",
      "[500]\ttraining's l1: 3.45095\tvalid_1's l1: 3.2873\n",
      "[550]\ttraining's l1: 3.42949\tvalid_1's l1: 3.28294\n",
      "[600]\ttraining's l1: 3.40915\tvalid_1's l1: 3.2802\n",
      "[650]\ttraining's l1: 3.3906\tvalid_1's l1: 3.27933\n",
      "[700]\ttraining's l1: 3.37271\tvalid_1's l1: 3.27865\n",
      "[750]\ttraining's l1: 3.35542\tvalid_1's l1: 3.27713\n",
      "[800]\ttraining's l1: 3.33882\tvalid_1's l1: 3.27572\n",
      "[850]\ttraining's l1: 3.32198\tvalid_1's l1: 3.2745\n",
      "[900]\ttraining's l1: 3.30704\tvalid_1's l1: 3.27413\n",
      "[950]\ttraining's l1: 3.29201\tvalid_1's l1: 3.27312\n",
      "[1000]\ttraining's l1: 3.27714\tvalid_1's l1: 3.27297\n",
      "[1050]\ttraining's l1: 3.26239\tvalid_1's l1: 3.27276\n",
      "[1100]\ttraining's l1: 3.24805\tvalid_1's l1: 3.27347\n",
      "[1150]\ttraining's l1: 3.2345\tvalid_1's l1: 3.27344\n",
      "[1200]\ttraining's l1: 3.22177\tvalid_1's l1: 3.27328\n",
      "Early stopping, best iteration is:\n",
      "[1046]\ttraining's l1: 3.26357\tvalid_1's l1: 3.27252\n",
      "0.012189365198427036\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's l1: 3.67017\tvalid_1's l1: 4.02544\n",
      "[100]\ttraining's l1: 3.57648\tvalid_1's l1: 4.02257\n",
      "[150]\ttraining's l1: 3.50946\tvalid_1's l1: 4.01605\n",
      "[200]\ttraining's l1: 3.45855\tvalid_1's l1: 4.00992\n",
      "[250]\ttraining's l1: 3.41639\tvalid_1's l1: 4.00599\n",
      "[300]\ttraining's l1: 3.38325\tvalid_1's l1: 4.00568\n",
      "[350]\ttraining's l1: 3.35445\tvalid_1's l1: 4.00644\n",
      "[400]\ttraining's l1: 3.3278\tvalid_1's l1: 4.00312\n",
      "[450]\ttraining's l1: 3.30437\tvalid_1's l1: 4.00545\n",
      "[500]\ttraining's l1: 3.28177\tvalid_1's l1: 4.00854\n",
      "[550]\ttraining's l1: 3.26112\tvalid_1's l1: 4.01242\n",
      "[600]\ttraining's l1: 3.24097\tvalid_1's l1: 4.0134\n",
      "Early stopping, best iteration is:\n",
      "[408]\ttraining's l1: 3.32386\tvalid_1's l1: 4.00299\n",
      "0.014638233101672622\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's l1: 3.68611\tvalid_1's l1: 3.92125\n",
      "[100]\ttraining's l1: 3.59068\tvalid_1's l1: 3.90501\n",
      "[150]\ttraining's l1: 3.52035\tvalid_1's l1: 3.89307\n",
      "[200]\ttraining's l1: 3.46652\tvalid_1's l1: 3.88891\n",
      "[250]\ttraining's l1: 3.42332\tvalid_1's l1: 3.89222\n",
      "[300]\ttraining's l1: 3.3885\tvalid_1's l1: 3.89541\n",
      "[350]\ttraining's l1: 3.35962\tvalid_1's l1: 3.89847\n",
      "[400]\ttraining's l1: 3.33044\tvalid_1's l1: 3.90049\n",
      "Early stopping, best iteration is:\n",
      "[210]\ttraining's l1: 3.45657\tvalid_1's l1: 3.88829\n",
      "0.014415823795816872\n",
      "mean mse: 37.87233591743205\n",
      "oof mse: 37.872338337250085\n",
      "mean mae: 3.5519979030368662\n",
      "oof mae: 3.551987859503364\n",
      "mean cprs: 0.013274265493207829\n",
      "oof cprs: 0.013274242430762407\n"
     ]
    }
   ],
   "source": [
    "kf=KFold(n_splits = 5)\n",
    "resu1 = 0\n",
    "impor1 = 0\n",
    "resu2_cprs = 0\n",
    "resu3_mae=0\n",
    "##y_pred = 0\n",
    "feature_importance_df = pd.DataFrame(X_train.columns, columns=[\"feature\"])\n",
    "stack_train = np.zeros([X_train.shape[0],])\n",
    "models = []\n",
    "for fold_, (train_index, test_index) in enumerate(kf.split(X_train, y_train)):\n",
    "    X_train2= X_train.iloc[train_index,:]\n",
    "    y_train2= y_train.iloc[train_index]\n",
    "    X_test2= X_train.iloc[test_index,:]\n",
    "    y_test2= y_train.iloc[test_index]\n",
    "#     clf = lgb.LGBMRegressor(n_estimators=10000, random_state=47,subsample=0.7,\n",
    "#                              colsample_bytree=0.7,learning_rate=0.005,importance_type = 'gain',\n",
    "#                      max_depth = -1, num_leaves = 100,min_child_samples=20,min_split_gain = 0.001,\n",
    "#                        bagging_freq=1,reg_alpha = 0,reg_lambda = 0,n_jobs = -1)\n",
    "    clf = lgb.LGBMRegressor(n_estimators=10000, random_state=47,learning_rate=0.005,importance_type = 'gain',\n",
    "                     n_jobs = -1,metric='mae')\n",
    "    clf.fit(X_train2,y_train2,eval_set = [(X_train2,y_train2),(X_test2,y_test2)],early_stopping_rounds=200,verbose=50)\n",
    "    feature_importance_df[\"Fold\"+str(fold_)] = clf.feature_importances_\n",
    "    models.append(clf)\n",
    "    temp_predict = clf.predict(X_test2)\n",
    "    stack_train[test_index] = temp_predict\n",
    "    ##y_pred += clf.predict(X_test)/5\n",
    "    mse = mean_squared_error(y_test2, temp_predict)\n",
    "    crps = CRPS_pingyi1(temp_predict,y_test2,4,cdf,dist_to_end_train.iloc[test_index])\n",
    "    mae = mean_absolute_error(y_test2, temp_predict)\n",
    "    print(crps)\n",
    "    \n",
    "    resu1 += mse/5\n",
    "    resu2_cprs += crps/5\n",
    "    resu3_mae += mae/5 \n",
    "    impor1 += clf.feature_importances_/5\n",
    "    gc.collect()\n",
    "print('mean mse:',resu1)\n",
    "print('oof mse:',mean_squared_error(y_train,stack_train))\n",
    "print('mean mae:',resu3_mae)\n",
    "print('oof mae:',mean_absolute_error(y_train,stack_train))\n",
    "print('mean cprs:',resu2_cprs)\n",
    "print('oof cprs:',CRPS_pingyi1(stack_train,y_train,4,cdf,dist_to_end_train))\n",
    "\n",
    "feature_importance_df[\"Average\"] = np.mean(feature_importance_df.iloc[:,1:], axis=1)\n",
    "feature_importance_df = feature_importance_df.sort_values(\"Average\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_test(test):\n",
    "    test.loc[test.VisitorTeamAbbr == \"ARI\",'VisitorTeamAbbr'] = \"ARZ\"\n",
    "    test.loc[test.HomeTeamAbbr == \"ARI\",'HomeTeamAbbr'] = \"ARZ\"\n",
    "\n",
    "    test.loc[test.VisitorTeamAbbr == \"BAL\",'VisitorTeamAbbr'] = \"BLT\"\n",
    "    test.loc[test.HomeTeamAbbr == \"BAL\",'HomeTeamAbbr'] = \"BLT\"\n",
    "\n",
    "    test.loc[test.VisitorTeamAbbr == \"CLE\",'VisitorTeamAbbr'] = \"CLV\"\n",
    "    test.loc[test.HomeTeamAbbr == \"CLE\",'HomeTeamAbbr'] = \"CLV\"\n",
    "\n",
    "    test.loc[test.VisitorTeamAbbr == \"HOU\",'VisitorTeamAbbr'] = \"HST\"\n",
    "    test.loc[test.HomeTeamAbbr == \"HOU\",'HomeTeamAbbr'] = \"HST\"\n",
    "    \n",
    "    test['is_run'] = test.NflId == test.NflIdRusher\n",
    "    \n",
    "    tmp_handoff = test['TimeHandoff'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    tmp_snap = test['TimeSnap'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    test['handoff_snap_diff'] = (tmp_handoff - tmp_snap).map(lambda x:x.seconds)\n",
    "    \n",
    "    # my original idea for feature engineering -------------------------------------------------------------\n",
    "    \n",
    "    # age\n",
    "    FMT_birth = '%m/%d/%Y'\n",
    "    FMT_gamedate = '%Y-%m-%d'\n",
    "    test[\"Age\"] = test[\"TimeSnap\"].apply(lambda t: t.split(\"T\")[0])\n",
    "    test[\"Age\"] = test[\"Age\"].apply(lambda t: datetime.strptime(t, FMT_gamedate))\n",
    "    tmp_birth = test[\"PlayerBirthDate\"].apply(lambda t: datetime.strptime(t, FMT_birth))\n",
    "    test[\"Age\"] = test[\"Age\"] - tmp_birth\n",
    "    test[\"Age\"] = test[\"Age\"].apply(lambda t: t.days//365)\n",
    "\n",
    "    # momentum \n",
    "    test[\"Momentum\"] = test[\"S\"] * test[\"PlayerWeight\"]\n",
    "\n",
    "    # on offense\n",
    "    test[\"OnOffense\"] = test[[\"PossessionTeam\", \"HomeTeamAbbr\"]].apply(func, axis=1)\n",
    "    test[\"OnOffense\"] = test[\"OnOffense\"] == test[\"Team\"]\n",
    "    \n",
    "    test[\"Margin\"] = (test[\"HomeScoreBeforePlay\"] - \n",
    "                      test[\"VisitorScoreBeforePlay\"]) + 2 * (1 - (test[\"PossessionTeam\"] == \n",
    "                                                                  test[\"HomeTeamAbbr\"]).astype(int)) * (test[\"VisitorScoreBeforePlay\"] \n",
    "                                                                                                                - test[\"HomeScoreBeforePlay\"])\n",
    "    \n",
    "    #test['ToLeft'] = test.PlayDirection == \"left\"\n",
    "    #test['Dir_rad'] = np.mod(90 - test.Dir, 360) * math.pi/180.0\n",
    "    #test['YardLine_std'] = 100 - test.YardLine\n",
    "    #test.loc[test.FieldPosition.fillna('') == test.PossessionTeam,  \n",
    "    #      'YardLine_std'\n",
    "    #     ] = test.loc[test.FieldPosition.fillna('') == test.PossessionTeam,  \n",
    "    #      'YardLine']\n",
    "    #test['X_std'] = test.X\n",
    "    #test.loc[test.ToLeft, 'X_std'] = 120 - test.loc[test.ToLeft, 'X'] \n",
    "    #test['Y_std'] = test.Y\n",
    "    #test.loc[test.ToLeft, 'Y_std'] = 160/3 - test.loc[test.ToLeft, 'Y'] \n",
    "     #train['Orientation_std'] = -90 + train.Orientation\n",
    "     #train.loc[train.ToLeft, 'Orientation_std'] = np.mod(180 + train.loc[train.ToLeft, 'Orientation_std'], 360)\n",
    "    #test['Dir_std'] = test.Dir_rad\n",
    "    #test.loc[test.ToLeft, 'Dir_std'] = np.mod(np.pi + test.loc[test.ToLeft, 'Dir_rad'], 2*np.pi)\n",
    "    \n",
    "    test[\"ExerciseEnegy\"] = 0.5 * test[\"PlayerWeight\"] * (test[\"S\"]**2)\n",
    "    \n",
    "    rusher_x = np.array(test.groupby([\"PlayId\", \"is_run\"])[\"X\"].agg(np.mean)[1::2])\n",
    "    rusher_x = np.repeat(rusher_x, 22) # repeat each elemnt 22 times train[\"RusherX\"]\n",
    "    rusher_y = np.array(test.groupby([\"PlayId\", \"is_run\"])[\"Y\"].agg(np.mean)[1::2])\n",
    "    rusher_y = np.repeat(rusher_y, 22) # train[\"RusherY\"]\n",
    "    test[\"DisToRusher\"] = np.sqrt((test[\"X\"] - rusher_x) ** 2 + (test[\"Y\"] - rusher_y) ** 2)\n",
    "    test[\"TackleTimeToRusher\"] = test[\"DisToRusher\"] / test[\"S\"] \n",
    "\n",
    "    rusher_s = np.array(test.groupby([\"PlayId\", \"is_run\"]).agg(np.mean)[\"S\"][1::2])\n",
    "    rusher_s = np.repeat(rusher_s, 22)\n",
    "    test[\"RatioSToRusher\"] = test[\"S\"] / rusher_s\n",
    "    \n",
    "    test[\"MoveDist\"] = test[\"S\"] * test[\"handoff_snap_diff\"] + 0.5 * test[\"A\"] * (test[\"handoff_snap_diff\"] **2)\n",
    "    # ratio of real movement distance to theoretical movement distance\n",
    "    test[\"RealToTheoryDis\"] = test[\"Dis\"] / test[\"MoveDist\"]\n",
    "    # my original idea end ------------------------------------------------------------\n",
    "    \n",
    "    test_single = test[test.is_run==True].copy()\n",
    "    test_single['time_quarter'] = test_single.GameClock.map(lambda x:transform_time_quarter(x))\n",
    "    test_single['time_end'] = test_single.apply(lambda x:transform_time_all(x.loc['GameClock'],x.loc['Quarter']),axis=1)\n",
    "    \n",
    "    # my original idea ----------------------------------------------------------------\n",
    "    #test_single['WindSpeed'] = test_single['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n",
    "    #test_single['WindSpeed'] = test_single['WindSpeed'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n",
    "    #test_single['WindSpeed'] = test_single['WindSpeed'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n",
    "    #test_single['WindSpeed'] = test_single['WindSpeed'].apply(str_to_float)\n",
    "    \n",
    "    #test_single['WindDirection'] = test_single['WindDirection'].apply(lambda x: \"north\" if x == \"N\" or x == \"FROM S\"\n",
    "    #                                               else (\"south\" if x == 'S' or x== 'FROM N'\n",
    "    #                                               else (\"west\" if x == 'W' or x == 'FROM E'\n",
    "    #                                               else (\"east\" if x == 'E' or x == 'FROM W'\n",
    "    #                                               else (\"north east\" if x == 'FROM SW' or x == 'FROM SSW' or x == 'FROM WSW'\n",
    "    #                                               else (\"north west\" if x == 'FROM SE' or x == 'FROM SSE' or x == 'FROM ESE'\n",
    "    #                                               else (\"south east\" if x == 'FROM NW' or x == 'FROM NNW' or x == 'FROM WNW'\n",
    "    #                                               else (\"south west\" if x == 'FROM NE' or x == 'FROM NNE' or x == 'FROM ENE'\n",
    "    #                                               else (\"north west\" if x == 'NW' or x == 'NORTHWEST'\n",
    "    #                                               else (\"north east\" if x == 'NE' or x == 'NORTH EAST'\n",
    "    #                                               else (\"south west\" if x == 'SW' or x == 'SOUTHWEST'\n",
    "    #                                               else (\"south east\" if x == 'SE' or x == 'SOUTHEAST' else \"unknown\"))))))))))))\n",
    "    \n",
    "    #test_single['GameWeather'] = test_single['GameWeather'].apply(lambda x: \"rain\" if x in rain \n",
    "    #                                                    else (\"overcast\" if x in overcast\n",
    "    #                                                    else (\"clear\" if x in clear\n",
    "    #                                                    else (\"snow\" if x in snow\n",
    "    #                                                    else (\"indoor\" if x in none else \"unknown\")))))\n",
    "    \n",
    "    test_single['StadiumType'] = test_single['StadiumType'].apply(lambda x: \"outdoor\" if x in outdoor \n",
    "                                                    else (\"indoor closed\" if x in indoor_closed\n",
    "                                                    else (\"indoor open\" if x in indoor_open\n",
    "                                                    else (\"dome_closed\" if x in dome_closed\n",
    "                                                    else (\"dome_open\" if x in dome_open else \"unknown\")))))\n",
    "    \n",
    "    test_single[\"Location\"] = test_single[\"Location\"].map(lambda x: \"Arlington, TX\" if x == \"Arlington, Texas\"\n",
    "                        else (\"Baltimore, MD\" if x == \"Baltimore, Maryland\" or x == \"Baltimore, Md.\"\n",
    "                        else (\"Charlotte, NC\" if x == \"Charlotte, North Carolina\"\n",
    "                        else (\"Chicago, IL\" if x == \"Chicago. IL\"\n",
    "                        else (\"Cincinnati, OH\" if x == \"Cincinnati, Ohio\"\n",
    "                        else (\"Cleveland, OH\" if x == \"Cleveland\" or x == \"Cleveland Ohio\" or x == \"Cleveland, Ohio\" or x == \"Cleveland,Ohio\"\n",
    "                        else (\"Detroit, MI\" if x == \"Detroit\"\n",
    "                        else (\"East Rutherford, NJ\" if x == \"E. Rutherford, NJ\" or x == \"East Rutherford, N.J.\"\n",
    "                        else (\"Foxborough, MA\" if x == \"Foxborough, Ma\"\n",
    "                        else (\"Houston, TX\" if x == \"Houston, Texas\"\n",
    "                        else (\"Jacksonville, FL\" if x == \"Jacksonville Florida\" or x == \"Jacksonville, Fl\" or x == \"Jacksonville, Florida\"\n",
    "                        else (\"London\" if x == \"London, England\"\n",
    "                        else (\"Los Angeles, CA\" if x == \"Los Angeles, Calif.\"\n",
    "                        else (\"Miami Gardens, FLA\" if x == \"Miami Gardens, Fla.\"\n",
    "                        else (\"New Orleans, LA\" if x == \"New Orleans\" or x == \"New Orleans, La.\"\n",
    "                        else (\"Orchard Park, NY\" if x == \"Orchard Park NY\"\n",
    "                        else (\"Philadelphia, PA\" if x == \"Philadelphia, Pa.\"\n",
    "                        else (\"Pittsburgh, PA\" if x == \"Pittsburgh\"\n",
    "                        else (\"Seattle, WA\" if x == \"Seattle\" else x)))))))))))))))))))\n",
    "    \n",
    "    test_single[\"Stadium\"] = test_single[\"Stadium\"].map(lambda x: \"Broncos Stadium at Mile High\" if x==\"Broncos Stadium At Mile High\" \n",
    "                                             else (\"CenturyLink Field\" if x == \"CenturyField\" or x == x==\"CenturyLink\"\n",
    "                                             else (\"Everbank Field\" if x == \"EverBank Field\"\n",
    "                                             else (\"FirstEnergy Stadium\" if x ==\"First Energy Stadium\" or x==\"FirstEnergy\" or x == \"FirstEnergyStadium\"\n",
    "                                             else (\"Lambeau Field\" if x == \"Lambeau field\"\n",
    "                                             else (\"Los Angeles Memorial Coliseum\" if x == \"Los Angeles Memorial Coliesum\"\n",
    "                                             else (\"M&T Bank Stadium\" if x == \"M & T Bank Stadium\" or x == \"M&T Stadium\"\n",
    "                                             else (\"Mercedes-Benz Superdome\" if x == \"Mercedes-Benz Dome\"\n",
    "                                             else (\"MetLife Stadium\" if x == \"MetLife\" or x == \"Metlife Stadium\"\n",
    "                                             else (\"NRG Stadium\" if x == \"NRG\"\n",
    "                                             else (\"Oakland-Alameda County Coliseum\" if x == \"Oakland Alameda-County Coliseum\"\n",
    "                                             else (\"Paul Brown Stadium\" if x == \"Paul Brown Stdium\"\n",
    "                                             else (\"Twickenham Stadium\" if x == \"Twickenham\" else x)))))))))))))\n",
    "    \n",
    "    test_single[\"OffenseFormation\"] = test_single[\"OffenseFormation\"].fillna(\"Unknown\") \n",
    "    test_single['DefendersInTheBox_vs_Distance'] = test_single['DefendersInTheBox'] / test_single['Distance']\n",
    "    \n",
    "    grass_labels = ['grass', 'natural grass', 'natural', 'naturall grass']\n",
    "    test_single['Turf'] = np.where(test_single.Turf.str.lower().isin(grass_labels), \"Natural\", \"Artificial\")\n",
    "    \n",
    "    arr = [[int(s[0]) for s in t.split(\", \")] for t in test_single[\"DefensePersonnel\"]]\n",
    "    test_single[\"DefenseDL\"] = np.array([a[0] for a in arr])\n",
    "    test_single[\"DefenseLB\"] = np.array([a[1] for a in arr])\n",
    "    test_single[\"DefenseDB\"] = np.array([a[2] for a in arr])\n",
    "    test_single[\"DefenseOL\"] = np.array([a[3] if len(a) == 4 else 0 for a in arr])\n",
    "    \n",
    "    test_single[\"OffenseRB\"] = test_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "                            int(x.replace(\",\", \"\").split(\" RB\")[0][-1]) if \"RB\" in x else 0)\n",
    "    test_single[\"OffenseTE\"] = test_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "                            int(x.replace(\",\", \"\").split(\" TE\")[0][-1]) if \"TE\" in x else 0)\n",
    "    test_single[\"OffenseWR\"] = test_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "                            int(x.replace(\",\", \"\").split(\" WR\")[0][-1]) if \"WR\" in x else 0)\n",
    "    test_single[\"OffenseOL\"] = test_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "                            int(x.replace(\",\", \"\").split(\" OL\")[0][-1]) if \"OL\" in x else 0)\n",
    "    test_single[\"OffenseDL\"] = test_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "                            int(x.replace(\",\", \"\").split(\" DL\")[0][-1]) if \"DL\" in x else 0)\n",
    "    test_single[\"OffenseQB\"] = test_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "                            int(x.replace(\",\", \"\").split(\" QB\")[0][-1]) if \"QB\" in x else 0)\n",
    "    \n",
    "    test_single[\"Distance10\"] = test_single[\"Distance\"].apply(lambda x: 1 if x > 10 else 0)\n",
    "    \n",
    "    # test_single[\"DownQuarter\"] = test_single[[\"Down\", \"Quarter\"]].apply(lambda x: \"D{}_Q{}\".format(x[0], x[1]), axis=1)\n",
    "    \n",
    "    # necessary yard per remaining down \n",
    "    test_single[\"NecDisPerDown\"] = test_single[\"Distance\"] / (5 - test_single[\"Down\"])\n",
    "    # my original idea end ------------------------------------------------------------\n",
    "    \n",
    "    test_single['date_game'] = test_single.GameId.map(lambda x:pd.to_datetime(str(x)[:8]))\n",
    "    test_single['runner_height'] = test_single.PlayerHeight.map(transform_height)\n",
    "    return test_single.drop(remove_features,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission file has been saved!  Once you `Commit` your Notebook and it finishes running, you can submit the file to the competition from the Notebook Viewer `Output` tab.\n"
     ]
    }
   ],
   "source": [
    "for (test_df, sample_prediction_df) in env.iter_test():\n",
    "    test_df['own_field'] = (test_df['FieldPosition'] == test_df['PossessionTeam']).astype(int)\n",
    "    dist_to_end_test = test_df.apply(lambda x:(100 - x.loc['YardLine']) if x.loc['own_field']==1 else x.loc['YardLine'],axis=1)\n",
    "    X_test = transform_test(test_df)\n",
    "    X_test.fillna(-999,inplace=True)\n",
    "    \n",
    "    # additional feature engineering -----------------------------------------------------------\n",
    "    tmp = test_df.groupby([\"PlayId\", \"OnOffense\"]).agg(np.mean)[[\"S\", \"X\", \"Y\", \"Age\"]]\n",
    "    X_test[\"DefenseAveSpeed\"] = np.array(tmp[0::2][\"S\"])\n",
    "    X_test[\"OffenseAveSpeed\"] = np.array(tmp[1::2][\"S\"])\n",
    "\n",
    "    X_test[\"DefenseAveX\"] = np.array(tmp[0::2][\"X\"])\n",
    "    X_test[\"OffenseAveX\"] = np.array(tmp[1::2][\"X\"])\n",
    "\n",
    "    X_test[\"DefenseAveY\"] = np.array(tmp[0::2][\"Y\"]) \n",
    "    X_test[\"OffenseAveY\"] = np.array(tmp[1::2][\"Y\"]) \n",
    "\n",
    "    X_test[\"DefenseAveAge\"] = np.array(tmp[0::2][\"Age\"])\n",
    "    X_test[\"OffenseAveAge\"] = np.array(tmp[1::2][\"Age\"])\n",
    "    \n",
    "    tmp = test_df.groupby([\"PlayId\", \"OnOffense\"]).agg([\"std\"])[[\"X\", \"Y\"]]\n",
    "    X_test[\"DefenseStdX\"] = np.array(tmp[0::2][\"X\"])\n",
    "    X_test[\"OffenseStdX\"] = np.array(tmp[1::2][\"X\"])\n",
    "\n",
    "    X_test[\"DefenseStdY\"] = np.array(tmp[0::2][\"Y\"])\n",
    "    X_test[\"OffenseStdY\"] = np.array(tmp[1::2][\"Y\"])\n",
    "\n",
    "    X_test[\"RunnerToDefenseCentoid\"] = np.sqrt((X_test[\"X\"] - X_test[\"DefenseAveX\"]) ** 2 + (X_test[\"Y\"] - X_test[\"DefenseAveY\"]) ** 2)\n",
    "    X_test[\"RunnerToOffenseCentoid\"] = np.sqrt((X_test[\"X\"] - X_test[\"OffenseAveX\"]) ** 2 + (X_test[\"Y\"] - X_test[\"OffenseAveY\"]) ** 2)\n",
    "\n",
    "    # defense x spread, offense x spread\n",
    "    tmp_max = test_df.groupby([\"PlayId\", \"OnOffense\"])[\"X\"].max()\n",
    "    tmp_min = test_df.groupby([\"PlayId\", \"OnOffense\"])[\"X\"].min()\n",
    "    X_test[\"DefenseSpreadX\"] = np.array(tmp_max[0::2]- tmp_min[0::2])\n",
    "    X_test[\"OffenseSpreadX\"] = np.array(tmp_max[1::2]- tmp_min[1::2])\n",
    "    \n",
    "    X_test[\"RunnerToScrimmage\"] = X_test[\"X\"] - X_test[\"YardLine\"]\n",
    "\n",
    "    # runner horizontal and vertical speed\n",
    "    radian_angle = (90 - X_test['Dir']) * np.pi / 180.0\n",
    "    X_test['v_horizontal'] = np.abs(X_test['S'] * np.cos(radian_angle))\n",
    "    X_test['v_vertical'] = np.abs(X_test['S'] * np.sin(radian_angle))\n",
    "\n",
    "    # runner horizontal and vertical momentum\n",
    "    X_test['m_horizontal'] = np.abs(X_test['Momentum'] * np.cos(radian_angle))\n",
    "    X_test['m_vertical'] = np.abs(X_test['Momentum'] * np.sin(radian_angle))\n",
    "\n",
    "    # minimum distance to rusher from defenders\n",
    "    X_test[\"MinDisFromRushToDef\"] = np.array(test_df.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].min()[0::2])\n",
    "\n",
    "    # tackle time from closest defender to rusher\n",
    "    X_test[\"MinTackleTime\"] = np.array(test_df.groupby([\"PlayId\", \"OnOffense\"])[\"TackleTimeToRusher\"].min()[0::2])\n",
    "\n",
    "    # average tackle time from all defenders to rusher\n",
    "    X_test[\"AveTackleTime\"] = np.array(test_df.groupby([\"PlayId\", \"OnOffense\"]).agg(np.mean)[\"TackleTimeToRusher\"][0::2])\n",
    "\n",
    "    # runner vs 1st defender speed: runner's velocity divided by closest defender's speed\n",
    "    X_test[\"RatioSRusherToCloseDef\"] = np.array(test_df.loc[test_df.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].idxmin()[0::2]][\"RatioSToRusher\"])\n",
    "    \n",
    "    # runner horizontal and vertical distance\n",
    "    X_test[\"dis_horizontal\"] = np.abs(X_test['Dis'] * np.cos(radian_angle))\n",
    "    X_test[\"dis_vertical\"] = np.abs(X_test['Dis'] * np.sin(radian_angle))\n",
    "    X_test[\"RunnerMoveRatio\"] = X_test[\"dis_horizontal\"] / X_test[\"dis_vertical\"]\n",
    "    \n",
    "    # the momentum of 1st closest defender to rusher, horizontal momentum, vertical momentum\n",
    "    X_test[\"DefMomentumCloToRusher\"] = np.array(test_df.loc[test_df.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].idxmin()[0::2]][\"Momentum\"])\n",
    "    X_test[\"DefMomentumCloToRusher_horizontal\"] = np.abs(X_test['DefMomentumCloToRusher'] * np.cos(radian_angle))\n",
    "    X_test[\"DefMomentumCloToRusher_vertical\"] = np.abs(X_test['DefMomentumCloToRusher'] * np.sin(radian_angle))\n",
    "\n",
    "    # the horizontal, vertical mometum of rusher\n",
    "    X_test[\"RusherMomentum_horizontal\"] =  np.abs(X_test['Momentum'] * np.cos(radian_angle))\n",
    "    X_test[\"RusherMomentum_vertical\"] =  np.abs(X_test['Momentum'] * np.sin(radian_angle))\n",
    "\n",
    "    # difference of horizontal momentum \n",
    "    X_test[\"hMomentum_rusher_vs_defender\"] = X_test[\"RusherMomentum_horizontal\"] - X_test[\"DefMomentumCloToRusher_horizontal\"]\n",
    "    \n",
    "    # voronoi area\n",
    "    pts = np.array(test_df[[\"X\", \"Y\"]]).reshape(test_df.shape[0]//22, 22, 2)\n",
    "    # index of row where rusher data is included when separated by each play\n",
    "    rusher_index = list(test_df[test_df.is_run==True].index % 22) \n",
    "    closest_def_index = list(test_df.loc[test_df.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].idxmin()[0::2]].index % 22)\n",
    "    rusher_voronoi = []\n",
    "    closest_def_voronoi = []\n",
    "    for i in range(0, test_df.shape[0] //22):\n",
    "        rusher_voronoi.append(voronoi_volumes(pts[i], rusher_index[i]))\n",
    "        closest_def_voronoi.append(voronoi_volumes(pts[i], closest_def_index[i]))\n",
    "    X_test[\"RusherVoronoi\"] = rusher_voronoi    \n",
    "    X_test[\"FirstDefenderVoronoi\"] = closest_def_voronoi \n",
    "    \n",
    "    # ------------------------------------------------------\n",
    "    for f in X_test.columns:\n",
    "        if X_test[f].dtype=='object':\n",
    "            X_test[f] = X_test[f].map(lambda x:x if x in set(X_train[f]) else -999)\n",
    "    for f in X_test.columns:\n",
    "        if X_test[f].dtype=='object': \n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(X_train[f])+[-999])\n",
    "            X_test[f] = lbl.transform(list(X_test[f])) \n",
    "    pred_value = 0\n",
    "    for model in models:\n",
    "        pred_value += model.predict(X_test)[0]/5\n",
    "    pred_data = list(get_score(pred_value,cdf,4,dist_to_end_test.values[0]))\n",
    "    pred_data = np.array(pred_data).reshape(1,199)\n",
    "    pred_target = pd.DataFrame(index = sample_prediction_df.index, \\\n",
    "                               columns = sample_prediction_df.columns, \\\n",
    "                               #data = np.array(pred_data))\n",
    "                               data = pred_data)\n",
    "    env.predict(pred_target)\n",
    "env.write_submission_file()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
