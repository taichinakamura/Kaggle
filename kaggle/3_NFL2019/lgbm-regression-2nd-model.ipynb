{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "\n",
    "### Explanation\n",
    "\n",
    "This kernel used LGBM and treated it as a regression problem. I only did a little feature engineering so far.(just transform some date format features into numeric)\n",
    "\n",
    "The ideas is that:\n",
    "- if we treated it as a regression problem, it's better to do some smooth operation. See the [kernel](https://www.kaggle.com/hukuda222/nfl-simple-evluation-trick).\n",
    "- I used the distribution in [kernel](https://www.kaggle.com/jpmiller/simple-distribution) as my smooth distribution.\n",
    "- We can see the simple distribution in [kernel](https://www.kaggle.com/jpmiller/simple-distribution) get the 1436 LB. If we use LGBM to do regression prediction and shift the distribution based on the yards we predicte, we should get a better LB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "###raw mae\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold,TimeSeriesSplit,KFold,GroupKFold\n",
    "from sklearn.metrics import roc_auc_score,mean_squared_error,mean_absolute_error\n",
    "import sqlite3\n",
    "import xgboost as xgb\n",
    "import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import pearsonr\n",
    "import gc\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from bayes_opt import BayesianOptimization\n",
    "from kaggle.competitions import nflrush\n",
    "import math\n",
    "import tqdm\n",
    "env = nflrush.make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/nfl-big-data-bowl-2020/train.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 509762/509762 [00:02<00:00, 177640.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess finished\n"
     ]
    }
   ],
   "source": [
    "def strtoseconds(txt):\n",
    "    txt = txt.split(':')\n",
    "    ans = int(txt[0])*60 + int(txt[1]) + int(txt[2])/60\n",
    "    return ans\n",
    "\n",
    "def str_to_float(txt):\n",
    "    try:\n",
    "        return float(txt)\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "train.loc[train.VisitorTeamAbbr == \"ARI\",'VisitorTeamAbbr'] = \"ARZ\"\n",
    "train.loc[train.HomeTeamAbbr == \"ARI\",'HomeTeamAbbr'] = \"ARZ\"\n",
    "\n",
    "train.loc[train.VisitorTeamAbbr == \"BAL\",'VisitorTeamAbbr'] = \"BLT\"\n",
    "train.loc[train.HomeTeamAbbr == \"BAL\",'HomeTeamAbbr'] = \"BLT\"\n",
    "\n",
    "train.loc[train.VisitorTeamAbbr == \"CLE\",'VisitorTeamAbbr'] = \"CLV\"\n",
    "train.loc[train.HomeTeamAbbr == \"CLE\",'HomeTeamAbbr'] = \"CLV\"\n",
    "\n",
    "train.loc[train.VisitorTeamAbbr == \"HOU\",'VisitorTeamAbbr'] = \"HST\"\n",
    "train.loc[train.HomeTeamAbbr == \"HOU\",'HomeTeamAbbr'] = \"HST\"\n",
    "\n",
    "train[\"OffenseFormation\"] = train[\"OffenseFormation\"].fillna(\"Unknown\") \n",
    "\n",
    "arr = [[int(s[0]) for s in t.split(\", \")] for t in train[\"DefensePersonnel\"]]\n",
    "train[\"DefenseDL\"] = np.array([a[0] for a in arr])\n",
    "train[\"DefenseLB\"] = np.array([a[1] for a in arr])\n",
    "train[\"DefenseDB\"] = np.array([a[2] for a in arr])\n",
    "train[\"DefenseOL\"] = np.array([a[3] if len(a) == 4 else 0 for a in arr])\n",
    "\n",
    "arr = [[s for s in t.replace(\" \", \"\").split(\",\")] for t in train[\"OffensePersonnel\"]]\n",
    "RB_count = np.zeros(len(arr))\n",
    "TE_count = np.zeros(len(arr))\n",
    "WR_count = np.zeros(len(arr))\n",
    "OL_count = np.zeros(len(arr))\n",
    "DL_count = np.zeros(len(arr))\n",
    "QB_count = np.zeros(len(arr))\n",
    "\n",
    "for i in tqdm.tqdm(range(len(arr))):\n",
    "    for j in range(len(arr[i])):\n",
    "        if \"RB\" in arr[i][j]:\n",
    "            RB_count[i] = int(arr[i][j][0])\n",
    "        elif \"TE\" in arr[i][j]:\n",
    "            TE_count[i] = int(arr[i][j][0])\n",
    "        elif \"WR\" in arr[i][j]:\n",
    "            WR_count[i] = int(arr[i][j][0])\n",
    "        elif \"OL\" in arr[i][j]:\n",
    "            OL_count[i] = int(arr[i][j][0])\n",
    "        elif \"DL\" in arr[i][j]:\n",
    "            DL_count[i] = int(arr[i][j][0])\n",
    "        elif \"QB\" in arr[i][j]:\n",
    "            QB_count[i] = int(arr[i][j][0])\n",
    "train[\"OffenseRB\"] = RB_count\n",
    "train[\"OffenseTE\"] = TE_count\n",
    "train[\"OffenseWR\"] = WR_count\n",
    "train[\"OffenseOL\"] = OL_count\n",
    "train[\"OffenseDL\"] = DL_count\n",
    "train[\"OffenseQB\"] = QB_count\n",
    "\n",
    "train['DefendersInTheBox_vs_Distance'] = train['DefendersInTheBox'] / train['Distance']\n",
    "\n",
    "train[\"Stadium\"] = train[\"Stadium\"].map(lambda x: \"Broncos Stadium at Mile High\" if x==\"Broncos Stadium At Mile High\" \n",
    "                                             else (\"CenturyLink Field\" if x == \"CenturyField\" or x == x==\"CenturyLink\"\n",
    "                                             else (\"Everbank Field\" if x == \"EverBank Field\"\n",
    "                                             else (\"FirstEnergy Stadium\" if x ==\"First Energy Stadium\" or x==\"FirstEnergy\" or x == \"FirstEnergyStadium\"\n",
    "                                             else (\"Lambeau Field\" if x == \"Lambeau field\"\n",
    "                                             else (\"Los Angeles Memorial Coliseum\" if x == \"Los Angeles Memorial Coliesum\"\n",
    "                                             else (\"M&T Bank Stadium\" if x == \"M & T Bank Stadium\" or x == \"M&T Stadium\"\n",
    "                                             else (\"Mercedes-Benz Superdome\" if x == \"Mercedes-Benz Dome\"\n",
    "                                             else (\"MetLife Stadium\" if x == \"MetLife\" or x == \"Metlife Stadium\"\n",
    "                                             else (\"NRG Stadium\" if x == \"NRG\"\n",
    "                                             else (\"Oakland-Alameda County Coliseum\" if x == \"Oakland Alameda-County Coliseum\"\n",
    "                                             else (\"Paul Brown Stadium\" if x == \"Paul Brown Stdium\"\n",
    "                                             else (\"Twickenham Stadium\" if x == \"Twickenham\" else x)))))))))))))\n",
    "\n",
    "train[\"Location\"] = train[\"Location\"].map(lambda x: \"Arlington, TX\" if x == \"Arlington, Texas\"\n",
    "                        else (\"Baltimore, MD\" if x == \"Baltimore, Maryland\" or x == \"Baltimore, Md.\"\n",
    "                        else (\"Charlotte, NC\" if x == \"Charlotte, North Carolina\"\n",
    "                        else (\"Chicago, IL\" if x == \"Chicago. IL\"\n",
    "                        else (\"Cincinnati, OH\" if x == \"Cincinnati, Ohio\"\n",
    "                        else (\"Cleveland, OH\" if x == \"Cleveland\" or x == \"Cleveland Ohio\" or x == \"Cleveland, Ohio\" or x == \"Cleveland,Ohio\"\n",
    "                        else (\"Detroit, MI\" if x == \"Detroit\"\n",
    "                        else (\"East Rutherford, NJ\" if x == \"E. Rutherford, NJ\" or x == \"East Rutherford, N.J.\"\n",
    "                        else (\"Foxborough, MA\" if x == \"Foxborough, Ma\"\n",
    "                        else (\"Houston, TX\" if x == \"Houston, Texas\"\n",
    "                        else (\"Jacksonville, FL\" if x == \"Jacksonville Florida\" or x == \"Jacksonville, Fl\" or x == \"Jacksonville, Florida\"\n",
    "                        else (\"London\" if x == \"London, England\"\n",
    "                        else (\"Los Angeles, CA\" if x == \"Los Angeles, Calif.\"\n",
    "                        else (\"Miami Gardens, FLA\" if x == \"Miami Gardens, Fla.\"\n",
    "                        else (\"New Orleans, LA\" if x == \"New Orleans\" or x == \"New Orleans, La.\"\n",
    "                        else (\"Orchard Park, NY\" if x == \"Orchard Park NY\"\n",
    "                        else (\"Philadelphia, PA\" if x == \"Philadelphia, Pa.\"\n",
    "                        else (\"Pittsburgh, PA\" if x == \"Pittsburgh\"\n",
    "                        else (\"Seattle, WA\" if x == \"Seattle\" else x)))))))))))))))))))\n",
    "\n",
    "train[\"Turf\"] = train[\"Turf\"].map(lambda x: \"Artificial\" if x == \"Artifical\"\n",
    "                                       else (\"Field Turf\" if x == \"FieldTurf\" or x == \"Field turf\"\n",
    "                                       else (\"FieldTurf 360\" if x == \"FieldTurf360\"\n",
    "                                       else (\"Natural Grass\" if x == \"natural grass\" or x == \"Naturall Grass\" or x == \"Natural grass\" or x == \"Natural\"\n",
    "                                       else (\"Grass\" if x == \"grass\"\n",
    "                                       else (\"UBU Speed Series-S5-M\" if x == \"UBU Sports Speed S5-M\" else x))))))\n",
    "\n",
    "outdoor =['Outdoor', 'Outdoors', 'Cloudy', 'Heinz Field', 'Outdor', 'Ourdoor', 'Outside', 'Outddors', 'Outdoor Retr Roof-Open', 'Oudoor', 'Bowl']\n",
    "indoor_closed = ['Indoors', 'Indoor', 'Indoor, Roof Closed', 'Indoor, Roof Closed', \n",
    "                 'Retractable Roof', 'Retr. Roof-Closed', 'Retr. Roof - Closed', 'Retr. Roof Closed']\n",
    "indoor_open = ['Indoor, Open Roof', 'Open', 'Retr. Roof-Open', 'Retr. Roof - Open']\n",
    "dome_closed = ['Dome', 'Domed, closed', 'Closed Dome', 'Domed', 'Dome, closed']\n",
    "dome_open = ['Domed, Open', 'Domed, open']\n",
    "\n",
    "train['StadiumType'] = train['StadiumType'].apply(lambda x: \"outdoor\" if x in outdoor \n",
    "                                                        else (\"indoor closed\" if x in indoor_closed\n",
    "                                                        else (\"indoor open\" if x in indoor_open\n",
    "                                                        else (\"dome_closed\" if x in dome_closed\n",
    "                                                        else (\"dome_open\" if x in dome_open else \"unknown\")))))\n",
    "\n",
    "train[\"Margin\"] = (train[\"HomeScoreBeforePlay\"] - \n",
    "                      train[\"VisitorScoreBeforePlay\"]) + 2 * (1 - (train[\"PossessionTeam\"] == \n",
    "                                                                      train[\"HomeTeamAbbr\"]).astype(int)) * (train[\"VisitorScoreBeforePlay\"] \n",
    "                                                                                                                - train[\"HomeScoreBeforePlay\"])\n",
    "\n",
    "rain = ['Rainy', 'Rain Chance 40%', 'Showers', 'Cloudy with periods of rain, thunder possible. Winds shifting to WNW, 10-20 mph.',\n",
    "          'Scattered Showers', 'Cloudy, Rain', 'Rain shower', 'Light Rain', 'Rain']\n",
    "overcast = ['Cloudy, light snow accumulating 1-3\"', 'Party Cloudy', 'Cloudy, chance of rain','Coudy', 'Cloudy, 50% change of rain', \n",
    "            'Rain likely, temps in low 40s.', 'Cloudy and cold', 'Cloudy, fog started developing in 2nd quarter', 'Partly Clouidy', \n",
    "            '30% Chance of Rain', 'Mostly Coudy', 'Cloudy and Cool', 'cloudy', 'Partly cloudy', 'Overcast', 'Hazy', 'Mostly cloudy', \n",
    "            'Mostly Cloudy', 'Partly Cloudy', 'Cloudy']\n",
    "clear = ['Partly clear', 'Sunny and clear', 'Sun & clouds', 'Clear and Sunny', 'Sunny and cold', 'Sunny Skies', 'Clear and Cool', 'Clear and sunny',\n",
    "        'Sunny, highs to upper 80s', 'Mostly Sunny Skies', 'Cold', 'Clear and warm', 'Sunny and warm', 'Clear and cold', 'Mostly sunny',\n",
    "        'T: 51; H: 55; W: NW 10 mph', 'Clear Skies', 'Clear skies', 'Partly sunny', 'Fair', 'Partly Sunny', 'Mostly Sunny', 'Clear', 'Sunny']\n",
    "snow = ['Heavy lake effect snow', 'Snow']\n",
    "none = ['N/A Indoor', 'Indoors', 'Indoor', 'N/A (Indoors)', 'Controlled Climate']\n",
    "\n",
    "train['GameWeather'] = train['GameWeather'].apply(lambda x: \"rain\" if x in rain \n",
    "                                                        else (\"overcast\" if x in overcast\n",
    "                                                        else (\"clear\" if x in clear\n",
    "                                                        else (\"snow\" if x in snow\n",
    "                                                        else (\"indoor\" if x in none else \"unknown\")))))\n",
    "\n",
    "train['WindSpeed'] = train['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n",
    "train['WindSpeed'] = train['WindSpeed'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n",
    "train['WindSpeed'] = train['WindSpeed'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n",
    "train['WindSpeed'] = train['WindSpeed'].apply(str_to_float)\n",
    "\n",
    "train['WindDirection'] = train['WindDirection'].apply(lambda x: \"north\" if x == \"N\" or x == \"FROM S\"\n",
    "                                                   else (\"south\" if x == 'S' or x== 'FROM N'\n",
    "                                                   else (\"west\" if x == 'W' or x == 'FROM E'\n",
    "                                                   else (\"east\" if x == 'E' or x == 'FROM W'\n",
    "                                                   else (\"north east\" if x == 'FROM SW' or x == 'FROM SSW' or x == 'FROM WSW'\n",
    "                                                   else (\"north west\" if x == 'FROM SE' or x == 'FROM SSE' or x == 'FROM ESE'\n",
    "                                                   else (\"south east\" if x == 'FROM NW' or x == 'FROM NNW' or x == 'FROM WNW'\n",
    "                                                   else (\"south west\" if x == 'FROM NE' or x == 'FROM NNE' or x == 'FROM ENE'\n",
    "                                                   else (\"north west\" if x == 'NW' or x == 'NORTHWEST'\n",
    "                                                   else (\"north east\" if x == 'NE' or x == 'NORTH EAST'\n",
    "                                                   else (\"south west\" if x == 'SW' or x == 'SOUTHWEST'\n",
    "                                                   else (\"south east\" if x == 'SE' or x == 'SOUTHEAST' else \"unknown\"))))))))))))\n",
    "\n",
    "train['ToLeft'] = train.PlayDirection == \"left\"\n",
    "train['Dir_rad'] = np.mod(90 - train.Dir, 360) * math.pi/180.0\n",
    "train['TeamOnOffense'] = \"home\"\n",
    "train.loc[train.PossessionTeam != train.HomeTeamAbbr, 'TeamOnOffense'] = \"away\"\n",
    "train['IsOnOffense'] = train.Team == train.TeamOnOffense # Is player on offense?\n",
    "train['YardLine_std'] = 100 - train.YardLine\n",
    "train.loc[train.FieldPosition.fillna('') == train.PossessionTeam,  \n",
    "          'YardLine_std'\n",
    "         ] = train.loc[train.FieldPosition.fillna('') == train.PossessionTeam,  \n",
    "          'YardLine']\n",
    "train['X_std'] = train.X\n",
    "train.loc[train.ToLeft, 'X_std'] = 120 - train.loc[train.ToLeft, 'X'] \n",
    "train['Y_std'] = train.Y\n",
    "train.loc[train.ToLeft, 'Y_std'] = 160/3 - train.loc[train.ToLeft, 'Y'] \n",
    "#train['Orientation_std'] = -90 + train.Orientation\n",
    "#train.loc[train.ToLeft, 'Orientation_std'] = np.mod(180 + train.loc[train.ToLeft, 'Orientation_std'], 360)\n",
    "train['Dir_std'] = train.Dir_rad\n",
    "train.loc[train.ToLeft, 'Dir_std'] = np.mod(np.pi + train.loc[train.ToLeft, 'Dir_rad'], 2*np.pi)\n",
    "print(\"Preprocess finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['is_run'] = train.NflId == train.NflIdRusher\n",
    "train_single = train[train.is_run==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "def transform_time_quarter(str1):\n",
    "    return int(str1[:2])*60 + int(str1[3:5])\n",
    "def transform_time_all(str1,quarter):\n",
    "    if quarter<=4:\n",
    "        return 15*60 - (int(str1[:2])*60 + int(str1[3:5])) + (quarter-1)*15*60\n",
    "    if quarter ==5:\n",
    "        return 10*60 - (int(str1[:2])*60 + int(str1[3:5])) + (quarter-1)*15*60\n",
    "train_single['time_quarter'] = train_single.GameClock.map(lambda x:transform_time_quarter(x))\n",
    "train_single['time_end'] = train_single.apply(lambda x:transform_time_all(x.loc['GameClock'],x.loc['Quarter']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "train_single['TimeHandoff'] = train_single['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "train_single['TimeSnap'] = train_single['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "train_single['handoff_snap_diff'] = (train_single['TimeHandoff'] - train_single['TimeSnap']).map(lambda x:x.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "remove_features = ['GameId','PlayId','DisplayName','GameClock','TimeHandoff','TimeSnap', 'OffensePersonnel', 'DefensePersonnel', 'X', 'Y', 'Dir', \"YardLine\"]\n",
    "train_single['date_game'] = train_single.GameId.map(lambda x:pd.to_datetime(str(x)[:8]))\n",
    "train_single['runner_age'] = (train_single.date_game.map(pd.to_datetime) - train_single.PlayerBirthDate.map(pd.to_datetime)).map(lambda x:x.days)/365\n",
    "remove_features.append('HomeTeamAbbr')\n",
    "remove_features.append('VisitorTeamAbbr')\n",
    "remove_features.append('PlayerBirthDate')\n",
    "remove_features.append('is_run')\n",
    "def transform_height(te):\n",
    "    return (int(te.split('-')[0])*12 + int(te.split('-')[1]))*2.54/100\n",
    "train_single['runner_height'] = train_single.PlayerHeight.map(transform_height)\n",
    "remove_features.append('PossessionTeam')\n",
    "remove_features.append('FieldPosition')\n",
    "remove_features.append('PlayerHeight')\n",
    "remove_features.append('NflIdRusher')\n",
    "remove_features.append('date_game')\n",
    "train_single['own_field'] = (train_single['FieldPosition'] == train_single['PossessionTeam']).astype(int)\n",
    "dist_to_end_train = train_single.apply(lambda x:(100 - x.loc['YardLine']) if x.loc['own_field']==1 else x.loc['YardLine'],axis=1)\n",
    "remove_features.append('own_field')\n",
    "train_single.drop(remove_features,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:4244: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  **kwargs\n"
     ]
    }
   ],
   "source": [
    "train_single.fillna(-999,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_single.Yards\n",
    "X_train = train_single.drop(['Yards'],axis=1)\n",
    "for f in X_train.columns:\n",
    "    if X_train[f].dtype=='object': \n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(X_train[f])+[-999])\n",
    "        X_train[f] = lbl.transform(list(X_train[f]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Team', 'S', 'A', 'Dis', 'Orientation', 'NflId', 'JerseyNumber',\n",
       "       'Season', 'Quarter', 'Down', 'Distance', 'HomeScoreBeforePlay',\n",
       "       'VisitorScoreBeforePlay', 'OffenseFormation', 'DefendersInTheBox',\n",
       "       'PlayDirection', 'PlayerWeight', 'PlayerCollegeName', 'Position',\n",
       "       'Week', 'Stadium', 'Location', 'StadiumType', 'Turf', 'GameWeather',\n",
       "       'Temperature', 'Humidity', 'WindSpeed', 'WindDirection', 'DefenseDL',\n",
       "       'DefenseLB', 'DefenseDB', 'DefenseOL', 'OffenseRB', 'OffenseTE',\n",
       "       'OffenseWR', 'OffenseOL', 'OffenseDL', 'OffenseQB',\n",
       "       'DefendersInTheBox_vs_Distance', 'Margin', 'ToLeft', 'Dir_rad',\n",
       "       'TeamOnOffense', 'IsOnOffense', 'YardLine_std', 'X_std', 'Y_std',\n",
       "       'Dir_std', 'time_quarter', 'time_end', 'handoff_snap_diff',\n",
       "       'runner_age', 'runner_height'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cdf_df(yards_array):\n",
    "    pdf, edges = np.histogram(yards_array, bins=199,\n",
    "                 range=(-99,100), density=True)\n",
    "    cdf = pdf.cumsum().clip(0, 1)\n",
    "    cdf_df = pd.DataFrame(data=cdf.reshape(-1, 1).T, \n",
    "                            columns=['Yards'+str(i) for i in range(-99,100)])\n",
    "    return cdf_df\n",
    "cdf = get_cdf_df(y_train).values.reshape(-1,)\n",
    "\n",
    "def get_score(y_pred,cdf,w,dist_to_end):\n",
    "    y_pred = int(y_pred)\n",
    "    if y_pred ==w:\n",
    "        y_pred_array = cdf.copy()\n",
    "    elif y_pred - w >0:\n",
    "        y_pred_array = np.zeros(199)\n",
    "        y_pred_array[(y_pred-w):] = cdf[:(-(y_pred-w))].copy()\n",
    "    elif w - y_pred >0:\n",
    "        y_pred_array = np.ones(199)\n",
    "        y_pred_array[:(y_pred-w)] = cdf[(w-y_pred):].copy()\n",
    "    y_pred_array[-1]=1\n",
    "    y_pred_array[(dist_to_end+99):]=1\n",
    "    return y_pred_array    \n",
    "\n",
    "def get_score_pingyi1(y_pred,y_true,cdf,w,dist_to_end):\n",
    "    y_pred = int(y_pred)\n",
    "    if y_pred ==w:\n",
    "        y_pred_array = cdf.copy()\n",
    "    elif y_pred - w >0:\n",
    "        y_pred_array = np.zeros(199)\n",
    "        y_pred_array[(y_pred-w):] = cdf[:(-(y_pred-w))].copy()\n",
    "    elif w - y_pred >0:\n",
    "        y_pred_array = np.ones(199)\n",
    "        y_pred_array[:(y_pred-w)] = cdf[(w-y_pred):].copy()\n",
    "    y_pred_array[-1]=1\n",
    "    y_pred_array[(dist_to_end+99):]=1\n",
    "    y_true_array = np.zeros(199)\n",
    "    y_true_array[(y_true+99):]=1\n",
    "    return np.mean((y_pred_array - y_true_array)**2)\n",
    "\n",
    "\n",
    "def CRPS_pingyi1(y_preds,y_trues,w,cdf,dist_to_ends):\n",
    "    if len(y_preds) != len(y_trues):\n",
    "        print('length does not match')\n",
    "        return None\n",
    "    n = len(y_preds)\n",
    "    tmp = []\n",
    "    for a,b,c in zip(y_preds, y_trues,dist_to_ends):\n",
    "        tmp.append(get_score_pingyi1(a,b,cdf,w,c))\n",
    "    return np.mean(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's l1: 3.78782\tvalid_1's l1: 3.70179\n",
      "[100]\ttraining's l1: 3.7213\tvalid_1's l1: 3.5998\n",
      "[150]\ttraining's l1: 3.67424\tvalid_1's l1: 3.53983\n",
      "[200]\ttraining's l1: 3.63573\tvalid_1's l1: 3.4886\n",
      "[250]\ttraining's l1: 3.60603\tvalid_1's l1: 3.45523\n",
      "[300]\ttraining's l1: 3.58177\tvalid_1's l1: 3.43432\n",
      "[350]\ttraining's l1: 3.55977\tvalid_1's l1: 3.41701\n",
      "[400]\ttraining's l1: 3.53939\tvalid_1's l1: 3.39977\n",
      "[450]\ttraining's l1: 3.52119\tvalid_1's l1: 3.38806\n",
      "[500]\ttraining's l1: 3.50441\tvalid_1's l1: 3.37827\n",
      "[550]\ttraining's l1: 3.48861\tvalid_1's l1: 3.36958\n",
      "[600]\ttraining's l1: 3.47374\tvalid_1's l1: 3.36225\n",
      "[650]\ttraining's l1: 3.45939\tvalid_1's l1: 3.35667\n",
      "[700]\ttraining's l1: 3.44553\tvalid_1's l1: 3.35245\n",
      "[750]\ttraining's l1: 3.43226\tvalid_1's l1: 3.34895\n",
      "[800]\ttraining's l1: 3.41962\tvalid_1's l1: 3.34577\n",
      "[850]\ttraining's l1: 3.40765\tvalid_1's l1: 3.34467\n",
      "[900]\ttraining's l1: 3.39582\tvalid_1's l1: 3.3423\n",
      "[950]\ttraining's l1: 3.38395\tvalid_1's l1: 3.34069\n",
      "[1000]\ttraining's l1: 3.37336\tvalid_1's l1: 3.3396\n",
      "[1050]\ttraining's l1: 3.36277\tvalid_1's l1: 3.33881\n",
      "[1100]\ttraining's l1: 3.35226\tvalid_1's l1: 3.3389\n",
      "[1150]\ttraining's l1: 3.3417\tvalid_1's l1: 3.33883\n",
      "[1200]\ttraining's l1: 3.33148\tvalid_1's l1: 3.34034\n",
      "[1250]\ttraining's l1: 3.32143\tvalid_1's l1: 3.34133\n",
      "Early stopping, best iteration is:\n",
      "[1066]\ttraining's l1: 3.35943\tvalid_1's l1: 3.33828\n",
      "0.012967960321280681\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's l1: 3.79637\tvalid_1's l1: 3.69392\n",
      "[100]\ttraining's l1: 3.72775\tvalid_1's l1: 3.59004\n",
      "[150]\ttraining's l1: 3.68255\tvalid_1's l1: 3.51969\n",
      "[200]\ttraining's l1: 3.64604\tvalid_1's l1: 3.46558\n",
      "[250]\ttraining's l1: 3.6165\tvalid_1's l1: 3.43269\n",
      "[300]\ttraining's l1: 3.59288\tvalid_1's l1: 3.41084\n",
      "[350]\ttraining's l1: 3.57219\tvalid_1's l1: 3.39343\n",
      "[400]\ttraining's l1: 3.55251\tvalid_1's l1: 3.38006\n",
      "[450]\ttraining's l1: 3.53353\tvalid_1's l1: 3.36953\n",
      "[500]\ttraining's l1: 3.51628\tvalid_1's l1: 3.36128\n",
      "[550]\ttraining's l1: 3.49991\tvalid_1's l1: 3.35378\n",
      "[600]\ttraining's l1: 3.48475\tvalid_1's l1: 3.34861\n",
      "[650]\ttraining's l1: 3.47014\tvalid_1's l1: 3.34471\n",
      "[700]\ttraining's l1: 3.45618\tvalid_1's l1: 3.34043\n",
      "[750]\ttraining's l1: 3.44293\tvalid_1's l1: 3.33743\n",
      "[800]\ttraining's l1: 3.42974\tvalid_1's l1: 3.33502\n",
      "[850]\ttraining's l1: 3.41718\tvalid_1's l1: 3.333\n",
      "[900]\ttraining's l1: 3.40562\tvalid_1's l1: 3.33126\n",
      "[950]\ttraining's l1: 3.39455\tvalid_1's l1: 3.33086\n",
      "[1000]\ttraining's l1: 3.38287\tvalid_1's l1: 3.33051\n",
      "[1050]\ttraining's l1: 3.37192\tvalid_1's l1: 3.33075\n",
      "[1100]\ttraining's l1: 3.36132\tvalid_1's l1: 3.33095\n",
      "[1150]\ttraining's l1: 3.35092\tvalid_1's l1: 3.33123\n",
      "[1200]\ttraining's l1: 3.34049\tvalid_1's l1: 3.33144\n",
      "Early stopping, best iteration is:\n",
      "[1024]\ttraining's l1: 3.3776\tvalid_1's l1: 3.33047\n",
      "0.012704768650504447\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's l1: 3.83206\tvalid_1's l1: 3.53754\n",
      "[100]\ttraining's l1: 3.75521\tvalid_1's l1: 3.47273\n",
      "[150]\ttraining's l1: 3.70066\tvalid_1's l1: 3.42966\n",
      "[200]\ttraining's l1: 3.65874\tvalid_1's l1: 3.39888\n",
      "[250]\ttraining's l1: 3.6284\tvalid_1's l1: 3.38268\n",
      "[300]\ttraining's l1: 3.60261\tvalid_1's l1: 3.37544\n",
      "[350]\ttraining's l1: 3.5787\tvalid_1's l1: 3.36695\n",
      "[400]\ttraining's l1: 3.55815\tvalid_1's l1: 3.35673\n",
      "[450]\ttraining's l1: 3.53976\tvalid_1's l1: 3.34989\n",
      "[500]\ttraining's l1: 3.52283\tvalid_1's l1: 3.34538\n",
      "[550]\ttraining's l1: 3.50656\tvalid_1's l1: 3.34021\n",
      "[600]\ttraining's l1: 3.49178\tvalid_1's l1: 3.33675\n",
      "[650]\ttraining's l1: 3.47737\tvalid_1's l1: 3.33371\n",
      "[700]\ttraining's l1: 3.46383\tvalid_1's l1: 3.33233\n",
      "[750]\ttraining's l1: 3.45041\tvalid_1's l1: 3.33075\n",
      "[800]\ttraining's l1: 3.43669\tvalid_1's l1: 3.32979\n",
      "[850]\ttraining's l1: 3.42318\tvalid_1's l1: 3.33012\n",
      "[900]\ttraining's l1: 3.41033\tvalid_1's l1: 3.33137\n",
      "[950]\ttraining's l1: 3.39822\tvalid_1's l1: 3.33473\n",
      "[1000]\ttraining's l1: 3.38656\tvalid_1's l1: 3.33632\n",
      "Early stopping, best iteration is:\n",
      "[823]\ttraining's l1: 3.43037\tvalid_1's l1: 3.32925\n",
      "0.012426998428385124\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's l1: 3.67585\tvalid_1's l1: 4.01225\n",
      "[100]\ttraining's l1: 3.58994\tvalid_1's l1: 4.00127\n",
      "[150]\ttraining's l1: 3.53252\tvalid_1's l1: 3.99402\n",
      "[200]\ttraining's l1: 3.48937\tvalid_1's l1: 3.99053\n",
      "[250]\ttraining's l1: 3.45734\tvalid_1's l1: 3.99377\n",
      "[300]\ttraining's l1: 3.42986\tvalid_1's l1: 3.99408\n",
      "[350]\ttraining's l1: 3.40646\tvalid_1's l1: 3.99495\n",
      "Early stopping, best iteration is:\n",
      "[184]\ttraining's l1: 3.50177\tvalid_1's l1: 3.98991\n",
      "0.014675268687130791\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's l1: 3.69932\tvalid_1's l1: 3.92626\n",
      "[100]\ttraining's l1: 3.61361\tvalid_1's l1: 3.90948\n",
      "[150]\ttraining's l1: 3.55216\tvalid_1's l1: 3.90099\n",
      "[200]\ttraining's l1: 3.50868\tvalid_1's l1: 3.89826\n",
      "[250]\ttraining's l1: 3.47471\tvalid_1's l1: 3.90128\n",
      "[300]\ttraining's l1: 3.44654\tvalid_1's l1: 3.90513\n",
      "[350]\ttraining's l1: 3.42227\tvalid_1's l1: 3.90952\n",
      "[400]\ttraining's l1: 3.40072\tvalid_1's l1: 3.9141\n",
      "Early stopping, best iteration is:\n",
      "[204]\ttraining's l1: 3.50561\tvalid_1's l1: 3.89818\n",
      "0.014478795016624727\n",
      "mean mse: 38.30272057622252\n",
      "oof mse: 38.30271841103062\n",
      "mean mae: 3.577216653321344\n",
      "oof mae: 3.5772063412471833\n",
      "mean cprs: 0.013450758220785154\n",
      "oof cprs: 0.013450737384485491\n"
     ]
    }
   ],
   "source": [
    "kf=KFold(n_splits = 5)\n",
    "resu1 = 0\n",
    "impor1 = 0\n",
    "resu2_cprs = 0\n",
    "resu3_mae=0\n",
    "##y_pred = 0\n",
    "stack_train = np.zeros([X_train.shape[0],])\n",
    "models = []\n",
    "for train_index, test_index in kf.split(X_train, y_train):\n",
    "    X_train2= X_train.iloc[train_index,:]\n",
    "    y_train2= y_train.iloc[train_index]\n",
    "    X_test2= X_train.iloc[test_index,:]\n",
    "    y_test2= y_train.iloc[test_index]\n",
    "#     clf = lgb.LGBMRegressor(n_estimators=10000, random_state=47,subsample=0.7,\n",
    "#                              colsample_bytree=0.7,learning_rate=0.005,importance_type = 'gain',\n",
    "#                      max_depth = -1, num_leaves = 100,min_child_samples=20,min_split_gain = 0.001,\n",
    "#                        bagging_freq=1,reg_alpha = 0,reg_lambda = 0,n_jobs = -1)\n",
    "    clf = lgb.LGBMRegressor(n_estimators=10000, random_state=47,learning_rate=0.005,importance_type = 'gain',\n",
    "                     n_jobs = -1,metric='mae')\n",
    "    clf.fit(X_train2,y_train2,eval_set = [(X_train2,y_train2),(X_test2,y_test2)],early_stopping_rounds=200,verbose=50)\n",
    "    models.append(clf)\n",
    "    temp_predict = clf.predict(X_test2)\n",
    "    stack_train[test_index] = temp_predict\n",
    "    ##y_pred += clf.predict(X_test)/5\n",
    "    mse = mean_squared_error(y_test2, temp_predict)\n",
    "    crps = CRPS_pingyi1(temp_predict,y_test2,4,cdf,dist_to_end_train.iloc[test_index])\n",
    "    mae = mean_absolute_error(y_test2, temp_predict)\n",
    "    print(crps)\n",
    "    \n",
    "    resu1 += mse/5\n",
    "    resu2_cprs += crps/5\n",
    "    resu3_mae += mae/5 \n",
    "    impor1 += clf.feature_importances_/5\n",
    "    gc.collect()\n",
    "print('mean mse:',resu1)\n",
    "print('oof mse:',mean_squared_error(y_train,stack_train))\n",
    "print('mean mae:',resu3_mae)\n",
    "print('oof mae:',mean_absolute_error(y_train,stack_train))\n",
    "print('mean cprs:',resu2_cprs)\n",
    "print('oof cprs:',CRPS_pingyi1(stack_train,y_train,4,cdf,dist_to_end_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mean cprs: 0.013492754797789282\n",
    "- oof cprs: 0.013492733928521948"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_test(test):\n",
    "    test.loc[test.VisitorTeamAbbr == \"ARI\",'VisitorTeamAbbr'] = \"ARZ\"\n",
    "    test.loc[test.HomeTeamAbbr == \"ARI\",'HomeTeamAbbr'] = \"ARZ\"\n",
    "\n",
    "    test.loc[test.VisitorTeamAbbr == \"BAL\",'VisitorTeamAbbr'] = \"BLT\"\n",
    "    test.loc[test.HomeTeamAbbr == \"BAL\",'HomeTeamAbbr'] = \"BLT\"\n",
    "\n",
    "    test.loc[test.VisitorTeamAbbr == \"CLE\",'VisitorTeamAbbr'] = \"CLV\"\n",
    "    test.loc[test.HomeTeamAbbr == \"CLE\",'HomeTeamAbbr'] = \"CLV\"\n",
    "\n",
    "    test.loc[test.VisitorTeamAbbr == \"HOU\",'VisitorTeamAbbr'] = \"HST\"\n",
    "    test.loc[test.HomeTeamAbbr == \"HOU\",'HomeTeamAbbr'] = \"HST\"\n",
    "    \n",
    "    test[\"OffenseFormation\"] = test[\"OffenseFormation\"].fillna(\"Unknown\") \n",
    "    \n",
    "    arr = [[int(s[0]) for s in t.split(\", \")] for t in test[\"DefensePersonnel\"]]\n",
    "    test[\"DefenseDL\"] = np.array([a[0] for a in arr])\n",
    "    test[\"DefenseLB\"] = np.array([a[1] for a in arr])\n",
    "    test[\"DefenseDB\"] = np.array([a[2] for a in arr])\n",
    "    test[\"DefenseOL\"] = np.array([a[3] if len(a) == 4 else 0 for a in arr])\n",
    "    \n",
    "    arr = [[s for s in t.replace(\" \", \"\").split(\",\")] for t in test[\"OffensePersonnel\"]]\n",
    "    RB_count = np.zeros(len(arr))\n",
    "    TE_count = np.zeros(len(arr))\n",
    "    WR_count = np.zeros(len(arr))\n",
    "    OL_count = np.zeros(len(arr))\n",
    "    DL_count = np.zeros(len(arr))\n",
    "    QB_count = np.zeros(len(arr))\n",
    "\n",
    "    for i in range(len(arr)):\n",
    "        for j in range(len(arr[i])):\n",
    "            if \"RB\" in arr[i][j]:\n",
    "                RB_count[i] = int(arr[i][j][0])\n",
    "            elif \"TE\" in arr[i][j]:\n",
    "                TE_count[i] = int(arr[i][j][0])\n",
    "            elif \"WR\" in arr[i][j]:\n",
    "                WR_count[i] = int(arr[i][j][0])\n",
    "            elif \"OL\" in arr[i][j]:\n",
    "                OL_count[i] = int(arr[i][j][0])\n",
    "            elif \"DL\" in arr[i][j]:\n",
    "                DL_count[i] = int(arr[i][j][0])\n",
    "            elif \"QB\" in arr[i][j]:\n",
    "                QB_count[i] = int(arr[i][j][0])\n",
    "    test[\"OffenseRB\"] = RB_count\n",
    "    test[\"OffenseTE\"] = TE_count\n",
    "    test[\"OffenseWR\"] = WR_count\n",
    "    test[\"OffenseOL\"] = OL_count\n",
    "    test[\"OffenseDL\"] = DL_count\n",
    "    test[\"OffenseQB\"] = QB_count\n",
    "    \n",
    "    test['DefendersInTheBox_vs_Distance'] = test['DefendersInTheBox'] / test['Distance']\n",
    "    \n",
    "    test[\"Stadium\"] = test[\"Stadium\"].map(lambda x: \"Broncos Stadium at Mile High\" if x==\"Broncos Stadium At Mile High\" \n",
    "                                             else (\"CenturyLink Field\" if x == \"CenturyField\" or x == x==\"CenturyLink\"\n",
    "                                             else (\"Everbank Field\" if x == \"EverBank Field\"\n",
    "                                             else (\"FirstEnergy Stadium\" if x ==\"First Energy Stadium\" or x==\"FirstEnergy\" or x == \"FirstEnergyStadium\"\n",
    "                                             else (\"Lambeau Field\" if x == \"Lambeau field\"\n",
    "                                             else (\"Los Angeles Memorial Coliseum\" if x == \"Los Angeles Memorial Coliesum\"\n",
    "                                             else (\"M&T Bank Stadium\" if x == \"M & T Bank Stadium\" or x == \"M&T Stadium\"\n",
    "                                             else (\"Mercedes-Benz Superdome\" if x == \"Mercedes-Benz Dome\"\n",
    "                                             else (\"MetLife Stadium\" if x == \"MetLife\" or x == \"Metlife Stadium\"\n",
    "                                             else (\"NRG Stadium\" if x == \"NRG\"\n",
    "                                             else (\"Oakland-Alameda County Coliseum\" if x == \"Oakland Alameda-County Coliseum\"\n",
    "                                             else (\"Paul Brown Stadium\" if x == \"Paul Brown Stdium\"\n",
    "                                             else (\"Twickenham Stadium\" if x == \"Twickenham\" else x)))))))))))))\n",
    "    \n",
    "    test[\"Margin\"] = (test[\"HomeScoreBeforePlay\"] - \n",
    "                      test[\"VisitorScoreBeforePlay\"]) + 2 * (1 - (test[\"PossessionTeam\"] == \n",
    "                                                                  test[\"HomeTeamAbbr\"]).astype(int)) * (test[\"VisitorScoreBeforePlay\"] \n",
    "                                                                                                                - test[\"HomeScoreBeforePlay\"])\n",
    "    \n",
    "    test[\"Location\"] = test[\"Location\"].map(lambda x: \"Arlington, TX\" if x == \"Arlington, Texas\"\n",
    "                        else (\"Baltimore, MD\" if x == \"Baltimore, Maryland\" or x == \"Baltimore, Md.\"\n",
    "                        else (\"Charlotte, NC\" if x == \"Charlotte, North Carolina\"\n",
    "                        else (\"Chicago, IL\" if x == \"Chicago. IL\"\n",
    "                        else (\"Cincinnati, OH\" if x == \"Cincinnati, Ohio\"\n",
    "                        else (\"Cleveland, OH\" if x == \"Cleveland\" or x == \"Cleveland Ohio\" or x == \"Cleveland, Ohio\" or x == \"Cleveland,Ohio\"\n",
    "                        else (\"Detroit, MI\" if x == \"Detroit\"\n",
    "                        else (\"East Rutherford, NJ\" if x == \"E. Rutherford, NJ\" or x == \"East Rutherford, N.J.\"\n",
    "                        else (\"Foxborough, MA\" if x == \"Foxborough, Ma\"\n",
    "                        else (\"Houston, TX\" if x == \"Houston, Texas\"\n",
    "                        else (\"Jacksonville, FL\" if x == \"Jacksonville Florida\" or x == \"Jacksonville, Fl\" or x == \"Jacksonville, Florida\"\n",
    "                        else (\"London\" if x == \"London, England\"\n",
    "                        else (\"Los Angeles, CA\" if x == \"Los Angeles, Calif.\"\n",
    "                        else (\"Miami Gardens, FLA\" if x == \"Miami Gardens, Fla.\"\n",
    "                        else (\"New Orleans, LA\" if x == \"New Orleans\" or x == \"New Orleans, La.\"\n",
    "                        else (\"Orchard Park, NY\" if x == \"Orchard Park NY\"\n",
    "                        else (\"Philadelphia, PA\" if x == \"Philadelphia, Pa.\"\n",
    "                        else (\"Pittsburgh, PA\" if x == \"Pittsburgh\"\n",
    "                        else (\"Seattle, WA\" if x == \"Seattle\" else x)))))))))))))))))))\n",
    "    \n",
    "    test[\"Turf\"] = test[\"Turf\"].map(lambda x: \"Artificial\" if x == \"Artifical\"\n",
    "                                       else (\"Field Turf\" if x == \"FieldTurf\" or x == \"Field turf\"\n",
    "                                       else (\"FieldTurf 360\" if x == \"FieldTurf360\"\n",
    "                                       else (\"Natural Grass\" if x == \"natural grass\" or x == \"Naturall Grass\" or x == \"Natural grass\" or x == \"Natural\"\n",
    "                                       else (\"Grass\" if x == \"grass\"\n",
    "                                       else (\"UBU Speed Series-S5-M\" if x == \"UBU Sports Speed S5-M\" else x))))))\n",
    "    \n",
    "    test['StadiumType'] = test['StadiumType'].apply(lambda x: \"outdoor\" if x in outdoor \n",
    "                                                        else (\"indoor closed\" if x in indoor_closed\n",
    "                                                        else (\"indoor open\" if x in indoor_open\n",
    "                                                        else (\"dome_closed\" if x in dome_closed\n",
    "                                                        else (\"dome_open\" if x in dome_open else \"unknown\")))))\n",
    "    \n",
    "    test['GameWeather'] = test['GameWeather'].apply(lambda x: \"rain\" if x in rain \n",
    "                                                        else (\"overcast\" if x in overcast\n",
    "                                                        else (\"clear\" if x in clear\n",
    "                                                        else (\"snow\" if x in snow\n",
    "                                                        else (\"indoor\" if x in none else \"unknown\")))))\n",
    "    \n",
    "    test['WindSpeed'] = test['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n",
    "    test['WindSpeed'] = test['WindSpeed'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n",
    "    test['WindSpeed'] = test['WindSpeed'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n",
    "    test['WindSpeed'] = test['WindSpeed'].apply(str_to_float)\n",
    "    \n",
    "    test['WindDirection'] = test['WindDirection'].apply(lambda x: \"north\" if x == \"N\" or x == \"FROM S\"\n",
    "                                                   else (\"south\" if x == 'S' or x== 'FROM N'\n",
    "                                                   else (\"west\" if x == 'W' or x == 'FROM E'\n",
    "                                                   else (\"east\" if x == 'E' or x == 'FROM W'\n",
    "                                                   else (\"north east\" if x == 'FROM SW' or x == 'FROM SSW' or x == 'FROM WSW'\n",
    "                                                   else (\"north west\" if x == 'FROM SE' or x == 'FROM SSE' or x == 'FROM ESE'\n",
    "                                                   else (\"south east\" if x == 'FROM NW' or x == 'FROM NNW' or x == 'FROM WNW'\n",
    "                                                   else (\"south west\" if x == 'FROM NE' or x == 'FROM NNE' or x == 'FROM ENE'\n",
    "                                                   else (\"north west\" if x == 'NW' or x == 'NORTHWEST'\n",
    "                                                   else (\"north east\" if x == 'NE' or x == 'NORTH EAST'\n",
    "                                                   else (\"south west\" if x == 'SW' or x == 'SOUTHWEST'\n",
    "                                                   else (\"south east\" if x == 'SE' or x == 'SOUTHEAST' else \"unknown\"))))))))))))\n",
    "    \n",
    "    test['ToLeft'] = test.PlayDirection == \"left\"\n",
    "    test['Dir_rad'] = np.mod(90 - test.Dir, 360) * math.pi/180.0\n",
    "    test['TeamOnOffense'] = \"home\"\n",
    "    test.loc[test.PossessionTeam != test.HomeTeamAbbr, 'TeamOnOffense'] = \"away\"\n",
    "    test['IsOnOffense'] = test.Team == test.TeamOnOffense # Is player on offense?\n",
    "    test['YardLine_std'] = 100 - test.YardLine\n",
    "    test.loc[test.FieldPosition.fillna('') == test.PossessionTeam,  \n",
    "          'YardLine_std'\n",
    "         ] = test.loc[test.FieldPosition.fillna('') == test.PossessionTeam,  \n",
    "          'YardLine']\n",
    "    test['X_std'] = test.X\n",
    "    test.loc[test.ToLeft, 'X_std'] = 120 - test.loc[test.ToLeft, 'X'] \n",
    "    test['Y_std'] = test.Y\n",
    "    test.loc[test.ToLeft, 'Y_std'] = 160/3 - test.loc[test.ToLeft, 'Y'] \n",
    "    #train['Orientation_std'] = -90 + train.Orientation\n",
    "    #train.loc[train.ToLeft, 'Orientation_std'] = np.mod(180 + train.loc[train.ToLeft, 'Orientation_std'], 360)\n",
    "    test['Dir_std'] = test.Dir_rad\n",
    "    test.loc[test.ToLeft, 'Dir_std'] = np.mod(np.pi + test.loc[test.ToLeft, 'Dir_rad'], 2*np.pi)\n",
    "    \n",
    "    test['is_run'] = test.NflId == test.NflIdRusher\n",
    "    test_single = test[test.is_run==True]\n",
    "    test_single['time_quarter'] = test_single.GameClock.map(lambda x:transform_time_quarter(x))\n",
    "    test_single['time_end'] = test_single.apply(lambda x:transform_time_all(x.loc['GameClock'],x.loc['Quarter']),axis=1)\n",
    "    test_single['TimeHandoff'] = test_single['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    test_single['TimeSnap'] = test_single['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    test_single['handoff_snap_diff'] = (test_single['TimeHandoff'] - test_single['TimeSnap']).map(lambda x:x.seconds)\n",
    "    test_single['date_game'] = test_single.GameId.map(lambda x:pd.to_datetime(str(x)[:8]))\n",
    "    test_single['runner_age'] = (test_single.date_game.map(pd.to_datetime) - test_single.PlayerBirthDate.map(pd.to_datetime)).map(lambda x:x.days)/365\n",
    "    test_single['runner_height'] = test_single.PlayerHeight.map(transform_height)\n",
    "    return test_single.drop(remove_features,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:150: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:151: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:152: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:153: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:154: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:155: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:156: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:157: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission file has been saved!  Once you `Commit` your Notebook and it finishes running, you can submit the file to the competition from the Notebook Viewer `Output` tab.\n"
     ]
    }
   ],
   "source": [
    "for (test_df, sample_prediction_df) in env.iter_test():\n",
    "    test_df['own_field'] = (test_df['FieldPosition'] == test_df['PossessionTeam']).astype(int)\n",
    "    dist_to_end_test = test_df.apply(lambda x:(100 - x.loc['YardLine']) if x.loc['own_field']==1 else x.loc['YardLine'],axis=1)\n",
    "    X_test = transform_test(test_df)\n",
    "    X_test.fillna(-999,inplace=True)\n",
    "    for f in X_test.columns:\n",
    "        if X_test[f].dtype=='object':\n",
    "            X_test[f] = X_test[f].map(lambda x:x if x in set(X_train[f]) else -999)\n",
    "    for f in X_test.columns:\n",
    "        if X_test[f].dtype=='object': \n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(X_train[f])+[-999])\n",
    "            X_test[f] = lbl.transform(list(X_test[f])) \n",
    "    pred_value = 0\n",
    "    for model in models:\n",
    "        pred_value += model.predict(X_test)[0]/5\n",
    "    pred_data = list(get_score(pred_value,cdf,4,dist_to_end_test.values[0]))\n",
    "    pred_data = np.array(pred_data).reshape(1,199)\n",
    "    pred_target = pd.DataFrame(index = sample_prediction_df.index, \\\n",
    "                               columns = sample_prediction_df.columns, \\\n",
    "                               #data = np.array(pred_data))\n",
    "                               data = pred_data)\n",
    "    #print(pred_target)\n",
    "    env.predict(pred_target)\n",
    "env.write_submission_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kf=KFold(n_splits = 5)\n",
    "# resu1 = 0\n",
    "# impor1 = 0\n",
    "# ##y_pred = 0\n",
    "# stack_train = np.zeros([X_train.shape[0],])\n",
    "# for train_index, test_index in kf.split(X_train, y_train):\n",
    "#     X_train2= X_train.iloc[train_index,:]\n",
    "#     y_train2= y_train.iloc[train_index]\n",
    "#     X_test2= X_train.iloc[test_index,:]\n",
    "#     y_test2= y_train.iloc[test_index]\n",
    "#     clf = lgb.LGBMRegressor(n_estimators=10000, random_state=47,subsample=0.7,\n",
    "#                              colsample_bytree=0.7,learning_rate=0.03,importance_type = 'gain',\n",
    "#                      max_depth = -1, num_leaves = 256,min_child_samples=20,min_split_gain = 0.001,\n",
    "#                        bagging_freq=1,reg_alpha = 0,reg_lambda = 0,n_jobs = -1)\n",
    "#     clf.fit(X_train2,y_train2,eval_set = [(X_train2,y_train2),(X_test2,y_test2)],early_stopping_rounds=100,verbose=50)\n",
    "#     temp_predict = clf.predict(X_test2)\n",
    "#     stack_train[test_index] = temp_predict\n",
    "#     ##y_pred += clf.predict(X_test)/5\n",
    "#     mse = mean_squared_error(y_test2, temp_predict)\n",
    "#     print(mse)\n",
    "#     resu1 += mse/5\n",
    "#     impor1 += clf.feature_importances_/5\n",
    "#     gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
