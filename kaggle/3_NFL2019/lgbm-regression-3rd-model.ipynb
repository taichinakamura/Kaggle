{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "### Explanation\n",
    "\n",
    "This kernel used LGBM and treated it as a regression problem. I only did a little feature engineering so far.(just transform some date format features into numeric)\n",
    "\n",
    "The ideas is that:\n",
    "- if we treated it as a regression problem, it's better to do some smooth operation. See the [kernel](https://www.kaggle.com/hukuda222/nfl-simple-evluation-trick).\n",
    "- I used the distribution in [kernel](https://www.kaggle.com/jpmiller/simple-distribution) as my smooth distribution.\n",
    "- We can see the simple distribution in [kernel](https://www.kaggle.com/jpmiller/simple-distribution) get the 1436 LB. If we use LGBM to do regression prediction and shift the distribution based on the yards we predicte, we should get a better LB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold,TimeSeriesSplit,KFold,GroupKFold\n",
    "from sklearn.metrics import roc_auc_score,mean_squared_error,mean_absolute_error\n",
    "import sqlite3\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import pearsonr\n",
    "import gc\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from bayes_opt import BayesianOptimization\n",
    "from kaggle.competitions import nflrush\n",
    "import math\n",
    "import tqdm\n",
    "from scipy.spatial import Delaunay, delaunay_plot_2d, Voronoi, voronoi_plot_2d, ConvexHull\n",
    "env = nflrush.make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/nfl-big-data-bowl-2020/train.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train.VisitorTeamAbbr == \"ARI\",'VisitorTeamAbbr'] = \"ARZ\"\n",
    "train.loc[train.HomeTeamAbbr == \"ARI\",'HomeTeamAbbr'] = \"ARZ\"\n",
    "\n",
    "train.loc[train.VisitorTeamAbbr == \"BAL\",'VisitorTeamAbbr'] = \"BLT\"\n",
    "train.loc[train.HomeTeamAbbr == \"BAL\",'HomeTeamAbbr'] = \"BLT\"\n",
    "\n",
    "train.loc[train.VisitorTeamAbbr == \"CLE\",'VisitorTeamAbbr'] = \"CLV\"\n",
    "train.loc[train.HomeTeamAbbr == \"CLE\",'HomeTeamAbbr'] = \"CLV\"\n",
    "\n",
    "train.loc[train.VisitorTeamAbbr == \"HOU\",'VisitorTeamAbbr'] = \"HST\"\n",
    "train.loc[train.HomeTeamAbbr == \"HOU\",'HomeTeamAbbr'] = \"HST\"\n",
    "\n",
    "train['is_run'] = train.NflId == train.NflIdRusher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess finished\n"
     ]
    }
   ],
   "source": [
    "# my original idea for feature engineering---------------------------------------------------\n",
    "#def strtoseconds(txt):\n",
    "#    txt = txt.split(':')\n",
    "#    ans = int(txt[0])*60 + int(txt[1]) + int(txt[2])/60\n",
    "#    return ans\n",
    "\n",
    "#def str_to_float(txt):\n",
    "#    try:\n",
    "#        return float(txt)\n",
    "#    except:\n",
    "#        return -1\n",
    "\n",
    "# age #\n",
    "FMT_birth = '%m/%d/%Y'\n",
    "FMT_gamedate = '%Y-%m-%d'\n",
    "train[\"Age\"] = train[\"TimeSnap\"].apply(lambda t: t.split(\"T\")[0])\n",
    "train[\"Age\"] = train[\"Age\"].apply(lambda t: datetime.strptime(t, FMT_gamedate))\n",
    "tmp_birth = train[\"PlayerBirthDate\"].apply(lambda t: datetime.strptime(t, FMT_birth))\n",
    "train[\"Age\"] = train[\"Age\"] - tmp_birth\n",
    "train[\"Age\"] = train[\"Age\"].apply(lambda t: t.days//365)\n",
    "\n",
    "# momentum \n",
    "train[\"Momentum\"] = train[\"S\"] * train[\"PlayerWeight\"]\n",
    "\n",
    "# on offense\n",
    "def func(row):\n",
    "    if row[\"PossessionTeam\"] == row[\"HomeTeamAbbr\"]:\n",
    "        return \"home\"\n",
    "    else:\n",
    "        return \"away\"\n",
    "train[\"OnOffense\"] = train[[\"PossessionTeam\", \"HomeTeamAbbr\"]].apply(func, axis=1)\n",
    "train[\"OnOffense\"] = train[\"OnOffense\"] == train[\"Team\"]\n",
    "\n",
    "#train[\"FieldvsPosession\"] = train[\"FieldPosition\"] == train[\"PossessionTeam\"]\n",
    "#train[\"Distance10\"] = train[\"Distance\"].apply(lambda x: 1 if x > 10 else 0)\n",
    "#train[\"DownQuarter\"] = train[[\"Down\", \"Quarter\"]].apply(lambda x: \"D{}_Q{}\".format(x[0], x[1]), axis=1)\n",
    "\n",
    "# exercise energy\n",
    "#train[\"ExerciseEnegy\"] = 0.5 * train[\"PlayerWeight\"] * (train[\"S\"]**2)\n",
    "\n",
    "rusher_x = np.array(train.groupby([\"PlayId\", \"is_run\"])[\"X\"].agg(np.mean)[1::2])\n",
    "rusher_x = np.repeat(rusher_x, 22) # repeat each elemnt 22 times train[\"RusherX\"]\n",
    "rusher_y = np.array(train.groupby([\"PlayId\", \"is_run\"])[\"Y\"].agg(np.mean)[1::2])\n",
    "rusher_y = np.repeat(rusher_y, 22) # train[\"RusherY\"]\n",
    "train[\"DisToRusher\"] = np.sqrt((train[\"X\"] - rusher_x) ** 2 + (train[\"Y\"] - rusher_y) ** 2)\n",
    "train[\"TackleTimeToRusher\"] = train[\"DisToRusher\"] / train[\"S\"] \n",
    "\n",
    "rusher_s = np.array(train.groupby([\"PlayId\", \"is_run\"]).agg(np.mean)[\"S\"][1::2])\n",
    "rusher_s = np.repeat(rusher_s, 22)\n",
    "train[\"RatioSToRusher\"] = train[\"S\"] / rusher_s\n",
    "\n",
    "# distance without no restriction if the difference between distance is large, the player is restricted by defenders\n",
    "#train[\"MoveDist\"] = train[\"S\"] * train[\"TimeFromSnapDiff\"] + 0.5 * train[\"A\"] * (train[\"TimeFromSnapDiff\"] **2)\n",
    "\n",
    "# ratio of real movement distance to theoretical movement distance\n",
    "#train[\"RealToTheoryDis\"] = train[\"Dis\"] / train[\"MoveDist\"]\n",
    "\n",
    "print(\"Preprocess finished\")\n",
    "# my original idea end ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_single = train[train.is_run==True].copy()\n",
    "\n",
    "def transform_time_quarter(str1):\n",
    "    return int(str1[:2])*60 + int(str1[3:5])\n",
    "def transform_time_all(str1,quarter):\n",
    "    if quarter<=4:\n",
    "        return 15*60 - (int(str1[:2])*60 + int(str1[3:5])) + (quarter-1)*15*60\n",
    "    if quarter ==5:\n",
    "        return 10*60 - (int(str1[:2])*60 + int(str1[3:5])) + (quarter-1)*15*60\n",
    "train_single['time_quarter'] = train_single.GameClock.map(lambda x:transform_time_quarter(x))\n",
    "train_single['time_end'] = train_single.apply(lambda x:transform_time_all(x.loc['GameClock'],x.loc['Quarter']),axis=1)\n",
    "\n",
    "train_single['TimeHandoff'] = train_single['TimeHandoff'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "train_single['TimeSnap'] = train_single['TimeSnap'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "train_single['handoff_snap_diff'] = (train_single['TimeHandoff'] - train_single['TimeSnap']).map(lambda x:x.seconds)\n",
    "# my original idea -----\n",
    "#train_single['WindSpeed'] = train_single['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n",
    "#train_single['WindSpeed'] = train_single['WindSpeed'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n",
    "#train_single['WindSpeed'] = train_single['WindSpeed'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n",
    "#train_single['WindSpeed'] = train_single['WindSpeed'].apply(str_to_float)\n",
    "\n",
    "#train_single['WindDirection'] = train_single['WindDirection'].apply(lambda x: \"north\" if x == \"N\" or x == \"FROM S\"\n",
    "#                                                   else (\"south\" if x == 'S' or x== 'FROM N'\n",
    "#                                                   else (\"west\" if x == 'W' or x == 'FROM E'\n",
    "#                                                   else (\"east\" if x == 'E' or x == 'FROM W'\n",
    "#                                                   else (\"north east\" if x == 'FROM SW' or x == 'FROM SSW' or x == 'FROM WSW'\n",
    "#                                                   else (\"north west\" if x == 'FROM SE' or x == 'FROM SSE' or x == 'FROM ESE'\n",
    "#                                                   else (\"south east\" if x == 'FROM NW' or x == 'FROM NNW' or x == 'FROM WNW'\n",
    "#                                                   else (\"south west\" if x == 'FROM NE' or x == 'FROM NNE' or x == 'FROM ENE'\n",
    "#                                                   else (\"north west\" if x == 'NW' or x == 'NORTHWEST'\n",
    "#                                                   else (\"north east\" if x == 'NE' or x == 'NORTH EAST'\n",
    "#                                                   else (\"south west\" if x == 'SW' or x == 'SOUTHWEST'\n",
    "#                                                   else (\"south east\" if x == 'SE' or x == 'SOUTHEAST' else \"unknown\"))))))))))))\n",
    "\n",
    "#rain = ['Rainy', 'Rain Chance 40%', 'Showers', 'Cloudy with periods of rain, thunder possible. Winds shifting to WNW, 10-20 mph.',\n",
    "#          'Scattered Showers', 'Cloudy, Rain', 'Rain shower', 'Light Rain', 'Rain']\n",
    "#overcast = ['Cloudy, light snow accumulating 1-3\"', 'Party Cloudy', 'Cloudy, chance of rain','Coudy', 'Cloudy, 50% change of rain', \n",
    "#            'Rain likely, temps in low 40s.', 'Cloudy and cold', 'Cloudy, fog started developing in 2nd quarter', 'Partly Clouidy', \n",
    "#            '30% Chance of Rain', 'Mostly Coudy', 'Cloudy and Cool', 'cloudy', 'Partly cloudy', 'Overcast', 'Hazy', 'Mostly cloudy', \n",
    "#            'Mostly Cloudy', 'Partly Cloudy', 'Cloudy']\n",
    "#clear = ['Partly clear', 'Sunny and clear', 'Sun & clouds', 'Clear and Sunny', 'Sunny and cold', 'Sunny Skies', 'Clear and Cool', 'Clear and sunny',\n",
    "#        'Sunny, highs to upper 80s', 'Mostly Sunny Skies', 'Cold', 'Clear and warm', 'Sunny and warm', 'Clear and cold', 'Mostly sunny',\n",
    "#        'T: 51; H: 55; W: NW 10 mph', 'Clear Skies', 'Clear skies', 'Partly sunny', 'Fair', 'Partly Sunny', 'Mostly Sunny', 'Clear', 'Sunny']\n",
    "#snow = ['Heavy lake effect snow', 'Snow']\n",
    "#none = ['N/A Indoor', 'Indoors', 'Indoor', 'N/A (Indoors)', 'Controlled Climate']\n",
    "\n",
    "#train_single['GameWeather'] = train_single['GameWeather'].apply(lambda x: \"rain\" if x in rain \n",
    "#                                                        else (\"overcast\" if x in overcast\n",
    "#                                                        else (\"clear\" if x in clear\n",
    "#                                                        else (\"snow\" if x in snow\n",
    "#                                                        else (\"indoor\" if x in none else \"unknown\")))))\n",
    "\n",
    "#outdoor =['Outdoor', 'Outdoors', 'Cloudy', 'Heinz Field', 'Outdor', 'Ourdoor', 'Outside', 'Outddors', 'Outdoor Retr Roof-Open', 'Oudoor', 'Bowl']\n",
    "#indoor_closed = ['Indoors', 'Indoor', 'Indoor, Roof Closed', 'Indoor, Roof Closed', \n",
    "#                 'Retractable Roof', 'Retr. Roof-Closed', 'Retr. Roof - Closed', 'Retr. Roof Closed']\n",
    "#indoor_open = ['Indoor, Open Roof', 'Open', 'Retr. Roof-Open', 'Retr. Roof - Open']\n",
    "#dome_closed = ['Dome', 'Domed, closed', 'Closed Dome', 'Domed', 'Dome, closed']\n",
    "#dome_open = ['Domed, Open', 'Domed, open']\n",
    "\n",
    "#train_single['StadiumType'] = train_single['StadiumType'].apply(lambda x: \"outdoor\" if x in outdoor \n",
    "#                                                        else (\"indoor closed\" if x in indoor_closed\n",
    "#                                                        else (\"indoor open\" if x in indoor_open\n",
    "#                                                        else (\"dome_closed\" if x in dome_closed\n",
    "#                                                        else (\"dome_open\" if x in dome_open else \"unknown\")))))\n",
    "\n",
    "train_single[\"Stadium\"] = train_single[\"Stadium\"].map(lambda x: \"Broncos Stadium at Mile High\" if x==\"Broncos Stadium At Mile High\" \n",
    "                                             else (\"CenturyLink Field\" if x == \"CenturyField\" or x == x==\"CenturyLink\"\n",
    "                                             else (\"Everbank Field\" if x == \"EverBank Field\"\n",
    "                                             else (\"FirstEnergy Stadium\" if x ==\"First Energy Stadium\" or x==\"FirstEnergy\" or x == \"FirstEnergyStadium\"\n",
    "                                             else (\"Lambeau Field\" if x == \"Lambeau field\"\n",
    "                                             else (\"Los Angeles Memorial Coliseum\" if x == \"Los Angeles Memorial Coliesum\"\n",
    "                                             else (\"M&T Bank Stadium\" if x == \"M & T Bank Stadium\" or x == \"M&T Stadium\"\n",
    "                                             else (\"Mercedes-Benz Superdome\" if x == \"Mercedes-Benz Dome\"\n",
    "                                             else (\"MetLife Stadium\" if x == \"MetLife\" or x == \"Metlife Stadium\"\n",
    "                                             else (\"NRG Stadium\" if x == \"NRG\"\n",
    "                                             else (\"Oakland-Alameda County Coliseum\" if x == \"Oakland Alameda-County Coliseum\"\n",
    "                                             else (\"Paul Brown Stadium\" if x == \"Paul Brown Stdium\"\n",
    "                                             else (\"Twickenham Stadium\" if x == \"Twickenham\" else x)))))))))))))\n",
    "\n",
    "train_single[\"Location\"] = train_single[\"Location\"].map(lambda x: \"Arlington, TX\" if x == \"Arlington, Texas\"\n",
    "                        else (\"Baltimore, MD\" if x == \"Baltimore, Maryland\" or x == \"Baltimore, Md.\"\n",
    "                        else (\"Charlotte, NC\" if x == \"Charlotte, North Carolina\"\n",
    "                        else (\"Chicago, IL\" if x == \"Chicago. IL\"\n",
    "                        else (\"Cincinnati, OH\" if x == \"Cincinnati, Ohio\"\n",
    "                        else (\"Cleveland, OH\" if x == \"Cleveland\" or x == \"Cleveland Ohio\" or x == \"Cleveland, Ohio\" or x == \"Cleveland,Ohio\"\n",
    "                        else (\"Detroit, MI\" if x == \"Detroit\"\n",
    "                        else (\"East Rutherford, NJ\" if x == \"E. Rutherford, NJ\" or x == \"East Rutherford, N.J.\"\n",
    "                        else (\"Foxborough, MA\" if x == \"Foxborough, Ma\"\n",
    "                        else (\"Houston, TX\" if x == \"Houston, Texas\"\n",
    "                        else (\"Jacksonville, FL\" if x == \"Jacksonville Florida\" or x == \"Jacksonville, Fl\" or x == \"Jacksonville, Florida\"\n",
    "                        else (\"London\" if x == \"London, England\"\n",
    "                        else (\"Los Angeles, CA\" if x == \"Los Angeles, Calif.\"\n",
    "                        else (\"Miami Gardens, FLA\" if x == \"Miami Gardens, Fla.\"\n",
    "                        else (\"New Orleans, LA\" if x == \"New Orleans\" or x == \"New Orleans, La.\"\n",
    "                        else (\"Orchard Park, NY\" if x == \"Orchard Park NY\"\n",
    "                        else (\"Philadelphia, PA\" if x == \"Philadelphia, Pa.\"\n",
    "                        else (\"Pittsburgh, PA\" if x == \"Pittsburgh\"\n",
    "                        else (\"Seattle, WA\" if x == \"Seattle\" else x)))))))))))))))))))\n",
    "\n",
    "train_single[\"Turf\"] = train_single[\"Turf\"].map(lambda x: \"Artificial\" if x == \"Artifical\"\n",
    "                                       else (\"Field Turf\" if x == \"FieldTurf\" or x == \"Field turf\"\n",
    "                                       else (\"FieldTurf 360\" if x == \"FieldTurf360\"\n",
    "                                       else (\"Natural Grass\" if x == \"natural grass\" or x == \"Naturall Grass\" or x == \"Natural grass\" or x == \"Natural\"\n",
    "                                       else (\"Grass\" if x == \"grass\"\n",
    "                                       else (\"UBU Speed Series-S5-M\" if x == \"UBU Sports Speed S5-M\" else x))))))\n",
    "\n",
    "train_single[\"OffenseFormation\"] = train_single[\"OffenseFormation\"].fillna(\"Unknown\") \n",
    "train_single['DefendersInTheBox_vs_Distance'] = train_single['DefendersInTheBox'] / train_single['Distance']\n",
    "\n",
    "# defense personnel -----\n",
    "#arr = [[int(s[0]) for s in t.split(\", \")] for t in train_single[\"DefensePersonnel\"]]\n",
    "#train_single[\"DefenseDL\"] = np.array([a[0] for a in arr])\n",
    "#train_single[\"DefenseLB\"] = np.array([a[1] for a in arr])\n",
    "#train_single[\"DefenseDB\"] = np.array([a[2] for a in arr])\n",
    "#train_single[\"DefenseOL\"] = np.array([a[3] if len(a) == 4 else 0 for a in arr])\n",
    "\n",
    "# offense personnel -----\n",
    "#train_single[\"OffenseRB\"] = train_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "#                        int(x.replace(\",\", \"\").split(\" RB\")[0][-1]) if \"RB\" in x else 0)\n",
    "#train_single[\"OffenseTE\"] = train_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "#                        int(x.replace(\",\", \"\").split(\" TE\")[0][-1]) if \"TE\" in x else 0)\n",
    "#train_single[\"OffenseWR\"] = train_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "#                        int(x.replace(\",\", \"\").split(\" WR\")[0][-1]) if \"WR\" in x else 0)\n",
    "#train_single[\"OffenseOL\"] = train_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "#                        int(x.replace(\",\", \"\").split(\" OL\")[0][-1]) if \"OL\" in x else 0)\n",
    "#train_single[\"OffenseDL\"] = train_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "#                        int(x.replace(\",\", \"\").split(\" DL\")[0][-1]) if \"DL\" in x else 0)\n",
    "#train_single[\"OffenseQB\"] = train_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "#                        int(x.replace(\",\", \"\").split(\" QB\")[0][-1]) if \"QB\" in x else 0)\n",
    "\n",
    "# necessary yard per remaining down \n",
    "train_single[\"NecDisPerDown\"] = train_single[\"Distance\"] / (5 - train_single[\"Down\"])\n",
    "\n",
    "train_single[\"Margin\"] = (train_single[\"HomeScoreBeforePlay\"] - \n",
    "                      train_single[\"VisitorScoreBeforePlay\"]) + 2 * (1 - (train_single[\"PossessionTeam\"] == \n",
    "                                                                      train_single[\"HomeTeamAbbr\"]).astype(int)) * (train_single[\"VisitorScoreBeforePlay\"] \n",
    "                                                                                                                - train_single[\"HomeScoreBeforePlay\"])\n",
    "# my original idea ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_features = ['DisplayName','GameClock','TimeHandoff','TimeSnap']#'GameId','PlayId',, 'OffensePersonnel', 'DefensePersonnel', 'X', 'Y', 'Dir', \"YardLine\"]\n",
    "train_single['date_game'] = train_single.GameId.map(lambda x:pd.to_datetime(str(x)[:8]))\n",
    "train_single['runner_age'] = (train_single.date_game.map(pd.to_datetime) - train_single.PlayerBirthDate.map(pd.to_datetime)).map(lambda x:x.days)/365\n",
    "remove_features.append('HomeTeamAbbr')\n",
    "remove_features.append('VisitorTeamAbbr')\n",
    "remove_features.append('PlayerBirthDate')\n",
    "remove_features.append('is_run')\n",
    "def transform_height(te):\n",
    "    return (int(te.split('-')[0])*12 + int(te.split('-')[1]))*2.54/100\n",
    "train_single['runner_height'] = train_single.PlayerHeight.map(transform_height)\n",
    "remove_features.append('PossessionTeam')\n",
    "remove_features.append('FieldPosition')\n",
    "remove_features.append('PlayerHeight')\n",
    "remove_features.append('NflIdRusher')\n",
    "remove_features.append('date_game')\n",
    "train_single['own_field'] = (train_single['FieldPosition'] == train_single['PossessionTeam']).astype(int)\n",
    "dist_to_end_train = train_single.apply(lambda x:(100 - x.loc['YardLine']) if x.loc['own_field']==1 else x.loc['YardLine'],axis=1)\n",
    "remove_features.append('own_field')\n",
    "train_single.drop(remove_features,axis=1,inplace=True)\n",
    "train_single.fillna(-999,inplace=True)\n",
    "train_single.sort_values([\"GameId\", \"PlayId\"], inplace=True)\n",
    "remove_features.append('GameId')\n",
    "remove_features.append('PlayId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_single.Yards\n",
    "X_train = train_single.drop(['Yards'],axis=1)\n",
    "for f in X_train.columns:\n",
    "    if X_train[f].dtype=='object': \n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(X_train[f])+[-999])\n",
    "        X_train[f] = lbl.transform(list(X_train[f]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional feature engineering -----------------------------------------------------------\n",
    "def voronoi_volumes(points, selected_index):\n",
    "    v = Voronoi(points)\n",
    "    vol = np.zeros(v.npoints)\n",
    "    \n",
    "    for i, reg_num in enumerate(v.point_region):\n",
    "        indices = v.regions[reg_num]\n",
    "        if -1 in indices: # some regions can be opened\n",
    "            vol[i] = -999 ## insert missing value when the area is open\n",
    "        else:\n",
    "            vol[i] = ConvexHull(v.vertices[indices]).volume\n",
    "        \n",
    "        if reg_num == v.point_region[selected_index]: # in the case of rusher or 1st defender etc...\n",
    "            index = i\n",
    "            rusher_reg_num = reg_num         \n",
    "        \n",
    "    return vol[index]\n",
    "\n",
    "tmp = train.groupby([\"PlayId\", \"OnOffense\"]).agg(np.mean)[[\"S\", \"X\", \"Y\", \"Age\"]]\n",
    "X_train[\"DefenseAveSpeed\"] = np.array(tmp[0::2][\"S\"])\n",
    "X_train[\"OffenseAveSpeed\"] = np.array(tmp[1::2][\"S\"])\n",
    "\n",
    "X_train[\"DefenseAveX\"] = np.array(tmp[0::2][\"X\"])\n",
    "X_train[\"OffenseAveX\"] = np.array(tmp[1::2][\"X\"])\n",
    "\n",
    "X_train[\"DefenseAveY\"] = np.array(tmp[0::2][\"Y\"]) \n",
    "X_train[\"OffenseAveY\"] = np.array(tmp[1::2][\"Y\"]) \n",
    "\n",
    "X_train[\"DefenseAveAge\"] = np.array(tmp[0::2][\"Age\"])\n",
    "X_train[\"OffenseAveAge\"] = np.array(tmp[1::2][\"Age\"])\n",
    "\n",
    "tmp = train.groupby([\"PlayId\", \"OnOffense\"]).agg([\"std\"])[[\"X\", \"Y\"]]\n",
    "X_train[\"DefenseStdX\"] = np.array(tmp[0::2][\"X\"])\n",
    "X_train[\"OffenseStdX\"] = np.array(tmp[1::2][\"X\"])\n",
    "\n",
    "X_train[\"DefenseStdY\"] = np.array(tmp[0::2][\"Y\"])\n",
    "X_train[\"OffenseStdY\"] = np.array(tmp[1::2][\"Y\"])\n",
    "\n",
    "X_train[\"RunnerToDefenseCentoid\"] = np.sqrt((X_train[\"X\"] - X_train[\"DefenseAveX\"]) ** 2 + (X_train[\"Y\"] - X_train[\"DefenseAveY\"]) ** 2)\n",
    "X_train[\"RunnerToOffenseCentoid\"] = np.sqrt((X_train[\"X\"] - X_train[\"OffenseAveX\"]) ** 2 + (X_train[\"Y\"] - X_train[\"OffenseAveY\"]) ** 2)\n",
    "\n",
    "# defense x spread, offense x spread\n",
    "tmp_max = train.groupby([\"PlayId\", \"OnOffense\"])[\"X\"].max()\n",
    "tmp_min = train.groupby([\"PlayId\", \"OnOffense\"])[\"X\"].min()\n",
    "X_train[\"DefenseSpreadX\"] = np.array(tmp_max[0::2]- tmp_min[0::2])\n",
    "X_train[\"OffenseSpreadX\"] = np.array(tmp_max[1::2]- tmp_min[1::2])\n",
    "\n",
    "X_train[\"RunnerToScrimmage\"] = X_train[\"X\"] - X_train[\"YardLine\"]\n",
    "\n",
    "# runner horizontal and vertical speed\n",
    "radian_angle = (90 - X_train['Dir']) * np.pi / 180.0\n",
    "X_train['v_horizontal'] = np.abs(X_train['S'] * np.cos(radian_angle))\n",
    "X_train['v_vertical'] = np.abs(X_train['S'] * np.sin(radian_angle))\n",
    "\n",
    "# runner horizontal and vertical momentum\n",
    "X_train['m_horizontal'] = np.abs(X_train['Momentum'] * np.cos(radian_angle))\n",
    "X_train['m_vertical'] = np.abs(X_train['Momentum'] * np.sin(radian_angle))\n",
    "\n",
    "# minimum distance to rusher from defenders\n",
    "X_train[\"MinDisFromRushToDef\"] = np.array(train.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].min()[0::2])\n",
    "\n",
    "# tackle time from closest defender to rusher\n",
    "X_train[\"MinTackleTime\"] = np.array(train.groupby([\"PlayId\", \"OnOffense\"])[\"TackleTimeToRusher\"].min()[0::2])\n",
    "\n",
    "# average tackle time from all defenders to rusher\n",
    "X_train[\"AveTackleTime\"] = np.array(train.groupby([\"PlayId\", \"OnOffense\"]).agg(np.mean)[\"TackleTimeToRusher\"][0::2])\n",
    "\n",
    "# runner vs 1st defender speed: runner's velocity divided by closest defender's speed\n",
    "X_train[\"RatioSRusherToCloseDef\"] = np.array(train.loc[train.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].idxmin()[0::2]][\"RatioSToRusher\"])\n",
    "\n",
    "# runner horizontal and vertical distance\n",
    "X_train[\"dis_horizontal\"] = np.abs(X_train['Dis'] * np.cos(radian_angle))\n",
    "X_train[\"dis_vertical\"] = np.abs(X_train['Dis'] * np.sin(radian_angle))\n",
    "X_train[\"RunnerMoveRatio\"] = X_train[\"dis_horizontal\"] / X_train[\"dis_vertical\"]\n",
    "\n",
    "# the momentum of 1st closest defender to rusher, horizontal momentum, vertical momentum\n",
    "X_train[\"DefMomentumCloToRusher\"] = np.array(train.loc[train.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].idxmin()[0::2]][\"Momentum\"])\n",
    "X_train[\"DefMomentumCloToRusher_horizontal\"] = np.abs(X_train['DefMomentumCloToRusher'] * np.cos(radian_angle))\n",
    "X_train[\"DefMomentumCloToRusher_vertical\"] = np.abs(X_train['DefMomentumCloToRusher'] * np.sin(radian_angle))\n",
    "\n",
    "# the horizontal, vertical mometum of rusher\n",
    "X_train[\"RusherMomentum_horizontal\"] =  np.abs(X_train['Momentum'] * np.cos(radian_angle))\n",
    "X_train[\"RusherMomentum_vertical\"] =  np.abs(X_train['Momentum'] * np.sin(radian_angle))\n",
    "\n",
    "# difference of horizontal momentum \n",
    "X_train[\"hMomentum_rusher_vs_defender\"] = X_train[\"RusherMomentum_horizontal\"] - X_train[\"DefMomentumCloToRusher_horizontal\"]\n",
    "\n",
    "# voronoi area\n",
    "pts = np.array(train[[\"X\", \"Y\"]]).reshape(train.shape[0]//22, 22, 2) # plays * players * (X, Y, rusher)\n",
    "# index of row where rusher data is included when separated by each play\n",
    "rusher_index = list(train[train.is_run==True].index % 22) \n",
    "closest_def_index = list(train.loc[train.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].idxmin()[0::2]].index % 22)\n",
    "rusher_voronoi = []\n",
    "closest_def_voronoi = []\n",
    "for i in range(0, train.shape[0] //22):\n",
    "    rusher_voronoi.append(voronoi_volumes(pts[i], rusher_index[i]))\n",
    "    closest_def_voronoi.append(voronoi_volumes(pts[i], closest_def_index[i]))\n",
    "X_train[\"RusherVoronoi\"] = rusher_voronoi    \n",
    "X_train[\"FirstDefenderVoronoi\"] = closest_def_voronoi \n",
    "# additional feature engineering end ---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cdf_df(yards_array):\n",
    "    pdf, edges = np.histogram(yards_array, bins=199,\n",
    "                 range=(-99,100), density=True)\n",
    "    cdf = pdf.cumsum().clip(0, 1)\n",
    "    cdf_df = pd.DataFrame(data=cdf.reshape(-1, 1).T, \n",
    "                            columns=['Yards'+str(i) for i in range(-99,100)])\n",
    "    return cdf_df\n",
    "cdf = get_cdf_df(y_train).values.reshape(-1,)\n",
    "\n",
    "def get_score(y_pred,cdf,w,dist_to_end):\n",
    "    y_pred = int(y_pred)\n",
    "    if y_pred ==w:\n",
    "        y_pred_array = cdf.copy()\n",
    "    elif y_pred - w >0:\n",
    "        y_pred_array = np.zeros(199)\n",
    "        y_pred_array[(y_pred-w):] = cdf[:(-(y_pred-w))].copy()\n",
    "    elif w - y_pred >0:\n",
    "        y_pred_array = np.ones(199)\n",
    "        y_pred_array[:(y_pred-w)] = cdf[(w-y_pred):].copy()\n",
    "    y_pred_array[-1]=1\n",
    "    y_pred_array[(dist_to_end+99):]=1\n",
    "    return y_pred_array    \n",
    "\n",
    "def get_score_pingyi1(y_pred,y_true,cdf,w,dist_to_end):\n",
    "    y_pred = int(y_pred)\n",
    "    if y_pred ==w:\n",
    "        y_pred_array = cdf.copy()\n",
    "    elif y_pred - w >0:\n",
    "        y_pred_array = np.zeros(199)\n",
    "        y_pred_array[(y_pred-w):] = cdf[:(-(y_pred-w))].copy()\n",
    "    elif w - y_pred >0:\n",
    "        y_pred_array = np.ones(199)\n",
    "        y_pred_array[:(y_pred-w)] = cdf[(w-y_pred):].copy()\n",
    "    y_pred_array[-1]=1\n",
    "    y_pred_array[(dist_to_end+99):]=1\n",
    "    y_true_array = np.zeros(199)\n",
    "    y_true_array[(y_true+99):]=1\n",
    "    return np.mean((y_pred_array - y_true_array)**2)\n",
    "\n",
    "\n",
    "def CRPS_pingyi1(y_preds,y_trues,w,cdf,dist_to_ends):\n",
    "    if len(y_preds) != len(y_trues):\n",
    "        print('length does not match')\n",
    "        return None\n",
    "    n = len(y_preds)\n",
    "    tmp = []\n",
    "    for a,b,c in zip(y_preds, y_trues,dist_to_ends):\n",
    "        tmp.append(get_score_pingyi1(a,b,cdf,w,c))\n",
    "    return np.mean(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n",
      "fold: 2\n",
      "fold: 3\n",
      "[2017090700, 2017091000, 2017091001, 2017091002, 2017091003, 2017091004, 2017091005, 2017091007, 2017091008, 2017091009, 2017091010, 2017091011, 2017091012, 2017091100, 2017091101, 2017091400, 2017091700, 2017091701, 2017091702, 2017091703, 2017091704, 2017091705, 2017091706, 2017091707, 2017091708, 2017091709, 2017091710, 2017091711, 2017091712, 2017091713, 2017091800, 2017092100, 2017092400, 2017092401, 2017092402, 2017092403, 2017092404, 2017092405, 2017092406, 2017092407, 2017092408, 2017092409, 2017092410, 2017092411, 2017092412, 2017092413, 2017092500, 2017092800, 2017100100, 2017100101, 2017100102, 2017100103, 2017100104, 2017100105, 2017100106, 2017100107, 2017100108, 2017100109, 2017100110, 2017100111, 2017100112, 2017100113, 2017100200, 2017100500, 2017100800, 2017100801, 2017100802, 2017100803, 2017100804, 2017100805, 2017100806, 2017100807, 2017100808, 2017100809, 2017100810, 2017100811, 2017100900, 2017101200, 2017101500, 2017101501, 2017101502, 2017101503, 2017101504, 2017101505, 2017101506, 2017101507, 2017101508, 2017101509, 2017101510, 2017101511, 2017101600, 2017101900, 2017102200, 2017102201, 2017102202, 2017102203, 2017102204, 2017102205, 2017102206, 2017102207, 2017102208, 2017102209, 2017102210, 2017102211, 2017102212, 2017102300, 2017102600, 2017102900, 2017102901, 2017102902, 2017102903, 2017102904, 2017102905, 2017102906, 2017102907, 2017102908, 2017102909, 2017102910, 2017103000, 2017110200, 2017110500, 2017110501, 2017110502, 2017110503, 2017110504, 2017110505, 2017110506, 2017110507, 2017110508, 2017110509, 2017110510, 2017110600, 2017110900, 2017111200, 2017111201, 2017111202, 2017111203, 2017111204, 2017111205, 2017111206, 2017111207, 2017111208, 2017111209, 2017111210, 2017111211, 2017111300, 2017111600, 2017111900, 2017111901, 2017111902, 2017111903, 2017111904, 2017111905, 2017111906, 2017111907, 2017111908, 2017111909, 2017111910, 2017111911, 2017112000, 2017112300, 2017112301, 2017112302, 2017112600, 2017112601, 2017112602, 2017112603, 2017112604, 2017112605, 2017112606, 2017112607, 2017112608, 2017112609, 2017112610, 2017112611, 2017112700, 2017113000, 2017120300, 2017120301, 2017120302, 2017120303, 2017120304, 2017120305, 2017120306, 2017120307, 2017120308, 2017120309, 2017120310, 2017120311, 2017120312, 2017120313, 2017120400, 2017120700, 2017121000, 2017121001, 2017121002, 2017121003, 2017121004, 2017121005]\n",
      "[2017121006 2017121007 2017121008 2017121009 2017121010 2017121011\n",
      " 2017121012 2017121013 2017121100 2017121400 2017121600 2017121601\n",
      " 2017121700 2017121701 2017121702 2017121703 2017121704 2017121705\n",
      " 2017121706 2017121707 2017121708 2017121709 2017121710 2017121711\n",
      " 2017121800 2017122300 2017122301 2017122400 2017122401 2017122402\n",
      " 2017122403 2017122404 2017122405 2017122406 2017122407 2017122408\n",
      " 2017122409 2017122410 2017122411 2017122500 2017122501 2017123100\n",
      " 2017123101 2017123102 2017123103 2017123104 2017123105 2017123106\n",
      " 2017123107 2017123108 2017123109 2017123110 2017123111 2017123112\n",
      " 2017123113 2017123114 2017123115 2018090600 2018090900 2018090901\n",
      " 2018090902 2018090903 2018090904 2018090905 2018090906 2018090907\n",
      " 2018090908 2018090909 2018090910 2018090911 2018090912 2018091000\n",
      " 2018091001 2018091300 2018091600 2018091601 2018091602 2018091603\n",
      " 2018091604 2018091605 2018091606 2018091607 2018091608 2018091609\n",
      " 2018091610 2018091611 2018091612 2018091613 2018091700 2018092000\n",
      " 2018092300 2018092301 2018092302 2018092303 2018092304 2018092305\n",
      " 2018092306 2018092307 2018092308 2018092309 2018092310 2018092311\n",
      " 2018092312 2018092313]\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's l1: 3.58811\tvalid_1's l1: 3.50743\n",
      "[100]\ttraining's l1: 3.44258\tvalid_1's l1: 3.46692\n",
      "[150]\ttraining's l1: 3.33621\tvalid_1's l1: 3.45618\n",
      "[200]\ttraining's l1: 3.25857\tvalid_1's l1: 3.4536\n",
      "[250]\ttraining's l1: 3.19478\tvalid_1's l1: 3.46199\n",
      "[300]\ttraining's l1: 3.14268\tvalid_1's l1: 3.47189\n",
      "[350]\ttraining's l1: 3.09792\tvalid_1's l1: 3.48005\n",
      "Early stopping, best iteration is:\n",
      "[187]\ttraining's l1: 3.27698\tvalid_1's l1: 3.45311\n",
      "0.012503199109214198\n",
      "fold: 4\n",
      "[2017090700, 2017091000, 2017091001, 2017091002, 2017091003, 2017091004, 2017091005, 2017091007, 2017091008, 2017091009, 2017091010, 2017091011, 2017091012, 2017091100, 2017091101, 2017091400, 2017091700, 2017091701, 2017091702, 2017091703, 2017091704, 2017091705, 2017091706, 2017091707, 2017091708, 2017091709, 2017091710, 2017091711, 2017091712, 2017091713, 2017091800, 2017092100, 2017092400, 2017092401, 2017092402, 2017092403, 2017092404, 2017092405, 2017092406, 2017092407, 2017092408, 2017092409, 2017092410, 2017092411, 2017092412, 2017092413, 2017092500, 2017092800, 2017100100, 2017100101, 2017100102, 2017100103, 2017100104, 2017100105, 2017100106, 2017100107, 2017100108, 2017100109, 2017100110, 2017100111, 2017100112, 2017100113, 2017100200, 2017100500, 2017100800, 2017100801, 2017100802, 2017100803, 2017100804, 2017100805, 2017100806, 2017100807, 2017100808, 2017100809, 2017100810, 2017100811, 2017100900, 2017101200, 2017101500, 2017101501, 2017101502, 2017101503, 2017101504, 2017101505, 2017101506, 2017101507, 2017101508, 2017101509, 2017101510, 2017101511, 2017101600, 2017101900, 2017102200, 2017102201, 2017102202, 2017102203, 2017102204, 2017102205, 2017102206, 2017102207, 2017102208, 2017102209, 2017102210, 2017102211, 2017102212, 2017102300, 2017102600, 2017102900, 2017102901, 2017102902, 2017102903, 2017102904, 2017102905, 2017102906, 2017102907, 2017102908, 2017102909, 2017102910, 2017103000, 2017110200, 2017110500, 2017110501, 2017110502, 2017110503, 2017110504, 2017110505, 2017110506, 2017110507, 2017110508, 2017110509, 2017110510, 2017110600, 2017110900, 2017111200, 2017111201, 2017111202, 2017111203, 2017111204, 2017111205, 2017111206, 2017111207, 2017111208, 2017111209, 2017111210, 2017111211, 2017111300, 2017111600, 2017111900, 2017111901, 2017111902, 2017111903, 2017111904, 2017111905, 2017111906, 2017111907, 2017111908, 2017111909, 2017111910, 2017111911, 2017112000, 2017112300, 2017112301, 2017112302, 2017112600, 2017112601, 2017112602, 2017112603, 2017112604, 2017112605, 2017112606, 2017112607, 2017112608, 2017112609, 2017112610, 2017112611, 2017112700, 2017113000, 2017120300, 2017120301, 2017120302, 2017120303, 2017120304, 2017120305, 2017120306, 2017120307, 2017120308, 2017120309, 2017120310, 2017120311, 2017120312, 2017120313, 2017120400, 2017120700, 2017121000, 2017121001, 2017121002, 2017121003, 2017121004, 2017121005, 2017121006, 2017121007, 2017121008, 2017121009, 2017121010, 2017121011, 2017121012, 2017121013, 2017121100, 2017121400, 2017121600, 2017121601, 2017121700, 2017121701, 2017121702, 2017121703, 2017121704, 2017121705, 2017121706, 2017121707, 2017121708, 2017121709, 2017121710, 2017121711, 2017121800, 2017122300, 2017122301, 2017122400, 2017122401, 2017122402, 2017122403, 2017122404, 2017122405, 2017122406, 2017122407, 2017122408, 2017122409, 2017122410, 2017122411, 2017122500, 2017122501, 2017123100, 2017123101, 2017123102, 2017123103, 2017123104, 2017123105, 2017123106, 2017123107, 2017123108, 2017123109, 2017123110, 2017123111, 2017123112, 2017123113, 2017123114, 2017123115, 2018090600, 2018090900, 2018090901, 2018090902, 2018090903, 2018090904, 2018090905, 2018090906, 2018090907, 2018090908, 2018090909, 2018090910, 2018090911, 2018090912, 2018091000, 2018091001, 2018091300, 2018091600, 2018091601, 2018091602, 2018091603, 2018091604, 2018091605, 2018091606, 2018091607, 2018091608, 2018091609, 2018091610, 2018091611, 2018091612, 2018091613, 2018091700, 2018092000, 2018092300, 2018092301, 2018092302, 2018092303, 2018092304, 2018092305, 2018092306, 2018092307, 2018092308, 2018092309, 2018092310, 2018092311, 2018092312]\n",
      "[2018092313 2018092400 2018092700 2018093000 2018093001 2018093002\n",
      " 2018093003 2018093004 2018093005 2018093006 2018093007 2018093008\n",
      " 2018093009 2018093010 2018093011 2018093012 2018100100 2018100400\n",
      " 2018100700 2018100701 2018100702 2018100703 2018100704 2018100705\n",
      " 2018100706 2018100707 2018100708 2018100709 2018100710 2018100711\n",
      " 2018100712 2018100800 2018101100 2018101400 2018101401 2018101402\n",
      " 2018101403 2018101404 2018101405 2018101406 2018101407 2018101408\n",
      " 2018101409 2018101410 2018101411 2018101412 2018101500 2018101800\n",
      " 2018102100 2018102101 2018102102 2018102103 2018102104 2018102105\n",
      " 2018102106 2018102107 2018102108 2018102109 2018102110 2018102111\n",
      " 2018102200 2018102500 2018102800 2018102801 2018102802 2018102803\n",
      " 2018102804 2018102805 2018102806 2018102807 2018102808 2018102809\n",
      " 2018102810 2018102811 2018102900 2018110100 2018110400 2018110401\n",
      " 2018110402 2018110403 2018110404 2018110405 2018110406 2018110407\n",
      " 2018110408 2018110409 2018110410 2018110500 2018110800 2018111100\n",
      " 2018111101 2018111102 2018111103 2018111104 2018111105 2018111106\n",
      " 2018111107 2018111108 2018111109 2018111110 2018111111 2018111200\n",
      " 2018111500 2018111800 2018111801 2018111802 2018111803]\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's l1: 3.55884\tvalid_1's l1: 3.99723\n",
      "[100]\ttraining's l1: 3.43844\tvalid_1's l1: 3.9992\n",
      "[150]\ttraining's l1: 3.35196\tvalid_1's l1: 4.00676\n",
      "[200]\ttraining's l1: 3.28794\tvalid_1's l1: 4.0203\n",
      "[250]\ttraining's l1: 3.23806\tvalid_1's l1: 4.0365\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's l1: 3.50367\tvalid_1's l1: 3.99455\n",
      "0.014729832760523864\n",
      "fold: 5\n",
      "[2017090700, 2017091000, 2017091001, 2017091002, 2017091003, 2017091004, 2017091005, 2017091007, 2017091008, 2017091009, 2017091010, 2017091011, 2017091012, 2017091100, 2017091101, 2017091400, 2017091700, 2017091701, 2017091702, 2017091703, 2017091704, 2017091705, 2017091706, 2017091707, 2017091708, 2017091709, 2017091710, 2017091711, 2017091712, 2017091713, 2017091800, 2017092100, 2017092400, 2017092401, 2017092402, 2017092403, 2017092404, 2017092405, 2017092406, 2017092407, 2017092408, 2017092409, 2017092410, 2017092411, 2017092412, 2017092413, 2017092500, 2017092800, 2017100100, 2017100101, 2017100102, 2017100103, 2017100104, 2017100105, 2017100106, 2017100107, 2017100108, 2017100109, 2017100110, 2017100111, 2017100112, 2017100113, 2017100200, 2017100500, 2017100800, 2017100801, 2017100802, 2017100803, 2017100804, 2017100805, 2017100806, 2017100807, 2017100808, 2017100809, 2017100810, 2017100811, 2017100900, 2017101200, 2017101500, 2017101501, 2017101502, 2017101503, 2017101504, 2017101505, 2017101506, 2017101507, 2017101508, 2017101509, 2017101510, 2017101511, 2017101600, 2017101900, 2017102200, 2017102201, 2017102202, 2017102203, 2017102204, 2017102205, 2017102206, 2017102207, 2017102208, 2017102209, 2017102210, 2017102211, 2017102212, 2017102300, 2017102600, 2017102900, 2017102901, 2017102902, 2017102903, 2017102904, 2017102905, 2017102906, 2017102907, 2017102908, 2017102909, 2017102910, 2017103000, 2017110200, 2017110500, 2017110501, 2017110502, 2017110503, 2017110504, 2017110505, 2017110506, 2017110507, 2017110508, 2017110509, 2017110510, 2017110600, 2017110900, 2017111200, 2017111201, 2017111202, 2017111203, 2017111204, 2017111205, 2017111206, 2017111207, 2017111208, 2017111209, 2017111210, 2017111211, 2017111300, 2017111600, 2017111900, 2017111901, 2017111902, 2017111903, 2017111904, 2017111905, 2017111906, 2017111907, 2017111908, 2017111909, 2017111910, 2017111911, 2017112000, 2017112300, 2017112301, 2017112302, 2017112600, 2017112601, 2017112602, 2017112603, 2017112604, 2017112605, 2017112606, 2017112607, 2017112608, 2017112609, 2017112610, 2017112611, 2017112700, 2017113000, 2017120300, 2017120301, 2017120302, 2017120303, 2017120304, 2017120305, 2017120306, 2017120307, 2017120308, 2017120309, 2017120310, 2017120311, 2017120312, 2017120313, 2017120400, 2017120700, 2017121000, 2017121001, 2017121002, 2017121003, 2017121004, 2017121005, 2017121006, 2017121007, 2017121008, 2017121009, 2017121010, 2017121011, 2017121012, 2017121013, 2017121100, 2017121400, 2017121600, 2017121601, 2017121700, 2017121701, 2017121702, 2017121703, 2017121704, 2017121705, 2017121706, 2017121707, 2017121708, 2017121709, 2017121710, 2017121711, 2017121800, 2017122300, 2017122301, 2017122400, 2017122401, 2017122402, 2017122403, 2017122404, 2017122405, 2017122406, 2017122407, 2017122408, 2017122409, 2017122410, 2017122411, 2017122500, 2017122501, 2017123100, 2017123101, 2017123102, 2017123103, 2017123104, 2017123105, 2017123106, 2017123107, 2017123108, 2017123109, 2017123110, 2017123111, 2017123112, 2017123113, 2017123114, 2017123115, 2018090600, 2018090900, 2018090901, 2018090902, 2018090903, 2018090904, 2018090905, 2018090906, 2018090907, 2018090908, 2018090909, 2018090910, 2018090911, 2018090912, 2018091000, 2018091001, 2018091300, 2018091600, 2018091601, 2018091602, 2018091603, 2018091604, 2018091605, 2018091606, 2018091607, 2018091608, 2018091609, 2018091610, 2018091611, 2018091612, 2018091613, 2018091700, 2018092000, 2018092300, 2018092301, 2018092302, 2018092303, 2018092304, 2018092305, 2018092306, 2018092307, 2018092308, 2018092309, 2018092310, 2018092311, 2018092312, 2018092313, 2018092400, 2018092700, 2018093000, 2018093001, 2018093002, 2018093003, 2018093004, 2018093005, 2018093006, 2018093007, 2018093008, 2018093009, 2018093010, 2018093011, 2018093012, 2018100100, 2018100400, 2018100700, 2018100701, 2018100702, 2018100703, 2018100704, 2018100705, 2018100706, 2018100707, 2018100708, 2018100709, 2018100710, 2018100711, 2018100712, 2018100800, 2018101100, 2018101400, 2018101401, 2018101402, 2018101403, 2018101404, 2018101405, 2018101406, 2018101407, 2018101408, 2018101409, 2018101410, 2018101411, 2018101412, 2018101500, 2018101800, 2018102100, 2018102101, 2018102102, 2018102103, 2018102104, 2018102105, 2018102106, 2018102107, 2018102108, 2018102109, 2018102110, 2018102111, 2018102200, 2018102500, 2018102800, 2018102801, 2018102802, 2018102803, 2018102804, 2018102805, 2018102806, 2018102807, 2018102808, 2018102809, 2018102810, 2018102811, 2018102900, 2018110100, 2018110400, 2018110401, 2018110402, 2018110403, 2018110404, 2018110405, 2018110406, 2018110407, 2018110408, 2018110409, 2018110410, 2018110500, 2018110800, 2018111100, 2018111101, 2018111102, 2018111103, 2018111104, 2018111105, 2018111106, 2018111107, 2018111108, 2018111109, 2018111110, 2018111111, 2018111200, 2018111500, 2018111800, 2018111801, 2018111802]\n",
      "[2018111803 2018111804 2018111805 2018111806 2018111807 2018111808\n",
      " 2018111809 2018111810 2018111900 2018112200 2018112201 2018112202\n",
      " 2018112500 2018112501 2018112502 2018112503 2018112504 2018112505\n",
      " 2018112506 2018112507 2018112508 2018112509 2018112510 2018112600\n",
      " 2018112900 2018120200 2018120201 2018120202 2018120203 2018120204\n",
      " 2018120205 2018120206 2018120207 2018120208 2018120209 2018120210\n",
      " 2018120211 2018120212 2018120213 2018120300 2018120600 2018120900\n",
      " 2018120901 2018120902 2018120903 2018120904 2018120905 2018120906\n",
      " 2018120907 2018120908 2018120909 2018120910 2018120911 2018120912\n",
      " 2018120913 2018121000 2018121300 2018121500 2018121501 2018121600\n",
      " 2018121601 2018121602 2018121603 2018121604 2018121605 2018121606\n",
      " 2018121607 2018121608 2018121609 2018121610 2018121611 2018121700\n",
      " 2018122200 2018122201 2018122300 2018122302 2018122304 2018122305\n",
      " 2018122306 2018122307 2018122308 2018122309 2018122310 2018122311\n",
      " 2018122312 2018122313 2018122314 2018122400 2018123000 2018123001\n",
      " 2018123002 2018123003 2018123004 2018123005 2018123006 2018123007\n",
      " 2018123008 2018123009 2018123010 2018123011 2018123012 2018123013\n",
      " 2018123014 2018123015]\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's l1: 3.68735\tvalid_1's l1: 3.91767\n",
      "[100]\ttraining's l1: 3.59134\tvalid_1's l1: 3.89889\n",
      "[150]\ttraining's l1: 3.52151\tvalid_1's l1: 3.88677\n",
      "[200]\ttraining's l1: 3.46885\tvalid_1's l1: 3.88302\n",
      "[250]\ttraining's l1: 3.42663\tvalid_1's l1: 3.88566\n",
      "[300]\ttraining's l1: 3.39258\tvalid_1's l1: 3.8879\n",
      "[350]\ttraining's l1: 3.36297\tvalid_1's l1: 3.89234\n",
      "[400]\ttraining's l1: 3.33441\tvalid_1's l1: 3.89456\n",
      "Early stopping, best iteration is:\n",
      "[204]\ttraining's l1: 3.46475\tvalid_1's l1: 3.88248\n",
      "0.014415396385095614\n",
      "mean mse: 40.32678323908244\n",
      "oof mse: 47.182941633495496\n",
      "mean mae: 3.7767152372874495\n",
      "oof mae: 4.104220587319068\n",
      "mean cprs: 0.013882809418277893\n",
      "oof cprs: 0.016077423260237877\n"
     ]
    }
   ],
   "source": [
    "kf=KFold(n_splits = 5)\n",
    "resu1 = 0\n",
    "resu2_cprs = 0\n",
    "resu3_mae=0\n",
    "stack_train = np.zeros([X_train.shape[0],])\n",
    "models = []\n",
    "for i ,(train_index, test_index) in enumerate(kf.split(X_train, y_train)):\n",
    "    print(\"fold:\", i+1)\n",
    "    training_data = pd.concat([X_train.iloc[train_index, :], y_train.iloc[train_index]], axis=1)\n",
    "    # validation data\n",
    "    all_gameid = X_train[\"GameId\"].unique()\n",
    "    X_test2= X_train.iloc[test_index,:].copy()\n",
    "    y_test2= y_train.iloc[test_index].copy()\n",
    "    test_first_gameid = min(X_test2[\"GameId\"].unique())\n",
    "    test_gameid = X_test2[\"GameId\"].unique()\n",
    "    X_test2.drop(['GameId','PlayId'],axis=1,inplace=True)\n",
    "    \n",
    "    final_train_gameid = [i for i in list(all_gameid) if i < test_first_gameid]\n",
    "\n",
    "    # generate new training data\n",
    "    if len(final_train_gameid) > len(test_gameid):\n",
    "        print(final_train_gameid)\n",
    "        print(test_gameid)\n",
    "        final_training_data = training_data[training_data.GameId.isin(final_train_gameid)].reset_index(drop=True)\n",
    "        X_train2 = final_training_data.drop(['GameId','PlayId', \"Yards\"], axis=1)\n",
    "        y_train2 = final_training_data[\"Yards\"]\n",
    "\n",
    "        clf = lgb.LGBMRegressor(n_estimators=10000, random_state=47,learning_rate=0.005,importance_type = 'gain',\n",
    "                     n_jobs = -1,metric='mae')\n",
    "        clf.fit(X_train2,y_train2,eval_set = [(X_train2,y_train2),(X_test2,y_test2)],early_stopping_rounds=200,verbose=50)\n",
    "        models.append(clf)\n",
    "        temp_predict = clf.predict(X_test2)\n",
    "        stack_train[test_index] = temp_predict\n",
    "        mse = mean_squared_error(y_test2, temp_predict)\n",
    "        crps = CRPS_pingyi1(temp_predict,y_test2,4,cdf,dist_to_end_train.iloc[test_index])\n",
    "        mae = mean_absolute_error(y_test2, temp_predict)\n",
    "        print(crps)\n",
    "    \n",
    "        resu1 += mse\n",
    "        resu2_cprs += crps\n",
    "        resu3_mae += mae\n",
    "        gc.collect()\n",
    "    # no learning process if the number of refined training data is smaller than that of validation data\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "resu1 /= len(models)\n",
    "resu2_cprs /= len(models)\n",
    "resu3_mae /= len(models)\n",
    "print('mean mse:',resu1)\n",
    "print('oof mse:',mean_squared_error(y_train,stack_train))\n",
    "print('mean mae:',resu3_mae)\n",
    "print('oof mae:',mean_absolute_error(y_train,stack_train))\n",
    "print('mean cprs:',resu2_cprs)\n",
    "print('oof cprs:',CRPS_pingyi1(stack_train,y_train,4,cdf,dist_to_end_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X_train = X_train.drop(['GameId','PlayId'],axis=1)\n",
    "clf = lgb.LGBMRegressor(n_estimators=10000, random_state=47,learning_rate=0.005,importance_type = 'gain',\n",
    "                     n_jobs = -1,metric='mae')\n",
    "clf.fit(all_X_train, y_train, verbose=50)\n",
    "models.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_test(test):\n",
    "    test.loc[test.VisitorTeamAbbr == \"ARI\",'VisitorTeamAbbr'] = \"ARZ\"\n",
    "    test.loc[test.HomeTeamAbbr == \"ARI\",'HomeTeamAbbr'] = \"ARZ\"\n",
    "\n",
    "    test.loc[test.VisitorTeamAbbr == \"BAL\",'VisitorTeamAbbr'] = \"BLT\"\n",
    "    test.loc[test.HomeTeamAbbr == \"BAL\",'HomeTeamAbbr'] = \"BLT\"\n",
    "\n",
    "    test.loc[test.VisitorTeamAbbr == \"CLE\",'VisitorTeamAbbr'] = \"CLV\"\n",
    "    test.loc[test.HomeTeamAbbr == \"CLE\",'HomeTeamAbbr'] = \"CLV\"\n",
    "\n",
    "    test.loc[test.VisitorTeamAbbr == \"HOU\",'VisitorTeamAbbr'] = \"HST\"\n",
    "    test.loc[test.HomeTeamAbbr == \"HOU\",'HomeTeamAbbr'] = \"HST\"\n",
    "    \n",
    "    test['is_run'] = test.NflId == test.NflIdRusher\n",
    "    \n",
    "    # my original idea for feature engineering -------------------------------------------------------------\n",
    "    \n",
    "    # age \n",
    "    FMT_birth = '%m/%d/%Y'\n",
    "    FMT_gamedate = '%Y-%m-%d'\n",
    "    test[\"Age\"] = test[\"TimeSnap\"].apply(lambda t: t.split(\"T\")[0])\n",
    "    test[\"Age\"] = test[\"Age\"].apply(lambda t: datetime.strptime(t, FMT_gamedate))\n",
    "    tmp_birth = test[\"PlayerBirthDate\"].apply(lambda t: datetime.strptime(t, FMT_birth))\n",
    "    test[\"Age\"] = test[\"Age\"] - tmp_birth\n",
    "    test[\"Age\"] = test[\"Age\"].apply(lambda t: t.days//365)\n",
    "\n",
    "    # momentum \n",
    "    test[\"Momentum\"] = test[\"S\"] * test[\"PlayerWeight\"]\n",
    "\n",
    "    # on offense\n",
    "    test[\"OnOffense\"] = test[[\"PossessionTeam\", \"HomeTeamAbbr\"]].apply(func, axis=1)\n",
    "    test[\"OnOffense\"] = test[\"OnOffense\"] == test[\"Team\"]\n",
    "    \n",
    "    #test['ToLeft'] = test.PlayDirection == \"left\"\n",
    "    #test['Dir_rad'] = np.mod(90 - test.Dir, 360) * math.pi/180.0\n",
    "    #test['TeamOnOffense'] = \"home\"\n",
    "    #test.loc[test.PossessionTeam != test.HomeTeamAbbr, 'TeamOnOffense'] = \"away\"\n",
    "    #test['IsOnOffense'] = test.Team == test.TeamOnOffense # Is player on offense?\n",
    "    #test['YardLine_std'] = 100 - test.YardLine\n",
    "    #test.loc[test.FieldPosition.fillna('') == test.PossessionTeam,  \n",
    "    #      'YardLine_std'\n",
    "    #     ] = test.loc[test.FieldPosition.fillna('') == test.PossessionTeam,  \n",
    "    #      'YardLine']\n",
    "    #test['X_std'] = test.X\n",
    "    #test.loc[test.ToLeft, 'X_std'] = 120 - test.loc[test.ToLeft, 'X'] \n",
    "    #test['Y_std'] = test.Y\n",
    "    #test.loc[test.ToLeft, 'Y_std'] = 160/3 - test.loc[test.ToLeft, 'Y'] \n",
    "     #train['Orientation_std'] = -90 + train.Orientation\n",
    "     #train.loc[train.ToLeft, 'Orientation_std'] = np.mod(180 + train.loc[train.ToLeft, 'Orientation_std'], 360)\n",
    "    #test['Dir_std'] = test.Dir_rad\n",
    "    #test.loc[test.ToLeft, 'Dir_std'] = np.mod(np.pi + test.loc[test.ToLeft, 'Dir_rad'], 2*np.pi)\n",
    "    \n",
    "    # exercise energy\n",
    "    #test[\"Exercise enegy\"] = 0.5 * test[\"PlayerWeight\"] * (test[\"S\"]**2)\n",
    "        \n",
    "    rusher_x = np.array(test.groupby([\"PlayId\", \"is_run\"])[\"X\"].agg(np.mean)[1::2])\n",
    "    rusher_x = np.repeat(rusher_x, 22) # repeat each elemnt 22 times train[\"RusherX\"]\n",
    "    rusher_y = np.array(test.groupby([\"PlayId\", \"is_run\"])[\"Y\"].agg(np.mean)[1::2])\n",
    "    rusher_y = np.repeat(rusher_y, 22) # train[\"RusherY\"]\n",
    "    test[\"DisToRusher\"] = np.sqrt((test[\"X\"] - rusher_x) ** 2 + (test[\"Y\"] - rusher_y) ** 2)\n",
    "    test[\"TackleTimeToRusher\"] = test[\"DisToRusher\"] / test[\"S\"] \n",
    "\n",
    "    rusher_s = np.array(test.groupby([\"PlayId\", \"is_run\"]).agg(np.mean)[\"S\"][1::2])\n",
    "    rusher_s = np.repeat(rusher_s, 22)\n",
    "    test[\"RatioSToRusher\"] = test[\"S\"] / rusher_s\n",
    "    \n",
    "    #test[\"MoveDist\"] = test[\"S\"] * test[\"TimeFromSnapDiff\"] + 0.5 * test[\"A\"] * (test[\"TimeFromSnapDiff\"] **2)\n",
    "    # ratio of real movement distance to theoretical movement distance\n",
    "    #test[\"RealToTheoryDis\"] = test[\"Dis\"] / test[\"MoveDist\"]\n",
    "    \n",
    "    # my original idea end ------------------------------------------------------------\n",
    "    \n",
    "    test_single = test[test.is_run==True].copy()\n",
    "    test_single['time_quarter'] = test_single.GameClock.map(lambda x:transform_time_quarter(x))\n",
    "    test_single['time_end'] = test_single.apply(lambda x:transform_time_all(x.loc['GameClock'],x.loc['Quarter']),axis=1)\n",
    "    test_single['TimeHandoff'] = test_single['TimeHandoff'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    test_single['TimeSnap'] = test_single['TimeSnap'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    test_single['handoff_snap_diff'] = (test_single['TimeHandoff'] - test_single['TimeSnap']).map(lambda x:x.seconds)\n",
    "    \n",
    "    # my original idea -----------\n",
    "    #test_single['WindSpeed'] = test_single['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n",
    "    #test_single['WindSpeed'] = test_single['WindSpeed'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n",
    "    #test_single['WindSpeed'] = test_single['WindSpeed'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n",
    "    #test_single['WindSpeed'] = test_single['WindSpeed'].apply(str_to_float)\n",
    "    \n",
    "    #test_single['WindDirection'] = test_single['WindDirection'].apply(lambda x: \"north\" if x == \"N\" or x == \"FROM S\"\n",
    "    #                                               else (\"south\" if x == 'S' or x== 'FROM N'\n",
    "    #                                               else (\"west\" if x == 'W' or x == 'FROM E'\n",
    "    #                                               else (\"east\" if x == 'E' or x == 'FROM W'\n",
    "    #                                               else (\"north east\" if x == 'FROM SW' or x == 'FROM SSW' or x == 'FROM WSW'\n",
    "    #                                               else (\"north west\" if x == 'FROM SE' or x == 'FROM SSE' or x == 'FROM ESE'\n",
    "    #                                               else (\"south east\" if x == 'FROM NW' or x == 'FROM NNW' or x == 'FROM WNW'\n",
    "    #                                               else (\"south west\" if x == 'FROM NE' or x == 'FROM NNE' or x == 'FROM ENE'\n",
    "    #                                               else (\"north west\" if x == 'NW' or x == 'NORTHWEST'\n",
    "    #                                               else (\"north east\" if x == 'NE' or x == 'NORTH EAST'\n",
    "    #                                               else (\"south west\" if x == 'SW' or x == 'SOUTHWEST'\n",
    "    #                                               else (\"south east\" if x == 'SE' or x == 'SOUTHEAST' else \"unknown\"))))))))))))\n",
    "    \n",
    "    #test_single['GameWeather'] = test_single['GameWeather'].apply(lambda x: \"rain\" if x in rain \n",
    "    #                                                    else (\"overcast\" if x in overcast\n",
    "    #                                                    else (\"clear\" if x in clear\n",
    "    #                                                    else (\"snow\" if x in snow\n",
    "    #                                                    else (\"indoor\" if x in none else \"unknown\")))))\n",
    "    \n",
    "    #test_single['StadiumType'] = test_single['StadiumType'].apply(lambda x: \"outdoor\" if x in outdoor \n",
    "    #                                                    else (\"indoor closed\" if x in indoor_closed\n",
    "    #                                                    else (\"indoor open\" if x in indoor_open\n",
    "    #                                                    else (\"dome_closed\" if x in dome_closed\n",
    "    #                                                    else (\"dome_open\" if x in dome_open else \"unknown\")))))\n",
    "    \n",
    "    test_single[\"Location\"] = test_single[\"Location\"].map(lambda x: \"Arlington, TX\" if x == \"Arlington, Texas\"\n",
    "                        else (\"Baltimore, MD\" if x == \"Baltimore, Maryland\" or x == \"Baltimore, Md.\"\n",
    "                        else (\"Charlotte, NC\" if x == \"Charlotte, North Carolina\"\n",
    "                        else (\"Chicago, IL\" if x == \"Chicago. IL\"\n",
    "                        else (\"Cincinnati, OH\" if x == \"Cincinnati, Ohio\"\n",
    "                        else (\"Cleveland, OH\" if x == \"Cleveland\" or x == \"Cleveland Ohio\" or x == \"Cleveland, Ohio\" or x == \"Cleveland,Ohio\"\n",
    "                        else (\"Detroit, MI\" if x == \"Detroit\"\n",
    "                        else (\"East Rutherford, NJ\" if x == \"E. Rutherford, NJ\" or x == \"East Rutherford, N.J.\"\n",
    "                        else (\"Foxborough, MA\" if x == \"Foxborough, Ma\"\n",
    "                        else (\"Houston, TX\" if x == \"Houston, Texas\"\n",
    "                        else (\"Jacksonville, FL\" if x == \"Jacksonville Florida\" or x == \"Jacksonville, Fl\" or x == \"Jacksonville, Florida\"\n",
    "                        else (\"London\" if x == \"London, England\"\n",
    "                        else (\"Los Angeles, CA\" if x == \"Los Angeles, Calif.\"\n",
    "                        else (\"Miami Gardens, FLA\" if x == \"Miami Gardens, Fla.\"\n",
    "                        else (\"New Orleans, LA\" if x == \"New Orleans\" or x == \"New Orleans, La.\"\n",
    "                        else (\"Orchard Park, NY\" if x == \"Orchard Park NY\"\n",
    "                        else (\"Philadelphia, PA\" if x == \"Philadelphia, Pa.\"\n",
    "                        else (\"Pittsburgh, PA\" if x == \"Pittsburgh\"\n",
    "                        else (\"Seattle, WA\" if x == \"Seattle\" else x)))))))))))))))))))\n",
    "    \n",
    "    test_single[\"Stadium\"] = test_single[\"Stadium\"].map(lambda x: \"Broncos Stadium at Mile High\" if x==\"Broncos Stadium At Mile High\" \n",
    "                                             else (\"CenturyLink Field\" if x == \"CenturyField\" or x == x==\"CenturyLink\"\n",
    "                                             else (\"Everbank Field\" if x == \"EverBank Field\"\n",
    "                                             else (\"FirstEnergy Stadium\" if x ==\"First Energy Stadium\" or x==\"FirstEnergy\" or x == \"FirstEnergyStadium\"\n",
    "                                             else (\"Lambeau Field\" if x == \"Lambeau field\"\n",
    "                                             else (\"Los Angeles Memorial Coliseum\" if x == \"Los Angeles Memorial Coliesum\"\n",
    "                                             else (\"M&T Bank Stadium\" if x == \"M & T Bank Stadium\" or x == \"M&T Stadium\"\n",
    "                                             else (\"Mercedes-Benz Superdome\" if x == \"Mercedes-Benz Dome\"\n",
    "                                             else (\"MetLife Stadium\" if x == \"MetLife\" or x == \"Metlife Stadium\"\n",
    "                                             else (\"NRG Stadium\" if x == \"NRG\"\n",
    "                                             else (\"Oakland-Alameda County Coliseum\" if x == \"Oakland Alameda-County Coliseum\"\n",
    "                                             else (\"Paul Brown Stadium\" if x == \"Paul Brown Stdium\"\n",
    "                                             else (\"Twickenham Stadium\" if x == \"Twickenham\" else x)))))))))))))\n",
    "    \n",
    "    test_single[\"OffenseFormation\"] = test_single[\"OffenseFormation\"].fillna(\"Unknown\") \n",
    "    test_single['DefendersInTheBox_vs_Distance'] = test_single['DefendersInTheBox'] / test['Distance']\n",
    "    \n",
    "    test_single[\"Turf\"] = test_single[\"Turf\"].map(lambda x: \"Artificial\" if x == \"Artifical\"\n",
    "                                       else (\"Field Turf\" if x == \"FieldTurf\" or x == \"Field turf\"\n",
    "                                       else (\"FieldTurf 360\" if x == \"FieldTurf360\"\n",
    "                                       else (\"Natural Grass\" if x == \"natural grass\" or x == \"Naturall Grass\" or x == \"Natural grass\" or x == \"Natural\"\n",
    "                                       else (\"Grass\" if x == \"grass\"\n",
    "                                       else (\"UBU Speed Series-S5-M\" if x == \"UBU Sports Speed S5-M\" else x))))))\n",
    "    \n",
    "    #arr = [[int(s[0]) for s in t.split(\", \")] for t in test_single[\"DefensePersonnel\"]]\n",
    "    #test_single[\"DefenseDL\"] = np.array([a[0] for a in arr])\n",
    "    #test_single[\"DefenseLB\"] = np.array([a[1] for a in arr])\n",
    "    #test_single[\"DefenseDB\"] = np.array([a[2] for a in arr])\n",
    "    #test_single[\"DefenseOL\"] = np.array([a[3] if len(a) == 4 else 0 for a in arr])\n",
    "    \n",
    "    # offense personnel -----\n",
    "    #test_single[\"OffenseRB\"] = test_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "    #                        int(x.replace(\",\", \"\").split(\" RB\")[0][-1]) if \"RB\" in x else 0)\n",
    "    #test_single[\"OffenseTE\"] = test_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "    #                        int(x.replace(\",\", \"\").split(\" TE\")[0][-1]) if \"TE\" in x else 0)\n",
    "    #test_single[\"OffenseWR\"] = test_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "    #                        int(x.replace(\",\", \"\").split(\" WR\")[0][-1]) if \"WR\" in x else 0)\n",
    "    #test_single[\"OffenseOL\"] = test_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "    #                        int(x.replace(\",\", \"\").split(\" OL\")[0][-1]) if \"OL\" in x else 0)\n",
    "    #test_single[\"OffenseDL\"] = test_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "    #                        int(x.replace(\",\", \"\").split(\" DL\")[0][-1]) if \"DL\" in x else 0)\n",
    "    #test_single[\"OffenseQB\"] = test_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "    #                        int(x.replace(\",\", \"\").split(\" QB\")[0][-1]) if \"QB\" in x else 0)\n",
    "    \n",
    "    test_single[\"NecDisPerDown\"] = test_single[\"Distance\"] / (5 - test_single[\"Down\"])\n",
    "    \n",
    "    test_single[\"Margin\"] = (test_single[\"HomeScoreBeforePlay\"] - \n",
    "                          test_single[\"VisitorScoreBeforePlay\"]) + 2 * (1 - (test_single[\"PossessionTeam\"] == \n",
    "                                                                  test_single[\"HomeTeamAbbr\"]).astype(int)) * (test_single[\"VisitorScoreBeforePlay\"] \n",
    "                                                                                                                - test_single[\"HomeScoreBeforePlay\"])\n",
    "    # my original idea -----------\n",
    "    test_single['date_game'] = test_single.GameId.map(lambda x:pd.to_datetime(str(x)[:8]))\n",
    "    test_single['runner_age'] = (test_single.date_game.map(pd.to_datetime) - test_single.PlayerBirthDate.map(pd.to_datetime)).map(lambda x:x.days)/365\n",
    "    test_single['runner_height'] = test_single.PlayerHeight.map(transform_height)\n",
    "    return test_single.drop(remove_features,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission file has been saved!  Once you `Commit` your Notebook and it finishes running, you can submit the file to the competition from the Notebook Viewer `Output` tab.\n"
     ]
    }
   ],
   "source": [
    "for (test_df, sample_prediction_df) in env.iter_test():\n",
    "    test_df['own_field'] = (test_df['FieldPosition'] == test_df['PossessionTeam']).astype(int)\n",
    "    dist_to_end_test = test_df.apply(lambda x:(100 - x.loc['YardLine']) if x.loc['own_field']==1 else x.loc['YardLine'],axis=1)\n",
    "    X_test = transform_test(test_df)\n",
    "    X_test.fillna(-999,inplace=True)\n",
    "    \n",
    "    # additional feature engineering -----------------------------------------------------------\n",
    "    tmp = test_df.groupby([\"PlayId\", \"OnOffense\"]).agg(np.mean)[[\"S\", \"X\", \"Y\", \"Age\"]]\n",
    "    X_test[\"DefenseAveSpeed\"] = np.array(tmp[0::2][\"S\"])\n",
    "    X_test[\"OffenseAveSpeed\"] = np.array(tmp[1::2][\"S\"])\n",
    "\n",
    "    X_test[\"DefenseAveX\"] = np.array(tmp[0::2][\"X\"])\n",
    "    X_test[\"OffenseAveX\"] = np.array(tmp[1::2][\"X\"])\n",
    "\n",
    "    X_test[\"DefenseAveY\"] = np.array(tmp[0::2][\"Y\"]) \n",
    "    X_test[\"OffenseAveY\"] = np.array(tmp[1::2][\"Y\"]) \n",
    "\n",
    "    X_test[\"DefenseAveAge\"] = np.array(tmp[0::2][\"Age\"])\n",
    "    X_test[\"OffenseAveAge\"] = np.array(tmp[1::2][\"Age\"])\n",
    "    \n",
    "    tmp = test_df.groupby([\"PlayId\", \"OnOffense\"]).agg([\"std\"])[[\"X\", \"Y\"]]\n",
    "    X_test[\"DefenseStdX\"] = np.array(tmp[0::2][\"X\"])\n",
    "    X_test[\"OffenseStdX\"] = np.array(tmp[1::2][\"X\"])\n",
    "\n",
    "    X_test[\"DefenseStdY\"] = np.array(tmp[0::2][\"Y\"])\n",
    "    X_test[\"OffenseStdY\"] = np.array(tmp[1::2][\"Y\"])\n",
    "\n",
    "    X_test[\"RunnerToDefenseCentoid\"] = np.sqrt((X_test[\"X\"] - X_test[\"DefenseAveX\"]) ** 2 + (X_test[\"Y\"] - X_test[\"DefenseAveY\"]) ** 2)\n",
    "    X_test[\"RunnerToOffenseCentoid\"] = np.sqrt((X_test[\"X\"] - X_test[\"OffenseAveX\"]) ** 2 + (X_test[\"Y\"] - X_test[\"OffenseAveY\"]) ** 2)\n",
    "\n",
    "    # defense x spread, offense x spread\n",
    "    tmp_max = test_df.groupby([\"PlayId\", \"OnOffense\"])[\"X\"].max()\n",
    "    tmp_min = test_df.groupby([\"PlayId\", \"OnOffense\"])[\"X\"].min()\n",
    "    X_test[\"DefenseSpreadX\"] = np.array(tmp_max[0::2]- tmp_min[0::2])\n",
    "    X_test[\"OffenseSpreadX\"] = np.array(tmp_max[1::2]- tmp_min[1::2])\n",
    "    \n",
    "    X_test[\"RunnerToScrimmage\"] = X_test[\"X\"] - X_test[\"YardLine\"]\n",
    "\n",
    "    # runner horizontal and vertical speed\n",
    "    radian_angle = (90 - X_test['Dir']) * np.pi / 180.0\n",
    "    X_test['v_horizontal'] = np.abs(X_test['S'] * np.cos(radian_angle))\n",
    "    X_test['v_vertical'] = np.abs(X_test['S'] * np.sin(radian_angle))\n",
    "\n",
    "    # runner horizontal and vertical momentum\n",
    "    X_test['m_horizontal'] = np.abs(X_test['Momentum'] * np.cos(radian_angle))\n",
    "    X_test['m_vertical'] = np.abs(X_test['Momentum'] * np.sin(radian_angle))\n",
    "\n",
    "    # minimum distance to rusher from defenders\n",
    "    X_test[\"MinDisFromRushToDef\"] = np.array(test_df.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].min()[0::2])\n",
    "\n",
    "    # tackle time from closest defender to rusher\n",
    "    X_test[\"MinTackleTime\"] = np.array(test_df.groupby([\"PlayId\", \"OnOffense\"])[\"TackleTimeToRusher\"].min()[0::2])\n",
    "\n",
    "    # average tackle time from all defenders to rusher\n",
    "    X_test[\"AveTackleTime\"] = np.array(test_df.groupby([\"PlayId\", \"OnOffense\"]).agg(np.mean)[\"TackleTimeToRusher\"][0::2])\n",
    "\n",
    "    # runner vs 1st defender speed: runner's velocity divided by closest defender's speed\n",
    "    X_test[\"RatioSRusherToCloseDef\"] = np.array(test_df.loc[test_df.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].idxmin()[0::2]][\"RatioSToRusher\"])\n",
    "    \n",
    "    # runner horizontal and vertical distance\n",
    "    X_test[\"dis_horizontal\"] = np.abs(X_test['Dis'] * np.cos(radian_angle))\n",
    "    X_test[\"dis_vertical\"] = np.abs(X_test['Dis'] * np.sin(radian_angle))\n",
    "    X_test[\"RunnerMoveRatio\"] = X_test[\"dis_horizontal\"] / X_test[\"dis_vertical\"]\n",
    "    \n",
    "    # the momentum of 1st closest defender to rusher, horizontal momentum, vertical momentum\n",
    "    X_test[\"DefMomentumCloToRusher\"] = np.array(test_df.loc[test_df.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].idxmin()[0::2]][\"Momentum\"])\n",
    "    X_test[\"DefMomentumCloToRusher_horizontal\"] = np.abs(X_test['DefMomentumCloToRusher'] * np.cos(radian_angle))\n",
    "    X_test[\"DefMomentumCloToRusher_vertical\"] = np.abs(X_test['DefMomentumCloToRusher'] * np.sin(radian_angle))\n",
    "\n",
    "    # the horizontal, vertical mometum of rusher\n",
    "    X_test[\"RusherMomentum_horizontal\"] =  np.abs(X_test['Momentum'] * np.cos(radian_angle))\n",
    "    X_test[\"RusherMomentum_vertical\"] =  np.abs(X_test['Momentum'] * np.sin(radian_angle))\n",
    "\n",
    "    # difference of horizontal momentum \n",
    "    X_test[\"hMomentum_rusher_vs_defender\"] = X_test[\"RusherMomentum_horizontal\"] - X_test[\"DefMomentumCloToRusher_horizontal\"]\n",
    "    \n",
    "    # voronoi area\n",
    "    pts = np.array(test_df[[\"X\", \"Y\"]]).reshape(test_df.shape[0]//22, 22, 2)\n",
    "    # index of row where rusher data is included when separated by each play\n",
    "    rusher_index = list(test_df[test_df.is_run==True].index % 22) \n",
    "    closest_def_index = list(test_df.loc[test_df.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].idxmin()[0::2]].index % 22)\n",
    "    rusher_voronoi = []\n",
    "    closest_def_voronoi = []\n",
    "    for i in range(0, test_df.shape[0] //22):\n",
    "        rusher_voronoi.append(voronoi_volumes(pts[i], rusher_index[i]))\n",
    "        closest_def_voronoi.append(voronoi_volumes(pts[i], closest_def_index[i]))\n",
    "    X_test[\"RusherVoronoi\"] = rusher_voronoi    \n",
    "    X_test[\"FirstDefenderVoronoi\"] = closest_def_voronoi \n",
    "    \n",
    "    # ------------------------------------------------------\n",
    "    for f in X_test.columns:\n",
    "        if X_test[f].dtype=='object':\n",
    "            X_test[f] = X_test[f].map(lambda x:x if x in set(X_train[f]) else -999)\n",
    "    for f in X_test.columns:\n",
    "        if X_test[f].dtype=='object': \n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(X_train[f])+[-999])\n",
    "            X_test[f] = lbl.transform(list(X_test[f])) \n",
    "    pred_value = 0\n",
    "    for model in models:\n",
    "        pred_value += model.predict(X_test)[0]/5\n",
    "    pred_data = list(get_score(pred_value,cdf,4,dist_to_end_test.values[0]))\n",
    "    pred_data = np.array(pred_data).reshape(1,199)\n",
    "    pred_target = pd.DataFrame(index = sample_prediction_df.index, \\\n",
    "                               columns = sample_prediction_df.columns, \\\n",
    "                               #data = np.array(pred_data))\n",
    "                               data = pred_data)\n",
    "    env.predict(pred_target)\n",
    "env.write_submission_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
