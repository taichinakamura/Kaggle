{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import combinations,permutations\n",
    "from sklearn.tree import *\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import random\n",
    "from math import floor\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "data_path = Path(\"/kaggle/input/abstraction-and-reasoning-challenge\")\n",
    "train_path = data_path/'training'\n",
    "test_path = data_path/'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(inp,eoup,oup):\n",
    "    \"\"\"\n",
    "    Plots the first train and test pairs of a specified task,\n",
    "    using same color scheme as the ARC app\n",
    "    \"\"\"\n",
    "    cmap = colors.ListedColormap(\n",
    "        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "    norm = colors.Normalize(vmin=0, vmax=9)\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15,15))\n",
    "    \n",
    "    axs[0].imshow(inp, cmap=cmap, norm=norm)\n",
    "    axs[0].axis('off')\n",
    "    axs[0].set_title('Input')\n",
    "\n",
    "    axs[1].imshow(eoup, cmap=cmap, norm=norm)\n",
    "    axs[1].axis('off')\n",
    "    axs[1].set_title('Output')\n",
    "    \n",
    "    axs[2].imshow(oup, cmap=cmap, norm=norm)\n",
    "    axs[2].axis('off')\n",
    "    axs[2].set_title('Model prediction')\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_mats(mats):\n",
    "    cmap = colors.ListedColormap(\n",
    "        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "    norm = colors.Normalize(vmin=0, vmax=9)\n",
    "    fig, axs = plt.subplots(1, len(mats), figsize=(15,15))\n",
    "    \n",
    "    for i in range(len(mats)):\n",
    "        axs[i].imshow(mats[i], cmap=cmap, norm=norm)\n",
    "        axs[i].axis('off')\n",
    "        axs[i].set_title('Fig: '+str(i))\n",
    "    \n",
    "    plt.rc('grid', linestyle=\"-\", color='white')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getiorc(pair):\n",
    "    inp = pair[\"input\"]\n",
    "    return pair[\"input\"],pair[\"output\"],len(inp),len(inp[0])\n",
    "    \n",
    "def getAround(i,j,inp,size=1):\n",
    "    #v = [-1,-1,-1,-1,-1,-1,-1,-1,-1]\n",
    "    r,c = len(inp),len(inp[0])\n",
    "    v = []\n",
    "    sc = [0]\n",
    "    for q in range(size):\n",
    "        sc.append(q+1)\n",
    "        sc.append(-(q+1))\n",
    "    for idx,(x,y) in enumerate(product(sc,sc)):\n",
    "        ii = (i+x)\n",
    "        jj = (j+y)\n",
    "        v.append(-1)\n",
    "        if((0<= ii < r) and (0<= jj < c)):\n",
    "            v[idx] = (inp[ii][jj])\n",
    "    return v\n",
    "\n",
    "def getDiagonal(i,j,r,c):\n",
    "    return\n",
    "        \n",
    "    \n",
    "def getX(inp,i,j,size):\n",
    "    z = []\n",
    "    n_inp = np.array(inp)\n",
    "    z.append(i)\n",
    "    z.append(j)\n",
    "    r,c = len(inp),len(inp[0])\n",
    "    for m in range(5):\n",
    "        z.append(i%(m+1))\n",
    "        z.append(j%(m+1))\n",
    "    z.append(i+j)\n",
    "    z.append(i*j)\n",
    "#     z.append(i%j)\n",
    "#     z.append(j%i)\n",
    "    z.append((i+1)/(j+1))\n",
    "    z.append((j+1)/(i+1))\n",
    "    z.append(r)\n",
    "    z.append(c)\n",
    "    z.append(len(np.unique(n_inp[i,:])))\n",
    "    z.append(len(np.unique(n_inp[:,j])))\n",
    "    arnd = getAround(i,j,inp,size)\n",
    "    z.append(len(np.unique(arnd)))\n",
    "    z.extend(arnd)\n",
    "    return z\n",
    "\n",
    "def getXy(inp,oup,size):\n",
    "    x = []\n",
    "    y = []\n",
    "    r,c = len(inp),len(inp[0])\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            x.append(getX(inp,i,j,size))\n",
    "            y.append(oup[i][j])\n",
    "    return x,y\n",
    "    \n",
    "def getBkgColor(task_json):\n",
    "    color_dict = defaultdict(int)\n",
    "    \n",
    "    for pair in task_json['train']:\n",
    "        inp,oup,r,c = getiorc(pair)\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                color_dict[inp[i][j]]+=1\n",
    "    color = -1\n",
    "    max_count = 0\n",
    "    for col,cnt in color_dict.items():\n",
    "        if(cnt > max_count):\n",
    "            color = col\n",
    "            max_count = cnt\n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_colors(inp,oup,bl_cols):\n",
    "    r,c = len(inp),len(inp[0])\n",
    "    return \n",
    "\n",
    "def replace(inp,uni,perm):\n",
    "    # uni = '234' perm = ['5','7','9']\n",
    "    #print(uni,perm)\n",
    "    r_map = { int(c):int(s) for c,s in zip(uni,perm)}\n",
    "    r,c = len(inp),len(inp[0])\n",
    "    rp = np.array(inp).tolist()\n",
    "    #print(rp)\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            if(rp[i][j] in r_map):\n",
    "                rp[i][j] = r_map[rp[i][j]]\n",
    "    return rp\n",
    "            \n",
    "    \n",
    "def augment(inp,oup,bl_cols):\n",
    "    cols = \"0123456789\"\n",
    "    npr_map = [1,9,72,3024,15120,60480,181440,362880,362880]\n",
    "    uni = \"\".join([str(x) for x in np.unique(inp).tolist()])\n",
    "    for c in bl_cols:\n",
    "        cols=cols.replace(str(c),\"\")\n",
    "        uni=uni.replace(str(c),\"\")\n",
    "\n",
    "    exp_size = len(inp)*len(inp[0])*npr_map[len(uni)]\n",
    "    \n",
    "    mod = floor(exp_size/120000)\n",
    "    mod = 1 if mod==0 else mod\n",
    "    \n",
    "    #print(exp_size,mod,len(uni))\n",
    "    result = []\n",
    "    count = 0\n",
    "    for comb in combinations(cols,len(uni)):\n",
    "        for perm in permutations(comb):\n",
    "            count+=1\n",
    "            if(count % mod == 0):\n",
    "                result.append((replace(inp,uni,perm),replace(oup,uni,perm)))\n",
    "    return result\n",
    "            \n",
    "def get_flips(inp,oup):\n",
    "    result = []\n",
    "    n_inp = np.array(inp)\n",
    "    n_oup = np.array(oup)\n",
    "    result.append((np.fliplr(inp).tolist(),np.fliplr(oup).tolist()))\n",
    "    result.append((np.rot90(np.fliplr(inp),1).tolist(),np.rot90(np.fliplr(oup),1).tolist()))\n",
    "    result.append((np.rot90(np.fliplr(inp),2).tolist(),np.rot90(np.fliplr(oup),2).tolist()))\n",
    "    result.append((np.rot90(np.fliplr(inp),3).tolist(),np.rot90(np.fliplr(oup),3).tolist()))\n",
    "    result.append((np.flipud(inp).tolist(),np.flipud(oup).tolist()))\n",
    "    result.append((np.rot90(np.flipud(inp),1).tolist(),np.rot90(np.flipud(oup),1).tolist()))\n",
    "    result.append((np.rot90(np.flipud(inp),2).tolist(),np.rot90(np.flipud(oup),2).tolist()))\n",
    "    result.append((np.rot90(np.flipud(inp),3).tolist(),np.rot90(np.flipud(oup),3).tolist()))\n",
    "    result.append((np.fliplr(np.flipud(inp)).tolist(),np.fliplr(np.flipud(oup)).tolist()))\n",
    "    result.append((np.flipud(np.fliplr(inp)).tolist(),np.flipud(np.fliplr(oup)).tolist()))\n",
    "    return result\n",
    "    \n",
    "def gettaskxy(task_json,aug,around_size,bl_cols,flip=True):    \n",
    "    X = []\n",
    "    Y = []\n",
    "    for pair in task_json['train']:\n",
    "        inp,oup=pair[\"input\"],pair[\"output\"]\n",
    "        tx,ty = getXy(inp,oup,around_size)\n",
    "        X.extend(tx)\n",
    "        Y.extend(ty)\n",
    "        if(flip):\n",
    "            for ainp,aoup in get_flips(inp,oup):\n",
    "                tx,ty = getXy(ainp,aoup,around_size)\n",
    "                X.extend(tx)\n",
    "                Y.extend(ty)\n",
    "                if(aug):\n",
    "                    augs = augment(ainp,aoup,bl_cols)\n",
    "                    for ainp,aoup in augs:\n",
    "                        tx,ty = getXy(ainp,aoup,around_size)\n",
    "                        X.extend(tx)\n",
    "                        Y.extend(ty)\n",
    "        if(aug):\n",
    "            augs = augment(inp,oup,bl_cols)\n",
    "            for ainp,aoup in augs:\n",
    "                tx,ty = getXy(ainp,aoup,around_size)\n",
    "                X.extend(tx)\n",
    "                Y.extend(ty)\n",
    "    return X,Y\n",
    "\n",
    "def test_predict(task_json,model,size):\n",
    "    inp = task_json['test'][0]['input']\n",
    "    eoup = task_json['test'][0]['output']\n",
    "    r,c = len(inp),len(inp[0])\n",
    "    oup = predict(inp,model,size)\n",
    "    return inp,eoup,oup\n",
    "\n",
    "def predict(inp,model,size):\n",
    "    r,c = len(inp),len(inp[0])\n",
    "    oup = np.zeros([r,c],dtype=int)\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            x = getX(inp,i,j,size)\n",
    "            o = int(model.predict([x]))\n",
    "            o = 0 if o<0 else o\n",
    "            oup[i][j]=o\n",
    "    return oup\n",
    "\n",
    "def submit_predict(task_json,model,size):\n",
    "    pred_map = {}\n",
    "    idx=0\n",
    "    for pair in task_json['test']:\n",
    "        inp = pair[\"input\"]\n",
    "        oup = predict(inp,model,size)\n",
    "        pred_map[idx] = oup.tolist()\n",
    "        idx+=1\n",
    "        #plot_result(inp,oup,oup)\n",
    "    return pred_map\n",
    "\n",
    "def dumb_predict(task_json):\n",
    "    pred_map = {}\n",
    "    idx=0\n",
    "    for pair in task_json['test']:\n",
    "        inp = pair[\"input\"]\n",
    "        pred_map[idx] = [[0,0],[0,0]]\n",
    "        idx+=1\n",
    "    return pred_map\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model,task_json,size):\n",
    "    total = 0\n",
    "    for pair in task_json['train']:\n",
    "        inp,oup=pair[\"input\"],pair[\"output\"]\n",
    "        eoup = predict(inp,model,size)\n",
    "        total+= np.sum((np.array(oup) != np.array(eoup)))\n",
    "    return total\n",
    "\n",
    "def get_test_loss(model,task_json,size):\n",
    "    total = 0\n",
    "    for pair in task_json['test']:\n",
    "        inp,oup=pair[\"input\"],pair[\"output\"]\n",
    "        eoup = predict(inp,model,size)\n",
    "        total+= np.sum((np.array(oup) != np.array(eoup)))\n",
    "    return total\n",
    "\n",
    "def get_a_size(task_json):\n",
    "    return 4;\n",
    "\n",
    "def get_bl_cols(task_json):\n",
    "    result = []\n",
    "    bkg_col = getBkgColor(task_json);\n",
    "    result.append(bkg_col)\n",
    "    # num_input,input_cnt,num_output,output_cnt\n",
    "    met_map = {}\n",
    "    for i in range(10):\n",
    "        met_map[i] = [0,0,0,0]\n",
    "        \n",
    "    total_ex = 0\n",
    "    for pair in task_json['train']:\n",
    "        inp,oup=pair[\"input\"],pair[\"output\"]\n",
    "        u,uc = np.unique(inp, return_counts=True)\n",
    "        inp_cnt_map = dict(zip(u,uc))\n",
    "        u,uc = np.unique(oup, return_counts=True)\n",
    "        oup_cnt_map = dict(zip(u,uc))\n",
    "        \n",
    "        for col,cnt in inp_cnt_map.items():\n",
    "            met_map[col][0] = met_map[col][0] + 1\n",
    "            met_map[col][1] = met_map[col][1] + cnt\n",
    "        for col,cnt in oup_cnt_map.items():\n",
    "            met_map[col][2] = met_map[col][2] + 1\n",
    "            met_map[col][3] = met_map[col][3] + cnt\n",
    "        total_ex+=1\n",
    "    \n",
    "    for col,met in met_map.items():\n",
    "        num_input,input_cnt,num_output,output_cnt = met\n",
    "        if(num_input == total_ex or num_output == total_ex):\n",
    "            result.append(col)\n",
    "        elif(num_input == 0 and num_output > 0):\n",
    "            result.append(col)\n",
    "    \n",
    "    result = np.unique(result).tolist()\n",
    "    if(len(result) == 10):\n",
    "        result.append(bkg_col)\n",
    "    return np.unique(result).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattener(pred):\n",
    "    str_pred = str([row for row in pred])\n",
    "    str_pred = str_pred.replace(', ', '')\n",
    "    str_pred = str_pred.replace('[[', '|')\n",
    "    str_pred = str_pred.replace('][', '|')\n",
    "    str_pred = str_pred.replace(']]', '|')\n",
    "    return str_pred\n",
    "\n",
    "def combine_preds(tid,pm1,pm2):\n",
    "    result = []\n",
    "    for i in range(len(pm1)):\n",
    "        tk_s = tid+\"_\"+str(i)\n",
    "        str_pred = flattener(pm1[i])+\" \"+flattener(pm2[i])\n",
    "        #print(tk_s,str_pred)\n",
    "        result.append([tk_s,str_pred])\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19bb5feb\n",
      "358ba94e\n",
      "2753e76c\n",
      "27a77e38\n",
      "09c534e7\n",
      "16b78196\n",
      "2072aba6\n",
      "3d31c5b3\n",
      "34b99a2b\n",
      "103eff5b\n",
      "22a4bbc2\n",
      "40f6cd08\n",
      "15663ba9\n",
      "14754a24\n",
      "136b0064\n",
      "03560426\n",
      "184a9768\n",
      "0607ce86\n",
      "2546ccf6\n",
      "15696249\n",
      "31adaf00\n",
      "423a55dc\n",
      "31d5ba1a\n",
      "27f8ce4f\n",
      "1e81d6f9\n",
      "256b0a75\n",
      "29700607\n",
      "0e671a1a\n",
      "2b01abd0\n",
      "281123b4\n",
      "2685904e\n",
      "351d6448\n",
      "3f23242b\n",
      "140c817e\n",
      "0c9aba6e\n",
      "292dd178\n",
      "0f63c0b9\n",
      "3391f8c0\n",
      "12eac192\n",
      "15113be4\n",
      "1a2e2828\n",
      "2f0c5170\n",
      "11e1fe23\n",
      "2c0b0aff\n",
      "2697da3f\n",
      "12997ef3\n",
      "0becf7df\n",
      "3ed85e70\n",
      "1d398264\n",
      "2c737e39\n",
      "1d0a4b61\n",
      "0bb8deee\n",
      "332efdb3\n",
      "3194b014\n",
      "18419cfa\n",
      "17cae0c1\n",
      "1990f7a8\n",
      "0934a4d8\n",
      "3a301edc\n",
      "05a7bcf2\n",
      "08573cc6\n",
      "0b17323b\n",
      "1da012fc\n",
      "32e9702f\n",
      "0c786b71\n",
      "00576224\n",
      "25094a63\n",
      "0692e18c\n",
      "1c0d0a4b\n",
      "3979b1a8\n",
      "20981f0e\n",
      "3b4c2228\n",
      "33b52de3\n",
      "13713586\n",
      "137f0df0\n",
      "414297c0\n",
      "17b80ad2\n",
      "1acc24af\n",
      "1c02dbbe\n",
      "212895b5\n",
      "12422b43\n",
      "2a5f8217\n",
      "3490cc26\n",
      "070dd51e\n",
      "0d87d2a6\n",
      "009d5c81\n",
      "1e97544e\n",
      "00dbd492\n",
      "37d3e8b2\n",
      "319f2597\n",
      "195ba7dc\n",
      "1a6449f1\n",
      "1c56ad9f\n",
      "2037f2c7\n",
      "20818e16\n",
      "310f3251\n",
      "21f83797\n",
      "0a1d4ef5\n",
      "0a2355a6\n",
      "3ee1011a\n"
     ]
    }
   ],
   "source": [
    "def inp_oup_dim_same(task_json):\n",
    "    return all([ len(pair[\"input\"]) == len(pair[\"output\"]) and len(pair[\"input\"][0]) == len(pair[\"output\"][0])\n",
    "                for pair in task_json['train']])\n",
    "    \n",
    "\n",
    "solved_task = 0\n",
    "total_task = 0\n",
    "task_ids = []\n",
    "task_preds = []\n",
    "for task_path in test_path.glob(\"*.json\"):\n",
    "    task_json = json.load(open(task_path))\n",
    "    tk_id = str(task_path).split(\"/\")[-1].split(\".\")[0]\n",
    "    print(tk_id)\n",
    "    if(inp_oup_dim_same(task_json)):\n",
    "        a_size = get_a_size(task_json)\n",
    "        bl_cols = get_bl_cols(task_json)\n",
    "        \n",
    "        isflip = False\n",
    "        X1,Y1 = gettaskxy(task_json,True,1,bl_cols,isflip)\n",
    "        X3,Y3 = gettaskxy(task_json,True,3,bl_cols,isflip)\n",
    "        X5,Y5 = gettaskxy(task_json,True,5,bl_cols,isflip)\n",
    "        \n",
    "        model_1 = BaggingClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=100).fit(X1, Y1)\n",
    "        #model_3 = BaggingClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=100).fit(X3, Y3)\n",
    "        model_5 = BaggingClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=100).fit(X5, Y5)\n",
    "        \n",
    "        pred_map_1 = submit_predict(task_json,model_1,1)\n",
    "        #pred_map_3 = submit_predict(task_json,model_3,3)\n",
    "        pred_map_5 = submit_predict(task_json,model_5,5)\n",
    "        \n",
    "        for tks,str_pred in combine_preds(tk_id,pred_map_1,pred_map_5):\n",
    "            task_ids.append(tks)\n",
    "            task_preds.append(str_pred)\n",
    "            #print(tks,str_pred)\n",
    "        solved_task+=1\n",
    "        #break\n",
    "    else:\n",
    "        pred_map_1 = dumb_predict(task_json)\n",
    "        #pred_map_3 = dumb_predict(task_json)\n",
    "        pred_map_5 = dumb_predict(task_json)\n",
    "        \n",
    "        for tks,str_pred in combine_preds(tk_id,pred_map_1,pred_map_5):\n",
    "            task_ids.append(tks)\n",
    "            task_preds.append(str_pred)\n",
    "            #print(tks,str_pred)\n",
    "        \n",
    "    total_task+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub1 = pd.DataFrame({\"output_id\":task_ids,'output':task_preds})\n",
    "#sample_sub1.to_csv(\"submission.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# method2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19bb5feb.json\n",
      "358ba94e.json\n",
      "2753e76c.json\n",
      "27a77e38.json\n",
      "09c534e7.json\n",
      "16b78196.json\n",
      "2072aba6.json\n",
      "3d31c5b3.json\n",
      "34b99a2b.json\n",
      "103eff5b.json\n",
      "22a4bbc2.json\n",
      "40f6cd08.json\n",
      "15663ba9.json\n",
      "14754a24.json\n",
      "136b0064.json\n",
      "03560426.json\n",
      "184a9768.json\n",
      "0607ce86.json\n",
      "2546ccf6.json\n",
      "15696249.json\n",
      "31adaf00.json\n",
      "423a55dc.json\n",
      "31d5ba1a.json\n",
      "27f8ce4f.json\n",
      "1e81d6f9.json\n",
      "256b0a75.json\n",
      "29700607.json\n",
      "0e671a1a.json\n",
      "2b01abd0.json\n",
      "281123b4.json\n",
      "2685904e.json\n",
      "351d6448.json\n",
      "3f23242b.json\n",
      "140c817e.json\n",
      "0c9aba6e.json\n",
      "292dd178.json\n",
      "0f63c0b9.json\n",
      "3391f8c0.json\n",
      "12eac192.json\n",
      "15113be4.json\n",
      "1a2e2828.json\n",
      "2f0c5170.json\n",
      "11e1fe23.json\n",
      "2c0b0aff.json\n",
      "2697da3f.json\n",
      "12997ef3.json\n",
      "0becf7df.json\n",
      "3ed85e70.json\n",
      "1d398264.json\n",
      "2c737e39.json\n",
      "1d0a4b61.json\n",
      "0bb8deee.json\n",
      "332efdb3.json\n",
      "3194b014.json\n",
      "18419cfa.json\n",
      "17cae0c1.json\n",
      "1990f7a8.json\n",
      "0934a4d8.json\n",
      "3a301edc.json\n",
      "05a7bcf2.json\n",
      "08573cc6.json\n",
      "0b17323b.json\n",
      "1da012fc.json\n",
      "32e9702f.json\n",
      "0c786b71.json\n",
      "00576224.json\n",
      "25094a63.json\n",
      "0692e18c.json\n",
      "1c0d0a4b.json\n",
      "3979b1a8.json\n",
      "20981f0e.json\n",
      "3b4c2228.json\n",
      "33b52de3.json\n",
      "13713586.json\n",
      "137f0df0.json\n",
      "414297c0.json\n",
      "17b80ad2.json\n",
      "1acc24af.json\n",
      "1c02dbbe.json\n",
      "212895b5.json\n",
      "12422b43.json\n",
      "2a5f8217.json\n",
      "3490cc26.json\n",
      "070dd51e.json\n",
      "0d87d2a6.json\n",
      "009d5c81.json\n",
      "1e97544e.json\n",
      "00dbd492.json\n",
      "37d3e8b2.json\n",
      "319f2597.json\n",
      "195ba7dc.json\n",
      "1a6449f1.json\n",
      "1c56ad9f.json\n",
      "2037f2c7.json\n",
      "20818e16.json\n",
      "310f3251.json\n",
      "21f83797.json\n",
      "0a1d4ef5.json\n",
      "0a2355a6.json\n",
      "3ee1011a.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def comparematrixes(a,b):\n",
    "    out=0;\n",
    "    for i in range(min(len(a),len(b))):\n",
    "        for j in range(min(len(a[0]),len(b[0]))):\n",
    "            if a[i][j]==b[i][j]:\n",
    "                out+=1\n",
    "    out/=len(a)*len(a[0]);\n",
    "    return 1-out\n",
    "\n",
    "def proces(parsedjson,filename):\n",
    "    #random.seed(0);\n",
    "    ines=[]\n",
    "    outes=[]\n",
    "    for i in range(len(parsedjson[\"train\"])):\n",
    "        vx=parsedjson[\"train\"][i][\"input\"].copy()\n",
    "        vi=parsedjson[\"train\"][i][\"output\"].copy()\n",
    "        for k1 in range(min(len(vx),len(vi))):\n",
    "            for k2 in range(min(len(vx[0]),len(vi[0]))):\n",
    "                dtm=[]\n",
    "                for k3 in range(-2,2+1,1):\n",
    "                    for k4 in range(-2,2+1,1):\n",
    "                        if(k1+k3<len(vx) and k1+k3>=0 and k2+k4<len(vx[0]) and k2+k4>=0 and k1+k3<len(vi) and k1+k3>=0 and k2+k4<len(vi[0]) and k2+k4>=0):\n",
    "                            td=[0,0,0,0,0,0,0,0,0,0,0]\n",
    "                            td[vx[k1+k3][k2+k4]]=1\n",
    "                            dtm+=td.copy()\n",
    "                            td=[0,0,0,0,0,0,0,0,0,0,0]\n",
    "                            td[vi[k1+k3][k2+k4]]=1\n",
    "                            dtm+=td.copy()\n",
    "                        else:\n",
    "                            dtm+=[0,0,0,0,0,0,0,0,0,0,0]\n",
    "                            dtm+=[0,0,0,0,0,0,0,0,0,0,0]\n",
    "                ines.append(dtm);\n",
    "                if(len(vi)>k1 and len(vi[0])>k2 and k1>=0 and k2>=0):\n",
    "                    outes.append(vi[k1][k2])\n",
    "                else:\n",
    "                    print(len(vi),k1)\n",
    "                    outes.append(0)\n",
    "    #print(dates[30]);\n",
    "    knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "    ines=json.loads(json.dumps(ines))\n",
    "    #print(ines);\n",
    "    knn.fit(ines,outes)\n",
    "    out=[]\n",
    "    for i in range(len(parsedjson[\"test\"])):\n",
    "        thisdone=False\n",
    "        vx=parsedjson[\"test\"][i][\"input\"].copy()\n",
    "        vi=parsedjson[\"test\"][i][\"input\"].copy()\n",
    "        for U in range(20):\n",
    "            for k1 in range(len(vx)):\n",
    "                for k2 in range(len(vx[0])):\n",
    "                    dtm=[]\n",
    "                    for k3 in range(-2,2+1,1):\n",
    "                        for k4 in range(-2,2+1,1):\n",
    "                            if(k1+k3<len(vx) and k1+k3>=0 and k2+k4<len(vx[0]) and k2+k4>=0 and k1+k3<len(vi) and k1+k3>=0 and k2+k4<len(vi[0]) and k2+k4>=0):\n",
    "                                td = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "                                td[vx[k1+k3][k2+k4]]=1\n",
    "                                dtm+=td.copy()\n",
    "                                td = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "                                td[vi[k1+k3][k2+k4]]=1\n",
    "                                dtm+=td.copy()\n",
    "                            else:\n",
    "                                dtm+=[0,0,0,0,0,0,0,0,0,0,0]\n",
    "                                dtm+=[0,0,0,0,0,0,0,0,0,0,0]\n",
    "                    vi[k1][k2]=int(knn.predict([dtm])[0])\n",
    "            vx=vi.copy()\n",
    "        b=vx\n",
    "        out=out+[\n",
    "            filename.replace('.json','_'+str(i))+','+\n",
    "          json.dumps(b).replace(', ', '').replace('[[', '|')\n",
    "            .replace('][', '|').replace(']]', '|')+'\\n' ]\n",
    "    return out\n",
    "\n",
    "import os\n",
    "if os.path.exists(\"submission.csv\"):\n",
    "    os.remove(\"submission.csv\")\n",
    "tofile = []\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/abstraction-and-reasoning-challenge/test'):\n",
    "    for filename in filenames:\n",
    "        parsed=json.loads(open('/kaggle/input/abstraction-and-reasoning-challenge/test/'+filename, \"r\").read())\n",
    "        print(filename)\n",
    "        tofile=tofile+proces(parsed,filename)\n",
    "tofile.sort()\n",
    "\n",
    "task_preds2 = [i.split(\",\")[1][:-1] for i in tofile]\n",
    "task_ids2 = [i.split(\",\")[0] for i in tofile]\n",
    "sample_sub2 = pd.DataFrame({\"output_id\":task_ids2,'output':task_preds2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sub = sample_sub1\n",
    "final_sub = final_sub.sort_values(by=\"output_id\").reset_index(drop=True)\n",
    "\n",
    "sample_sub2 = sample_sub2.sort_values(by=\"output_id\")\n",
    "out1 = final_sub[\"output\"].astype(str).values\n",
    "out2 = sample_sub2[\"output\"].astype(str).values\n",
    "\n",
    "merge_output = []\n",
    "for o1, o2 in zip(out1, out2):\n",
    "    o = o1.strip().split(\" \")[:2] + o2.strip().split(\" \")[:1]\n",
    "    o = \" \".join(o[:3])\n",
    "    merge_output.append(o)\n",
    "    \n",
    "final_sub[\"output\"] = merge_output\n",
    "final_sub[\"output\"] = final_sub[\"output\"].astype(str)\n",
    "final_sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
