{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "In this approach we use Bag of decision trees.\n",
    "**Features:**\n",
    "\n",
    "Surrouding cells for a given cell.\n",
    "\n",
    "**Data Augmentation**\n",
    "* Background color is detected using custom logic.\n",
    "* Custom logic is written to find the colors which need to be excempted from augmentation.\n",
    " * All the colors which are present in all the input of training exmaples are marked for excemption.\n",
    " * Color which is not present in input but present in output are excepted.\n",
    "* For rest of colors all permutations are used to augment.\n",
    "\n",
    "**Model** \n",
    "\n",
    " Bag of decision trees are used since, single decision tree have some randomness factor which may give incorrect result.\n",
    " \n",
    " **Result**\n",
    " \n",
    " Training: Solved 41/400\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import combinations,permutations\n",
    "from sklearn.tree import *\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import random\n",
    "from math import floor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "data_path = Path(\"/kaggle/input/abstraction-and-reasoning-challenge\")\n",
    "train_path = data_path/'training'\n",
    "test_path = data_path/'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(inp,eoup,oup):\n",
    "    \"\"\"\n",
    "    Plots the first train and test pairs of a specified task,\n",
    "    using same color scheme as the ARC app\n",
    "    \"\"\"\n",
    "    cmap = colors.ListedColormap(\n",
    "        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "    norm = colors.Normalize(vmin=0, vmax=9)\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15,15))\n",
    "    \n",
    "    axs[0].imshow(inp, cmap=cmap, norm=norm)\n",
    "    axs[0].axis('off')\n",
    "    axs[0].set_title('Input')\n",
    "\n",
    "    axs[1].imshow(eoup, cmap=cmap, norm=norm)\n",
    "    axs[1].axis('off')\n",
    "    axs[1].set_title('Output')\n",
    "    \n",
    "    axs[2].imshow(oup, cmap=cmap, norm=norm)\n",
    "    axs[2].axis('off')\n",
    "    axs[2].set_title('Model prediction')\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_mats(mats):\n",
    "    cmap = colors.ListedColormap(\n",
    "        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "    norm = colors.Normalize(vmin=0, vmax=9)\n",
    "    fig, axs = plt.subplots(1, len(mats), figsize=(15,15))\n",
    "    \n",
    "    for i in range(len(mats)):\n",
    "        axs[i].imshow(mats[i], cmap=cmap, norm=norm)\n",
    "        axs[i].axis('off')\n",
    "        axs[i].set_title('Fig: '+str(i))\n",
    "    \n",
    "    plt.rc('grid', linestyle=\"-\", color='white')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getiorc(pair):\n",
    "    inp = pair[\"input\"]\n",
    "    return pair[\"input\"],pair[\"output\"],len(inp),len(inp[0])\n",
    "    \n",
    "def getAround(i,j,inp,size=1):\n",
    "    #v = [-1,-1,-1,-1,-1,-1,-1,-1,-1]\n",
    "    r,c = len(inp),len(inp[0])\n",
    "    v = []\n",
    "    sc = [0]\n",
    "    for q in range(size):\n",
    "        sc.append(q+1)\n",
    "        sc.append(-(q+1))\n",
    "    for idx,(x,y) in enumerate(product(sc,sc)):\n",
    "        ii = (i+x)\n",
    "        jj = (j+y)\n",
    "        v.append(-1)\n",
    "        if((0<= ii < r) and (0<= jj < c)):\n",
    "            v[idx] = (inp[ii][jj])\n",
    "    return v\n",
    "\n",
    "def getDiagonal(i,j,r,c):\n",
    "    return\n",
    "        \n",
    "    \n",
    "def getX(inp,i,j,size):\n",
    "    z = []\n",
    "    n_inp = np.array(inp)\n",
    "    z.append(i)\n",
    "    z.append(j)\n",
    "    r,c = len(inp),len(inp[0])\n",
    "    for m in range(5):\n",
    "        z.append(i%(m+1))\n",
    "        z.append(j%(m+1))\n",
    "    z.append(i+j)\n",
    "    z.append(i*j)\n",
    "#     z.append(i%j)\n",
    "#     z.append(j%i)\n",
    "    z.append((i+1)/(j+1))\n",
    "    z.append((j+1)/(i+1))\n",
    "    z.append(r)\n",
    "    z.append(c)\n",
    "    z.append(len(np.unique(n_inp[i,:])))\n",
    "    z.append(len(np.unique(n_inp[:,j])))\n",
    "    arnd = getAround(i,j,inp,size)\n",
    "    z.append(len(np.unique(arnd)))\n",
    "    z.extend(arnd)\n",
    "    return z\n",
    "\n",
    "def getXy(inp,oup,size):\n",
    "    x = []\n",
    "    y = []\n",
    "    r,c = len(inp),len(inp[0])\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            x.append(getX(inp,i,j,size))\n",
    "            y.append(oup[i][j])\n",
    "    return x,y\n",
    "    \n",
    "def getBkgColor(task_json):\n",
    "    color_dict = defaultdict(int)\n",
    "    \n",
    "    for pair in task_json['train']:\n",
    "        inp,oup,r,c = getiorc(pair)\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                color_dict[inp[i][j]]+=1\n",
    "    color = -1\n",
    "    max_count = 0\n",
    "    for col,cnt in color_dict.items():\n",
    "        if(cnt > max_count):\n",
    "            color = col\n",
    "            max_count = cnt\n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_colors(inp,oup,bl_cols):\n",
    "    r,c = len(inp),len(inp[0])\n",
    "    return \n",
    "\n",
    "def replace(inp,uni,perm):\n",
    "    # uni = '234' perm = ['5','7','9']\n",
    "    #print(uni,perm)\n",
    "    r_map = { int(c):int(s) for c,s in zip(uni,perm)}\n",
    "    r,c = len(inp),len(inp[0])\n",
    "    rp = np.array(inp).tolist()\n",
    "    #print(rp)\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            if(rp[i][j] in r_map):\n",
    "                rp[i][j] = r_map[rp[i][j]]\n",
    "    return rp\n",
    "            \n",
    "    \n",
    "def augment(inp,oup,bl_cols):\n",
    "    cols = \"0123456789\"\n",
    "    npr_map = [1,9,72,3024,15120,60480,181440,362880,362880]\n",
    "    uni = \"\".join([str(x) for x in np.unique(inp).tolist()])\n",
    "    for c in bl_cols:\n",
    "        cols=cols.replace(str(c),\"\")\n",
    "        uni=uni.replace(str(c),\"\")\n",
    "\n",
    "    exp_size = len(inp)*len(inp[0])*npr_map[len(uni)]\n",
    "    \n",
    "    mod = floor(exp_size/120000)\n",
    "    mod = 1 if mod==0 else mod\n",
    "    \n",
    "    #print(exp_size,mod,len(uni))\n",
    "    result = []\n",
    "    count = 0\n",
    "    for comb in combinations(cols,len(uni)):\n",
    "        for perm in permutations(comb):\n",
    "            count+=1\n",
    "            if(count % mod == 0):\n",
    "                result.append((replace(inp,uni,perm),replace(oup,uni,perm)))\n",
    "    return result\n",
    "            \n",
    "def get_flips(inp,oup):\n",
    "    result = []\n",
    "    n_inp = np.array(inp)\n",
    "    n_oup = np.array(oup)\n",
    "    result.append((np.fliplr(inp).tolist(),np.fliplr(oup).tolist()))\n",
    "    result.append((np.rot90(np.fliplr(inp),1).tolist(),np.rot90(np.fliplr(oup),1).tolist()))\n",
    "    result.append((np.rot90(np.fliplr(inp),2).tolist(),np.rot90(np.fliplr(oup),2).tolist()))\n",
    "    result.append((np.rot90(np.fliplr(inp),3).tolist(),np.rot90(np.fliplr(oup),3).tolist()))\n",
    "    result.append((np.flipud(inp).tolist(),np.flipud(oup).tolist()))\n",
    "    result.append((np.rot90(np.flipud(inp),1).tolist(),np.rot90(np.flipud(oup),1).tolist()))\n",
    "    result.append((np.rot90(np.flipud(inp),2).tolist(),np.rot90(np.flipud(oup),2).tolist()))\n",
    "    result.append((np.rot90(np.flipud(inp),3).tolist(),np.rot90(np.flipud(oup),3).tolist()))\n",
    "    result.append((np.fliplr(np.flipud(inp)).tolist(),np.fliplr(np.flipud(oup)).tolist()))\n",
    "    result.append((np.flipud(np.fliplr(inp)).tolist(),np.flipud(np.fliplr(oup)).tolist()))\n",
    "    return result\n",
    "    \n",
    "def gettaskxy(task_json,aug,around_size,bl_cols,flip=True):    \n",
    "    X = []\n",
    "    Y = []\n",
    "    for pair in task_json['train']:\n",
    "        inp,oup=pair[\"input\"],pair[\"output\"]\n",
    "        tx,ty = getXy(inp,oup,around_size)\n",
    "        X.extend(tx)\n",
    "        Y.extend(ty)\n",
    "        if(flip):\n",
    "            for ainp,aoup in get_flips(inp,oup):\n",
    "                tx,ty = getXy(ainp,aoup,around_size)\n",
    "                X.extend(tx)\n",
    "                Y.extend(ty)\n",
    "                if(aug):\n",
    "                    augs = augment(ainp,aoup,bl_cols)\n",
    "                    for ainp,aoup in augs:\n",
    "                        tx,ty = getXy(ainp,aoup,around_size)\n",
    "                        X.extend(tx)\n",
    "                        Y.extend(ty)\n",
    "        if(aug):\n",
    "            augs = augment(inp,oup,bl_cols)\n",
    "            for ainp,aoup in augs:\n",
    "                tx,ty = getXy(ainp,aoup,around_size)\n",
    "                X.extend(tx)\n",
    "                Y.extend(ty)\n",
    "    return X,Y\n",
    "\n",
    "def test_predict(task_json,model,size):\n",
    "    inp = task_json['test'][0]['input']\n",
    "    eoup = task_json['test'][0]['output']\n",
    "    r,c = len(inp),len(inp[0])\n",
    "    oup = predict(inp,model,size)\n",
    "    return inp,eoup,oup\n",
    "\n",
    "def predict(inp,model,size):\n",
    "    r,c = len(inp),len(inp[0])\n",
    "    oup = np.zeros([r,c],dtype=int)\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            x = getX(inp,i,j,size)\n",
    "            o = int(model.predict([x]))\n",
    "            o = 0 if o<0 else o\n",
    "            oup[i][j]=o\n",
    "    return oup\n",
    "\n",
    "def submit_predict(task_json,model,size):\n",
    "    pred_map = {}\n",
    "    idx=0\n",
    "    for pair in task_json['test']:\n",
    "        inp = pair[\"input\"]\n",
    "        oup = predict(inp,model,size)\n",
    "        pred_map[idx] = oup.tolist()\n",
    "        idx+=1\n",
    "        #plot_result(inp,oup,oup)\n",
    "    return pred_map\n",
    "\n",
    "def dumb_predict(task_json):\n",
    "    pred_map = {}\n",
    "    idx=0\n",
    "    for pair in task_json['test']:\n",
    "        inp = pair[\"input\"]\n",
    "        pred_map[idx] = [[0,0],[0,0]]\n",
    "        idx+=1\n",
    "    return pred_map\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model,task_json,size):\n",
    "    total = 0\n",
    "    for pair in task_json['train']:\n",
    "        inp,oup=pair[\"input\"],pair[\"output\"]\n",
    "        eoup = predict(inp,model,size)\n",
    "        total+= np.sum((np.array(oup) != np.array(eoup)))\n",
    "    return total\n",
    "\n",
    "def get_test_loss(model,task_json,size):\n",
    "    total = 0\n",
    "    for pair in task_json['test']:\n",
    "        inp,oup=pair[\"input\"],pair[\"output\"]\n",
    "        eoup = predict(inp,model,size)\n",
    "        total+= np.sum((np.array(oup) != np.array(eoup)))\n",
    "    return total\n",
    "\n",
    "def get_a_size(task_json):\n",
    "    return 4;\n",
    "\n",
    "def get_bl_cols(task_json):\n",
    "    result = []\n",
    "    bkg_col = getBkgColor(task_json);\n",
    "    result.append(bkg_col)\n",
    "    # num_input,input_cnt,num_output,output_cnt\n",
    "    met_map = {}\n",
    "    for i in range(10):\n",
    "        met_map[i] = [0,0,0,0]\n",
    "        \n",
    "    total_ex = 0\n",
    "    for pair in task_json['train']:\n",
    "        inp,oup=pair[\"input\"],pair[\"output\"]\n",
    "        u,uc = np.unique(inp, return_counts=True)\n",
    "        inp_cnt_map = dict(zip(u,uc))\n",
    "        u,uc = np.unique(oup, return_counts=True)\n",
    "        oup_cnt_map = dict(zip(u,uc))\n",
    "        \n",
    "        for col,cnt in inp_cnt_map.items():\n",
    "            met_map[col][0] = met_map[col][0] + 1\n",
    "            met_map[col][1] = met_map[col][1] + cnt\n",
    "        for col,cnt in oup_cnt_map.items():\n",
    "            met_map[col][2] = met_map[col][2] + 1\n",
    "            met_map[col][3] = met_map[col][3] + cnt\n",
    "        total_ex+=1\n",
    "    \n",
    "    for col,met in met_map.items():\n",
    "        num_input,input_cnt,num_output,output_cnt = met\n",
    "        if(num_input == total_ex or num_output == total_ex):\n",
    "            result.append(col)\n",
    "        elif(num_input == 0 and num_output > 0):\n",
    "            result.append(col)\n",
    "    \n",
    "    result = np.unique(result).tolist()\n",
    "    if(len(result) == 10):\n",
    "        result.append(bkg_col)\n",
    "    return np.unique(result).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattener(pred):\n",
    "    str_pred = str([row for row in pred])\n",
    "    str_pred = str_pred.replace(', ', '')\n",
    "    str_pred = str_pred.replace('[[', '|')\n",
    "    str_pred = str_pred.replace('][', '|')\n",
    "    str_pred = str_pred.replace(']]', '|')\n",
    "    return str_pred\n",
    "\n",
    "def combine_preds(tid,pm1,pm2):\n",
    "    result = []\n",
    "    for i in range(len(pm1)):\n",
    "        tk_s = tid+\"_\"+str(i)\n",
    "        str_pred = flattener(pm1[i])+\" \"+flattener(pm2[i])\n",
    "        #print(tk_s,str_pred)\n",
    "        result.append([tk_s,str_pred])\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34b99a2b\n",
      "3d31c5b3\n",
      "0692e18c\n",
      "20818e16\n",
      "332efdb3\n",
      "423a55dc\n",
      "1e81d6f9\n",
      "212895b5\n",
      "2037f2c7\n",
      "3b4c2228\n",
      "3ed85e70\n",
      "33b52de3\n",
      "1a2e2828\n",
      "0a2355a6\n",
      "0b17323b\n",
      "11e1fe23\n",
      "2685904e\n",
      "009d5c81\n",
      "136b0064\n",
      "05a7bcf2\n",
      "0e671a1a\n",
      "19bb5feb\n",
      "195ba7dc\n",
      "1c56ad9f\n",
      "0607ce86\n",
      "2c737e39\n",
      "31adaf00\n",
      "15696249\n",
      "1a6449f1\n",
      "3a301edc\n",
      "414297c0\n",
      "37d3e8b2\n",
      "13713586\n",
      "08573cc6\n",
      "0a1d4ef5\n",
      "15113be4\n",
      "3f23242b\n",
      "21f83797\n",
      "1990f7a8\n",
      "00576224\n",
      "1c0d0a4b\n",
      "256b0a75\n",
      "2546ccf6\n",
      "2c0b0aff\n",
      "0d87d2a6\n",
      "31d5ba1a\n",
      "2697da3f\n",
      "1d398264\n",
      "2753e76c\n",
      "16b78196\n",
      "25094a63\n",
      "15663ba9\n",
      "22a4bbc2\n",
      "319f2597\n",
      "0bb8deee\n",
      "2f0c5170\n",
      "3490cc26\n",
      "03560426\n",
      "12422b43\n",
      "0c786b71\n",
      "184a9768\n",
      "3391f8c0\n",
      "0c9aba6e\n",
      "140c817e\n",
      "2072aba6\n",
      "20981f0e\n",
      "292dd178\n",
      "29700607\n",
      "27a77e38\n",
      "27f8ce4f\n",
      "17cae0c1\n",
      "3979b1a8\n",
      "40f6cd08\n",
      "3194b014\n",
      "32e9702f\n",
      "310f3251\n",
      "358ba94e\n",
      "137f0df0\n",
      "0becf7df\n",
      "3ee1011a\n",
      "17b80ad2\n",
      "18419cfa\n",
      "070dd51e\n",
      "1da012fc\n",
      "09c534e7\n",
      "1d0a4b61\n",
      "351d6448\n",
      "1acc24af\n",
      "14754a24\n",
      "00dbd492\n",
      "281123b4\n",
      "12eac192\n",
      "0934a4d8\n",
      "1c02dbbe\n",
      "2a5f8217\n",
      "1e97544e\n",
      "0f63c0b9\n",
      "103eff5b\n",
      "2b01abd0\n",
      "12997ef3\n"
     ]
    }
   ],
   "source": [
    "def inp_oup_dim_same(task_json):\n",
    "    return all([ len(pair[\"input\"]) == len(pair[\"output\"]) and len(pair[\"input\"][0]) == len(pair[\"output\"][0])\n",
    "                for pair in task_json['train']])\n",
    "    \n",
    "\n",
    "solved_task = 0\n",
    "total_task = 0\n",
    "task_ids = []\n",
    "task_preds = []\n",
    "for task_path in test_path.glob(\"*.json\"):\n",
    "    task_json = json.load(open(task_path))\n",
    "    tk_id = str(task_path).split(\"/\")[-1].split(\".\")[0]\n",
    "    print(tk_id)\n",
    "    if(inp_oup_dim_same(task_json)):\n",
    "        a_size = get_a_size(task_json)\n",
    "        bl_cols = get_bl_cols(task_json)\n",
    "        \n",
    "        isflip = False\n",
    "        X1,Y1 = gettaskxy(task_json,True,1,bl_cols,isflip)\n",
    "        X3,Y3 = gettaskxy(task_json,True,3,bl_cols,isflip)\n",
    "        X5,Y5 = gettaskxy(task_json,True,5,bl_cols,isflip)\n",
    "        \n",
    "        model_1 = BaggingClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=100).fit(X1, Y1)\n",
    "        #model_3 = BaggingClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=100).fit(X3, Y3)\n",
    "        model_5 = BaggingClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=100).fit(X5, Y5)\n",
    "        \n",
    "        pred_map_1 = submit_predict(task_json,model_1,1)\n",
    "        #pred_map_3 = submit_predict(task_json,model_3,3)\n",
    "        pred_map_5 = submit_predict(task_json,model_5,5)\n",
    "        \n",
    "        for tks,str_pred in combine_preds(tk_id,pred_map_1,pred_map_5):\n",
    "            task_ids.append(tks)\n",
    "            task_preds.append(str_pred)\n",
    "            #print(tks,str_pred)\n",
    "        solved_task+=1\n",
    "        #break\n",
    "    else:\n",
    "        pred_map_1 = dumb_predict(task_json)\n",
    "        #pred_map_3 = dumb_predict(task_json)\n",
    "        pred_map_5 = dumb_predict(task_json)\n",
    "        \n",
    "        for tks,str_pred in combine_preds(tk_id,pred_map_1,pred_map_5):\n",
    "            task_ids.append(tks)\n",
    "            task_preds.append(str_pred)\n",
    "            #print(tks,str_pred)\n",
    "        \n",
    "    total_task+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\"output_id\":task_ids,'output':task_preds})\n",
    "sub_df.to_csv(\"submission.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
