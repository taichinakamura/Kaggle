{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "- add simple padding when dimension of input and output is different\n",
    "- https://www.kaggle.com/meaninglesslives/using-decision-trees-for-arc\n",
    "- https://www.kaggle.com/davidbnn92/task-tagging\n",
    "- https://www.kaggle.com/nxrprime/grid-search-with-xgboost-and-cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import floor\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from itertools import permutations\n",
    "from lightgbm import LGBMClassifier\n",
    "from collections import defaultdict\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from itertools import combinations,permutations\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('/kaggle/input/abstraction-and-reasoning-challenge/')\n",
    "training_path = data_path / 'training'\n",
    "evaluation_path = data_path / 'evaluation'\n",
    "test_path = data_path / 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(task, index): # modify mistakes in data\n",
    "    # 025d127b\n",
    "    if index == \"025d127b.json\":\n",
    "        for i in range(9, 12):\n",
    "            for j in range(3, 8):\n",
    "                task['train'][0]['output'][i][j] = 0\n",
    "        for i in range(7, 10):\n",
    "            for j in range(3, 6):\n",
    "                task['train'][0]['output'][i][j] = 2\n",
    "        task['train'][0]['output'][8][4] = 0\n",
    "    # ef135b50\n",
    "    elif index == \"ef135b50.json\":\n",
    "        task['test'][0]['output'][6][4] = 9\n",
    "    # bd14c3bf\n",
    "    elif index == \"bd14c3bf.json\":\n",
    "        for i in range(3):\n",
    "            for j in range(5):\n",
    "                if task['test'][0]['input'][i][j] == 1:\n",
    "                    task['test'][0]['input'][i][j] = 2\n",
    "    # a8610ef7\n",
    "    elif index == \"a8610ef7.json\":\n",
    "        for i in range(6):\n",
    "            for j in range(6):\n",
    "                if task['test'][0]['output'][i][j] == 8:\n",
    "                    task['test'][0]['output'][i][j] = 5\n",
    "        task['train'][3]['input'][0][1] = 2\n",
    "        task['train'][3]['input'][5][1] = 2\n",
    "    # 54db823b\n",
    "    elif index == \"54db823b.json\":\n",
    "        task['train'][0]['output'][2][3] = 3\n",
    "        task['train'][0]['output'][2][4] = 9\n",
    "    # e5062a87\n",
    "    elif index == \"e5062a87.json\":\n",
    "        for j in range(3, 7):\n",
    "            task['train'][1]['output'][1][j] = 2\n",
    "    # 1b60fb0c\n",
    "    elif index == \"1b60fb0c.json\":\n",
    "        task['train'][1]['output'][8][8] = 0\n",
    "        task['train'][1]['output'][8][9] = 0\n",
    "    # 82819916\n",
    "    elif index == \"82819916.json\":\n",
    "        task['train'][0]['output'][4][5] = 4\n",
    "    # fea12743\n",
    "    elif index == \"fea12743.json\":\n",
    "        for i in range(11, 16):\n",
    "            for j in range(6):\n",
    "                if task['train'][0]['output'][i][j] == 2:\n",
    "                    task['train'][0]['output'][i][j] = 8\n",
    "    # 42a50994\n",
    "    elif index == \"42a50994.json\":\n",
    "        task['train'][0]['output'][1][0] = 8\n",
    "        task['train'][0]['output'][0][1] = 8\n",
    "    # f8be4b64\n",
    "    elif index == \"f8be4b64.json\":\n",
    "        for j in range(19):\n",
    "            if task['test'][0]['output'][12][j] == 0:\n",
    "                task['test'][0]['output'][12][j] = 1\n",
    "        task['test'][0]['output'][12][8] = 0\n",
    "    # d511f180\n",
    "    elif index == \"d511f180.json\":\n",
    "        task['train'][1]['output'][2][2] = 9\n",
    "    # 10fcaaa3\n",
    "    elif index == \"10fcaaa3.json\":\n",
    "        task['train'][1]['output'][4][7] = 8\n",
    "    # cbded52d\n",
    "    elif index == \"cbded52d.json\":\n",
    "        task['train'][0]['input'][4][6] = 1\n",
    "    # 11852cab\n",
    "    elif index == \"11852cab.json\":\n",
    "        task['train'][0]['input'][1][2] = 3\n",
    "    # 868de0fa\n",
    "    elif index == \"868de0fa.json\":\n",
    "        for j in range(2, 9):\n",
    "            task['train'][2]['input'][9][j] = 0\n",
    "            task['train'][2]['input'][10][j] = 1\n",
    "            task['train'][2]['input'][15][j] = 0\n",
    "            task['train'][2]['input'][16][j] = 1\n",
    "        task['train'][2]['input'][15][2] = 1\n",
    "        task['train'][2]['input'][15][8] = 1\n",
    "    # 6d58a25d\n",
    "    elif index == \"6d58a25d.json\":\n",
    "        task['train'][0]['output'][10][0] = 0\n",
    "        task['train'][2]['output'][6][13] = 4\n",
    "    # a9f96cdd\n",
    "    elif index == \"a9f96cdd.json\":\n",
    "        task['train'][3]['output'][1][3] = 0\n",
    "    # 48131b3c\n",
    "    elif index == \"48131b3c.json\":\n",
    "        task['train'][2]['output'][4][4] = 0\n",
    "    # 150deff5\n",
    "    elif index == \"150deff5.json\":\n",
    "        aux = task['train'][2]['output'].copy()\n",
    "        task['train'][2]['output'] = task['train'][2]['input'].copy()\n",
    "        task['train'][2]['input'] = aux\n",
    "    # 17cae0c1\n",
    "    elif index == \"17cae0c1.json\":\n",
    "        for i in range(3):\n",
    "            for j in range(3, 6):\n",
    "                task['test'][0]['output'][i][j] = 9\n",
    "    # e48d4e1a\n",
    "    elif index == \"e48d4e1a.json\":\n",
    "        task['train'][3]['input'][0][9] = 5\n",
    "        task['train'][3]['output'][0][9] = 0\n",
    "    # 8fbca751\n",
    "    elif index == \"8fbca751.json\":\n",
    "        task['train'][1]['output'][1][3] = 2\n",
    "        task['train'][1]['output'][2][3] = 8\n",
    "    # 4938f0c2\n",
    "    elif index == \"4938f0c2.json\":\n",
    "        for i in range(12):\n",
    "            for j in range(6,13):\n",
    "                if task['train'][2]['input'][i][j]==2:\n",
    "                    task['train'][2]['input'][i][j] = 0\n",
    "        for i in range(5,11):\n",
    "            for j in range(7):\n",
    "                if task['train'][2]['input'][i][j]==2:\n",
    "                    task['train'][2]['input'][i][j] = 0\n",
    "    # 9aec4887\n",
    "    elif index == \"9aec4887.json\":\n",
    "        task['train'][0]['output'][1][4] = 8\n",
    "    # b0f4d537\n",
    "    elif index == \"b0f4d537.json\":\n",
    "        for i in range(9):\n",
    "            task['train'][0]['output'][i][3] = 0\n",
    "            task['train'][0]['output'][i][4] = 1\n",
    "        task['train'][0]['output'][2][3] = 3\n",
    "        task['train'][0]['output'][2][4] = 3\n",
    "        task['train'][0]['output'][5][3] = 2\n",
    "    # aa300dc3\n",
    "    elif index == \"aa300dc3.json\":\n",
    "        task['train'][1]['input'][1][7] = 5\n",
    "        task['train'][1]['output'][1][7] = 5\n",
    "        task['train'][1]['input'][8][2] = 5\n",
    "        task['train'][1]['output'][8][2] = 5\n",
    "    # ad7e01d0\n",
    "    elif index == \"ad7e01d0.json\":\n",
    "        task['train'][0]['output'][6][7] = 0\n",
    "    # a8610ef7\n",
    "    elif index == \"a8610ef7.json\":\n",
    "        task['train'][3]['input'][0][1] = 0\n",
    "        task['train'][3]['input'][5][1] = 0\n",
    "        task['train'][3]['output'][0][1] = 0\n",
    "        task['train'][3]['output'][5][1] = 0\n",
    "    # 97239e3d\n",
    "    elif index == \"97239e3d.json\":\n",
    "        task['test'][0]['input'][14][6] = 0\n",
    "        task['test'][0]['input'][14][10] = 0\n",
    "    # d687bc17\n",
    "    elif index == \"d687bc17.json\":\n",
    "        task['train'][2]['output'][7][1] = 4\n",
    "    return task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattener(pred):\n",
    "    str_pred = str([row for row in pred])\n",
    "    str_pred = str_pred.replace(', ', '')\n",
    "    str_pred = str_pred.replace('[[', '|')\n",
    "    str_pred = str_pred.replace('][', '|')\n",
    "    str_pred = str_pred.replace(']]', '|')\n",
    "    return str_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# task tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_check(color_list):\n",
    "    tmp = color_list[0]\n",
    "    for i in range(1,len(color_list)):\n",
    "        if set(tmp) != set(color_list[i]):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def create_df(folder_path):\n",
    "    task_names_list = sorted(os.listdir(folder_path))\n",
    "    task_list = []\n",
    "    for task_name in task_names_list: \n",
    "        task_file = str(folder_path / task_name)\n",
    "        with open(task_file, 'r') as f:\n",
    "            task = json.load(f)\n",
    "            if \"test\" not in str(folder_path):\n",
    "                task = preprocess(task, task_name)\n",
    "            task_list.append(task)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['task_name'] = task_names_list\n",
    "    df['task'] = task_list\n",
    "    df['number_of_train_pairs'] = df['task'].apply(lambda x: len(x['train']))\n",
    "    df['number_of_test_pairs'] = df['task'].apply(lambda x: len(x['test']))\n",
    "    \n",
    "    # Compare image sizes\n",
    "    df['inputs_all_have_same_height'] = df['task'].apply(\n",
    "        lambda task: int(len(set([len(example['input']) for example in task['train']])) == 1)\n",
    "    )\n",
    "    df['inputs_all_have_same_width'] = df['task'].apply(\n",
    "        lambda task: int(len(set([len(example['input'][0]) for example in task['train']])) == 1)\n",
    "    )\n",
    "    df['inputs_all_have_same_shape'] = df['inputs_all_have_same_height'] * df['inputs_all_have_same_width']\n",
    "    df['input_height_if_constant'] = df['task'].apply(\n",
    "        lambda task: len(task['train'][0]['input'])\n",
    "                     if (len(set([len(example['input']) for example in task['train']])) == 1)\n",
    "                     else np.nan\n",
    "    )\n",
    "    df['input_width_if_constant'] = df['task'].apply(\n",
    "        lambda task: len(task['train'][0]['input'][0])\n",
    "                     if (len(set([len(example['input'][0]) for example in task['train']])) == 1)\n",
    "                     else np.nan\n",
    "    )\n",
    "    df['outputs_all_have_same_height'] = df['task'].apply(\n",
    "        lambda task: int(len(set([len(example['output']) for example in task['train']])) == 1)\n",
    "    )\n",
    "    df['outputs_all_have_same_width'] = df['task'].apply(\n",
    "        lambda task: int(len(set([len(example['output'][0]) for example in task['train']])) == 1)\n",
    "    )\n",
    "    df['outputs_all_have_same_shape'] = df['outputs_all_have_same_height'] * df['outputs_all_have_same_width']\n",
    "    df['output_height_if_constant'] = df['task'].apply(\n",
    "        lambda task: len(task['train'][0]['output'])\n",
    "                     if (len(set([len(example['output']) for example in task['train']])) == 1)\n",
    "                     else np.nan\n",
    "    )\n",
    "    df['output_width_if_constant'] = df['task'].apply(\n",
    "        lambda task: len(task['train'][0]['output'][0])\n",
    "                     if (len(set([len(example['output'][0]) for example in task['train']])) == 1)\n",
    "                     else np.nan\n",
    "    )  \n",
    "    df['in_each_pair_shape_doesnt_change'] = df['task'].apply(\n",
    "        lambda task: np.prod([int(len(example['input'][0])==len(example['output'][0])\n",
    "                                  and len(example['input'])==len(example['output'])\n",
    "                                 ) for example in task['train']\n",
    "                            ])\n",
    "    )\n",
    "    df['in_each_pair_shape_ratio_is_the_same'] = df['task'].apply(\n",
    "        lambda task: (len(set([len(example['input'][0]) / len(example['output'][0])\n",
    "                                 for example in task['train']]))==1) * (\n",
    "                      len(set([len(example['input']) / len(example['output'])\n",
    "                                 for example in task['train']]))==1)\n",
    "    )\n",
    "    df['o/i_height_ratio_if_constant'] = df['task'].apply(\n",
    "        lambda task: len(task['train'][0]['output']) / len(task['train'][0]['input'])\n",
    "                     if (len(set([len(example['input']) / len(example['output'])\n",
    "                                 for example in task['train']]))==1)\n",
    "                     else np.nan\n",
    "    )\n",
    "    df['o/i_width_ratio_if_constant'] = df['task'].apply(\n",
    "        lambda task: len(task['train'][0]['output'][0]) / len(task['train'][0]['input'][0])\n",
    "                     if (len(set([len(example['input'][0]) / len(example['output'][0])\n",
    "                                 for example in task['train']]))==1)\n",
    "                     else np.nan\n",
    "    )\n",
    "    \n",
    "    # my idea ---------\n",
    "    df[\"same_color_sum\"] = df['task'].apply(lambda task: \n",
    "                        np.all([int(sum(sum(np.array(example['input'])))== sum(sum(np.array(example['output'])))) for example in task['train']]))\n",
    "    \n",
    "    df[\"same_color_sum_in_edge\"] = df['task'].apply(lambda task: \n",
    "                        np.all([int(sum(np.array(example['input'])[0,:]) +sum(np.array(example['input'])[:,0]) + \n",
    "                                    sum(np.array(example['input'])[-1,:]) +sum(np.array(example['input'])[:,-1])\n",
    "                                    == \n",
    "                                    sum(np.array(example['output'])[0,:]) +sum(np.array(example['output'])[:,0]) + \n",
    "                                    sum(np.array(example['output'])[-1,:]) +sum(np.array(example['output'])[:,-1])) for example in task['train']]))\n",
    "    \n",
    "    df[\"io_color_kind_diff\"] = df['task'].apply(lambda task: [len(np.unique(np.array(example['input']))) - len(np.unique(np.array(example['output']))) for example in task['train']])\n",
    "    df[\"io_color_kind_diff_constant\"] = df['io_color_kind_diff'].apply(lambda task: np.unique(np.array(task))[0] if len(np.unique(np.array(task)))==1 else -1)\n",
    "    df[\"output_not_include_0\"] = df['task'].apply(lambda task: np.all([np.all(np.array(example['output']) > 0) for example in task['train']]))\n",
    "    df[\"increase_color_sum\"] = df['task'].apply(lambda task: \n",
    "                        np.all([int(sum(sum(np.array(example['input']))) < sum(sum(np.array(example['output'])))) for example in task['train']]))\n",
    "    df[\"decrease_color_sum\"] = df['task'].apply(lambda task: \n",
    "                        np.all([int(sum(sum(np.array(example['input']))) > sum(sum(np.array(example['output'])))) for example in task['train']]))\n",
    "    # **\n",
    "    df[\"input_color_change_or_not\"] = df['task'].apply(lambda task: color_check([list(np.unique(np.array(example['input']))) for example in task[\"train\"]] ))\n",
    "    # **\n",
    "    df['color_kind_increase'] = df['task'].apply(\n",
    "        lambda task: np.all([len(np.unique(np.array(example['input']))) < len(np.unique(np.array(example['output']))) for example in task['train']]))\n",
    "    df['color_kind_decrease'] = df['task'].apply(\n",
    "        lambda task: np.all([len(np.unique(np.array(example['input']))) > len(np.unique(np.array(example['output']))) for example in task['train']]))\n",
    "    df['smaller_output'] = df['task'].apply(\n",
    "        lambda task: np.all([(np.array(example['input']).shape[0] > np.array(example['output']).shape[0] or \n",
    "                             np.array(example['input']).shape[1] > np.array(example['output']).shape[1]) for example in task['train']]))\n",
    "    return df\n",
    "\n",
    "training_descriptive_df = create_df(training_path)\n",
    "evaluation_descriptive_df = create_df(evaluation_path)\n",
    "test_descriptive_df = create_df(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(row):\n",
    "    # same shape and color doesn't change in input and color kind decrease\n",
    "    if row[\"in_each_pair_shape_doesnt_change\"] == 1 and row[\"o/i_height_ratio_if_constant\"] ==1 and row[\"o/i_width_ratio_if_constant\"]==1 and row.input_color_change_or_not==1 and row.color_kind_decrease==1:\n",
    "        return 1\n",
    "    # same shape and color doesn't change in input and color kind increase\n",
    "    elif row[\"in_each_pair_shape_doesnt_change\"] == 1 and row[\"o/i_height_ratio_if_constant\"] ==1 and row[\"o/i_width_ratio_if_constant\"]==1 and row.input_color_change_or_not==1 and row.color_kind_increase==1:\n",
    "        return 2\n",
    "    # same shape and color doesn't change in input and color kind same\n",
    "    elif row[\"in_each_pair_shape_doesnt_change\"] == 1 and row[\"o/i_height_ratio_if_constant\"] ==1 and row[\"o/i_width_ratio_if_constant\"]==1 and row.input_color_change_or_not==1 and row.color_kind_increase==0  and row.color_kind_decrease==0:\n",
    "        return 3\n",
    "    # same shape and decrease color sum → xgboost\n",
    "    if row[\"in_each_pair_shape_doesnt_change\"] == 1 and row[\"o/i_height_ratio_if_constant\"] ==1 and row[\"o/i_width_ratio_if_constant\"]==1 and row.input_color_change_or_not==0 and row.color_kind_decrease==1:\n",
    "        return 4\n",
    "    # different shape and decrease color sum\n",
    "    if row[\"in_each_pair_shape_doesnt_change\"] == 1 and row[\"o/i_height_ratio_if_constant\"] ==1 and row[\"o/i_width_ratio_if_constant\"]==1 and row.input_color_change_or_not==0 and row.color_kind_increase==1:\n",
    "        return 5\n",
    "    # different shape and increase color sum\n",
    "    elif row[\"in_each_pair_shape_doesnt_change\"] == 1 and row[\"o/i_height_ratio_if_constant\"] ==1 and row[\"o/i_width_ratio_if_constant\"]==1 and row.input_color_change_or_not==0 and row.color_kind_increase==0  and row.color_kind_decrease==0:\n",
    "        return 6\n",
    "    # otherwise\n",
    "    elif row[\"smaller_output\"] == 1 and row[\"outputs_all_have_same_shape\"] == 1:\n",
    "        return 7\n",
    "    else:\n",
    "        return 8\n",
    "\n",
    "training_descriptive_df[\"class\"] = training_descriptive_df.apply(lambda x: classification(x), axis=1)\n",
    "evaluation_descriptive_df[\"class\"] = evaluation_descriptive_df.apply(lambda x: classification(x), axis=1)\n",
    "test_descriptive_df[\"class\"] = test_descriptive_df.apply(lambda x: classification(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(training_descriptive_df[\"class\"].value_counts(normalize=True))\n",
    "#print(evaluation_descriptive_df[\"class\"].value_counts(normalize=True))\n",
    "#print(test_descriptive_df[\"class\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbours(color, cur_row, cur_col, nrows, ncols, radius):\n",
    "\n",
    "    if cur_row<=radius-1: top = -1\n",
    "    else: top = color[cur_row-radius][cur_col]\n",
    "        \n",
    "    if cur_row>=nrows-radius: bottom = -1\n",
    "    else: bottom = color[cur_row+radius][cur_col]\n",
    "        \n",
    "    if cur_col<=radius-1: left = -1\n",
    "    else: left = color[cur_row][cur_col-radius]\n",
    "        \n",
    "    if cur_col>=ncols-radius: right = -1\n",
    "    else: right = color[cur_row][cur_col+radius]\n",
    "        \n",
    "    return top, bottom, left, right\n",
    "\n",
    "def get_tl_tr(color, cur_row, cur_col, nrows, ncols, radius):\n",
    "        \n",
    "    if cur_row<=radius-1:\n",
    "        top_left = -1\n",
    "        top_right = -1\n",
    "    else:\n",
    "        if cur_col<=radius-1: top_left=-1\n",
    "        else: top_left = color[cur_row-radius][cur_col-radius]\n",
    "        if cur_col>=ncols-radius: top_right=-1\n",
    "        else: top_right = color[cur_row-radius][cur_col+radius]   \n",
    "        \n",
    "    return top_left, top_right\n",
    "\n",
    "def get_bl_br(color, cur_row, cur_col, nrows, ncols, radius):\n",
    "        \n",
    "    if cur_row>=nrows-radius:\n",
    "        bottom_left = -1\n",
    "        bottom_right = -1\n",
    "    else:\n",
    "        if cur_col<=radius-1: bottom_left=-1\n",
    "        else: bottom_left = color[cur_row+radius][cur_col-radius]\n",
    "        if cur_col>=ncols-radius: bottom_right=-1\n",
    "        else: bottom_right = color[cur_row+radius][cur_col+radius]   \n",
    "        \n",
    "    return bottom_left, bottom_right\n",
    "\n",
    "def diagonal(color, cur_row, cur_col, nrows, ncols, direction):\n",
    "    element = []\n",
    "    element.append(color[cur_row, cur_col])\n",
    "    if direction == \"upper-right\":\n",
    "        for i in range(-nrows,nrows):\n",
    "            if (cur_row + i < nrows and cur_row +i >=0) and (cur_col - i < ncols and cur_col - i >=0):\n",
    "                element.append(color[cur_row+i][cur_col-i])\n",
    "            else:\n",
    "                continue\n",
    "    else:\n",
    "        for i in range(-nrows,nrows):  \n",
    "            if (cur_row + i < nrows and cur_row +i >=0) and (cur_col + i < ncols and cur_col + i >=0):\n",
    "                element.append(color[cur_row+i][cur_col+i])\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "    return np.array(element)\n",
    "\n",
    "def make_features(input_color, nfeat):\n",
    "    nrows, ncols = input_color.shape\n",
    "    feat = np.zeros((nrows*ncols,nfeat))\n",
    "    cur_idx = 0\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            feat[cur_idx,0] = i\n",
    "            feat[cur_idx,1] = j\n",
    "            feat[cur_idx,2] = input_color[i][j]\n",
    "            feat[cur_idx,3:7] = neighbours(input_color, i, j, nrows, ncols,1)\n",
    "            feat[cur_idx,7:9] = get_tl_tr(input_color, i, j, nrows, ncols,1)\n",
    "            feat[cur_idx,9] = len(np.unique(input_color[i,:]))\n",
    "            feat[cur_idx,10] = len(np.unique(input_color[:,j]))\n",
    "            feat[cur_idx,11] = (i+j)\n",
    "            feat[cur_idx,12] = len(np.unique(input_color[i-1:i+1,j-1:j+1]))\n",
    "            feat[cur_idx,13:15] = get_bl_br(input_color, i, j, nrows, ncols,1)\n",
    "            feat[cur_idx,15] = np.sum(input_color[i,:])\n",
    "            feat[cur_idx,16] = np.sum(input_color[:,j])\n",
    "            feat[cur_idx,17:21] = neighbours(input_color, i, j, nrows, ncols,2)\n",
    "            feat[cur_idx,21] = np.max(input_color[i,:])\n",
    "            feat[cur_idx,22] = np.min(input_color[i,:])\n",
    "            feat[cur_idx,23] = np.max(input_color[:,j])\n",
    "            feat[cur_idx,24] = np.min(input_color[:,j])\n",
    "            feat[cur_idx,25:29] = neighbours(input_color, i, j, nrows, ncols,3)\n",
    "            feat[cur_idx,29] = np.sum(input_color[i-1:i+1,j-1:j+1])\n",
    "            feat[cur_idx,30] = np.sum(input_color[i-2:i+2,j-2:j+2])\n",
    "            feat[cur_idx,31] = len(input_color[i-5:i+5,j-5:j+5])\n",
    "            #feat[cur_idx,32] = len(np.unique(input_color[i+1,:])) if i+1<nrows else -1\n",
    "            #feat[cur_idx,33] = np.sum(input_color[i-1,:]) if i-1>0 else -1\n",
    "            #feat[cur_idx,34] = np.sum(input_color[:,j+1]) if j+1<ncols else -1\n",
    "            #feat[cur_idx,35] = np.sum(input_color[:,j-1]) if j-1>0 else -1     \n",
    "            cur_idx += 1\n",
    "        \n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(task, mode='train'):\n",
    "    num_train_pairs = len(task[mode])\n",
    "    feat, target = [], []\n",
    "    \n",
    "    global local_neighb\n",
    "    for task_num in range(num_train_pairs):\n",
    "        input_color = np.array(task[mode][task_num]['input'])\n",
    "        target_color = task[mode][task_num]['output']\n",
    "        nrows, ncols = len(task[mode][task_num]['input']), len(task[mode][task_num]['input'][0])\n",
    "\n",
    "        target_rows, target_cols = len(task[mode][task_num]['output']), len(task[mode][task_num]['output'][0])\n",
    "        \n",
    "        if (target_rows!=nrows) or (target_cols!=ncols):\n",
    "            return None, None, 1\n",
    "\n",
    "        imsize = nrows*ncols\n",
    "        offset = imsize*task_num*3 #since we are using three types of aug\n",
    "        feat.extend(make_features(input_color, nfeat))\n",
    "        target.extend(np.array(target_color).reshape(-1,))\n",
    "            \n",
    "    return np.array(feat), np.array(target), 0\n",
    "\n",
    "def new_features(task):\n",
    "    num_train_pairs = len(task)\n",
    "    feat, target = [], []\n",
    "    \n",
    "    global local_neighb\n",
    "    for task_num in range(num_train_pairs):\n",
    "        input_color = np.array(task[task_num]['input'])\n",
    "        target_color = task[task_num]['output']\n",
    "        nrows, ncols = len(task[task_num]['input']), len(task[task_num]['input'][0])\n",
    "\n",
    "        target_rows, target_cols = len(task[task_num]['output']), len(task[task_num]['output'][0])\n",
    "        \n",
    "        if (target_rows!=nrows) or (target_cols!=ncols):\n",
    "            return None, None, 1\n",
    "\n",
    "        imsize = nrows*ncols\n",
    "        offset = imsize*task_num*3 #since we are using three types of aug\n",
    "        feat.extend(make_features(input_color, nfeat))  \n",
    "        target.extend(np.array(target_color).reshape(-1,))\n",
    "            \n",
    "    return np.array(feat), np.array(target), 0"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(tasks):\n",
    "    ans = []\n",
    "    for task in tasks:\n",
    "        tmp = {\"input\": 0, \"output\": 0}\n",
    "        tmp[\"input\"] = task[\"input\"]\n",
    "        saigen = np.zeros(np.array(task[\"input\"]).shape)\n",
    "        cur_h, cur_w = np.array(task[\"output\"]).shape\n",
    "        saigen[:cur_h, :cur_w] = np.array(task[\"output\"])\n",
    "        tmp[\"output\"] = saigen.astype(int).tolist()\n",
    "        ans.append(tmp)\n",
    "    return ans, cur_h, cur_w\n",
    "\n",
    "def data_aug(tasks):\n",
    "    ans = []\n",
    "    for i in tasks:\n",
    "        ans.append(i)\n",
    "    \n",
    "    for i in range(len(tasks)):\n",
    "        tmp1 = {'input': 0, 'output': 0}\n",
    "        tmp1[\"input\"], tmp1[\"output\"] = np.fliplr(tasks[i][\"input\"]).tolist(), np.fliplr(tasks[i][\"output\"]).tolist()\n",
    "        tmp2 = {'input': 0, 'output': 0}\n",
    "        tmp2[\"input\"], tmp2[\"output\"] = np.flipud(tasks[i][\"input\"]).tolist(), np.flipud(tasks[i][\"output\"]).tolist()\n",
    "        tmp3 = {'input': 0, 'output': 0}\n",
    "        tmp3[\"input\"], tmp3[\"output\"] = np.rot90(tasks[i][\"input\"]).tolist(), np.rot90(tasks[i][\"output\"]).tolist()\n",
    "        tmp4 = {'input': 0, 'output': 0}\n",
    "        tmp4[\"input\"], tmp4[\"output\"] = np.rot90(np.fliplr(tasks[i][\"input\"]),1).tolist(), np.rot90(np.fliplr(tasks[i][\"output\"]),1).tolist()\n",
    "        tmp5 = {'input': 0, 'output': 0}\n",
    "        tmp5[\"input\"], tmp5[\"output\"] = np.rot90(np.fliplr(tasks[i][\"input\"]),2).tolist(), np.rot90(np.fliplr(tasks[i][\"output\"]),2).tolist()\n",
    "        tmp6 = {'input': 0, 'output': 0}\n",
    "        tmp6[\"input\"], tmp6[\"output\"] = np.rot90(np.fliplr(tasks[i][\"input\"]),3).tolist(), np.rot90(np.fliplr(tasks[i][\"output\"]),3).tolist()\n",
    "        tmp7 = {'input': 0, 'output': 0}\n",
    "        tmp7[\"input\"], tmp7[\"output\"] = np.rot90(np.flipud(tasks[i][\"input\"]),1).tolist(), np.rot90(np.flipud(tasks[i][\"output\"]),1).tolist()\n",
    "        tmp8 = {'input': 0, 'output': 0}\n",
    "        tmp8[\"input\"], tmp8[\"output\"] = np.rot90(np.flipud(tasks[i][\"input\"]),2).tolist(), np.rot90(np.flipud(tasks[i][\"output\"]),2).tolist()\n",
    "        tmp9 = {'input': 0, 'output': 0}\n",
    "        tmp9[\"input\"], tmp9[\"output\"] = np.rot90(np.flipud(tasks[i][\"input\"]),3).tolist(), np.rot90(np.flipud(tasks[i][\"output\"]),3).tolist()\n",
    "        tmp10 = {'input': 0, 'output': 0}\n",
    "        tmp10[\"input\"], tmp10[\"output\"] = np.fliplr(np.flipud(tasks[i][\"input\"])).tolist(), np.fliplr(np.flipud(tasks[i][\"output\"])).tolist()\n",
    "        #tmp11 = {'input': 0, 'output': 0}\n",
    "        #tmp11[\"input\"], tmp11[\"output\"] = np.transpose(tasks[i][\"input\"]).tolist(), np.transpose(tasks[i][\"output\"]).tolist()\n",
    "        ans.append(tmp1)\n",
    "        ans.append(tmp2)\n",
    "        ans.append(tmp3)\n",
    "        ans.append(tmp4)\n",
    "        ans.append(tmp5)\n",
    "        ans.append(tmp6)\n",
    "        ans.append(tmp7)\n",
    "        ans.append(tmp8)\n",
    "        ans.append(tmp9)\n",
    "        ans.append(tmp10)\n",
    "    return ans\n",
    "\n",
    "def data_aug2(a):\n",
    "    new_data = []\n",
    "    for job in a:\n",
    "        new_data.append(job)\n",
    "    for job in a:\n",
    "        color = [i for i in np.unique(np.array(job[\"input\"])) if i != 0]\n",
    "        color_out = [i for i in np.unique(np.array(job[\"output\"])) if i != 0]\n",
    "        if set(color) == set(color_out):\n",
    "            color_pos = []\n",
    "            color_posout = []\n",
    "            for i in color: # for input\n",
    "                tmp = np.argwhere(np.array(job[\"input\"])==i).tolist()\n",
    "                color_pos.append(tmp)\n",
    "            for i in color: # for output\n",
    "                tmp = np.argwhere(np.array(job[\"output\"])==i).tolist()\n",
    "                color_posout.append(tmp)\n",
    "            ind = [j for j in range(len(color))]\n",
    "            for i,ele in enumerate(permutations(ind)):\n",
    "                if i != 0:\n",
    "                    tmp1 = np.copy(job[\"input\"])\n",
    "                    for c in range(len(ele)):\n",
    "                        for pos in color_pos[ele[c]]:\n",
    "                            tmp1[pos[0],pos[1]] = color[c]\n",
    "                    tmp2 = np.copy(job[\"output\"])\n",
    "                    for c in range(len(ele)):\n",
    "                        for pos in color_posout[ele[c]]:\n",
    "                            tmp2[pos[0],pos[1]] = color[c]\n",
    "                    if len(new_data) >50:\n",
    "                        break\n",
    "                    new_data.append({\"input\":tmp1.tolist(), \"output\":tmp2.tolist()})\n",
    "        else:\n",
    "            return a\n",
    "    return new_data\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "def getiorc(pair):\n",
    "    inp = pair[\"input\"]\n",
    "    return pair[\"input\"],pair[\"output\"],len(inp),len(inp[0])\n",
    "\n",
    "def getBkgColor(task_json):\n",
    "    color_dict = defaultdict(int)\n",
    "    \n",
    "    for pair in task_json:\n",
    "        inp,oup,r,c = getiorc(pair)\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                color_dict[inp[i][j]]+=1\n",
    "    color = -1\n",
    "    max_count = 0\n",
    "    for col,cnt in color_dict.items():\n",
    "        if(cnt > max_count):\n",
    "            color = col\n",
    "            max_count = cnt\n",
    "    return color\n",
    "\n",
    "def replace(inp,uni,perm):\n",
    "    # uni = '234' perm = ['5','7','9']\n",
    "    r_map = { int(c):int(s) for c,s in zip(uni,perm)}\n",
    "    r,c = len(inp),len(inp[0])\n",
    "    rp = np.array(inp).tolist()\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            if(rp[i][j] in r_map):\n",
    "                rp[i][j] = r_map[rp[i][j]]\n",
    "    return rp\n",
    "\n",
    "def augment(inp,oup,bl_cols):\n",
    "    cols = \"0123456789\"\n",
    "    npr_map = [1,9,72,3024,15120,60480,181440,362880,362880]\n",
    "    uni = \"\".join([str(x) for x in np.unique(inp).tolist()])\n",
    "    for c in bl_cols:\n",
    "        cols=cols.replace(str(c),\"\")\n",
    "        uni=uni.replace(str(c),\"\")\n",
    "\n",
    "    exp_size = len(inp)*len(inp[0])*npr_map[len(uni)]\n",
    "    \n",
    "    mod = floor(exp_size/120000)\n",
    "    mod = 1 if mod==0 else mod\n",
    "    \n",
    "    #print(exp_size,mod,len(uni))\n",
    "    result = []\n",
    "    count = 0\n",
    "    for comb in combinations(cols,len(uni)):\n",
    "        for perm in permutations(comb):\n",
    "            count+=1\n",
    "            if(count % mod == 0):\n",
    "                result.append({\"input\":replace(inp,uni,perm),\"output\":replace(oup,uni,perm)})\n",
    "    return result\n",
    "\n",
    "def get_bl_cols(task_json):\n",
    "    result = []\n",
    "    bkg_col = getBkgColor(task_json);\n",
    "    result.append(bkg_col)\n",
    "    # num_input,input_cnt,num_output,output_cnt\n",
    "    met_map = {}\n",
    "    for i in range(10):\n",
    "        met_map[i] = [0,0,0,0]\n",
    "        \n",
    "    total_ex = 0\n",
    "    for pair in task_json:\n",
    "        inp,oup=pair[\"input\"],pair[\"output\"]\n",
    "        u,uc = np.unique(inp, return_counts=True)\n",
    "        inp_cnt_map = dict(zip(u,uc))\n",
    "        u,uc = np.unique(oup, return_counts=True)\n",
    "        oup_cnt_map = dict(zip(u,uc))\n",
    "        \n",
    "        for col,cnt in inp_cnt_map.items():\n",
    "            met_map[col][0] = met_map[col][0] + 1\n",
    "            met_map[col][1] = met_map[col][1] + cnt\n",
    "        for col,cnt in oup_cnt_map.items():\n",
    "            met_map[col][2] = met_map[col][2] + 1\n",
    "            met_map[col][3] = met_map[col][3] + cnt\n",
    "        total_ex+=1\n",
    "        \n",
    "    for col,met in met_map.items():\n",
    "        num_input,input_cnt,num_output,output_cnt = met\n",
    "        if(num_input == total_ex or num_output == total_ex):\n",
    "            result.append(col)\n",
    "        elif(num_input == 0 and num_output > 0):\n",
    "            result.append(col)\n",
    "    \n",
    "    result = np.unique(result).tolist()\n",
    "    if(len(result) == 10):\n",
    "        result.append(bkg_col)\n",
    "    return np.unique(result).tolist()\n",
    "\n",
    "def data_aug3(task_json):\n",
    "    ans = []\n",
    "    for i in task_json:\n",
    "        ans.append(i)\n",
    "        \n",
    "    bl_cols = get_bl_cols(task_json)\n",
    "    for pair in task_json:\n",
    "        inp,oup=pair[\"input\"],pair[\"output\"]\n",
    "        augs = augment(inp,oup,bl_cols)\n",
    "        for i in augs:\n",
    "            ans.append(i)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/007bbfb7.json\n",
      "2, 00d62c1b.json ensemble accuracy 0.94\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/017c7c7b.json\n",
      "6, 025d127b.json ensemble accuracy 1.0\n",
      "6, 045e512c.json ensemble accuracy 0.9070294784580499\n",
      "7, 0520fde7.json ensemble accuracy 0.6666666666666666\n",
      "4, 05269061.json ensemble accuracy 0.673469387755102\n",
      "3, 05f2a901.json ensemble accuracy 0.9\n",
      "6, 06df4c85.json ensemble accuracy 0.9289940828402367\n",
      "2, 08ed6ac7.json ensemble accuracy 0.8148148148148148\n",
      "1, 09629e4f.json ensemble accuracy 0.7107438016528925\n",
      "6, 0962bcdd.json ensemble accuracy 0.9444444444444444\n",
      "*******************reprediction success**********************\n",
      "6, 0a938d79.json ensemble accuracy 0.8653198653198653\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/0b148d64.json\n",
      "5, 0ca9ddb6.json ensemble accuracy 0.9382716049382716\n",
      "6, 0d3d703e.json ensemble accuracy 0.0\n",
      "4, 0dfd9992.json ensemble accuracy 0.6417233560090703\n",
      "6, 0e206a2e.json ensemble accuracy 0.9583333333333334\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/10fcaaa3.json\n",
      "6, 11852cab.json ensemble accuracy 0.97\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/1190e5a7.json\n",
      "7, 137eaa0f.json ensemble accuracy 0.0\n",
      "2, 150deff5.json ensemble accuracy 0.9659090909090909\n",
      "3, 178fcbfb.json ensemble accuracy 1.0\n",
      "4, 1a07d186.json ensemble accuracy 0.9858299595141701\n",
      "7, 1b2d62fb.json ensemble accuracy 0.7333333333333333\n",
      "2, 1b60fb0c.json ensemble accuracy 0.95\n",
      "6, 1bfc4729.json ensemble accuracy 0.73\n",
      "*******************reprediction success**********************\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/1c786137.json\n",
      "3, 1caeab9d.json ensemble accuracy 0.75\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/1cf80156.json\n",
      "6, 1e0a9b12.json ensemble accuracy 0.88\n",
      "6, 1e32b0e9.json ensemble accuracy 0.8685121107266436\n",
      "4, 1f0c79e5.json ensemble accuracy 0.691358024691358\n",
      "6, 1f642eb9.json ensemble accuracy 0.92\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/1f85a75f.json\n",
      "6, 1f876c06.json ensemble accuracy 0.8\n",
      "7, 1fad071e.json ensemble accuracy 0.4\n",
      "7, 2013d3e2.json ensemble accuracy 0.4444444444444444\n",
      "4, 2204b7a8.json ensemble accuracy 0.83\n",
      "6, 22168020.json ensemble accuracy 0.9\n",
      "2, 22233c11.json ensemble accuracy 0.92\n",
      "2, 2281f1f4.json ensemble accuracy 1.0\n",
      "6, 228f6490.json ensemble accuracy 0.88\n",
      "6, 22eb0ac0.json ensemble accuracy 0.9\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/234bbc79.json\n",
      "2, 23581191.json ensemble accuracy 1.0\n",
      "7, 239be575.json ensemble accuracy 0.0\n",
      "7, 239be575.json ensemble accuracy 1.0\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/23b5c85d.json\n",
      "3, 253bf280.json ensemble accuracy 0.9423076923076923\n",
      "6, 25d487eb.json ensemble accuracy 0.9886363636363636\n",
      "4, 25d8a9c8.json ensemble accuracy 1.0\n",
      "6, 25ff71a9.json ensemble accuracy 1.0\n",
      "6, 25ff71a9.json ensemble accuracy 1.0\n",
      "6, 264363fd.json ensemble accuracy 0.9211111111111111\n",
      "2, 272f95fa.json ensemble accuracy 0.592156862745098\n",
      "7, 27a28665.json ensemble accuracy 0.0\n",
      "7, 27a28665.json ensemble accuracy 0.0\n",
      "7, 27a28665.json ensemble accuracy 0.0\n",
      "7, 28bf18c6.json ensemble accuracy 0.4444444444444444\n",
      "2, 28e73c20.json ensemble accuracy 0.8209876543209876\n",
      "6, 29623171.json ensemble accuracy 0.7520661157024794\n",
      "5, 29c11459.json ensemble accuracy 0.9636363636363636\n",
      "*******************reprediction success**********************\n",
      "4, 29ec7d0e.json ensemble accuracy 0.8117283950617284\n",
      "4, 2bcee788.json ensemble accuracy 0.92\n",
      "2, 2bee17df.json ensemble accuracy 1.0\n",
      "6, 2c608aff.json ensemble accuracy 0.949874686716792\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/2dc579da.json\n",
      "3, 2dd70a9a.json ensemble accuracy 0.9171597633136095\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/2dee498d.json\n",
      "4, 31aa019c.json ensemble accuracy 0.87\n",
      "4, 321b1fc6.json ensemble accuracy 0.79\n",
      "2, 32597951.json ensemble accuracy 1.0\n",
      "4, 3345333e.json ensemble accuracy 0.8125\n",
      "7, 3428a4f5.json ensemble accuracy 0.6\n",
      "7, 3428a4f5.json ensemble accuracy 0.5666666666666667\n",
      "3, 3618c87e.json ensemble accuracy 1.0\n",
      "1, 3631a71a.json ensemble accuracy 0.9533333333333334\n",
      "4, 363442ee.json ensemble accuracy 0.5897435897435898\n",
      "3, 36d67576.json ensemble accuracy 0.9095238095238095\n",
      "5, 36fdfd69.json ensemble accuracy 0.9836601307189542\n",
      "3, 3906de3d.json ensemble accuracy 0.92\n",
      "7, 39a8645d.json ensemble accuracy 0.3333333333333333\n",
      "6, 39e1d7f9.json ensemble accuracy 0.9001189060642093\n",
      "2, 3aa6fb7a.json ensemble accuracy 1.0\n",
      "6, 3ac3eb23.json ensemble accuracy 0.7638888888888888\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/3af2c5a8.json\n",
      "5, 3bd67248.json ensemble accuracy 0.87\n",
      "6, 3bdb4ada.json ensemble accuracy 0.9818181818181818\n",
      "6, 3befdf3e.json ensemble accuracy 0.9236111111111112\n",
      "6, 3c9b0459.json ensemble accuracy 0.5555555555555556\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/3de23699.json\n",
      "6, 3e980e27.json ensemble accuracy 0.8994082840236687\n",
      "5, 3eda0437.json ensemble accuracy 0.90625\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/3f7978a0.json\n",
      "6, 40853293.json ensemble accuracy 0.8725\n",
      "4, 4093f84a.json ensemble accuracy 0.9489795918367347\n",
      "2, 41e4d17e.json ensemble accuracy 0.92\n",
      "2, 4258a5f9.json ensemble accuracy 1.0\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/4290ef0e.json\n",
      "6, 42a50994.json ensemble accuracy 0.9915966386554622\n",
      "6, 4347f46a.json ensemble accuracy 1.0\n",
      "6, 444801d8.json ensemble accuracy 0.93\n",
      "7, 445eab21.json ensemble accuracy 0.0\n",
      "3, 447fd412.json ensemble accuracy 0.7198879551820728\n",
      "3, 44d8ac46.json ensemble accuracy 0.9305555555555556\n",
      "7, 44f52bb0.json ensemble accuracy 0.0\n",
      "7, 44f52bb0.json ensemble accuracy 0.0\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/4522001f.json\n",
      "2, 4612dd53.json ensemble accuracy 0.9822485207100592\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/46442a0e.json\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/469497ad.json\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/46f33fce.json\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/47c1f68c.json\n",
      "4, 484b58aa.json ensemble accuracy 0.8608799048751486\n",
      "7, 48d8fb45.json ensemble accuracy 0.4444444444444444\n",
      "3, 4938f0c2.json ensemble accuracy 0.9206349206349206\n",
      "6, 496994bd.json ensemble accuracy 0.7\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/49d1d64f.json\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/4be741c5.json\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/4c4377d9.json\n",
      "6, 4c5c2cf0.json ensemble accuracy 0.88\n",
      "2, 50846271.json ensemble accuracy 0.9593301435406698\n",
      "2, 508bd3b6.json ensemble accuracy 0.9305555555555556\n",
      "5, 50cb2852.json ensemble accuracy 1.0\n",
      "7, 5117e062.json ensemble accuracy 0.3333333333333333\n",
      "3, 5168d44c.json ensemble accuracy 0.9915966386554622\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/539a4f51.json\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/53b68214.json\n",
      "2, 543a7ed5.json ensemble accuracy 0.9955555555555555\n",
      "5, 54d82841.json ensemble accuracy 1.0\n",
      "4, 54d9e175.json ensemble accuracy 0.961038961038961\n",
      "3, 5521c0d9.json ensemble accuracy 0.8311111111111111\n",
      "4, 5582e5ca.json ensemble accuracy 0.0\n",
      "7, 5614dbcf.json ensemble accuracy 0.6666666666666666\n",
      "2, 56dc2b01.json ensemble accuracy 0.875\n",
      "6, 56ff96f3.json ensemble accuracy 0.6944444444444444\n",
      "6, 57aa92db.json ensemble accuracy 0.7385964912280701\n",
      "7, 5ad4f10b.json ensemble accuracy 0.4444444444444444\n",
      "7, 5bd6f4ac.json ensemble accuracy 0.3333333333333333\n",
      "3, 5c0a986e.json ensemble accuracy 0.95\n",
      "6, 5c2c9af4.json ensemble accuracy 0.8214285714285714\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/5daaa586.json\n",
      "2, 60b61512.json ensemble accuracy 0.9876543209876543\n",
      "6, 6150a2bd.json ensemble accuracy 0.4444444444444444\n",
      "6, 623ea044.json ensemble accuracy 0.9307958477508651\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/62c24649.json\n",
      "4, 63613498.json ensemble accuracy 0.92\n",
      "7, 6430c8c4.json ensemble accuracy 0.875\n",
      "2, 6455b5f5.json ensemble accuracy 0.8028846153846154\n",
      "7, 662c240a.json ensemble accuracy 0.2222222222222222\n",
      "2, 67385a82.json ensemble accuracy 1.0\n",
      "2, 673ef223.json ensemble accuracy 0.8571428571428571\n",
      "7, 6773b310.json ensemble accuracy 0.5555555555555556\n",
      "3, 67a3c6ac.json ensemble accuracy 0.5555555555555556\n",
      "5, 67a423a3.json ensemble accuracy 0.9930555555555556\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/67e8384a.json\n",
      "7, 681b3aeb.json ensemble accuracy 0.0\n",
      "3, 6855a6e4.json ensemble accuracy 0.9333333333333333\n",
      "3, 68b16354.json ensemble accuracy 0.2653061224489796\n",
      "2, 694f12f3.json ensemble accuracy 0.96\n",
      "3, 6a1e5592.json ensemble accuracy 0.94\n",
      "6, 6aa20dc0.json ensemble accuracy 0.8760330578512396\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/6b9890af.json\n",
      "2, 6c434453.json ensemble accuracy 1.0\n",
      "4, 6cdd2623.json ensemble accuracy 0.8519736842105263\n",
      "5, 6cf79266.json ensemble accuracy 0.945\n",
      "4, 6d0160f0.json ensemble accuracy 0.9669421487603306\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/6d0aefbc.json\n",
      "6, 6d58a25d.json ensemble accuracy 0.965\n",
      "2, 6d75e8bb.json ensemble accuracy 1.0\n",
      "6, 6e02f1e3.json ensemble accuracy 0.7777777777777778\n",
      "6, 6e19193c.json ensemble accuracy 0.94\n",
      "2, 6e82a1ae.json ensemble accuracy 0.96\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/6ecd11f4.json\n",
      "2, 6f8cd79b.json ensemble accuracy 1.0\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/6fa7a44f.json\n",
      "6, 72322fa7.json ensemble accuracy 0.9473684210526315\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/72ca375d.json\n",
      "4, 73251a56.json ensemble accuracy 0.8866213151927438\n",
      "2, 7447852a.json ensemble accuracy 0.8133333333333334\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/7468f01a.json\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/746b3537.json\n",
      "6, 74dd1130.json ensemble accuracy 0.3333333333333333\n",
      "7, 75b8110e.json ensemble accuracy 0.4375\n",
      "3, 760b3cac.json ensemble accuracy 0.8333333333333334\n",
      "6, 776ffc46.json ensemble accuracy 0.9475\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/77fdfe62.json\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/780d0b14.json\n",
      "7, 7837ac64.json ensemble accuracy 0.4444444444444444\n",
      "3, 794b24be.json ensemble accuracy 1.0\n",
      "3, 794b24be.json ensemble accuracy 0.8888888888888888\n",
      "5, 7b6016b9.json ensemble accuracy 0.9181818181818182\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/7b7f7511.json\n",
      "7, 7c008303.json ensemble accuracy 0.6111111111111112\n",
      "6, 7ddcd7ec.json ensemble accuracy 0.91\n",
      "3, 7df24a62.json ensemble accuracy 0.9187145557655955\n",
      "4, 7e0986d6.json ensemble accuracy 0.5392156862745098\n",
      "6, 7f4411dc.json ensemble accuracy 0.99\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/7fe24cdd.json\n",
      "7, 80af3007.json ensemble accuracy 0.5555555555555556\n",
      "2, 810b9b61.json ensemble accuracy 0.9236111111111112\n",
      "6, 82819916.json ensemble accuracy 0.8428571428571429\n",
      "5, 83302e8f.json ensemble accuracy 0.7462277091906722\n",
      "5, 834ec97d.json ensemble accuracy 0.7291666666666666\n",
      "5, 8403a5d5.json ensemble accuracy 0.65\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/846bdb03.json\n",
      "6, 855e0971.json ensemble accuracy 0.7450980392156863\n",
      "6, 85c4e7cd.json ensemble accuracy 0.1326530612244898\n",
      "2, 868de0fa.json ensemble accuracy 0.71\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/8731374e.json\n",
      "4, 88a10436.json ensemble accuracy 0.9545454545454546\n",
      "7, 88a62173.json ensemble accuracy 0.5\n",
      "6, 890034e9.json ensemble accuracy 0.9523809523809523\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/8a004b2b.json\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/8be77c9e.json\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/8d5021e8.json\n",
      "3, 8d510a79.json ensemble accuracy 0.91\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/8e1813be.json\n",
      "4, 8e5a5113.json ensemble accuracy 0.24242424242424243\n",
      "6, 8eb1be9a.json ensemble accuracy 0.8846153846153846\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/8efcae92.json\n",
      "6, 8f2ea7aa.json ensemble accuracy 0.8024691358024691\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/90c28cc7.json\n",
      "2, 90f3ed37.json ensemble accuracy 0.9466666666666667\n",
      "5, 913fb3ed.json ensemble accuracy 0.94921875\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/91413438.json\n",
      "1, 91714a58.json ensemble accuracy 0.953125\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/9172f3a0.json\n",
      "6, 928ad970.json ensemble accuracy 0.8666666666666667\n",
      "6, 93b581b8.json ensemble accuracy 0.6111111111111112\n",
      "2, 941d9a10.json ensemble accuracy 0.97\n",
      "7, 94f9d214.json ensemble accuracy 0.75\n",
      "6, 952a094c.json ensemble accuracy 0.78\n",
      "6, 9565186b.json ensemble accuracy 0.5555555555555556\n",
      "2, 95990924.json ensemble accuracy 0.9155555555555556\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/963e52fc.json\n",
      "5, 97999447.json ensemble accuracy 0.9722222222222222\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/97a05b5b.json\n",
      "6, 98cf29f8.json ensemble accuracy 0.8382352941176471\n",
      "7, 995c5fa3.json ensemble accuracy 0.0\n",
      "7, 99b1bc43.json ensemble accuracy 0.625\n",
      "6, 99fa7670.json ensemble accuracy 0.9464285714285714\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/9aec4887.json\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/9af7a82c.json\n",
      "6, 9d9215db.json ensemble accuracy 0.8698060941828255\n",
      "6, 9dfd6313.json ensemble accuracy 0.8055555555555556\n",
      "7, 9ecd008a.json ensemble accuracy 0.0\n",
      "3, 9edfc990.json ensemble accuracy 0.84765625\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/9f236235.json\n",
      "3, a1570a43.json ensemble accuracy 0.8875\n",
      "2, a2fd1cf0.json ensemble accuracy 0.9642857142857143\n",
      "*******************reprediction success**********************\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/a3325580.json\n",
      "3, a3df8b1e.json ensemble accuracy 0.84\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/a416b8f3.json\n",
      "3, a48eeaf7.json ensemble accuracy 0.93\n",
      "2, a5313dff.json ensemble accuracy 0.9876543209876543\n",
      "5, a5f85a15.json ensemble accuracy 0.9513888888888888\n",
      "7, a61ba2ce.json ensemble accuracy 0.25\n",
      "2, a61f2674.json ensemble accuracy 0.9506172839506173\n",
      "5, a64e4611.json ensemble accuracy 0.9611111111111111\n",
      "2, a65b410d.json ensemble accuracy 0.8888888888888888\n",
      "7, a68b268e.json ensemble accuracy 0.8125\n",
      "2, a699fb00.json ensemble accuracy 0.99\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/a740d043.json\n",
      "4, a78176bb.json ensemble accuracy 0.82\n",
      "3, a79310a0.json ensemble accuracy 1.0\n",
      "3, a85d4709.json ensemble accuracy 1.0\n",
      "7, a87f7484.json ensemble accuracy 0.3333333333333333\n",
      "7, a8c38be5.json ensemble accuracy 0.16049382716049382\n",
      "2, a8d7556c.json ensemble accuracy 0.9969135802469136\n",
      "3, a9f96cdd.json ensemble accuracy 1.0\n",
      "4, aabf363d.json ensemble accuracy 0.673469387755102\n",
      "5, aba27056.json ensemble accuracy 0.76\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/ac0a08a4.json\n",
      "3, ae3edfdc.json ensemble accuracy 0.9911111111111112\n",
      "7, ae4f1146.json ensemble accuracy 0.0\n",
      "2, aedd82e4.json ensemble accuracy 1.0\n",
      "2, af902bf9.json ensemble accuracy 0.9\n",
      "7, b0c4d837.json ensemble accuracy 0.8888888888888888\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/b190f7f5.json\n",
      "3, b1948b0a.json ensemble accuracy 1.0\n",
      "2, b230c067.json ensemble accuracy 0.92\n",
      "2, b27ca6d3.json ensemble accuracy 0.9007352941176471\n",
      "2, b2862040.json ensemble accuracy 0.9208333333333333\n",
      "3, b527c5c6.json ensemble accuracy 0.5625\n",
      "4, b548a754.json ensemble accuracy 0.621301775147929\n",
      "2, b60334d2.json ensemble accuracy 1.0\n",
      "2, b6afb2da.json ensemble accuracy 1.0\n",
      "6, b7249182.json ensemble accuracy 0.8771929824561403\n",
      "6, b775ac94.json ensemble accuracy 0.9288194444444444\n",
      "6, b782dc8a.json ensemble accuracy 0.7866666666666666\n",
      "4, b8825c91.json ensemble accuracy 0.9140625\n",
      "6, b8cdaf2b.json ensemble accuracy 0.9135802469135802\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/b91ae062.json\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/b94a9452.json\n",
      "7, b9b7f026.json ensemble accuracy 0.0\n",
      "2, ba26e723.json ensemble accuracy 0.9215686274509803\n",
      "6, ba97ae07.json ensemble accuracy 1.0\n",
      "2, bb43febb.json ensemble accuracy 1.0\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/bbc9ae5d.json\n",
      "7, bc1d5164.json ensemble accuracy 0.4444444444444444\n",
      "4, bd4472b8.json ensemble accuracy 0.31666666666666665\n",
      "6, bda2d7a6.json ensemble accuracy 0.5\n",
      "6, bda2d7a6.json ensemble accuracy 0.6875\n",
      "2, bdad9b1f.json ensemble accuracy 1.0\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/be94b721.json\n",
      "6, beb8660c.json ensemble accuracy 0.625\n",
      "2, c0f76784.json ensemble accuracy 1.0\n",
      "5, c1d99e64.json ensemble accuracy 1.0\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/c3e719e8.json\n",
      "4, c3f564a4.json ensemble accuracy 0.83984375\n",
      "6, c444b776.json ensemble accuracy 0.9237749546279492\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/c59eb873.json\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/training/c8cbb738.json\n",
      "3, c8f0f002.json ensemble accuracy 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:100: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-feb211ee81f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msample_sub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_taskids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_xgb_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ids\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodelling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_xgb_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_ids\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmodelling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-feb211ee81f0>\u001b[0m in \u001b[0;36mmodelling\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mclass_num\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                     \u001b[0mens_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mpreds_7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_row\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mout_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                     \u001b[0mnew_ens_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mnew_test_preds_7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_row\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mout_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bool' object has no attribute 'sum'"
     ]
    }
   ],
   "source": [
    "nfeat = 32\n",
    "local_neighb = 5\n",
    "def modelling(mode):\n",
    "    print(mode)\n",
    "    count = 0\n",
    "    reproduction = 0\n",
    "    sample_sub = pd.read_csv(data_path/'sample_submission.csv')\n",
    "    sample_sub = sample_sub.set_index('output_id')\n",
    "    \n",
    "    valid_scores = {}\n",
    "    model_accuracies = {'ens': []}\n",
    "    pred_taskids = []\n",
    "    \n",
    "    if mode=='eval':\n",
    "        task_path = evaluation_path\n",
    "        df = evaluation_descriptive_df\n",
    "    elif mode=='train':\n",
    "        task_path = training_path\n",
    "        df = training_descriptive_df\n",
    "    elif mode=='test':\n",
    "        task_path = test_path\n",
    "        df = test_descriptive_df\n",
    "    all_task_ids = sorted(os.listdir(task_path))\n",
    "    # training ----------\n",
    "    for task_id in all_task_ids:\n",
    "        class_num = df[df.task_name==task_id][\"class\"].values[0]\n",
    "        task_file = str(task_path / task_id)\n",
    "        with open(task_file, 'r') as f:\n",
    "            task = json.load(f)\n",
    "        \n",
    "        if mode != \"test\":\n",
    "            task = preprocess(task, task_id)\n",
    "\n",
    "        if class_num == 1 or class_num == 3 or class_num == 5 or class_num == 6:\n",
    "            _, _, not_valid = features(task)\n",
    "            if not_valid:\n",
    "                print(str(class_num) + ' ignoring task', task_file)\n",
    "                count += 1\n",
    "                continue\n",
    "            task[\"train\"] = data_aug3(task[\"train\"])\n",
    "            feat, target, _ = features(task)\n",
    "            \n",
    "        elif class_num == 2 or class_num == 4:\n",
    "            _, _, not_valid = features(task)\n",
    "            if not_valid:\n",
    "                print(str(class_num) + ' ignoring task', task_file)\n",
    "                count += 1\n",
    "                continue\n",
    "            task[\"train\"] = data_aug(task[\"train\"])\n",
    "            feat, target, _ = features(task)\n",
    "            \n",
    "        elif class_num == 7:\n",
    "            task[\"train\"], out_row, out_col = padding(task[\"train\"])\n",
    "            task[\"train\"] = data_aug(task[\"train\"])\n",
    "            feat, target, _ = features(task)\n",
    "            \n",
    "        else:\n",
    "            feat, target, not_valid = features(task)\n",
    "            if not_valid:\n",
    "                print(str(class_num) + ' ignoring task', task_file)\n",
    "                count += 1\n",
    "                continue\n",
    "         \n",
    "        model = XGBClassifier(n_estimators=50, max_depth = 5, num_leaves=10, learning_rate=0.1, n_jobs=-1)        \n",
    "        model.fit(feat, target, verbose=0)\n",
    "    # training on input pairs is done ----------\n",
    "    \n",
    "    # reprediction -------\n",
    "        num_train_pairs = len(task[\"train\"])\n",
    "        count_rep = 0\n",
    "        new_tasks = []\n",
    "        for task_num in range(num_train_pairs):\n",
    "            nrows, ncols = np.array(task['train'][task_num]['input']).shape[0], np.array(task['train'][task_num]['input']).shape[1]\n",
    "            tmp_feat = feat[count_rep:count_rep+nrows*ncols,:]\n",
    "            tmp_target = task['train'][task_num]['output']\n",
    "            train_preds = model.predict(tmp_feat).reshape(nrows,ncols).tolist()\n",
    "            tmp_dict = {\"input\": train_preds, \"output\": tmp_target}\n",
    "            new_tasks.append(tmp_dict)\n",
    "            count_rep += nrows * ncols\n",
    "        new_feat, new_target, _ = new_features(new_tasks)\n",
    "        model2 = XGBClassifier(n_estimators=50, max_depth = 5, num_leaves=10, learning_rate=0.1, n_jobs=-1)\n",
    "        model2.fit(new_feat, new_target, verbose=0)\n",
    "    # -------\n",
    "    \n",
    "    # test predictions begins here\n",
    "        num_test_pairs = len(task['test'])\n",
    "        for task_num in range(num_test_pairs):\n",
    "            cur_idx = 0\n",
    "            input_color = np.array(task['test'][task_num]['input'])\n",
    "            nrows, ncols = len(task['test'][task_num]['input']), len(task['test'][task_num]['input'][0])\n",
    "            feat = make_features(input_color, nfeat)\n",
    "            preds = model.predict(feat).reshape(nrows,ncols)\n",
    "            new_test_feat = make_features(preds, nfeat) #**\n",
    "            new_test_preds = model2.predict(new_test_feat).reshape(nrows,ncols) #**\n",
    "            if class_num == 7:\n",
    "                preds_7 = np.array(preds)[:out_row, :out_col]\n",
    "                new_test_preds_7 = np.array(new_test_preds)[:out_row, :out_col]\n",
    "            if (mode=='train') or (mode=='eval'):\n",
    "                if class_num == 7:                    \n",
    "                    ens_acc = (np.array(task['test'][task_num]['output'])==preds_7).sum()/(out_row*out_col)\n",
    "                    new_ens_acc = (np.array(task['test'][task_num]['output'])==new_test_preds_7).sum()/(out_row*out_col)\n",
    "                else:\n",
    "                    ens_acc = (np.array(task['test'][task_num]['output'])==preds).sum()/(nrows*ncols)\n",
    "                    new_ens_acc = (np.array(task['test'][task_num]['output'])==new_test_preds).sum()/(nrows*ncols)\n",
    "                model_accuracies['ens'].append(ens_acc)\n",
    "                pred_taskids.append(f'{task_id[:-5]}_{task_num}')\n",
    "                print(str(class_num) + \", \" + str(task_id) + ' ensemble accuracy',ens_acc)\n",
    "                if ens_acc < 1 and new_ens_acc == 1:\n",
    "                    print(\"*******************reprediction success**********************\")\n",
    "                    reproduction += 1\n",
    "            else:\n",
    "                if class_num == 7:\n",
    "                    preds_7 = preds7.astype(int).tolist()\n",
    "                    new_test_preds7 = new_test_preds_7.astype(int).tolist()\n",
    "                    sample_sub.loc[f'{task_id[:-5]}_{task_num}','output'] = flattener(preds_7)+\" \"+flattener(new_test_preds_7) #flattener(preds)\n",
    "                else:\n",
    "                    preds = preds.astype(int).tolist()\n",
    "                    new_test_preds = new_test_preds.astype(int).tolist()\n",
    "                    sample_sub.loc[f'{task_id[:-5]}_{task_num}','output'] = flattener(preds)+\" \"+flattener(new_test_preds) #flattener(preds)\n",
    "    print(str(count) + \" tasks were ignored.\")\n",
    "    print(str(reproduction) + \" tasks were corrected\")\n",
    "    return sample_sub, model_accuracies, pred_taskids\n",
    "\n",
    "_, train_xgb_accuracies, train_ids= modelling('train')\n",
    "_, eval_xgb_accuracies, eval_ids  = modelling('eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_xgb_accuracies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ff80c7d2b9d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_xgb_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'for {c} no. of complete training tasks is'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'for {c} no. of complete training tasks is'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_xgb_accuracies' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(train_xgb_accuracies, index=train_ids)\n",
    "for c in df.columns:\n",
    "    print(f'for {c} no. of complete training tasks is', (df.loc[:, c]==1).sum())\n",
    "    print(df[df.loc[:, c]==1].index)\n",
    "    print(f'for {c} no. of complete training tasks is', (df.loc[:, c]>0.9).sum())\n",
    "\n",
    "df = pd.DataFrame(eval_xgb_accuracies, index=eval_ids)\n",
    "for c in df.columns:\n",
    "    print(f'for {c} no. of complete evaluation tasks is', (df.loc[:, c]==1).sum())\n",
    "    print(df[df.loc[:, c]==1].index)\n",
    "    print(f'for {c} no. of complete evaluation tasks is', (df.loc[:, c]>0.9).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/00576224.json\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/0692e18c.json\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/0934a4d8.json\n",
      "8 ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/0a1d4ef5.json\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'preds7' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-32b74a939469>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_xgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_xgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"submission.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-feb211ee81f0>\u001b[0m in \u001b[0;36mmodelling\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mclass_num\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0mpreds_7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                     \u001b[0mnew_test_preds7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_test_preds_7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0msample_sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{task_id[:-5]}_{task_num}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflattener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mflattener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_test_preds_7\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#flattener(preds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preds7' is not defined"
     ]
    }
   ],
   "source": [
    "test_xgb, _, _ = modelling('test')\n",
    "test_xgb.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_sub = test_xgb.reset_index()\n",
    "#final_sub = final_sub.sort_values(by=\"output_id\")\n",
    "\n",
    "#test_lgb = test_lgb.sort_values(by=\"output_id\")\n",
    "#test_cat = test_cat.sort_values(by=\"output_id\")\n",
    "#out1 = final_sub[\"output\"].astype(str).values\n",
    "#out2 = test_lgb[\"output\"].astype(str).values\n",
    "#out3 = test_cat[\"output\"].astype(str).values\n",
    "\n",
    "#merge_output = []\n",
    "#for o1, o2, o3 in zip(out1, out2, out3):\n",
    "#    o = o1.strip().split(\" \")[:1] + o2.strip().split(\" \")[:1] + o2.strip().split(\" \")[:1]\n",
    "#    o = \" \".join(o[:3])\n",
    "#    merge_output.append(o)\n",
    "#final_sub[\"output\"] = merge_output\n",
    "#final_sub[\"output\"] = final_sub[\"output\"].astype(str)\n",
    "#final_sub.to_csv(\"submission.csv\", index=False)\n",
    "#final_sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
