{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030438,
     "end_time": "2020-12-08T14:39:56.021651",
     "exception": false,
     "start_time": "2020-12-08T14:39:55.991213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- modify mistake in test prediction in got_point_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-12-08T14:39:56.075683Z",
     "iopub.status.busy": "2020-12-08T14:39:56.074806Z",
     "iopub.status.idle": "2020-12-08T14:40:28.134931Z",
     "shell.execute_reply": "2020-12-08T14:40:28.134023Z"
    },
    "papermill": {
     "duration": 32.089399,
     "end_time": "2020-12-08T14:40:28.135073",
     "exception": false,
     "start_time": "2020-12-08T14:39:56.045674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install ../input/python-datatable/datatable-0.11.0-cp37-cp37m-manylinux2010_x86_64.whl > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-12-08T14:40:28.193168Z",
     "iopub.status.busy": "2020-12-08T14:40:28.192003Z",
     "iopub.status.idle": "2020-12-08T14:40:29.830469Z",
     "shell.execute_reply": "2020-12-08T14:40:29.829582Z"
    },
    "papermill": {
     "duration": 1.671676,
     "end_time": "2020-12-08T14:40:29.830654",
     "exception": false,
     "start_time": "2020-12-08T14:40:28.158978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n",
      "  del sys.path[0]\n",
      "/opt/conda/lib/python3.7/site-packages/tqdm/std.py:666: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import datatable as dt\n",
    "import lightgbm as lgb\n",
    "from matplotlib import pyplot as plt\n",
    "import riiideducation\n",
    "from bitarray import bitarray\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas(desc=\"progress: \")\n",
    "\n",
    "_ = np.seterr(divide='ignore', invalid='ignore')\n",
    "pd.set_option(\"max_columns\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T14:40:29.886531Z",
     "iopub.status.busy": "2020-12-08T14:40:29.885707Z",
     "iopub.status.idle": "2020-12-08T14:40:29.888861Z",
     "shell.execute_reply": "2020-12-08T14:40:29.888250Z"
    },
    "papermill": {
     "duration": 0.033179,
     "end_time": "2020-12-08T14:40:29.889004",
     "exception": false,
     "start_time": "2020-12-08T14:40:29.855825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_bitarray():\n",
    "    a = bitarray(32737, endian='little')\n",
    "    a.setall(True)   \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T14:40:29.943434Z",
     "iopub.status.busy": "2020-12-08T14:40:29.942267Z",
     "iopub.status.idle": "2020-12-08T14:40:29.945994Z",
     "shell.execute_reply": "2020-12-08T14:40:29.945164Z"
    },
    "papermill": {
     "duration": 0.032857,
     "end_time": "2020-12-08T14:40:29.946129",
     "exception": false,
     "start_time": "2020-12-08T14:40:29.913272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FULL_TRAIN = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024081,
     "end_time": "2020-12-08T14:40:29.995162",
     "exception": false,
     "start_time": "2020-12-08T14:40:29.971081",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T14:40:30.054740Z",
     "iopub.status.busy": "2020-12-08T14:40:30.053746Z",
     "iopub.status.idle": "2020-12-08T14:40:30.057159Z",
     "shell.execute_reply": "2020-12-08T14:40:30.056366Z"
    },
    "papermill": {
     "duration": 0.034462,
     "end_time": "2020-12-08T14:40:30.057284",
     "exception": false,
     "start_time": "2020-12-08T14:40:30.022822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_types_dict = {\n",
    "    #'row_id': 'uint32',\n",
    "    'timestamp': 'uint64',\n",
    "    'user_id': 'int32', \n",
    "    'content_id': 'int16', \n",
    "    'answered_correctly': 'int8', \n",
    "    'prior_question_elapsed_time': 'float32', \n",
    "    'prior_question_had_explanation': 'bool',\n",
    "}\n",
    "target = 'answered_correctly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T14:40:30.116965Z",
     "iopub.status.busy": "2020-12-08T14:40:30.115775Z",
     "iopub.status.idle": "2020-12-08T14:43:17.153800Z",
     "shell.execute_reply": "2020-12-08T14:43:17.152925Z"
    },
    "papermill": {
     "duration": 167.071959,
     "end_time": "2020-12-08T14:43:17.153943",
     "exception": false,
     "start_time": "2020-12-08T14:40:30.081984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = dt.fread('../input/riiid-test-answer-prediction/train.csv', columns=set(data_types_dict.keys())).to_pandas()\n",
    "train_df = train_df[train_df[target] != -1].reset_index(drop=True)\n",
    "\n",
    "train_df['prior_question_had_explanation'].fillna(False, inplace=True)\n",
    "train_df['prior_question_elapsed_time'].fillna(0, inplace=True)\n",
    "\n",
    "train_df['timestamp'] = (train_df['timestamp'] // 86400000) + 1 # days from start\n",
    "train_df = train_df.astype(data_types_dict)\n",
    "\n",
    "if FULL_TRAIN:\n",
    "    train_size = 100\n",
    "else:\n",
    "    train_size = 24\n",
    "    valid_size = 6\n",
    "    \n",
    "train_index = list(train_df.groupby('user_id').tail(train_size).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T14:43:17.217617Z",
     "iopub.status.busy": "2020-12-08T14:43:17.212993Z",
     "iopub.status.idle": "2020-12-08T14:43:33.747811Z",
     "shell.execute_reply": "2020-12-08T14:43:33.746771Z"
    },
    "papermill": {
     "duration": 16.568833,
     "end_time": "2020-12-08T14:43:33.747967",
     "exception": false,
     "start_time": "2020-12-08T14:43:17.179134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "questions_df = pd.read_csv(\n",
    "    '../input/riiid-test-answer-prediction/questions.csv', \n",
    "    usecols=[0, 3, 4], \n",
    "    dtype={'question_id': 'int16', 'part': 'int8', 'tags': 'str'} \n",
    ")\n",
    "\n",
    "#questions_df['tags'] = questions_df['tags'].apply(lambda ts: [int(x) for x in str(ts).split() if x != 'nan'])\n",
    "\n",
    "#def join(df):\n",
    "#    x = [str(e) for e in list(df)]\n",
    "#    return \" \".join(x)\n",
    "\n",
    "#ids = [\"tags\"]\n",
    "#tfidf_svd_feats = []\n",
    "\n",
    "#for id_ in ids:\n",
    "#    print(id_)\n",
    "#    docs = questions_df.groupby(\"question_id\")[id_].apply(join)\n",
    "#    max_features = int(questions_df[id_].nunique() * 0.8)\n",
    "#    tv = TfidfVectorizer(max_features=max_features)\n",
    "#    X = tv.fit_transform(docs)\n",
    "\n",
    "#    n_components = 3\n",
    "#    svd = TruncatedSVD(n_components=n_components, random_state=0)\n",
    "#    X = svd.fit_transform(X)\n",
    "#    df = pd.DataFrame(X, columns=[f\"tfidf_{id_}_{i}\" for i in range(n_components)])\n",
    "#    df.index = docs.index\n",
    "#    tfidf_svd_feats += [f\"tfidf_{id_}_{i}\" for i in range(n_components)]\n",
    "    \n",
    "#kmeans = KMeans(n_clusters=20, random_state=0).fit(df.values)\n",
    "#df[\"tag_class\"] = kmeans.labels_\n",
    "\n",
    "train_df = pd.merge(train_df, questions_df[[\"question_id\", \"part\"]], left_on='content_id', right_on='question_id', how='left', right_index=True).reset_index(drop=True)\n",
    "train_df.drop(columns=['question_id'], inplace=True)\n",
    "\n",
    "#train_df = pd.merge(train_df, df, left_on='content_id', right_on='question_id', how='left')\n",
    "#train_df.drop(tfidf_svd_feats, axis=1, inplace=True)\n",
    "#tag_class_array = train_df.tag_class.values\n",
    "#train_df.drop(\"tag_class\", axis=1, inplace=True)\n",
    "#tag_class_array = tag_class_array[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T14:43:33.810623Z",
     "iopub.status.busy": "2020-12-08T14:43:33.808960Z",
     "iopub.status.idle": "2020-12-08T14:43:53.286502Z",
     "shell.execute_reply": "2020-12-08T14:43:53.285575Z"
    },
    "papermill": {
     "duration": 19.512559,
     "end_time": "2020-12-08T14:43:53.286652",
     "exception": false,
     "start_time": "2020-12-08T14:43:33.774093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['lag'] = train_df.groupby('user_id')[target].shift()\n",
    "cum = train_df.groupby('user_id')['lag'].agg(['cumsum', 'cumcount'])\n",
    "user_correctness_array = np.array(cum['cumsum'] / cum['cumcount'])\n",
    "user_correctness_array = user_correctness_array[train_index]\n",
    "train_df.drop(columns=['lag'], inplace=True)\n",
    "del cum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T14:43:53.461198Z",
     "iopub.status.busy": "2020-12-08T14:43:53.346878Z",
     "iopub.status.idle": "2020-12-08T14:48:34.257842Z",
     "shell.execute_reply": "2020-12-08T14:48:34.256944Z"
    },
    "papermill": {
     "duration": 280.94595,
     "end_time": "2020-12-08T14:48:34.258016",
     "exception": false,
     "start_time": "2020-12-08T14:43:53.312066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(1)\n",
    "train_df[\"part_count\"] = train_df[\"part\"] ==1\n",
    "train_df[\"part_count\"] = train_df[\"part_count\"].astype(\"int8\")\n",
    "train_df['part_count_lag'] = train_df.groupby('user_id')[\"part_count\"].shift()\n",
    "part1_count_array = train_df.groupby('user_id')['part_count_lag'].agg(['cumsum']).values\n",
    "part1_count_array = part1_count_array[train_index] \n",
    "train_df.drop(columns=['part_count_lag', 'part_count'], inplace=True)\n",
    "\n",
    "#\n",
    "print(2)\n",
    "train_df[\"part_count\"] = train_df[\"part\"] ==2\n",
    "train_df[\"part_count\"] = train_df[\"part_count\"].astype(\"int8\")\n",
    "train_df['part_count_lag'] = train_df.groupby('user_id')[\"part_count\"].shift()\n",
    "part2_count_array = train_df.groupby('user_id')['part_count_lag'].agg(['cumsum']).values\n",
    "part2_count_array = part2_count_array[train_index] \n",
    "train_df.drop(columns=['part_count_lag', 'part_count'], inplace=True)\n",
    "\n",
    "#\n",
    "print(3)\n",
    "train_df[\"part_count\"] = train_df[\"part\"] ==3\n",
    "train_df[\"part_count\"] = train_df[\"part_count\"].astype(\"int8\")\n",
    "train_df['part_count_lag'] = train_df.groupby('user_id')[\"part_count\"].shift()\n",
    "part3_count_array = train_df.groupby('user_id')['part_count_lag'].agg(['cumsum']).values\n",
    "part3_count_array = part3_count_array[train_index] \n",
    "train_df.drop(columns=['part_count_lag', 'part_count'], inplace=True)\n",
    "\n",
    "#\n",
    "print(4)\n",
    "train_df[\"part_count\"] = train_df[\"part\"] ==4\n",
    "train_df[\"part_count\"] = train_df[\"part_count\"].astype(\"int8\")\n",
    "train_df['part_count_lag'] = train_df.groupby('user_id')[\"part_count\"].shift()\n",
    "part4_count_array = train_df.groupby('user_id')['part_count_lag'].agg(['cumsum']).values\n",
    "part4_count_array = part4_count_array[train_index] \n",
    "train_df.drop(columns=['part_count_lag', 'part_count'], inplace=True)\n",
    "\n",
    "#\n",
    "print(5)\n",
    "train_df[\"part_count\"] = train_df[\"part\"] ==5\n",
    "train_df[\"part_count\"] = train_df[\"part_count\"].astype(\"int8\")\n",
    "train_df['part_count_lag'] = train_df.groupby('user_id')[\"part_count\"].shift()\n",
    "part5_count_array = train_df.groupby('user_id')['part_count_lag'].agg(['cumsum']).values\n",
    "part5_count_array = part5_count_array[train_index] \n",
    "train_df.drop(columns=['part_count_lag', 'part_count'], inplace=True)\n",
    "\n",
    "#\n",
    "print(6)\n",
    "train_df[\"part_count\"] = train_df[\"part\"] ==6\n",
    "train_df[\"part_count\"] = train_df[\"part_count\"].astype(\"int8\")\n",
    "train_df['part_count_lag'] = train_df.groupby('user_id')[\"part_count\"].shift()\n",
    "part6_count_array = train_df.groupby('user_id')['part_count_lag'].agg(['cumsum']).values\n",
    "part6_count_array = part6_count_array[train_index] \n",
    "train_df.drop(columns=['part_count_lag', 'part_count'], inplace=True)\n",
    "\n",
    "#\n",
    "print(7)\n",
    "train_df[\"part_count\"] = train_df[\"part\"] ==7\n",
    "train_df[\"part_count\"] = train_df[\"part_count\"].astype(\"int8\")\n",
    "train_df['part_count_lag'] = train_df.groupby('user_id')[\"part_count\"].shift()\n",
    "part7_count_array = train_df.groupby('user_id')['part_count_lag'].agg(['cumsum']).values\n",
    "part7_count_array = part7_count_array[train_index] \n",
    "train_df.drop(columns=['part_count_lag', 'part_count'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T14:48:34.330015Z",
     "iopub.status.busy": "2020-12-08T14:48:34.329086Z",
     "iopub.status.idle": "2020-12-08T14:49:06.220782Z",
     "shell.execute_reply": "2020-12-08T14:49:06.220120Z"
    },
    "papermill": {
     "duration": 31.932708,
     "end_time": "2020-12-08T14:49:06.220939",
     "exception": false,
     "start_time": "2020-12-08T14:48:34.288231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prior_question_had_explanation_mean\n",
    "train_df['lag'] = train_df.groupby('user_id')['prior_question_had_explanation'].shift().astype(bool)\n",
    "cum = train_df.groupby('user_id')['lag'].agg(['cumsum', 'cumcount'])\n",
    "prior_question_had_explanation_mean_array = np.array(cum['cumsum'] / cum['cumcount'])\n",
    "prior_question_had_explanation_mean_array = prior_question_had_explanation_mean_array[train_index]\n",
    "\n",
    "user_prior_question_had_explanation_sum_agg = train_df.groupby('user_id')[\"prior_question_had_explanation\"].agg(['sum'])\n",
    "user_prior_question_had_explanation_sum_dict = user_prior_question_had_explanation_sum_agg['sum'].astype('int32').to_dict(defaultdict(int))\n",
    "train_df.drop(columns=['lag'], inplace=True)\n",
    "del cum, user_prior_question_had_explanation_sum_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T14:49:06.293797Z",
     "iopub.status.busy": "2020-12-08T14:49:06.292944Z",
     "iopub.status.idle": "2020-12-08T14:50:05.885529Z",
     "shell.execute_reply": "2020-12-08T14:50:05.884675Z"
    },
    "papermill": {
     "duration": 59.635054,
     "end_time": "2020-12-08T14:50:05.885668",
     "exception": false,
     "start_time": "2020-12-08T14:49:06.250614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_attempt_df = pd.read_csv(\"../input/riiid-additional-data/content_first_attempt.csv\")\n",
    "first_attempt_array = first_attempt_df.first_attempt.values\n",
    "train_df[\"first_attempt\"] = first_attempt_array\n",
    "unique_attempt_array= train_df.groupby(\"user_id\")[\"first_attempt\"].cumsum().values\n",
    "train_df[\"unique_attempt\"] = unique_attempt_array\n",
    "user_unique_agg = train_df.groupby('user_id')[\"unique_attempt\"].agg(['max'])\n",
    "user_unique_dict = user_unique_agg['max'].astype('int32').to_dict(defaultdict(int))\n",
    "\n",
    "first_attempt_array = first_attempt_array[train_index]\n",
    "unique_attempt_array = unique_attempt_array[train_index]\n",
    "train_df.drop(['first_attempt', 'unique_attempt'], axis=1, inplace=True)\n",
    "del first_attempt_df, user_unique_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T14:50:05.975758Z",
     "iopub.status.busy": "2020-12-08T14:50:05.974134Z",
     "iopub.status.idle": "2020-12-08T14:51:47.424678Z",
     "shell.execute_reply": "2020-12-08T14:51:47.423753Z"
    },
    "papermill": {
     "duration": 101.510467,
     "end_time": "2020-12-08T14:51:47.424835",
     "exception": false,
     "start_time": "2020-12-08T14:50:05.914368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_agg = train_df.groupby('user_id')[target].agg(['sum', 'count'])\n",
    "content_agg = train_df.groupby('content_id')[target].agg(['sum', 'count'])\n",
    "\n",
    "user_sum_dict = user_agg['sum'].astype('int16').to_dict(defaultdict(int))\n",
    "user_count_dict = user_agg['count'].astype('int16').to_dict(defaultdict(int))\n",
    "content_sum_dict = content_agg['sum'].astype('int32').to_dict(defaultdict(int))\n",
    "content_count_dict = content_agg['count'].astype('int32').to_dict(defaultdict(int))\n",
    "\n",
    "content_count_array = train_df['content_id'].map(content_agg['count']).astype('int32').values\n",
    "content_id_array = train_df['content_id'].map(content_agg['sum'] / content_agg['count']).values\n",
    "\n",
    "# benefit of solving difficult questions\n",
    "# https://stackoverflow.com/questions/35215161/most-efficient-way-to-map-function-over-numpy-array\n",
    "func = lambda t: 1/(t + 0.1)\n",
    "vfunc = np.vectorize(func)\n",
    "point_array = vfunc(content_id_array)\n",
    "train_df[\"point\"] = point_array\n",
    "train_df[\"got_point\"] = point_array * train_df[\"answered_correctly\"].values\n",
    "user_point_agg = train_df.groupby('user_id')[\"got_point\"].agg(['sum'])\n",
    "user_point_sum_dict = user_point_agg['sum'].astype('float32').to_dict(defaultdict(float))\n",
    "\n",
    "train_df['lag'] = train_df.groupby('user_id')[\"got_point\"].shift()\n",
    "cum = train_df.groupby('user_id')['lag'].agg(['cumsum', 'cumcount'])\n",
    "got_point_array = np.array(cum['cumsum'] / cum['cumcount'])\n",
    "train_df.drop(columns=['lag'], inplace=True)\n",
    "\n",
    "train_df.drop(columns=['point', 'got_point'], inplace=True)\n",
    "del cum, user_agg, content_agg\n",
    "\n",
    "content_count_array = content_count_array[train_index]\n",
    "content_id_array = content_id_array[train_index]\n",
    "got_point_array = got_point_array[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T14:51:47.495871Z",
     "iopub.status.busy": "2020-12-08T14:51:47.494914Z",
     "iopub.status.idle": "2020-12-08T14:54:18.446656Z",
     "shell.execute_reply": "2020-12-08T14:54:18.447479Z"
    },
    "papermill": {
     "duration": 150.991934,
     "end_time": "2020-12-08T14:54:18.447672",
     "exception": false,
     "start_time": "2020-12-08T14:51:47.455738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 27s, sys: 3.02 s, total: 2min 30s\n",
      "Wall time: 2min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "user_content_agg = train_df.groupby(\"user_id\")[\"content_id\"].unique().reset_index().set_index(\"user_id\")\n",
    "\n",
    "value = []\n",
    "for j in user_content_agg.index:\n",
    "    a = bitarray(32737, endian='little')\n",
    "    a.setall(True)\n",
    "    for i in user_content_agg.loc[j][0]:\n",
    "        a[i] = 0\n",
    "    value.append(a)\n",
    "    \n",
    "user_content_agg[\"content_exp\"] = value\n",
    "\n",
    "user_content_dict = user_content_agg[\"content_exp\"].to_dict(defaultdict(make_bitarray))\n",
    "del user_content_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T14:54:18.515712Z",
     "iopub.status.busy": "2020-12-08T14:54:18.514567Z",
     "iopub.status.idle": "2020-12-08T14:54:26.753085Z",
     "shell.execute_reply": "2020-12-08T14:54:26.752374Z"
    },
    "papermill": {
     "duration": 8.275291,
     "end_time": "2020-12-08T14:54:26.753214",
     "exception": false,
     "start_time": "2020-12-08T14:54:18.477923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df[\"count\"] = 1\n",
    "count_array = train_df.groupby(\"user_id\")[\"count\"].cumsum().values\n",
    "count_array = count_array[train_index]\n",
    "train_df.drop(\"count\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T14:54:26.818775Z",
     "iopub.status.busy": "2020-12-08T14:54:26.817919Z",
     "iopub.status.idle": "2020-12-08T14:54:39.714160Z",
     "shell.execute_reply": "2020-12-08T14:54:39.713471Z"
    },
    "papermill": {
     "duration": 12.931888,
     "end_time": "2020-12-08T14:54:39.714330",
     "exception": false,
     "start_time": "2020-12-08T14:54:26.782442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df[\"count_inday\"] = 1\n",
    "count_inday_array = train_df.groupby([\"user_id\",\"timestamp\"])[\"count_inday\"].cumsum().values\n",
    "count_inday_array = count_inday_array[train_index]\n",
    "train_df.drop(\"count_inday\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T14:54:39.783119Z",
     "iopub.status.busy": "2020-12-08T14:54:39.782301Z",
     "iopub.status.idle": "2020-12-08T14:54:52.017851Z",
     "shell.execute_reply": "2020-12-08T14:54:52.014254Z"
    },
    "papermill": {
     "duration": 12.271605,
     "end_time": "2020-12-08T14:54:52.018156",
     "exception": false,
     "start_time": "2020-12-08T14:54:39.746551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = train_df.groupby('user_id').tail(train_size).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T14:54:52.310405Z",
     "iopub.status.busy": "2020-12-08T14:54:52.302411Z",
     "iopub.status.idle": "2020-12-08T14:55:06.420578Z",
     "shell.execute_reply": "2020-12-08T14:55:06.421258Z"
    },
    "papermill": {
     "duration": 14.292921,
     "end_time": "2020-12-08T14:55:06.421551",
     "exception": false,
     "start_time": "2020-12-08T14:54:52.128630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['content_count'] = content_count_array\n",
    "train_df['content_id'] = content_id_array\n",
    "train_df['user_correctness'] = user_correctness_array\n",
    "train_df['first_attempt'] = first_attempt_array\n",
    "train_df['count'] = count_array\n",
    "train_df['count_inday'] = count_inday_array\n",
    "train_df['unique_attempt'] = unique_attempt_array\n",
    "train_df['part1_count'] = part1_count_array\n",
    "train_df['part2_count'] = part2_count_array\n",
    "train_df['part3_count'] = part3_count_array\n",
    "train_df['part4_count'] = part4_count_array\n",
    "train_df['part5_count'] = part5_count_array\n",
    "train_df['part6_count'] = part6_count_array\n",
    "train_df['part7_count'] = part7_count_array\n",
    "train_df['prior_question_had_explanation_mean'] = prior_question_had_explanation_mean_array\n",
    "train_df['got_point'] = got_point_array\n",
    "\n",
    "part1_count_agg = train_df.groupby('user_id')[\"part1_count\"].agg(['max'])\n",
    "part2_count_agg = train_df.groupby('user_id')[\"part2_count\"].agg(['max'])\n",
    "part3_count_agg = train_df.groupby('user_id')[\"part3_count\"].agg(['max'])\n",
    "part4_count_agg = train_df.groupby('user_id')[\"part4_count\"].agg(['max'])\n",
    "part5_count_agg = train_df.groupby('user_id')[\"part5_count\"].agg(['max'])\n",
    "part6_count_agg = train_df.groupby('user_id')[\"part6_count\"].agg(['max'])\n",
    "part7_count_agg = train_df.groupby('user_id')[\"part7_count\"].agg(['max'])\n",
    "part1_count_agg['max'].fillna(0,inplace=True)\n",
    "part2_count_agg['max'].fillna(0,inplace=True)\n",
    "part3_count_agg['max'].fillna(0,inplace=True)\n",
    "part4_count_agg['max'].fillna(0,inplace=True)\n",
    "part5_count_agg['max'].fillna(0,inplace=True)\n",
    "part6_count_agg['max'].fillna(0,inplace=True)\n",
    "part7_count_agg['max'].fillna(0,inplace=True)\n",
    "part1_count_dict = part1_count_agg['max'].astype('int32').to_dict(defaultdict(int))\n",
    "part2_count_dict = part2_count_agg['max'].astype('int32').to_dict(defaultdict(int))\n",
    "part3_count_dict = part3_count_agg['max'].astype('int32').to_dict(defaultdict(int))\n",
    "part4_count_dict = part4_count_agg['max'].astype('int32').to_dict(defaultdict(int))\n",
    "part5_count_dict = part5_count_agg['max'].astype('int32').to_dict(defaultdict(int))\n",
    "part6_count_dict = part6_count_agg['max'].astype('int32').to_dict(defaultdict(int))\n",
    "part7_count_dict = part7_count_agg['max'].astype('int32').to_dict(defaultdict(int))\n",
    "\n",
    "user_timestamp_dict = train_df.groupby(\"user_id\").tail(1)[\"timestamp\"].to_dict(defaultdict(int))\n",
    "user_count_inday_dict = train_df.groupby(\"user_id\").tail(1)[\"count_inday\"].to_dict(defaultdict(int))\n",
    "\n",
    "del part1_count_agg, part2_count_agg, part3_count_agg, part4_count_agg, part5_count_agg, part6_count_agg, part7_count_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T14:55:06.493949Z",
     "iopub.status.busy": "2020-12-08T14:55:06.492889Z",
     "iopub.status.idle": "2020-12-08T14:55:06.496448Z",
     "shell.execute_reply": "2020-12-08T14:55:06.497475Z"
    },
    "papermill": {
     "duration": 0.045052,
     "end_time": "2020-12-08T14:55:06.497647",
     "exception": false,
     "start_time": "2020-12-08T14:55:06.452595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "['user_id']\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'content_id',\n",
    "    'prior_question_elapsed_time',\n",
    "    'prior_question_had_explanation',\n",
    "    'user_correctness',\n",
    "    'part',\n",
    "    'content_count',\n",
    "    'count',\n",
    "    'first_attempt',\n",
    "    'timestamp', #?\n",
    "    'count_inday', #?\n",
    "    'unique_attempt', #?\n",
    "    'part1_count',\n",
    "    'part2_count',\n",
    "    'part3_count',\n",
    "    'part4_count',\n",
    "    'part5_count',\n",
    "    'part6_count',\n",
    "    'part7_count', \n",
    "    'prior_question_had_explanation_mean',\n",
    "    'got_point',\n",
    "]\n",
    "\n",
    "print(len(features))\n",
    "drop_cols = [i for i in train_df.columns if i not in features + [target]]\n",
    "print(drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T14:55:06.570998Z",
     "iopub.status.busy": "2020-12-08T14:55:06.570066Z",
     "iopub.status.idle": "2020-12-08T14:55:10.015135Z",
     "shell.execute_reply": "2020-12-08T14:55:10.015752Z"
    },
    "papermill": {
     "duration": 3.486485,
     "end_time": "2020-12-08T14:55:10.015950",
     "exception": false,
     "start_time": "2020-12-08T14:55:06.529465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6536675, 21) (2360984, 21)\n"
     ]
    }
   ],
   "source": [
    "if FULL_TRAIN:\n",
    "    train_df.drop(drop_cols, axis=1, inplace=True)\n",
    "    print(train_df.shape)\n",
    "else:\n",
    "    valid_df = train_df.groupby('user_id').tail(valid_size).copy()\n",
    "    train_df.drop(valid_df.index, inplace=True)\n",
    "    train_df.drop(drop_cols, axis=1, inplace=True)\n",
    "    valid_df.drop(drop_cols, axis=1, inplace=True)\n",
    "    print(train_df.shape, valid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T14:55:10.117010Z",
     "iopub.status.busy": "2020-12-08T14:55:10.112709Z",
     "iopub.status.idle": "2020-12-08T14:55:10.191950Z",
     "shell.execute_reply": "2020-12-08T14:55:10.192649Z"
    },
    "papermill": {
     "duration": 0.135902,
     "end_time": "2020-12-08T14:55:10.192841",
     "exception": false,
     "start_time": "2020-12-08T14:55:10.056939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>content_id</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "      <th>part</th>\n",
       "      <th>content_count</th>\n",
       "      <th>user_correctness</th>\n",
       "      <th>first_attempt</th>\n",
       "      <th>count</th>\n",
       "      <th>count_inday</th>\n",
       "      <th>unique_attempt</th>\n",
       "      <th>part1_count</th>\n",
       "      <th>part2_count</th>\n",
       "      <th>part3_count</th>\n",
       "      <th>part4_count</th>\n",
       "      <th>part5_count</th>\n",
       "      <th>part6_count</th>\n",
       "      <th>part7_count</th>\n",
       "      <th>prior_question_had_explanation_mean</th>\n",
       "      <th>got_point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.687217</td>\n",
       "      <td>0</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>36674</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.765325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.608222</td>\n",
       "      <td>0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>47047</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.732050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.601824</td>\n",
       "      <td>1</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>40452</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.701548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.418436</td>\n",
       "      <td>1</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>190170</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.730480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.474545</td>\n",
       "      <td>1</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>56707</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.776572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.461387</td>\n",
       "      <td>1</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>30430</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.812274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.543071</td>\n",
       "      <td>1</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>66146</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>True</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.846882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.359970</td>\n",
       "      <td>0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>195861</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.871301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.353568</td>\n",
       "      <td>1</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>15386</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.842258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0.381249</td>\n",
       "      <td>0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>47486</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.886209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  content_id  answered_correctly  prior_question_elapsed_time  \\\n",
       "0          1    0.687217                   0                      19000.0   \n",
       "1          1    0.608222                   0                      21000.0   \n",
       "2          1    0.601824                   1                      22000.0   \n",
       "3          1    0.418436                   1                      16000.0   \n",
       "4          1    0.474545                   1                      20000.0   \n",
       "5          1    0.461387                   1                      22000.0   \n",
       "6          1    0.543071                   1                      22000.0   \n",
       "7          1    0.359970                   0                      23000.0   \n",
       "8          1    0.353568                   1                      20000.0   \n",
       "9          1    0.381249                   0                      15000.0   \n",
       "\n",
       "   prior_question_had_explanation  part  content_count  user_correctness  \\\n",
       "0                           False     1          36674          0.727273   \n",
       "1                           False     1          47047          0.695652   \n",
       "2                           False     1          40452          0.666667   \n",
       "3                           False     1         190170          0.680000   \n",
       "4                           False     1          56707          0.692308   \n",
       "5                           False     1          30430          0.703704   \n",
       "6                           False     1          66146          0.714286   \n",
       "7                           False     1         195861          0.724138   \n",
       "8                           False     1          15386          0.700000   \n",
       "9                           False     1          47486          0.709677   \n",
       "\n",
       "   first_attempt  count  count_inday  unique_attempt  part1_count  \\\n",
       "0           True     23           23              23         20.0   \n",
       "1           True     24           24              24         21.0   \n",
       "2           True     25           25              25         22.0   \n",
       "3           True     26           26              26         23.0   \n",
       "4           True     27           27              27         24.0   \n",
       "5           True     28           28              28         25.0   \n",
       "6           True     29           29              29         26.0   \n",
       "7           True     30           30              30         27.0   \n",
       "8           True     31           31              31         28.0   \n",
       "9           True     32           32              32         29.0   \n",
       "\n",
       "   part2_count  part3_count  part4_count  part5_count  part6_count  \\\n",
       "0          0.0          0.0          0.0          2.0          0.0   \n",
       "1          0.0          0.0          0.0          2.0          0.0   \n",
       "2          0.0          0.0          0.0          2.0          0.0   \n",
       "3          0.0          0.0          0.0          2.0          0.0   \n",
       "4          0.0          0.0          0.0          2.0          0.0   \n",
       "5          0.0          0.0          0.0          2.0          0.0   \n",
       "6          0.0          0.0          0.0          2.0          0.0   \n",
       "7          0.0          0.0          0.0          2.0          0.0   \n",
       "8          0.0          0.0          0.0          2.0          0.0   \n",
       "9          0.0          0.0          0.0          2.0          0.0   \n",
       "\n",
       "   part7_count  prior_question_had_explanation_mean  got_point  \n",
       "0          0.0                             0.045455   0.765325  \n",
       "1          0.0                             0.043478   0.732050  \n",
       "2          0.0                             0.041667   0.701548  \n",
       "3          0.0                             0.040000   0.730480  \n",
       "4          0.0                             0.038462   0.776572  \n",
       "5          0.0                             0.037037   0.812274  \n",
       "6          0.0                             0.035714   0.846882  \n",
       "7          0.0                             0.034483   0.871301  \n",
       "8          0.0                             0.033333   0.842258  \n",
       "9          0.0                             0.032258   0.886209  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.034528,
     "end_time": "2020-12-08T14:55:10.263197",
     "exception": false,
     "start_time": "2020-12-08T14:55:10.228669",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T14:55:10.342186Z",
     "iopub.status.busy": "2020-12-08T14:55:10.340919Z",
     "iopub.status.idle": "2020-12-08T14:55:10.344667Z",
     "shell.execute_reply": "2020-12-08T14:55:10.345255Z"
    },
    "papermill": {
     "duration": 0.0455,
     "end_time": "2020-12-08T14:55:10.345509",
     "exception": false,
     "start_time": "2020-12-08T14:55:10.300009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'seed': 42,\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.05,\n",
    "    'max_bin': 800,\n",
    "    'num_leaves': 80\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T14:55:10.428155Z",
     "iopub.status.busy": "2020-12-08T14:55:10.427275Z",
     "iopub.status.idle": "2020-12-08T16:12:37.894109Z",
     "shell.execute_reply": "2020-12-08T16:12:37.895051Z"
    },
    "papermill": {
     "duration": 4647.515791,
     "end_time": "2020-12-08T16:12:37.895584",
     "exception": false,
     "start_time": "2020-12-08T14:55:10.379793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's auc: 0.760261\tvalid_1's auc: 0.745436\n",
      "[100]\ttraining's auc: 0.76272\tvalid_1's auc: 0.748595\n",
      "[150]\ttraining's auc: 0.763909\tvalid_1's auc: 0.749926\n",
      "[200]\ttraining's auc: 0.764543\tvalid_1's auc: 0.750427\n",
      "[250]\ttraining's auc: 0.765035\tvalid_1's auc: 0.75075\n",
      "[300]\ttraining's auc: 0.765537\tvalid_1's auc: 0.751073\n",
      "[350]\ttraining's auc: 0.765907\tvalid_1's auc: 0.751252\n",
      "[400]\ttraining's auc: 0.76625\tvalid_1's auc: 0.7514\n",
      "[450]\ttraining's auc: 0.766602\tvalid_1's auc: 0.751551\n",
      "[500]\ttraining's auc: 0.766922\tvalid_1's auc: 0.751666\n",
      "[550]\ttraining's auc: 0.767229\tvalid_1's auc: 0.751771\n",
      "[600]\ttraining's auc: 0.767553\tvalid_1's auc: 0.751879\n",
      "[650]\ttraining's auc: 0.767843\tvalid_1's auc: 0.751956\n",
      "[700]\ttraining's auc: 0.768136\tvalid_1's auc: 0.752049\n",
      "[750]\ttraining's auc: 0.768413\tvalid_1's auc: 0.75212\n",
      "[800]\ttraining's auc: 0.768688\tvalid_1's auc: 0.752196\n",
      "[850]\ttraining's auc: 0.768946\tvalid_1's auc: 0.752253\n",
      "[900]\ttraining's auc: 0.769224\tvalid_1's auc: 0.752307\n",
      "[950]\ttraining's auc: 0.76951\tvalid_1's auc: 0.752366\n",
      "[1000]\ttraining's auc: 0.769763\tvalid_1's auc: 0.752413\n",
      "[1050]\ttraining's auc: 0.770005\tvalid_1's auc: 0.752446\n",
      "[1100]\ttraining's auc: 0.770249\tvalid_1's auc: 0.75247\n",
      "[1150]\ttraining's auc: 0.770484\tvalid_1's auc: 0.752499\n",
      "[1200]\ttraining's auc: 0.770706\tvalid_1's auc: 0.75252\n",
      "[1250]\ttraining's auc: 0.770954\tvalid_1's auc: 0.752544\n",
      "[1300]\ttraining's auc: 0.771184\tvalid_1's auc: 0.752562\n",
      "[1350]\ttraining's auc: 0.771422\tvalid_1's auc: 0.752586\n",
      "[1400]\ttraining's auc: 0.771657\tvalid_1's auc: 0.752603\n",
      "[1450]\ttraining's auc: 0.771881\tvalid_1's auc: 0.75262\n",
      "[1500]\ttraining's auc: 0.772121\tvalid_1's auc: 0.752642\n",
      "[1550]\ttraining's auc: 0.772344\tvalid_1's auc: 0.752654\n",
      "[1600]\ttraining's auc: 0.772575\tvalid_1's auc: 0.752673\n",
      "[1650]\ttraining's auc: 0.772793\tvalid_1's auc: 0.752695\n",
      "[1700]\ttraining's auc: 0.772993\tvalid_1's auc: 0.752699\n",
      "[1750]\ttraining's auc: 0.773219\tvalid_1's auc: 0.752715\n",
      "[1800]\ttraining's auc: 0.773449\tvalid_1's auc: 0.752726\n",
      "[1850]\ttraining's auc: 0.773714\tvalid_1's auc: 0.752759\n",
      "[1900]\ttraining's auc: 0.773929\tvalid_1's auc: 0.752776\n",
      "[1950]\ttraining's auc: 0.774144\tvalid_1's auc: 0.752787\n",
      "[2000]\ttraining's auc: 0.774356\tvalid_1's auc: 0.752794\n",
      "[2050]\ttraining's auc: 0.774575\tvalid_1's auc: 0.752808\n",
      "[2100]\ttraining's auc: 0.774802\tvalid_1's auc: 0.752826\n",
      "[2150]\ttraining's auc: 0.774998\tvalid_1's auc: 0.752834\n",
      "[2200]\ttraining's auc: 0.775213\tvalid_1's auc: 0.752853\n",
      "[2250]\ttraining's auc: 0.775434\tvalid_1's auc: 0.752867\n",
      "[2300]\ttraining's auc: 0.77565\tvalid_1's auc: 0.75288\n",
      "[2350]\ttraining's auc: 0.775854\tvalid_1's auc: 0.75288\n",
      "[2400]\ttraining's auc: 0.776057\tvalid_1's auc: 0.75288\n",
      "Early stopping, best iteration is:\n",
      "[2359]\ttraining's auc: 0.775896\tvalid_1's auc: 0.752884\n"
     ]
    }
   ],
   "source": [
    "if FULL_TRAIN:\n",
    "    X_train = np.ndarray(shape=(train_df.shape[0], len(features)), dtype=np.float32)\n",
    "    y_train = np.ndarray(shape=(train_df.shape[0], 1), dtype=np.float32)\n",
    "    for idx, feature in enumerate(features):\n",
    "        X_train[:,idx] = train_df[feature].values.astype(np.float32)\n",
    "        train_df.drop(feature, axis=1, inplace=True)\n",
    "    y_train = train_df[target].values.astype(np.float32)\n",
    "    train_df.drop(target, axis=1, inplace=True)\n",
    "\n",
    "    tr_data = lgb.Dataset(X_train, label=y_train)\n",
    "    print(\"Full training starts\")\n",
    "    model = lgb.train(\n",
    "        params, \n",
    "        tr_data, \n",
    "        num_boost_round=4000,\n",
    "        valid_sets=None, \n",
    "        )\n",
    "else:    \n",
    "    X_train = np.ndarray(shape=(train_df.shape[0], len(features)), dtype=np.float32)\n",
    "    y_train = np.ndarray(shape=(train_df.shape[0], 1), dtype=np.float32)\n",
    "    for idx, feature in enumerate(features):\n",
    "        X_train[:,idx] = train_df[feature].values.astype(np.float32)\n",
    "        train_df.drop(feature, axis=1, inplace=True)\n",
    "    y_train = train_df[target].values.astype(np.float32)\n",
    "    train_df.drop(target, axis=1, inplace=True)\n",
    "    tr_data = lgb.Dataset(X_train, label=y_train)\n",
    "    \n",
    "    X_valid = np.ndarray(shape=(valid_df.shape[0], len(features)), dtype=np.float32)\n",
    "    y_valid = np.ndarray(shape=(valid_df.shape[0], 1), dtype=np.float32)\n",
    "    for idx, feature in enumerate(features):\n",
    "        X_valid[:,idx] = valid_df[feature].values.astype(np.float32)\n",
    "        valid_df.drop(feature, axis=1, inplace=True)\n",
    "    y_valid = valid_df[target].values.astype(np.float32)\n",
    "    valid_df.drop(target, axis=1, inplace=True)\n",
    "    va_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "    model = lgb.train(\n",
    "        params, \n",
    "        tr_data, \n",
    "        num_boost_round=10000,\n",
    "        valid_sets=[tr_data, va_data], \n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=50\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.064143,
     "end_time": "2020-12-08T16:12:38.023139",
     "exception": false,
     "start_time": "2020-12-08T16:12:37.958996",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T16:12:38.139276Z",
     "iopub.status.busy": "2020-12-08T16:12:38.138082Z",
     "iopub.status.idle": "2020-12-08T16:12:38.141772Z",
     "shell.execute_reply": "2020-12-08T16:12:38.141119Z"
    },
    "papermill": {
     "duration": 0.063302,
     "end_time": "2020-12-08T16:12:38.141915",
     "exception": false,
     "start_time": "2020-12-08T16:12:38.078613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = riiideducation.make_env()\n",
    "iter_test = env.iter_test()\n",
    "prior_test_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T16:12:38.266247Z",
     "iopub.status.busy": "2020-12-08T16:12:38.261154Z",
     "iopub.status.idle": "2020-12-08T16:12:39.141325Z",
     "shell.execute_reply": "2020-12-08T16:12:39.140604Z"
    },
    "papermill": {
     "duration": 0.945898,
     "end_time": "2020-12-08T16:12:39.141476",
     "exception": false,
     "start_time": "2020-12-08T16:12:38.195578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.42 s, sys: 85.9 ms, total: 1.51 s\n",
      "Wall time: 863 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    if prior_test_df is not None:\n",
    "        prior_test_df[target] = eval(test_df['prior_group_answers_correct'].iloc[0])\n",
    "        prior_test_df = prior_test_df[prior_test_df[target] != -1].reset_index(drop=True)\n",
    "        \n",
    "        user_ids = prior_test_df['user_id'].values\n",
    "        content_ids = prior_test_df['content_id'].values\n",
    "        targets = prior_test_df[target].values\n",
    "         \n",
    "        for user_id, content_id, answered_correctly, part, first_attempt_ornot, prior_explanation, prior_point in zip(user_ids, content_ids, \n",
    "                                                                targets, \n",
    "                                                                prior_part_arrays, \n",
    "                                                                prior_f_attempt_arrays,\n",
    "                                                                p_prior_question_had_explanation,\n",
    "                                                                prior_point_array):\n",
    "            user_sum_dict[user_id] += answered_correctly\n",
    "            user_count_dict[user_id] += 1\n",
    "            content_sum_dict[content_id] += answered_correctly\n",
    "            content_count_dict[content_id] += 1\n",
    "            if part == 1:\n",
    "                part1_count_dict[user_id] +=1\n",
    "            elif part == 2:\n",
    "                part2_count_dict[user_id] +=1\n",
    "            elif part == 3:\n",
    "                part3_count_dict[user_id] +=1\n",
    "            elif part == 4:\n",
    "                part4_count_dict[user_id] +=1\n",
    "            elif part == 5:\n",
    "                part5_count_dict[user_id] +=1\n",
    "            elif part == 6:\n",
    "                part6_count_dict[user_id] +=1\n",
    "            else:\n",
    "                part7_count_dict[user_id] +=1\n",
    "            user_unique_dict[user_id] += first_attempt_ornot\n",
    "            user_prior_question_had_explanation_sum_dict[user_id] += prior_explanation\n",
    "            user_point_sum_dict[user_id] += prior_point * answered_correctly\n",
    "\n",
    "    prior_test_df = test_df.copy()\n",
    "    \n",
    "    test_df = test_df[test_df['content_type_id'] == 0].reset_index(drop=True)\n",
    "    test_df = pd.merge(test_df, questions_df, left_on='content_id', right_on='question_id', how='left', right_index=True).reset_index(drop=True)\n",
    "    test_df['prior_question_had_explanation'] = test_df['prior_question_had_explanation'].fillna(False).astype('bool')\n",
    "    test_df['prior_question_elapsed_time'] = test_df['prior_question_elapsed_time'].fillna(0)\n",
    "    test_df['timestamp'] = (test_df['timestamp'] // 86400000) + 1\n",
    "    \n",
    "    prior_part_arrays = test_df['part'].values\n",
    "    p_prior_question_had_explanation = test_df['prior_question_had_explanation'].values\n",
    "    \n",
    "    user_sum = np.zeros(len(test_df), dtype=np.int16)\n",
    "    user_count = np.zeros(len(test_df), dtype=np.int16)\n",
    "    content_sum = np.zeros(len(test_df), dtype=np.int32)\n",
    "    content_count = np.zeros(len(test_df), dtype=np.int32)\n",
    "    part1_count = np.zeros(len(test_df), dtype=np.int32)\n",
    "    part2_count = np.zeros(len(test_df), dtype=np.int32)\n",
    "    part3_count = np.zeros(len(test_df), dtype=np.int32)\n",
    "    part4_count = np.zeros(len(test_df), dtype=np.int32)\n",
    "    part5_count = np.zeros(len(test_df), dtype=np.int32)\n",
    "    part6_count = np.zeros(len(test_df), dtype=np.int32)\n",
    "    part7_count = np.zeros(len(test_df), dtype=np.int32)\n",
    "    user_count_inday = np.zeros(len(test_df), dtype=np.int32)\n",
    "    first_attempt_values = []\n",
    "    user_unique_count = np.zeros(len(test_df), dtype=np.int32)\n",
    "    user_prior_question_had_explanation_sum = np.zeros(len(test_df), dtype=np.int32)\n",
    "    got_point_array = np.zeros(len(test_df), dtype=np.float32)\n",
    "    \n",
    "    for i, (user_id, content_id, timestamp) in enumerate(zip(test_df['user_id'].values, test_df['content_id'].values, test_df['timestamp'].values)):\n",
    "        user_sum[i] = user_sum_dict[user_id]\n",
    "        user_count[i] = user_count_dict[user_id]\n",
    "        content_sum[i] = content_sum_dict[content_id]\n",
    "        content_count[i] = content_count_dict[content_id]\n",
    "        part1_count[i] = part1_count_dict[user_id]\n",
    "        part2_count[i] = part2_count_dict[user_id]\n",
    "        part3_count[i] = part3_count_dict[user_id]\n",
    "        part4_count[i] = part4_count_dict[user_id]\n",
    "        part5_count[i] = part5_count_dict[user_id]\n",
    "        part6_count[i] = part6_count_dict[user_id]\n",
    "        part7_count[i] = part7_count_dict[user_id]\n",
    "        first_attempt_values.append(user_content_dict[user_id][content_id])\n",
    "        user_content_dict[user_id][content_id] = False \n",
    "        if user_timestamp_dict[user_id] == timestamp:\n",
    "            user_count_inday_dict[user_id] += 1\n",
    "        else:\n",
    "            user_count_inday_dict[user_id] = 1\n",
    "            user_timestamp_dict[user_id] = timestamp\n",
    "        user_count_inday[i] = user_count_inday_dict[user_id]\n",
    "        user_unique_count[i] = user_unique_dict[user_id]\n",
    "        user_prior_question_had_explanation_sum[i] = user_prior_question_had_explanation_sum_dict[user_id]\n",
    "        got_point_array[i] = user_point_sum_dict[user_id]\n",
    "            \n",
    "    test_df['user_correctness'] = user_sum / user_count\n",
    "    test_df['content_count'] = content_count\n",
    "    test_df['content_id'] = content_sum / content_count\n",
    "    test_df['count'] = 1\n",
    "    test_df['count'] = test_df.groupby(\"user_id\")[\"count\"].cumsum()\n",
    "    test_df['count'] += user_count\n",
    "    test_df['part1_count'] = part1_count\n",
    "    test_df['part2_count'] = part2_count\n",
    "    test_df['part3_count'] = part3_count\n",
    "    test_df['part4_count'] = part4_count\n",
    "    test_df['part5_count'] = part5_count\n",
    "    test_df['part6_count'] = part6_count\n",
    "    test_df['part7_count'] = part7_count\n",
    "    test_df[\"first_attempt\"] = first_attempt_values\n",
    "    test_df['count_inday'] = user_count_inday\n",
    "    test_df[\"unique_attempt\"] = test_df.groupby(\"user_id\")[\"first_attempt\"].cumsum()\n",
    "    test_df[\"unique_attempt\"] += user_unique_count\n",
    "    test_df['prior_question_had_explanation_mean'] = user_prior_question_had_explanation_sum / user_count\n",
    "    test_df['got_point'] = got_point_array / user_count\n",
    "\n",
    "    prior_f_attempt_arrays = test_df['first_attempt'].values\n",
    "    prior_point_array = vfunc(test_df.content_id.values)\n",
    "\n",
    "    test_df[target] = model.predict(test_df[features])\n",
    "    env.predict(test_df[['row_id', target]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.052812,
     "end_time": "2020-12-08T16:12:39.248492",
     "exception": false,
     "start_time": "2020-12-08T16:12:39.195680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 5569.159197,
   "end_time": "2020-12-08T16:12:39.614184",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-08T14:39:50.454987",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
