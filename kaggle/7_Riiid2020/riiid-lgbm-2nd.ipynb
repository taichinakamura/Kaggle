{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027414,
     "end_time": "2020-12-27T07:27:19.277401",
     "exception": false,
     "start_time": "2020-12-27T07:27:19.249987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- renew user_count and part_count and part_ratio, prior_had_explanation_mean, got_point, accuracy_last7 by bundle\n",
    "- unite premade feature in one dataset\n",
    "- add prior_question_elapsed_time_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-12-27T07:27:19.333559Z",
     "iopub.status.busy": "2020-12-27T07:27:19.332858Z",
     "iopub.status.idle": "2020-12-27T07:27:50.287513Z",
     "shell.execute_reply": "2020-12-27T07:27:50.288065Z"
    },
    "papermill": {
     "duration": 30.984568,
     "end_time": "2020-12-27T07:27:50.288303",
     "exception": false,
     "start_time": "2020-12-27T07:27:19.303735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install ../input/python-datatable/datatable-0.11.0-cp37-cp37m-manylinux2010_x86_64.whl > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-12-27T07:27:50.343911Z",
     "iopub.status.busy": "2020-12-27T07:27:50.343247Z",
     "iopub.status.idle": "2020-12-27T07:27:52.580445Z",
     "shell.execute_reply": "2020-12-27T07:27:52.579251Z"
    },
    "papermill": {
     "duration": 2.266254,
     "end_time": "2020-12-27T07:27:52.580635",
     "exception": false,
     "start_time": "2020-12-27T07:27:50.314381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAA4CAYAAADuMJi0AAAGR0lEQVR42rVZ21IbRxBtCbQrkIR2dQVjsLmDLBsET3nTQ8ouYRkQVf6e/E9+Im958qMfkgoXAaKSSj6C9Jnd2R2NeiRSRaZqitVOT5+Z6dNnWoKGlN94JFp8Ipofkb/7SOXjGyp8wF+z35K3f0uUp/GW4XfLQ8v2gefj3ZCCzojoNfue+43o1Q3l3xB/yA3JO7jnF2pCLnI+pNyx/qw7L+SQ7T2N9p2f8c60QcfcK6KGXsAd+ZvA4LlZYuSSAoOhMs5vwJkEGDlbPMaJoA+FcQ0IH38QLWkbAFLkOOhoMF5tU6/eBRhNjro0ZgKiPRAt3FLhCO/vqdgmNTm32LkmKpvBmQY4q5uAaAgbwDBG2BVv3bfI8KKAMWj2kfw9+pkZREIbEql4ST1x7hgHIANkbJ//MF8mAH/ilTCJ2tIi4ASr1IC3VNqXHKOxjy34mgoImnOQtx1g81fkqTiMOBVGcTogNhiT5iBHET8R8C+iApJUmgim3SQAXhsLQz7ee2G8gOAQNtJckBEplADiAxtX+G9NmhDl0qJKnTvyWlAMPYZnvIviGXRg6/Dh824DBXhP/tbfREXJEIvQ+aaPGjG7pvw6r3xdx+9hqb4dgZaP2XmdHO2K/B0c1+oUph6k8kShBryl/Ft0DYgjTlOieOACHFFpVyUl72T9V3cM1jUoYvxIC2vpCSys/ck70mDYuYvdvKjlMdKAUThneWVU1aAsyjv6PURDiwNsHGBZzY+JtAAgE2TFxdRHJdyIp/f+zqu09M5cDP2F08Ukkpj4YNSdX950HY2pNCCUK/Hhx5ZMBfjNSEzdsIihVzzAMdn9dz4eDYhnyQb9SSCiAryiJcQk82LiTbJ4x2FZJaUenpKnzP95WyDf4Y+QN9EFHHSeDLGdBjjKNQ5vKHf4XMA7KrY0y0GEObBOO/8e1ywuQExOHXktuQyJALEBpcEqhwtHqgiDuCK5b6i0p2MQpcckIIoh+6hYgTZtO8xlMi6O4tKCF/kOGHEg/W0UUpHW0ZoGNZ1ExZWcn7EErgwt4uj50E/sFBjXXIayWvh7WryjasxarZKssXon0zxvvkc32Q0bqbBCuZiKt9dWFysfQefeL29JYFaeztX6tePaZdz5mYx8+6Zq3Mk0wXECQxlhdzgS2wjBHju3j1RIgKyOMdNUE8X0+RAdbSapS11MRCv1SzUXmO6wGZe2SQYrv2MvCSWEv2VODE6DN7bz8ufypgQKW7uQskFTQHULLKyaEyrnlZbgOGLrV5qrn9U79jjm2HJmgkaVN98AfBub91lGPLZBqdroN5LYgjSu4zYZDDHXZOIPC691HqrWI1900I8qLzgKP4ft8DxEWigprPfrO+KcXno9gZz4jjGewWdUcpGCj0qVFuGPYbl2VturndZ2qRvlL8acDO6lF/DY/VjsFesiUK+ypJ+r/ep+cJkSQxEK4PG4WozgA75TYrDDqStE69K8/mzGEM+JXTeqvmedEElMmwCMm2SLd6bNNF9su02zEtoW6nAQtpMj5Gd7fKa//wqonF7UdtHFsVn+6hf1o7AfriPH7M6EeIUEF5zKVxXbYo7kS/OEtOqDYZKPoBsETIixn0uYrasThmzDkhdKPkz2EnaX0HdQbIgr59vAdGYDqjHrxkjS7WOxkTD8sqEqhiwcJETgBYigrBqF08KyDaje9SZ/I1A7MzaTzMGDEulPtZUkuKcyIRAjxEJPVrnVlb/9wkfij31D/pQt1IN+iL8bGJcstBIO7Y5VI/cwDqURbXhMuJxBqD0KLoK3esWFs0Jz5i5ZvJUAfFJMFb9XmGIOnzGpijpcWYCaMqXSQWp8EnCABepQ0Elyi4wfKfsw78ikIqif1pe1AGPlLmojl1SKxHHXp1L+Ut7AmDQHvhI5xHGi4EooO2BR7k78PEkJOdL7cAxQUZ/Tyclu9gnfwGgOmm2lNHGNmZXsq4Pqgc1EG1ATrvKl8s4R9ywwnqulGUnaRLVhxy8v3ieUwy2hbooT68uscW++DCDH0WSzuoyN2D4LUJ/tLECbcSKznwMIFs0ChF4mRTCnQbIIfk4SHJo6A9BMuTnXTs3Ku/KxsgZWqzuSe+Os8cEUfnMBY6UF5gi3SUbd5K7vDjq5WW0UENJlRsWn4sy21Er/E/AvPQSFHy1p4fgAAAAASUVORK5CYII=');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit\n",
    "import riiideducation\n",
    "import datatable as dt\n",
    "import lightgbm as lgb\n",
    "from bitarray import bitarray\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "\n",
    "_ = np.seterr(divide='ignore', invalid='ignore')\n",
    "pd.set_option(\"max_rows\", 100)\n",
    "pd.set_option(\"max_columns\", 100)\n",
    "\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:27:52.648069Z",
     "iopub.status.busy": "2020-12-27T07:27:52.647348Z",
     "iopub.status.idle": "2020-12-27T07:27:52.650256Z",
     "shell.execute_reply": "2020-12-27T07:27:52.650831Z"
    },
    "papermill": {
     "duration": 0.042935,
     "end_time": "2020-12-27T07:27:52.651008",
     "exception": false,
     "start_time": "2020-12-27T07:27:52.608073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_bitarray():\n",
    "    a = bitarray(32737, endian='little')\n",
    "    a.setall(True)   \n",
    "    return a\n",
    "\n",
    "def clear_mem():\n",
    "    %reset -f out\n",
    "    %reset -f in\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:27:52.707284Z",
     "iopub.status.busy": "2020-12-27T07:27:52.706647Z",
     "iopub.status.idle": "2020-12-27T07:27:52.710288Z",
     "shell.execute_reply": "2020-12-27T07:27:52.711035Z"
    },
    "papermill": {
     "duration": 0.033953,
     "end_time": "2020-12-27T07:27:52.711201",
     "exception": false,
     "start_time": "2020-12-27T07:27:52.677248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FULL_TRAIN = False\n",
    "CV_SCHEME = \"original\" #\"time\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026683,
     "end_time": "2020-12-27T07:27:52.765678",
     "exception": false,
     "start_time": "2020-12-27T07:27:52.738995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:27:52.823244Z",
     "iopub.status.busy": "2020-12-27T07:27:52.822576Z",
     "iopub.status.idle": "2020-12-27T07:27:52.827197Z",
     "shell.execute_reply": "2020-12-27T07:27:52.827762Z"
    },
    "papermill": {
     "duration": 0.035742,
     "end_time": "2020-12-27T07:27:52.827929",
     "exception": false,
     "start_time": "2020-12-27T07:27:52.792187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_types_dict = {\n",
    "    'timestamp': 'int64',\n",
    "    'user_id': 'int32', \n",
    "    'content_id': 'int16', \n",
    "    'answered_correctly': 'int8', \n",
    "    'prior_question_elapsed_time': 'float32', \n",
    "    'prior_question_had_explanation': 'bool',\n",
    "}\n",
    "target = 'answered_correctly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:27:52.884927Z",
     "iopub.status.busy": "2020-12-27T07:27:52.884238Z",
     "iopub.status.idle": "2020-12-27T07:29:31.856494Z",
     "shell.execute_reply": "2020-12-27T07:29:31.855700Z"
    },
    "papermill": {
     "duration": 99.001701,
     "end_time": "2020-12-27T07:29:31.856648",
     "exception": false,
     "start_time": "2020-12-27T07:27:52.854947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = dt.fread('../input/riiid-test-answer-prediction/train.csv', columns=set(data_types_dict.keys())).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:29:31.928656Z",
     "iopub.status.busy": "2020-12-27T07:29:31.927956Z",
     "iopub.status.idle": "2020-12-27T07:30:06.464926Z",
     "shell.execute_reply": "2020-12-27T07:30:06.465447Z"
    },
    "papermill": {
     "duration": 34.581848,
     "end_time": "2020-12-27T07:30:06.465718",
     "exception": false,
     "start_time": "2020-12-27T07:29:31.883870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = train_df[train_df[target] != -1].reset_index(drop=True)\n",
    "\n",
    "train_df['prior_question_had_explanation'] = train_df['prior_question_had_explanation'].fillna(False).astype('int8')\n",
    "train_df['prior_question_elapsed_time'].fillna(0, inplace=True)\n",
    "\n",
    "train_df = train_df.astype(data_types_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:30:06.556187Z",
     "iopub.status.busy": "2020-12-27T07:30:06.555291Z",
     "iopub.status.idle": "2020-12-27T07:30:15.815862Z",
     "shell.execute_reply": "2020-12-27T07:30:15.815252Z"
    },
    "papermill": {
     "duration": 9.307815,
     "end_time": "2020-12-27T07:30:15.816001",
     "exception": false,
     "start_time": "2020-12-27T07:30:06.508186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CV_SCHEME==\"time\":\n",
    "    max_timestamp_u = train_df[['user_id','timestamp']].groupby(['user_id']).agg(['max']).reset_index()\n",
    "    max_timestamp_u.columns = ['user_id', 'max_time_stamp']\n",
    "    MAX_TIME_STAMP = max_timestamp_u.max_time_stamp.max()\n",
    "\n",
    "    def rand_time(max_time_stamp):\n",
    "        interval = MAX_TIME_STAMP - max_time_stamp\n",
    "        rand_time_stamp = random.randint(0,interval)\n",
    "        return rand_time_stamp\n",
    "\n",
    "    max_timestamp_u['rand_time_stamp'] = max_timestamp_u.max_time_stamp.apply(rand_time)\n",
    "    train_df = train_df.merge(max_timestamp_u, on='user_id', how='left')\n",
    "    train_df['viretual_time_stamp'] = train_df.timestamp + train_df['rand_time_stamp']\n",
    "\n",
    "    del train_df['max_time_stamp']\n",
    "    del train_df['rand_time_stamp']\n",
    "    del max_timestamp_u\n",
    "\n",
    "    train_index = list(train_df['viretual_time_stamp'].nlargest(10000000).index)\n",
    "\n",
    "else:\n",
    "    if FULL_TRAIN:\n",
    "        train_size = 200\n",
    "    else:\n",
    "        train_size = 24\n",
    "        valid_size = 6\n",
    "    \n",
    "    train_index = list(train_df.groupby('user_id').tail(train_size).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:30:15.882501Z",
     "iopub.status.busy": "2020-12-27T07:30:15.881814Z",
     "iopub.status.idle": "2020-12-27T07:30:46.295000Z",
     "shell.execute_reply": "2020-12-27T07:30:46.294151Z"
    },
    "papermill": {
     "duration": 30.452034,
     "end_time": "2020-12-27T07:30:46.295137",
     "exception": false,
     "start_time": "2020-12-27T07:30:15.843103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def count_by_bundle(T):\n",
    "    ans = np.zeros(len(T))\n",
    "    prev_time = -1\n",
    "    count = 0\n",
    "    for i in range(len(T)):\n",
    "        if i == 0:\n",
    "            ans[i] = 0\n",
    "        elif prev_time == T[i]:\n",
    "            ans[i] = ans[i-1]\n",
    "        else:\n",
    "            ans[i] = count          \n",
    "        prev_time = T[i]\n",
    "        count += 1\n",
    "    return ans\n",
    "\n",
    "count_array = train_df.groupby(\"user_id\").apply(lambda x: count_by_bundle(x[\"timestamp\"].values))\n",
    "count_array = np.hstack(count_array)\n",
    "count_array = count_array[train_index]\n",
    "count_zero_index = count_array == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:30:46.386336Z",
     "iopub.status.busy": "2020-12-27T07:30:46.381297Z",
     "iopub.status.idle": "2020-12-27T07:35:19.791258Z",
     "shell.execute_reply": "2020-12-27T07:35:19.791951Z"
    },
    "papermill": {
     "duration": 273.468931,
     "end_time": "2020-12-27T07:35:19.792151",
     "exception": false,
     "start_time": "2020-12-27T07:30:46.323220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def timediff_by_bundle(T):\n",
    "    ans = np.zeros(len(T))\n",
    "    prev_time = 0\n",
    "    for i in range(len(T)): \n",
    "        if i == 0:\n",
    "            ans[i] = np.nan\n",
    "        elif prev_time == T[i]:\n",
    "            ans[i] = ans[i-1]\n",
    "        else:\n",
    "            ans[i] = T[i] - prev_time\n",
    "        prev_time = T[i]\n",
    "    return ans\n",
    "\n",
    "timediff_array = train_df.groupby(\"user_id\").apply(lambda x: timediff_by_bundle(x[\"timestamp\"].values))\n",
    "timediff_array = np.hstack(timediff_array)\n",
    "timediff_array = timediff_array[train_index]\n",
    "\n",
    "@jit\n",
    "def timediff2_by_bundle(T):\n",
    "    ans = np.zeros(len(T))\n",
    "    prev_time = [-1, -1]\n",
    "    for i in range(len(T)): \n",
    "        if i == 0 or i == 1:\n",
    "            ans[i] = np.nan     \n",
    "        elif prev_time[1] == T[i]:\n",
    "            ans[i] = ans[i-1]\n",
    "        else:\n",
    "            ans[i] = T[i]-prev_time[0]\n",
    "            \n",
    "        if prev_time[0] == -1:\n",
    "            prev_time[0] = T[i]\n",
    "        elif prev_time[0] != T[i] and prev_time[1] == -1:\n",
    "            prev_time[1] = T[i]\n",
    "        elif T[i] not in prev_time:\n",
    "            prev_time[0] = prev_time[1]\n",
    "            prev_time[1] = T[i]\n",
    "    return ans\n",
    "\n",
    "timediff2_array = train_df.groupby(\"user_id\").apply(lambda x: timediff2_by_bundle(x[\"timestamp\"].values))\n",
    "timediff2_array = np.hstack(timediff2_array)\n",
    "timediff2_array = timediff2_array[train_index]\n",
    "\n",
    "@jit\n",
    "def timediff3_by_bundle(T):\n",
    "    ans = np.zeros(len(T))\n",
    "    prev_time = [-1, -1, -1]\n",
    "    for i in range(len(T)): \n",
    "        if i == 0 or i == 1 or i ==2:\n",
    "            ans[i] = np.nan\n",
    "        elif prev_time[2] == T[i]:\n",
    "            ans[i] = ans[i-1]\n",
    "        else:\n",
    "            ans[i] = T[i]-prev_time[0]\n",
    "            \n",
    "        if prev_time[0] == -1:\n",
    "            prev_time[0] = T[i]\n",
    "        elif prev_time[0] != T[i] and prev_time[1] == -1:\n",
    "            prev_time[1] = T[i]\n",
    "        elif prev_time[1] != T[i] and prev_time[2] == -1:\n",
    "            prev_time[2] = T[i]\n",
    "        elif T[i] not in prev_time:\n",
    "            prev_time[0] = prev_time[1]\n",
    "            prev_time[1] = prev_time[2]\n",
    "            prev_time[2] = T[i]\n",
    "    return ans\n",
    "\n",
    "timediff3_array = train_df.groupby(\"user_id\").apply(lambda x: timediff3_by_bundle(x[\"timestamp\"].values))\n",
    "timediff3_array = np.hstack(timediff3_array)\n",
    "timediff3_array = timediff3_array[train_index]\n",
    "\n",
    "@jit\n",
    "def timediff4_by_bundle(T):\n",
    "    ans = np.zeros(len(T))\n",
    "    prev_time = [-1, -1, -1, -1]\n",
    "    for i in range(len(T)): \n",
    "        if i == 0 or i == 1 or i ==2 or i == 3:\n",
    "            ans[i] = np.nan     \n",
    "        elif prev_time[3] == T[i]:\n",
    "            ans[i] = ans[i-1]\n",
    "        else:\n",
    "            ans[i] = T[i]- prev_time[0]\n",
    "            \n",
    "        if prev_time[0] == -1:\n",
    "            prev_time[0] = T[i]\n",
    "        elif prev_time[0] != T[i] and prev_time[1] == -1:\n",
    "            prev_time[1] = T[i]\n",
    "        elif prev_time[1] != T[i] and prev_time[2] == -1:\n",
    "            prev_time[2] = T[i]\n",
    "        elif prev_time[2] != T[i] and prev_time[3] == -1:\n",
    "            prev_time[3] = T[i]\n",
    "        elif T[i] not in prev_time:\n",
    "            prev_time[0] = prev_time[1]\n",
    "            prev_time[1] = prev_time[2]\n",
    "            prev_time[2] = prev_time[3]\n",
    "            prev_time[3] = T[i]\n",
    "    return ans\n",
    "\n",
    "timediff4_array = train_df.groupby(\"user_id\").apply(lambda x: timediff4_by_bundle(x[\"timestamp\"].values))\n",
    "timediff4_array = np.hstack(timediff4_array)\n",
    "timediff4_array = timediff4_array[train_index]\n",
    "\n",
    "user_timestamp_max_dict = train_df.groupby(\"user_id\")[\"timestamp\"].apply(lambda x: x.drop_duplicates()[-4:].values).to_dict(defaultdict(partial(np.ndarray, 0, dtype=\"int64\")))\n",
    "\n",
    "time_dd_array = timediff2_array - timediff_array\n",
    "timediff_array = np.nan_to_num(timediff_array, nan=-1)\n",
    "timediff2_array = np.nan_to_num(timediff2_array, nan=-1)\n",
    "timediff3_array = np.nan_to_num(timediff3_array, nan=-1)\n",
    "timediff4_array = np.nan_to_num(timediff4_array, nan=-1)\n",
    "time_dd_array = np.nan_to_num(time_dd_array, nan=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:35:19.866734Z",
     "iopub.status.busy": "2020-12-27T07:35:19.865925Z",
     "iopub.status.idle": "2020-12-27T07:36:08.926457Z",
     "shell.execute_reply": "2020-12-27T07:36:08.924967Z"
    },
    "papermill": {
     "duration": 49.105514,
     "end_time": "2020-12-27T07:36:08.926651",
     "exception": false,
     "start_time": "2020-12-27T07:35:19.821137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def elapsed_time_mean_by_bundle(E, T):\n",
    "    ans = np.zeros(len(T))\n",
    "    count = 0\n",
    "    prev_time = -1 \n",
    "    for i in range(len(T)): \n",
    "        if prev_time == T[i]:\n",
    "            ans[i] = ans[i-1]\n",
    "        else:\n",
    "            ans[i] = count\n",
    "        prev_time = T[i]\n",
    "        count = count + E[i]\n",
    "    return ans\n",
    "\n",
    "prior_question_elapsed_time_mean_array = train_df.groupby(\"user_id\").apply(lambda x: \n",
    "                                                                         elapsed_time_mean_by_bundle(x[\"prior_question_elapsed_time\"].values, \n",
    "                                                                                                     x[\"timestamp\"].values))\n",
    "prior_question_elapsed_time_mean_array = np.hstack(prior_question_elapsed_time_mean_array)\n",
    "prior_question_elapsed_time_mean_array = prior_question_elapsed_time_mean_array[train_index]\n",
    "prior_question_elapsed_time_mean_array = prior_question_elapsed_time_mean_array / count_array\n",
    "prior_question_elapsed_time_mean_array[count_zero_index] = -1\n",
    "\n",
    "user_prior_question_elapsed_time_sum_agg = train_df.groupby('user_id')[\"prior_question_elapsed_time\"].agg(['sum'])\n",
    "user_prior_question_elapsed_time_sum_dict = user_prior_question_elapsed_time_sum_agg['sum'].astype('int32').to_dict(defaultdict(int))\n",
    "del user_prior_question_elapsed_time_sum_agg\n",
    "\n",
    "prior_question_elapsed_time_array = train_df.prior_question_elapsed_time.values\n",
    "train_df.drop(\"prior_question_elapsed_time\", axis =1, inplace=True)\n",
    "prior_question_elapsed_time_array = prior_question_elapsed_time_array[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:36:08.999432Z",
     "iopub.status.busy": "2020-12-27T07:36:08.998741Z",
     "iopub.status.idle": "2020-12-27T07:36:30.423055Z",
     "shell.execute_reply": "2020-12-27T07:36:30.422000Z"
    },
    "papermill": {
     "duration": 21.468297,
     "end_time": "2020-12-27T07:36:30.423206",
     "exception": false,
     "start_time": "2020-12-27T07:36:08.954909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "questions_df = pd.read_csv(\n",
    "    '../input/riiid-test-answer-prediction/questions.csv', \n",
    "    usecols=[0, 1, 3], \n",
    "    dtype={'question_id': 'int16', 'bundle_id': 'int16', 'part': 'int8'} \n",
    ")\n",
    "\n",
    "additional_q_df = pd.read_csv('../input/riiid-question-clustering/question_cmnts.csv')\n",
    "questions_df[\"community\"] = additional_q_df[\"community\"].astype('int8')\n",
    "del additional_q_df \n",
    "    \n",
    "train_df = pd.merge(train_df, questions_df, left_on='content_id', right_on='question_id', how='left', right_index=True).reset_index(drop=True)\n",
    "train_df.drop(columns=['question_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:36:30.505292Z",
     "iopub.status.busy": "2020-12-27T07:36:30.504529Z",
     "iopub.status.idle": "2020-12-27T07:36:30.509134Z",
     "shell.execute_reply": "2020-12-27T07:36:30.507851Z"
    },
    "papermill": {
     "duration": 0.057894,
     "end_time": "2020-12-27T07:36:30.509255",
     "exception": false,
     "start_time": "2020-12-27T07:36:30.451361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "community_num = len(questions_df.community.unique())\n",
    "print(community_num)\n",
    "\n",
    "@jit\n",
    "def tag_accuracy(A, C):\n",
    "    ans = []\n",
    "    community_count = [0] * community_num\n",
    "    community_correct = [0] * community_num\n",
    "    for i in range(len(C)):\n",
    "        if community_count[C[i]]==0:\n",
    "            ans.append(-1)\n",
    "        else:\n",
    "            ans.append(community_correct[C[i]]/community_count[C[i]])\n",
    "        community_count[C[i]] +=1\n",
    "        community_correct[C[i]] += A[i]\n",
    "    return np.array(ans)\n",
    "\n",
    "@jit\n",
    "def tag_correct_last(A, C):\n",
    "    community_correct = [0] * community_num\n",
    "    for i in range(len(C)):\n",
    "        community_correct[C[i]] += A[i]\n",
    "    return np.array(community_correct)\n",
    "\n",
    "@jit\n",
    "def tag_count_last(A, C):\n",
    "    community_count = [0] * community_num\n",
    "    for i in range(len(C)):\n",
    "        community_count[C[i]] +=1\n",
    "    return np.array(community_count)\n",
    "\n",
    "def init_dict():\n",
    "    ans = [0] * community_num\n",
    "    return np.array(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:36:30.568761Z",
     "iopub.status.busy": "2020-12-27T07:36:30.568030Z",
     "iopub.status.idle": "2020-12-27T07:38:41.659147Z",
     "shell.execute_reply": "2020-12-27T07:38:41.658286Z"
    },
    "papermill": {
     "duration": 131.1222,
     "end_time": "2020-12-27T07:38:41.659301",
     "exception": false,
     "start_time": "2020-12-27T07:36:30.537101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "###\n",
    "tag_acc_array = train_df.groupby(\"user_id\").apply(lambda x: tag_accuracy(x[\"answered_correctly\"].values, x[\"community\"].values))\n",
    "tag_acc_array = np.hstack(tag_acc_array)\n",
    "tag_acc_array = tag_acc_array[train_index]\n",
    "\n",
    "user_community_count_dict = train_df.groupby(\"user_id\").apply(lambda x: tag_count_last(x[\"answered_correctly\"].values, x[\"community\"].values)).to_dict(defaultdict(init_dict))\n",
    "user_community_correct_dict = train_df.groupby(\"user_id\").apply(lambda x: tag_correct_last(x[\"answered_correctly\"].values, x[\"community\"].values)).to_dict(defaultdict(init_dict))\n",
    "    \n",
    "#\n",
    "community_agg = train_df.groupby('community')[target].agg(['count'])\n",
    "community_count_dict = community_agg['count'].astype('int32').to_dict(defaultdict(int))\n",
    "community_count_array = train_df['community'].map(community_agg['count']).astype('int32').values\n",
    "del community_agg\n",
    "community_count_array = community_count_array[train_index]\n",
    "    \n",
    "community_array = train_df[\"community\"].values\n",
    "community_array = community_array[train_index]\n",
    "train_df.drop('community', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:38:41.745245Z",
     "iopub.status.busy": "2020-12-27T07:38:41.743980Z",
     "iopub.status.idle": "2020-12-27T07:39:24.111291Z",
     "shell.execute_reply": "2020-12-27T07:39:24.110397Z"
    },
    "papermill": {
     "duration": 42.423289,
     "end_time": "2020-12-27T07:39:24.111433",
     "exception": false,
     "start_time": "2020-12-27T07:38:41.688144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def user_correctness_by_bundle(A, T):\n",
    "    ans = np.zeros(len(T))\n",
    "    count = np.zeros(len(T))\n",
    "    correct = np.zeros(len(T))\n",
    "    prev_time = 0\n",
    "    for i in range(len(T)): \n",
    "        if i == 0:\n",
    "            ans[i] = -1\n",
    "        elif prev_time == T[i]:\n",
    "            ans[i] = ans[i-1]\n",
    "        else:\n",
    "            if count[i-1] == 0:\n",
    "                ans[i] = -1\n",
    "            else:\n",
    "                ans[i] = correct[i-1] / count[i-1]\n",
    "        count[i] = count[i-1] + 1\n",
    "        correct[i] = correct[i-1] + A[i]\n",
    "        prev_time = T[i]\n",
    "    return ans\n",
    "\n",
    "user_correctness_array = train_df.groupby(\"user_id\").apply(lambda x: user_correctness_by_bundle(x[\"answered_correctly\"].values,\n",
    "                                                                                                x[\"timestamp\"].values))\n",
    "user_correctness_array = np.hstack(user_correctness_array)\n",
    "user_correctness_array = user_correctness_array[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:39:24.177122Z",
     "iopub.status.busy": "2020-12-27T07:39:24.176300Z",
     "iopub.status.idle": "2020-12-27T07:39:24.180909Z",
     "shell.execute_reply": "2020-12-27T07:39:24.180207Z"
    },
    "papermill": {
     "duration": 0.038787,
     "end_time": "2020-12-27T07:39:24.181026",
     "exception": false,
     "start_time": "2020-12-27T07:39:24.142239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @jit\n",
    "# def continuous_part_by_bundle(P, T):\n",
    "#     ans = np.zeros(len(T))\n",
    "#     count = 1\n",
    "#     prev_time = -1\n",
    "#     prev_part = -1\n",
    "#     for i in range(len(T)): \n",
    "#         if prev_part == P[i]:\n",
    "#             count += 1\n",
    "#         else:\n",
    "#             count = 1\n",
    "        \n",
    "#         if prev_time != T[i]:\n",
    "#             ans[i] = count\n",
    "#         else:    \n",
    "#             ans[i] = ans[i-1]\n",
    "#         prev_time = T[i]\n",
    "#         prev_part = P[i]\n",
    "#     return ans\n",
    "\n",
    "# continuous_part_array = tmp.groupby(\"user_id\").apply(lambda x: continuous_part_by_bundle(x[\"part\"].values,\n",
    "#                                                                                          x[\"timestamp\"].values))\n",
    "# continuous_part_array = np.hstack(continuous_part_array)\n",
    "# continuous_part_array = continuous_part_array[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:39:24.258878Z",
     "iopub.status.busy": "2020-12-27T07:39:24.248007Z",
     "iopub.status.idle": "2020-12-27T07:40:32.012148Z",
     "shell.execute_reply": "2020-12-27T07:40:32.012708Z"
    },
    "papermill": {
     "duration": 67.803129,
     "end_time": "2020-12-27T07:40:32.012979",
     "exception": false,
     "start_time": "2020-12-27T07:39:24.209850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def part_count_by_bundle(P, T):\n",
    "    ans = np.zeros(len(T))\n",
    "    part_count = [0] * 8\n",
    "    prev_time = -1\n",
    "    for i in range(len(T)):\n",
    "        if i == 0:\n",
    "            ans[i] = 0\n",
    "        elif prev_time == T[i]:\n",
    "            ans[i] = ans[i-1]\n",
    "        else:\n",
    "            ans[i] = part_count[P[i]]            \n",
    "        prev_time = T[i]\n",
    "        part_count[P[i]] += 1\n",
    "    return ans \n",
    "\n",
    "@jit\n",
    "def part_count_dict_calc(P):\n",
    "    part_count = [0] * 8\n",
    "    for i in range(len(P)):\n",
    "        part_count[P[i]] += 1\n",
    "    return np.array(part_count)\n",
    "\n",
    "def part_dict_init():\n",
    "    ans = [0] * 8\n",
    "    return np.array(ans)\n",
    "\n",
    "part_count_array = train_df.groupby(\"user_id\").apply(lambda x: part_count_by_bundle(x[\"part\"].values,\n",
    "                                                                                    x[\"timestamp\"].values))\n",
    "part_count_array = np.hstack(part_count_array)\n",
    "part_count_array = part_count_array[train_index]\n",
    "part_ratio_array = part_count_array / count_array\n",
    "part_ratio_array[count_zero_index] = -1\n",
    "\n",
    "user_part_count_dict = train_df.groupby(\"user_id\").apply(lambda x: part_count_dict_calc(x[\"part\"].values)).to_dict(defaultdict(part_dict_init))\n",
    "\n",
    "part_array = train_df.part.values\n",
    "train_df.drop(\"part\", axis=1, inplace=True)\n",
    "part_array = part_array[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:40:32.076049Z",
     "iopub.status.busy": "2020-12-27T07:40:32.074657Z",
     "iopub.status.idle": "2020-12-27T07:41:18.129166Z",
     "shell.execute_reply": "2020-12-27T07:41:18.128461Z"
    },
    "papermill": {
     "duration": 46.086691,
     "end_time": "2020-12-27T07:41:18.129306",
     "exception": false,
     "start_time": "2020-12-27T07:40:32.042615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def had_explanation_mean_by_bundle(E, T):\n",
    "    ans = np.zeros(len(T))\n",
    "    count = 0\n",
    "    prev_time = -1 \n",
    "    for i in range(len(T)): \n",
    "        if prev_time == T[i]:\n",
    "            ans[i] = ans[i-1]\n",
    "        else:\n",
    "            ans[i] = count\n",
    "        prev_time = T[i]\n",
    "        count = count + E[i]\n",
    "    return ans\n",
    "\n",
    "prior_question_had_explanation_mean_array = train_df.groupby(\"user_id\").apply(lambda x: \n",
    "                                                                         had_explanation_mean_by_bundle(x[\"prior_question_had_explanation\"].values, \n",
    "                                                                                                        x[\"timestamp\"].values))\n",
    "prior_question_had_explanation_mean_array = np.hstack(prior_question_had_explanation_mean_array)\n",
    "prior_question_had_explanation_mean_array = prior_question_had_explanation_mean_array[train_index]\n",
    "prior_question_had_explanation_mean_array = prior_question_had_explanation_mean_array / count_array\n",
    "prior_question_had_explanation_mean_array[count_zero_index] = -1\n",
    "\n",
    "user_prior_question_had_explanation_sum_agg = train_df.groupby('user_id')[\"prior_question_had_explanation\"].agg(['sum'])\n",
    "user_prior_question_had_explanation_sum_dict = user_prior_question_had_explanation_sum_agg['sum'].astype('int32').to_dict(defaultdict(int))\n",
    "del user_prior_question_had_explanation_sum_agg\n",
    "\n",
    "prior_question_had_explanation_array = train_df.prior_question_had_explanation.values\n",
    "train_df.drop('prior_question_had_explanation', axis=1, inplace=True)\n",
    "prior_question_had_explanation_array = prior_question_had_explanation_array[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:41:18.205590Z",
     "iopub.status.busy": "2020-12-27T07:41:18.204906Z",
     "iopub.status.idle": "2020-12-27T07:41:47.156048Z",
     "shell.execute_reply": "2020-12-27T07:41:47.155389Z"
    },
    "papermill": {
     "duration": 28.996179,
     "end_time": "2020-12-27T07:41:47.156194",
     "exception": false,
     "start_time": "2020-12-27T07:41:18.160015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flushing output cache (0 entries)\n",
      "Flushing input history\n"
     ]
    }
   ],
   "source": [
    "first_attempt_df = pd.read_csv(\"../input/riiidpremadedatabundle/content_first_attempt.csv\")\n",
    "first_attempt_array = first_attempt_df.first_attempt.values\n",
    "train_df[\"first_attempt\"] = first_attempt_array\n",
    "\n",
    "unique_attempt_array= train_df.groupby(\"user_id\")[\"first_attempt\"].cumsum().values\n",
    "train_df[\"unique_attempt\"] = unique_attempt_array\n",
    "user_unique_agg = train_df.groupby('user_id')[\"unique_attempt\"].agg(['max'])\n",
    "user_unique_dict = user_unique_agg['max'].astype('int32').to_dict(defaultdict(int))\n",
    "\n",
    "first_attempt_array = first_attempt_array[train_index]\n",
    "unique_attempt_array = unique_attempt_array[train_index]\n",
    "train_df.drop(['first_attempt', 'unique_attempt'], axis=1, inplace=True)\n",
    "del first_attempt_df, user_unique_agg\n",
    "\n",
    "clear_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:41:47.230368Z",
     "iopub.status.busy": "2020-12-27T07:41:47.229657Z",
     "iopub.status.idle": "2020-12-27T07:41:59.961221Z",
     "shell.execute_reply": "2020-12-27T07:41:59.961726Z"
    },
    "papermill": {
     "duration": 12.774633,
     "end_time": "2020-12-27T07:41:59.961906",
     "exception": false,
     "start_time": "2020-12-27T07:41:47.187273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flushing output cache (0 entries)\n",
      "Flushing input history\n",
      "Flushing output cache (0 entries)\n",
      "Flushing input history\n"
     ]
    }
   ],
   "source": [
    "user_agg = train_df.groupby('user_id')[target].agg(['sum', 'count'])\n",
    "user_sum_dict = user_agg['sum'].astype('int16').to_dict(defaultdict(int))\n",
    "del user_agg['sum']\n",
    "user_count_dict = user_agg['count'].astype('int16').to_dict(defaultdict(int))\n",
    "del user_agg['count']\n",
    "clear_mem()\n",
    "\n",
    "#\n",
    "content_agg = train_df.groupby('content_id')[target].agg(['sum', 'count'])\n",
    "content_sum_dict = content_agg['sum'].astype('int32').to_dict(defaultdict(int))\n",
    "content_count_dict = content_agg['count'].astype('int32').to_dict(defaultdict(int))\n",
    "\n",
    "content_count_array = train_df['content_id'].map(content_agg['count']).astype('int32').values\n",
    "content_id_array = train_df['content_id'].map(content_agg['sum'] / content_agg['count']).values\n",
    "del content_agg\n",
    "clear_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:42:00.029204Z",
     "iopub.status.busy": "2020-12-27T07:42:00.027906Z",
     "iopub.status.idle": "2020-12-27T07:42:15.760440Z",
     "shell.execute_reply": "2020-12-27T07:42:15.760970Z"
    },
    "papermill": {
     "duration": 15.767975,
     "end_time": "2020-12-27T07:42:15.761147",
     "exception": false,
     "start_time": "2020-12-27T07:41:59.993172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('../input/riiidpremadedatabundle/got_point_array.pickle', 'rb') as f:\n",
    "    got_point_array = pickle.load(f)\n",
    "got_point_array = got_point_array[train_index]\n",
    "got_point_array = got_point_array / count_array\n",
    "got_point_array[count_zero_index] = -1\n",
    "    \n",
    "with open('../input/riiidpremadedatabundle/user_point_sum_dict.pickle', 'rb') as f: \n",
    "    user_point_sum_dict = pickle.load(f)\n",
    "\n",
    "content_id_array = content_id_array[train_index]\n",
    "content_count_array = content_count_array[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:42:15.826982Z",
     "iopub.status.busy": "2020-12-27T07:42:15.825997Z",
     "iopub.status.idle": "2020-12-27T07:42:34.705014Z",
     "shell.execute_reply": "2020-12-27T07:42:34.704335Z"
    },
    "papermill": {
     "duration": 18.913047,
     "end_time": "2020-12-27T07:42:34.705157",
     "exception": false,
     "start_time": "2020-12-27T07:42:15.792110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.drop([\"content_id\"], axis=1, inplace=True)\n",
    "\n",
    "with open('../input/riiidpremadedatabundle/user_content_dict.pickle', 'rb') as f: \n",
    "    user_content_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:42:34.884508Z",
     "iopub.status.busy": "2020-12-27T07:42:34.833028Z",
     "iopub.status.idle": "2020-12-27T07:46:06.414123Z",
     "shell.execute_reply": "2020-12-27T07:46:06.414742Z"
    },
    "papermill": {
     "duration": 211.678665,
     "end_time": "2020-12-27T07:46:06.414915",
     "exception": false,
     "start_time": "2020-12-27T07:42:34.736250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with open('../input/riiidpremadedatabundle/answered_correctly_last7_array.pickle','rb') as f:\n",
    "#     answered_correctly_last7_array = pickle.load(f)\n",
    "# answered_correctly_last7_array = answered_correctly_last7_array[train_index]\n",
    "    \n",
    "# with open('../input/riiidpremadedatabundle/user_last7_answer_dict.pickle','rb') as f:\n",
    "#     user_last7_answer_dict = pickle.load(f)\n",
    "    \n",
    "    \n",
    "@jit\n",
    "def last_accuracy7_by_bundle(A, T):\n",
    "    ans = np.zeros(len(T))\n",
    "    prev_time = np.array([-1] * 7)\n",
    "    correct = np.array([-1] * 7)\n",
    "    count = np.array([-1] * 7)\n",
    "    for i in range(len(T)): \n",
    "        length = np.sum(prev_time != -1)\n",
    "        if length <= 6:\n",
    "            ans[i] = np.nan\n",
    "        else: \n",
    "            if prev_time[-1] == T[i]:\n",
    "                ans[i] = ans[i-1]\n",
    "            else:\n",
    "                ans[i] = np.sum(correct) / np.sum(count)\n",
    "\n",
    "        if np.sum(prev_time == T[i]) == 0:\n",
    "            for j in range(6):\n",
    "                prev_time[j] = prev_time[j+1]\n",
    "                correct[j] = correct[j+1]\n",
    "                count[j] = count[j+1]\n",
    "            prev_time[-1] = T[i]\n",
    "            correct[-1] = A[i]\n",
    "            count[-1] = 1\n",
    "        else:\n",
    "            index = np.where(prev_time==T[i])[0][0]\n",
    "            correct[index] += A[i]\n",
    "            count[index] += 1  \n",
    "    return ans\n",
    "\n",
    "@jit\n",
    "def last_count7_by_bundle(A, T):\n",
    "    prev_time = np.array([-1] * 7)\n",
    "    correct = np.array([-1] * 7)\n",
    "    count = np.array([-1] * 7)\n",
    "    for i in range(len(T)): \n",
    "        length = np.sum(prev_time != -1)\n",
    "        if np.sum(prev_time == T[i]) == 0:\n",
    "            for j in range(6):\n",
    "                prev_time[j] = prev_time[j+1]\n",
    "                correct[j] = correct[j+1]\n",
    "                count[j] = count[j+1]\n",
    "            prev_time[-1] = T[i]\n",
    "            correct[-1] = A[i]\n",
    "            count[-1] = 1\n",
    "        else:\n",
    "            index = np.where(prev_time==T[i])[0][0]\n",
    "            correct[index] += A[i]\n",
    "            count[index] += 1  \n",
    "    return count\n",
    "\n",
    "@jit\n",
    "def last_correct7_by_bundle(A, T):\n",
    "    prev_time = np.array([-1] * 7)\n",
    "    correct = np.array([-1] * 7)\n",
    "    count = np.array([-1] * 7)\n",
    "    for i in range(len(T)): \n",
    "        length = np.sum(prev_time != -1)\n",
    "        if np.sum(prev_time == T[i]) == 0:\n",
    "            for j in range(6):\n",
    "                prev_time[j] = prev_time[j+1]\n",
    "                correct[j] = correct[j+1]\n",
    "                count[j] = count[j+1]\n",
    "            prev_time[-1] = T[i]\n",
    "            correct[-1] = A[i]\n",
    "            count[-1] = 1\n",
    "        else:\n",
    "            index = np.where(prev_time==T[i])[0][0]\n",
    "            correct[index] += A[i]\n",
    "            count[index] += 1  \n",
    "    return correct\n",
    "\n",
    "def init_last7():\n",
    "    ans = [-1] * 7\n",
    "    return np.array(ans)\n",
    "\n",
    "answered_correctly_last7_array = train_df.groupby(\"user_id\").apply(lambda x: last_accuracy7_by_bundle(x[\"answered_correctly\"].values, \n",
    "                                                                                          x[\"timestamp\"].values))\n",
    "answered_correctly_last7_array = np.hstack(answered_correctly_last7_array)\n",
    "answered_correctly_last7_array = answered_correctly_last7_array[train_index]\n",
    "\n",
    "user_last_count7_dict = train_df.groupby(\"user_id\").apply(lambda x: last_count7_by_bundle(x[\"answered_correctly\"].values, \n",
    "                                                                                x[\"timestamp\"].values)).to_dict(defaultdict(init_last7))\n",
    "\n",
    "user_last_correct7_dict = train_df.groupby(\"user_id\").apply(lambda x: last_correct7_by_bundle(x[\"answered_correctly\"].values, \n",
    "                                                                                    x[\"timestamp\"].values)).to_dict((defaultdict(init_last7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:46:06.516841Z",
     "iopub.status.busy": "2020-12-27T07:46:06.516147Z",
     "iopub.status.idle": "2020-12-27T07:48:13.130267Z",
     "shell.execute_reply": "2020-12-27T07:48:13.130847Z"
    },
    "papermill": {
     "duration": 126.684488,
     "end_time": "2020-12-27T07:48:13.131030",
     "exception": false,
     "start_time": "2020-12-27T07:46:06.446542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def continuous_correct_by_bundle(A, T):\n",
    "    ans = np.zeros(len(T))\n",
    "    count = 0\n",
    "    prev_time = -1\n",
    "    for i in range(len(T)): \n",
    "        if prev_time != T[i]:\n",
    "            ans[i] = count\n",
    "        else:    \n",
    "            ans[i] = ans[i-1]\n",
    "        if A[i] ==1:\n",
    "            count += 1\n",
    "        else:\n",
    "            count = 0\n",
    "        prev_time = T[i]\n",
    "    return ans\n",
    "\n",
    "continuous_correct_array = train_df.groupby(\"user_id\").apply(lambda x: continuous_correct_by_bundle(x[\"answered_correctly\"].values,\n",
    "                                                                                              x[\"timestamp\"].values))\n",
    "continuous_correct_array = np.hstack(continuous_correct_array)\n",
    "continuous_correct_array = continuous_correct_array[train_index]\n",
    "\n",
    "@jit\n",
    "def continuous_incorrect_by_bundle(A, T):\n",
    "    ans = np.zeros(len(T))\n",
    "    count = 0\n",
    "    prev_time = -1\n",
    "    for i in range(len(T)): \n",
    "        if prev_time != T[i]:\n",
    "            ans[i] = count\n",
    "        else:    \n",
    "            ans[i] = ans[i-1]\n",
    "        if A[i] ==0:\n",
    "            count += 1\n",
    "        else:\n",
    "            count = 0\n",
    "        prev_time = T[i]\n",
    "    return ans\n",
    "continuous_incorrect_array = train_df.groupby(\"user_id\").apply(lambda x: continuous_incorrect_by_bundle(x[\"answered_correctly\"].values,\n",
    "                                                                                        x[\"timestamp\"].values))\n",
    "continuous_incorrect_array = np.hstack(continuous_incorrect_array)\n",
    "continuous_incorrect_array = continuous_incorrect_array[train_index]\n",
    "\n",
    "@jit\n",
    "def continuous_correct_dict_calc(A):\n",
    "    count = 0\n",
    "    for i in range(len(A)): \n",
    "        if A[i] ==1:\n",
    "            count += 1\n",
    "        else:\n",
    "            count = 0\n",
    "    return count\n",
    "\n",
    "@jit\n",
    "def continuous_incorrect_dict_calc(A):\n",
    "    count = 0\n",
    "    for i in range(len(A)): \n",
    "        if A[i] ==0:\n",
    "            count += 1\n",
    "        else:\n",
    "            count = 0\n",
    "    return count\n",
    "\n",
    "continuous_incorrect_dict = train_df.groupby(\"user_id\").apply(lambda x: continuous_incorrect_dict_calc(x[\"answered_correctly\"].values)).to_dict(defaultdict(int))\n",
    "continuous_correct_dict = train_df.groupby(\"user_id\").apply(lambda x: continuous_correct_dict_calc(x[\"answered_correctly\"].values)).to_dict(defaultdict(int))\n",
    "\n",
    "# with open('continuous_correct_array.pickle','rb') as f:\n",
    "#     continuous_correct_array = pickle.load(f)\n",
    "\n",
    "# with open('continuous_correct_dict.pickle','rb') as f:\n",
    "#     continuous_correct_dict = pickle.load(f)\n",
    "    \n",
    "# with open('continuous_incorrect_array.pickle','rb') as f:\n",
    "#     continuous_incorrect_array = pickle.load(f)\n",
    "    \n",
    "# with open('continuous_incorrect_dict.pickle','rb') as f:\n",
    "#     continuous_incorrect_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:48:13.198151Z",
     "iopub.status.busy": "2020-12-27T07:48:13.197148Z",
     "iopub.status.idle": "2020-12-27T07:48:16.209644Z",
     "shell.execute_reply": "2020-12-27T07:48:16.210305Z"
    },
    "papermill": {
     "duration": 3.048215,
     "end_time": "2020-12-27T07:48:16.210573",
     "exception": false,
     "start_time": "2020-12-27T07:48:13.162358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "answered_correctly_array = train_df[target].values\n",
    "train_df.drop(target, axis=1, inplace=True)\n",
    "answered_correctly_array = answered_correctly_array[train_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032379,
     "end_time": "2020-12-27T07:48:16.275959",
     "exception": false,
     "start_time": "2020-12-27T07:48:16.243580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# data formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:48:16.398928Z",
     "iopub.status.busy": "2020-12-27T07:48:16.397967Z",
     "iopub.status.idle": "2020-12-27T07:48:32.436506Z",
     "shell.execute_reply": "2020-12-27T07:48:32.437256Z"
    },
    "papermill": {
     "duration": 16.129395,
     "end_time": "2020-12-27T07:48:32.437477",
     "exception": false,
     "start_time": "2020-12-27T07:48:16.308082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not FULL_TRAIN:\n",
    "    train_df = train_df[train_df.index.isin(train_index)].reset_index(drop=True)\n",
    "    if CV_SCHEME == \"original\":\n",
    "        valid_index = list(train_df.groupby('user_id').tail(valid_size).index)\n",
    "    else:\n",
    "        valid_index = list(train_df['viretual_time_stamp'].nlargest(2500000).index)\n",
    "    train_index = list(train_df[~train_df.index.isin(valid_index)].index)\n",
    "del train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:48:32.506867Z",
     "iopub.status.busy": "2020-12-27T07:48:32.506138Z",
     "iopub.status.idle": "2020-12-27T07:48:32.520660Z",
     "shell.execute_reply": "2020-12-27T07:48:32.521367Z"
    },
    "papermill": {
     "duration": 0.050351,
     "end_time": "2020-12-27T07:48:32.521600",
     "exception": false,
     "start_time": "2020-12-27T07:48:32.471249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "features_dict = {\n",
    "    'content_id': content_id_array,\n",
    "    'prior_question_elapsed_time': prior_question_elapsed_time_array,\n",
    "    'prior_question_had_explanation':  prior_question_had_explanation_array,\n",
    "    'user_correctness': user_correctness_array,\n",
    "    'part': part_array,\n",
    "    'content_count': content_count_array,\n",
    "    'count': count_array,\n",
    "    'first_attempt': first_attempt_array,\n",
    "    'unique_attempt': unique_attempt_array,\n",
    "    'part_count': part_count_array,\n",
    "    'part_ratio': part_ratio_array,\n",
    "    'prior_question_had_explanation_mean': prior_question_had_explanation_mean_array,\n",
    "    'got_point': got_point_array,\n",
    "    'answered_correctly_last7': answered_correctly_last7_array,   \n",
    "    'timediff': timediff_array,\n",
    "    'timediff2': timediff2_array,\n",
    "    'timediff3': timediff3_array,\n",
    "    'timediff4': timediff4_array,\n",
    "    'community': community_array,\n",
    "    'tag_acc': tag_acc_array,\n",
    "    'community_count': community_count_array,\n",
    "    'time_dd': time_dd_array,\n",
    "    'continuous_correct': continuous_correct_array,\n",
    "    'continuous_incorrect': continuous_incorrect_array,\n",
    "    'prior_question_elapsed_time_mean': prior_question_elapsed_time_mean_array\n",
    "}\n",
    "\n",
    "features = list(features_dict.keys())\n",
    "print(len(features))\n",
    "\n",
    "del content_id_array, prior_question_elapsed_time_array, prior_question_had_explanation_array,\n",
    "del user_correctness_array, part_array,\n",
    "del content_count_array, count_array, first_attempt_array, unique_attempt_array,\n",
    "del part_ratio_array, part_count_array,\n",
    "del prior_question_had_explanation_mean_array, prior_question_elapsed_time_mean_array, got_point_array, \n",
    "del answered_correctly_last7_array, timediff_array, timediff2_array, timediff3_array, timediff4_array,\n",
    "del community_array,\n",
    "del tag_acc_array, community_count_array, time_dd_array, continuous_correct_array, continuous_incorrect_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:48:32.594807Z",
     "iopub.status.busy": "2020-12-27T07:48:32.594123Z",
     "iopub.status.idle": "2020-12-27T07:48:32.597706Z",
     "shell.execute_reply": "2020-12-27T07:48:32.598296Z"
    },
    "papermill": {
     "duration": 0.044624,
     "end_time": "2020-12-27T07:48:32.598434",
     "exception": false,
     "start_time": "2020-12-27T07:48:32.553810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6536675, 26) (2360984, 26)\n"
     ]
    }
   ],
   "source": [
    "if FULL_TRAIN:\n",
    "    print(len(train_index), len(features)+1)\n",
    "else:\n",
    "    print((len(train_index), len(features)+1), (len(valid_index), len(features)+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033447,
     "end_time": "2020-12-27T07:48:32.663830",
     "exception": false,
     "start_time": "2020-12-27T07:48:32.630383",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:48:32.733228Z",
     "iopub.status.busy": "2020-12-27T07:48:32.732546Z",
     "iopub.status.idle": "2020-12-27T07:48:32.737017Z",
     "shell.execute_reply": "2020-12-27T07:48:32.737584Z"
    },
    "papermill": {
     "duration": 0.041149,
     "end_time": "2020-12-27T07:48:32.737763",
     "exception": false,
     "start_time": "2020-12-27T07:48:32.696614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'seed': 42,\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.05,\n",
    "    'max_bin': 800,\n",
    "    'num_leaves': 80\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:48:32.808608Z",
     "iopub.status.busy": "2020-12-27T07:48:32.807895Z",
     "iopub.status.idle": "2020-12-27T07:49:27.738652Z",
     "shell.execute_reply": "2020-12-27T07:49:27.736701Z"
    },
    "papermill": {
     "duration": 54.96827,
     "end_time": "2020-12-27T07:49:27.738827",
     "exception": false,
     "start_time": "2020-12-27T07:48:32.770557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if FULL_TRAIN:\n",
    "    X_train = np.ndarray(shape=(len(train_index), len(features)), dtype=np.float32)\n",
    "\n",
    "    for idx, feature in enumerate(features):\n",
    "        X_train[:,idx] = features_dict[feature].astype(np.float32).reshape(-1)\n",
    "        del features_dict[feature]\n",
    "    y_train = answered_correctly_array.astype(np.float32)\n",
    "    tr_data = lgb.Dataset(X_train, label=y_train)\n",
    "else:\n",
    "    X_train = np.ndarray(shape=(len(train_index), len(features)), dtype=np.float32)\n",
    "    X_valid = np.ndarray(shape=(len(valid_index), len(features)), dtype=np.float32)\n",
    "\n",
    "    for idx, feature in enumerate(features):\n",
    "        X_train[:,idx] = features_dict[feature][train_index].astype(np.float32).reshape(-1)\n",
    "        X_valid[:,idx] = features_dict[feature][valid_index].astype(np.float32).reshape(-1)\n",
    "        del features_dict[feature]\n",
    "    y_train = answered_correctly_array[train_index].astype(np.float32)\n",
    "    y_valid = answered_correctly_array[valid_index].astype(np.float32)\n",
    "\n",
    "    tr_data = lgb.Dataset(X_train, label=y_train)\n",
    "    va_data = lgb.Dataset(X_valid, label=y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T07:49:27.816501Z",
     "iopub.status.busy": "2020-12-27T07:49:27.815500Z",
     "iopub.status.idle": "2020-12-27T09:07:40.808230Z",
     "shell.execute_reply": "2020-12-27T09:07:40.809504Z"
    },
    "papermill": {
     "duration": 4693.035861,
     "end_time": "2020-12-27T09:07:40.809866",
     "exception": false,
     "start_time": "2020-12-27T07:49:27.774005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training starts\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\ttraining's auc: 0.765546\tvalid_1's auc: 0.751674\n",
      "[100]\ttraining's auc: 0.770363\tvalid_1's auc: 0.757581\n",
      "[150]\ttraining's auc: 0.772719\tvalid_1's auc: 0.76006\n",
      "[200]\ttraining's auc: 0.774103\tvalid_1's auc: 0.761318\n",
      "[250]\ttraining's auc: 0.775113\tvalid_1's auc: 0.762164\n",
      "[300]\ttraining's auc: 0.77581\tvalid_1's auc: 0.76263\n",
      "[350]\ttraining's auc: 0.776406\tvalid_1's auc: 0.762958\n",
      "[400]\ttraining's auc: 0.7769\tvalid_1's auc: 0.763197\n",
      "[450]\ttraining's auc: 0.777331\tvalid_1's auc: 0.763385\n",
      "[500]\ttraining's auc: 0.777783\tvalid_1's auc: 0.76359\n",
      "[550]\ttraining's auc: 0.778196\tvalid_1's auc: 0.763773\n",
      "[600]\ttraining's auc: 0.778642\tvalid_1's auc: 0.764035\n",
      "[650]\ttraining's auc: 0.779021\tvalid_1's auc: 0.764183\n",
      "[700]\ttraining's auc: 0.779401\tvalid_1's auc: 0.764312\n",
      "[750]\ttraining's auc: 0.77973\tvalid_1's auc: 0.764412\n",
      "[800]\ttraining's auc: 0.780097\tvalid_1's auc: 0.76456\n",
      "[850]\ttraining's auc: 0.780437\tvalid_1's auc: 0.764646\n",
      "[900]\ttraining's auc: 0.780773\tvalid_1's auc: 0.764775\n",
      "[950]\ttraining's auc: 0.781117\tvalid_1's auc: 0.764882\n",
      "[1000]\ttraining's auc: 0.781467\tvalid_1's auc: 0.76501\n",
      "[1050]\ttraining's auc: 0.781777\tvalid_1's auc: 0.765086\n",
      "[1100]\ttraining's auc: 0.782105\tvalid_1's auc: 0.765181\n",
      "[1150]\ttraining's auc: 0.782432\tvalid_1's auc: 0.765293\n",
      "[1200]\ttraining's auc: 0.782751\tvalid_1's auc: 0.765389\n",
      "[1250]\ttraining's auc: 0.783091\tvalid_1's auc: 0.765514\n",
      "[1300]\ttraining's auc: 0.783395\tvalid_1's auc: 0.76558\n",
      "[1350]\ttraining's auc: 0.783693\tvalid_1's auc: 0.765632\n",
      "[1400]\ttraining's auc: 0.783969\tvalid_1's auc: 0.765676\n",
      "[1450]\ttraining's auc: 0.784249\tvalid_1's auc: 0.765711\n",
      "[1500]\ttraining's auc: 0.784545\tvalid_1's auc: 0.76576\n",
      "[1550]\ttraining's auc: 0.784838\tvalid_1's auc: 0.765818\n",
      "[1600]\ttraining's auc: 0.785098\tvalid_1's auc: 0.765836\n",
      "[1650]\ttraining's auc: 0.785397\tvalid_1's auc: 0.765893\n",
      "[1700]\ttraining's auc: 0.785687\tvalid_1's auc: 0.765945\n",
      "[1750]\ttraining's auc: 0.785964\tvalid_1's auc: 0.765997\n",
      "[1800]\ttraining's auc: 0.786249\tvalid_1's auc: 0.766058\n",
      "[1850]\ttraining's auc: 0.786513\tvalid_1's auc: 0.76609\n",
      "[1900]\ttraining's auc: 0.786793\tvalid_1's auc: 0.766125\n",
      "[1950]\ttraining's auc: 0.787048\tvalid_1's auc: 0.766139\n",
      "[2000]\ttraining's auc: 0.787289\tvalid_1's auc: 0.766154\n",
      "[2050]\ttraining's auc: 0.787551\tvalid_1's auc: 0.766191\n",
      "[2100]\ttraining's auc: 0.787813\tvalid_1's auc: 0.766221\n",
      "[2150]\ttraining's auc: 0.788088\tvalid_1's auc: 0.766263\n",
      "[2200]\ttraining's auc: 0.788338\tvalid_1's auc: 0.766279\n",
      "[2250]\ttraining's auc: 0.788596\tvalid_1's auc: 0.766302\n",
      "Early stopping, best iteration is:\n",
      "[2251]\ttraining's auc: 0.7886\tvalid_1's auc: 0.766302\n"
     ]
    }
   ],
   "source": [
    "print(\"training starts\")\n",
    "if FULL_TRAIN:\n",
    "    model = lgb.train(\n",
    "        params, \n",
    "        tr_data, \n",
    "        num_boost_round=3000,\n",
    "        valid_sets=None, \n",
    "        )\n",
    "    del X_train, y_train\n",
    "else:\n",
    "    model = lgb.train(\n",
    "        params, \n",
    "        tr_data, \n",
    "        num_boost_round= 2500,\n",
    "        valid_sets=[tr_data, va_data], \n",
    "        early_stopping_rounds=20,\n",
    "        verbose_eval=50\n",
    "        )\n",
    "    del X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.056948,
     "end_time": "2020-12-27T09:07:40.930756",
     "exception": false,
     "start_time": "2020-12-27T09:07:40.873808",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T09:07:41.040495Z",
     "iopub.status.busy": "2020-12-27T09:07:41.039783Z",
     "iopub.status.idle": "2020-12-27T09:07:41.044007Z",
     "shell.execute_reply": "2020-12-27T09:07:41.043243Z"
    },
    "papermill": {
     "duration": 0.064872,
     "end_time": "2020-12-27T09:07:41.044141",
     "exception": false,
     "start_time": "2020-12-27T09:07:40.979269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = riiideducation.make_env()\n",
    "iter_test = env.iter_test()\n",
    "prior_test_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-27T09:07:41.207814Z",
     "iopub.status.busy": "2020-12-27T09:07:41.155394Z",
     "iopub.status.idle": "2020-12-27T09:07:42.251904Z",
     "shell.execute_reply": "2020-12-27T09:07:42.251160Z"
    },
    "papermill": {
     "duration": 1.157528,
     "end_time": "2020-12-27T09:07:42.252057",
     "exception": false,
     "start_time": "2020-12-27T09:07:41.094529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.67 s, sys: 135 ms, total: 1.8 s\n",
      "Wall time: 1.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    if prior_test_df is not None:\n",
    "        prior_test_df[target] = eval(test_df['prior_group_answers_correct'].iloc[0])\n",
    "        prior_test_df = prior_test_df[prior_test_df[target] != -1].reset_index(drop=True)\n",
    "        \n",
    "        user_ids = prior_test_df['user_id'].values\n",
    "        content_ids = prior_test_df['content_id'].values\n",
    "        targets = prior_test_df[target].values\n",
    "        timestamps = prior_test_df['timestamp'].values\n",
    "                 \n",
    "        for (user_id, content_id, answered_correctly, first_attempt_ornot, prior_explanation,\n",
    "             prior_point, prior_community, prior_timestamp, prior_part, prior_elapsed) in zip(user_ids, \n",
    "                                                            content_ids, \n",
    "                                                            targets, \n",
    "                                                            prior_f_attempt_arrays,\n",
    "                                                            p_prior_question_had_explanation,\n",
    "                                                            prior_point_array,\n",
    "                                                            prior_community_arrays,\n",
    "                                                            timestamps,\n",
    "                                                            prior_part_array,\n",
    "                                                            p_prior_question_elapsed_time):\n",
    "            \n",
    "            user_sum_dict[user_id] += answered_correctly\n",
    "            user_count_dict[user_id] += 1\n",
    "            content_sum_dict[content_id] += answered_correctly\n",
    "            content_count_dict[content_id] += 1\n",
    "            user_unique_dict[user_id] += first_attempt_ornot\n",
    "            user_prior_question_had_explanation_sum_dict[user_id] += prior_explanation\n",
    "            user_prior_question_elapsed_time_sum_dict[user_id] += prior_elapsed\n",
    "            user_point_sum_dict[user_id] += prior_point * answered_correctly\n",
    "            user_part_count_dict[user_id][prior_part] += 1\n",
    "            user_community_correct_dict[user_id][prior_community] += answered_correctly\n",
    "            user_community_count_dict[user_id][prior_community] += 1\n",
    "            community_count_dict[prior_community] += 1  \n",
    "            \n",
    "            if np.sum(user_timestamp_max_dict[user_id] == prior_timestamp) == 0:\n",
    "                if len(user_timestamp_max_dict[user_id]) <= 3: \n",
    "                    user_timestamp_max_dict[user_id] = np.concatenate([user_timestamp_max_dict[user_id],[prior_timestamp]])\n",
    "                else:\n",
    "                    user_timestamp_max_dict[user_id] = np.concatenate([user_timestamp_max_dict[user_id],[prior_timestamp]])[1:]  \n",
    "                user_last_count7_dict[user_id] = np.concatenate([user_last_count7_dict[user_id],[1]])[1:]\n",
    "                user_last_correct7_dict[user_id] = np.concatenate([user_last_correct7_dict[user_id],[answered_correctly]])[1:]\n",
    "            else:\n",
    "                user_last_count7_dict[user_id][-1] += 1\n",
    "                user_last_correct7_dict[user_id][-1] += answered_correctly\n",
    "                    \n",
    "            if answered_correctly == 1:\n",
    "                continuous_correct_dict[user_id] += 1\n",
    "                continuous_incorrect_dict[user_id] = 0\n",
    "            else:\n",
    "                continuous_correct_dict[user_id] = 0\n",
    "                continuous_incorrect_dict[user_id] += 1\n",
    "                    \n",
    "    prior_test_df = test_df.copy()\n",
    "           \n",
    "    test_df = test_df[test_df['content_type_id'] == 0].reset_index(drop=True)\n",
    "    test_df = pd.merge(test_df, questions_df, left_on='content_id', right_on='question_id', how='left', right_index=True).reset_index(drop=True)\n",
    "    test_df['prior_question_had_explanation'] = test_df['prior_question_had_explanation'].fillna(False).astype('int8')\n",
    "    test_df['prior_question_elapsed_time'] = test_df['prior_question_elapsed_time'].fillna(0)\n",
    "\n",
    "    p_prior_question_elapsed_time = test_df['prior_question_elapsed_time'].values\n",
    "    p_prior_question_had_explanation = test_df['prior_question_had_explanation'].values\n",
    "    prior_community_arrays = test_df['community'].values\n",
    "    prior_part_array = test_df['part'].values\n",
    "   \n",
    "    first_attempt_values = []\n",
    "    user_sum = np.zeros(len(test_df), dtype=np.int16)\n",
    "    user_count = np.zeros(len(test_df), dtype=np.int16)\n",
    "    content_sum = np.zeros(len(test_df), dtype=np.int32)\n",
    "    content_count = np.zeros(len(test_df), dtype=np.int32)\n",
    "    part_count = np.zeros(len(test_df), dtype=np.int32)\n",
    "    part_ratio_array = np.zeros(len(test_df), dtype=np.float32)\n",
    "    user_correctness_array = np.zeros(len(test_df), dtype=np.float32)\n",
    "    user_unique_count = np.zeros(len(test_df), dtype=np.int32)\n",
    "    user_prior_question_had_explanation_mean_array = np.zeros(len(test_df), dtype=np.float32)\n",
    "    user_prior_question_elapsed_time_mean_array = np.zeros(len(test_df), dtype=np.float32)\n",
    "    got_point_array = np.zeros(len(test_df), dtype=np.float32)\n",
    "    user_last7_accuracy_array = np.zeros(len(test_df), dtype=np.float32)\n",
    "    timediff_array = np.zeros(len(test_df), dtype = np.int64)\n",
    "    timediff2_array = np.zeros(len(test_df), dtype = np.int64)\n",
    "    timediff3_array = np.zeros(len(test_df), dtype = np.int64)\n",
    "    timediff4_array = np.zeros(len(test_df), dtype = np.int64)\n",
    "    tag_acc_array = np.zeros(len(test_df), dtype=np.float32)\n",
    "    community_count_array = np.zeros(len(test_df), dtype=np.int32)\n",
    "    time_dd_array = np.zeros(len(test_df), dtype = np.int64)\n",
    "    user_con_correct_array = np.zeros(len(test_df), dtype=np.int16)\n",
    "    user_con_incorrect_array = np.zeros(len(test_df), dtype=np.int16)\n",
    "    \n",
    "    for i, (user_id, content_id, timestamp, community, part) in enumerate(zip(test_df['user_id'].values, \n",
    "                                                             test_df['content_id'].values,\n",
    "                                                             test_df['timestamp'].values,\n",
    "                                                             test_df['community'].values,\n",
    "                                                             test_df['part'].values)):\n",
    "        user_sum[i] = user_sum_dict[user_id]\n",
    "        user_count[i] = user_count_dict[user_id]\n",
    "        content_sum[i] = content_sum_dict[content_id]\n",
    "        content_count[i] = content_count_dict[content_id]\n",
    "        part_count[i] = user_part_count_dict[user_id][part]\n",
    "        first_attempt_values.append(user_content_dict[user_id][content_id])\n",
    "        user_content_dict[user_id][content_id] = False             \n",
    "        user_unique_count[i] = user_unique_dict[user_id]\n",
    "        if user_count[i] != 0:\n",
    "            user_correctness_array[i] = user_sum[i] / user_count[i]\n",
    "            part_ratio_array[i] = part_count[i] / user_count[i]\n",
    "            user_prior_question_had_explanation_mean_array[i] = user_prior_question_had_explanation_sum_dict[user_id] / user_count[i]\n",
    "            user_prior_question_elapsed_time_mean_array[i] = user_prior_question_elapsed_time_sum_dict[user_id] / user_count[i]\n",
    "        else:\n",
    "            user_correctness_array[i] = -1\n",
    "            part_ratio_array[i] = -1\n",
    "            user_prior_question_had_explanation_mean_array[i] = -1\n",
    "            user_prior_question_elapsed_time_mean_array[i] = -1\n",
    "        \n",
    "        if np.sum(user_last_count7_dict != -1)==7:\n",
    "            user_last7_accuracy_array[i] = user_last_correct7_dict[user_id].sum() / user_last_count7_dict[user_id].sum()\n",
    "        else:\n",
    "            user_last7_accuracy_array[i] = np.nan\n",
    "\n",
    "        if len(user_timestamp_max_dict[user_id]) ==0:\n",
    "            timediff_array[i] = -1\n",
    "            timediff2_array[i] = -1\n",
    "            timediff3_array[i] = -1\n",
    "            timediff4_array[i] = -1\n",
    "            time_dd_array[i] = -1\n",
    "            \n",
    "        elif len(user_timestamp_max_dict[user_id]) ==1:\n",
    "            timediff_array[i] = timestamp - user_timestamp_max_dict[user_id][0]\n",
    "            timediff2_array[i] = -1\n",
    "            timediff3_array[i] = -1\n",
    "            timediff4_array[i] = -1\n",
    "            time_dd_array[i] = -1\n",
    "            \n",
    "        elif len(user_timestamp_max_dict[user_id]) ==2:\n",
    "            timediff_array[i] = timestamp - user_timestamp_max_dict[user_id][1]\n",
    "            timediff2_array[i] = timestamp - user_timestamp_max_dict[user_id][0]\n",
    "            timediff3_array[i] = -1\n",
    "            timediff4_array[i] = -1\n",
    "            time_dd_array[i] = timediff2_array[i] - timediff_array[i]\n",
    "            \n",
    "        elif len(user_timestamp_max_dict[user_id]) ==3:\n",
    "            timediff_array[i] = timestamp - user_timestamp_max_dict[user_id][2]\n",
    "            timediff2_array[i] = timestamp - user_timestamp_max_dict[user_id][1]\n",
    "            timediff3_array[i] = timestamp - user_timestamp_max_dict[user_id][0]\n",
    "            timediff4_array[i] = -1\n",
    "            time_dd_array[i] = timediff2_array[i] - timediff_array[i]\n",
    "    \n",
    "        else:\n",
    "            timediff_array[i] = timestamp - user_timestamp_max_dict[user_id][3]\n",
    "            timediff2_array[i] = timestamp - user_timestamp_max_dict[user_id][2]\n",
    "            timediff3_array[i] = timestamp - user_timestamp_max_dict[user_id][1]\n",
    "            timediff4_array[i] = timestamp - user_timestamp_max_dict[user_id][0]\n",
    "            time_dd_array[i] = timediff2_array[i] - timediff_array[i]\n",
    "            \n",
    "        if user_community_count_dict[user_id][community] == 0:\n",
    "            tag_acc_array[i] = -1\n",
    "        else:\n",
    "            tag_acc_array[i] = user_community_correct_dict[user_id][community] / user_community_count_dict[user_id][community]\n",
    "\n",
    "        got_point_array[i] = user_point_sum_dict[user_id]\n",
    "        community_count_array[i] = community_count_dict[community]\n",
    "        user_con_correct_array[i] = continuous_correct_dict[user_id]\n",
    "        user_con_incorrect_array[i] = continuous_incorrect_dict[user_id]\n",
    "     \n",
    "    test_df['count'] = user_count\n",
    "    test_df['user_correctness'] = user_correctness_array\n",
    "    test_df['content_count'] = content_count\n",
    "    test_df['content_id'] = content_sum / content_count\n",
    "    test_df['part_count'] = part_count\n",
    "    test_df['part_ratio'] = part_ratio_array\n",
    "    test_df[\"first_attempt\"] = first_attempt_values\n",
    "    test_df[\"unique_attempt\"] = test_df.groupby(\"user_id\")[\"first_attempt\"].cumsum()\n",
    "    test_df[\"unique_attempt\"] += user_unique_count\n",
    "    test_df['prior_question_had_explanation_mean'] = user_prior_question_had_explanation_mean_array\n",
    "    test_df['prior_question_elapsed_time_mean'] = user_prior_question_elapsed_time_mean_array\n",
    "    test_df['got_point'] = got_point_array / user_count\n",
    "    test_df['answered_correctly_last7'] = user_last7_accuracy_array\n",
    "    test_df['timediff'] = timediff_array\n",
    "    test_df['timediff2'] = timediff2_array\n",
    "    test_df['timediff3'] = timediff3_array\n",
    "    test_df['timediff4'] = timediff4_array\n",
    "    test_df['tag_acc'] = tag_acc_array\n",
    "    test_df['community_count'] = community_count_array\n",
    "    test_df['time_dd'] = time_dd_array\n",
    "    test_df['continuous_correct'] = user_con_correct_array\n",
    "    test_df['continuous_incorrect'] = user_con_incorrect_array\n",
    "\n",
    "    prior_f_attempt_arrays = test_df['first_attempt'].values\n",
    "    prior_point_array = 1 / (test_df.content_id.values + 0.1)\n",
    "    \n",
    "    test_df[target] = model.predict(test_df[features])\n",
    "    env.predict(test_df[['row_id', target]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.051756,
     "end_time": "2020-12-27T09:07:42.354588",
     "exception": false,
     "start_time": "2020-12-27T09:07:42.302832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 6028.849305,
   "end_time": "2020-12-27T09:07:42.816717",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-27T07:27:13.967412",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
