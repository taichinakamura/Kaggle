{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "This kernel used LGBM and treated it as a regression problem. I only did a little feature engineering so far.(just transform some date format features into numeric)\n",
    "\n",
    "The ideas is that:\n",
    "- if we treated it as a regression problem, it's better to do some smooth operation. See the [kernel](https://www.kaggle.com/hukuda222/nfl-simple-evluation-trick).\n",
    "- I used the distribution in [kernel](https://www.kaggle.com/jpmiller/simple-distribution) as my smooth distribution.\n",
    "- We can see the simple distribution in [kernel](https://www.kaggle.com/jpmiller/simple-distribution) get the 1436 LB. If we use LGBM to do regression prediction and shift the distribution based on the yards we predicte, we should get a better LB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold,TimeSeriesSplit,KFold,GroupKFold\n",
    "from sklearn.metrics import roc_auc_score,mean_squared_error,mean_absolute_error\n",
    "from datetime import datetime\n",
    "import gc\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from bayes_opt import BayesianOptimization\n",
    "from kaggle.competitions import nflrush\n",
    "import math\n",
    "import tqdm\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.special import expit\n",
    "from scipy.spatial import Delaunay, delaunay_plot_2d, Voronoi, voronoi_plot_2d, ConvexHull\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option(\"display.max_columns\",1000)\n",
    "env = nflrush.make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/nfl-big-data-bowl-2020/train.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess and feature enginnering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train.VisitorTeamAbbr == \"ARI\",'VisitorTeamAbbr'] = \"ARZ\"\n",
    "train.loc[train.HomeTeamAbbr == \"ARI\",'HomeTeamAbbr'] = \"ARZ\"\n",
    "\n",
    "train.loc[train.VisitorTeamAbbr == \"BAL\",'VisitorTeamAbbr'] = \"BLT\"\n",
    "train.loc[train.HomeTeamAbbr == \"BAL\",'HomeTeamAbbr'] = \"BLT\"\n",
    "\n",
    "train.loc[train.VisitorTeamAbbr == \"CLE\",'VisitorTeamAbbr'] = \"CLV\"\n",
    "train.loc[train.HomeTeamAbbr == \"CLE\",'HomeTeamAbbr'] = \"CLV\"\n",
    "\n",
    "train.loc[train.VisitorTeamAbbr == \"HOU\",'VisitorTeamAbbr'] = \"HST\"\n",
    "train.loc[train.HomeTeamAbbr == \"HOU\",'HomeTeamAbbr'] = \"HST\"\n",
    "\n",
    "train['is_run'] = train.NflId == train.NflIdRusher\n",
    "\n",
    "tmp_handoff = train['TimeHandoff'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "tmp_snap = train['TimeSnap'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "train['handoff_snap_diff'] = (tmp_handoff - tmp_snap).map(lambda x:x.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my original idea for feature engineering---------------------------------------------------\n",
    "def str_to_float(txt):\n",
    "    try:\n",
    "        return float(txt)\n",
    "    except:\n",
    "        return -1\n",
    "    \n",
    "def yardline_func(row):\n",
    "    if row[\"X\"] >= 60:\n",
    "        return 60 + (50 - row[\"YardLine\"])\n",
    "    else:\n",
    "        return 10 + row[\"YardLine\"]\n",
    "    \n",
    "## standardization ------    \n",
    "#train['ToLeft'] = train.PlayDirection == \"left\"\n",
    "#train[\"Dir_std\"] = (360 - train.Dir.copy() + 90).mod(360)\n",
    "#train[\"Orientation_std\"] = train[\"Orientation\"].copy()\n",
    "#train.loc[train.Season == 2017, \"Orientation_std\"] = (360 - train['Orientation_std'][train['Season'] == 2017]).mod(360)\n",
    "#train.loc[train.Season == 2018, \"Orientation_std\"] = (360 - train['Orientation_std'][train['Season'] == 2018] + 90).mod(360)\n",
    "# represent Yardline in terms of coordinate X\n",
    "#tmp_df = train.groupby(\"PlayId\").agg(\"median\")[[\"X\", \"YardLine\"]].reset_index(drop=True)\n",
    "#tmp_yardline = np.array(tmp_df.apply(yardline_func, axis=1))\n",
    "#train[\"YardLine_std\"] = np.repeat(tmp_yardline, 22)\n",
    "# To unite the offense direction to right, change X, Y, YardLine.\n",
    "#train['X_std'] = train.X.copy()\n",
    "#train.loc[train.ToLeft, 'X_std'] = 120 - train.loc[train.ToLeft, 'X']\n",
    "#train['Y_std'] = train.Y.copy()\n",
    "#train.loc[train.ToLeft, 'Y_std'] = 160/3 - train.loc[train.ToLeft, 'Y']\n",
    "#train.loc[train.ToLeft, \"YardLine_std\"] = 120 - train[\"YardLine_std\"][train['ToLeft'] == True]\n",
    "# Additionally, rechange Orientation_std, Dir_std\n",
    "#train.loc[train.ToLeft, \"Orientation_std\"] = train[\"Orientation_std\"][train['ToLeft'] == True].apply(lambda x: x-180 if x>180 and x<=360 else 180+x)\n",
    "#train.loc[train.ToLeft, \"Dir_std\"] = train[\"Dir_std\"][train['ToLeft'] == True].apply(lambda x: x-180 if x>180 and x<=360 else 180+x)\n",
    "# standardization ---------\n",
    "\n",
    "# age #\n",
    "FMT_birth = '%m/%d/%Y'\n",
    "FMT_gamedate = '%Y-%m-%d'\n",
    "train[\"Age\"] = train[\"TimeSnap\"].apply(lambda t: t.split(\"T\")[0])\n",
    "train[\"Age\"] = train[\"Age\"].apply(lambda t: datetime.strptime(t, FMT_gamedate))\n",
    "tmp_birth = train[\"PlayerBirthDate\"].apply(lambda t: datetime.strptime(t, FMT_birth))\n",
    "train[\"Age\"] = train[\"Age\"] - tmp_birth\n",
    "train[\"Age\"] = train[\"Age\"].apply(lambda t: t.days//365)\n",
    "\n",
    "# momentum \n",
    "train[\"Momentum\"] = train[\"S\"] * train[\"PlayerWeight\"]\n",
    "\n",
    "# on offense\n",
    "def func(row):\n",
    "    if row[\"PossessionTeam\"] == row[\"HomeTeamAbbr\"]:\n",
    "        return \"home\"\n",
    "    else:\n",
    "        return \"away\"\n",
    "train[\"OnOffense\"] = train[[\"PossessionTeam\", \"HomeTeamAbbr\"]].apply(func, axis=1)\n",
    "train[\"OnOffense\"] = train[\"OnOffense\"] == train[\"Team\"]\n",
    "\n",
    "#train[\"Margin\"] = (train[\"HomeScoreBeforePlay\"] - \n",
    "#                train[\"VisitorScoreBeforePlay\"]) + 2 * (1 - (train[\"PossessionTeam\"] == \n",
    "#                                                                      train[\"HomeTeamAbbr\"]).astype(int)) * (train[\"VisitorScoreBeforePlay\"] \n",
    "#                                                                                                                - train[\"HomeScoreBeforePlay\"])\n",
    "\n",
    "rusher_x = np.array(train.groupby([\"PlayId\", \"is_run\"])[\"X\"].agg(np.mean)[1::2])\n",
    "rusher_x = np.repeat(rusher_x, 22) # repeat each elemnt 22 times train[\"RusherX\"]\n",
    "rusher_y = np.array(train.groupby([\"PlayId\", \"is_run\"])[\"Y\"].agg(np.mean)[1::2])\n",
    "rusher_y = np.repeat(rusher_y, 22) # train[\"RusherY\"]\n",
    "train[\"DisToRusher\"] = np.sqrt((train[\"X\"] - rusher_x) ** 2 + (train[\"Y\"] - rusher_y) ** 2)\n",
    "train[\"TackleTimeToRusher\"] = train[\"DisToRusher\"] / train[\"S\"] \n",
    "\n",
    "rusher_s = np.array(train.groupby([\"PlayId\", \"is_run\"]).agg(np.mean)[\"S\"][1::2])\n",
    "rusher_s = np.repeat(rusher_s, 22)\n",
    "train[\"RatioSToRusher\"] = train[\"S\"] / rusher_s\n",
    "\n",
    "# distance without no restriction if the difference between distance is large, the player is restricted by defenders\n",
    "#train[\"MoveDist\"] = train[\"S\"] * train[\"handoff_snap_diff\"] + 0.5 * train[\"A\"] * (train[\"handoff_snap_diff\"] **2)\n",
    "\n",
    "# ratio of real movement distance to theoretical movement distance\n",
    "#train[\"RealToTheoryDis\"] = train[\"Dis\"] / train[\"MoveDist\"]\n",
    "\n",
    "#train[\"Ori_Dir_diff\"] = train[\"Dir_std\"] - train[\"Orientation_std\"]\n",
    "# my original idea end ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_single = train[train.is_run==True].copy()\n",
    "def transform_time_quarter(str1):\n",
    "    return int(str1[:2])*60 + int(str1[3:5])\n",
    "def transform_time_all(str1,quarter):\n",
    "    if quarter<=4:\n",
    "        return 15*60 - (int(str1[:2])*60 + int(str1[3:5])) + (quarter-1)*15*60\n",
    "    if quarter ==5:\n",
    "        return 10*60 - (int(str1[:2])*60 + int(str1[3:5])) + (quarter-1)*15*60\n",
    "train_single['time_quarter'] = train_single.GameClock.map(lambda x:transform_time_quarter(x))\n",
    "train_single['time_end'] = train_single.apply(lambda x:transform_time_all(x.loc['GameClock'],x.loc['Quarter']),axis=1)\n",
    "# my original idea -----------------------\n",
    "#def strtoseconds(txt):\n",
    "#    txt = txt.split(':')\n",
    "#    ans = int(txt[0])*60 + int(txt[1]) + int(txt[2])/60\n",
    "#    return ans\n",
    "#train_single['TimeLeft'] = train_single['GameClock'].apply(strtoseconds)\n",
    "\n",
    "#train_single['WindSpeed'] = train_single['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n",
    "#train_single['WindSpeed'] = train_single['WindSpeed'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n",
    "#train_single['WindSpeed'] = train_single['WindSpeed'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n",
    "#train_single['WindSpeed'] = train_single['WindSpeed'].apply(str_to_float)\n",
    "\n",
    "#train_single['WindDirection'] = train_single['WindDirection'].apply(lambda x: \"north\" if x == \"N\" or x == \"FROM S\"\n",
    "#                                                   else (\"south\" if x == 'S' or x== 'FROM N'\n",
    "#                                                   else (\"west\" if x == 'W' or x == 'FROM E'\n",
    "#                                                   else (\"east\" if x == 'E' or x == 'FROM W'\n",
    "#                                                   else (\"north east\" if x == 'FROM SW' or x == 'FROM SSW' or x == 'FROM WSW'\n",
    "#                                                   else (\"north west\" if x == 'FROM SE' or x == 'FROM SSE' or x == 'FROM ESE'\n",
    "#                                                   else (\"south east\" if x == 'FROM NW' or x == 'FROM NNW' or x == 'FROM WNW'\n",
    "#                                                   else (\"south west\" if x == 'FROM NE' or x == 'FROM NNE' or x == 'FROM ENE'\n",
    "#                                                   else (\"north west\" if x == 'NW' or x == 'NORTHWEST'\n",
    "#                                                   else (\"north east\" if x == 'NE' or x == 'NORTH EAST'\n",
    "#                                                   else (\"south west\" if x == 'SW' or x == 'SOUTHWEST'\n",
    "#                                                   else (\"south east\" if x == 'SE' or x == 'SOUTHEAST' else \"unknown\"))))))))))))\n",
    "\n",
    "#rain = ['Rainy', 'Rain Chance 40%', 'Showers', 'Cloudy with periods of rain, thunder possible. Winds shifting to WNW, 10-20 mph.',\n",
    "#          'Scattered Showers', 'Cloudy, Rain', 'Rain shower', 'Light Rain', 'Rain']\n",
    "#overcast = ['Cloudy, light snow accumulating 1-3\"', 'Party Cloudy', 'Cloudy, chance of rain','Coudy', 'Cloudy, 50% change of rain', \n",
    "#            'Rain likely, temps in low 40s.', 'Cloudy and cold', 'Cloudy, fog started developing in 2nd quarter', 'Partly Clouidy', \n",
    "#            '30% Chance of Rain', 'Mostly Coudy', 'Cloudy and Cool', 'cloudy', 'Partly cloudy', 'Overcast', 'Hazy', 'Mostly cloudy', \n",
    "#            'Mostly Cloudy', 'Partly Cloudy', 'Cloudy']\n",
    "#clear = ['Partly clear', 'Sunny and clear', 'Sun & clouds', 'Clear and Sunny', 'Sunny and cold', 'Sunny Skies', 'Clear and Cool', 'Clear and sunny',\n",
    "#        'Sunny, highs to upper 80s', 'Mostly Sunny Skies', 'Cold', 'Clear and warm', 'Sunny and warm', 'Clear and cold', 'Mostly sunny',\n",
    "#        'T: 51; H: 55; W: NW 10 mph', 'Clear Skies', 'Clear skies', 'Partly sunny', 'Fair', 'Partly Sunny', 'Mostly Sunny', 'Clear', 'Sunny']\n",
    "#snow = ['Heavy lake effect snow', 'Snow']\n",
    "#none = ['N/A Indoor', 'Indoors', 'Indoor', 'N/A (Indoors)', 'Controlled Climate']\n",
    "\n",
    "#train_single['GameWeather'] = train_single['GameWeather'].apply(lambda x: \"rain\" if x in rain \n",
    "#                                                        else (\"overcast\" if x in overcast\n",
    "#                                                        else (\"clear\" if x in clear\n",
    "#                                                        else (\"snow\" if x in snow\n",
    "#                                                        else (\"indoor\" if x in none else \"unknown\")))))\n",
    "\n",
    "#train_single['GameWeather'] = np.where(train_single.Turf.str.lower().isin(rain), \"Rain\", \"NotRain\")\n",
    "\n",
    "#outdoor =['Outdoor', 'Outdoors', 'Cloudy', 'Heinz Field', 'Outdor', 'Ourdoor', \n",
    "#          'Outside', 'Outddors', 'Outdoor Retr Roof-Open', 'Oudoor', 'Bowl']\n",
    "#indoor_closed = ['Indoors', 'Indoor', 'Indoor, Roof Closed', 'Indoor, Roof Closed', \n",
    "#                 'Retractable Roof', 'Retr. Roof-Closed', 'Retr. Roof - Closed', 'Retr. Roof Closed']\n",
    "#indoor_open = ['Indoor, Open Roof', 'Open', 'Retr. Roof-Open', 'Retr. Roof - Open']\n",
    "#dome_closed = ['Dome', 'Domed, closed', 'Closed Dome', 'Domed', 'Dome, closed']\n",
    "#dome_open = ['Domed, Open', 'Domed, open']\n",
    "\n",
    "#train_single['StadiumType'] = train_single['StadiumType'].apply(lambda x: \"outdoor\" if x in outdoor \n",
    "#                                                    else (\"indoor closed\" if x in indoor_closed\n",
    "#                                                    else (\"indoor open\" if x in indoor_open\n",
    "#                                                    else (\"dome_closed\" if x in dome_closed\n",
    "#                                                    else (\"dome_open\" if x in dome_open else \"unknown\")))))\n",
    "\n",
    "train_single[\"Location\"] = train_single[\"Location\"].map(lambda x: \"Arlington, TX\" if x == \"Arlington, Texas\"\n",
    "                        else (\"Baltimore, MD\" if x == \"Baltimore, Maryland\" or x == \"Baltimore, Md.\"\n",
    "                        else (\"Charlotte, NC\" if x == \"Charlotte, North Carolina\"\n",
    "                        else (\"Chicago, IL\" if x == \"Chicago. IL\"\n",
    "                        else (\"Cincinnati, OH\" if x == \"Cincinnati, Ohio\"\n",
    "                        else (\"Cleveland, OH\" if x == \"Cleveland\" or x == \"Cleveland Ohio\" or x == \"Cleveland, Ohio\" or x == \"Cleveland,Ohio\"\n",
    "                        else (\"Detroit, MI\" if x == \"Detroit\"\n",
    "                        else (\"East Rutherford, NJ\" if x == \"E. Rutherford, NJ\" or x == \"East Rutherford, N.J.\"\n",
    "                        else (\"Foxborough, MA\" if x == \"Foxborough, Ma\"\n",
    "                        else (\"Houston, TX\" if x == \"Houston, Texas\"\n",
    "                        else (\"Jacksonville, FL\" if x == \"Jacksonville Florida\" or x == \"Jacksonville, Fl\" or x == \"Jacksonville, Florida\"\n",
    "                        else (\"London\" if x == \"London, England\"\n",
    "                        else (\"Los Angeles, CA\" if x == \"Los Angeles, Calif.\"\n",
    "                        else (\"Miami Gardens, FLA\" if x == \"Miami Gardens, Fla.\"\n",
    "                        else (\"New Orleans, LA\" if x == \"New Orleans\" or x == \"New Orleans, La.\"\n",
    "                        else (\"Orchard Park, NY\" if x == \"Orchard Park NY\"\n",
    "                        else (\"Philadelphia, PA\" if x == \"Philadelphia, Pa.\"\n",
    "                        else (\"Pittsburgh, PA\" if x == \"Pittsburgh\"\n",
    "                        else (\"Seattle, WA\" if x == \"Seattle\" else x)))))))))))))))))))\n",
    "\n",
    "train_single[\"Stadium\"] = train_single[\"Stadium\"].map(lambda x: \"Broncos Stadium at Mile High\" if x==\"Broncos Stadium At Mile High\" \n",
    "                                             else (\"CenturyLink Field\" if x == \"CenturyField\" or x == x==\"CenturyLink\"\n",
    "                                             else (\"Everbank Field\" if x == \"EverBank Field\"\n",
    "                                             else (\"FirstEnergy Stadium\" if x ==\"First Energy Stadium\" or x==\"FirstEnergy\" or x == \"FirstEnergyStadium\"\n",
    "                                             else (\"Lambeau Field\" if x == \"Lambeau field\"\n",
    "                                             else (\"Los Angeles Memorial Coliseum\" if x == \"Los Angeles Memorial Coliesum\"\n",
    "                                             else (\"M&T Bank Stadium\" if x == \"M & T Bank Stadium\" or x == \"M&T Stadium\"\n",
    "                                             else (\"Mercedes-Benz Superdome\" if x == \"Mercedes-Benz Dome\"\n",
    "                                             else (\"MetLife Stadium\" if x == \"MetLife\" or x == \"Metlife Stadium\"\n",
    "                                             else (\"NRG Stadium\" if x == \"NRG\"\n",
    "                                             else (\"Oakland-Alameda County Coliseum\" if x == \"Oakland Alameda-County Coliseum\"\n",
    "                                             else (\"Paul Brown Stadium\" if x == \"Paul Brown Stdium\"\n",
    "                                             else (\"Twickenham Stadium\" if x == \"Twickenham\" else x)))))))))))))\n",
    "\n",
    "train_single[\"OffenseFormation\"] = train_single[\"OffenseFormation\"].fillna(\"Unknown\") \n",
    "train_single['DefendersInTheBox_vs_Distance'] = train_single['DefendersInTheBox'] / train_single['Distance']\n",
    "\n",
    "#grass_labels = ['grass', 'natural grass', 'natural', 'naturall grass']\n",
    "#train_single['Turf'] = np.where(train_single.Turf.str.lower().isin(grass_labels), \"Natural\", \"Artificial\")\n",
    "\n",
    "#arr = [[int(s[0]) for s in t.split(\", \")] for t in train_single[\"DefensePersonnel\"]]\n",
    "#train_single[\"DefenseDL\"] = np.array([a[0] for a in arr])\n",
    "#train_single[\"DefenseLB\"] = np.array([a[1] for a in arr])\n",
    "#train_single[\"DefenseDB\"] = np.array([a[2] for a in arr])\n",
    "#train_single[\"DefenseOL\"] = np.array([a[3] if len(a) == 4 else 0 for a in arr])\n",
    "\n",
    "#train_single[\"OffenseRB\"] = train_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "#                        int(x.replace(\",\", \"\").split(\" RB\")[0][-1]) if \"RB\" in x else 0)\n",
    "#train_single[\"OffenseTE\"] = train_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "#                        int(x.replace(\",\", \"\").split(\" TE\")[0][-1]) if \"TE\" in x else 0)\n",
    "#train_single[\"OffenseWR\"] = train_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "#                        int(x.replace(\",\", \"\").split(\" WR\")[0][-1]) if \"WR\" in x else 0)\n",
    "#train_single[\"OffenseOL\"] = train_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "#                        int(x.replace(\",\", \"\").split(\" OL\")[0][-1]) if \"OL\" in x else 0)\n",
    "#train_single[\"OffenseDL\"] = train_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "#                        int(x.replace(\",\", \"\").split(\" DL\")[0][-1]) if \"DL\" in x else 0)\n",
    "#train_single[\"OffenseQB\"] = train_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "#                        int(x.replace(\",\", \"\").split(\" QB\")[0][-1]) if \"QB\" in x else 0)\n",
    "\n",
    "# train_single[\"DownQuarter\"] = train_single[[\"Down\", \"Quarter\"]].apply(lambda x: \"D{}_Q{}\".format(x[0], x[1]), axis=1)\n",
    "\n",
    "# necessary yard per remaining down \n",
    "train_single[\"NecDisPerDown\"] = train_single[\"Distance\"] / (5 - train_single[\"Down\"])\n",
    "# my original idea end -----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_features = ['GameId','PlayId','DisplayName','GameClock','TimeHandoff','TimeSnap'] \n",
    "                  #,\"PlayDirection\", \"YardLine\", \"Orientation\", \"Dir\", \"X\", \"Y\", \"ToLeft\"]\n",
    "train_single['date_game'] = train_single.GameId.map(lambda x:pd.to_datetime(str(x)[:8]))\n",
    "remove_features.append('HomeTeamAbbr')\n",
    "remove_features.append('VisitorTeamAbbr')\n",
    "remove_features.append('PlayerBirthDate')\n",
    "remove_features.append('is_run')\n",
    "def transform_height(te):\n",
    "    return (int(te.split('-')[0])*12 + int(te.split('-')[1]))*2.54/100\n",
    "train_single['runner_height'] = train_single.PlayerHeight.map(transform_height)\n",
    "remove_features.append('PossessionTeam')\n",
    "remove_features.append('FieldPosition')\n",
    "remove_features.append('PlayerHeight')\n",
    "remove_features.append('NflIdRusher')\n",
    "remove_features.append('date_game')\n",
    "train_single['own_field'] = (train_single['FieldPosition'] == train_single['PossessionTeam']).astype(int)\n",
    "dist_to_end_train = train_single.apply(lambda x:(100 - x.loc['YardLine']) if x.loc['own_field']==1 else x.loc['YardLine'],axis=1)\n",
    "remove_features.append('own_field')\n",
    "train_single.drop(remove_features,axis=1,inplace=True)\n",
    "train_single.fillna(-999,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_single.Yards\n",
    "X_train = train_single.drop(['Yards'],axis=1)\n",
    "for f in X_train.columns:\n",
    "    if X_train[f].dtype=='object': \n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(X_train[f])+[-999])\n",
    "        X_train[f] = lbl.transform(list(X_train[f]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional feature engineering -----------------------------------------------------------\n",
    "def voronoi_volumes(points, selected_index):\n",
    "    v = Voronoi(points)\n",
    "    vol = np.zeros(v.npoints)\n",
    "    \n",
    "    for i, reg_num in enumerate(v.point_region):\n",
    "        indices = v.regions[reg_num]\n",
    "        if -1 in indices: # some regions can be opened\n",
    "            vol[i] = -999 ## insert missing value when the area is open\n",
    "        else:\n",
    "            vol[i] = ConvexHull(v.vertices[indices]).volume\n",
    "        \n",
    "        if reg_num == v.point_region[selected_index]: # in the case of rusher or 1st defender etc...\n",
    "            index = i\n",
    "            rusher_reg_num = reg_num         \n",
    "        \n",
    "    return vol[index]\n",
    "\n",
    "#X_train.rename(columns={'X_std': 'X', \"Y_std\": \"Y\", \"Dir_std\": \"Dir\", \"YardLine_std\": \"YardLine\", \n",
    "#                        \"Orientation_std\": \"Orientation\"}, inplace=True)\n",
    "\n",
    "tmp = train.groupby([\"PlayId\", \"OnOffense\"]).agg(np.mean)[[\"S\", \"X\", \"Y\", \"Age\"]]\n",
    "X_train[\"DefenseAveSpeed\"] = np.array(tmp[0::2][\"S\"])\n",
    "X_train[\"OffenseAveSpeed\"] = np.array(tmp[1::2][\"S\"])\n",
    "\n",
    "X_train[\"DefenseAveX\"] = np.array(tmp[0::2][\"X\"])\n",
    "X_train[\"OffenseAveX\"] = np.array(tmp[1::2][\"X\"])\n",
    "\n",
    "X_train[\"DefenseAveY\"] = np.array(tmp[0::2][\"Y\"]) \n",
    "X_train[\"OffenseAveY\"] = np.array(tmp[1::2][\"Y\"]) \n",
    "\n",
    "X_train[\"DefenseAveAge\"] = np.array(tmp[0::2][\"Age\"])\n",
    "X_train[\"OffenseAveAge\"] = np.array(tmp[1::2][\"Age\"])\n",
    "\n",
    "tmp = train.groupby([\"PlayId\", \"OnOffense\"]).agg([\"std\"])[[\"X\", \"Y\"]]\n",
    "X_train[\"DefenseStdX\"] = np.array(tmp[0::2][\"X\"])\n",
    "X_train[\"OffenseStdX\"] = np.array(tmp[1::2][\"X\"])\n",
    "\n",
    "X_train[\"DefenseStdY\"] = np.array(tmp[0::2][\"Y\"])\n",
    "X_train[\"OffenseStdY\"] = np.array(tmp[1::2][\"Y\"])\n",
    "\n",
    "X_train[\"RunnerToDefenseCentoid\"] = np.sqrt((X_train[\"X\"] - X_train[\"DefenseAveX\"]) ** 2 + (X_train[\"Y\"] - X_train[\"DefenseAveY\"]) ** 2)\n",
    "X_train[\"RunnerToOffenseCentoid\"] = np.sqrt((X_train[\"X\"] - X_train[\"OffenseAveX\"]) ** 2 + (X_train[\"Y\"] - X_train[\"OffenseAveY\"]) ** 2)\n",
    "\n",
    "# defense x spread, offense x spread\n",
    "tmp_max = train.groupby([\"PlayId\", \"OnOffense\"])[\"X\"].max()\n",
    "tmp_min = train.groupby([\"PlayId\", \"OnOffense\"])[\"X\"].min()\n",
    "X_train[\"DefenseSpreadX\"] = np.array(tmp_max[0::2]- tmp_min[0::2])\n",
    "X_train[\"OffenseSpreadX\"] = np.array(tmp_max[1::2]- tmp_min[1::2])\n",
    "\n",
    "X_train[\"RunnerToScrimmage\"] = X_train[\"X\"] - X_train[\"YardLine\"]\n",
    "\n",
    "# runner horizontal and vertical speed\n",
    "#radian_angle = (90 - X_train['Dir']) * np.pi / 180.0\n",
    "radian_angle = X_train['Dir'] * np.pi / 180.0\n",
    "X_train['v_horizontal'] = np.abs(X_train['S'] * np.cos(radian_angle))\n",
    "X_train['v_vertical'] = np.abs(X_train['S'] * np.sin(radian_angle))\n",
    "\n",
    "# runner horizontal and vertical momentum\n",
    "X_train['m_horizontal'] = np.abs(X_train['Momentum'] * np.cos(radian_angle))\n",
    "X_train['m_vertical'] = np.abs(X_train['Momentum'] * np.sin(radian_angle))\n",
    "\n",
    "# minimum distance to rusher from defenders\n",
    "X_train[\"MinDisFromRushToDef\"] = np.array(train.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].min()[0::2])\n",
    "\n",
    "# tackle time from closest defender to rusher\n",
    "X_train[\"MinTackleTime\"] = np.array(train.groupby([\"PlayId\", \"OnOffense\"])[\"TackleTimeToRusher\"].min()[0::2])\n",
    "\n",
    "# average tackle time from all defenders to rusher\n",
    "X_train[\"AveTackleTime\"] = np.array(train.groupby([\"PlayId\", \"OnOffense\"]).agg(np.mean)[\"TackleTimeToRusher\"][0::2])\n",
    "\n",
    "# runner vs 1st defender speed: runner's velocity divided by closest defender's speed\n",
    "X_train[\"RatioSRusherToCloseDef\"] = np.array(train.loc[train.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].idxmin()[0::2]][\"RatioSToRusher\"])\n",
    "\n",
    "# runner horizontal and vertical distance\n",
    "X_train[\"dis_horizontal\"] = np.abs(X_train['Dis'] * np.cos(radian_angle))\n",
    "X_train[\"dis_vertical\"] = np.abs(X_train['Dis'] * np.sin(radian_angle))\n",
    "X_train[\"RunnerMoveRatio\"] = X_train[\"dis_horizontal\"] / X_train[\"dis_vertical\"]\n",
    "\n",
    "# the momentum of 1st closest defender to rusher, horizontal momentum, vertical momentum\n",
    "X_train[\"DefMomentumCloToRusher\"] = np.array(train.loc[train.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].idxmin()[0::2]][\"Momentum\"])\n",
    "X_train[\"DefMomentumCloToRusher_horizontal\"] = np.abs(X_train['DefMomentumCloToRusher'] * np.cos(radian_angle))\n",
    "X_train[\"DefMomentumCloToRusher_vertical\"] = np.abs(X_train['DefMomentumCloToRusher'] * np.sin(radian_angle))\n",
    "\n",
    "# the horizontal, vertical mometum of rusher\n",
    "X_train[\"RusherMomentum_horizontal\"] =  np.abs(X_train['Momentum'] * np.cos(radian_angle))\n",
    "X_train[\"RusherMomentum_vertical\"] =  np.abs(X_train['Momentum'] * np.sin(radian_angle))\n",
    "\n",
    "# difference of horizontal momentum \n",
    "X_train[\"hMomentum_rusher_vs_defender\"] = X_train[\"RusherMomentum_horizontal\"] - X_train[\"DefMomentumCloToRusher_horizontal\"]\n",
    "\n",
    "# voronoi area\n",
    "#pts = np.array(train[[\"X\", \"Y\"]]).reshape(train.shape[0]//22, 22, 2) # plays * players * (X, Y, rusher)\n",
    "# index of row where rusher data is included when separated by each play\n",
    "#rusher_index = list(train[train.is_run==True].index % 22) \n",
    "#closest_def_index = list(train.loc[train.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].idxmin()[0::2]].index % 22)\n",
    "#rusher_voronoi = []\n",
    "#closest_def_voronoi = []\n",
    "#for i in range(0, train.shape[0] //22):\n",
    "    ##rusher_voronoi.append(voronoi_volumes(pts[i], rusher_index[i]))\n",
    "    #closest_def_voronoi.append(voronoi_volumes(pts[i], closest_def_index[i]))\n",
    "##X_train[\"RusherVoronoi\"] = rusher_voronoi    \n",
    "#X_train[\"FirstDefenderVoronoi\"] = closest_def_voronoi \n",
    "\n",
    "#tmp_df = train[[\"PlayId\", \"OnOffense\", \"DisToRusher\"]].copy()\n",
    "#tmp_df[\"3yards\"] = train[\"DisToRusher\"].apply(lambda x: 1 if x<=3 else 0)\n",
    "#tmp_df[\"5yards\"] = train[\"DisToRusher\"].apply(lambda x: 1 if x<=5 else 0)\n",
    "#tmp_df[\"7yards\"] = train[\"DisToRusher\"].apply(lambda x: 1 if x<=7 else 0)\n",
    "#tmp_df[\"10yards\"] = train[\"DisToRusher\"].apply(lambda x: 1 if x<=10 else 0)\n",
    "#tmp_yard_defense = tmp_df.groupby([\"PlayId\", \"OnOffense\"]).agg(np.sum)[[\"3yards\", \"5yards\", \"7yards\", \"10yards\"]][0::2]\n",
    "#tmp_yard_offense = tmp_df.groupby([\"PlayId\", \"OnOffense\"]).agg(np.sum)[[\"3yards\", \"5yards\", \"7yards\", \"10yards\"]][1::2]\n",
    "#X_train[\"Offense3yards\"] = np.array(tmp_yard_offense[\"3yards\"]-1)\n",
    "#X_train[\"Offense5yards\"] = np.array(tmp_yard_offense[\"5yards\"]-1)\n",
    "#X_train[\"Offense7yards\"] = np.array(tmp_yard_offense[\"7yards\"]-1)\n",
    "#X_train[\"Offense10yards\"] = np.array(tmp_yard_offense[\"10yards\"]-1)\n",
    "#X_train[\"Defense3yards\"] = np.array(tmp_yard_defense[\"3yards\"])\n",
    "#X_train[\"Defense5yards\"] = np.array(tmp_yard_defense[\"5yards\"])\n",
    "#X_train[\"Defense7yards\"] = np.array(tmp_yard_defense[\"7yards\"])\n",
    "#X_train[\"Defense10yards\"] = np.array(tmp_yard_defense[\"10yards\"])\n",
    "\n",
    "#X_train = X_train.drop(['RatioSToRusher', 'TackleTimeToRusher', 'OnOffense', 'RusherMomentum_horizontal', 'RusherMomentum_vertical', 'DisToRusher'],axis=1)\n",
    "# additional feature engineering end ---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cdf_df(yards_array):\n",
    "    pdf, edges = np.histogram(yards_array, bins=199,\n",
    "                 range=(-99,100), density=True)\n",
    "    cdf = pdf.cumsum().clip(0, 1)\n",
    "    cdf_df = pd.DataFrame(data=cdf.reshape(-1, 1).T, \n",
    "                            columns=['Yards'+str(i) for i in range(-99,100)])\n",
    "    return cdf_df\n",
    "cdf = get_cdf_df(y_train).values.reshape(-1,)\n",
    "\n",
    "def get_score(y_pred,cdf,w,dist_to_end):\n",
    "    y_pred = int(y_pred)\n",
    "    if y_pred ==w:\n",
    "        y_pred_array = cdf.copy()\n",
    "    elif y_pred - w >0:\n",
    "        y_pred_array = np.zeros(199)\n",
    "        y_pred_array[(y_pred-w):] = cdf[:(-(y_pred-w))].copy()\n",
    "    elif w - y_pred >0:\n",
    "        y_pred_array = np.ones(199)\n",
    "        y_pred_array[:(y_pred-w)] = cdf[(w-y_pred):].copy()\n",
    "    y_pred_array[-1]=1\n",
    "    y_pred_array[(dist_to_end+99):]=1\n",
    "    return y_pred_array    \n",
    "\n",
    "def get_score_pingyi1(y_pred,y_true,cdf,w,dist_to_end):\n",
    "    y_pred = int(y_pred)\n",
    "    if y_pred ==w:\n",
    "        y_pred_array = cdf.copy()\n",
    "    elif y_pred - w >0:\n",
    "        y_pred_array = np.zeros(199)\n",
    "        y_pred_array[(y_pred-w):] = cdf[:(-(y_pred-w))].copy()\n",
    "    elif w - y_pred >0:\n",
    "        y_pred_array = np.ones(199)\n",
    "        y_pred_array[:(y_pred-w)] = cdf[(w-y_pred):].copy()\n",
    "    y_pred_array[-1]=1\n",
    "    y_pred_array[(dist_to_end+99):]=1\n",
    "    y_true_array = np.zeros(199)\n",
    "    y_true_array[(y_true+99):]=1\n",
    "    return np.mean((y_pred_array - y_true_array)**2)\n",
    "\n",
    "def CRPS_pingyi1(y_preds,y_trues,w,cdf,dist_to_ends):\n",
    "    if len(y_preds) != len(y_trues):\n",
    "        print('length does not match')\n",
    "        return None\n",
    "    n = len(y_preds)\n",
    "    tmp = []\n",
    "    for a,b,c in zip(y_preds, y_trues,dist_to_ends):\n",
    "        tmp.append(get_score_pingyi1(a,b,cdf,w,c))\n",
    "    return np.mean(tmp)\n",
    "\n",
    "# evaluation metric\n",
    "def crps(y_true, y_pred):\n",
    "    y_true = np.clip(np.cumsum(y_true, axis=1), 0, 1)\n",
    "    y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n",
    "    return ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * y_true.shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's l1: 3.7498\tvalid_1's l1: 3.76645\n",
      "[100]\ttraining's l1: 3.66645\tvalid_1's l1: 3.69629\n",
      "[150]\ttraining's l1: 3.60273\tvalid_1's l1: 3.64486\n",
      "[200]\ttraining's l1: 3.55478\tvalid_1's l1: 3.61126\n",
      "[250]\ttraining's l1: 3.51529\tvalid_1's l1: 3.58805\n",
      "[300]\ttraining's l1: 3.48096\tvalid_1's l1: 3.56952\n",
      "[350]\ttraining's l1: 3.45311\tvalid_1's l1: 3.55718\n",
      "[400]\ttraining's l1: 3.42821\tvalid_1's l1: 3.54909\n",
      "[450]\ttraining's l1: 3.40609\tvalid_1's l1: 3.54523\n",
      "[500]\ttraining's l1: 3.38454\tvalid_1's l1: 3.54169\n",
      "[550]\ttraining's l1: 3.3644\tvalid_1's l1: 3.5387\n",
      "[600]\ttraining's l1: 3.34424\tvalid_1's l1: 3.5354\n",
      "[650]\ttraining's l1: 3.32434\tvalid_1's l1: 3.53223\n",
      "[700]\ttraining's l1: 3.307\tvalid_1's l1: 3.53007\n",
      "[750]\ttraining's l1: 3.2901\tvalid_1's l1: 3.52851\n",
      "[800]\ttraining's l1: 3.27401\tvalid_1's l1: 3.52731\n",
      "[850]\ttraining's l1: 3.25855\tvalid_1's l1: 3.52773\n",
      "[900]\ttraining's l1: 3.2436\tvalid_1's l1: 3.52833\n",
      "[950]\ttraining's l1: 3.22942\tvalid_1's l1: 3.52886\n",
      "[1000]\ttraining's l1: 3.21553\tvalid_1's l1: 3.52902\n",
      "Early stopping, best iteration is:\n",
      "[802]\ttraining's l1: 3.27337\tvalid_1's l1: 3.52717\n",
      "0.013197165483490224\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's l1: 3.75671\tvalid_1's l1: 3.746\n",
      "[100]\ttraining's l1: 3.67098\tvalid_1's l1: 3.6729\n",
      "[150]\ttraining's l1: 3.60681\tvalid_1's l1: 3.62509\n",
      "[200]\ttraining's l1: 3.55747\tvalid_1's l1: 3.59048\n",
      "[250]\ttraining's l1: 3.51861\tvalid_1's l1: 3.56622\n",
      "[300]\ttraining's l1: 3.48634\tvalid_1's l1: 3.55172\n",
      "[350]\ttraining's l1: 3.45751\tvalid_1's l1: 3.5375\n",
      "[400]\ttraining's l1: 3.43097\tvalid_1's l1: 3.52967\n",
      "[450]\ttraining's l1: 3.40725\tvalid_1's l1: 3.5237\n",
      "[500]\ttraining's l1: 3.385\tvalid_1's l1: 3.51981\n",
      "[550]\ttraining's l1: 3.3642\tvalid_1's l1: 3.51719\n",
      "[600]\ttraining's l1: 3.34409\tvalid_1's l1: 3.51522\n",
      "[650]\ttraining's l1: 3.32523\tvalid_1's l1: 3.51228\n",
      "[700]\ttraining's l1: 3.30827\tvalid_1's l1: 3.51053\n",
      "[750]\ttraining's l1: 3.2913\tvalid_1's l1: 3.50795\n",
      "[800]\ttraining's l1: 3.27432\tvalid_1's l1: 3.50655\n",
      "[850]\ttraining's l1: 3.2578\tvalid_1's l1: 3.5062\n",
      "[900]\ttraining's l1: 3.24311\tvalid_1's l1: 3.50662\n",
      "[950]\ttraining's l1: 3.22854\tvalid_1's l1: 3.5076\n",
      "[1000]\ttraining's l1: 3.21357\tvalid_1's l1: 3.50773\n",
      "[1050]\ttraining's l1: 3.19932\tvalid_1's l1: 3.50832\n",
      "Early stopping, best iteration is:\n",
      "[865]\ttraining's l1: 3.25334\tvalid_1's l1: 3.50599\n",
      "0.013202550905277182\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's l1: 3.76844\tvalid_1's l1: 3.74086\n",
      "[100]\ttraining's l1: 3.68277\tvalid_1's l1: 3.67813\n",
      "[150]\ttraining's l1: 3.6184\tvalid_1's l1: 3.63527\n",
      "[200]\ttraining's l1: 3.56722\tvalid_1's l1: 3.60424\n",
      "[250]\ttraining's l1: 3.52701\tvalid_1's l1: 3.58693\n",
      "[300]\ttraining's l1: 3.49368\tvalid_1's l1: 3.57383\n",
      "[350]\ttraining's l1: 3.4654\tvalid_1's l1: 3.56512\n",
      "[400]\ttraining's l1: 3.4395\tvalid_1's l1: 3.55955\n",
      "[450]\ttraining's l1: 3.41595\tvalid_1's l1: 3.55629\n",
      "[500]\ttraining's l1: 3.39431\tvalid_1's l1: 3.55439\n",
      "[550]\ttraining's l1: 3.37399\tvalid_1's l1: 3.55418\n",
      "[600]\ttraining's l1: 3.35441\tvalid_1's l1: 3.55323\n",
      "[650]\ttraining's l1: 3.33554\tvalid_1's l1: 3.55079\n",
      "[700]\ttraining's l1: 3.31767\tvalid_1's l1: 3.55023\n",
      "[750]\ttraining's l1: 3.30035\tvalid_1's l1: 3.55129\n",
      "[800]\ttraining's l1: 3.28367\tvalid_1's l1: 3.55243\n",
      "[850]\ttraining's l1: 3.26815\tvalid_1's l1: 3.55379\n",
      "Early stopping, best iteration is:\n",
      "[690]\ttraining's l1: 3.32128\tvalid_1's l1: 3.55013\n",
      "0.01309998258064348\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's l1: 3.75888\tvalid_1's l1: 3.73887\n",
      "[100]\ttraining's l1: 3.6712\tvalid_1's l1: 3.67919\n",
      "[150]\ttraining's l1: 3.60413\tvalid_1's l1: 3.63688\n",
      "[200]\ttraining's l1: 3.55455\tvalid_1's l1: 3.60809\n",
      "[250]\ttraining's l1: 3.51606\tvalid_1's l1: 3.59062\n",
      "[300]\ttraining's l1: 3.48415\tvalid_1's l1: 3.57788\n",
      "[350]\ttraining's l1: 3.45623\tvalid_1's l1: 3.56973\n",
      "[400]\ttraining's l1: 3.43035\tvalid_1's l1: 3.56203\n",
      "[450]\ttraining's l1: 3.40687\tvalid_1's l1: 3.55597\n",
      "[500]\ttraining's l1: 3.38565\tvalid_1's l1: 3.55203\n",
      "[550]\ttraining's l1: 3.36568\tvalid_1's l1: 3.54931\n",
      "[600]\ttraining's l1: 3.34709\tvalid_1's l1: 3.5474\n",
      "[650]\ttraining's l1: 3.32965\tvalid_1's l1: 3.54522\n",
      "[700]\ttraining's l1: 3.31212\tvalid_1's l1: 3.5444\n",
      "[750]\ttraining's l1: 3.29513\tvalid_1's l1: 3.54301\n",
      "[800]\ttraining's l1: 3.2796\tvalid_1's l1: 3.54287\n",
      "[850]\ttraining's l1: 3.26467\tvalid_1's l1: 3.54257\n",
      "[900]\ttraining's l1: 3.24997\tvalid_1's l1: 3.54258\n",
      "[950]\ttraining's l1: 3.23554\tvalid_1's l1: 3.54197\n",
      "[1000]\ttraining's l1: 3.2217\tvalid_1's l1: 3.54238\n",
      "[1050]\ttraining's l1: 3.20783\tvalid_1's l1: 3.54213\n",
      "[1100]\ttraining's l1: 3.19405\tvalid_1's l1: 3.54194\n",
      "[1150]\ttraining's l1: 3.18083\tvalid_1's l1: 3.54155\n",
      "[1200]\ttraining's l1: 3.16834\tvalid_1's l1: 3.542\n",
      "[1250]\ttraining's l1: 3.15594\tvalid_1's l1: 3.54302\n",
      "[1300]\ttraining's l1: 3.14375\tvalid_1's l1: 3.54417\n",
      "[1350]\ttraining's l1: 3.13174\tvalid_1's l1: 3.54443\n",
      "Early stopping, best iteration is:\n",
      "[1160]\ttraining's l1: 3.17838\tvalid_1's l1: 3.54138\n",
      "0.013178473063664022\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's l1: 3.72892\tvalid_1's l1: 3.85362\n",
      "[100]\ttraining's l1: 3.64658\tvalid_1's l1: 3.78772\n",
      "[150]\ttraining's l1: 3.58583\tvalid_1's l1: 3.74102\n",
      "[200]\ttraining's l1: 3.53773\tvalid_1's l1: 3.70628\n",
      "[250]\ttraining's l1: 3.4978\tvalid_1's l1: 3.67995\n",
      "[300]\ttraining's l1: 3.46517\tvalid_1's l1: 3.66322\n",
      "[350]\ttraining's l1: 3.43708\tvalid_1's l1: 3.65085\n",
      "[400]\ttraining's l1: 3.41206\tvalid_1's l1: 3.64436\n",
      "[450]\ttraining's l1: 3.38922\tvalid_1's l1: 3.63996\n",
      "[500]\ttraining's l1: 3.36854\tvalid_1's l1: 3.63577\n",
      "[550]\ttraining's l1: 3.34824\tvalid_1's l1: 3.6331\n",
      "[600]\ttraining's l1: 3.32911\tvalid_1's l1: 3.62879\n",
      "[650]\ttraining's l1: 3.31094\tvalid_1's l1: 3.62707\n",
      "[700]\ttraining's l1: 3.29363\tvalid_1's l1: 3.62603\n",
      "[750]\ttraining's l1: 3.27736\tvalid_1's l1: 3.62392\n",
      "[800]\ttraining's l1: 3.26167\tvalid_1's l1: 3.62231\n",
      "[850]\ttraining's l1: 3.24605\tvalid_1's l1: 3.62334\n",
      "[900]\ttraining's l1: 3.23073\tvalid_1's l1: 3.62141\n",
      "[950]\ttraining's l1: 3.21607\tvalid_1's l1: 3.62089\n",
      "[1000]\ttraining's l1: 3.20156\tvalid_1's l1: 3.62095\n",
      "[1050]\ttraining's l1: 3.18768\tvalid_1's l1: 3.62123\n",
      "[1100]\ttraining's l1: 3.17427\tvalid_1's l1: 3.62168\n",
      "[1150]\ttraining's l1: 3.16119\tvalid_1's l1: 3.62152\n",
      "[1200]\ttraining's l1: 3.1487\tvalid_1's l1: 3.62175\n",
      "Early stopping, best iteration is:\n",
      "[1019]\ttraining's l1: 3.1963\tvalid_1's l1: 3.6206\n",
      "0.013515443268033082\n",
      "mean mse: 37.5779535589669\n",
      "oof mse: 37.578135361053405\n",
      "mean mae: 3.549054603668367\n",
      "oof mae: 3.5490536591474875\n",
      "mean cprs: 0.013238723060221598\n",
      "oof cprs: 0.013238721266704842\n"
     ]
    }
   ],
   "source": [
    "n_folds=5\n",
    "kf=KFold(n_splits = n_folds, shuffle=True, random_state=42)\n",
    "resu1 = 0\n",
    "impor1 = 0\n",
    "resu2_cprs = 0\n",
    "resu3_mae=0\n",
    "##y_pred = 0\n",
    "feature_importance_df = pd.DataFrame(X_train.columns, columns=[\"feature\"])\n",
    "stack_train = np.zeros([X_train.shape[0],])\n",
    "models = []\n",
    "for fold_, (train_index, test_index) in enumerate(kf.split(X_train, y_train)):\n",
    "    X_train2= X_train.iloc[train_index,:]\n",
    "    y_train2= y_train.iloc[train_index]\n",
    "    X_test2= X_train.iloc[test_index,:]\n",
    "    y_test2= y_train.iloc[test_index]\n",
    "    clf = lgb.LGBMRegressor(n_estimators=10000, random_state=47,learning_rate=0.005,importance_type = 'gain',\n",
    "                     n_jobs = -1,metric='mae')\n",
    "    clf.fit(X_train2,y_train2,eval_set = [(X_train2,y_train2),(X_test2,y_test2)],early_stopping_rounds=200,verbose=50)\n",
    "    feature_importance_df[\"Fold\"+str(fold_)] = clf.feature_importances_\n",
    "    models.append(clf)\n",
    "    temp_predict = clf.predict(X_test2)\n",
    "    stack_train[test_index] = temp_predict\n",
    "    ##y_pred += clf.predict(X_test)/n_folds\n",
    "    mse = mean_squared_error(y_test2, temp_predict)\n",
    "    crps = CRPS_pingyi1(temp_predict,y_test2,4,cdf,dist_to_end_train.iloc[test_index])\n",
    "    mae = mean_absolute_error(y_test2, temp_predict)\n",
    "    print(crps)\n",
    "    \n",
    "    resu1 += mse/n_folds\n",
    "    resu2_cprs += crps/n_folds\n",
    "    resu3_mae += mae/n_folds\n",
    "    impor1 += clf.feature_importances_/n_folds\n",
    "    gc.collect()\n",
    "print('mean mse:',resu1)\n",
    "print('oof mse:',mean_squared_error(y_train,stack_train))\n",
    "print('mean mae:',resu3_mae)\n",
    "print('oof mae:',mean_absolute_error(y_train,stack_train))\n",
    "print('mean cprs:',resu2_cprs)\n",
    "print('oof cprs:',CRPS_pingyi1(stack_train,y_train,4,cdf,dist_to_end_train))\n",
    "\n",
    "feature_importance_df[\"Average\"] = np.mean(feature_importance_df.iloc[:,1:], axis=1)\n",
    "#feature_importance_df[\"Std\"] = np.std(feature_importance_df.iloc[:,1:5], axis=1)\n",
    "feature_importance_df = feature_importance_df.sort_values(\"Average\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mean mse: 37.506906623190936\n",
    "- oof mse: 37.50709773495258\n",
    "- mean mae: 3.544533086069717\n",
    "- oof mae: 3.5445321933905447\n",
    "- mean cprs: 0.013242423035214999\n",
    "- oof cprs: 0.013242424127343047"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_test(test):\n",
    "    test.loc[test.VisitorTeamAbbr == \"ARI\",'VisitorTeamAbbr'] = \"ARZ\"\n",
    "    test.loc[test.HomeTeamAbbr == \"ARI\",'HomeTeamAbbr'] = \"ARZ\"\n",
    "\n",
    "    test.loc[test.VisitorTeamAbbr == \"BAL\",'VisitorTeamAbbr'] = \"BLT\"\n",
    "    test.loc[test.HomeTeamAbbr == \"BAL\",'HomeTeamAbbr'] = \"BLT\"\n",
    "\n",
    "    test.loc[test.VisitorTeamAbbr == \"CLE\",'VisitorTeamAbbr'] = \"CLV\"\n",
    "    test.loc[test.HomeTeamAbbr == \"CLE\",'HomeTeamAbbr'] = \"CLV\"\n",
    "\n",
    "    test.loc[test.VisitorTeamAbbr == \"HOU\",'VisitorTeamAbbr'] = \"HST\"\n",
    "    test.loc[test.HomeTeamAbbr == \"HOU\",'HomeTeamAbbr'] = \"HST\"\n",
    "    \n",
    "    test['is_run'] = test.NflId == test.NflIdRusher\n",
    "    \n",
    "    tmp_handoff = test['TimeHandoff'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    tmp_snap = test['TimeSnap'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    test['handoff_snap_diff'] = (tmp_handoff - tmp_snap).map(lambda x:x.seconds)\n",
    "    \n",
    "    # my original idea for feature engineering -------------------------------------------------------------\n",
    "    \n",
    "    ## standardization ------    \n",
    "    #test['ToLeft'] = test.PlayDirection == \"left\"\n",
    "    #test[\"Dir_std\"] = (360 - test.Dir.copy() + 90).mod(360)\n",
    "    #test[\"Orientation_std\"] = test[\"Orientation\"].copy()\n",
    "    #test.loc[test.Season == 2017, \"Orientation_std\"] = (360 - test['Orientation_std'][train['Season'] == 2017]).mod(360)\n",
    "    #test.loc[test.Season == 2018, \"Orientation_std\"] = (360 - test['Orientation_std'][train['Season'] == 2018] + 90).mod(360)\n",
    "    # represent Yardline in terms of coordinate X\n",
    "    #tmp_df = test.groupby(\"PlayId\").agg(\"median\")[[\"X\", \"YardLine\"]].reset_index(drop=True)\n",
    "    #tmp_yardline = np.array(tmp_df.apply(yardline_func, axis=1))\n",
    "    #test[\"YardLine_std\"] = np.repeat(tmp_yardline, 22)\n",
    "    # To unite the offense direction to right, change X, Y, YardLine.\n",
    "    #test['X_std'] = test.X.copy()\n",
    "    #test.loc[test.ToLeft, 'X_std'] = 120 - test.loc[test.ToLeft, 'X']\n",
    "    #test['Y_std'] = test.Y.copy()\n",
    "    #test.loc[test.ToLeft, 'Y_std'] = 160/3 - test.loc[test.ToLeft, 'Y']\n",
    "    #test.loc[test.ToLeft, \"YardLine_std\"] = 120 - test[\"YardLine_std\"][test['ToLeft'] == True]\n",
    "    # Additionally, rechange Orientation_std, Dir_std\n",
    "    #test.loc[test.ToLeft, \"Orientation_std\"] = test[\"Orientation_std\"][test['ToLeft'] == True].apply(lambda x: x-180 if x>180 and x<=360 else 180+x)\n",
    "    #test.loc[test.ToLeft, \"Dir_std\"] = test[\"Dir_std\"][test['ToLeft'] == True].apply(lambda x: x-180 if x>180 and x<=360 else 180+x)\n",
    "    # standardization ---------\n",
    "    \n",
    "    FMT_birth = '%m/%d/%Y'\n",
    "    FMT_gamedate = '%Y-%m-%d'\n",
    "    test[\"Age\"] = test[\"TimeSnap\"].apply(lambda t: t.split(\"T\")[0])\n",
    "    test[\"Age\"] = test[\"Age\"].apply(lambda t: datetime.strptime(t, FMT_gamedate))\n",
    "    tmp_birth = test[\"PlayerBirthDate\"].apply(lambda t: datetime.strptime(t, FMT_birth))\n",
    "    test[\"Age\"] = test[\"Age\"] - tmp_birth\n",
    "    test[\"Age\"] = test[\"Age\"].apply(lambda t: t.days//365)\n",
    "\n",
    "    test[\"Momentum\"] = test[\"S\"] * test[\"PlayerWeight\"]\n",
    "\n",
    "    test[\"OnOffense\"] = test[[\"PossessionTeam\", \"HomeTeamAbbr\"]].apply(func, axis=1)\n",
    "    test[\"OnOffense\"] = test[\"OnOffense\"] == test[\"Team\"]\n",
    "    \n",
    "    #test[\"Margin\"] = (test[\"HomeScoreBeforePlay\"] - \n",
    "    #                  test[\"VisitorScoreBeforePlay\"]) + 2 * (1 - (test[\"PossessionTeam\"] == \n",
    "    #                                                              test[\"HomeTeamAbbr\"]).astype(int)) * (test[\"VisitorScoreBeforePlay\"] \n",
    "    #                                                                                                            - test[\"HomeScoreBeforePlay\"])    \n",
    "    \n",
    "    rusher_x = np.array(test.groupby([\"PlayId\", \"is_run\"])[\"X\"].agg(np.mean)[1::2])\n",
    "    rusher_x = np.repeat(rusher_x, 22) # repeat each elemnt 22 times train[\"RusherX\"]\n",
    "    rusher_y = np.array(test.groupby([\"PlayId\", \"is_run\"])[\"Y\"].agg(np.mean)[1::2])\n",
    "    rusher_y = np.repeat(rusher_y, 22) # train[\"RusherY\"]\n",
    "    test[\"DisToRusher\"] = np.sqrt((test[\"X\"] - rusher_x) ** 2 + (test[\"Y\"] - rusher_y) ** 2)\n",
    "    test[\"TackleTimeToRusher\"] = test[\"DisToRusher\"] / test[\"S\"] \n",
    "\n",
    "    rusher_s = np.array(test.groupby([\"PlayId\", \"is_run\"]).agg(np.mean)[\"S\"][1::2])\n",
    "    rusher_s = np.repeat(rusher_s, 22)\n",
    "    test[\"RatioSToRusher\"] = test[\"S\"] / rusher_s\n",
    "    \n",
    "    #test[\"MoveDist\"] = test[\"S\"] * test[\"handoff_snap_diff\"] + 0.5 * test[\"A\"] * (test[\"handoff_snap_diff\"] **2)\n",
    "    #test[\"RealToTheoryDis\"] = test[\"Dis\"] / test[\"MoveDist\"]\n",
    "    \n",
    "    #test[\"Ori_Dir_diff\"] = test[\"Dir_std\"] - test[\"Orientation_std\"]\n",
    "    # my original idea end ------------------------------------------------------------\n",
    "    \n",
    "    test_single = test[test.is_run==True].copy()\n",
    "    test_single['time_quarter'] = test_single.GameClock.map(lambda x:transform_time_quarter(x))\n",
    "    test_single['time_end'] = test_single.apply(lambda x:transform_time_all(x.loc['GameClock'],x.loc['Quarter']),axis=1)\n",
    "    #test_single['TimeLeft'] = test_single['GameClock'].apply(strtoseconds)\n",
    "    \n",
    "    # my original idea ----------------------------------------------------------------\n",
    "    #test_single['WindSpeed'] = test_single['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n",
    "    #test_single['WindSpeed'] = test_single['WindSpeed'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n",
    "    #test_single['WindSpeed'] = test_single['WindSpeed'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n",
    "    #test_single['WindSpeed'] = test_single['WindSpeed'].apply(str_to_float)\n",
    "    \n",
    "    #test_single['WindDirection'] = test_single['WindDirection'].apply(lambda x: \"north\" if x == \"N\" or x == \"FROM S\"\n",
    "    #                                               else (\"south\" if x == 'S' or x== 'FROM N'\n",
    "    #                                               else (\"west\" if x == 'W' or x == 'FROM E'\n",
    "    #                                               else (\"east\" if x == 'E' or x == 'FROM W'\n",
    "    #                                               else (\"north east\" if x == 'FROM SW' or x == 'FROM SSW' or x == 'FROM WSW'\n",
    "    #                                               else (\"north west\" if x == 'FROM SE' or x == 'FROM SSE' or x == 'FROM ESE'\n",
    "    #                                               else (\"south east\" if x == 'FROM NW' or x == 'FROM NNW' or x == 'FROM WNW'\n",
    "    #                                               else (\"south west\" if x == 'FROM NE' or x == 'FROM NNE' or x == 'FROM ENE'\n",
    "    #                                               else (\"north west\" if x == 'NW' or x == 'NORTHWEST'\n",
    "    #                                               else (\"north east\" if x == 'NE' or x == 'NORTH EAST'\n",
    "    #                                               else (\"south west\" if x == 'SW' or x == 'SOUTHWEST'\n",
    "    #                                               else (\"south east\" if x == 'SE' or x == 'SOUTHEAST' else \"unknown\"))))))))))))\n",
    "    \n",
    "    #test_single['GameWeather'] = test_single['GameWeather'].apply(lambda x: \"rain\" if x in rain \n",
    "    #                                                    else (\"overcast\" if x in overcast\n",
    "    #                                                    else (\"clear\" if x in clear\n",
    "    #                                                    else (\"snow\" if x in snow\n",
    "    #                                                    else (\"indoor\" if x in none else \"unknown\")))))\n",
    "    \n",
    "    #test_single['StadiumType'] = test_single['StadiumType'].apply(lambda x: \"outdoor\" if x in outdoor \n",
    "    #                                                else (\"indoor closed\" if x in indoor_closed\n",
    "    #                                                else (\"indoor open\" if x in indoor_open\n",
    "    #                                                else (\"dome_closed\" if x in dome_closed\n",
    "    #                                                else (\"dome_open\" if x in dome_open else \"unknown\")))))\n",
    "    \n",
    "    test_single[\"Location\"] = test_single[\"Location\"].map(lambda x: \"Arlington, TX\" if x == \"Arlington, Texas\"\n",
    "                        else (\"Baltimore, MD\" if x == \"Baltimore, Maryland\" or x == \"Baltimore, Md.\"\n",
    "                        else (\"Charlotte, NC\" if x == \"Charlotte, North Carolina\"\n",
    "                        else (\"Chicago, IL\" if x == \"Chicago. IL\"\n",
    "                        else (\"Cincinnati, OH\" if x == \"Cincinnati, Ohio\"\n",
    "                        else (\"Cleveland, OH\" if x == \"Cleveland\" or x == \"Cleveland Ohio\" or x == \"Cleveland, Ohio\" or x == \"Cleveland,Ohio\"\n",
    "                        else (\"Detroit, MI\" if x == \"Detroit\"\n",
    "                        else (\"East Rutherford, NJ\" if x == \"E. Rutherford, NJ\" or x == \"East Rutherford, N.J.\"\n",
    "                        else (\"Foxborough, MA\" if x == \"Foxborough, Ma\"\n",
    "                        else (\"Houston, TX\" if x == \"Houston, Texas\"\n",
    "                        else (\"Jacksonville, FL\" if x == \"Jacksonville Florida\" or x == \"Jacksonville, Fl\" or x == \"Jacksonville, Florida\"\n",
    "                        else (\"London\" if x == \"London, England\"\n",
    "                        else (\"Los Angeles, CA\" if x == \"Los Angeles, Calif.\"\n",
    "                        else (\"Miami Gardens, FLA\" if x == \"Miami Gardens, Fla.\"\n",
    "                        else (\"New Orleans, LA\" if x == \"New Orleans\" or x == \"New Orleans, La.\"\n",
    "                        else (\"Orchard Park, NY\" if x == \"Orchard Park NY\"\n",
    "                        else (\"Philadelphia, PA\" if x == \"Philadelphia, Pa.\"\n",
    "                        else (\"Pittsburgh, PA\" if x == \"Pittsburgh\"\n",
    "                        else (\"Seattle, WA\" if x == \"Seattle\" else x)))))))))))))))))))\n",
    "    \n",
    "    test_single[\"Stadium\"] = test_single[\"Stadium\"].map(lambda x: \"Broncos Stadium at Mile High\" if x==\"Broncos Stadium At Mile High\" \n",
    "                                             else (\"CenturyLink Field\" if x == \"CenturyField\" or x == x==\"CenturyLink\"\n",
    "                                             else (\"Everbank Field\" if x == \"EverBank Field\"\n",
    "                                             else (\"FirstEnergy Stadium\" if x ==\"First Energy Stadium\" or x==\"FirstEnergy\" or x == \"FirstEnergyStadium\"\n",
    "                                             else (\"Lambeau Field\" if x == \"Lambeau field\"\n",
    "                                             else (\"Los Angeles Memorial Coliseum\" if x == \"Los Angeles Memorial Coliesum\"\n",
    "                                             else (\"M&T Bank Stadium\" if x == \"M & T Bank Stadium\" or x == \"M&T Stadium\"\n",
    "                                             else (\"Mercedes-Benz Superdome\" if x == \"Mercedes-Benz Dome\"\n",
    "                                             else (\"MetLife Stadium\" if x == \"MetLife\" or x == \"Metlife Stadium\"\n",
    "                                             else (\"NRG Stadium\" if x == \"NRG\"\n",
    "                                             else (\"Oakland-Alameda County Coliseum\" if x == \"Oakland Alameda-County Coliseum\"\n",
    "                                             else (\"Paul Brown Stadium\" if x == \"Paul Brown Stdium\"\n",
    "                                             else (\"Twickenham Stadium\" if x == \"Twickenham\" else x)))))))))))))\n",
    "    \n",
    "    test_single[\"OffenseFormation\"] = test_single[\"OffenseFormation\"].fillna(\"Unknown\") \n",
    "    test_single['DefendersInTheBox_vs_Distance'] = test_single['DefendersInTheBox'] / test_single['Distance']\n",
    "    \n",
    "    #grass_labels = ['grass', 'natural grass', 'natural', 'naturall grass']\n",
    "    #test_single['Turf'] = np.where(test_single.Turf.str.lower().isin(grass_labels), \"Natural\", \"Artificial\")\n",
    "    \n",
    "    #arr = [[int(s[0]) for s in t.split(\", \")] for t in test_single[\"DefensePersonnel\"]]\n",
    "    #test_single[\"DefenseDL\"] = np.array([a[0] for a in arr])\n",
    "    #test_single[\"DefenseLB\"] = np.array([a[1] for a in arr])\n",
    "    #test_single[\"DefenseDB\"] = np.array([a[2] for a in arr])\n",
    "    #test_single[\"DefenseOL\"] = np.array([a[3] if len(a) == 4 else 0 for a in arr])\n",
    "    \n",
    "    #test_single[\"OffenseRB\"] = test_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "    #                        int(x.replace(\",\", \"\").split(\" RB\")[0][-1]) if \"RB\" in x else 0)\n",
    "    #test_single[\"OffenseTE\"] = test_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "    #                        int(x.replace(\",\", \"\").split(\" TE\")[0][-1]) if \"TE\" in x else 0)\n",
    "    #test_single[\"OffenseWR\"] = test_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "    #                        int(x.replace(\",\", \"\").split(\" WR\")[0][-1]) if \"WR\" in x else 0)\n",
    "    #test_single[\"OffenseOL\"] = test_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "    #                        int(x.replace(\",\", \"\").split(\" OL\")[0][-1]) if \"OL\" in x else 0)\n",
    "    #test_single[\"OffenseDL\"] = test_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "    #                        int(x.replace(\",\", \"\").split(\" DL\")[0][-1]) if \"DL\" in x else 0)\n",
    "    #test_single[\"OffenseQB\"] = test_single[\"OffensePersonnel\"].apply(lambda x: \n",
    "    #                        int(x.replace(\",\", \"\").split(\" QB\")[0][-1]) if \"QB\" in x else 0)\n",
    "        \n",
    "    # test_single[\"DownQuarter\"] = test_single[[\"Down\", \"Quarter\"]].apply(lambda x: \"D{}_Q{}\".format(x[0], x[1]), axis=1)\n",
    "    \n",
    "    test_single[\"NecDisPerDown\"] = test_single[\"Distance\"] / (5 - test_single[\"Down\"])\n",
    "    # my original idea end ------------------------------------------------------------\n",
    "    \n",
    "    test_single['date_game'] = test_single.GameId.map(lambda x:pd.to_datetime(str(x)[:8]))\n",
    "    test_single['runner_height'] = test_single.PlayerHeight.map(transform_height)\n",
    "    return test_single.drop(remove_features,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission file has been saved!  Once you `Commit` your Notebook and it finishes running, you can submit the file to the competition from the Notebook Viewer `Output` tab.\n"
     ]
    }
   ],
   "source": [
    "for (test_df, sample_prediction_df) in env.iter_test():\n",
    "    test_df['own_field'] = (test_df['FieldPosition'] == test_df['PossessionTeam']).astype(int)\n",
    "    dist_to_end_test = test_df.apply(lambda x:(100 - x.loc['YardLine']) if x.loc['own_field']==1 else x.loc['YardLine'],axis=1)\n",
    "    X_test = transform_test(test_df)\n",
    "    X_test.fillna(-999,inplace=True)\n",
    "    \n",
    "    # additional feature engineering -----------------------------------------------------------\n",
    "    #X_test.rename(columns={'X_std': 'X', \"Y_std\": \"Y\", \"Dir_std\": \"Dir\", \"YardLine_std\": \"YardLine\", \n",
    "    #                    \"Orientation_std\": \"Orientation\"}, inplace=True)\n",
    "    tmp = test_df.groupby([\"PlayId\", \"OnOffense\"]).agg(np.mean)[[\"S\", \"X\", \"Y\", \"Age\"]]\n",
    "    X_test[\"DefenseAveSpeed\"] = np.array(tmp[0::2][\"S\"])\n",
    "    X_test[\"OffenseAveSpeed\"] = np.array(tmp[1::2][\"S\"])\n",
    "\n",
    "    X_test[\"DefenseAveX\"] = np.array(tmp[0::2][\"X\"])\n",
    "    X_test[\"OffenseAveX\"] = np.array(tmp[1::2][\"X\"])\n",
    "\n",
    "    X_test[\"DefenseAveY\"] = np.array(tmp[0::2][\"Y\"]) \n",
    "    X_test[\"OffenseAveY\"] = np.array(tmp[1::2][\"Y\"]) \n",
    "\n",
    "    X_test[\"DefenseAveAge\"] = np.array(tmp[0::2][\"Age\"])\n",
    "    X_test[\"OffenseAveAge\"] = np.array(tmp[1::2][\"Age\"])\n",
    "    \n",
    "    tmp = test_df.groupby([\"PlayId\", \"OnOffense\"]).agg([\"std\"])[[\"X\", \"Y\"]]\n",
    "    X_test[\"DefenseStdX\"] = np.array(tmp[0::2][\"X\"])\n",
    "    X_test[\"OffenseStdX\"] = np.array(tmp[1::2][\"X\"])\n",
    "\n",
    "    X_test[\"DefenseStdY\"] = np.array(tmp[0::2][\"Y\"])\n",
    "    X_test[\"OffenseStdY\"] = np.array(tmp[1::2][\"Y\"])\n",
    "\n",
    "    X_test[\"RunnerToDefenseCentoid\"] = np.sqrt((X_test[\"X\"] - X_test[\"DefenseAveX\"]) ** 2 + (X_test[\"Y\"] - X_test[\"DefenseAveY\"]) ** 2)\n",
    "    X_test[\"RunnerToOffenseCentoid\"] = np.sqrt((X_test[\"X\"] - X_test[\"OffenseAveX\"]) ** 2 + (X_test[\"Y\"] - X_test[\"OffenseAveY\"]) ** 2)\n",
    "\n",
    "    tmp_max = test_df.groupby([\"PlayId\", \"OnOffense\"])[\"X\"].max()\n",
    "    tmp_min = test_df.groupby([\"PlayId\", \"OnOffense\"])[\"X\"].min()\n",
    "    X_test[\"DefenseSpreadX\"] = np.array(tmp_max[0::2]- tmp_min[0::2])\n",
    "    X_test[\"OffenseSpreadX\"] = np.array(tmp_max[1::2]- tmp_min[1::2])\n",
    "    \n",
    "    X_test[\"RunnerToScrimmage\"] = X_test[\"X\"] - X_test[\"YardLine\"]\n",
    "\n",
    "    radian_angle = (90 - X_test['Dir']) * np.pi / 180.0\n",
    "    #radian_angle = X_test['Dir'] * np.pi / 180.0\n",
    "    X_test['v_horizontal'] = np.abs(X_test['S'] * np.cos(radian_angle))\n",
    "    X_test['v_vertical'] = np.abs(X_test['S'] * np.sin(radian_angle))\n",
    "\n",
    "    X_test['m_horizontal'] = np.abs(X_test['Momentum'] * np.cos(radian_angle))\n",
    "    X_test['m_vertical'] = np.abs(X_test['Momentum'] * np.sin(radian_angle))\n",
    "\n",
    "    X_test[\"MinDisFromRushToDef\"] = np.array(test_df.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].min()[0::2])\n",
    "\n",
    "    X_test[\"MinTackleTime\"] = np.array(test_df.groupby([\"PlayId\", \"OnOffense\"])[\"TackleTimeToRusher\"].min()[0::2])\n",
    "\n",
    "    X_test[\"AveTackleTime\"] = np.array(test_df.groupby([\"PlayId\", \"OnOffense\"]).agg(np.mean)[\"TackleTimeToRusher\"][0::2])\n",
    "\n",
    "    X_test[\"RatioSRusherToCloseDef\"] = np.array(test_df.loc[test_df.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].idxmin()[0::2]][\"RatioSToRusher\"])\n",
    "    \n",
    "    X_test[\"dis_horizontal\"] = np.abs(X_test['Dis'] * np.cos(radian_angle))\n",
    "    X_test[\"dis_vertical\"] = np.abs(X_test['Dis'] * np.sin(radian_angle))\n",
    "    X_test[\"RunnerMoveRatio\"] = X_test[\"dis_horizontal\"] / X_test[\"dis_vertical\"]\n",
    "    \n",
    "    X_test[\"DefMomentumCloToRusher\"] = np.array(test_df.loc[test_df.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].idxmin()[0::2]][\"Momentum\"])\n",
    "    X_test[\"DefMomentumCloToRusher_horizontal\"] = np.abs(X_test['DefMomentumCloToRusher'] * np.cos(radian_angle))\n",
    "    X_test[\"DefMomentumCloToRusher_vertical\"] = np.abs(X_test['DefMomentumCloToRusher'] * np.sin(radian_angle))\n",
    "\n",
    "    X_test[\"RusherMomentum_horizontal\"] =  np.abs(X_test['Momentum'] * np.cos(radian_angle))\n",
    "    X_test[\"RusherMomentum_vertical\"] =  np.abs(X_test['Momentum'] * np.sin(radian_angle))\n",
    "\n",
    "    X_test[\"hMomentum_rusher_vs_defender\"] = X_test[\"RusherMomentum_horizontal\"] - X_test[\"DefMomentumCloToRusher_horizontal\"]\n",
    "    \n",
    "    # voronoi area\n",
    "    #pts = np.array(test_df[[\"X\", \"Y\"]]).reshape(test_df.shape[0]//22, 22, 2)\n",
    "    #rusher_index = list(test_df[test_df.is_run==True].index % 22) \n",
    "    #closest_def_index = list(test_df.loc[test_df.groupby([\"PlayId\", \"OnOffense\"])[\"DisToRusher\"].idxmin()[0::2]].index % 22)\n",
    "    #rusher_voronoi = []\n",
    "    #closest_def_voronoi = []\n",
    "    #for i in range(0, test_df.shape[0] //22):\n",
    "        ##rusher_voronoi.append(voronoi_volumes(pts[i], rusher_index[i]))\n",
    "        #closest_def_voronoi.append(voronoi_volumes(pts[i], closest_def_index[i]))\n",
    "    ##X_test[\"RusherVoronoi\"] = rusher_voronoi    \n",
    "    #X_test[\"FirstDefenderVoronoi\"] = closest_def_voronoi \n",
    "    \n",
    "    #tmp_df = test_df[[\"PlayId\", \"OnOffense\", \"DisToRusher\"]].copy()\n",
    "    #tmp_df[\"3yards\"] = test_df[\"DisToRusher\"].apply(lambda x: 1 if x<=3 else 0)\n",
    "    #tmp_df[\"5yards\"] = test_df[\"DisToRusher\"].apply(lambda x: 1 if x<=5 else 0)\n",
    "    #tmp_df[\"7yards\"] = test_df[\"DisToRusher\"].apply(lambda x: 1 if x<=7 else 0)\n",
    "    #tmp_df[\"10yards\"] = test_df[\"DisToRusher\"].apply(lambda x: 1 if x<=10 else 0)\n",
    "    #tmp_yard_defense = tmp_df.groupby([\"PlayId\", \"OnOffense\"]).agg(np.sum)[[\"3yards\", \"5yards\", \"7yards\", \"10yards\"]][0::2]\n",
    "    #tmp_yard_offense = tmp_df.groupby([\"PlayId\", \"OnOffense\"]).agg(np.sum)[[\"3yards\", \"5yards\", \"7yards\", \"10yards\"]][1::2]\n",
    "    #X_test[\"Offense3yards\"] = np.array(tmp_yard_offense[\"3yards\"]-1)\n",
    "    #X_test[\"Offense5yards\"] = np.array(tmp_yard_offense[\"5yards\"]-1)\n",
    "    #X_test[\"Offense7yards\"] = np.array(tmp_yard_offense[\"7yards\"]-1)\n",
    "    #X_test[\"Offense10yards\"] = np.array(tmp_yard_offense[\"10yards\"]-1)\n",
    "    #X_test[\"Defense3yards\"] = np.array(tmp_yard_defense[\"3yards\"])\n",
    "    #X_test[\"Defense5yards\"] = np.array(tmp_yard_defense[\"5yards\"])\n",
    "    #X_test[\"Defense7yards\"] = np.array(tmp_yard_defense[\"7yards\"])\n",
    "    #X_test[\"Defense10yards\"] = np.array(tmp_yard_defense[\"10yards\"])\n",
    "    \n",
    "    #X_test = X_test.drop(['RatioSToRusher', 'TackleTimeToRusher', 'OnOffense', 'RusherMomentum_horizontal', 'RusherMomentum_vertical', 'DisToRusher'],axis=1)\n",
    "    # ------------------------------------------------------\n",
    "    for f in X_test.columns:\n",
    "        if X_test[f].dtype=='object':\n",
    "            X_test[f] = X_test[f].map(lambda x:x if x in set(X_train[f]) else -999)\n",
    "    for f in X_test.columns:\n",
    "        if X_test[f].dtype=='object': \n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(X_train[f])+[-999])\n",
    "            X_test[f] = lbl.transform(list(X_test[f])) \n",
    "    pred_value = 0\n",
    "    for model in models:\n",
    "        pred_value += model.predict(X_test)[0]/5\n",
    "    pred_data = list(get_score(pred_value,cdf,4,dist_to_end_test.values[0]))\n",
    "    pred_data = np.array(pred_data).reshape(1,199)\n",
    "    pred_target = pd.DataFrame(index = sample_prediction_df.index, \\\n",
    "                               columns = sample_prediction_df.columns, \\\n",
    "                               #data = np.array(pred_data))\n",
    "                               data = pred_data)\n",
    "    env.predict(pred_target)\n",
    "env.write_submission_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
