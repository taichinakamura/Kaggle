{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "- modify truncated validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import datetime\n",
    "from time import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, log_loss, roc_auc_score, precision_score, recall_score, accuracy_score, f1_score, confusion_matrix, cohen_kappa_score\n",
    "import optuna.integration.lightgbm as lgb_opt\n",
    "import lightgbm as lgb\n",
    "from functools import partial\n",
    "import json\n",
    "import copy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "from hyperopt import hp, tpe, Trials, fmin, space_eval\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.max_rows\",1000)\n",
    "np.set_printoptions(precision=8)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qwk(a1, a2):\n",
    "    max_rat = 3\n",
    "    a1 = np.asarray(a1, dtype=int)\n",
    "    a2 = np.asarray(a2, dtype=int)\n",
    "    hist1 = np.zeros((max_rat + 1, ))\n",
    "    hist2 = np.zeros((max_rat + 1, ))\n",
    "    o = 0\n",
    "    for k in range(a1.shape[0]):\n",
    "        i, j = a1[k], a2[k]\n",
    "        hist1[i] += 1\n",
    "        hist2[j] += 1\n",
    "        o +=  (i - j) * (i - j)\n",
    "    e = 0\n",
    "    for i in range(max_rat + 1):\n",
    "        for j in range(max_rat + 1):\n",
    "            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n",
    "    e = e / a1.shape[0]\n",
    "    return np.round(1 - o / e, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedRounder_cla(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "        return -qwk(y, X_p)\n",
    "        #return -mod_qwk(y, X_p, weights=weights)\n",
    "    \n",
    "    def fit(self, X, y, random_flg = False):\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        if random_flg:\n",
    "            initial_coef = [np.random.uniform(0.4,0.5), np.random.uniform(0.5,0.6), np.random.uniform(0.6,0.7)]\n",
    "        else:\n",
    "            initial_coef = [0.5, 1.5, 2.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead') #Powell\n",
    "        \n",
    "    def predict(self, X, coef):\n",
    "        return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']\n",
    "    \n",
    "class OptimizedRounder_reg(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "        return -qwk(y, X_p)\n",
    "        #return -mod_qwk(y, X_p, weights=weights)\n",
    "    \n",
    "    def fit(self, X, y, random_flg = False):\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        if random_flg:\n",
    "            initial_coef = [np.random.uniform(1.0,1.1), np.random.uniform(1.7,1.8), np.random.uniform(2.1,2.2)]\n",
    "        else:\n",
    "            initial_coef = [0.5, 1.5, 2.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead') #Powell\n",
    "        \n",
    "    def predict(self, X, coef):\n",
    "        return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_qwk_lgb_regr(y_pred, train_t):\n",
    "    dist = Counter(train_t['accuracy_group'])\n",
    "    for k in dist:\n",
    "        dist[k] /= len(train_t)\n",
    "    \n",
    "    acum = 0\n",
    "    bound = {}\n",
    "    for i in range(3):\n",
    "        acum += dist[i]\n",
    "        bound[i] = np.percentile(y_pred, acum * 100)\n",
    "\n",
    "    def classify(x):\n",
    "        if x <= bound[0]:\n",
    "            return 0\n",
    "        elif x <= bound[1]:\n",
    "            return 1\n",
    "        elif x <= bound[2]:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "\n",
    "    y_pred = np.array(list(map(classify, y_pred)))\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 17s, sys: 11.9 s, total: 1min 29s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv('../input/data-science-bowl-2019/train.csv')\n",
    "train_labels = pd.read_csv('../input/data-science-bowl-2019/train_labels.csv')\n",
    "test = pd.read_csv('../input/data-science-bowl-2019/test.csv')\n",
    "sample_submission = pd.read_csv('../input/data-science-bowl-2019/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Preprocess and Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 53s, sys: 9.87 s, total: 2min 3s\n",
      "Wall time: 2min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def encode_title(train, test):\n",
    "    train['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), train['title'], train['event_code']))\n",
    "    test['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), test['title'], test['event_code']))\n",
    "    list_of_title_eventcode = sorted(list(set(train['title_event_code'].unique()).union(set(test['title_event_code'].unique()))))\n",
    "    \n",
    "    train['type_world'] = list(map(lambda x, y: str(x) + '_' + str(y), train['type'], train['world']))\n",
    "    test['type_world'] = list(map(lambda x, y: str(x) + '_' + str(y), test['type'], test['world']))\n",
    "    list_of_type_world = sorted(list(set(train['type_world'].unique()).union(set(test['type_world'].unique()))))\n",
    "    \n",
    "    list_of_user_activities = sorted(list(set(train['title'].unique()).union(set(test['title'].unique()))))\n",
    "    list_of_event_code = sorted(list(set(train['event_code'].unique()).union(set(test['event_code'].unique()))))\n",
    "    list_of_worlds = sorted(list(set(train['world'].unique()).union(set(test['world'].unique()))))\n",
    "    activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n",
    "    activities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\n",
    "    activities_world = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n",
    "    assess_titles = sorted(list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(set(test[test['type'] == 'Assessment']['title'].value_counts().index))))\n",
    "\n",
    "    train['title'] = train['title'].map(activities_map)\n",
    "    test['title'] = test['title'].map(activities_map)\n",
    "    train['world'] = train['world'].map(activities_world)\n",
    "    test['world'] = test['world'].map(activities_world)\n",
    "\n",
    "    win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\n",
    "    win_code[activities_map['Bird Measurer (Assessment)']] = 4110\n",
    "    \n",
    "    train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "    test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "    \n",
    "    train[\"misses\"] = train[\"event_data\"].apply(lambda x: json.loads(x)[\"misses\"] if \"\\\"misses\\\"\" in x else np.nan)\n",
    "    test[\"misses\"] = test[\"event_data\"].apply(lambda x: json.loads(x)[\"misses\"] if \"\\\"misses\\\"\" in x else np.nan)\n",
    "        \n",
    "    train[\"true\"] = train[\"event_data\"].apply(lambda x: 1 if \"true\" in x and \"correct\" in x else 0)\n",
    "    test[\"true\"] = test[\"event_data\"].apply(lambda x: 1 if \"true\" in x and \"correct\" in x else 0)\n",
    "\n",
    "    train[\"false\"] = train[\"event_data\"].apply(lambda x: 1 if \"false\" in x and \"correct\" in x else 0)\n",
    "    test[\"false\"] = test[\"event_data\"].apply(lambda x: 1 if \"false\" in x and \"correct\" in x else 0)\n",
    "    \n",
    "    train[\"game_complete\"] = train[\"event_data\"].apply(lambda x: 1 if \"game_completed\" in x else 0)\n",
    "    test[\"game_complete\"] = test[\"event_data\"].apply(lambda x: 1 if \"game_completed\" in x else 0)\n",
    "    \n",
    "    #train[\"level\"] = train[\"event_data\"].apply(lambda x: json.loads(x)[\"level\"] if \"\\\"level\\\"\" in x else np.nan)\n",
    "    #test[\"level\"] = test[\"event_data\"].apply(lambda x: json.loads(x)[\"level\"] if \"\\\"level\\\"\" in x else np.nan)\n",
    "    \n",
    "    #train[\"round\"] = train[\"event_data\"].apply(lambda x: json.loads(x)[\"round\"] if \"\\\"round\\\"\" in x else np.nan)\n",
    "    #test[\"round\"] = test[\"event_data\"].apply(lambda x: json.loads(x)[\"round\"] if \"\\\"round\\\"\" in x else np.nan)\n",
    "               \n",
    "    return train, test, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, activities_world, list_of_title_eventcode, list_of_type_world\n",
    "\n",
    "train, test, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, activities_world, list_of_title_eventcode, list_of_type_world = encode_title(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def make_ratio(features, dic):\n",
    "    total = sum(dic.values())\n",
    "    if total != 0:\n",
    "        for key in dic.keys():\n",
    "            features[str(key)] = features[str(key)] / total\n",
    "    else:\n",
    "        pass\n",
    "    return features\n",
    "\n",
    "def get_data(user_sample, test_set=False):\n",
    "    last_activity = 0\n",
    "    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "    title_eventcode_count = {str(ele): 0 for ele in list_of_title_eventcode}\n",
    "    user_world_count = {\"world_\"+str(wor) : 0 for wor in activities_world.values()}\n",
    "    event_code_count = {str(ev): 0 for ev in list_of_event_code}\n",
    "    title_count = {actv: 0 for actv in list_of_user_activities}\n",
    "    type_world_count = {str(ev): 0 for ev in list_of_type_world}\n",
    "    last_accuracy_title = {'acc_' + title: -1 for title in assess_titles}\n",
    "    last_game_time_title = {'lgt_' + title: 0 for title in assess_titles}\n",
    "    ac_game_time_title = {'agt_' + title: 0 for title in assess_titles}\n",
    "    ac_true_attempts_title = {'ata_' + title: 0 for title in assess_titles}\n",
    "    ac_false_attempts_title = {'afa_' + title: 0 for title in assess_titles}\n",
    "    \n",
    "    all_assessments = []\n",
    "    accuracy_groups = {\"0\":0, \"1\":0, \"2\":0, \"3\":0}\n",
    "    accumulated_accuracy_group = 0\n",
    "    accumulated_correct_attempts = 0 \n",
    "    accumulated_uncorrect_attempts = 0 \n",
    "    accumulated_actions = 0\n",
    "    counter = 0\n",
    "    time_first_activity = user_sample.iloc[0]['timestamp']\n",
    "    miss = 0\n",
    "    crys_game_true = 0; crys_game_false = 0\n",
    "    tree_game_true = 0; tree_game_false = 0\n",
    "    magma_game_true = 0; magma_game_false = 0\n",
    "    crys_game_acc = []; tree_game_acc = []; magma_game_acc = []\n",
    "    durations = []\n",
    "    prev_assess_title = -999\n",
    "    assess_count = 1\n",
    "    last_accuracy = -999\n",
    "    prev_assess_start = -999; prev_assess_end = -999\n",
    "    real_prev_assess_start = -999; real_prev_assess_end = -999\n",
    "    real_assess_start = -999; real_assess_end = -999\n",
    "    complete_games = 0\n",
    "    no_result_count = 0\n",
    "    crys_game_level = np.array([]); tree_game_level = np.array([]); magma_game_level = np.array([])\n",
    "    crys_game_round = np.array([]); tree_game_round = np.array([]); magma_game_round = np.array([])\n",
    "    \n",
    "    for i, session in user_sample.groupby('game_session', sort=False):      \n",
    "        session_type = session['type'].iloc[0]\n",
    "        session_title = session['title'].iloc[0]\n",
    "        session_title_text = activities_labels[session_title]\n",
    "        session_world = session[\"world\"].iloc[0]\n",
    "        \n",
    "        if session_type != 'Assessment':\n",
    "            if session_type == \"Game\":\n",
    "                true = session['true'].sum()\n",
    "                false = session['false'].sum() \n",
    "                if session_world == activities_world[\"CRYSTALCAVES\"]:\n",
    "                    crys_game_true += true\n",
    "                    crys_game_false += false\n",
    "                    crys_game_acc.append(true / (true + false) if (true + false) != 0 else 0)\n",
    "                    #crys_game_level = np.concatenate([crys_game_level, session[\"level\"]], axis=0)\n",
    "                    #crys_game_round = np.concatenate([crys_game_round, session[\"round\"]], axis=0)\n",
    "                elif session_world == activities_world[\"TREETOPCITY\"]:\n",
    "                    tree_game_true += true\n",
    "                    tree_game_false += false\n",
    "                    tree_game_acc.append(true / (true + false) if (true + false) != 0 else 0)\n",
    "                    #tree_game_level = np.concatenate([tree_game_level, session[\"level\"]], axis=0)\n",
    "                    #tree_game_round = np.concatenate([tree_game_round, session[\"round\"]], axis=0)\n",
    "                elif session_world == activities_world[\"MAGMAPEAK\"]:\n",
    "                    magma_game_true += true\n",
    "                    magma_game_false += false\n",
    "                    magma_game_acc.append(true / (true + false) if (true + false) != 0 else 0)\n",
    "                    #magma_game_level = np.concatenate([magma_game_level, session[\"level\"]], axis=0)\n",
    "                    #magma_game_round = np.concatenate([magma_game_round, session[\"round\"]], axis=0)\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "        if (session_type == 'Assessment') & (test_set or len(session)>1): \n",
    "            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n",
    "            true_attempts = all_attempts['event_data'].str.contains('true').sum() # true in target assess\n",
    "            false_attempts = all_attempts['event_data'].str.contains('false').sum() # false in target assessment\n",
    "            assess_start = session.iloc[0,2]\n",
    "            assess_end = session.iloc[-1,2]\n",
    "            \n",
    "            # from start of installation_id to the start of target assessment ------------------------\n",
    "            features = user_activities_count.copy() # appearance of each type without duplicates\n",
    "            features = make_ratio(features, user_activities_count)\n",
    "            features.update(title_eventcode_count.copy()) # apperance of combi of title and event_code\n",
    "            features = make_ratio(features, title_eventcode_count)\n",
    "            features.update(user_world_count.copy()) # appearance of world with duplicates\n",
    "            features = make_ratio(features, user_world_count)\n",
    "            features.update(event_code_count.copy())\n",
    "            features = make_ratio(features, event_code_count)\n",
    "            features.update(title_count.copy())\n",
    "            features = make_ratio(features, title_count)\n",
    "            features.update(type_world_count.copy())\n",
    "            features = make_ratio(features, type_world_count)\n",
    "            features.update(last_accuracy_title.copy())\n",
    "            features.update(last_game_time_title.copy())\n",
    "            features.update(ac_game_time_title.copy())\n",
    "            features.update(ac_true_attempts_title.copy())\n",
    "            features.update(ac_false_attempts_title.copy())\n",
    "            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n",
    "            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n",
    "            accumulated_correct_attempts += true_attempts \n",
    "            accumulated_uncorrect_attempts += false_attempts\n",
    "            ac_true_attempts_title['ata_' + session_title_text] += true_attempts\n",
    "            ac_false_attempts_title['afa_' + session_title_text] += false_attempts\n",
    "            last_game_time_title['lgt_' + session_title_text] = session['game_time'].iloc[-1]\n",
    "            ac_game_time_title['agt_' + session_title_text] += session['game_time'].iloc[-1]\n",
    "            features[\"misses\"] = miss\n",
    "            features['accumulated_actions'] = accumulated_actions\n",
    "            features[\"no_complete_game\"] = complete_games\n",
    "            features[\"no_result_count\"] = no_result_count \n",
    "            \n",
    "            if true_attempts + false_attempts == 0:\n",
    "                no_result_count += 1\n",
    "            else:\n",
    "                real_assess_start = session.iloc[0,2]\n",
    "                real_assess_end = session.iloc[-1,2]\n",
    "             \n",
    "            #features[\"crys_game_true\"] = crys_game_true\n",
    "            #features[\"crys_game_false\"] = crys_game_false\n",
    "            #features['crys_game_accuracy'] = crys_game_true / (crys_game_true + crys_game_false) if (crys_game_true + crys_game_false) != 0 else 0\n",
    "            #features[\"crys_game_accuracy_std\"] = np.std(crys_game_acc) if len(crys_game_acc) >=1 else 0\n",
    "            #features[\"cryslast_game_acc\"] = crys_game_acc[-1] if len(crys_game_acc) >=1 else 0\n",
    "            #features[\"tree_game_true\"] = tree_game_true\n",
    "            #features[\"tree_game_false\"] = tree_game_false\n",
    "            #features['tree_game_accuracy'] = tree_game_true / (tree_game_true + tree_game_false) if (tree_game_true + tree_game_false) != 0 else 0\n",
    "            #features[\"tree_game_accuracy_std\"] = np.std(tree_game_acc) if len(tree_game_acc) >=1 else 0\n",
    "            #features[\"tree_last_game_acc\"] = tree_game_acc[-1] if len(tree_game_acc) >=1 else 0\n",
    "            #features[\"magma_game_true\"] = magma_game_true\n",
    "            #features[\"magma_game_false\"] = magma_game_false\n",
    "            #features['magma_game_accuracy'] = magma_game_true / (magma_game_true + magma_game_false) if (magma_game_true + magma_game_false) != 0 else 0\n",
    "            #features[\"magma_game_accuracy_std\"] = np.std(magma_game_acc) if len(magma_game_acc) >=1 else 0\n",
    "            #features[\"magma_last_game_acc\"] = magma_game_acc[-1] if len(magma_game_acc) >=1 else 0\n",
    "            \n",
    "            if session_world == activities_world[\"CRYSTALCAVES\"]:\n",
    "                features[\"game_true\"] = crys_game_true\n",
    "                features[\"game_false\"] = crys_game_false\n",
    "                features['game_accuracy'] = crys_game_true / (crys_game_true + crys_game_false) if (crys_game_true + crys_game_false) != 0 else 0\n",
    "                features[\"game_accuracy_std\"] = np.std(crys_game_acc) if len(crys_game_acc) >=1 else 0\n",
    "                features[\"last_game_acc\"] = crys_game_acc[-1] if len(crys_game_acc) >=1 else 0\n",
    "            elif session_world == activities_world[\"TREETOPCITY\"]:\n",
    "                features[\"game_true\"] = tree_game_true\n",
    "                features[\"game_false\"] = tree_game_false\n",
    "                features['game_accuracy'] = tree_game_true / (tree_game_true + tree_game_false) if (tree_game_true + tree_game_false) != 0 else 0\n",
    "                features[\"game_accuracy_std\"] = np.std(tree_game_acc) if len(tree_game_acc) >=1 else 0\n",
    "                features[\"last_game_acc\"] = tree_game_acc[-1] if len(tree_game_acc) >=1 else 0\n",
    "            elif session_world == activities_world[\"MAGMAPEAK\"]:\n",
    "                features[\"game_true\"] = magma_game_true\n",
    "                features[\"game_false\"] = magma_game_false\n",
    "                features['game_accuracy'] = magma_game_true / (magma_game_true + magma_game_false) if (magma_game_true + magma_game_false) != 0 else 0\n",
    "                features[\"game_accuracy_std\"] = np.std(magma_game_acc) if len(magma_game_acc) >=1 else 0\n",
    "                features[\"last_game_acc\"] = magma_game_acc[-1] if len(magma_game_acc) >=1 else 0\n",
    "            \n",
    "            features['installation_id'] = session['installation_id'].iloc[-1]\n",
    "            features['session_title'] = session_title\n",
    "            features[\"prev_assess_title\"] = prev_assess_title\n",
    "            prev_assess_title = session_title\n",
    "            features[\"first_assessment\"] = 1 if assess_count == 1 else 0\n",
    "            #features[\"assess_count\"] = assess_count\n",
    "            assess_count += 1\n",
    "            features[\"time_from_start\"] = (assess_start - time_first_activity).seconds\n",
    "\n",
    "            if prev_assess_end == -999:\n",
    "                features[\"time_bet_assess\"] = -999\n",
    "            else:\n",
    "                features[\"time_bet_assess\"] = (assess_start - prev_assess_end).seconds\n",
    "            prev_assess_start = assess_start\n",
    "            prev_assess_end = assess_end\n",
    "            if real_prev_assess_end == -999:\n",
    "                features[\"time_bet_real_assess\"] = -999\n",
    "            else:\n",
    "                features[\"time_bet_real_assess\"] = (real_assess_start - real_prev_assess_end).seconds\n",
    "            real_prev_assess_start = real_assess_start\n",
    "            real_prev_assess_end = real_assess_end\n",
    "            \n",
    "            if durations == []: #span of timestamp in target assessment\n",
    "                features['duration_mean'] = 0\n",
    "                features['duration_std'] = 0\n",
    "                features['duration_max'] = 0\n",
    "            else:\n",
    "                features['duration_mean'] = np.mean(durations)\n",
    "                features['duration_std'] = np.std(durations)\n",
    "                features['duration_max'] = np.max(durations)\n",
    "            durations.append((session.iloc[-1, 2] - session.iloc[0, 2]).seconds)\n",
    "            \n",
    "            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "            features['last_assess_acc'] = last_accuracy\n",
    "            last_accuracy_title['acc_' + session_title_text] = accuracy\n",
    "            last_accuracy = accuracy\n",
    "            if accuracy == 0:\n",
    "                features['accuracy_group'] = 0\n",
    "            elif accuracy == 1:\n",
    "                features['accuracy_group'] = 3\n",
    "            elif accuracy == 0.5:\n",
    "                features['accuracy_group'] = 2\n",
    "            else:\n",
    "                features['accuracy_group'] = 1\n",
    "            features.update(accuracy_groups)\n",
    "            accuracy_groups[str(features['accuracy_group'])] += 1\n",
    "            features['accumulated_accuracy_group'] = accumulated_accuracy_group/counter if counter > 0 else 0\n",
    "            accumulated_accuracy_group += features['accuracy_group']\n",
    "            \n",
    "            if test_set:\n",
    "                all_assessments.append(features)\n",
    "            elif true_attempts+false_attempts > 0:\n",
    "                all_assessments.append(features)\n",
    "                \n",
    "            counter += 1\n",
    "            \n",
    "        complete_games += np.sum(session[\"game_complete\"])\n",
    "        miss += np.sum(session[\"misses\"])\n",
    "        user_world_count[\"world_\"+str(session_world)] += session.shape[0]\n",
    "        \n",
    "        n_of_type_world = Counter(session['type_world']) \n",
    "        for key in n_of_type_world.keys():\n",
    "            type_world_count[str(key)] += n_of_type_world[key]\n",
    "            \n",
    "        n_of_title = Counter(session['title']) \n",
    "        for key in n_of_title.keys():\n",
    "            title_count[activities_labels[key]] += n_of_title[key]\n",
    "            \n",
    "        n_of_eventcode = Counter(session['event_code']) \n",
    "        for key in n_of_eventcode.keys():\n",
    "            event_code_count[str(key)] += n_of_eventcode[key]\n",
    "                        \n",
    "        n_of_title_eventcode = Counter(session['title_event_code']) \n",
    "        for key in n_of_title_eventcode.keys():\n",
    "            title_eventcode_count[str(key)] += n_of_title_eventcode[key]\n",
    "        \n",
    "        accumulated_actions += len(session)\n",
    "        if last_activity != session_type:\n",
    "            user_activities_count[session_type] += 1\n",
    "            last_activitiy = session_type\n",
    "    if test_set:\n",
    "        return all_assessments[-1], all_assessments[:-1] # test previous data to incorporate into training\n",
    "    return all_assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469ee1bb0bfc43a2be942c4cd72be476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Installation_id', max=17000, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "652bb3ee761e43d7a4bc6b2875330a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Installation_id', max=1000, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_train_and_test(train, test):\n",
    "    compiled_train = []\n",
    "    compiled_test = []\n",
    "    compiled_val = []\n",
    "\n",
    "    for i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort=False)), total=train.installation_id.nunique(), desc='Installation_id', position=0):\n",
    "        compiled_train += get_data(user_sample)\n",
    "    del train\n",
    "    for ins_id, user_sample in tqdm(test.groupby('installation_id', sort=False), total=test.installation_id.nunique(), desc='Installation_id', position=0):\n",
    "        test_data, val_data = get_data(user_sample, test_set=True)\n",
    "        compiled_test.append(test_data)\n",
    "        compiled_val += val_data\n",
    "    del test\n",
    "    reduce_train = pd.DataFrame(compiled_train)\n",
    "    reduce_test = pd.DataFrame(compiled_test)\n",
    "    reduce_val = pd.DataFrame(compiled_val)\n",
    "\n",
    "    categoricals = ['session_title']\n",
    "    return reduce_train, reduce_test, reduce_val, categoricals\n",
    "new_train, new_test, new_val, categoricals = get_train_and_test(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = new_train[new_train.Game==0].copy()\n",
    "tmp = tmp[tmp.Activity == 0].copy()\n",
    "tmp = tmp[tmp.Clip == 0].copy()\n",
    "tmp = tmp[tmp.Assessment ==0].copy()\n",
    "remove_train_index = tmp.index\n",
    "new_train = new_train[~new_train.index.isin(remove_train_index)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17577, 563)\n",
      "(1000, 563)\n",
      "(2347, 563)\n"
     ]
    }
   ],
   "source": [
    "print(new_train.shape)\n",
    "print(new_test.shape)\n",
    "print(new_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19906, 563)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data augmentation\n",
    "tmp = new_val[new_val.Game==0].copy()\n",
    "tmp = tmp[tmp.Activity == 0].copy()\n",
    "tmp = tmp[tmp.Clip == 0].copy()\n",
    "tmp = tmp[tmp.Assessment ==0].copy()\n",
    "remove_val_index = tmp.index\n",
    "add_val = new_val[~new_val.index.isin(remove_val_index)].copy()\n",
    "\n",
    "#tmp = add_val.installation_id.value_counts().reset_index(drop=False) # include some part of new_test installation_id\n",
    "#val_id = list(tmp[tmp.installation_id >= 20][\"index\"])\n",
    "#add_val = add_val[add_val.installation_id.isin(val_id)]\n",
    "\n",
    "mod_train = pd.concat([new_train, add_val], ignore_index=True)\n",
    "mod_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Air Show_4080\n",
      "Bottle Filler (Activity)_2010\n",
      "Bubble Bath_4080\n",
      "Bubble Bath_4090\n",
      "Bug Measurer (Activity)_4080\n",
      "Cart Balancer (Assessment)_4080\n",
      "Chest Sorter (Assessment)_4080\n",
      "Crystals Rule_2010\n",
      "Dino Dive_4080\n",
      "Dino Drink_4080\n",
      "Egg Dropper (Activity)_4080\n",
      "Fireworks (Activity)_4080\n",
      "Happy Camel_4080\n",
      "Leaf Leader_4080\n",
      "Mushroom Sorter (Assessment)_4080\n",
      "Pan Balance_2010\n",
      "Pan Balance_4080\n",
      "Sandcastle Builder (Activity)_2010\n",
      "Scrub-A-Dub_4080\n",
      "Watering Hole (Activity)_2010\n",
      "acc_Cart Balancer (Assessment)\n"
     ]
    }
   ],
   "source": [
    "def exclude(reduce_train, reduce_test, features):\n",
    "    to_exclude = [] \n",
    "    ajusted_test = reduce_test.copy()\n",
    "    for feature in features:\n",
    "        if feature not in ['accuracy_group', 'installation_id', 'session_title', 'hightest_level']:\n",
    "            data = reduce_train[feature]\n",
    "            train_mean = data.mean()\n",
    "            data = ajusted_test[feature] \n",
    "            test_mean = data.mean()\n",
    "            try:\n",
    "                ajust_factor = train_mean / test_mean\n",
    "                if ajust_factor > 10 or ajust_factor < 0.1:# or error > 0.01:\n",
    "                    to_exclude.append(feature)\n",
    "                    print(feature)\n",
    "                else:\n",
    "                    ajusted_test[feature] *= ajust_factor\n",
    "            except:\n",
    "                to_exclude.append(feature)\n",
    "                print(feature)\n",
    "    return to_exclude, ajusted_test\n",
    "features = [i for i in new_train.columns if i not in [\"game_session\"]]\n",
    "to_exclude, ajusted_test = exclude(new_train, new_test, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(train):\n",
    "    X_train = train.drop(['accuracy_group'],axis=1) \n",
    "    y_train = train.accuracy_group.copy()\n",
    "    y_train.loc[y_train <=1] = 0\n",
    "    y_train.loc[y_train >=2] = 1\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(X_train[\"installation_id\"]))\n",
    "    X_train[\"installation_id\"] = lbl.transform(list(X_train[\"installation_id\"]))\n",
    "    remove_features = [i for i in X_train.columns if \"_4235\" in i or i == \"world_\"+str(activities_world[\"NONE\"])\n",
    "                      or i in to_exclude]\n",
    "    for i in X_train.columns:\n",
    "        if X_train[i].std() == 0 and i not in remove_features:\n",
    "            remove_features.append(i)\n",
    "    X_train = X_train.drop(remove_features, axis=1)\n",
    "    X_train = X_train[sorted(X_train.columns.tolist())]\n",
    "\n",
    "    n_folds=5\n",
    "    skf=GroupKFold(n_splits = n_folds)\n",
    "    models = []\n",
    "    lgbm_params = {'objective': 'binary','eval_metric': 'auc','metric': 'auc', 'boosting_type': 'gbdt',\n",
    " 'tree_learner': 'serial','bagging_fraction': 0.9605425291685099,'bagging_freq': 4,'colsample_bytree': 0.6784238046856443,\n",
    " 'feature_fraction': 1,'learning_rate': 0.017891320270412462,'max_depth': 7,\n",
    " 'min_data_in_leaf': 8,'min_sum_hessian_in_leaf': 17,'num_leaves': 17}\n",
    "\n",
    "    valid = pd.DataFrame(np.zeros([X_train.shape[0]]))\n",
    "    features_list = [i for i in X_train.columns if i != \"installation_id\"]\n",
    "    feature_importance_df = pd.DataFrame(features_list, columns=[\"Feature\"])\n",
    "    for i , (train_index, test_index) in enumerate(skf.split(X_train, y_train, X_train[\"installation_id\"])):\n",
    "        print(\"Fold \"+str(i+1))\n",
    "        X_train2 = X_train.iloc[train_index,:]\n",
    "        y_train2 = y_train.iloc[train_index]\n",
    "        X_train2 = X_train2.drop(['installation_id'],axis=1)\n",
    "    \n",
    "        X_test2 = X_train.iloc[test_index,:]\n",
    "        y_test2 = y_train.iloc[test_index]\n",
    "        X_test2 = X_test2.drop(['installation_id'],axis=1)\n",
    "            \n",
    "        lgb_train = lgb.Dataset(X_train2, y_train2)\n",
    "        lgb_eval = lgb.Dataset(X_test2, y_test2, reference=lgb_train)\n",
    "        clf = lgb.train(lgbm_params, lgb_train,valid_sets=[lgb_train, lgb_eval],\n",
    "            num_boost_round=10000,early_stopping_rounds=100,verbose_eval = 500,categorical_feature = categoricals)\n",
    "        test_predict = clf.predict(X_test2, num_iteration = clf.best_iteration)\n",
    "        valid.iloc[test_index] = test_predict.reshape(X_test2.shape[0], 1)\n",
    "        feature_importance_df[\"Fold_\"+str(i+1)] = clf.feature_importance()\n",
    "                \n",
    "    print(\"logloss = \\t {}\".format(log_loss(y_train, valid)))\n",
    "    print(\"ROC = \\t {}\".format(roc_auc_score(y_train, valid)))\n",
    "    feature_importance_df[\"Average\"] = np.mean(feature_importance_df.iloc[:,1:n_folds+1], axis=1)\n",
    "    feature_importance_df[\"Std\"] = np.std(feature_importance_df.iloc[:,1:n_folds+1], axis=1)\n",
    "    feature_importance_df[\"Cv\"] = feature_importance_df[\"Std\"] / feature_importance_df[\"Average\"]\n",
    "    return feature_importance_df\n",
    "#df_for_classification = feature_selection(new_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_class(train, test, fea, select_flg):\n",
    "    X_train = train.drop(['accuracy_group'],axis=1) \n",
    "    y_train = train.accuracy_group.copy()\n",
    "    y_train.loc[y_train <=1] = 0\n",
    "    y_train.loc[y_train >=2] = 1\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(X_train[\"installation_id\"]))\n",
    "    X_train[\"installation_id\"] = lbl.transform(list(X_train[\"installation_id\"]))\n",
    "    remove_features = [i for i in X_train.columns if \"_4235\" in i or i == \"world_\"+str(activities_world[\"NONE\"])\n",
    "                      or i in to_exclude ]\n",
    "    for i in X_train.columns:\n",
    "        if X_train[i].std() == 0 and i not in remove_features:\n",
    "            remove_features.append(i)\n",
    "    X_train = X_train.drop(remove_features, axis=1)\n",
    "    if select_flg == True:\n",
    "        X_train = X_train[fea]\n",
    "    X_train = X_train[sorted(X_train.columns.tolist())]\n",
    "\n",
    "    X_test = test.drop([\"installation_id\",\"accuracy_group\"], axis=1)\n",
    "    X_test = X_test.drop(remove_features, axis=1)\n",
    "    if select_flg == True:\n",
    "        X_test = X_test[fea]\n",
    "    X_test = X_test[sorted(X_test.columns.tolist())]\n",
    "    print(X_test.shape[1])\n",
    "    \n",
    "    n_folds=5\n",
    "    skf=GroupKFold(n_splits = n_folds)\n",
    "    models = []\n",
    "    lgbm_params = {'objective': 'binary','eval_metric': 'auc','metric': 'auc', 'boosting_type': 'gbdt',\n",
    " 'tree_learner': 'serial','bagging_fraction': 0.9605425291685099,'bagging_freq': 4,'colsample_bytree': 0.6784238046856443,\n",
    " 'feature_fraction': 1,'learning_rate': 0.017891320270412462,'max_depth': 7,\n",
    " 'min_data_in_leaf': 8,'min_sum_hessian_in_leaf': 17,'num_leaves': 17}\n",
    "\n",
    "    valid = pd.DataFrame(np.zeros([X_train.shape[0]]))\n",
    "    for i , (train_index, test_index) in enumerate(skf.split(X_train, y_train, X_train[\"installation_id\"])):\n",
    "        print(\"Fold \"+str(i+1))\n",
    "        X_train2 = X_train.iloc[train_index,:]\n",
    "        y_train2 = y_train.iloc[train_index]\n",
    "        X_train2 = X_train2.drop(['installation_id'],axis=1)\n",
    "    \n",
    "        X_test2 = X_train.iloc[test_index,:]\n",
    "        y_test2 = y_train.iloc[test_index]\n",
    "        X_test2 = X_test2.drop(['installation_id'],axis=1)\n",
    "        if select_flg == True:\n",
    "            X_train2 = X_train2[fea] \n",
    "            X_test2 = X_test2[fea]\n",
    "            \n",
    "        lgb_train = lgb.Dataset(X_train2, y_train2)\n",
    "        lgb_eval = lgb.Dataset(X_test2, y_test2, reference=lgb_train)\n",
    "        \n",
    "        clf = lgb.train(lgbm_params, lgb_train,valid_sets=[lgb_train, lgb_eval],\n",
    "            num_boost_round=10000,early_stopping_rounds=100,verbose_eval = 500,categorical_feature = categoricals)\n",
    "        test_predict = clf.predict(X_test2, num_iteration = clf.best_iteration)\n",
    "        models.append(clf)\n",
    "        valid.iloc[test_index] = test_predict.reshape(X_test2.shape[0], 1)\n",
    "                \n",
    "    print(\"logloss = \\t {}\".format(log_loss(y_train, valid)))\n",
    "    print(\"ROC = \\t {}\".format(roc_auc_score(y_train, valid)))\n",
    "    print('Accuracy score = \\t {}'.format(accuracy_score(y_train, np.round(valid))))\n",
    "    print('Precision score = \\t {}'.format(precision_score(y_train, np.round(valid))))\n",
    "    print('Recall score =   \\t {}'.format(recall_score(y_train, np.round(valid))))\n",
    "    print('F1 score =      \\t {}'.format(f1_score(y_train, np.round(valid))))\n",
    "    print(confusion_matrix(y_train, np.round(valid)))\n",
    "    pred_value = np.zeros([X_test.shape[0]])\n",
    "    for model in models:\n",
    "        pred_value += model.predict(X_test, num_iteration = model.best_iteration) / len(models)\n",
    "    return pred_value, valid\n",
    "\n",
    "#tmp = df_for_classification.sort_values(\"Cv\", ascending = True).reset_index(drop=True).copy()\n",
    "#feat = tmp[tmp.index <= 120][\"Feature\"]\n",
    "#feat = []\n",
    "#pred_value, valid = accuracy_class(new_train, new_test, feat, False)\n",
    "#pred_value, valid = accuracy_class(mod_train, new_test, feat, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score = 0\n",
    "#for i in range(10):\n",
    "#    optR = OptimizedRounder_cla()\n",
    "#    #optR.fit(np.array(valid).reshape(-1,), new_train.accuracy_group, random_flg=True)\n",
    "#    optR.fit(np.array(valid).reshape(-1,), mod_train.accuracy_group, random_flg=True)\n",
    "#    coefficients = optR.coefficients()\n",
    "#    final_valid_pred = optR.predict(np.array(valid).reshape(-1,), coefficients)\n",
    "    #score = qwk(new_train.accuracy_group, final_valid_pred)\n",
    "    #score = qwk(mod_train.accuracy_group, final_valid_pred)\n",
    "#    print(i, np.sort(coefficients), score)\n",
    "#    if score > best_score:\n",
    "#        best_score = score\n",
    "#        best_coefficients = coefficients\n",
    "#final_test_pred = pd.cut(np.array(pred_value).reshape(-1,), [-np.inf] + list(np.sort(best_coefficients)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "#final_test_pred = pd.cut(np.array(pred_value).reshape(-1,), [-np.inf] + list(np.sort([0.31635244, 0.54903181, 0.74679975])) + [np.inf], labels = [0, 1, 2, 3])\n",
    "\n",
    "#sample_submission[\"accuracy_group\"] = final_test_pred.astype(int)\n",
    "#sample_submission.to_csv('submission.csv', index=False)\n",
    "#sample_submission[\"accuracy_group\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# truncated version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection_mod(train):\n",
    "    X_train = train.drop(['accuracy_group'],axis=1) \n",
    "    y_train = train.accuracy_group.copy()\n",
    "    y_train.loc[y_train <=1] = 0\n",
    "    y_train.loc[y_train >=2] = 1\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(X_train[\"installation_id\"]))\n",
    "    X_train[\"installation_id\"] = lbl.transform(list(X_train[\"installation_id\"]))\n",
    "    remove_features = [i for i in X_train.columns if \"_4235\" in i or i == \"world_\"+str(activities_world[\"NONE\"])\n",
    "                      or i in to_exclude]\n",
    "    for i in X_train.columns:\n",
    "        if X_train[i].std() == 0 and i not in remove_features:\n",
    "            remove_features.append(i)\n",
    "    X_train = X_train.drop(remove_features, axis=1)\n",
    "    X_train = X_train[sorted(X_train.columns.tolist())]\n",
    "\n",
    "    n_folds=5\n",
    "    skf=GroupKFold(n_splits = n_folds)\n",
    "    models = []\n",
    "    lgbm_params = {'objective': 'binary','eval_metric': 'auc','metric': 'auc', 'boosting_type': 'gbdt',\n",
    " 'tree_learner': 'serial','bagging_fraction': 0.9605425291685099,'bagging_freq': 4,'colsample_bytree': 0.6784238046856443,\n",
    " 'feature_fraction': 1,'learning_rate': 0.017891320270412462,'max_depth': 7,\n",
    " 'min_data_in_leaf': 8,'min_sum_hessian_in_leaf': 17,'num_leaves': 17}\n",
    "\n",
    "    valid = pd.DataFrame(np.zeros([X_train.shape[0]]))\n",
    "    features_list = [i for i in X_train.columns if i != \"installation_id\"]\n",
    "    feature_importance_df = pd.DataFrame(features_list, columns=[\"Feature\"])\n",
    "    random_try = 10\n",
    "    for try_time in range(random_try):\n",
    "        valid = np.array([])\n",
    "        real = np.array([])\n",
    "        for i , (train_index, test_index) in enumerate(skf.split(X_train, y_train, X_train[\"installation_id\"])):\n",
    "            print(\"Fold \"+str(i+1))\n",
    "            X_train2 = X_train.iloc[train_index,:]\n",
    "            y_train2 = y_train.iloc[train_index]\n",
    "            X_train2 = X_train2.drop(['installation_id'],axis=1)\n",
    "    \n",
    "            X_test2 = X_train.iloc[test_index,:]\n",
    "            y_test2 = y_train.iloc[test_index]\n",
    "            print(\"Before truncation:\", (X_test2.shape, y_test2.shape))\n",
    "            X_test2['accuracy_group'] = y_test2\n",
    "            np.random.seed(try_time)\n",
    "            X_test2 = X_test2.groupby('installation_id').agg(np.random.choice).reset_index(drop=False)\n",
    "            y_test2 = X_test2.accuracy_group.copy()\n",
    "            X_test2.drop([\"accuracy_group\"], axis=1, inplace=True)\n",
    "            print(\"After truncation:\", (X_test2.shape, y_test2.shape))\n",
    "            X_test2 = X_test2.drop(['installation_id'],axis=1)\n",
    "            \n",
    "            lgb_train = lgb.Dataset(X_train2, y_train2)\n",
    "            lgb_eval = lgb.Dataset(X_test2, y_test2, reference=lgb_train)\n",
    "            clf = lgb.train(lgbm_params, lgb_train,valid_sets=[lgb_train, lgb_eval],\n",
    "                num_boost_round=10000,early_stopping_rounds=100,verbose_eval = 500,categorical_feature = categoricals)\n",
    "            valid_predict = clf.predict(X_test2, num_iteration = clf.best_iteration).reshape(X_test2.shape[0], )\n",
    "            #mean_score += average_precision_score(y_test2,valid_predict) / n_folds\n",
    "            valid = np.concatenate([valid, valid_predict])\n",
    "            real = np.concatenate([real, y_test2])\n",
    "            feature_importance_df[\"Fold_\"+str(i+1)] = clf.feature_importance()\n",
    "                \n",
    "        print(\"logloss = \\t {}\".format(log_loss(real, valid)))\n",
    "        print(\"ROC = \\t {}\".format(roc_auc_score(real, valid)))\n",
    "        feature_importance_df[\"Average\"] = np.mean(feature_importance_df.iloc[:,1:n_folds+1], axis=1)\n",
    "        feature_importance_df[\"Std\"] = np.std(feature_importance_df.iloc[:,1:n_folds+1], axis=1)\n",
    "        feature_importance_df[\"Cv\"] = feature_importance_df[\"Std\"] / feature_importance_df[\"Average\"]\n",
    "    return feature_importance_df\n",
    "#df_for_classification = feature_selection_mod(new_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_random_assessment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f126f92e7512>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;31m#feat = tmp[tmp.index <= 120][\"Feature\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m \u001b[0mpred_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_coefficients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_class_mod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0mfinal_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_coefficients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m#final_test_pred = pd.cut(np.array(pred_value).reshape(-1,), [-np.inf] + list(np.sort([0.32229148, 0.51887455, 0.77529457])) + [np.inf], labels = [0, 1, 2, 3])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-f126f92e7512>\u001b[0m in \u001b[0;36maccuracy_class_mod\u001b[0;34m(train, test, fea, select_flg)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0my_test2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mX_test2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_random_assessment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mtmp_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"past_target\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mX_test2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'installation_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'past_target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_random_assessment' is not defined"
     ]
    }
   ],
   "source": [
    "def accuracy_class_mod(train, test, fea, select_flg):\n",
    "    #X_train = train.drop([\"accuracy_group\"],axis=1) \n",
    "    y_train = train.accuracy_group.copy()\n",
    "    X_train = train.rename(columns={\"accuracy_group\": \"past_target\"})\n",
    "    y_train.loc[y_train <=1] = 0\n",
    "    y_train.loc[y_train >=2] = 1\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(X_train[\"installation_id\"]))\n",
    "    X_train[\"installation_id\"] = lbl.transform(list(X_train[\"installation_id\"]))\n",
    "    remove_features = [i for i in X_train.columns if \"_4235\" in i or i == \"world_\"+str(activities_world[\"NONE\"])\n",
    "                      or i in to_exclude]\n",
    "    for i in X_train.columns:\n",
    "        if X_train[i].std() == 0 and i not in remove_features:\n",
    "            remove_features.append(i)\n",
    "    X_train = X_train.drop(remove_features, axis=1)\n",
    "    if select_flg == True:\n",
    "        X_train = X_train[fea]\n",
    "    X_train = X_train[sorted(X_train.columns.tolist())]\n",
    "\n",
    "    X_test = test.drop([\"installation_id\",\"accuracy_group\"], axis=1)\n",
    "    X_test = X_test.drop(remove_features, axis=1)\n",
    "    if select_flg == True:\n",
    "        X_test = X_test[fea]\n",
    "    X_test = X_test[sorted(X_test.columns.tolist())]\n",
    "    \n",
    "    n_folds = 10\n",
    "    skf=GroupKFold(n_splits = n_folds)\n",
    "    models = []\n",
    "    lgbm_params = {'objective': 'binary','eval_metric': 'auc','metric': 'auc', 'boosting_type': 'gbdt',\n",
    " 'tree_learner': 'serial','bagging_fraction': 0.5698056418890787,'bagging_freq': 4,\n",
    " 'colsample_bytree': 0.37564408454469,'learning_rate': 0.015433389422506185,'max_depth': 8,\n",
    " 'min_data_in_leaf': 51,'min_sum_hessian_in_leaf': 10,'num_leaves': 48}\n",
    "    random_try = 5\n",
    "    mean_qwk_score = 0\n",
    "    for try_time in range(random_try):\n",
    "        # model learning ---------------------------\n",
    "        for i , (train_index, test_index) in enumerate(skf.split(X_train, y_train, X_train[\"installation_id\"])):\n",
    "            target = np.array([])\n",
    "            print(\"Fold \"+str(i+1))\n",
    "            X_train2 = X_train.iloc[train_index,:]\n",
    "            y_train2 = y_train.iloc[train_index]\n",
    "            X_train2 = X_train2.drop(['installation_id', 'past_target'],axis=1)\n",
    "    \n",
    "            X_test2 = X_train.iloc[test_index,:]\n",
    "            y_test2 = y_train.iloc[test_index]\n",
    "            \n",
    "            X_test2, idx_val = get_random_assessment(X_test2)\n",
    "            tmp_target = X_test2.loc[idx_val][\"past_target\"]\n",
    "            X_test2.drop(['installation_id', 'past_target'], inplace=True, axis=1)\n",
    "            y_test2 = y_test2.loc[idx_val]\n",
    "            print(\"After truncation:\", (X_test2.shape, y_test2.shape))\n",
    "            \n",
    "            lgb_train = lgb.Dataset(X_train2, y_train2)\n",
    "            lgb_eval = lgb.Dataset(X_test2, y_test2, reference=lgb_train)\n",
    "            clf = lgb.train(lgbm_params, lgb_train,valid_sets=[lgb_train, lgb_eval],\n",
    "                num_boost_round=10000,early_stopping_rounds=100,verbose_eval = 500,categorical_feature = categoricals)\n",
    "            valid = np.array(clf.predict(X_test2, num_iteration = clf.best_iteration).reshape(X_test2.shape[0], ))\n",
    "            real = np.array(y_test2)\n",
    "            target = np.array(tmp_target)\n",
    "            \n",
    "            models.append(clf)\n",
    "            print(\"logloss = \\t {}\".format(log_loss(real, valid)))\n",
    "            print(\"ROC = \\t {}\".format(roc_auc_score(real, valid)))\n",
    "        \n",
    "            # threshold optimization --------------\n",
    "            best_score = 0\n",
    "            for i in range(20):\n",
    "                optR = OptimizedRounder_cla()\n",
    "                optR.fit(np.array(valid).reshape(-1,), target, random_flg=True)\n",
    "                coefficients = optR.coefficients()\n",
    "                final_valid_pred = optR.predict(np.array(valid).reshape(-1,), coefficients)\n",
    "                score = qwk(target, final_valid_pred)\n",
    "                print(i, np.sort(coefficients), score)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_coefficients = coefficients\n",
    "            mean_qwk_score += best_score / (random_try * n_folds)\n",
    "            if try_time == 0:\n",
    "                final_coefficients = np.sort(best_coefficients) / (random_try * n_folds)\n",
    "            else:\n",
    "                final_coefficients += np.sort(best_coefficients) / (random_try * n_folds)\n",
    "            \n",
    "    print(\"MEAN QWK = \\t {}\".format(mean_qwk_score))\n",
    "    # test prediction  ------------------------\n",
    "    pred_value = np.zeros([X_test.shape[0]])\n",
    "    for model in models:\n",
    "        pred_value += model.predict(X_test, num_iteration = model.best_iteration) / len(models)\n",
    "    return pred_value, valid, final_coefficients\n",
    "\n",
    "#tmp = df_for_classification.sort_values(\"Cv\", ascending = True).reset_index(drop=True).copy()\n",
    "#feat = tmp[tmp.index <= 120][\"Feature\"]\n",
    "feat = []\n",
    "pred_value, valid, final_coefficients = accuracy_class_mod(new_train, new_test, feat, False)\n",
    "final_test_pred = pd.cut(np.array(pred_value).reshape(-1,), [-np.inf] + list(np.sort(final_coefficients)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "#final_test_pred = pd.cut(np.array(pred_value).reshape(-1,), [-np.inf] + list(np.sort([0.32229148, 0.51887455, 0.77529457])) + [np.inf], labels = [0, 1, 2, 3])\n",
    "\n",
    "sample_submission[\"accuracy_group\"] = final_test_pred.astype(int)\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission[\"accuracy_group\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/jakubwasikowski/stratified-group-k-fold-cross-validation\n",
    "from collections import defaultdict\n",
    "\n",
    "def stratified_group_k_fold(X, y, groups, k, seed=None):\n",
    "    labels_num = np.max(y) + 1\n",
    "    y_counts_per_group = defaultdict(lambda: np.zeros(labels_num))\n",
    "    y_distr = Counter()\n",
    "    for label, g in zip(y, groups):\n",
    "        y_counts_per_group[g][label] += 1\n",
    "        y_distr[label] += 1\n",
    "\n",
    "    y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num))\n",
    "    groups_per_fold = defaultdict(set)\n",
    "\n",
    "    def eval_y_counts_per_fold(y_counts, fold):\n",
    "        y_counts_per_fold[fold] += y_counts\n",
    "        std_per_label = []\n",
    "        for label in range(labels_num):\n",
    "            label_std = np.std([y_counts_per_fold[i][label] / y_distr[label] for i in range(k)])\n",
    "            std_per_label.append(label_std)\n",
    "        y_counts_per_fold[fold] -= y_counts\n",
    "        return np.mean(std_per_label)\n",
    "    \n",
    "    groups_and_y_counts = list(y_counts_per_group.items())\n",
    "    random.Random(seed).shuffle(groups_and_y_counts)\n",
    "\n",
    "    for g, y_counts in sorted(groups_and_y_counts, key=lambda x: -np.std(x[1])):\n",
    "        best_fold = None\n",
    "        min_eval = None\n",
    "        for i in range(k):\n",
    "            fold_eval = eval_y_counts_per_fold(y_counts, i)\n",
    "            if min_eval is None or fold_eval < min_eval:\n",
    "                min_eval = fold_eval\n",
    "                best_fold = i\n",
    "        y_counts_per_fold[best_fold] += y_counts\n",
    "        groups_per_fold[best_fold].add(g)\n",
    "\n",
    "    all_groups = set(groups)\n",
    "    for i in range(k):\n",
    "        train_groups = all_groups - groups_per_fold[i]\n",
    "        test_groups = groups_per_fold[i]\n",
    "\n",
    "        train_indices = [i for i, g in enumerate(groups) if g in train_groups]\n",
    "        test_indices = [i for i, g in enumerate(groups) if g in test_groups]\n",
    "\n",
    "        yield train_indices, test_indices\n",
    "        \n",
    "def get_random_assessment(reduce_train):\n",
    "    used_idx = []\n",
    "    for iid in tqdm(set(reduce_train['installation_id']), miniters=200):\n",
    "        list_ = list(reduce_train[reduce_train['installation_id'] == iid].index)\n",
    "        cur = random.choices(list_, k=1)[0]\n",
    "        used_idx.append(cur)\n",
    "    reduce_train_t = reduce_train.loc[used_idx]\n",
    "    return reduce_train_t, used_idx\n",
    "\n",
    "def modelling_sgk_reg(train, test, feat, select_flg): # stratify by target, group by session_id\n",
    "    lgbm_params = {'objective': 'regression', 'boosting_type': 'gbdt',\n",
    "     'tree_learner': 'serial','bagging_fraction': 0.5698056418890787,'bagging_freq': 4,\n",
    "     'colsample_bytree': 0.37564408454469,'learning_rate': 0.015433389422506185,'max_depth': 8,\n",
    "     'min_data_in_leaf': 51,'min_sum_hessian_in_leaf': 10,'num_leaves': 48}\n",
    "\n",
    "    y_train = train.accuracy_group.copy()\n",
    "    X_train = train.drop([\"accuracy_group\"],axis=1) \n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(X_train[\"installation_id\"]))\n",
    "    X_train[\"installation_id\"] = lbl.transform(list(X_train[\"installation_id\"]))\n",
    "    remove_features = [i for i in X_train.columns if \"_4235\" in i or i == \"world_\"+str(activities_world[\"NONE\"])\n",
    "                      or i in to_exclude]\n",
    "    for i in X_train.columns:\n",
    "        if X_train[i].std() == 0 and i not in remove_features:\n",
    "            remove_features.append(i)\n",
    "    X_train = X_train.drop(remove_features, axis=1)\n",
    "    if select_flg == True:\n",
    "        X_train = X_train[fea]\n",
    "    X_train = X_train[sorted(X_train.columns.tolist())]\n",
    "\n",
    "    X_test = test.drop([\"installation_id\",\"accuracy_group\"], axis=1)\n",
    "    X_test = X_test.drop(remove_features, axis=1)\n",
    "    if select_flg == True:\n",
    "        X_test = X_test[fea]\n",
    "    X_test = X_test[sorted(X_test.columns.tolist())]\n",
    "    groups = np.array(X_train.installation_id.values)\n",
    "\n",
    "    models = []\n",
    "    random_try = 1\n",
    "    n_folds = 10\n",
    "    evals_result = {}\n",
    "    mean_qwk_score = 0\n",
    "    for try_time in range(random_try):\n",
    "        for i, (train_index, test_index) in enumerate(stratified_group_k_fold(X_train, y_train, groups, k=n_folds, seed=12)):\n",
    "            print(\"Fold \"+str(i+1))\n",
    "            X_train2 = X_train.iloc[train_index,:]\n",
    "            y_train2 = y_train.iloc[train_index]\n",
    "            X_train2.drop(\"installation_id\", axis=1, inplace=True)\n",
    "\n",
    "            X_test2 = X_train.iloc[test_index,:]\n",
    "            y_test2 = y_train.iloc[test_index]\n",
    "            \n",
    "            X_test2, idx_val = get_random_assessment(X_test2)\n",
    "            X_test2.drop('installation_id', inplace=True, axis=1)\n",
    "            y_test2 = y_test2.loc[idx_val]\n",
    "\n",
    "            lgb_train = lgb.Dataset(X_train2, y_train2)\n",
    "            lgb_eval = lgb.Dataset(X_test2, y_test2, reference=lgb_train)\n",
    "            clf = lgb.train(lgbm_params, lgb_train,valid_sets=[lgb_train, lgb_eval],\n",
    "                num_boost_round=10000,early_stopping_rounds=100,verbose_eval = 500, categorical_feature = categoricals)\n",
    "            valid = np.array(clf.predict(X_test2, num_iteration = clf.best_iteration))\n",
    "            real = np.array(y_test2)\n",
    "\n",
    "            models.append(clf)\n",
    "            rmse = np.sqrt(mean_squared_error(real, valid))\n",
    "            print(\"RMSE = {}\".format(rmse))\n",
    "            \n",
    "            # threshold optimization --------------\n",
    "            best_score = 0\n",
    "            for i in range(20):\n",
    "                optR = OptimizedRounder_reg()\n",
    "                optR.fit(np.array(valid).reshape(-1,), real, random_flg=True)\n",
    "                coefficients = optR.coefficients()\n",
    "                final_valid_pred = optR.predict(np.array(valid).reshape(-1,), coefficients)\n",
    "                score = qwk(real, final_valid_pred)\n",
    "                print(i, np.sort(coefficients), score)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_coefficients = coefficients\n",
    "            mean_qwk_score += best_score / (random_try * n_folds)\n",
    "            if try_time == 0:\n",
    "                final_coefficients = np.sort(best_coefficients) / (random_try * n_folds)\n",
    "            else:\n",
    "                final_coefficients += np.sort(best_coefficients) / (random_try * n_folds)\n",
    "\n",
    "    print(\"mean QWK = {}\".format(mean_qwk_score))\n",
    "    pred_value = np.zeros(X_test.shape[0])\n",
    "    for model in models:\n",
    "        pred_value += model.predict(X_test, num_iteration = model.best_iteration) / len(models)\n",
    "    return mean_qwk_score, pred_value, final_coefficients\n",
    "    \n",
    "#qwk_sgk1, pred_value, final_coefficients = modelling_sgk_reg(new_train, new_test, feat, False)\n",
    "#final_test_pred = pd.cut(np.array(pred_value).reshape(-1,), [-np.inf] + list(np.sort(final_coefficients)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "#final_test_pred = pd.cut(np.array(pred_value).reshape(-1,), [-np.inf] + list(np.sort([0.32229148, 0.51887455, 0.77529457])) + [np.inf], labels = [0, 1, 2, 3])\n",
    "\n",
    "#sample_submission[\"accuracy_group\"] = final_test_pred.astype(int)\n",
    "#sample_submission.to_csv('submission.csv', index=False)\n",
    "#sample_submission[\"accuracy_group\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_hyperopt(X, Y):\n",
    "    def para_tuning_obj(params):\n",
    "        params = {\n",
    "        'boosting_type': 'gbdt', \n",
    "        'metric': \"auc\", \n",
    "        'objective': 'binary', \n",
    "        'eval_metric': 'cappa', \n",
    "        \"tree_learner\": \"serial\",\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'bagging_freq': int(params['bagging_freq']),\n",
    "        'bagging_fraction': float(params['bagging_fraction']),\n",
    "        'num_leaves': int(params['num_leaves']),\n",
    "        'learning_rate': float(params['learning_rate']),\n",
    "        'min_data_in_leaf': int(params['min_data_in_leaf']),\n",
    "        'min_sum_hessian_in_leaf': int(params['min_sum_hessian_in_leaf']),\n",
    "        'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n",
    "}\n",
    "    \n",
    "        real = np.array([])\n",
    "        pred = np.array([])\n",
    "        skf = GroupKFold(n_splits=10)\n",
    "        for trn_idx, val_idx in skf.split(X, Y, X[\"installation_id\"]):\n",
    "            x_train, x_val = X.iloc[trn_idx, :], X.iloc[val_idx, :]\n",
    "            y_train, y_val = Y.iloc[trn_idx], Y.iloc[val_idx]\n",
    "            x_val['accuracy_group'] = y_val\n",
    "            np.random.seed(0)\n",
    "            x_val_mod = x_val.groupby('installation_id').agg(np.random.choice).reset_index(drop=False)\n",
    "            y_val_mod = x_val_mod.accuracy_group.copy()\n",
    "            x_train.drop('installation_id', inplace = True, axis = 1)\n",
    "            x_val_mod.drop(['installation_id', \"accuracy_group\"], inplace = True, axis = 1)\n",
    "            train_set = lgb.Dataset(x_train, y_train, categorical_feature = ['session_title'])\n",
    "            val_set = lgb.Dataset(x_val_mod, y_val_mod, categorical_feature = ['session_title'])\n",
    "        \n",
    "            clf = lgb.train(params, train_set, num_boost_round = 100000, early_stopping_rounds = 100, \n",
    "                         valid_sets = [train_set, val_set], verbose_eval = 300)\n",
    "            pred = np.concatenate((pred, np.array(clf.predict(x_val_mod, num_iteration = clf.best_iteration))), axis=0) \n",
    "            real = np.concatenate((real, np.array(y_val_mod)), axis=0) \n",
    "        score = roc_auc_score(real, pred)\n",
    "    \n",
    "        return - score\n",
    "\n",
    "    trials = Trials()\n",
    "\n",
    "    space ={\n",
    "        'max_depth': hp.quniform('max_depth', 1, 15, 1),\n",
    "        'bagging_freq': hp.quniform('bagging_freq', 1, 10, 1),\n",
    "        'bagging_fraction': hp.uniform('bagging_fraction', 0.2, 1.0),\n",
    "        'num_leaves': hp.quniform('num_leaves', 8, 64, 1),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.001, 0.1),\n",
    "        'min_data_in_leaf': hp.quniform('min_data_in_leaf', 8, 64, 1),\n",
    "        'min_sum_hessian_in_leaf': hp.quniform('min_sum_hessian_in_leaf', 5, 30, 1),\n",
    "        'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0)\n",
    "    }\n",
    "\n",
    "    best = fmin(para_tuning_obj, space = space, algo=tpe.suggest, max_evals=10, trials=trials, verbose=1)\n",
    "\n",
    "    best_params = space_eval(space, best)\n",
    "    return best_params\n",
    "\n",
    "#X_train = new_train.drop([\"accuracy_group\"], axis=1).copy()\n",
    "#Y = new_train.accuracy_group.copy()\n",
    "#Y.loc[Y <=1] = 0\n",
    "#Y.loc[Y >=2] = 1\n",
    "#lbl = preprocessing.LabelEncoder()\n",
    "#lbl.fit(list(X_train[\"installation_id\"]))\n",
    "#X_train[\"installation_id\"] = lbl.transform(list(X_train[\"installation_id\"]))\n",
    "#remove_features = [i for i in X_train.columns if \"_4235\" in i or i == \"world_\"+str(activities_world[\"NONE\"])\n",
    "#                      or i in to_exclude]\n",
    "#for i in X_train.columns:\n",
    "#    if X_train[i].std() == 0 and i not in remove_features:\n",
    "#        remove_features.append(i)\n",
    "#X_train = X_train.drop(remove_features, axis=1)\n",
    "#X_train = X_train[sorted(X_train.columns.tolist())]\n",
    "\n",
    "#random_state = 42\n",
    "#my_hyperopt(X_train, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "14abeddbb86747838177dbd5c9b84a26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fc1dc5113a644be3b3c2d20c6562f81e",
       "placeholder": "​",
       "style": "IPY_MODEL_ec85224f0b964c439695983c8e437323",
       "value": " 17000/17000 [13:50&lt;00:00, 20.47it/s]"
      }
     },
     "2d0c70cef96c4643b9f8ebc2a92af2a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Installation_id: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ef2aa41ce8ef4a5387c56598a9828f66",
       "max": 1000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_57b32d84dd054763a3275991b208599c",
       "value": 1000
      }
     },
     "3f2a30549c8d402a9e018d3f6252a3fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "469ee1bb0bfc43a2be942c4cd72be476": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_acddce54c677484d9760c59ed35825f7",
        "IPY_MODEL_14abeddbb86747838177dbd5c9b84a26"
       ],
       "layout": "IPY_MODEL_b0c11acdbc124534aa90ebe4f6effd73"
      }
     },
     "57b32d84dd054763a3275991b208599c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "58dd9442fb8947eebb2980aebfcd5255": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "652bb3ee761e43d7a4bc6b2875330a3e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2d0c70cef96c4643b9f8ebc2a92af2a1",
        "IPY_MODEL_e18bb3c40fe34395b95a306df59b3505"
       ],
       "layout": "IPY_MODEL_a0c0de36c9284ffdafd7f039807369e8"
      }
     },
     "7ffbb2296bb94ee18379a259d471892e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "9b035d08312345e3a0d0e54a286b0154": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a0c0de36c9284ffdafd7f039807369e8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "acddce54c677484d9760c59ed35825f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Installation_id: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3f2a30549c8d402a9e018d3f6252a3fc",
       "max": 17000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7ffbb2296bb94ee18379a259d471892e",
       "value": 17000
      }
     },
     "b0c11acdbc124534aa90ebe4f6effd73": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e18bb3c40fe34395b95a306df59b3505": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_58dd9442fb8947eebb2980aebfcd5255",
       "placeholder": "​",
       "style": "IPY_MODEL_9b035d08312345e3a0d0e54a286b0154",
       "value": " 1000/1000 [01:30&lt;00:00, 11.03it/s]"
      }
     },
     "ec85224f0b964c439695983c8e437323": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ef2aa41ce8ef4a5387c56598a9828f66": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc1dc5113a644be3b3c2d20c6562f81e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
