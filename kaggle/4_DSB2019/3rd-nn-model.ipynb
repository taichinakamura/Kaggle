{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import datetime\n",
    "from time import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "import lightgbm as lgb\n",
    "from functools import partial\n",
    "import json\n",
    "import copy\n",
    "import time\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.max_rows\",1000)\n",
    "np.set_printoptions(precision=8)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "        return -qwk(y, X_p)\n",
    "        \n",
    "    def fit(self, X, y,random_flg=False):\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        if random_flg:\n",
    "            initial_coef = [np.random.uniform(0.5,0.6), np.random.uniform(0.6,0.7), np.random.uniform(0.8,0.9)]\n",
    "        else:\n",
    "            initial_coef = [0.5, 1.5, 2.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "        \n",
    "    def predict(self, X, coef):\n",
    "        return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qwk(a1, a2):\n",
    "    max_rat = 3\n",
    "    a1 = np.asarray(a1, dtype=int)\n",
    "    a2 = np.asarray(a2, dtype=int)\n",
    "    hist1 = np.zeros((max_rat + 1, ))\n",
    "    hist2 = np.zeros((max_rat + 1, ))\n",
    "    o = 0\n",
    "    for k in range(a1.shape[0]):\n",
    "        i, j = a1[k], a2[k]\n",
    "        hist1[i] += 1\n",
    "        hist2[j] += 1\n",
    "        o +=  (i - j) * (i - j)\n",
    "    e = 0\n",
    "    for i in range(max_rat + 1):\n",
    "        for j in range(max_rat + 1):\n",
    "            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n",
    "    e = e / a1.shape[0]\n",
    "    return np.round(1 - o / e, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 12s, sys: 9.02 s, total: 1min 21s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv('../input/data-science-bowl-2019/train.csv')\n",
    "train_labels = pd.read_csv('../input/data-science-bowl-2019/train_labels.csv')\n",
    "test = pd.read_csv('../input/data-science-bowl-2019/test.csv')\n",
    "#specs = pd.read_csv('../input/data-science-bowl-2019/specs.csv')\n",
    "sample_submission = pd.read_csv('../input/data-science-bowl-2019/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_id = train[train.type == \"Assessment\"][['installation_id']].drop_duplicates()\n",
    "train = pd.merge(train, keep_id, on=\"installation_id\", how=\"inner\")\n",
    "train = train[train.installation_id.isin(train_labels.installation_id.unique())]\n",
    "assess_title = ['Mushroom Sorter (Assessment)', 'Bird Measurer (Assessment)',\n",
    "       'Cauldron Filler (Assessment)', 'Cart Balancer (Assessment)', 'Chest Sorter (Assessment)']\n",
    "def remove_index_calc(df):\n",
    "    additional_remove_index = []\n",
    "    for i, session in df.groupby('installation_id', sort=False):\n",
    "        last_row = session.index[-1]\n",
    "        session = session[session.title.isin(assess_title)]\n",
    "        first_row = session.index[-1] + 1\n",
    "        for j in range(first_row, last_row+1):\n",
    "            additional_remove_index.append(j)                \n",
    "    return additional_remove_index\n",
    "additional_remove_index = remove_index_calc(train)\n",
    "train = train[~train.index.isin(additional_remove_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.5 s, sys: 2.72 s, total: 36.2 s\n",
      "Wall time: 36.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def encode_title(train, test):\n",
    "    train['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), train['title'], train['event_code']))\n",
    "    test['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), test['title'], test['event_code']))\n",
    "    list_of_title_eventcode = list(set(train['title_event_code'].unique()).union(set(test['title_event_code'].unique())))\n",
    "    \n",
    "    list_of_eventid = list(set(train['event_id'].unique()).union(set(test['event_id'].unique())))\n",
    "\n",
    "    list_of_user_activities = list(set(train['title'].unique()).union(set(test['title'].unique())))\n",
    "    list_of_event_code = list(set(train['event_code'].unique()).union(set(test['event_code'].unique())))\n",
    "    list_of_worlds = list(set(train['world'].unique()).union(set(test['world'].unique())))\n",
    "    activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n",
    "    activities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\n",
    "    activities_world = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n",
    "    assess_titles = list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(set(test[test['type'] == 'Assessment']['title'].value_counts().index)))\n",
    "    \n",
    "    train['title'] = train['title'].map(activities_map)\n",
    "    test['title'] = test['title'].map(activities_map)\n",
    "    train['world'] = train['world'].map(activities_world)\n",
    "    test['world'] = test['world'].map(activities_world)\n",
    "\n",
    "    win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\n",
    "    win_code[activities_map['Bird Measurer (Assessment)']] = 4110\n",
    "    \n",
    "    train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "    test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "    train[\"misses\"] = train[\"event_data\"].apply(lambda x: json.loads(x)[\"misses\"] if \"\\\"misses\\\"\" in x else np.nan)\n",
    "    test[\"misses\"] = test[\"event_data\"].apply(lambda x: json.loads(x)[\"misses\"] if \"\\\"misses\\\"\" in x else np.nan)\n",
    "    \n",
    "    return train, test, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, activities_world, list_of_title_eventcode, list_of_eventid\n",
    "\n",
    "train, test, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, activities_world, list_of_title_eventcode, list_of_eventid = encode_title(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(user_sample, test_set=False):\n",
    "    last_activity = 0\n",
    "    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "    time_spent_each_act = {actv: 0 for actv in list_of_user_activities}\n",
    "    title_eventcode_count = {str(ele): 0 for ele in list_of_title_eventcode}\n",
    "    eventid_count = {str(ele): 0 for ele in list_of_eventid}\n",
    "    user_world_count = {\"world_\"+str(wor) : 0 for wor in activities_world.values()}\n",
    "    eventcode_count = {str(ele): 0 for ele in list_of_event_code}\n",
    "    \n",
    "    last_session_time_sec = 0\n",
    "    all_assessments = []\n",
    "    accuracy_groups = {\"0\":0, \"1\":0, \"2\":0, \"3\":0}\n",
    "    accumulated_accuracy_group = 0\n",
    "    accumulated_correct_attempts = 0 \n",
    "    accumulated_uncorrect_attempts = 0 \n",
    "    accumulated_actions = 0\n",
    "    counter = 0\n",
    "    time_first_activity = float(user_sample['timestamp'].values[0])\n",
    "    durations = []\n",
    "    miss = 0\n",
    "    crys_game_true = 0; crys_game_false = 0\n",
    "    tree_game_true = 0; tree_game_false = 0\n",
    "    magma_game_true = 0; magma_game_false = 0\n",
    "    crys_game_acc = []; tree_game_acc = []; magma_game_acc = []\n",
    "    crys_act_true = 0; crys_act_false = 0\n",
    "    tree_act_true = 0; tree_act_false = 0\n",
    "    magma_act_true = 0; magma_act_false = 0\n",
    "    crys_act_acc = []; tree_act_acc = []; magma_act_acc = []\n",
    "    #x = np.array([]); y = np.array([])\n",
    "    #game_title = []\n",
    "    #act_title = []\n",
    "        \n",
    "    for i, session in user_sample.groupby('game_session', sort=False):      \n",
    "        session_type = session['type'].iloc[0]\n",
    "        session_title = session['title'].iloc[0]\n",
    "        session_title_text = activities_labels[session_title]\n",
    "        session_world = session[\"world\"].iloc[0]\n",
    "        \n",
    "        # get current session time in seconds\n",
    "        if session_type != 'Assessment':\n",
    "            time_spent = int(session['game_time'].iloc[-1] / 1000)\n",
    "            time_spent_each_act[activities_labels[session_title]] += time_spent   \n",
    "            \n",
    "            if session_type == \"Game\":\n",
    "                true = session['event_data'].str.contains('true').sum()\n",
    "                false = session['event_data'].str.contains('false').sum() \n",
    "                #game_title.append(session_title)\n",
    "                if session_world == activities_world[\"CRYSTALCAVES\"]:\n",
    "                    crys_game_true += true\n",
    "                    crys_game_false += false\n",
    "                    crys_game_acc.append(true / (true + false) if (true + false) != 0 else 0)\n",
    "                elif session_world == activities_world[\"TREETOPCITY\"]:\n",
    "                    tree_game_true += true\n",
    "                    tree_game_false += false\n",
    "                    tree_game_acc.append(true / (true + false) if (true + false) != 0 else 0)\n",
    "                elif session_world == activities_world[\"MAGMAPEAK\"]:\n",
    "                    magma_game_true += true\n",
    "                    magma_game_false += false\n",
    "                    magma_game_acc.append(true / (true + false) if (true + false) != 0 else 0)\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "            if session_type == \"Activity\":\n",
    "                true = session['event_data'].str.contains('true').sum()\n",
    "                false = session['event_data'].str.contains('false').sum() \n",
    "                #act_title.append(session_title)\n",
    "                if session_world == activities_world[\"CRYSTALCAVES\"]:\n",
    "                    crys_act_true += true\n",
    "                    crys_act_false += false\n",
    "                    crys_act_acc.append(true / (true + false) if (true + false) != 0 else 0)\n",
    "                elif session_world == activities_world[\"TREETOPCITY\"]:\n",
    "                    tree_act_true += true\n",
    "                    tree_act_false += false\n",
    "                    tree_act_acc.append(true / (true + false) if (true + false) != 0 else 0)\n",
    "                elif session_world == activities_world[\"MAGMAPEAK\"]:\n",
    "                    magma_act_true += true\n",
    "                    magma_act_false += false\n",
    "                    magma_act_acc.append(true / (true + false) if (true + false) != 0 else 0)\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "        if (session_type == 'Assessment') & (test_set or len(session)>1): # test set or session in train_label\n",
    "            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n",
    "            true_attempts = all_attempts['event_data'].str.contains('true').sum() # true in target assess\n",
    "            false_attempts = all_attempts['event_data'].str.contains('false').sum() # false in target assessment\n",
    "            \n",
    "            # from start of installation_id to the start of target assessment ------------------------\n",
    "            features = user_activities_count.copy() # appearance of each type without duplicates\n",
    "            features.update(time_spent_each_act.copy()) # cumulative gameplay time in each title\n",
    "            features.update(title_eventcode_count.copy()) # apperance of combi of title and event_code\n",
    "            features.update(eventid_count.copy()) # apperance of eventid\n",
    "            features.update(user_world_count.copy()) # appearance of world with duplicates\n",
    "            features.update(eventcode_count.copy()) # appearance of world with duplicates\n",
    "            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n",
    "            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n",
    "            accumulated_correct_attempts += true_attempts \n",
    "            accumulated_uncorrect_attempts += false_attempts\n",
    "            features[\"misses\"] = miss\n",
    "            features['accumulated_actions'] = accumulated_actions\n",
    "            #features[\"crysgame_complete\"] = len(set(game_title).intersection(set(crysgame))) / len(crysgame)\n",
    "            #features[\"treegame_complete\"] = len(set(game_title).intersection(set(treegame))) / len(treegame)      \n",
    "            #features[\"magmagame_complete\"] = len(set(game_title).intersection(set(magmagame))) / len(magmagame)    \n",
    "            #features[\"crysact_complete\"] = len(set(act_title).intersection(set(crysact))) / len(crysact)\n",
    "            #features[\"treeact_complete\"] = len(set(act_title).intersection(set(treeact))) / len(treeact)      \n",
    "            #features[\"magmaact_complete\"] = len(set(act_title).intersection(set(magmaact))) / len(magmaact)   \n",
    "            if session_world == activities_world[\"CRYSTALCAVES\"]:\n",
    "                features[\"game_true\"] = crys_game_true\n",
    "                features[\"game_false\"] = crys_game_false\n",
    "                features['game_accuracy'] = crys_game_true / (crys_game_true + crys_game_false) if (crys_game_true + crys_game_false) != 0 else 0\n",
    "                features[\"game_accuracy_std\"] = np.std(crys_game_acc) if len(crys_game_acc) >=1 else 0\n",
    "                features[\"last_game_acc\"] = crys_game_acc[-1] if len(crys_game_acc) >=1 else 0\n",
    "                features[\"act_true\"] = crys_act_true\n",
    "                features[\"act_false\"] = crys_act_false\n",
    "                features['act_accuracy'] = crys_act_true / (crys_act_true + crys_act_false) if (crys_act_true + crys_act_false) != 0 else 0\n",
    "                features[\"act_accuracy_std\"] = np.std(crys_act_acc) if len(crys_act_acc) >=1 else 0\n",
    "                features[\"last_act_acc\"] = crys_act_acc[-1] if len(crys_act_acc) >=1 else 0\n",
    "                #features[\"gamecomplete_sameworld\"] = features[\"crysgame_complete\"] \n",
    "                #features[\"actcomplete_sameworld\"] = features[\"crysact_complete\"] \n",
    "            elif session_world == activities_world[\"TREETOPCITY\"]:\n",
    "                features[\"game_true\"] = tree_game_true\n",
    "                features[\"game_false\"] = tree_game_false\n",
    "                features['game_accuracy'] = tree_game_true / (tree_game_true + tree_game_false) if (tree_game_true + tree_game_false) != 0 else 0\n",
    "                features[\"game_accuracy_std\"] = np.std(tree_game_acc) if len(tree_game_acc) >=1 else 0\n",
    "                features[\"last_game_acc\"] = tree_game_acc[-1] if len(tree_game_acc) >=1 else 0\n",
    "                features[\"act_true\"] = tree_act_true\n",
    "                features[\"act_false\"] = tree_act_false\n",
    "                features['act_accuracy'] = tree_act_true / (tree_act_true + tree_act_false) if (tree_act_true + tree_act_false) != 0 else 0\n",
    "                features[\"act_accuracy_std\"] = np.std(tree_act_acc) if len(tree_act_acc) >=1 else 0\n",
    "                features[\"last_act_acc\"] = tree_act_acc[-1] if len(tree_act_acc) >=1 else 0\n",
    "                #features[\"gamecomplete_sameworld\"] = features[\"treegame_complete\"] \n",
    "                #features[\"actcomplete_sameworld\"] = features[\"treeact_complete\"] \n",
    "            elif session_world == activities_world[\"MAGMAPEAK\"]:\n",
    "                features[\"game_true\"] = magma_game_true\n",
    "                features[\"game_false\"] = magma_game_false\n",
    "                features['game_accuracy'] = magma_game_true / (magma_game_true + magma_game_false) if (magma_game_true + magma_game_false) != 0 else 0\n",
    "                features[\"game_accuracy_std\"] = np.std(magma_game_acc) if len(magma_game_acc) >=1 else 0\n",
    "                features[\"last_game_acc\"] = magma_game_acc[-1] if len(magma_game_acc) >=1 else 0\n",
    "                features[\"act_true\"] = magma_act_true\n",
    "                features[\"act_false\"] = magma_act_false\n",
    "                features['act_accuracy'] = magma_act_true / (magma_act_true + magma_act_false) if (magma_act_true + magma_act_false) != 0 else 0\n",
    "                features[\"act_accuracy_std\"] = np.std(magma_act_acc) if len(magma_act_acc) >=1 else 0\n",
    "                features[\"last_act_acc\"] = magma_act_acc[-1] if len(magma_act_acc) >=1 else 0\n",
    "                #features[\"gamecomplete_sameworld\"] = features[\"magmagame_complete\"] \n",
    "                #features[\"actcomplete_sameworld\"] = features[\"magmaact_complete\"] \n",
    "\n",
    "            #if len(x[~np.isnan(x)]) >=2:\n",
    "            #    features[\"xstd\"] = np.nanstd(x)\n",
    "            #    features[\"ystd\"] = np.nanstd(y)\n",
    "            #    features[\"xrange\"] = np.nanmax(x) - np.nanmin(x)\n",
    "            #    features[\"yrange\"] = np.nanmax(y) - np.nanmin(y)\n",
    "            #else:\n",
    "            #    features[\"xstd\"] = 0\n",
    "            #    features[\"ystd\"] = 0\n",
    "            #    features[\"xrange\"] = 0\n",
    "            #    features[\"yrange\"] = 0\n",
    "            #features[\"touch_range\"] = features[\"xrange\"] * features[\"yrange\"] \n",
    "            \n",
    "            # from the end of previous assessment to the start of next assessment --------------------------\n",
    "            \n",
    "            # unique type --------------------------------------------------------\n",
    "            features['installation_id'] = session['installation_id'].iloc[-1]\n",
    "            features['session_title'] = session_title\n",
    "            \n",
    "            # nums in target assessment data ------------------------------------------\n",
    "            if durations == []: #span of timestamp in target assessment\n",
    "                features['duration_mean'] = 0\n",
    "            else:\n",
    "                features['duration_mean'] = np.mean(durations)\n",
    "            durations.append((session.iloc[-1, 2] - session.iloc[0, 2]).seconds) \n",
    "            \n",
    "            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "            if accuracy == 0:\n",
    "                features['accuracy_group'] = 0\n",
    "            elif accuracy == 1:\n",
    "                features['accuracy_group'] = 3\n",
    "            elif accuracy == 0.5:\n",
    "                features['accuracy_group'] = 2\n",
    "            else:\n",
    "                features['accuracy_group'] = 1\n",
    "            features.update(accuracy_groups)\n",
    "            accuracy_groups[str(features['accuracy_group'])] += 1\n",
    "            features['accumulated_accuracy_group'] = accumulated_accuracy_group/counter if counter > 0 else 0\n",
    "            accumulated_accuracy_group += features['accuracy_group']\n",
    "            \n",
    "            if test_set:\n",
    "                all_assessments.append(features)\n",
    "            elif true_attempts+false_attempts > 0:# or session.iloc[0][\"installation_id\"] in dummy_id:\n",
    "                all_assessments.append(features)\n",
    "                \n",
    "            counter += 1\n",
    "                        \n",
    "        n_of_title_eventcode = Counter(session['title_event_code']) \n",
    "        for key in n_of_title_eventcode.keys():\n",
    "            title_eventcode_count[str(key)] += n_of_title_eventcode[key]\n",
    "        miss += np.sum(session[\"misses\"])\n",
    "        n_of_eventid = Counter(session['event_id']) \n",
    "        for key in n_of_eventid.keys():\n",
    "            eventid_count[str(key)] += n_of_eventid[key]\n",
    "            \n",
    "        user_world_count[\"world_\"+str(session_world)] += session.shape[0]\n",
    "        \n",
    "        n_of_eventcode = Counter(session['event_code']) \n",
    "        for key in n_of_eventcode.keys():\n",
    "            eventcode_count[str(key)] += n_of_eventcode[key]\n",
    "        \n",
    "        #x = np.concatenate([x, session[\"x\"]], axis=0)\n",
    "        #y = np.concatenate([y, session[\"y\"]], axis=0)\n",
    "\n",
    "        accumulated_actions += len(session)\n",
    "        if last_activity != session_type:\n",
    "            user_activities_count[session_type] += 1\n",
    "            last_activitiy = session_type\n",
    "    if test_set:\n",
    "        return all_assessments[-1]\n",
    "    return all_assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019b324f639b4e61a6b0c733a9d97fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Installation_id', max=3614, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(17690, 892)\n"
     ]
    }
   ],
   "source": [
    "new_train = []\n",
    "for i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort=False)), total=train.installation_id.nunique(), desc='Installation_id', position=0):\n",
    "    new_train += get_data(user_sample)\n",
    "new_train = pd.DataFrame(new_train)\n",
    "print(new_train.shape)\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a347f306d63b482a8c8562eda16ccd5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Installation_id', max=1000, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(1000, 892)\n"
     ]
    }
   ],
   "source": [
    "new_test = []\n",
    "for ins_id, user_sample in tqdm(test.groupby('installation_id', sort=False), total=test.installation_id.nunique(), desc='Installation_id', position=0):\n",
    "    a = get_data(user_sample, test_set=True)\n",
    "    new_test.append(a)   \n",
    "new_test = pd.DataFrame(new_test)\n",
    "print(new_test.shape)\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlations = new_train.corr().abs()\n",
    "#correlations = correlations.mask(np.tril(np.ones(correlations.shape)).astype(np.bool))\n",
    "#correlations = correlations.stack().reset_index()\n",
    "#corr_columns = [\"level_0\", \"level_1\", \"value\"]\n",
    "#correlations.columns = corr_columns\n",
    "#correlations = correlations.sort_values(\"value\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "#high_corr = correlations[correlations[\"value\"] >= 0.995]\n",
    "\n",
    "#high_corr_features = []\n",
    "#for i in range(high_corr.shape[0]):\n",
    "#    if high_corr.iloc[i][\"level_0\"] not in high_corr_features and high_corr.iloc[i][\"level_1\"] not in high_corr_features:\n",
    "#        high_corr_features.append(high_corr.iloc[i][\"level_0\"])\n",
    "#    elif high_corr.iloc[i][\"level_0\"] in high_corr_features and high_corr.iloc[i][\"level_1\"] not in high_corr_features:\n",
    "#        high_corr_features.append(high_corr.iloc[i][\"level_1\"])\n",
    "#    elif high_corr.iloc[i][\"level_0\"] not in high_corr_features and high_corr.iloc[i][\"level_1\"] in high_corr_features:\n",
    "#        high_corr_features.append(high_corr.iloc[i][\"level_0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "features = [i for i in new_train.columns if i not in [\"installation_id\", \"accuracy_group\"]]\n",
    "categoricals = ['session_title']\n",
    "\n",
    "features = features.copy()\n",
    "new_train_nn = new_train.copy()\n",
    "new_test_nn = new_test.copy()\n",
    "if len(categoricals) > 0:\n",
    "    for cat in categoricals:\n",
    "        enc = OneHotEncoder()\n",
    "        train_cats = enc.fit_transform(new_train_nn[[cat]])\n",
    "        test_cats = enc.transform(new_test_nn[[cat]])\n",
    "        cat_cols = ['{}_{}'.format(cat, str(col)) for col in enc.active_features_]\n",
    "        features += cat_cols\n",
    "        train_cats = pd.DataFrame(train_cats.toarray(), columns=cat_cols)\n",
    "        test_cats = pd.DataFrame(test_cats.toarray(), columns=cat_cols)\n",
    "        new_train_nn = pd.concat([new_train_nn, train_cats], axis=1)\n",
    "        new_test_nn = pd.concat([new_test_nn, test_cats], axis=1)\n",
    "    scalar = MinMaxScaler()\n",
    "    new_train_nn[features] = scalar.fit_transform(new_train_nn[features])\n",
    "    new_test_nn[features] = scalar.transform(new_test_nn[features])\n",
    "    \n",
    "X_train = new_train_nn.drop(['accuracy_group'],axis=1) \n",
    "lbl = preprocessing.LabelEncoder()\n",
    "lbl.fit(list(X_train[\"installation_id\"]))\n",
    "X_train[\"installation_id\"] = lbl.transform(list(X_train[\"installation_id\"]))\n",
    "remove_features = []\n",
    "for i in categoricals:\n",
    "    remove_features.append(i)\n",
    "for i in X_train.columns:\n",
    "    if X_train[i].std() == 0 and i not in remove_features:\n",
    "        remove_features.append(i)\n",
    "X_train = X_train.drop(remove_features, axis=1)\n",
    "X_train = X_train[sorted(X_train.columns.tolist())]\n",
    "y_train = new_train.accuracy_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               174000    \n",
      "_________________________________________________________________\n",
      "layer_normalization (LayerNo (None, 200)               400       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "layer_normalization_1 (Layer (None, 100)               200       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                2525      \n",
      "_________________________________________________________________\n",
      "layer_normalization_2 (Layer (None, 25)                50        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 197,301\n",
      "Trainable params: 197,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 14151 samples, validate on 683 samples\n",
      "Epoch 1/100\n",
      "14080/14151 [============================>.] - ETA: 0s - loss: 1.6672\n",
      "Epoch 00001: val_loss improved from inf to 1.12073, saving model to ./nn_model.w8\n",
      "14151/14151 [==============================] - 4s 305us/sample - loss: 1.6650 - val_loss: 1.1207\n",
      "Epoch 2/100\n",
      "14048/14151 [============================>.] - ETA: 0s - loss: 1.3273\n",
      "Epoch 00002: val_loss improved from 1.12073 to 1.11207, saving model to ./nn_model.w8\n",
      "14151/14151 [==============================] - 3s 209us/sample - loss: 1.3274 - val_loss: 1.1121\n",
      "Epoch 3/100\n",
      "14144/14151 [============================>.] - ETA: 0s - loss: 1.2252\n",
      "Epoch 00003: val_loss improved from 1.11207 to 1.10626, saving model to ./nn_model.w8\n",
      "14151/14151 [==============================] - 3s 207us/sample - loss: 1.2252 - val_loss: 1.1063\n",
      "Epoch 4/100\n",
      "14080/14151 [============================>.] - ETA: 0s - loss: 1.1743\n",
      "Epoch 00004: val_loss improved from 1.10626 to 1.10036, saving model to ./nn_model.w8\n",
      "14151/14151 [==============================] - 3s 205us/sample - loss: 1.1738 - val_loss: 1.1004\n",
      "Epoch 5/100\n",
      "14016/14151 [============================>.] - ETA: 0s - loss: 1.1505\n",
      "Epoch 00005: val_loss improved from 1.10036 to 1.09537, saving model to ./nn_model.w8\n",
      "14151/14151 [==============================] - 3s 204us/sample - loss: 1.1511 - val_loss: 1.0954\n",
      "Epoch 6/100\n",
      "13920/14151 [============================>.] - ETA: 0s - loss: 1.1151\n",
      "Epoch 00006: val_loss did not improve from 1.09537\n",
      "14151/14151 [==============================] - 3s 242us/sample - loss: 1.1136 - val_loss: 1.1164\n",
      "Epoch 7/100\n",
      "13952/14151 [============================>.] - ETA: 0s - loss: 1.0998\n",
      "Epoch 00007: val_loss did not improve from 1.09537\n",
      "14151/14151 [==============================] - 3s 204us/sample - loss: 1.1003 - val_loss: 1.1124\n",
      "Epoch 8/100\n",
      "14016/14151 [============================>.] - ETA: 0s - loss: 1.0711\n",
      "Epoch 00008: val_loss did not improve from 1.09537\n",
      "14151/14151 [==============================] - 3s 206us/sample - loss: 1.0701 - val_loss: 1.1063\n",
      "Epoch 9/100\n",
      "14112/14151 [============================>.] - ETA: 0s - loss: 1.0535\n",
      "Epoch 00009: val_loss did not improve from 1.09537\n",
      "14151/14151 [==============================] - 3s 212us/sample - loss: 1.0541 - val_loss: 1.1149\n",
      "Epoch 10/100\n",
      "14112/14151 [============================>.] - ETA: 0s - loss: 1.0503\n",
      "Epoch 00010: val_loss did not improve from 1.09537\n",
      "14151/14151 [==============================] - 3s 203us/sample - loss: 1.0495 - val_loss: 1.0979\n",
      "Epoch 11/100\n",
      "14016/14151 [============================>.] - ETA: 0s - loss: 1.0230\n",
      "Epoch 00011: val_loss did not improve from 1.09537\n",
      "14151/14151 [==============================] - 3s 200us/sample - loss: 1.0224 - val_loss: 1.1157\n",
      "Epoch 12/100\n",
      "14048/14151 [============================>.] - ETA: 0s - loss: 1.0084\n",
      "Epoch 00012: val_loss did not improve from 1.09537\n",
      "14151/14151 [==============================] - 3s 204us/sample - loss: 1.0088 - val_loss: 1.1029\n",
      "Epoch 13/100\n",
      "13984/14151 [============================>.] - ETA: 0s - loss: 1.0020\n",
      "Epoch 00013: val_loss did not improve from 1.09537\n",
      "14151/14151 [==============================] - 3s 206us/sample - loss: 1.0006 - val_loss: 1.1095\n",
      "Epoch 14/100\n",
      "14112/14151 [============================>.] - ETA: 0s - loss: 0.9846\n",
      "Epoch 00014: val_loss did not improve from 1.09537\n",
      "14151/14151 [==============================] - 3s 240us/sample - loss: 0.9847 - val_loss: 1.1014\n",
      "Epoch 15/100\n",
      "13888/14151 [============================>.] - ETA: 0s - loss: 0.9594\n",
      "Epoch 00015: val_loss did not improve from 1.09537\n",
      "14151/14151 [==============================] - 3s 230us/sample - loss: 0.9600 - val_loss: 1.1006\n",
      "fold_0 coefficients:  [0.79492689 1.85256542 2.34220376]\n",
      "training qwk:  0.59895697\n",
      "validation qwk:  0.53055483\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 200)               174000    \n",
      "_________________________________________________________________\n",
      "layer_normalization_3 (Layer (None, 200)               400       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "layer_normalization_4 (Layer (None, 100)               200       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 25)                2525      \n",
      "_________________________________________________________________\n",
      "layer_normalization_5 (Layer (None, 25)                50        \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 197,301\n",
      "Trainable params: 197,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 14152 samples, validate on 728 samples\n",
      "Epoch 1/100\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.6792\n",
      "Epoch 00001: val_loss improved from inf to 1.17276, saving model to ./nn_model.w8\n",
      "14152/14152 [==============================] - 4s 281us/sample - loss: 1.6788 - val_loss: 1.1728\n",
      "Epoch 2/100\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.3250\n",
      "Epoch 00002: val_loss improved from 1.17276 to 1.12979, saving model to ./nn_model.w8\n",
      "14152/14152 [==============================] - 3s 205us/sample - loss: 1.3260 - val_loss: 1.1298\n",
      "Epoch 3/100\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.2332\n",
      "Epoch 00003: val_loss improved from 1.12979 to 1.11401, saving model to ./nn_model.w8\n",
      "14152/14152 [==============================] - 3s 205us/sample - loss: 1.2332 - val_loss: 1.1140\n",
      "Epoch 4/100\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.1811\n",
      "Epoch 00004: val_loss did not improve from 1.11401\n",
      "14152/14152 [==============================] - 3s 204us/sample - loss: 1.1825 - val_loss: 1.1190\n",
      "Epoch 5/100\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.1471\n",
      "Epoch 00005: val_loss improved from 1.11401 to 1.09112, saving model to ./nn_model.w8\n",
      "14152/14152 [==============================] - 3s 207us/sample - loss: 1.1473 - val_loss: 1.0911\n",
      "Epoch 6/100\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.1189\n",
      "Epoch 00006: val_loss did not improve from 1.09112\n",
      "14152/14152 [==============================] - 3s 198us/sample - loss: 1.1186 - val_loss: 1.1031\n",
      "Epoch 7/100\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.0870\n",
      "Epoch 00007: val_loss improved from 1.09112 to 1.08744, saving model to ./nn_model.w8\n",
      "14152/14152 [==============================] - 3s 204us/sample - loss: 1.0878 - val_loss: 1.0874\n",
      "Epoch 8/100\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.0781\n",
      "Epoch 00008: val_loss improved from 1.08744 to 1.08345, saving model to ./nn_model.w8\n",
      "14152/14152 [==============================] - 3s 202us/sample - loss: 1.0786 - val_loss: 1.0835\n",
      "Epoch 9/100\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.0494\n",
      "Epoch 00009: val_loss did not improve from 1.08345\n",
      "14152/14152 [==============================] - 3s 196us/sample - loss: 1.0504 - val_loss: 1.0847\n",
      "Epoch 10/100\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.0353\n",
      "Epoch 00010: val_loss did not improve from 1.08345\n",
      "14152/14152 [==============================] - 3s 200us/sample - loss: 1.0361 - val_loss: 1.1044\n",
      "Epoch 11/100\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0156\n",
      "Epoch 00011: val_loss did not improve from 1.08345\n",
      "14152/14152 [==============================] - 3s 200us/sample - loss: 1.0143 - val_loss: 1.0903\n",
      "Epoch 12/100\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0153\n",
      "Epoch 00012: val_loss improved from 1.08345 to 1.08044, saving model to ./nn_model.w8\n",
      "14152/14152 [==============================] - 3s 203us/sample - loss: 1.0144 - val_loss: 1.0804\n",
      "Epoch 13/100\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9909\n",
      "Epoch 00013: val_loss did not improve from 1.08044\n",
      "14152/14152 [==============================] - 3s 200us/sample - loss: 0.9914 - val_loss: 1.0999\n",
      "Epoch 14/100\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.9803\n",
      "Epoch 00014: val_loss did not improve from 1.08044\n",
      "14152/14152 [==============================] - 3s 200us/sample - loss: 0.9810 - val_loss: 1.1058\n",
      "Epoch 15/100\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9750\n",
      "Epoch 00015: val_loss did not improve from 1.08044\n",
      "14152/14152 [==============================] - 3s 199us/sample - loss: 0.9757 - val_loss: 1.0971\n",
      "Epoch 16/100\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9654\n",
      "Epoch 00016: val_loss did not improve from 1.08044\n",
      "14152/14152 [==============================] - 3s 200us/sample - loss: 0.9652 - val_loss: 1.1192\n",
      "Epoch 17/100\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9450\n",
      "Epoch 00017: val_loss did not improve from 1.08044\n",
      "14152/14152 [==============================] - 3s 199us/sample - loss: 0.9437 - val_loss: 1.1252\n",
      "Epoch 18/100\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9303\n",
      "Epoch 00018: val_loss did not improve from 1.08044\n",
      "14152/14152 [==============================] - 3s 201us/sample - loss: 0.9300 - val_loss: 1.1154\n",
      "Epoch 19/100\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9215\n",
      "Epoch 00019: val_loss did not improve from 1.08044\n",
      "14152/14152 [==============================] - 3s 200us/sample - loss: 0.9225 - val_loss: 1.1045\n",
      "Epoch 20/100\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.9066\n",
      "Epoch 00020: val_loss did not improve from 1.08044\n",
      "14152/14152 [==============================] - 3s 201us/sample - loss: 0.9079 - val_loss: 1.1370\n",
      "Epoch 21/100\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9037\n",
      "Epoch 00021: val_loss did not improve from 1.08044\n",
      "14152/14152 [==============================] - 3s 205us/sample - loss: 0.9030 - val_loss: 1.1387\n",
      "Epoch 22/100\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.8829\n",
      "Epoch 00022: val_loss did not improve from 1.08044\n",
      "14152/14152 [==============================] - 3s 202us/sample - loss: 0.8833 - val_loss: 1.1499\n",
      "fold_1 coefficients:  [0.66222351 1.36340424 2.10897773]\n",
      "training qwk:  0.64135319\n",
      "validation qwk:  0.53997507\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 200)               174000    \n",
      "_________________________________________________________________\n",
      "layer_normalization_6 (Layer (None, 200)               400       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "layer_normalization_7 (Layer (None, 100)               200       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 25)                2525      \n",
      "_________________________________________________________________\n",
      "layer_normalization_8 (Layer (None, 25)                50        \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 197,301\n",
      "Trainable params: 197,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 14152 samples, validate on 789 samples\n",
      "Epoch 1/100\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.8436\n",
      "Epoch 00001: val_loss improved from inf to 1.16502, saving model to ./nn_model.w8\n",
      "14152/14152 [==============================] - 4s 283us/sample - loss: 1.8381 - val_loss: 1.1650\n",
      "Epoch 2/100\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.3571\n",
      "Epoch 00002: val_loss improved from 1.16502 to 1.13066, saving model to ./nn_model.w8\n",
      "14152/14152 [==============================] - 3s 211us/sample - loss: 1.3577 - val_loss: 1.1307\n",
      "Epoch 3/100\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.2643\n",
      "Epoch 00003: val_loss improved from 1.13066 to 1.12699, saving model to ./nn_model.w8\n",
      "14152/14152 [==============================] - 3s 210us/sample - loss: 1.2654 - val_loss: 1.1270\n",
      "Epoch 4/100\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.1874\n",
      "Epoch 00004: val_loss improved from 1.12699 to 1.11139, saving model to ./nn_model.w8\n",
      "14152/14152 [==============================] - 3s 208us/sample - loss: 1.1883 - val_loss: 1.1114\n",
      "Epoch 5/100\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.1435\n",
      "Epoch 00005: val_loss did not improve from 1.11139\n",
      "14152/14152 [==============================] - 3s 203us/sample - loss: 1.1442 - val_loss: 1.1364\n",
      "Epoch 6/100\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.1153\n",
      "Epoch 00006: val_loss did not improve from 1.11139\n",
      "14152/14152 [==============================] - 3s 206us/sample - loss: 1.1160 - val_loss: 1.1218\n",
      "Epoch 7/100\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.0994\n",
      "Epoch 00007: val_loss improved from 1.11139 to 1.09455, saving model to ./nn_model.w8\n",
      "14152/14152 [==============================] - 3s 208us/sample - loss: 1.0977 - val_loss: 1.0945\n",
      "Epoch 8/100\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0710\n",
      "Epoch 00008: val_loss did not improve from 1.09455\n",
      "14152/14152 [==============================] - 3s 193us/sample - loss: 1.0715 - val_loss: 1.1038\n",
      "Epoch 9/100\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0503\n",
      "Epoch 00009: val_loss improved from 1.09455 to 1.08270, saving model to ./nn_model.w8\n",
      "14152/14152 [==============================] - 3s 192us/sample - loss: 1.0503 - val_loss: 1.0827\n",
      "Epoch 10/100\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.0396\n",
      "Epoch 00010: val_loss did not improve from 1.08270\n",
      "14152/14152 [==============================] - 3s 192us/sample - loss: 1.0419 - val_loss: 1.0930\n",
      "Epoch 11/100\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.0256\n",
      "Epoch 00011: val_loss did not improve from 1.08270\n",
      "14152/14152 [==============================] - 3s 193us/sample - loss: 1.0263 - val_loss: 1.0975\n",
      "Epoch 12/100\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.0050\n",
      "Epoch 00012: val_loss did not improve from 1.08270\n",
      "14152/14152 [==============================] - 3s 192us/sample - loss: 1.0030 - val_loss: 1.1034\n",
      "Epoch 13/100\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.9847\n",
      "Epoch 00013: val_loss did not improve from 1.08270\n",
      "14152/14152 [==============================] - 3s 194us/sample - loss: 0.9869 - val_loss: 1.0883\n",
      "Epoch 14/100\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9876\n",
      "Epoch 00014: val_loss did not improve from 1.08270\n",
      "14152/14152 [==============================] - 3s 195us/sample - loss: 0.9860 - val_loss: 1.0831\n",
      "Epoch 15/100\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.9677\n",
      "Epoch 00015: val_loss did not improve from 1.08270\n",
      "14152/14152 [==============================] - 3s 195us/sample - loss: 0.9680 - val_loss: 1.0999\n",
      "Epoch 16/100\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9614\n",
      "Epoch 00016: val_loss did not improve from 1.08270\n",
      "14152/14152 [==============================] - 3s 196us/sample - loss: 0.9624 - val_loss: 1.1049\n",
      "Epoch 17/100\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.9388\n",
      "Epoch 00017: val_loss did not improve from 1.08270\n",
      "14152/14152 [==============================] - 3s 195us/sample - loss: 0.9386 - val_loss: 1.0954\n",
      "Epoch 18/100\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 0.9212\n",
      "Epoch 00018: val_loss improved from 1.08270 to 1.08129, saving model to ./nn_model.w8\n",
      "14152/14152 [==============================] - 3s 197us/sample - loss: 0.9215 - val_loss: 1.0813\n",
      "Epoch 19/100\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9352\n",
      "Epoch 00019: val_loss did not improve from 1.08129\n",
      "14152/14152 [==============================] - 3s 191us/sample - loss: 0.9327 - val_loss: 1.1243\n",
      "Epoch 20/100\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9122\n",
      "Epoch 00020: val_loss did not improve from 1.08129\n",
      "14152/14152 [==============================] - 3s 189us/sample - loss: 0.9124 - val_loss: 1.1039\n",
      "Epoch 21/100\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9032\n",
      "Epoch 00021: val_loss did not improve from 1.08129\n",
      "14152/14152 [==============================] - 3s 189us/sample - loss: 0.9036 - val_loss: 1.1098\n",
      "Epoch 22/100\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.8889\n",
      "Epoch 00022: val_loss did not improve from 1.08129\n",
      "14152/14152 [==============================] - 3s 189us/sample - loss: 0.8892 - val_loss: 1.1156\n",
      "Epoch 23/100\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.8796\n",
      "Epoch 00023: val_loss did not improve from 1.08129\n",
      "14152/14152 [==============================] - 3s 189us/sample - loss: 0.8803 - val_loss: 1.1201\n",
      "Epoch 24/100\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 0.8623\n",
      "Epoch 00024: val_loss did not improve from 1.08129\n",
      "14152/14152 [==============================] - 3s 192us/sample - loss: 0.8622 - val_loss: 1.1319\n",
      "Epoch 25/100\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.8629\n",
      "Epoch 00025: val_loss did not improve from 1.08129\n",
      "14152/14152 [==============================] - 3s 193us/sample - loss: 0.8631 - val_loss: 1.1212\n",
      "Epoch 26/100\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.8491\n",
      "Epoch 00026: val_loss did not improve from 1.08129\n",
      "14152/14152 [==============================] - 3s 188us/sample - loss: 0.8489 - val_loss: 1.0978\n",
      "Epoch 27/100\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.8360\n",
      "Epoch 00027: val_loss did not improve from 1.08129\n",
      "14152/14152 [==============================] - 3s 189us/sample - loss: 0.8365 - val_loss: 1.1180\n",
      "Epoch 28/100\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.8255\n",
      "Epoch 00028: val_loss did not improve from 1.08129\n",
      "14152/14152 [==============================] - 3s 197us/sample - loss: 0.8258 - val_loss: 1.1100\n",
      "fold_2 coefficients:  [0.79239687 1.86789572 2.29267307]\n",
      "training qwk:  0.67286643\n",
      "validation qwk:  0.52519756\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 200)               174000    \n",
      "_________________________________________________________________\n",
      "layer_normalization_9 (Layer (None, 200)               400       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "layer_normalization_10 (Laye (None, 100)               200       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 25)                2525      \n",
      "_________________________________________________________________\n",
      "layer_normalization_11 (Laye (None, 25)                50        \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 197,301\n",
      "Trainable params: 197,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 14152 samples, validate on 807 samples\n",
      "Epoch 1/100\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.6774\n",
      "Epoch 00001: val_loss improved from inf to 1.28727, saving model to ./nn_model.w8\n",
      "14152/14152 [==============================] - 4s 295us/sample - loss: 1.6733 - val_loss: 1.2873\n",
      "Epoch 2/100\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.3030\n",
      "Epoch 00002: val_loss improved from 1.28727 to 1.25054, saving model to ./nn_model.w8\n",
      "14152/14152 [==============================] - 3s 193us/sample - loss: 1.2997 - val_loss: 1.2505\n",
      "Epoch 3/100\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.2236\n",
      "Epoch 00003: val_loss improved from 1.25054 to 1.24138, saving model to ./nn_model.w8\n",
      "14152/14152 [==============================] - 3s 193us/sample - loss: 1.2202 - val_loss: 1.2414\n",
      "Epoch 4/100\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.1559\n",
      "Epoch 00004: val_loss improved from 1.24138 to 1.22220, saving model to ./nn_model.w8\n",
      "14152/14152 [==============================] - 3s 190us/sample - loss: 1.1563 - val_loss: 1.2222\n",
      "Epoch 5/100\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.1150\n",
      "Epoch 00005: val_loss did not improve from 1.22220\n",
      "14152/14152 [==============================] - 3s 189us/sample - loss: 1.1175 - val_loss: 1.2520\n",
      "Epoch 6/100\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.0926\n",
      "Epoch 00006: val_loss did not improve from 1.22220\n",
      "14152/14152 [==============================] - 3s 191us/sample - loss: 1.0929 - val_loss: 1.3083\n",
      "Epoch 7/100\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.0823\n",
      "Epoch 00007: val_loss improved from 1.22220 to 1.20602, saving model to ./nn_model.w8\n",
      "14152/14152 [==============================] - 3s 195us/sample - loss: 1.0823 - val_loss: 1.2060\n",
      "Epoch 8/100\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 1.0678\n",
      "Epoch 00008: val_loss did not improve from 1.20602\n",
      "14152/14152 [==============================] - 3s 195us/sample - loss: 1.0665 - val_loss: 1.2502\n",
      "Epoch 9/100\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0515\n",
      "Epoch 00009: val_loss improved from 1.20602 to 1.20480, saving model to ./nn_model.w8\n",
      "14152/14152 [==============================] - 3s 193us/sample - loss: 1.0529 - val_loss: 1.2048\n",
      "Epoch 10/100\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.0321\n",
      "Epoch 00010: val_loss did not improve from 1.20480\n",
      "14152/14152 [==============================] - 3s 193us/sample - loss: 1.0320 - val_loss: 1.2159\n",
      "Epoch 11/100\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.0288\n",
      "Epoch 00011: val_loss did not improve from 1.20480\n",
      "14152/14152 [==============================] - 3s 191us/sample - loss: 1.0280 - val_loss: 1.2680\n",
      "Epoch 12/100\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.0068\n",
      "Epoch 00012: val_loss did not improve from 1.20480\n",
      "14152/14152 [==============================] - 3s 194us/sample - loss: 1.0073 - val_loss: 1.2149\n",
      "Epoch 13/100\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.9940\n",
      "Epoch 00013: val_loss improved from 1.20480 to 1.20304, saving model to ./nn_model.w8\n",
      "14152/14152 [==============================] - 4s 259us/sample - loss: 0.9949 - val_loss: 1.2030\n",
      "Epoch 14/100\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9803\n",
      "Epoch 00014: val_loss did not improve from 1.20304\n",
      "14152/14152 [==============================] - 3s 191us/sample - loss: 0.9804 - val_loss: 1.3026\n",
      "Epoch 15/100\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9729\n",
      "Epoch 00015: val_loss did not improve from 1.20304\n",
      "14152/14152 [==============================] - 3s 187us/sample - loss: 0.9727 - val_loss: 1.2248\n",
      "Epoch 16/100\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.9517\n",
      "Epoch 00016: val_loss did not improve from 1.20304\n",
      "14152/14152 [==============================] - 3s 189us/sample - loss: 0.9527 - val_loss: 1.2282\n",
      "Epoch 17/100\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9410\n",
      "Epoch 00017: val_loss did not improve from 1.20304\n",
      "14152/14152 [==============================] - 3s 190us/sample - loss: 0.9419 - val_loss: 1.2267\n",
      "Epoch 18/100\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9340\n",
      "Epoch 00018: val_loss did not improve from 1.20304\n",
      "14152/14152 [==============================] - 3s 189us/sample - loss: 0.9357 - val_loss: 1.2519\n",
      "Epoch 19/100\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.9193\n",
      "Epoch 00019: val_loss did not improve from 1.20304\n",
      "14152/14152 [==============================] - 3s 191us/sample - loss: 0.9161 - val_loss: 1.2408\n",
      "Epoch 20/100\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9051\n",
      "Epoch 00020: val_loss did not improve from 1.20304\n",
      "14152/14152 [==============================] - 3s 208us/sample - loss: 0.9055 - val_loss: 1.2117\n",
      "Epoch 21/100\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.8918\n",
      "Epoch 00021: val_loss did not improve from 1.20304\n",
      "14152/14152 [==============================] - 3s 218us/sample - loss: 0.8967 - val_loss: 1.2264\n",
      "Epoch 22/100\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.8954\n",
      "Epoch 00022: val_loss did not improve from 1.20304\n",
      "14152/14152 [==============================] - 3s 215us/sample - loss: 0.8956 - val_loss: 1.2645\n",
      "Epoch 23/100\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.8752\n",
      "Epoch 00023: val_loss improved from 1.20304 to 1.19956, saving model to ./nn_model.w8\n",
      "14152/14152 [==============================] - 3s 210us/sample - loss: 0.8754 - val_loss: 1.1996\n",
      "Epoch 24/100\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.8589\n",
      "Epoch 00024: val_loss did not improve from 1.19956\n",
      "14152/14152 [==============================] - 3s 184us/sample - loss: 0.8592 - val_loss: 1.2013\n",
      "Epoch 25/100\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.8537\n",
      "Epoch 00025: val_loss did not improve from 1.19956\n",
      "14152/14152 [==============================] - 3s 183us/sample - loss: 0.8535 - val_loss: 1.3183\n",
      "Epoch 26/100\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.8381\n",
      "Epoch 00026: val_loss did not improve from 1.19956\n",
      "14152/14152 [==============================] - 3s 186us/sample - loss: 0.8380 - val_loss: 1.2724\n",
      "Epoch 27/100\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.8386\n",
      "Epoch 00027: val_loss did not improve from 1.19956\n",
      "14152/14152 [==============================] - 3s 184us/sample - loss: 0.8383 - val_loss: 1.2697\n",
      "Epoch 28/100\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.8247\n",
      "Epoch 00028: val_loss did not improve from 1.19956\n",
      "14152/14152 [==============================] - 3s 187us/sample - loss: 0.8244 - val_loss: 1.2645\n",
      "Epoch 29/100\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.8154\n",
      "Epoch 00029: val_loss did not improve from 1.19956\n",
      "14152/14152 [==============================] - 3s 191us/sample - loss: 0.8159 - val_loss: 1.2702\n",
      "Epoch 30/100\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.8151\n",
      "Epoch 00030: val_loss did not improve from 1.19956\n",
      "14152/14152 [==============================] - 3s 187us/sample - loss: 0.8146 - val_loss: 1.2184\n",
      "Epoch 31/100\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.7997\n",
      "Epoch 00031: val_loss did not improve from 1.19956\n",
      "14152/14152 [==============================] - 3s 188us/sample - loss: 0.8000 - val_loss: 1.2249\n",
      "Epoch 32/100\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.7951\n",
      "Epoch 00032: val_loss did not improve from 1.19956\n",
      "14152/14152 [==============================] - 3s 190us/sample - loss: 0.7940 - val_loss: 1.2439\n",
      "Epoch 33/100\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.7774\n",
      "Epoch 00033: val_loss did not improve from 1.19956\n",
      "14152/14152 [==============================] - 3s 188us/sample - loss: 0.7772 - val_loss: 1.2889\n",
      "fold_3 coefficients:  [1.12488225 1.8283835  2.23214207]\n",
      "training qwk:  0.70967886\n",
      "validation qwk:  0.52049911\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 200)               174000    \n",
      "_________________________________________________________________\n",
      "layer_normalization_12 (Laye (None, 200)               400       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "layer_normalization_13 (Laye (None, 100)               200       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 25)                2525      \n",
      "_________________________________________________________________\n",
      "layer_normalization_14 (Laye (None, 25)                50        \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 197,301\n",
      "Trainable params: 197,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 14153 samples, validate on 775 samples\n",
      "Epoch 1/100\n",
      "13952/14153 [============================>.] - ETA: 0s - loss: 1.7789\n",
      "Epoch 00001: val_loss improved from inf to 1.15925, saving model to ./nn_model.w8\n",
      "14153/14153 [==============================] - 4s 258us/sample - loss: 1.7769 - val_loss: 1.1593\n",
      "Epoch 2/100\n",
      "13920/14153 [============================>.] - ETA: 0s - loss: 1.3540\n",
      "Epoch 00002: val_loss improved from 1.15925 to 1.12719, saving model to ./nn_model.w8\n",
      "14153/14153 [==============================] - 3s 189us/sample - loss: 1.3541 - val_loss: 1.1272\n",
      "Epoch 3/100\n",
      "13920/14153 [============================>.] - ETA: 0s - loss: 1.2308\n",
      "Epoch 00003: val_loss did not improve from 1.12719\n",
      "14153/14153 [==============================] - 3s 184us/sample - loss: 1.2299 - val_loss: 1.1277\n",
      "Epoch 4/100\n",
      "13888/14153 [============================>.] - ETA: 0s - loss: 1.1929\n",
      "Epoch 00004: val_loss improved from 1.12719 to 1.10684, saving model to ./nn_model.w8\n",
      "14153/14153 [==============================] - 3s 185us/sample - loss: 1.1940 - val_loss: 1.1068\n",
      "Epoch 5/100\n",
      "13888/14153 [============================>.] - ETA: 0s - loss: 1.1557\n",
      "Epoch 00005: val_loss improved from 1.10684 to 1.09474, saving model to ./nn_model.w8\n",
      "14153/14153 [==============================] - 3s 185us/sample - loss: 1.1513 - val_loss: 1.0947\n",
      "Epoch 6/100\n",
      "14048/14153 [============================>.] - ETA: 0s - loss: 1.1234\n",
      "Epoch 00006: val_loss did not improve from 1.09474\n",
      "14153/14153 [==============================] - 3s 184us/sample - loss: 1.1227 - val_loss: 1.1158\n",
      "Epoch 7/100\n",
      "13952/14153 [============================>.] - ETA: 0s - loss: 1.1018\n",
      "Epoch 00007: val_loss did not improve from 1.09474\n",
      "14153/14153 [==============================] - 3s 184us/sample - loss: 1.1017 - val_loss: 1.1009\n",
      "Epoch 8/100\n",
      "13984/14153 [============================>.] - ETA: 0s - loss: 1.0740\n",
      "Epoch 00008: val_loss did not improve from 1.09474\n",
      "14153/14153 [==============================] - 3s 197us/sample - loss: 1.0743 - val_loss: 1.1001\n",
      "Epoch 9/100\n",
      "14112/14153 [============================>.] - ETA: 0s - loss: 1.0750\n",
      "Epoch 00009: val_loss did not improve from 1.09474\n",
      "14153/14153 [==============================] - 3s 220us/sample - loss: 1.0744 - val_loss: 1.1035\n",
      "Epoch 10/100\n",
      "13920/14153 [============================>.] - ETA: 0s - loss: 1.0406\n",
      "Epoch 00010: val_loss improved from 1.09474 to 1.09328, saving model to ./nn_model.w8\n",
      "14153/14153 [==============================] - 3s 202us/sample - loss: 1.0389 - val_loss: 1.0933\n",
      "Epoch 11/100\n",
      "13984/14153 [============================>.] - ETA: 0s - loss: 1.0273\n",
      "Epoch 00011: val_loss did not improve from 1.09328\n",
      "14153/14153 [==============================] - 3s 179us/sample - loss: 1.0255 - val_loss: 1.1094\n",
      "Epoch 12/100\n",
      "14048/14153 [============================>.] - ETA: 0s - loss: 1.0063\n",
      "Epoch 00012: val_loss did not improve from 1.09328\n",
      "14153/14153 [==============================] - 3s 182us/sample - loss: 1.0071 - val_loss: 1.1019\n",
      "Epoch 13/100\n",
      "14016/14153 [============================>.] - ETA: 0s - loss: 1.0107\n",
      "Epoch 00013: val_loss did not improve from 1.09328\n",
      "14153/14153 [==============================] - 3s 182us/sample - loss: 1.0119 - val_loss: 1.1062\n",
      "Epoch 14/100\n",
      "14144/14153 [============================>.] - ETA: 0s - loss: 0.9922\n",
      "Epoch 00014: val_loss did not improve from 1.09328\n",
      "14153/14153 [==============================] - 3s 185us/sample - loss: 0.9921 - val_loss: 1.1168\n",
      "Epoch 15/100\n",
      "13984/14153 [============================>.] - ETA: 0s - loss: 0.9747\n",
      "Epoch 00015: val_loss did not improve from 1.09328\n",
      "14153/14153 [==============================] - 3s 183us/sample - loss: 0.9736 - val_loss: 1.1179\n",
      "Epoch 16/100\n",
      "13984/14153 [============================>.] - ETA: 0s - loss: 0.9692\n",
      "Epoch 00016: val_loss improved from 1.09328 to 1.08310, saving model to ./nn_model.w8\n",
      "14153/14153 [==============================] - 3s 181us/sample - loss: 0.9681 - val_loss: 1.0831\n",
      "Epoch 17/100\n",
      "14048/14153 [============================>.] - ETA: 0s - loss: 0.9591\n",
      "Epoch 00017: val_loss did not improve from 1.08310\n",
      "14153/14153 [==============================] - 3s 182us/sample - loss: 0.9580 - val_loss: 1.0858\n",
      "Epoch 18/100\n",
      "14080/14153 [============================>.] - ETA: 0s - loss: 0.9405\n",
      "Epoch 00018: val_loss did not improve from 1.08310\n",
      "14153/14153 [==============================] - 3s 180us/sample - loss: 0.9402 - val_loss: 1.1076\n",
      "Epoch 19/100\n",
      "14112/14153 [============================>.] - ETA: 0s - loss: 0.9374\n",
      "Epoch 00019: val_loss did not improve from 1.08310\n",
      "14153/14153 [==============================] - 3s 181us/sample - loss: 0.9365 - val_loss: 1.1107\n",
      "Epoch 20/100\n",
      "14144/14153 [============================>.] - ETA: 0s - loss: 0.9255\n",
      "Epoch 00020: val_loss did not improve from 1.08310\n",
      "14153/14153 [==============================] - 3s 184us/sample - loss: 0.9258 - val_loss: 1.1044\n",
      "Epoch 21/100\n",
      "13952/14153 [============================>.] - ETA: 0s - loss: 0.9126\n",
      "Epoch 00021: val_loss did not improve from 1.08310\n",
      "14153/14153 [==============================] - 3s 183us/sample - loss: 0.9129 - val_loss: 1.1138\n",
      "Epoch 22/100\n",
      "14048/14153 [============================>.] - ETA: 0s - loss: 0.9042\n",
      "Epoch 00022: val_loss did not improve from 1.08310\n",
      "14153/14153 [==============================] - 3s 180us/sample - loss: 0.9029 - val_loss: 1.0927\n",
      "Epoch 23/100\n",
      "13920/14153 [============================>.] - ETA: 0s - loss: 0.8867\n",
      "Epoch 00023: val_loss did not improve from 1.08310\n",
      "14153/14153 [==============================] - 3s 181us/sample - loss: 0.8910 - val_loss: 1.1142\n",
      "Epoch 24/100\n",
      "14048/14153 [============================>.] - ETA: 0s - loss: 0.8685\n",
      "Epoch 00024: val_loss did not improve from 1.08310\n",
      "14153/14153 [==============================] - 3s 183us/sample - loss: 0.8690 - val_loss: 1.1088\n",
      "Epoch 25/100\n",
      "13952/14153 [============================>.] - ETA: 0s - loss: 0.8700\n",
      "Epoch 00025: val_loss did not improve from 1.08310\n",
      "14153/14153 [==============================] - 3s 180us/sample - loss: 0.8694 - val_loss: 1.1036\n",
      "Epoch 26/100\n",
      "13920/14153 [============================>.] - ETA: 0s - loss: 0.8607\n",
      "Epoch 00026: val_loss did not improve from 1.08310\n",
      "14153/14153 [==============================] - 3s 183us/sample - loss: 0.8601 - val_loss: 1.0987\n",
      "fold_4 coefficients:  [0.84641769 1.67315314 2.25683645]\n",
      "training qwk:  0.66134228\n",
      "validation qwk:  0.55177607\n",
      "                             \n",
      "-----------------------------\n",
      "coefficients:  [array([0.79492689, 1.85256542, 2.34220376]), array([0.66222351, 1.36340424, 2.10897773]), array([0.79239687, 1.86789572, 2.29267307]), array([1.12488225, 1.8283835 , 2.23214207]), array([0.84641769, 1.67315314, 2.25683645])]\n",
      "train qwk list: [0.59895697, 0.64135319, 0.67286643, 0.70967886, 0.66134228]\n",
      "train qwk average score: 0.6568395459999999\n",
      "valid qwk list:  [0.53055483, 0.53997507, 0.52519756, 0.52049911, 0.55177607]\n",
      "valid qwk average score: 0.533600528\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "n_folds=5\n",
    "skf=StratifiedKFold(n_splits = n_folds, random_state=1223)\n",
    "coefficients = []\n",
    "models = []\n",
    "train_qwk_scores = []\n",
    "test_qwk_scores = []\n",
    "\n",
    "features_list = [i for i in X_train.columns if i != \"installation_id\"]\n",
    "feature_importance_df = pd.DataFrame(features_list, columns=[\"Feature\"])\n",
    "for i , (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "    optR = OptimizedRounder()\n",
    "    X_train2 = X_train.iloc[train_index,:]\n",
    "    y_train2 = y_train.iloc[train_index]\n",
    "    X_train2 = X_train2.drop(['installation_id'],axis=1)\n",
    "    \n",
    "    X_test2 = X_train.iloc[test_index,:]\n",
    "    y_test2 = y_train.iloc[test_index]\n",
    "    test2 = pd.concat([X_test2, y_test2], axis=1)\n",
    "    test2 = test2.groupby('installation_id').apply(lambda x: x.sample(1, random_state=1223)).reset_index(drop=True)\n",
    "    X_test2 = test2.drop([\"accuracy_group\", \"installation_id\"], axis=1)\n",
    "    y_test2 = test2[\"accuracy_group\"]\n",
    "        \n",
    "    verbosity = 100\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Input(shape=(X_train2.shape[1],)),\n",
    "            tf.keras.layers.Dense(200, activation='relu'),\n",
    "            tf.keras.layers.LayerNormalization(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(100, activation='tanh'),\n",
    "            tf.keras.layers.LayerNormalization(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            #tf.keras.layers.Dense(50, activation='relu'),\n",
    "            #tf.keras.layers.LayerNormalization(),\n",
    "            #tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(25, activation='relu'),\n",
    "            tf.keras.layers.LayerNormalization(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(1, activation='relu')\n",
    "        ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=4e-4), loss='mse')\n",
    "    print(model.summary())\n",
    "    save_best = tf.keras.callbacks.ModelCheckpoint('./nn_model.w8', save_weights_only=True, save_best_only=True, verbose=1)\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "    \n",
    "    model.fit(X_train2, \n",
    "                y_train2, \n",
    "                validation_data=(X_test2, y_test2),\n",
    "                epochs=100,\n",
    "                 callbacks=[save_best, early_stop])\n",
    "    model.load_weights('./nn_model.w8')\n",
    "\n",
    "    models.append(model)\n",
    "    train_predict = model.predict(X_train2)\n",
    "    test_predict = model.predict(X_test2)\n",
    "    \n",
    "    optR.fit(train_predict.reshape(-1,), y_train2)\n",
    "    tmp_coefficients = optR.coefficients()\n",
    "    print(\"fold_\"+str(i)+\" coefficients: \", tmp_coefficients)\n",
    "    opt_train_preds = optR.predict(train_predict.reshape(-1, ), tmp_coefficients)\n",
    "    train_qwk_score = qwk(y_train2, opt_train_preds)\n",
    "    print(\"training qwk: \", train_qwk_score)\n",
    "    opt_test_preds = optR.predict(test_predict.reshape(-1, ), tmp_coefficients)\n",
    "    test_qwk_score = qwk(y_test2, opt_test_preds)\n",
    "    print(\"validation qwk: \", test_qwk_score)\n",
    "    train_qwk_scores.append(train_qwk_score)\n",
    "    test_qwk_scores.append(test_qwk_score)\n",
    "    coefficients.append(tmp_coefficients)\n",
    "    \n",
    "print(\"                             \")\n",
    "print(\"-----------------------------\")\n",
    "print('coefficients: ', coefficients)\n",
    "print('train qwk list:', train_qwk_scores)\n",
    "print('train qwk average score:',np.mean(train_qwk_scores))\n",
    "print('valid qwk list: ', test_qwk_scores)\n",
    "print('valid qwk average score:',np.mean(test_qwk_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train qwk list: [0.65665743, 0.64927645, 0.6476875, 0.6272318, 0.65061782]\n",
    "- train qwk average score: 0.6462942\n",
    "- valid qwk list:  [0.54446962, 0.57552825, 0.53624626, 0.51145234, 0.541244]\n",
    "- valid qwk average score: 0.5417880939999999\n",
    "- \n",
    "- 0.636, 0.538"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    0.446\n",
       "2    0.254\n",
       "1    0.150\n",
       "0    0.150\n",
       "Name: accuracy_group, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = new_test_nn.drop([\"installation_id\", \"accuracy_group\"], axis=1)\n",
    "X_test = X_test.drop(remove_features, axis=1)\n",
    "X_test = X_test[sorted(X_test.columns.tolist())]\n",
    "pred_value = np.zeros([X_test.shape[0]])\n",
    "test_coefficients = np.mean(coefficients, axis=0)\n",
    "for model in models:\n",
    "    pred_value += model.predict(X_test).reshape(X_test.shape[0],) / n_folds\n",
    "test_pred_class= optR.predict(pred_value.reshape(-1, ), test_coefficients)\n",
    "sample_submission[\"accuracy_group\"] = test_pred_class\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission[\"accuracy_group\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "012491486f44467aa763ecd8016220f2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "019b324f639b4e61a6b0c733a9d97fb6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_31895798593d4ac4aaf6ffa3234ff3c3",
        "IPY_MODEL_a21401b1cec745cdb7c2fc0f47295e7a"
       ],
       "layout": "IPY_MODEL_012491486f44467aa763ecd8016220f2"
      }
     },
     "07514735822b449fb60dd720c7dba0bf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "16da7f41037b4f129a9be52bd31272f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "31895798593d4ac4aaf6ffa3234ff3c3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Installation_id: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f797dec3b82c468693c0e04e423ab176",
       "max": 3614,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_990e2137bf294a5e8257f8656aaf7606",
       "value": 3614
      }
     },
     "45d4bd1bcddf4cfcb585c529ef3b59b3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6614e141c5f14aadbf00d4d309f2bcc6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "799531f3a82e4d1aa52d72ae81e6c812": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "93baff84663e4c1bb0dcbc149535c884": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f637cf029b9f4dcfa6a3e27a7241677e",
       "placeholder": "​",
       "style": "IPY_MODEL_16da7f41037b4f129a9be52bd31272f3",
       "value": " 1000/1000 [01:49&lt;00:00,  9.12it/s]"
      }
     },
     "990e2137bf294a5e8257f8656aaf7606": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "a21401b1cec745cdb7c2fc0f47295e7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a535df52cb5b494cb3aa34a12355873b",
       "placeholder": "​",
       "style": "IPY_MODEL_799531f3a82e4d1aa52d72ae81e6c812",
       "value": " 3614/3614 [09:06&lt;00:00,  6.61it/s]"
      }
     },
     "a347f306d63b482a8c8562eda16ccd5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c64675ba1f164920bea2ed2096b882ff",
        "IPY_MODEL_93baff84663e4c1bb0dcbc149535c884"
       ],
       "layout": "IPY_MODEL_07514735822b449fb60dd720c7dba0bf"
      }
     },
     "a535df52cb5b494cb3aa34a12355873b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c64675ba1f164920bea2ed2096b882ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Installation_id: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_45d4bd1bcddf4cfcb585c529ef3b59b3",
       "max": 1000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6614e141c5f14aadbf00d4d309f2bcc6",
       "value": 1000
      }
     },
     "f637cf029b9f4dcfa6a3e27a7241677e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f797dec3b82c468693c0e04e423ab176": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
