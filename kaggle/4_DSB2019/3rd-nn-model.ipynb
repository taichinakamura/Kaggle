{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "- cancel revmoving training data\n",
    "- change feature engineering process\n",
    "- incorporate truncation validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import datetime\n",
    "from time import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "from functools import partial\n",
    "import random\n",
    "import json\n",
    "import copy\n",
    "import time\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.max_rows\",1000)\n",
    "np.set_printoptions(precision=8)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "        return -qwk(y, X_p)\n",
    "        #return -mod_qwk(y, X_p, weights=weights)\n",
    "    \n",
    "    def fit(self, X, y, random_flg = False):\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        if random_flg:\n",
    "            initial_coef = [np.random.uniform(1.0,1.1), np.random.uniform(1.7,1.8), np.random.uniform(2.1,2.2)]\n",
    "        else:\n",
    "            initial_coef = [0.5, 1.5, 2.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead') #Powell\n",
    "        \n",
    "    def predict(self, X, coef):\n",
    "        return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qwk(a1, a2):\n",
    "    max_rat = 3\n",
    "    a1 = np.asarray(a1, dtype=int)\n",
    "    a2 = np.asarray(a2, dtype=int)\n",
    "    hist1 = np.zeros((max_rat + 1, ))\n",
    "    hist2 = np.zeros((max_rat + 1, ))\n",
    "    o = 0\n",
    "    for k in range(a1.shape[0]):\n",
    "        i, j = a1[k], a2[k]\n",
    "        hist1[i] += 1\n",
    "        hist2[j] += 1\n",
    "        o +=  (i - j) * (i - j)\n",
    "    e = 0\n",
    "    for i in range(max_rat + 1):\n",
    "        for j in range(max_rat + 1):\n",
    "            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n",
    "    e = e / a1.shape[0]\n",
    "    return np.round(1 - o / e, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_qwk_lgb_regr(y_pred, train_t):\n",
    "    dist = Counter(train_t['accuracy_group'])\n",
    "    for k in dist:\n",
    "        dist[k] /= len(train_t)\n",
    "    \n",
    "    acum = 0\n",
    "    bound = {}\n",
    "    for i in range(3):\n",
    "        acum += dist[i]\n",
    "        bound[i] = np.percentile(y_pred, acum * 100)\n",
    "\n",
    "    def classify(x):\n",
    "        if x <= bound[0]:\n",
    "            return 0\n",
    "        elif x <= bound[1]:\n",
    "            return 1\n",
    "        elif x <= bound[2]:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "\n",
    "    y_pred = np.array(list(map(classify, y_pred)))\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Preprocess and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 17s, sys: 13 s, total: 1min 30s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv('../input/data-science-bowl-2019/train.csv')\n",
    "train_labels = pd.read_csv('../input/data-science-bowl-2019/train_labels.csv')\n",
    "test = pd.read_csv('../input/data-science-bowl-2019/test.csv')\n",
    "#specs = pd.read_csv('../input/data-science-bowl-2019/specs.csv')\n",
    "sample_submission = pd.read_csv('../input/data-science-bowl-2019/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 39s, sys: 8.56 s, total: 1min 47s\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def encode_title(train, test):\n",
    "    train['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), train['title'], train['event_code']))\n",
    "    test['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), test['title'], test['event_code']))\n",
    "    list_of_title_eventcode = sorted(list(set(train['title_event_code'].unique()).union(set(test['title_event_code'].unique()))))\n",
    "    \n",
    "    train['type_world'] = list(map(lambda x, y: str(x) + '_' + str(y), train['type'], train['world']))\n",
    "    test['type_world'] = list(map(lambda x, y: str(x) + '_' + str(y), test['type'], test['world']))\n",
    "    list_of_type_world = sorted(list(set(train['type_world'].unique()).union(set(test['type_world'].unique()))))\n",
    "    \n",
    "    list_of_user_activities = sorted(list(set(train['title'].unique()).union(set(test['title'].unique()))))\n",
    "    list_of_event_code = sorted(list(set(train['event_code'].unique()).union(set(test['event_code'].unique()))))\n",
    "    list_of_worlds = sorted(list(set(train['world'].unique()).union(set(test['world'].unique()))))\n",
    "    activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n",
    "    activities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\n",
    "    activities_world = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n",
    "    assess_titles = sorted(list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(set(test[test['type'] == 'Assessment']['title'].value_counts().index))))\n",
    "\n",
    "    train['title'] = train['title'].map(activities_map)\n",
    "    test['title'] = test['title'].map(activities_map)\n",
    "    train['world'] = train['world'].map(activities_world)\n",
    "    test['world'] = test['world'].map(activities_world)\n",
    "\n",
    "    win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\n",
    "    win_code[activities_map['Bird Measurer (Assessment)']] = 4110\n",
    "    \n",
    "    train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "    test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "    \n",
    "    train[\"misses\"] = train[\"event_data\"].apply(lambda x: json.loads(x)[\"misses\"] if \"\\\"misses\\\"\" in x else np.nan)\n",
    "    test[\"misses\"] = test[\"event_data\"].apply(lambda x: json.loads(x)[\"misses\"] if \"\\\"misses\\\"\" in x else np.nan)\n",
    "\n",
    "    train[\"true\"] = train[\"event_data\"].apply(lambda x: 1 if \"true\" in x and \"correct\" in x else 0)\n",
    "    test[\"true\"] = test[\"event_data\"].apply(lambda x: 1 if \"true\" in x and \"correct\" in x else 0)\n",
    "\n",
    "    train[\"false\"] = train[\"event_data\"].apply(lambda x: 1 if \"false\" in x and \"correct\" in x else 0)\n",
    "    test[\"false\"] = test[\"event_data\"].apply(lambda x: 1 if \"false\" in x and \"correct\" in x else 0)\n",
    "    \n",
    "    train[\"game_complete\"] = train[\"event_data\"].apply(lambda x: 1 if \"game_completed\" in x else 0)\n",
    "    test[\"game_complete\"] = test[\"event_data\"].apply(lambda x: 1 if \"game_completed\" in x else 0)\n",
    "\n",
    "    return train, test, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, activities_world, list_of_title_eventcode, list_of_type_world\n",
    "\n",
    "train, test, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, activities_world, list_of_title_eventcode, list_of_type_world = encode_title(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ratio(features, dic):\n",
    "    total = sum(dic.values())\n",
    "    if total != 0:\n",
    "        for key in dic.keys():\n",
    "            features[str(key)] = features[str(key)] / total\n",
    "    else:\n",
    "        pass\n",
    "    return features\n",
    "\n",
    "def get_data(user_sample, test_set=False):\n",
    "    last_activity = 0\n",
    "    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "    title_eventcode_count = {str(ele): 0 for ele in list_of_title_eventcode}\n",
    "    user_world_count = {\"world_\"+str(wor) : 0 for wor in activities_world.values()}\n",
    "    event_code_count = {str(ev): 0 for ev in list_of_event_code}\n",
    "    title_count = {actv: 0 for actv in list_of_user_activities}\n",
    "    type_world_count = {str(ev): 0 for ev in list_of_type_world}\n",
    "    last_accuracy_title = {'acc_' + title: -1 for title in assess_titles}\n",
    "    last_game_time_title = {'lgt_' + title: 0 for title in assess_titles}\n",
    "    ac_game_time_title = {'agt_' + title: 0 for title in assess_titles}\n",
    "    ac_true_attempts_title = {'ata_' + title: 0 for title in assess_titles}\n",
    "    ac_false_attempts_title = {'afa_' + title: 0 for title in assess_titles}\n",
    "    \n",
    "    all_assessments = []\n",
    "    accuracy_groups = {\"0\":0, \"1\":0, \"2\":0, \"3\":0}\n",
    "    accumulated_accuracy_group = 0\n",
    "    accumulated_correct_attempts = 0 \n",
    "    accumulated_uncorrect_attempts = 0 \n",
    "    accumulated_actions = 0\n",
    "    counter = 0\n",
    "    time_first_activity = user_sample.iloc[0]['timestamp']\n",
    "    miss = 0\n",
    "    crys_game_true = 0; crys_game_false = 0\n",
    "    tree_game_true = 0; tree_game_false = 0\n",
    "    magma_game_true = 0; magma_game_false = 0\n",
    "    crys_game_acc = []; tree_game_acc = []; magma_game_acc = []\n",
    "    durations = []\n",
    "    prev_assess_title = -999\n",
    "    assess_count = 1\n",
    "    last_accuracy = -999\n",
    "    prev_assess_start = -999; prev_assess_end = -999\n",
    "    real_prev_assess_start = -999; real_prev_assess_end = -999\n",
    "    real_assess_start = -999; real_assess_end = -999\n",
    "    complete_games = 0\n",
    "    no_result_count = 0\n",
    "    crys_game_level = np.array([]); tree_game_level = np.array([]); magma_game_level = np.array([])\n",
    "    crys_game_round = np.array([]); tree_game_round = np.array([]); magma_game_round = np.array([])\n",
    "    \n",
    "    for i, session in user_sample.groupby('game_session', sort=False):      \n",
    "        session_type = session['type'].iloc[0]\n",
    "        session_title = session['title'].iloc[0]\n",
    "        session_title_text = activities_labels[session_title]\n",
    "        session_world = session[\"world\"].iloc[0]\n",
    "        \n",
    "        if session_type != 'Assessment':\n",
    "            if session_type == \"Game\":\n",
    "                true = session['true'].sum()\n",
    "                false = session['false'].sum() \n",
    "                if session_world == activities_world[\"CRYSTALCAVES\"]:\n",
    "                    crys_game_true += true\n",
    "                    crys_game_false += false\n",
    "                    crys_game_acc.append(true / (true + false) if (true + false) != 0 else 0)\n",
    "                elif session_world == activities_world[\"TREETOPCITY\"]:\n",
    "                    tree_game_true += true\n",
    "                    tree_game_false += false\n",
    "                    tree_game_acc.append(true / (true + false) if (true + false) != 0 else 0)\n",
    "                elif session_world == activities_world[\"MAGMAPEAK\"]:\n",
    "                    magma_game_true += true\n",
    "                    magma_game_false += false\n",
    "                    magma_game_acc.append(true / (true + false) if (true + false) != 0 else 0)\n",
    "                else:\n",
    "                    pass\n",
    "        if (session_type == 'Assessment') & (test_set or len(session)>1): \n",
    "            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n",
    "            true_attempts = all_attempts['event_data'].str.contains('true').sum() # true in target assess\n",
    "            false_attempts = all_attempts['event_data'].str.contains('false').sum() # false in target assessment\n",
    "            assess_start = session.iloc[0,2]\n",
    "            assess_end = session.iloc[-1,2]\n",
    "            \n",
    "            # from start of installation_id to the start of target assessment ------------------------\n",
    "            features = user_activities_count.copy() # appearance of each type without duplicates\n",
    "            features = make_ratio(features, user_activities_count)\n",
    "            features.update(title_eventcode_count.copy()) # apperance of combi of title and event_code\n",
    "            features = make_ratio(features, title_eventcode_count)\n",
    "            features.update(user_world_count.copy()) # appearance of world with duplicates\n",
    "            features = make_ratio(features, user_world_count)\n",
    "            features.update(event_code_count.copy())\n",
    "            features = make_ratio(features, event_code_count)\n",
    "            features.update(title_count.copy())\n",
    "            features = make_ratio(features, title_count)\n",
    "            features.update(type_world_count.copy())\n",
    "            features = make_ratio(features, type_world_count)\n",
    "            features.update(last_accuracy_title.copy())\n",
    "            features.update(last_game_time_title.copy())\n",
    "            features.update(ac_game_time_title.copy())\n",
    "            features.update(ac_true_attempts_title.copy())\n",
    "            features.update(ac_false_attempts_title.copy())\n",
    "            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n",
    "            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n",
    "            accumulated_correct_attempts += true_attempts \n",
    "            accumulated_uncorrect_attempts += false_attempts\n",
    "            ac_true_attempts_title['ata_' + session_title_text] += true_attempts\n",
    "            ac_false_attempts_title['afa_' + session_title_text] += false_attempts\n",
    "            last_game_time_title['lgt_' + session_title_text] = session['game_time'].iloc[-1]\n",
    "            ac_game_time_title['agt_' + session_title_text] += session['game_time'].iloc[-1]\n",
    "            features[\"misses\"] = miss\n",
    "            features['accumulated_actions'] = accumulated_actions\n",
    "            features[\"no_complete_game\"] = complete_games\n",
    "            features[\"no_result_count\"] = no_result_count \n",
    "            \n",
    "            if true_attempts + false_attempts == 0:\n",
    "                no_result_count += 1\n",
    "            else:\n",
    "                real_assess_start = session.iloc[0,2]\n",
    "                real_assess_end = session.iloc[-1,2]\n",
    "            if session_world == activities_world[\"CRYSTALCAVES\"]:\n",
    "                features[\"game_true\"] = crys_game_true\n",
    "                features[\"game_false\"] = crys_game_false\n",
    "                features['game_accuracy'] = crys_game_true / (crys_game_true + crys_game_false) if (crys_game_true + crys_game_false) != 0 else 0\n",
    "                features[\"game_accuracy_std\"] = np.std(crys_game_acc) if len(crys_game_acc) >=1 else 0\n",
    "                features[\"last_game_acc\"] = crys_game_acc[-1] if len(crys_game_acc) >=1 else 0\n",
    "            elif session_world == activities_world[\"TREETOPCITY\"]:\n",
    "                features[\"game_true\"] = tree_game_true\n",
    "                features[\"game_false\"] = tree_game_false\n",
    "                features['game_accuracy'] = tree_game_true / (tree_game_true + tree_game_false) if (tree_game_true + tree_game_false) != 0 else 0\n",
    "                features[\"game_accuracy_std\"] = np.std(tree_game_acc) if len(tree_game_acc) >=1 else 0\n",
    "                features[\"last_game_acc\"] = tree_game_acc[-1] if len(tree_game_acc) >=1 else 0\n",
    "            elif session_world == activities_world[\"MAGMAPEAK\"]:\n",
    "                features[\"game_true\"] = magma_game_true\n",
    "                features[\"game_false\"] = magma_game_false\n",
    "                features['game_accuracy'] = magma_game_true / (magma_game_true + magma_game_false) if (magma_game_true + magma_game_false) != 0 else 0\n",
    "                features[\"game_accuracy_std\"] = np.std(magma_game_acc) if len(magma_game_acc) >=1 else 0\n",
    "                features[\"last_game_acc\"] = magma_game_acc[-1] if len(magma_game_acc) >=1 else 0\n",
    "                \n",
    "            features['installation_id'] = session['installation_id'].iloc[-1]\n",
    "            features['session_title'] = session_title\n",
    "            features[\"prev_assess_title\"] = prev_assess_title\n",
    "            prev_assess_title = session_title\n",
    "            features[\"first_assessment\"] = 1 if assess_count == 1 else 0\n",
    "            #features[\"assess_count\"] = assess_count\n",
    "            assess_count += 1\n",
    "            features[\"time_from_start\"] = (assess_start - time_first_activity).seconds\n",
    "\n",
    "            if prev_assess_end == -999:\n",
    "                features[\"time_bet_assess\"] = -999\n",
    "            else:\n",
    "                features[\"time_bet_assess\"] = (assess_start - prev_assess_end).seconds\n",
    "            prev_assess_start = assess_start\n",
    "            prev_assess_end = assess_end\n",
    "            if real_prev_assess_end == -999:\n",
    "                features[\"time_bet_real_assess\"] = -999\n",
    "            else:\n",
    "                features[\"time_bet_real_assess\"] = (real_assess_start - real_prev_assess_end).seconds\n",
    "            real_prev_assess_start = real_assess_start\n",
    "            real_prev_assess_end = real_assess_end\n",
    "            if durations == []: #span of timestamp in target assessment\n",
    "                features['duration_mean'] = 0\n",
    "                features['duration_std'] = 0\n",
    "                features['duration_max'] = 0\n",
    "            else:\n",
    "                features['duration_mean'] = np.mean(durations)\n",
    "                features['duration_std'] = np.std(durations)\n",
    "                features['duration_max'] = np.max(durations)\n",
    "            durations.append((session.iloc[-1, 2] - session.iloc[0, 2]).seconds)\n",
    "            \n",
    "            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "            features['last_assess_acc'] = last_accuracy\n",
    "            last_accuracy_title['acc_' + session_title_text] = accuracy\n",
    "            last_accuracy = accuracy\n",
    "            if accuracy == 0:\n",
    "                features['accuracy_group'] = 0\n",
    "            elif accuracy == 1:\n",
    "                features['accuracy_group'] = 3\n",
    "            elif accuracy == 0.5:\n",
    "                features['accuracy_group'] = 2\n",
    "            else:\n",
    "                features['accuracy_group'] = 1\n",
    "            features.update(accuracy_groups)\n",
    "            accuracy_groups[str(features['accuracy_group'])] += 1\n",
    "            features['accumulated_accuracy_group'] = accumulated_accuracy_group/counter if counter > 0 else 0\n",
    "            accumulated_accuracy_group += features['accuracy_group']\n",
    "            \n",
    "            if test_set:\n",
    "                all_assessments.append(features)\n",
    "            elif true_attempts+false_attempts > 0:\n",
    "                all_assessments.append(features)\n",
    "                \n",
    "            counter += 1\n",
    "            \n",
    "        complete_games += np.sum(session[\"game_complete\"])\n",
    "        miss += np.sum(session[\"misses\"])\n",
    "        user_world_count[\"world_\"+str(session_world)] += session.shape[0]\n",
    "        \n",
    "        n_of_type_world = Counter(session['type_world']) \n",
    "        for key in n_of_type_world.keys():\n",
    "            type_world_count[str(key)] += n_of_type_world[key]\n",
    "            \n",
    "        n_of_title = Counter(session['title']) \n",
    "        for key in n_of_title.keys():\n",
    "            title_count[activities_labels[key]] += n_of_title[key]\n",
    "            \n",
    "        n_of_eventcode = Counter(session['event_code']) \n",
    "        for key in n_of_eventcode.keys():\n",
    "            event_code_count[str(key)] += n_of_eventcode[key]\n",
    "                        \n",
    "        n_of_title_eventcode = Counter(session['title_event_code']) \n",
    "        for key in n_of_title_eventcode.keys():\n",
    "            title_eventcode_count[str(key)] += n_of_title_eventcode[key]\n",
    "        \n",
    "        accumulated_actions += len(session)\n",
    "        if last_activity != session_type:\n",
    "            user_activities_count[session_type] += 1\n",
    "            last_activitiy = session_type\n",
    "    if test_set:\n",
    "        return all_assessments[-1], all_assessments[:-1] # test previous data to incorporate int\n",
    "    return all_assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b0b8aeb5674479a32fcbe13a7b23ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Installation_id', max=17000, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243644499aa74f15b6d68a7c8945e257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Installation_id', max=1000, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_train_and_test(train, test):\n",
    "    compiled_train = []\n",
    "    compiled_test = []\n",
    "    compiled_val = []\n",
    "\n",
    "    for i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort=False)), total=train.installation_id.nunique(), desc='Installation_id', position=0):\n",
    "        compiled_train += get_data(user_sample)\n",
    "    del train\n",
    "    for ins_id, user_sample in tqdm(test.groupby('installation_id', sort=False), total=test.installation_id.nunique(), desc='Installation_id', position=0):\n",
    "        test_data, val_data = get_data(user_sample, test_set=True)\n",
    "        compiled_test.append(test_data)\n",
    "        compiled_val += val_data\n",
    "    del test\n",
    "    reduce_train = pd.DataFrame(compiled_train)\n",
    "    reduce_test = pd.DataFrame(compiled_test)\n",
    "    reduce_val = pd.DataFrame(compiled_val)\n",
    "\n",
    "    categoricals = ['session_title']\n",
    "    return reduce_train, reduce_test, reduce_val, categoricals\n",
    "new_train, new_test, new_val, categoricals = get_train_and_test(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Feature selection and modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = new_train.corr().abs()\n",
    "correlations = correlations.mask(np.tril(np.ones(correlations.shape)).astype(np.bool))\n",
    "correlations = correlations.stack().reset_index()\n",
    "corr_columns = [\"level_0\", \"level_1\", \"value\"]\n",
    "correlations.columns = corr_columns\n",
    "correlations = correlations.sort_values(\"value\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "high_corr = correlations[correlations[\"value\"] >= 0.995]\n",
    "\n",
    "high_corr_features = []\n",
    "for i in range(high_corr.shape[0]):\n",
    "    if high_corr.iloc[i][\"level_0\"] not in high_corr_features and high_corr.iloc[i][\"level_1\"] not in high_corr_features:\n",
    "        high_corr_features.append(high_corr.iloc[i][\"level_0\"])\n",
    "    elif high_corr.iloc[i][\"level_0\"] in high_corr_features and high_corr.iloc[i][\"level_1\"] not in high_corr_features:\n",
    "        high_corr_features.append(high_corr.iloc[i][\"level_1\"])\n",
    "    elif high_corr.iloc[i][\"level_0\"] not in high_corr_features and high_corr.iloc[i][\"level_1\"] in high_corr_features:\n",
    "        high_corr_features.append(high_corr.iloc[i][\"level_0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_assessment(reduce_train):\n",
    "    used_idx = []\n",
    "    #for iid in tqdm(set(reduce_train['installation_id']), miniters=200):\n",
    "    for iid in set(reduce_train['installation_id']):\n",
    "        list_ = list(reduce_train[reduce_train['installation_id'] == iid].index)\n",
    "        cur = random.choices(list_, k=1)[0]\n",
    "        used_idx.append(cur)\n",
    "    reduce_train_t = reduce_train.loc[used_idx]\n",
    "    return reduce_train_t, used_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 random try 1\n",
      "Train on 14152 samples, validate on 721 samples\n",
      "Epoch 1/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.7657\n",
      "Epoch 00001: val_loss improved from inf to 1.25849, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 5s 323us/sample - loss: 1.7627 - val_loss: 1.2585\n",
      "Epoch 2/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.2970\n",
      "Epoch 00002: val_loss improved from 1.25849 to 1.22248, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 184us/sample - loss: 1.2954 - val_loss: 1.2225\n",
      "Epoch 3/25\n",
      "13856/14152 [============================>.] - ETA: 0s - loss: 1.2321\n",
      "Epoch 00003: val_loss improved from 1.22248 to 1.18313, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 192us/sample - loss: 1.2300 - val_loss: 1.1831\n",
      "Epoch 4/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.1608\n",
      "Epoch 00004: val_loss improved from 1.18313 to 1.17296, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 183us/sample - loss: 1.1619 - val_loss: 1.1730\n",
      "Epoch 5/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.1249\n",
      "Epoch 00005: val_loss did not improve from 1.17296\n",
      "14152/14152 [==============================] - 3s 196us/sample - loss: 1.1259 - val_loss: 1.1855\n",
      "Epoch 6/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.1096\n",
      "Epoch 00006: val_loss did not improve from 1.17296\n",
      "14152/14152 [==============================] - 3s 203us/sample - loss: 1.1125 - val_loss: 1.1863\n",
      "Epoch 7/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.0991\n",
      "Epoch 00007: val_loss improved from 1.17296 to 1.16302, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 191us/sample - loss: 1.1024 - val_loss: 1.1630\n",
      "Epoch 8/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.0827\n",
      "Epoch 00008: val_loss improved from 1.16302 to 1.15258, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 178us/sample - loss: 1.0825 - val_loss: 1.1526\n",
      "Epoch 9/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0673\n",
      "Epoch 00009: val_loss did not improve from 1.15258\n",
      "14152/14152 [==============================] - 3s 188us/sample - loss: 1.0675 - val_loss: 1.1870\n",
      "Epoch 10/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.0498\n",
      "Epoch 00010: val_loss did not improve from 1.15258\n",
      "14152/14152 [==============================] - 3s 186us/sample - loss: 1.0495 - val_loss: 1.1768\n",
      "Epoch 11/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 1.0408\n",
      "Epoch 00011: val_loss did not improve from 1.15258\n",
      "14152/14152 [==============================] - 3s 181us/sample - loss: 1.0430 - val_loss: 1.1873\n",
      "Epoch 12/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.0277\n",
      "Epoch 00012: val_loss did not improve from 1.15258\n",
      "14152/14152 [==============================] - 3s 179us/sample - loss: 1.0274 - val_loss: 1.2007\n",
      "Epoch 13/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.0314\n",
      "Epoch 00013: val_loss did not improve from 1.15258\n",
      "14152/14152 [==============================] - 3s 181us/sample - loss: 1.0310 - val_loss: 1.1771\n",
      "Epoch 14/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 1.0175\n",
      "Epoch 00014: val_loss did not improve from 1.15258\n",
      "14152/14152 [==============================] - 3s 185us/sample - loss: 1.0172 - val_loss: 1.1651\n",
      "Epoch 15/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.0000\n",
      "Epoch 00015: val_loss did not improve from 1.15258\n",
      "14152/14152 [==============================] - 3s 181us/sample - loss: 1.0010 - val_loss: 1.1750\n",
      "Epoch 16/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9880\n",
      "Epoch 00016: val_loss did not improve from 1.15258\n",
      "14152/14152 [==============================] - 2s 177us/sample - loss: 0.9872 - val_loss: 1.2009\n",
      "Epoch 17/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9846\n",
      "Epoch 00017: val_loss did not improve from 1.15258\n",
      "14152/14152 [==============================] - 3s 185us/sample - loss: 0.9842 - val_loss: 1.1876\n",
      "Epoch 18/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.9621\n",
      "Epoch 00018: val_loss did not improve from 1.15258\n",
      "14152/14152 [==============================] - 3s 188us/sample - loss: 0.9624 - val_loss: 1.1956\n",
      "Epoch 19/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.9496\n",
      "Epoch 00019: val_loss did not improve from 1.15258\n",
      "14152/14152 [==============================] - 3s 182us/sample - loss: 0.9506 - val_loss: 1.1626\n",
      "Epoch 20/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9427\n",
      "Epoch 00020: val_loss did not improve from 1.15258\n",
      "14152/14152 [==============================] - 3s 182us/sample - loss: 0.9439 - val_loss: 1.1967\n",
      "Epoch 21/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.9299\n",
      "Epoch 00021: val_loss did not improve from 1.15258\n",
      "14152/14152 [==============================] - 3s 197us/sample - loss: 0.9297 - val_loss: 1.1768\n",
      "Epoch 22/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9262\n",
      "Epoch 00022: val_loss did not improve from 1.15258\n",
      "14152/14152 [==============================] - 3s 246us/sample - loss: 0.9272 - val_loss: 1.1641\n",
      "Epoch 23/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.9223\n",
      "Epoch 00023: val_loss did not improve from 1.15258\n",
      "14152/14152 [==============================] - 3s 209us/sample - loss: 0.9223 - val_loss: 1.2399\n",
      "Epoch 24/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9143\n",
      "Epoch 00024: val_loss did not improve from 1.15258\n",
      "14152/14152 [==============================] - 3s 180us/sample - loss: 0.9138 - val_loss: 1.1734\n",
      "Epoch 25/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9051\n",
      "Epoch 00025: val_loss did not improve from 1.15258\n",
      "14152/14152 [==============================] - 3s 188us/sample - loss: 0.9050 - val_loss: 1.2197\n",
      "0 [1.07615687 1.78524491 2.09886092] 0.5245463\n",
      "1 [1.05013713 1.81266848 2.09052571] 0.52225854\n",
      "2 [1.02748907 1.80941345 2.09377214] 0.52272835\n",
      "3 [1.0765634  1.79368418 2.12969118] 0.52371118\n",
      "4 [1.07844916 1.7897766  2.13151528] 0.52371118\n",
      "5 [1.06827241 1.82584471 2.09255749] 0.52200001\n",
      "6 [1.04398259 1.79173516 2.09446357] 0.52371936\n",
      "7 [1.04111789 1.81302813 2.08917243] 0.52282556\n",
      "8 [1.07937139 1.80136661 2.09714828] 0.52312984\n",
      "9 [1.0422965  1.83926251 2.08929867] 0.52172427\n",
      "10 [1.0296886  1.78993822 2.09580572] 0.52362456\n",
      "11 [1.18796452 1.83102121 2.09424826] 0.52417511\n",
      "12 [1.07928889 1.78889806 2.13083243] 0.52371118\n",
      "13 [1.04986596 1.79072249 2.08919899] 0.52438189\n",
      "14 [1.02904745 1.79186482 2.12919968] 0.52185549\n",
      "15 [1.05795299 1.79183222 2.11184348] 0.52258636\n",
      "16 [1.07189041 1.85133034 2.09266058] 0.52276302\n",
      "17 [1.0777884  1.81416961 2.1183073 ] 0.52281738\n",
      "18 [1.06691654 1.78682863 2.09381881] 0.52363574\n",
      "19 [1.03375937 1.79211626 2.11476192] 0.52230958\n",
      "Fold 1 random try 2\n",
      "Train on 14152 samples, validate on 721 samples\n",
      "Epoch 1/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.6723\n",
      "Epoch 00001: val_loss improved from inf to 1.19821, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 4s 274us/sample - loss: 1.6703 - val_loss: 1.1982\n",
      "Epoch 2/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.2839\n",
      "Epoch 00002: val_loss improved from 1.19821 to 1.12818, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 186us/sample - loss: 1.2833 - val_loss: 1.1282\n",
      "Epoch 3/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.1864\n",
      "Epoch 00003: val_loss improved from 1.12818 to 1.12079, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 184us/sample - loss: 1.1855 - val_loss: 1.1208\n",
      "Epoch 4/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.1463\n",
      "Epoch 00004: val_loss did not improve from 1.12079\n",
      "14152/14152 [==============================] - 3s 185us/sample - loss: 1.1484 - val_loss: 1.1313\n",
      "Epoch 5/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.1150\n",
      "Epoch 00005: val_loss improved from 1.12079 to 1.11907, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 191us/sample - loss: 1.1150 - val_loss: 1.1191\n",
      "Epoch 6/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 1.0881\n",
      "Epoch 00006: val_loss did not improve from 1.11907\n",
      "14152/14152 [==============================] - 3s 187us/sample - loss: 1.0917 - val_loss: 1.1242\n",
      "Epoch 7/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.0855\n",
      "Epoch 00007: val_loss did not improve from 1.11907\n",
      "14152/14152 [==============================] - 3s 184us/sample - loss: 1.0872 - val_loss: 1.1255\n",
      "Epoch 8/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.0647\n",
      "Epoch 00008: val_loss improved from 1.11907 to 1.10616, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 184us/sample - loss: 1.0645 - val_loss: 1.1062\n",
      "Epoch 9/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.0503\n",
      "Epoch 00009: val_loss did not improve from 1.10616\n",
      "14152/14152 [==============================] - 3s 185us/sample - loss: 1.0514 - val_loss: 1.1499\n",
      "Epoch 10/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.0380\n",
      "Epoch 00010: val_loss did not improve from 1.10616\n",
      "14152/14152 [==============================] - 3s 185us/sample - loss: 1.0378 - val_loss: 1.1391\n",
      "Epoch 11/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.0179\n",
      "Epoch 00011: val_loss did not improve from 1.10616\n",
      "14152/14152 [==============================] - 3s 187us/sample - loss: 1.0192 - val_loss: 1.1492\n",
      "Epoch 12/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.0121\n",
      "Epoch 00012: val_loss did not improve from 1.10616\n",
      "14152/14152 [==============================] - 3s 192us/sample - loss: 1.0122 - val_loss: 1.1805\n",
      "Epoch 13/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 1.0021\n",
      "Epoch 00013: val_loss did not improve from 1.10616\n",
      "14152/14152 [==============================] - 3s 196us/sample - loss: 1.0014 - val_loss: 1.1541\n",
      "Epoch 14/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9903\n",
      "Epoch 00014: val_loss did not improve from 1.10616\n",
      "14152/14152 [==============================] - 3s 189us/sample - loss: 0.9909 - val_loss: 1.1388\n",
      "Epoch 15/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9854\n",
      "Epoch 00015: val_loss did not improve from 1.10616\n",
      "14152/14152 [==============================] - 3s 187us/sample - loss: 0.9881 - val_loss: 1.1267\n",
      "Epoch 16/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9631\n",
      "Epoch 00016: val_loss did not improve from 1.10616\n",
      "14152/14152 [==============================] - 3s 187us/sample - loss: 0.9617 - val_loss: 1.1655\n",
      "Epoch 17/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.9700\n",
      "Epoch 00017: val_loss did not improve from 1.10616\n",
      "14152/14152 [==============================] - 3s 182us/sample - loss: 0.9688 - val_loss: 1.1582\n",
      "Epoch 18/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.9384\n",
      "Epoch 00018: val_loss did not improve from 1.10616\n",
      "14152/14152 [==============================] - 3s 184us/sample - loss: 0.9394 - val_loss: 1.1792\n",
      "Epoch 19/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.9397\n",
      "Epoch 00019: val_loss did not improve from 1.10616\n",
      "14152/14152 [==============================] - 3s 195us/sample - loss: 0.9402 - val_loss: 1.1625\n",
      "Epoch 20/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.9283\n",
      "Epoch 00020: val_loss did not improve from 1.10616\n",
      "14152/14152 [==============================] - 3s 184us/sample - loss: 0.9288 - val_loss: 1.1796\n",
      "Epoch 21/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9163\n",
      "Epoch 00021: val_loss did not improve from 1.10616\n",
      "14152/14152 [==============================] - 3s 186us/sample - loss: 0.9163 - val_loss: 1.1670\n",
      "Epoch 22/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.9068\n",
      "Epoch 00022: val_loss did not improve from 1.10616\n",
      "14152/14152 [==============================] - 3s 192us/sample - loss: 0.9099 - val_loss: 1.1819\n",
      "Epoch 23/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9001\n",
      "Epoch 00023: val_loss did not improve from 1.10616\n",
      "14152/14152 [==============================] - 3s 185us/sample - loss: 0.9000 - val_loss: 1.1925\n",
      "Epoch 24/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.8876\n",
      "Epoch 00024: val_loss did not improve from 1.10616\n",
      "14152/14152 [==============================] - 3s 186us/sample - loss: 0.8869 - val_loss: 1.1764\n",
      "Epoch 25/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.8818\n",
      "Epoch 00025: val_loss did not improve from 1.10616\n",
      "14152/14152 [==============================] - 3s 183us/sample - loss: 0.8824 - val_loss: 1.2042\n",
      "0 [1.03673576 1.73231461 2.29122733] 0.56829779\n",
      "1 [0.97083019 1.79180254 2.33108075] 0.57421574\n",
      "2 [0.99276625 1.79644672 2.33043614] 0.57523249\n",
      "3 [1.04443246 1.79477731 2.3292416 ] 0.57376266\n",
      "4 [1.00098948 1.79557481 2.32917694] 0.57538968\n",
      "5 [1.00269857 1.86561772 2.3489321 ] 0.57287006\n",
      "6 [0.99140748 1.79593363 2.32947768] 0.57523249\n",
      "7 [1.03863285 1.73613167 2.33194819] 0.57403773\n",
      "8 [1.00422241 1.73413861 2.33140722] 0.57387707\n",
      "9 [0.99488823 1.87327993 2.33065211] 0.57570275\n",
      "10 [1.02318918 1.72629796 2.33349837] 0.57467373\n",
      "11 [0.99387504 1.79660635 2.33481777] 0.57523249\n",
      "12 [0.99722941 1.77848019 2.33551252] 0.57369663\n",
      "13 [0.8709172  1.7940286  2.33321138] 0.57609585\n",
      "14 [0.95407793 1.73626659 2.33072166] 0.57244627\n",
      "15 [1.0235782  1.72560792 2.33012789] 0.57467373\n",
      "16 [0.98942741 1.73567675 2.33555154] 0.57371558\n",
      "17 [0.99792249 1.81709392 2.33560173] 0.572705\n",
      "18 [0.99546628 1.87196425 2.32798222] 0.57455564\n",
      "19 [0.99884979 1.73789763 2.33143436] 0.57371558\n",
      "Fold 1 random try 3\n",
      "Train on 14152 samples, validate on 721 samples\n",
      "Epoch 1/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.7024\n",
      "Epoch 00001: val_loss improved from inf to 1.22677, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 4s 252us/sample - loss: 1.6986 - val_loss: 1.2268\n",
      "Epoch 2/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.2618\n",
      "Epoch 00002: val_loss improved from 1.22677 to 1.16586, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 184us/sample - loss: 1.2622 - val_loss: 1.1659\n",
      "Epoch 3/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.1920\n",
      "Epoch 00003: val_loss improved from 1.16586 to 1.16313, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 222us/sample - loss: 1.1909 - val_loss: 1.1631\n",
      "Epoch 4/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.1424\n",
      "Epoch 00004: val_loss improved from 1.16313 to 1.14722, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 236us/sample - loss: 1.1445 - val_loss: 1.1472\n",
      "Epoch 5/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.1130\n",
      "Epoch 00005: val_loss improved from 1.14722 to 1.13985, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 235us/sample - loss: 1.1131 - val_loss: 1.1399\n",
      "Epoch 6/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.0959\n",
      "Epoch 00006: val_loss improved from 1.13985 to 1.13141, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 204us/sample - loss: 1.0992 - val_loss: 1.1314\n",
      "Epoch 7/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 1.0886\n",
      "Epoch 00007: val_loss did not improve from 1.13141\n",
      "14152/14152 [==============================] - 3s 187us/sample - loss: 1.0900 - val_loss: 1.1430\n",
      "Epoch 8/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.0736\n",
      "Epoch 00008: val_loss improved from 1.13141 to 1.12891, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 184us/sample - loss: 1.0731 - val_loss: 1.1289\n",
      "Epoch 9/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.0619\n",
      "Epoch 00009: val_loss did not improve from 1.12891\n",
      "14152/14152 [==============================] - 3s 182us/sample - loss: 1.0600 - val_loss: 1.1461\n",
      "Epoch 10/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.0449\n",
      "Epoch 00010: val_loss did not improve from 1.12891\n",
      "14152/14152 [==============================] - 3s 191us/sample - loss: 1.0448 - val_loss: 1.1518\n",
      "Epoch 11/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0226\n",
      "Epoch 00011: val_loss did not improve from 1.12891\n",
      "14152/14152 [==============================] - 3s 187us/sample - loss: 1.0243 - val_loss: 1.1695\n",
      "Epoch 12/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0155\n",
      "Epoch 00012: val_loss did not improve from 1.12891\n",
      "14152/14152 [==============================] - 3s 197us/sample - loss: 1.0148 - val_loss: 1.1528\n",
      "Epoch 13/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0119\n",
      "Epoch 00013: val_loss did not improve from 1.12891\n",
      "14152/14152 [==============================] - 3s 189us/sample - loss: 1.0109 - val_loss: 1.1718\n",
      "Epoch 14/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0077\n",
      "Epoch 00014: val_loss improved from 1.12891 to 1.12251, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 192us/sample - loss: 1.0076 - val_loss: 1.1225\n",
      "Epoch 15/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.9831\n",
      "Epoch 00015: val_loss did not improve from 1.12251\n",
      "14152/14152 [==============================] - 3s 193us/sample - loss: 0.9833 - val_loss: 1.1402\n",
      "Epoch 16/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9755\n",
      "Epoch 00016: val_loss did not improve from 1.12251\n",
      "14152/14152 [==============================] - 4s 269us/sample - loss: 0.9745 - val_loss: 1.1450\n",
      "Epoch 17/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.9666\n",
      "Epoch 00017: val_loss did not improve from 1.12251\n",
      "14152/14152 [==============================] - 3s 221us/sample - loss: 0.9669 - val_loss: 1.1620\n",
      "Epoch 18/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9531\n",
      "Epoch 00018: val_loss did not improve from 1.12251\n",
      "14152/14152 [==============================] - 3s 203us/sample - loss: 0.9536 - val_loss: 1.1754\n",
      "Epoch 19/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.9470\n",
      "Epoch 00019: val_loss did not improve from 1.12251\n",
      "14152/14152 [==============================] - 3s 195us/sample - loss: 0.9473 - val_loss: 1.1546\n",
      "Epoch 20/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.9344\n",
      "Epoch 00020: val_loss did not improve from 1.12251\n",
      "14152/14152 [==============================] - 3s 200us/sample - loss: 0.9346 - val_loss: 1.1694\n",
      "Epoch 21/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.9282\n",
      "Epoch 00021: val_loss did not improve from 1.12251\n",
      "14152/14152 [==============================] - 3s 206us/sample - loss: 0.9300 - val_loss: 1.1415\n",
      "Epoch 22/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9230\n",
      "Epoch 00022: val_loss did not improve from 1.12251\n",
      "14152/14152 [==============================] - 3s 204us/sample - loss: 0.9242 - val_loss: 1.1906\n",
      "Epoch 23/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9145\n",
      "Epoch 00023: val_loss did not improve from 1.12251\n",
      "14152/14152 [==============================] - 3s 197us/sample - loss: 0.9138 - val_loss: 1.1738\n",
      "Epoch 24/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9017\n",
      "Epoch 00024: val_loss did not improve from 1.12251\n",
      "14152/14152 [==============================] - 3s 193us/sample - loss: 0.9009 - val_loss: 1.1528\n",
      "Epoch 25/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.8954\n",
      "Epoch 00025: val_loss did not improve from 1.12251\n",
      "14152/14152 [==============================] - 3s 201us/sample - loss: 0.8960 - val_loss: 1.1902\n",
      "0 [1.00367478 1.94796548 2.31344922] 0.54046502\n",
      "1 [1.0342434  1.64788164 2.31258699] 0.54054891\n",
      "2 [1.10981229 1.93562808 2.08635278] 0.52849369\n",
      "3 [1.09060868 1.82454498 2.08564886] 0.52613958\n",
      "4 [0.91214254 1.9427257  2.32477567] 0.54744943\n",
      "5 [1.00457071 1.84368036 2.2752375 ] 0.53728819\n",
      "6 [1.09150846 1.8906274  2.31300231] 0.54487171\n",
      "7 [0.90908079 1.96226392 2.31318818] 0.54919127\n",
      "8 [1.09160009 1.65979456 2.3126354 ] 0.54352085\n",
      "9 [1.11570116 1.64641502 2.31301554] 0.54343797\n",
      "10 [1.10795492 1.6491317  2.31247814] 0.54343797\n",
      "11 [0.96810931 1.98060731 2.32207953] 0.54106877\n",
      "12 [1.02830473 1.94855702 2.312148  ] 0.54107218\n",
      "13 [1.03202459 1.89276151 2.27689212] 0.54045076\n",
      "14 [1.10322871 1.86317606 2.13539184] 0.52607914\n",
      "15 [1.1149456  1.83245773 2.08588177] 0.52773361\n",
      "16 [0.98315923 1.83238468 2.28517658] 0.5389425\n",
      "17 [0.88124094 1.89023231 2.31375624] 0.55037145\n",
      "18 [1.12169489 1.63923875 2.31235404] 0.54406921\n",
      "19 [1.12166354 1.88861406 2.31315054] 0.54510216\n",
      "Fold 1 random try 4\n",
      "Train on 14152 samples, validate on 721 samples\n",
      "Epoch 1/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.5821\n",
      "Epoch 00001: val_loss improved from inf to 1.17979, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 4s 284us/sample - loss: 1.5794 - val_loss: 1.1798\n",
      "Epoch 2/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.2358\n",
      "Epoch 00002: val_loss improved from 1.17979 to 1.14783, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 212us/sample - loss: 1.2361 - val_loss: 1.1478\n",
      "Epoch 3/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.1818\n",
      "Epoch 00003: val_loss improved from 1.14783 to 1.14736, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 227us/sample - loss: 1.1787 - val_loss: 1.1474\n",
      "Epoch 4/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.1434\n",
      "Epoch 00004: val_loss improved from 1.14736 to 1.13082, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 209us/sample - loss: 1.1445 - val_loss: 1.1308\n",
      "Epoch 5/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.1092\n",
      "Epoch 00005: val_loss did not improve from 1.13082\n",
      "14152/14152 [==============================] - 3s 203us/sample - loss: 1.1097 - val_loss: 1.1590\n",
      "Epoch 6/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.1070\n",
      "Epoch 00006: val_loss improved from 1.13082 to 1.11742, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 196us/sample - loss: 1.1093 - val_loss: 1.1174\n",
      "Epoch 7/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.0894\n",
      "Epoch 00007: val_loss did not improve from 1.11742\n",
      "14152/14152 [==============================] - 3s 196us/sample - loss: 1.0915 - val_loss: 1.1376\n",
      "Epoch 8/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.0756\n",
      "Epoch 00008: val_loss did not improve from 1.11742\n",
      "14152/14152 [==============================] - 3s 202us/sample - loss: 1.0745 - val_loss: 1.1431\n",
      "Epoch 9/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0647\n",
      "Epoch 00009: val_loss did not improve from 1.11742\n",
      "14152/14152 [==============================] - 3s 195us/sample - loss: 1.0647 - val_loss: 1.1465\n",
      "Epoch 10/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.0426\n",
      "Epoch 00010: val_loss did not improve from 1.11742\n",
      "14152/14152 [==============================] - 3s 191us/sample - loss: 1.0430 - val_loss: 1.1355\n",
      "Epoch 11/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.0391\n",
      "Epoch 00011: val_loss did not improve from 1.11742\n",
      "14152/14152 [==============================] - 3s 190us/sample - loss: 1.0404 - val_loss: 1.1446\n",
      "Epoch 12/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0275\n",
      "Epoch 00012: val_loss did not improve from 1.11742\n",
      "14152/14152 [==============================] - 3s 205us/sample - loss: 1.0282 - val_loss: 1.1330\n",
      "Epoch 13/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.0199\n",
      "Epoch 00013: val_loss did not improve from 1.11742\n",
      "14152/14152 [==============================] - 3s 197us/sample - loss: 1.0193 - val_loss: 1.1624\n",
      "Epoch 14/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.0096\n",
      "Epoch 00014: val_loss did not improve from 1.11742\n",
      "14152/14152 [==============================] - 3s 203us/sample - loss: 1.0094 - val_loss: 1.1260\n",
      "Epoch 15/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0026\n",
      "Epoch 00015: val_loss did not improve from 1.11742\n",
      "14152/14152 [==============================] - 3s 212us/sample - loss: 1.0051 - val_loss: 1.1322\n",
      "Epoch 16/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 0.9886\n",
      "Epoch 00016: val_loss did not improve from 1.11742\n",
      "14152/14152 [==============================] - 3s 216us/sample - loss: 0.9885 - val_loss: 1.1425\n",
      "Epoch 17/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9836\n",
      "Epoch 00017: val_loss did not improve from 1.11742\n",
      "14152/14152 [==============================] - 3s 214us/sample - loss: 0.9834 - val_loss: 1.1234\n",
      "Epoch 18/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9655\n",
      "Epoch 00018: val_loss did not improve from 1.11742\n",
      "14152/14152 [==============================] - 3s 206us/sample - loss: 0.9662 - val_loss: 1.1464\n",
      "Epoch 19/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.9660\n",
      "Epoch 00019: val_loss did not improve from 1.11742\n",
      "14152/14152 [==============================] - 3s 203us/sample - loss: 0.9666 - val_loss: 1.1389\n",
      "Epoch 20/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9545\n",
      "Epoch 00020: val_loss did not improve from 1.11742\n",
      "14152/14152 [==============================] - 3s 196us/sample - loss: 0.9541 - val_loss: 1.1421\n",
      "Epoch 21/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.9420\n",
      "Epoch 00021: val_loss did not improve from 1.11742\n",
      "14152/14152 [==============================] - 3s 190us/sample - loss: 0.9426 - val_loss: 1.1285\n",
      "Epoch 22/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.9320\n",
      "Epoch 00022: val_loss did not improve from 1.11742\n",
      "14152/14152 [==============================] - 3s 196us/sample - loss: 0.9347 - val_loss: 1.1598\n",
      "Epoch 23/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.9347\n",
      "Epoch 00023: val_loss did not improve from 1.11742\n",
      "14152/14152 [==============================] - 3s 211us/sample - loss: 0.9335 - val_loss: 1.1643\n",
      "Epoch 24/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9143\n",
      "Epoch 00024: val_loss did not improve from 1.11742\n",
      "14152/14152 [==============================] - 3s 199us/sample - loss: 0.9140 - val_loss: 1.1784\n",
      "Epoch 25/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.9176\n",
      "Epoch 00025: val_loss did not improve from 1.11742\n",
      "14152/14152 [==============================] - 3s 203us/sample - loss: 0.9181 - val_loss: 1.1994\n",
      "0 [1.0834182  1.61231105 2.26859677] 0.54553312\n",
      "1 [1.08007765 1.70666306 2.27019437] 0.54585604\n",
      "2 [0.89690622 1.88189351 2.24184866] 0.5534956\n",
      "3 [1.08160811 1.57689976 2.24676493] 0.54869015\n",
      "4 [1.07983318 1.82029005 2.2404815 ] 0.54544069\n",
      "5 [1.0880763  1.87664792 2.24658456] 0.54480977\n",
      "6 [0.89311451 1.91843869 2.20588259] 0.5513735\n",
      "7 [0.9340225  1.82285048 2.27054556] 0.55082475\n",
      "8 [1.1239323  1.53922734 2.26862528] 0.5425973\n",
      "9 [1.08044084 1.62462362 2.26947488] 0.5476608\n",
      "10 [0.93268749 1.90074039 2.24672002] 0.55047733\n",
      "11 [0.95479765 1.94705845 2.32943003] 0.55095889\n",
      "12 [1.06845955 1.85778827 2.26857351] 0.54375203\n",
      "13 [0.95681623 1.91968162 2.26763449] 0.5538491\n",
      "14 [0.95332619 1.87776341 2.24041274] 0.55289182\n",
      "15 [0.94158022 1.87677856 2.24565206] 0.55213892\n",
      "16 [1.06355036 1.85987426 2.24056882] 0.54424072\n",
      "17 [0.95464798 1.91982029 2.24055548] 0.55423045\n",
      "18 [0.89716738 1.93854509 2.240647  ] 0.5562994\n",
      "19 [0.94032152 1.85909471 2.23672479] 0.55076518\n",
      "Fold 1 random try 5\n",
      "Train on 14152 samples, validate on 721 samples\n",
      "Epoch 1/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.7331\n",
      "Epoch 00001: val_loss improved from inf to 1.17326, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 4s 297us/sample - loss: 1.7305 - val_loss: 1.1733\n",
      "Epoch 2/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.2968\n",
      "Epoch 00002: val_loss improved from 1.17326 to 1.11475, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 207us/sample - loss: 1.2968 - val_loss: 1.1147\n",
      "Epoch 3/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.2047\n",
      "Epoch 00003: val_loss improved from 1.11475 to 1.10646, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 204us/sample - loss: 1.2042 - val_loss: 1.1065\n",
      "Epoch 4/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.1560\n",
      "Epoch 00004: val_loss improved from 1.10646 to 1.09718, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 211us/sample - loss: 1.1568 - val_loss: 1.0972\n",
      "Epoch 5/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.1230\n",
      "Epoch 00005: val_loss improved from 1.09718 to 1.09581, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 213us/sample - loss: 1.1234 - val_loss: 1.0958\n",
      "Epoch 6/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.1086\n",
      "Epoch 00006: val_loss did not improve from 1.09581\n",
      "14152/14152 [==============================] - 3s 213us/sample - loss: 1.1117 - val_loss: 1.1021\n",
      "Epoch 7/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.0993\n",
      "Epoch 00007: val_loss improved from 1.09581 to 1.09273, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 215us/sample - loss: 1.1013 - val_loss: 1.0927\n",
      "Epoch 8/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0692\n",
      "Epoch 00008: val_loss improved from 1.09273 to 1.07193, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 206us/sample - loss: 1.0685 - val_loss: 1.0719\n",
      "Epoch 9/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0652\n",
      "Epoch 00009: val_loss did not improve from 1.07193\n",
      "14152/14152 [==============================] - 3s 211us/sample - loss: 1.0645 - val_loss: 1.1028\n",
      "Epoch 10/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0408\n",
      "Epoch 00010: val_loss did not improve from 1.07193\n",
      "14152/14152 [==============================] - 3s 204us/sample - loss: 1.0411 - val_loss: 1.0958\n",
      "Epoch 11/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0340\n",
      "Epoch 00011: val_loss did not improve from 1.07193\n",
      "14152/14152 [==============================] - 3s 206us/sample - loss: 1.0353 - val_loss: 1.0959\n",
      "Epoch 12/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.0273\n",
      "Epoch 00012: val_loss did not improve from 1.07193\n",
      "14152/14152 [==============================] - 3s 205us/sample - loss: 1.0270 - val_loss: 1.1199\n",
      "Epoch 13/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0167\n",
      "Epoch 00013: val_loss did not improve from 1.07193\n",
      "14152/14152 [==============================] - 3s 206us/sample - loss: 1.0157 - val_loss: 1.1144\n",
      "Epoch 14/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0024\n",
      "Epoch 00014: val_loss did not improve from 1.07193\n",
      "14152/14152 [==============================] - 3s 198us/sample - loss: 1.0029 - val_loss: 1.0848\n",
      "Epoch 15/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.9871\n",
      "Epoch 00015: val_loss did not improve from 1.07193\n",
      "14152/14152 [==============================] - 3s 201us/sample - loss: 0.9887 - val_loss: 1.0898\n",
      "Epoch 16/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.9827\n",
      "Epoch 00016: val_loss did not improve from 1.07193\n",
      "14152/14152 [==============================] - 4s 259us/sample - loss: 0.9811 - val_loss: 1.1114\n",
      "Epoch 17/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.9751\n",
      "Epoch 00017: val_loss did not improve from 1.07193\n",
      "14152/14152 [==============================] - 4s 276us/sample - loss: 0.9741 - val_loss: 1.1058\n",
      "Epoch 18/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.9567\n",
      "Epoch 00018: val_loss did not improve from 1.07193\n",
      "14152/14152 [==============================] - 3s 205us/sample - loss: 0.9568 - val_loss: 1.1106\n",
      "Epoch 19/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9459\n",
      "Epoch 00019: val_loss did not improve from 1.07193\n",
      "14152/14152 [==============================] - 3s 205us/sample - loss: 0.9470 - val_loss: 1.1171\n",
      "Epoch 20/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9406\n",
      "Epoch 00020: val_loss did not improve from 1.07193\n",
      "14152/14152 [==============================] - 3s 208us/sample - loss: 0.9417 - val_loss: 1.1271\n",
      "Epoch 21/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.9241\n",
      "Epoch 00021: val_loss did not improve from 1.07193\n",
      "14152/14152 [==============================] - 3s 203us/sample - loss: 0.9238 - val_loss: 1.1166\n",
      "Epoch 22/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.9161\n",
      "Epoch 00022: val_loss did not improve from 1.07193\n",
      "14152/14152 [==============================] - 3s 196us/sample - loss: 0.9174 - val_loss: 1.1264\n",
      "Epoch 23/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9107\n",
      "Epoch 00023: val_loss did not improve from 1.07193\n",
      "14152/14152 [==============================] - 3s 200us/sample - loss: 0.9109 - val_loss: 1.1369\n",
      "Epoch 24/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.8978\n",
      "Epoch 00024: val_loss did not improve from 1.07193\n",
      "14152/14152 [==============================] - 3s 206us/sample - loss: 0.8982 - val_loss: 1.1094\n",
      "Epoch 25/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.8875\n",
      "Epoch 00025: val_loss did not improve from 1.07193\n",
      "14152/14152 [==============================] - 3s 203us/sample - loss: 0.8883 - val_loss: 1.1240\n",
      "0 [1.01704985 1.94990917 2.2190971 ] 0.58983917\n",
      "1 [1.03475209 1.71313679 2.27801519] 0.59568796\n",
      "2 [1.03312071 1.9587289  2.12093302] 0.5982363\n",
      "3 [1.10607601 1.71706841 2.12194494] 0.59433673\n",
      "4 [1.09313875 1.69835631 2.12099887] 0.59289023\n",
      "5 [1.03417553 1.88454182 2.27808313] 0.59137804\n",
      "6 [1.06574729 1.71051285 2.11937116] 0.59755842\n",
      "7 [1.03168729 1.70475374 2.11948021] 0.59933472\n",
      "8 [1.03710987 1.70913878 2.27918713] 0.59568796\n",
      "9 [1.03421025 1.84197328 2.07020394] 0.5957422\n",
      "10 [1.01994811 1.88189562 2.10904888] 0.59391551\n",
      "11 [1.01907436 1.90111564 2.12128385] 0.59661645\n",
      "12 [1.06183236 1.71351733 2.28774901] 0.59212989\n",
      "13 [1.06549216 1.81421587 2.11967663] 0.59213514\n",
      "14 [1.03351979 1.70810852 2.14495209] 0.59635618\n",
      "15 [1.01899889 1.77801427 2.12084245] 0.59790831\n",
      "16 [1.06740838 1.58326641 2.14410959] 0.5998786\n",
      "17 [1.03256228 1.77765579 2.12082201] 0.59714541\n",
      "18 [1.01740652 1.83949701 2.14815827] 0.59638253\n",
      "19 [1.03648018 1.7879891  2.12171309] 0.59651837\n",
      "Fold 1 random try 6\n",
      "Train on 14152 samples, validate on 721 samples\n",
      "Epoch 1/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.6636\n",
      "Epoch 00001: val_loss improved from inf to 1.20900, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 4s 273us/sample - loss: 1.6607 - val_loss: 1.2090\n",
      "Epoch 2/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.2896\n",
      "Epoch 00002: val_loss improved from 1.20900 to 1.14746, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 197us/sample - loss: 1.2897 - val_loss: 1.1475\n",
      "Epoch 3/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.1994\n",
      "Epoch 00003: val_loss improved from 1.14746 to 1.12659, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 193us/sample - loss: 1.1994 - val_loss: 1.1266\n",
      "Epoch 4/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.1429\n",
      "Epoch 00004: val_loss did not improve from 1.12659\n",
      "14152/14152 [==============================] - 3s 191us/sample - loss: 1.1436 - val_loss: 1.1345\n",
      "Epoch 5/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.1169\n",
      "Epoch 00005: val_loss improved from 1.12659 to 1.11861, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 196us/sample - loss: 1.1170 - val_loss: 1.1186\n",
      "Epoch 6/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.0995\n",
      "Epoch 00006: val_loss did not improve from 1.11861\n",
      "14152/14152 [==============================] - 3s 190us/sample - loss: 1.1016 - val_loss: 1.1218\n",
      "Epoch 7/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0826\n",
      "Epoch 00007: val_loss did not improve from 1.11861\n",
      "14152/14152 [==============================] - 3s 197us/sample - loss: 1.0849 - val_loss: 1.1244\n",
      "Epoch 8/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.0664\n",
      "Epoch 00008: val_loss improved from 1.11861 to 1.10990, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 198us/sample - loss: 1.0658 - val_loss: 1.1099\n",
      "Epoch 9/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0607\n",
      "Epoch 00009: val_loss improved from 1.10990 to 1.10762, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 209us/sample - loss: 1.0599 - val_loss: 1.1076\n",
      "Epoch 10/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.0367\n",
      "Epoch 00010: val_loss did not improve from 1.10762\n",
      "14152/14152 [==============================] - 3s 205us/sample - loss: 1.0363 - val_loss: 1.1196\n",
      "Epoch 11/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0305\n",
      "Epoch 00011: val_loss did not improve from 1.10762\n",
      "14152/14152 [==============================] - 3s 208us/sample - loss: 1.0312 - val_loss: 1.1255\n",
      "Epoch 12/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.0235\n",
      "Epoch 00012: val_loss did not improve from 1.10762\n",
      "14152/14152 [==============================] - 3s 197us/sample - loss: 1.0234 - val_loss: 1.1129\n",
      "Epoch 13/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0188\n",
      "Epoch 00013: val_loss did not improve from 1.10762\n",
      "14152/14152 [==============================] - 3s 196us/sample - loss: 1.0173 - val_loss: 1.1255\n",
      "Epoch 14/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 1.0077\n",
      "Epoch 00014: val_loss improved from 1.10762 to 1.09198, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 202us/sample - loss: 1.0088 - val_loss: 1.0920\n",
      "Epoch 15/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.9891\n",
      "Epoch 00015: val_loss did not improve from 1.09198\n",
      "14152/14152 [==============================] - 3s 199us/sample - loss: 0.9921 - val_loss: 1.1000\n",
      "Epoch 16/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9848\n",
      "Epoch 00016: val_loss did not improve from 1.09198\n",
      "14152/14152 [==============================] - 3s 191us/sample - loss: 0.9837 - val_loss: 1.1195\n",
      "Epoch 17/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.9852\n",
      "Epoch 00017: val_loss did not improve from 1.09198\n",
      "14152/14152 [==============================] - 3s 198us/sample - loss: 0.9856 - val_loss: 1.1234\n",
      "Epoch 18/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 0.9601\n",
      "Epoch 00018: val_loss did not improve from 1.09198\n",
      "14152/14152 [==============================] - 3s 195us/sample - loss: 0.9585 - val_loss: 1.1339\n",
      "Epoch 19/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.9522\n",
      "Epoch 00019: val_loss did not improve from 1.09198\n",
      "14152/14152 [==============================] - 3s 189us/sample - loss: 0.9525 - val_loss: 1.1192\n",
      "Epoch 20/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.9445\n",
      "Epoch 00020: val_loss did not improve from 1.09198\n",
      "14152/14152 [==============================] - 3s 183us/sample - loss: 0.9447 - val_loss: 1.1496\n",
      "Epoch 21/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9233\n",
      "Epoch 00021: val_loss did not improve from 1.09198\n",
      "14152/14152 [==============================] - 3s 180us/sample - loss: 0.9243 - val_loss: 1.1351\n",
      "Epoch 22/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9256\n",
      "Epoch 00022: val_loss did not improve from 1.09198\n",
      "14152/14152 [==============================] - 3s 188us/sample - loss: 0.9264 - val_loss: 1.1476\n",
      "Epoch 23/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.9205\n",
      "Epoch 00023: val_loss did not improve from 1.09198\n",
      "14152/14152 [==============================] - 3s 183us/sample - loss: 0.9212 - val_loss: 1.1638\n",
      "Epoch 24/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9035\n",
      "Epoch 00024: val_loss did not improve from 1.09198\n",
      "14152/14152 [==============================] - 3s 195us/sample - loss: 0.9031 - val_loss: 1.1691\n",
      "Epoch 25/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.8992\n",
      "Epoch 00025: val_loss did not improve from 1.09198\n",
      "14152/14152 [==============================] - 3s 206us/sample - loss: 0.9001 - val_loss: 1.1731\n",
      "0 [1.026316   1.92090379 2.38767894] 0.57526117\n",
      "1 [0.91151469 1.92891091 2.37981034] 0.5758521\n",
      "2 [1.05393532 1.73110659 2.28576058] 0.56323106\n",
      "3 [0.90856011 1.92967884 2.33887452] 0.5783196\n",
      "4 [0.99456047 1.91427379 2.18199703] 0.57326216\n",
      "5 [1.0269524  1.93877188 2.33905318] 0.57854446\n",
      "6 [1.02496407 1.76754226 2.17247059] 0.56134222\n",
      "7 [0.91410274 1.94353016 2.41369621] 0.57734458\n",
      "8 [0.97749561 1.94317908 2.33833973] 0.57553812\n",
      "9 [0.95760567 1.91465509 2.33424013] 0.57508437\n",
      "10 [0.9838174  1.83497743 2.17148733] 0.56677074\n",
      "11 [1.07619533 1.54205139 2.3088119 ] 0.56719784\n",
      "12 [1.00861027 1.94121357 2.33524321] 0.57754491\n",
      "13 [0.99466328 1.83509622 2.17177465] 0.56873718\n",
      "14 [0.98310267 1.94383221 2.35713971] 0.5747589\n",
      "15 [1.0122434  1.85134407 2.18284132] 0.56702654\n",
      "16 [1.0010764  1.94542841 2.33425471] 0.57754491\n",
      "17 [1.00018164 1.94107132 2.33704442] 0.57754491\n",
      "18 [0.88755277 1.93984848 2.18396369] 0.5712731\n",
      "19 [0.91078714 1.94523799 2.33802976] 0.5776735\n",
      "Fold 1 random try 7\n",
      "Train on 14152 samples, validate on 721 samples\n",
      "Epoch 1/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.9631\n",
      "Epoch 00001: val_loss improved from inf to 1.30906, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 4s 305us/sample - loss: 1.9610 - val_loss: 1.3091\n",
      "Epoch 2/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.3392\n",
      "Epoch 00002: val_loss improved from 1.30906 to 1.25645, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 207us/sample - loss: 1.3382 - val_loss: 1.2565\n",
      "Epoch 3/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 1.2447\n",
      "Epoch 00003: val_loss improved from 1.25645 to 1.20787, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 194us/sample - loss: 1.2431 - val_loss: 1.2079\n",
      "Epoch 4/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.1717\n",
      "Epoch 00004: val_loss improved from 1.20787 to 1.20330, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 193us/sample - loss: 1.1718 - val_loss: 1.2033\n",
      "Epoch 5/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.1346\n",
      "Epoch 00005: val_loss did not improve from 1.20330\n",
      "14152/14152 [==============================] - 3s 187us/sample - loss: 1.1360 - val_loss: 1.2353\n",
      "Epoch 6/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.1235\n",
      "Epoch 00006: val_loss did not improve from 1.20330\n",
      "14152/14152 [==============================] - 3s 190us/sample - loss: 1.1260 - val_loss: 1.2230\n",
      "Epoch 7/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.1127\n",
      "Epoch 00007: val_loss did not improve from 1.20330\n",
      "14152/14152 [==============================] - 3s 187us/sample - loss: 1.1149 - val_loss: 1.2454\n",
      "Epoch 8/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0843\n",
      "Epoch 00008: val_loss did not improve from 1.20330\n",
      "14152/14152 [==============================] - 3s 187us/sample - loss: 1.0838 - val_loss: 1.2277\n",
      "Epoch 9/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.0729\n",
      "Epoch 00009: val_loss did not improve from 1.20330\n",
      "14152/14152 [==============================] - 3s 187us/sample - loss: 1.0713 - val_loss: 1.2329\n",
      "Epoch 10/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.0469\n",
      "Epoch 00010: val_loss did not improve from 1.20330\n",
      "14152/14152 [==============================] - 3s 190us/sample - loss: 1.0468 - val_loss: 1.2381\n",
      "Epoch 11/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.0367\n",
      "Epoch 00011: val_loss did not improve from 1.20330\n",
      "14152/14152 [==============================] - 3s 194us/sample - loss: 1.0374 - val_loss: 1.2282\n",
      "Epoch 12/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.0397\n",
      "Epoch 00012: val_loss did not improve from 1.20330\n",
      "14152/14152 [==============================] - 3s 194us/sample - loss: 1.0387 - val_loss: 1.2488\n",
      "Epoch 13/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.0204\n",
      "Epoch 00013: val_loss did not improve from 1.20330\n",
      "14152/14152 [==============================] - 3s 204us/sample - loss: 1.0191 - val_loss: 1.2393\n",
      "Epoch 14/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.0088\n",
      "Epoch 00014: val_loss did not improve from 1.20330\n",
      "14152/14152 [==============================] - 3s 198us/sample - loss: 1.0089 - val_loss: 1.2062\n",
      "Epoch 15/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.9960\n",
      "Epoch 00015: val_loss did not improve from 1.20330\n",
      "14152/14152 [==============================] - 3s 188us/sample - loss: 0.9962 - val_loss: 1.2447\n",
      "Epoch 16/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.9842\n",
      "Epoch 00016: val_loss did not improve from 1.20330\n",
      "14152/14152 [==============================] - 3s 200us/sample - loss: 0.9826 - val_loss: 1.2181\n",
      "Epoch 17/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9758\n",
      "Epoch 00017: val_loss did not improve from 1.20330\n",
      "14152/14152 [==============================] - 3s 198us/sample - loss: 0.9759 - val_loss: 1.2406\n",
      "Epoch 18/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9663\n",
      "Epoch 00018: val_loss did not improve from 1.20330\n",
      "14152/14152 [==============================] - 3s 202us/sample - loss: 0.9673 - val_loss: 1.2550\n",
      "Epoch 19/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.9552\n",
      "Epoch 00019: val_loss did not improve from 1.20330\n",
      "14152/14152 [==============================] - 3s 190us/sample - loss: 0.9556 - val_loss: 1.2389\n",
      "Epoch 20/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9443\n",
      "Epoch 00020: val_loss did not improve from 1.20330\n",
      "14152/14152 [==============================] - 3s 195us/sample - loss: 0.9441 - val_loss: 1.2408\n",
      "Epoch 21/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.9374\n",
      "Epoch 00021: val_loss did not improve from 1.20330\n",
      "14152/14152 [==============================] - 3s 193us/sample - loss: 0.9385 - val_loss: 1.2345\n",
      "Epoch 22/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9244\n",
      "Epoch 00022: val_loss did not improve from 1.20330\n",
      "14152/14152 [==============================] - 3s 198us/sample - loss: 0.9260 - val_loss: 1.2570\n",
      "Epoch 23/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9208\n",
      "Epoch 00023: val_loss did not improve from 1.20330\n",
      "14152/14152 [==============================] - 3s 200us/sample - loss: 0.9201 - val_loss: 1.2397\n",
      "Epoch 24/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 0.9062\n",
      "Epoch 00024: val_loss did not improve from 1.20330\n",
      "14152/14152 [==============================] - 3s 205us/sample - loss: 0.9054 - val_loss: 1.2525\n",
      "Epoch 25/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.9060\n",
      "Epoch 00025: val_loss did not improve from 1.20330\n",
      "14152/14152 [==============================] - 3s 191us/sample - loss: 0.9066 - val_loss: 1.2584\n",
      "0 [0.96409289 1.95481752 2.26583927] 0.53096496\n",
      "1 [1.0033143  1.94582352 2.17812478] 0.53260069\n",
      "2 [1.12796233 1.95446021 2.17992824] 0.52651263\n",
      "3 [0.97835363 1.81647579 2.17403248] 0.53104979\n",
      "4 [0.91194612 1.95477583 2.27958558] 0.52894601\n",
      "5 [0.98641246 1.88267341 2.17361866] 0.53490027\n",
      "6 [1.13010454 1.81109808 2.17924108] 0.52117909\n",
      "7 [1.18629786 1.95509873 2.17711232] 0.52709803\n",
      "8 [1.05966605 1.89797524 2.18450351] 0.52494493\n",
      "9 [0.98700758 1.88591543 2.18012391] 0.5341537\n",
      "10 [1.12298354 1.81178912 2.18213272] 0.51940056\n",
      "11 [1.0521685  1.88469613 2.17826439] 0.52572591\n",
      "12 [1.09444223 1.78877911 2.17400145] 0.51915376\n",
      "13 [1.13278418 1.95413881 2.1692525 ] 0.52641431\n",
      "14 [0.97718523 1.92982845 2.17244937] 0.53478449\n",
      "15 [1.16484178 1.8825489  2.17331821] 0.52753116\n",
      "16 [1.15362935 1.88256185 2.17342214] 0.52753116\n",
      "17 [1.05740969 1.87331077 2.26577613] 0.52421938\n",
      "18 [0.9873272  1.88732944 2.26281009] 0.53117931\n",
      "19 [1.05656371 1.81066184 2.17305026] 0.52207671\n",
      "Fold 1 random try 8\n",
      "Train on 14152 samples, validate on 721 samples\n",
      "Epoch 1/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.7756\n",
      "Epoch 00001: val_loss improved from inf to 1.21552, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 4s 264us/sample - loss: 1.7731 - val_loss: 1.2155\n",
      "Epoch 2/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 1.3038\n",
      "Epoch 00002: val_loss improved from 1.21552 to 1.15649, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 192us/sample - loss: 1.3042 - val_loss: 1.1565\n",
      "Epoch 3/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.2271\n",
      "Epoch 00003: val_loss improved from 1.15649 to 1.15210, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 191us/sample - loss: 1.2268 - val_loss: 1.1521\n",
      "Epoch 4/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.1628\n",
      "Epoch 00004: val_loss improved from 1.15210 to 1.13313, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 188us/sample - loss: 1.1642 - val_loss: 1.1331\n",
      "Epoch 5/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.1293\n",
      "Epoch 00005: val_loss did not improve from 1.13313\n",
      "14152/14152 [==============================] - 3s 187us/sample - loss: 1.1291 - val_loss: 1.1516\n",
      "Epoch 6/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.1104\n",
      "Epoch 00006: val_loss improved from 1.13313 to 1.12257, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 192us/sample - loss: 1.1129 - val_loss: 1.1226\n",
      "Epoch 7/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0970\n",
      "Epoch 00007: val_loss did not improve from 1.12257\n",
      "14152/14152 [==============================] - 3s 202us/sample - loss: 1.0999 - val_loss: 1.1435\n",
      "Epoch 8/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.0783\n",
      "Epoch 00008: val_loss did not improve from 1.12257\n",
      "14152/14152 [==============================] - 3s 187us/sample - loss: 1.0781 - val_loss: 1.1537\n",
      "Epoch 9/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0650\n",
      "Epoch 00009: val_loss did not improve from 1.12257\n",
      "14152/14152 [==============================] - 3s 194us/sample - loss: 1.0652 - val_loss: 1.1461\n",
      "Epoch 10/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.0455\n",
      "Epoch 00010: val_loss did not improve from 1.12257\n",
      "14152/14152 [==============================] - 3s 198us/sample - loss: 1.0454 - val_loss: 1.1557\n",
      "Epoch 11/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.0262\n",
      "Epoch 00011: val_loss did not improve from 1.12257\n",
      "14152/14152 [==============================] - 3s 192us/sample - loss: 1.0272 - val_loss: 1.1541\n",
      "Epoch 12/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0250\n",
      "Epoch 00012: val_loss did not improve from 1.12257\n",
      "14152/14152 [==============================] - 3s 183us/sample - loss: 1.0254 - val_loss: 1.1575\n",
      "Epoch 13/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.0150\n",
      "Epoch 00013: val_loss did not improve from 1.12257\n",
      "14152/14152 [==============================] - 3s 198us/sample - loss: 1.0136 - val_loss: 1.1869\n",
      "Epoch 14/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.0055\n",
      "Epoch 00014: val_loss improved from 1.12257 to 1.12232, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 197us/sample - loss: 1.0058 - val_loss: 1.1223\n",
      "Epoch 15/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9863\n",
      "Epoch 00015: val_loss did not improve from 1.12232\n",
      "14152/14152 [==============================] - 3s 197us/sample - loss: 0.9884 - val_loss: 1.1414\n",
      "Epoch 16/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9875\n",
      "Epoch 00016: val_loss did not improve from 1.12232\n",
      "14152/14152 [==============================] - 3s 207us/sample - loss: 0.9868 - val_loss: 1.1722\n",
      "Epoch 17/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9835\n",
      "Epoch 00017: val_loss did not improve from 1.12232\n",
      "14152/14152 [==============================] - 3s 200us/sample - loss: 0.9836 - val_loss: 1.1366\n",
      "Epoch 18/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9512\n",
      "Epoch 00018: val_loss did not improve from 1.12232\n",
      "14152/14152 [==============================] - 3s 203us/sample - loss: 0.9522 - val_loss: 1.1878\n",
      "Epoch 19/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9493\n",
      "Epoch 00019: val_loss did not improve from 1.12232\n",
      "14152/14152 [==============================] - 3s 200us/sample - loss: 0.9491 - val_loss: 1.1479\n",
      "Epoch 20/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9465\n",
      "Epoch 00020: val_loss did not improve from 1.12232\n",
      "14152/14152 [==============================] - 3s 199us/sample - loss: 0.9477 - val_loss: 1.1546\n",
      "Epoch 21/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9292\n",
      "Epoch 00021: val_loss did not improve from 1.12232\n",
      "14152/14152 [==============================] - 3s 204us/sample - loss: 0.9289 - val_loss: 1.1562\n",
      "Epoch 22/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 0.9216\n",
      "Epoch 00022: val_loss did not improve from 1.12232\n",
      "14152/14152 [==============================] - 3s 197us/sample - loss: 0.9243 - val_loss: 1.1644\n",
      "Epoch 23/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.9076\n",
      "Epoch 00023: val_loss did not improve from 1.12232\n",
      "14152/14152 [==============================] - 3s 195us/sample - loss: 0.9075 - val_loss: 1.1924\n",
      "Epoch 24/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.8989\n",
      "Epoch 00024: val_loss did not improve from 1.12232\n",
      "14152/14152 [==============================] - 3s 197us/sample - loss: 0.8983 - val_loss: 1.1526\n",
      "Epoch 25/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.8884\n",
      "Epoch 00025: val_loss did not improve from 1.12232\n",
      "14152/14152 [==============================] - 3s 203us/sample - loss: 0.8884 - val_loss: 1.2058\n",
      "0 [1.05325525 1.91247901 2.33827477] 0.53923574\n",
      "1 [0.92215575 1.61781193 2.37413303] 0.54569167\n",
      "2 [0.94855318 1.91495524 2.28380636] 0.54723277\n",
      "3 [1.02755943 1.69466351 2.28396358] 0.54490036\n",
      "4 [1.0442487  1.60476878 2.28390233] 0.54408821\n",
      "5 [1.10347321 1.64684266 2.28436837] 0.54495663\n",
      "6 [1.14199917 1.59425922 2.24904936] 0.5387393\n",
      "7 [1.12986059 1.59800392 2.37385621] 0.53856958\n",
      "8 [1.05405348 1.90968622 2.23968627] 0.53690261\n",
      "9 [1.13311766 1.62100295 2.28434014] 0.54445205\n",
      "10 [1.08604711 1.64356792 2.28396734] 0.54495663\n",
      "11 [1.11937504 1.62650838 2.28414104] 0.54445205\n",
      "12 [0.9295391  1.69916989 2.37381726] 0.54698143\n",
      "13 [1.01662499 1.65261395 2.28406686] 0.54343107\n",
      "14 [1.13097662 1.59441107 2.28422694] 0.54445606\n",
      "15 [1.06264851 1.64367701 2.28525633] 0.54478816\n",
      "16 [0.92243911 1.89611749 2.28430632] 0.54949926\n",
      "17 [1.16794596 1.7006736  2.33752258] 0.53947757\n",
      "18 [0.95702924 1.91318339 2.24304386] 0.54220413\n",
      "19 [0.98838047 1.94214803 2.28377409] 0.54211906\n",
      "Fold 1 random try 9\n",
      "Train on 14152 samples, validate on 721 samples\n",
      "Epoch 1/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.6962\n",
      "Epoch 00001: val_loss improved from inf to 1.19207, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 4s 257us/sample - loss: 1.6936 - val_loss: 1.1921\n",
      "Epoch 2/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.2882\n",
      "Epoch 00002: val_loss improved from 1.19207 to 1.11470, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 181us/sample - loss: 1.2883 - val_loss: 1.1147\n",
      "Epoch 3/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.2096\n",
      "Epoch 00003: val_loss improved from 1.11470 to 1.09290, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 180us/sample - loss: 1.2085 - val_loss: 1.0929\n",
      "Epoch 4/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.1653\n",
      "Epoch 00004: val_loss did not improve from 1.09290\n",
      "14152/14152 [==============================] - 3s 180us/sample - loss: 1.1676 - val_loss: 1.0952\n",
      "Epoch 5/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.1165\n",
      "Epoch 00005: val_loss did not improve from 1.09290\n",
      "14152/14152 [==============================] - 3s 183us/sample - loss: 1.1167 - val_loss: 1.1157\n",
      "Epoch 6/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 1.1139\n",
      "Epoch 00006: val_loss improved from 1.09290 to 1.08820, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 180us/sample - loss: 1.1153 - val_loss: 1.0882\n",
      "Epoch 7/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0922\n",
      "Epoch 00007: val_loss did not improve from 1.08820\n",
      "14152/14152 [==============================] - 3s 181us/sample - loss: 1.0940 - val_loss: 1.1184\n",
      "Epoch 8/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0749\n",
      "Epoch 00008: val_loss improved from 1.08820 to 1.08700, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 186us/sample - loss: 1.0741 - val_loss: 1.0870\n",
      "Epoch 9/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0581\n",
      "Epoch 00009: val_loss did not improve from 1.08700\n",
      "14152/14152 [==============================] - 3s 187us/sample - loss: 1.0569 - val_loss: 1.1000\n",
      "Epoch 10/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0413\n",
      "Epoch 00010: val_loss did not improve from 1.08700\n",
      "14152/14152 [==============================] - 3s 189us/sample - loss: 1.0412 - val_loss: 1.1148\n",
      "Epoch 11/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 1.0329\n",
      "Epoch 00011: val_loss did not improve from 1.08700\n",
      "14152/14152 [==============================] - 3s 193us/sample - loss: 1.0342 - val_loss: 1.1150\n",
      "Epoch 12/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.0077\n",
      "Epoch 00013: val_loss did not improve from 1.03904\n",
      "14152/14152 [==============================] - 3s 199us/sample - loss: 1.0069 - val_loss: 1.0663\n",
      "Epoch 14/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 0.9902\n",
      "Epoch 00014: val_loss improved from 1.03904 to 1.03465, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 205us/sample - loss: 0.9896 - val_loss: 1.0346\n",
      "Epoch 15/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.9841\n",
      "Epoch 00015: val_loss did not improve from 1.03465\n",
      "14152/14152 [==============================] - 3s 199us/sample - loss: 0.9843 - val_loss: 1.0404\n",
      "Epoch 16/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9673\n",
      "Epoch 00016: val_loss did not improve from 1.03465\n",
      "14152/14152 [==============================] - 3s 200us/sample - loss: 0.9668 - val_loss: 1.0543\n",
      "Epoch 17/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9669\n",
      "Epoch 00017: val_loss did not improve from 1.03465\n",
      "14152/14152 [==============================] - 3s 205us/sample - loss: 0.9648 - val_loss: 1.0467\n",
      "Epoch 18/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9391\n",
      "Epoch 00018: val_loss did not improve from 1.03465\n",
      "14152/14152 [==============================] - 3s 199us/sample - loss: 0.9403 - val_loss: 1.0684\n",
      "Epoch 19/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.9376\n",
      "Epoch 00019: val_loss did not improve from 1.03465\n",
      "14152/14152 [==============================] - 3s 203us/sample - loss: 0.9383 - val_loss: 1.0655\n",
      "Epoch 20/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9336\n",
      "Epoch 00020: val_loss did not improve from 1.03465\n",
      "14152/14152 [==============================] - 3s 200us/sample - loss: 0.9329 - val_loss: 1.0705\n",
      "Epoch 21/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.9104\n",
      "Epoch 00021: val_loss did not improve from 1.03465\n",
      "14152/14152 [==============================] - 3s 204us/sample - loss: 0.9105 - val_loss: 1.0781\n",
      "Epoch 22/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9070\n",
      "Epoch 00022: val_loss did not improve from 1.03465\n",
      "14152/14152 [==============================] - 3s 205us/sample - loss: 0.9084 - val_loss: 1.0743\n",
      "Epoch 23/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9050\n",
      "Epoch 00023: val_loss did not improve from 1.03465\n",
      "14152/14152 [==============================] - 3s 225us/sample - loss: 0.9050 - val_loss: 1.0747\n",
      "Epoch 24/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.8908\n",
      "Epoch 00024: val_loss did not improve from 1.03465\n",
      "14152/14152 [==============================] - 3s 207us/sample - loss: 0.8904 - val_loss: 1.1013\n",
      "Epoch 25/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.8735\n",
      "Epoch 00025: val_loss did not improve from 1.03465\n",
      "14152/14152 [==============================] - 3s 208us/sample - loss: 0.8739 - val_loss: 1.0965\n",
      "0 [1.01133919 1.69054273 2.37999408] 0.59873528\n",
      "1 [0.99257825 1.95232647 2.37999702] 0.60168596\n",
      "2 [1.00899433 1.9261028  2.38129761] 0.60225047\n",
      "3 [1.0145252  1.95384708 2.40058094] 0.60215802\n",
      "4 [0.97409492 1.95311223 2.38008051] 0.60068066\n",
      "5 [1.15938964 1.70087472 2.380642  ] 0.59986376\n",
      "6 [1.03299059 1.69925671 2.3869785 ] 0.59812776\n",
      "7 [1.02410188 1.87472095 2.4078431 ] 0.59842931\n",
      "8 [1.13039417 1.7017888  2.38133791] 0.59881118\n",
      "9 [0.97960686 1.95258287 2.39028288] 0.60027361\n",
      "10 [1.14000651 1.69655645 2.38858446] 0.5972099\n",
      "11 [1.10115217 1.70257889 2.37938884] 0.59679987\n",
      "12 [1.15891753 1.70105194 2.38977727] 0.59845538\n",
      "13 [1.00760154 1.95160599 2.4261593 ] 0.60364474\n",
      "14 [0.97513371 1.94872041 2.38115738] 0.60038751\n",
      "15 [1.02972133 1.95156074 2.41021272] 0.60202919\n",
      "16 [1.0079143  1.71914347 2.4286077 ] 0.59782443\n",
      "17 [0.9731435  1.95258228 2.38027806] 0.60068066\n",
      "18 [0.98832541 1.87760848 2.42802261] 0.59690599\n",
      "19 [1.14256198 1.71234574 2.38097645] 0.59920704\n",
      "Fold 1 random try 24\n",
      "Train on 14152 samples, validate on 721 samples\n",
      "Epoch 1/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 1.6981\n",
      "Epoch 00001: val_loss improved from inf to 1.23526, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 4s 287us/sample - loss: 1.6918 - val_loss: 1.2353\n",
      "Epoch 2/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.2663\n",
      "Epoch 00002: val_loss improved from 1.23526 to 1.19426, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 207us/sample - loss: 1.2662 - val_loss: 1.1943\n",
      "Epoch 3/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.2048\n",
      "Epoch 00003: val_loss improved from 1.19426 to 1.18403, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 198us/sample - loss: 1.2041 - val_loss: 1.1840\n",
      "Epoch 4/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.1392\n",
      "Epoch 00004: val_loss improved from 1.18403 to 1.18113, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 201us/sample - loss: 1.1405 - val_loss: 1.1811\n",
      "Epoch 5/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.1091\n",
      "Epoch 00005: val_loss did not improve from 1.18113\n",
      "14152/14152 [==============================] - 3s 198us/sample - loss: 1.1092 - val_loss: 1.2155\n",
      "Epoch 6/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.1028\n",
      "Epoch 00006: val_loss did not improve from 1.18113\n",
      "14152/14152 [==============================] - 3s 196us/sample - loss: 1.1052 - val_loss: 1.1812\n",
      "Epoch 7/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0891\n",
      "Epoch 00007: val_loss did not improve from 1.18113\n",
      "14152/14152 [==============================] - 3s 191us/sample - loss: 1.0907 - val_loss: 1.2006\n",
      "Epoch 8/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.0691\n",
      "Epoch 00008: val_loss did not improve from 1.18113\n",
      "14152/14152 [==============================] - 3s 192us/sample - loss: 1.0690 - val_loss: 1.2083\n",
      "Epoch 9/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.0597\n",
      "Epoch 00009: val_loss did not improve from 1.18113\n",
      "14152/14152 [==============================] - 3s 191us/sample - loss: 1.0601 - val_loss: 1.1949\n",
      "Epoch 10/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.0274\n",
      "Epoch 00010: val_loss did not improve from 1.18113\n",
      "14152/14152 [==============================] - 3s 193us/sample - loss: 1.0283 - val_loss: 1.1968\n",
      "Epoch 11/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.0224\n",
      "Epoch 00011: val_loss did not improve from 1.18113\n",
      "14152/14152 [==============================] - 3s 193us/sample - loss: 1.0231 - val_loss: 1.1988\n",
      "Epoch 12/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0180\n",
      "Epoch 00012: val_loss did not improve from 1.18113\n",
      "14152/14152 [==============================] - 3s 194us/sample - loss: 1.0169 - val_loss: 1.1915\n",
      "Epoch 13/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0104\n",
      "Epoch 00013: val_loss did not improve from 1.18113\n",
      "14152/14152 [==============================] - 3s 195us/sample - loss: 1.0071 - val_loss: 1.2144\n",
      "Epoch 14/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9948\n",
      "Epoch 00014: val_loss did not improve from 1.18113\n",
      "14152/14152 [==============================] - 3s 200us/sample - loss: 0.9952 - val_loss: 1.2024\n",
      "Epoch 15/25\n",
      "13856/14152 [============================>.] - ETA: 0s - loss: 0.9741\n",
      "Epoch 00015: val_loss did not improve from 1.18113\n",
      "14152/14152 [==============================] - 3s 193us/sample - loss: 0.9778 - val_loss: 1.1964\n",
      "Epoch 16/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.9652\n",
      "Epoch 00016: val_loss did not improve from 1.18113\n",
      "14152/14152 [==============================] - 3s 209us/sample - loss: 0.9643 - val_loss: 1.2380\n",
      "Epoch 17/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.9686\n",
      "Epoch 00017: val_loss did not improve from 1.18113\n",
      "14152/14152 [==============================] - 3s 209us/sample - loss: 0.9673 - val_loss: 1.2274\n",
      "Epoch 18/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9455\n",
      "Epoch 00018: val_loss did not improve from 1.18113\n",
      "14152/14152 [==============================] - 3s 212us/sample - loss: 0.9472 - val_loss: 1.2502\n",
      "Epoch 19/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9390\n",
      "Epoch 00019: val_loss did not improve from 1.18113\n",
      "14152/14152 [==============================] - 3s 205us/sample - loss: 0.9387 - val_loss: 1.1918\n",
      "Epoch 20/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 0.9349\n",
      "Epoch 00020: val_loss did not improve from 1.18113\n",
      "14152/14152 [==============================] - 3s 197us/sample - loss: 0.9335 - val_loss: 1.2218\n",
      "Epoch 21/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.9240\n",
      "Epoch 00021: val_loss did not improve from 1.18113\n",
      "14152/14152 [==============================] - 3s 206us/sample - loss: 0.9241 - val_loss: 1.2092\n",
      "Epoch 22/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9137\n",
      "Epoch 00022: val_loss did not improve from 1.18113\n",
      "14152/14152 [==============================] - 3s 203us/sample - loss: 0.9149 - val_loss: 1.2161\n",
      "Epoch 23/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9032\n",
      "Epoch 00023: val_loss did not improve from 1.18113\n",
      "14152/14152 [==============================] - 3s 202us/sample - loss: 0.9038 - val_loss: 1.2542\n",
      "Epoch 24/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.8937\n",
      "Epoch 00024: val_loss did not improve from 1.18113\n",
      "14152/14152 [==============================] - 3s 200us/sample - loss: 0.8932 - val_loss: 1.2859\n",
      "Epoch 25/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9955\n",
      "Epoch 00013: val_loss did not improve from 1.01110\n",
      "14152/14152 [==============================] - 3s 213us/sample - loss: 0.9955 - val_loss: 1.0242\n",
      "Epoch 14/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.9883\n",
      "Epoch 00014: val_loss improved from 1.01110 to 1.00307, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 203us/sample - loss: 0.9880 - val_loss: 1.0031\n",
      "Epoch 15/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.9890\n",
      "Epoch 00015: val_loss did not improve from 1.00307\n",
      "14152/14152 [==============================] - 3s 181us/sample - loss: 0.9881 - val_loss: 1.0324\n",
      "Epoch 16/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9719\n",
      "Epoch 00016: val_loss did not improve from 1.00307\n",
      "14152/14152 [==============================] - 2s 176us/sample - loss: 0.9710 - val_loss: 1.0455\n",
      "Epoch 17/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9598\n",
      "Epoch 00017: val_loss did not improve from 1.00307\n",
      "14152/14152 [==============================] - 3s 180us/sample - loss: 0.9609 - val_loss: 1.0586\n",
      "Epoch 18/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9560\n",
      "Epoch 00018: val_loss did not improve from 1.00307\n",
      "14152/14152 [==============================] - 3s 182us/sample - loss: 0.9538 - val_loss: 1.0513\n",
      "Epoch 19/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.9455\n",
      "Epoch 00019: val_loss did not improve from 1.00307\n",
      "14152/14152 [==============================] - 2s 176us/sample - loss: 0.9453 - val_loss: 1.0538\n",
      "Epoch 20/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.9308\n",
      "Epoch 00020: val_loss did not improve from 1.00307\n",
      "14152/14152 [==============================] - 2s 173us/sample - loss: 0.9296 - val_loss: 1.0554\n",
      "Epoch 21/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9265\n",
      "Epoch 00021: val_loss did not improve from 1.00307\n",
      "14152/14152 [==============================] - 3s 181us/sample - loss: 0.9263 - val_loss: 1.0878\n",
      "Epoch 22/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9187\n",
      "Epoch 00022: val_loss did not improve from 1.00307\n",
      "14152/14152 [==============================] - 3s 178us/sample - loss: 0.9175 - val_loss: 1.0817\n",
      "Epoch 23/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.9076\n",
      "Epoch 00023: val_loss did not improve from 1.00307\n",
      "14152/14152 [==============================] - 3s 183us/sample - loss: 0.9072 - val_loss: 1.0890\n",
      "Epoch 24/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.8895\n",
      "Epoch 00024: val_loss did not improve from 1.00307\n",
      "14152/14152 [==============================] - 3s 182us/sample - loss: 0.8889 - val_loss: 1.0934\n",
      "Epoch 25/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.8819\n",
      "Epoch 00025: val_loss did not improve from 1.00307\n",
      "14152/14152 [==============================] - 3s 185us/sample - loss: 0.8825 - val_loss: 1.0513\n",
      "0 [1.05908858 1.74292831 2.25835509] 0.6358726\n",
      "1 [1.01567543 1.87486908 2.26744399] 0.63572055\n",
      "2 [1.0612741  1.87997134 2.26757943] 0.63823124\n",
      "3 [1.06778363 1.8721937  2.26015266] 0.63750627\n",
      "4 [0.99248551 1.7473588  2.26768806] 0.63144726\n",
      "5 [1.06047324 1.74775449 2.2948128 ] 0.63259778\n",
      "6 [1.05227825 1.87346287 2.25708498] 0.63723504\n",
      "7 [1.06010016 1.87253269 2.26771304] 0.63855731\n",
      "8 [1.01999814 1.74786867 2.26798054] 0.63337847\n",
      "9 [1.03584165 1.74654283 2.26743447] 0.63528251\n",
      "10 [1.04708665 1.73238903 2.26764041] 0.63470013\n",
      "11 [1.0187252  1.87096129 2.25068531] 0.63388082\n",
      "12 [1.05264408 1.73244086 2.25714027] 0.63525802\n",
      "13 [1.04067354 1.88428465 2.25905078] 0.63715341\n",
      "14 [1.06204825 1.79728806 2.25741754] 0.63200721\n",
      "15 [1.06124563 1.73256434 2.25671025] 0.63620032\n",
      "16 [1.0592708  1.87106697 2.25604907] 0.63816493\n",
      "17 [1.07664185 1.74016878 2.25635159] 0.63496701\n",
      "18 [1.07254948 1.87307555 2.26454734] 0.63660509\n",
      "19 [1.06097693 1.74491041 2.25764442] 0.6358726\n",
      "Fold 2 random try 14\n",
      "Train on 14152 samples, validate on 722 samples\n",
      "Epoch 1/25\n",
      "13856/14152 [============================>.] - ETA: 0s - loss: 1.6682\n",
      "Epoch 00001: val_loss improved from inf to 1.17629, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 4s 251us/sample - loss: 1.6628 - val_loss: 1.1763\n",
      "Epoch 2/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.2660\n",
      "Epoch 00002: val_loss improved from 1.17629 to 1.09368, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 181us/sample - loss: 1.2659 - val_loss: 1.0937\n",
      "Epoch 3/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.1758\n",
      "Epoch 00003: val_loss improved from 1.09368 to 1.07200, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 178us/sample - loss: 1.1754 - val_loss: 1.0720\n",
      "Epoch 4/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.1380\n",
      "Epoch 00004: val_loss improved from 1.07200 to 1.05329, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 177us/sample - loss: 1.1385 - val_loss: 1.0533\n",
      "Epoch 5/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.1125\n",
      "Epoch 00005: val_loss did not improve from 1.05329\n",
      "14152/14152 [==============================] - 3s 180us/sample - loss: 1.1116 - val_loss: 1.0674\n",
      "Epoch 6/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.0928\n",
      "Epoch 00006: val_loss did not improve from 1.05329\n",
      "14152/14152 [==============================] - 3s 181us/sample - loss: 1.0919 - val_loss: 1.0931\n",
      "Epoch 7/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0876\n",
      "Epoch 00007: val_loss improved from 1.05329 to 1.04021, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 179us/sample - loss: 1.0854 - val_loss: 1.0402\n",
      "Epoch 8/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0602\n",
      "Epoch 00008: val_loss improved from 1.04021 to 1.03622, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 182us/sample - loss: 1.0614 - val_loss: 1.0362\n",
      "Epoch 9/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0522\n",
      "Epoch 00009: val_loss improved from 1.03622 to 1.02826, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 185us/sample - loss: 1.0510 - val_loss: 1.0283\n",
      "Epoch 10/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.0300\n",
      "Epoch 00010: val_loss did not improve from 1.02826\n",
      "14152/14152 [==============================] - 3s 182us/sample - loss: 1.0315 - val_loss: 1.0429\n",
      "Epoch 11/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.0202\n",
      "Epoch 00011: val_loss improved from 1.02826 to 1.02645, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 182us/sample - loss: 1.0192 - val_loss: 1.0265\n",
      "Epoch 12/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.0240\n",
      "Epoch 00012: val_loss improved from 1.02645 to 1.02275, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 180us/sample - loss: 1.0235 - val_loss: 1.0227\n",
      "Epoch 13/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.0005\n",
      "Epoch 00013: val_loss improved from 1.02275 to 1.01361, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 183us/sample - loss: 0.9995 - val_loss: 1.0136\n",
      "Epoch 14/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9936\n",
      "Epoch 00014: val_loss did not improve from 1.01361\n",
      "14152/14152 [==============================] - 3s 185us/sample - loss: 0.9920 - val_loss: 1.0156\n",
      "Epoch 15/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.9846\n",
      "Epoch 00015: val_loss did not improve from 1.01361\n",
      "14152/14152 [==============================] - 2s 174us/sample - loss: 0.9853 - val_loss: 1.0354\n",
      "Epoch 16/25\n",
      "13856/14152 [============================>.] - ETA: 0s - loss: 0.9894\n",
      "Epoch 00016: val_loss did not improve from 1.01361\n",
      "14152/14152 [==============================] - 2s 173us/sample - loss: 0.9890 - val_loss: 1.0236\n",
      "Epoch 17/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9658\n",
      "Epoch 00017: val_loss did not improve from 1.01361\n",
      "14152/14152 [==============================] - 3s 177us/sample - loss: 0.9662 - val_loss: 1.0156\n",
      "Epoch 18/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9604\n",
      "Epoch 00018: val_loss did not improve from 1.01361\n",
      "14152/14152 [==============================] - 3s 190us/sample - loss: 0.9604 - val_loss: 1.0306\n",
      "Epoch 19/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9545\n",
      "Epoch 00019: val_loss did not improve from 1.01361\n",
      "14152/14152 [==============================] - 3s 179us/sample - loss: 0.9551 - val_loss: 1.0300\n",
      "Epoch 20/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.9433\n",
      "Epoch 00020: val_loss did not improve from 1.01361\n",
      "14152/14152 [==============================] - 3s 180us/sample - loss: 0.9420 - val_loss: 1.0387\n",
      "Epoch 21/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 0.9462\n",
      "Epoch 00021: val_loss did not improve from 1.01361\n",
      "14152/14152 [==============================] - 3s 190us/sample - loss: 0.9453 - val_loss: 1.0218\n",
      "Epoch 22/25\n",
      "13856/14152 [============================>.] - ETA: 0s - loss: 0.9357\n",
      "Epoch 00022: val_loss did not improve from 1.01361\n",
      "14152/14152 [==============================] - 3s 178us/sample - loss: 0.9329 - val_loss: 1.0180\n",
      "Epoch 23/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 0.9255\n",
      "Epoch 00023: val_loss did not improve from 1.01361\n",
      "14152/14152 [==============================] - 3s 177us/sample - loss: 0.9234 - val_loss: 1.0246\n",
      "Epoch 24/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.9060\n",
      "Epoch 00024: val_loss did not improve from 1.01361\n",
      "14152/14152 [==============================] - 3s 180us/sample - loss: 0.9058 - val_loss: 1.0419\n",
      "Epoch 25/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9029\n",
      "Epoch 00025: val_loss did not improve from 1.01361\n",
      "14152/14152 [==============================] - 3s 180us/sample - loss: 0.9033 - val_loss: 1.0231\n",
      "0 [0.99702137 1.82033657 2.24730576] 0.61401396\n",
      "1 [0.99533046 1.84558385 2.25448082] 0.61258393\n",
      "2 [0.99021643 1.84843914 2.24933827] 0.61179433\n",
      "3 [1.01111625 1.82330255 2.25435812] 0.61400474\n",
      "4 [0.99613148 1.8416069  2.25436507] 0.6128985\n",
      "5 [0.92151434 1.82411631 2.25384009] 0.61160987\n",
      "6 [0.97772016 1.82028148 2.2491932 ] 0.61208834\n",
      "7 [0.99442598 1.8912752  2.25336203] 0.61251092\n",
      "8 [0.95092469 1.82247975 2.25536241] 0.61174106\n",
      "9 [0.99494688 1.89181674 2.24149934] 0.61243492\n",
      "10 [1.0037068  1.82473745 2.25519907] 0.61304658\n",
      "11 [0.99427838 1.82403734 2.24929284] 0.61401396\n",
      "12 [1.0118657  1.8230838  2.25902266] 0.61450354\n",
      "13 [0.98926274 1.8254445  2.25890492] 0.61338107\n",
      "14 [1.00527302 1.78764407 2.24708002] 0.61021671\n",
      "15 [1.01118765 1.8237159  2.25793573] 0.61333665\n",
      "16 [0.94783504 1.89065339 2.24151914] 0.61034372\n",
      "17 [1.01157211 1.84107918 2.24913905] 0.61323486\n",
      "18 [1.01107472 1.86224627 2.25014275] 0.61223312\n",
      "19 [0.99522272 1.93503569 2.24934165] 0.6149911\n",
      "Fold 2 random try 15\n",
      "Train on 14152 samples, validate on 722 samples\n",
      "Epoch 1/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.7810\n",
      "Epoch 00001: val_loss improved from inf to 1.05961, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 4s 263us/sample - loss: 1.7813 - val_loss: 1.0596\n",
      "Epoch 2/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.2937\n",
      "Epoch 00002: val_loss improved from 1.05961 to 0.99658, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 190us/sample - loss: 1.2886 - val_loss: 0.9966\n",
      "Epoch 3/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.9190\n",
      "Epoch 00022: val_loss did not improve from 1.01863\n",
      "14152/14152 [==============================] - 2s 162us/sample - loss: 0.9189 - val_loss: 1.0429\n",
      "Epoch 23/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 0.9103\n",
      "Epoch 00023: val_loss did not improve from 1.01863\n",
      "14152/14152 [==============================] - 2s 163us/sample - loss: 0.9082 - val_loss: 1.0342\n",
      "Epoch 24/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.8972\n",
      "Epoch 00024: val_loss did not improve from 1.01863\n",
      "14152/14152 [==============================] - 2s 168us/sample - loss: 0.8959 - val_loss: 1.0549\n",
      "Epoch 25/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.8799\n",
      "Epoch 00025: val_loss did not improve from 1.01863\n",
      "14152/14152 [==============================] - 2s 171us/sample - loss: 0.8810 - val_loss: 1.0439\n",
      "0 [0.99848487 1.88074963 2.3211991 ] 0.58817876\n",
      "1 [0.95303808 1.83860433 2.27858333] 0.58916866\n",
      "2 [0.9676379  1.62012022 2.32038578] 0.59440583\n",
      "3 [0.98301618 1.88002781 2.37325226] 0.58731428\n",
      "4 [1.08918866 1.57475614 2.2792358 ] 0.59038291\n",
      "5 [1.0242511  1.87936776 2.32153598] 0.58961092\n",
      "6 [1.02363802 1.88675983 2.27893222] 0.58768185\n",
      "7 [0.957993   1.87980288 2.30883628] 0.58926937\n",
      "8 [0.98668245 1.9211883  2.35660843] 0.58664952\n",
      "9 [1.02455895 1.81685383 2.27972625] 0.58634793\n",
      "10 [1.02572898 1.86370796 2.32157498] 0.58767297\n",
      "11 [0.96611845 1.81734845 2.37329221] 0.58651943\n",
      "12 [1.14233165 1.87800615 2.32066067] 0.58586626\n",
      "13 [1.02233638 1.84909535 2.32038774] 0.58701765\n",
      "14 [0.96872899 1.92057225 2.33230644] 0.58840837\n",
      "15 [0.97158744 1.92771642 2.49593851] 0.58945349\n",
      "16 [0.97198159 1.8109613  2.28204313] 0.58755137\n",
      "17 [1.01966513 1.92082287 2.32162006] 0.59059637\n",
      "18 [0.98577563 1.62705591 2.32229227] 0.59119879\n",
      "19 [1.02213575 1.87920249 2.30890326] 0.5886198\n",
      "Fold 2 random try 27\n",
      "Train on 14152 samples, validate on 722 samples\n",
      "Epoch 1/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.5643\n",
      "Epoch 00001: val_loss improved from inf to 1.15997, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 243us/sample - loss: 1.5647 - val_loss: 1.1600\n",
      "Epoch 2/25\n",
      "13856/14152 [============================>.] - ETA: 0s - loss: 1.2517\n",
      "Epoch 00002: val_loss improved from 1.15997 to 1.10105, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 2s 171us/sample - loss: 1.2450 - val_loss: 1.1010\n",
      "Epoch 3/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.1659\n",
      "Epoch 00003: val_loss improved from 1.10105 to 1.08267, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 2s 167us/sample - loss: 1.1657 - val_loss: 1.0827\n",
      "Epoch 4/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.1296\n",
      "Epoch 00004: val_loss improved from 1.08267 to 1.07556, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 2s 168us/sample - loss: 1.1302 - val_loss: 1.0756\n",
      "Epoch 5/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.1005\n",
      "Epoch 00005: val_loss did not improve from 1.07556\n",
      "14152/14152 [==============================] - 2s 166us/sample - loss: 1.0999 - val_loss: 1.0905\n",
      "Epoch 6/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.0902\n",
      "Epoch 00006: val_loss did not improve from 1.07556\n",
      "14152/14152 [==============================] - 2s 169us/sample - loss: 1.0901 - val_loss: 1.0889\n",
      "Epoch 7/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.0768\n",
      "Epoch 00007: val_loss improved from 1.07556 to 1.06497, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 2s 173us/sample - loss: 1.0758 - val_loss: 1.0650\n",
      "Epoch 8/25\n",
      " 4192/14152 [=======>......................] - ETA: 1s - loss: 1.02671 [1.1017548  1.70390766 2.10808282] 0.59487494\n",
      "2 [1.07464171 1.67639494 2.09498245] 0.59053428\n",
      "3 [1.09354272 1.79237995 2.13140849] 0.59786192\n",
      "4 [1.09005109 1.79507725 2.13308587] 0.59771623\n",
      "5 [1.09932066 1.69125997 2.2258686 ] 0.59584227\n",
      "6 [1.13927543 1.70371063 2.13723103] 0.59771281\n",
      "7 [1.10605711 1.79051662 2.09471481] 0.59520217\n",
      "8 [1.07711691 1.77421179 2.22475618] 0.59312432\n",
      "9 [1.10670449 1.77971661 2.13331509] 0.59689345\n",
      "10 [1.10735995 1.7947559  2.13283641] 0.59868391\n",
      "11 [1.10919704 1.79193194 2.22501403] 0.59762958\n",
      "12 [1.10492653 1.78750161 2.10616302] 0.59423939\n",
      "13 [1.12602985 1.78825371 2.22591718] 0.59749156\n",
      "14 [1.09675343 1.70383121 2.09445813] 0.59557197\n",
      "15 [1.10824041 1.70208948 2.12479494] 0.59712109\n",
      "16 [1.08259546 1.68689473 2.13205884] 0.5934572\n",
      "17 [1.06452077 1.78248171 2.22595477] 0.59435749\n",
      "18 [1.09371367 1.77256688 2.22493896] 0.5961254\n",
      "19 [1.11808967 1.70489009 2.13343393] 0.59764317\n",
      "Fold 3 random try 4\n",
      "Train on 14152 samples, validate on 723 samples\n",
      "Epoch 1/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.7192\n",
      "Epoch 00001: val_loss improved from inf to 1.11236, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 4s 252us/sample - loss: 1.7163 - val_loss: 1.1124\n",
      "Epoch 2/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.3022\n",
      "Epoch 00002: val_loss improved from 1.11236 to 1.02768, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 2s 172us/sample - loss: 1.3017 - val_loss: 1.0277\n",
      "Epoch 3/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.2116\n",
      "Epoch 00003: val_loss improved from 1.02768 to 1.02366, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 177us/sample - loss: 1.2111 - val_loss: 1.0237\n",
      "Epoch 4/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.1594\n",
      "Epoch 00004: val_loss did not improve from 1.02366\n",
      "14152/14152 [==============================] - 2s 173us/sample - loss: 1.1584 - val_loss: 1.0340\n",
      "Epoch 5/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.1401\n",
      "Epoch 00005: val_loss did not improve from 1.02366\n",
      "14152/14152 [==============================] - 2s 172us/sample - loss: 1.1401 - val_loss: 1.0239\n",
      "Epoch 6/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.1118\n",
      "Epoch 00006: val_loss improved from 1.02366 to 1.00229, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 184us/sample - loss: 1.1118 - val_loss: 1.0023\n",
      "Epoch 7/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.0852\n",
      "Epoch 00007: val_loss did not improve from 1.00229\n",
      "14152/14152 [==============================] - 3s 179us/sample - loss: 1.0837 - val_loss: 1.0210\n",
      "Epoch 8/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.0812\n",
      "Epoch 00008: val_loss did not improve from 1.00229\n",
      "14152/14152 [==============================] - 2s 173us/sample - loss: 1.0828 - val_loss: 1.0148\n",
      "Epoch 9/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.0592\n",
      "Epoch 00009: val_loss did not improve from 1.00229\n",
      "14152/14152 [==============================] - 3s 178us/sample - loss: 1.0596 - val_loss: 1.0368\n",
      "Epoch 10/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.0311\n",
      "Epoch 00010: val_loss did not improve from 1.00229\n",
      "14152/14152 [==============================] - 2s 169us/sample - loss: 1.0310 - val_loss: 1.0038\n",
      "Epoch 11/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.0214\n",
      "Epoch 00011: val_loss did not improve from 1.00229\n",
      "14152/14152 [==============================] - 2s 172us/sample - loss: 1.0217 - val_loss: 1.0342\n",
      "Epoch 12/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0121\n",
      "Epoch 00012: val_loss did not improve from 1.00229\n",
      "14152/14152 [==============================] - 2s 165us/sample - loss: 1.0117 - val_loss: 1.0324\n",
      "Epoch 13/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9969\n",
      "Epoch 00013: val_loss did not improve from 1.00229\n",
      "14152/14152 [==============================] - 2s 169us/sample - loss: 0.9971 - val_loss: 1.0383\n",
      "Epoch 14/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.9887\n",
      "Epoch 00014: val_loss did not improve from 1.00229\n",
      "14152/14152 [==============================] - 2s 166us/sample - loss: 0.9887 - val_loss: 1.0466\n",
      "Epoch 15/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9833\n",
      "Epoch 00015: val_loss did not improve from 1.00229\n",
      "14152/14152 [==============================] - 2s 168us/sample - loss: 0.9820 - val_loss: 1.0646\n",
      "Epoch 16/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9645\n",
      "Epoch 00016: val_loss did not improve from 1.00229\n",
      "14152/14152 [==============================] - 3s 191us/sample - loss: 0.9639 - val_loss: 1.0452\n",
      "Epoch 17/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.9431\n",
      "Epoch 00017: val_loss did not improve from 1.00229\n",
      "14152/14152 [==============================] - 3s 212us/sample - loss: 0.9423 - val_loss: 1.0268\n",
      "Epoch 18/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.9506\n",
      "Epoch 00018: val_loss did not improve from 1.00229\n",
      "14152/14152 [==============================] - 3s 211us/sample - loss: 0.9505 - val_loss: 1.0618\n",
      "Epoch 19/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9421\n",
      "Epoch 00019: val_loss did not improve from 1.00229\n",
      "14152/14152 [==============================] - 3s 205us/sample - loss: 0.9423 - val_loss: 1.0508\n",
      "Epoch 20/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9232\n",
      "Epoch 00020: val_loss did not improve from 1.00229\n",
      "14152/14152 [==============================] - 3s 181us/sample - loss: 0.9249 - val_loss: 1.0530\n",
      "Epoch 21/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.9115\n",
      "Epoch 00021: val_loss did not improve from 1.00229\n",
      "14152/14152 [==============================] - 2s 170us/sample - loss: 0.9132 - val_loss: 1.0467\n",
      "Epoch 22/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9064\n",
      "Epoch 00022: val_loss did not improve from 1.00229\n",
      "14152/14152 [==============================] - 2s 162us/sample - loss: 0.9066 - val_loss: 1.0696\n",
      "Epoch 23/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.8882\n",
      "Epoch 00023: val_loss did not improve from 1.00229\n",
      "14152/14152 [==============================] - 2s 159us/sample - loss: 0.8903 - val_loss: 1.0435\n",
      "Epoch 24/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.8925\n",
      "Epoch 00024: val_loss did not improve from 1.00229\n",
      "14152/14152 [==============================] - 2s 166us/sample - loss: 0.8918 - val_loss: 1.0669\n",
      "Epoch 25/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.8756\n",
      "Epoch 00025: val_loss did not improve from 1.00229\n",
      "14152/14152 [==============================] - 2s 166us/sample - loss: 0.8778 - val_loss: 1.0506\n",
      "0 [1.07822441 1.5840753  2.24448689] 0.59634395\n",
      "1 [1.1974366  1.46940503 2.25407299] 0.59563918\n",
      "2 [1.18690342 1.54124738 2.25129535] 0.59912294\n",
      "3 [1.1093537  1.55782371 2.26494442] 0.59376602\n",
      "4 [1.17179951 1.53919797 2.23905316] 0.59627359\n",
      "5 [1.0804231  1.5903226  2.23858604] 0.59577\n",
      "6 [1.07908422 1.64045704 2.25144074] 0.59686703\n",
      "7 [1.09644032 1.72513877 2.25695801] 0.58810925\n",
      "8 [1.16247243 1.53569961 2.23942062] 0.59627359\n",
      "9 [1.0840992  1.58344761 2.24202406] 0.59569984\n",
      "10 [1.09593115 1.58576188 2.24647354] 0.59634395\n",
      "11 [1.08793196 1.63902152 2.26565133] 0.59647157\n",
      "12 [1.0913072  1.64765859 2.25806041] 0.59666964\n",
      "13 [1.09169158 1.57813762 2.23919517] 0.59512\n",
      "14 [1.08605079 1.58565098 2.2457607 ] 0.59634395\n",
      "15 [1.06715546 1.64704911 2.23849136] 0.59706376\n",
      "16 [1.09381154 1.58566755 2.25799393] 0.59665636\n",
      "17 [1.08122313 1.77417175 2.2467425 ] 0.58819458\n",
      "18 [1.18256956 1.54142726 2.23911206] 0.599313\n",
      "19 [1.08922084 1.5857863  2.24673016] 0.59634395\n",
      "Fold 3 random try 5\n",
      "Train on 14152 samples, validate on 723 samples\n",
      "Epoch 1/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.7776\n",
      "Epoch 00001: val_loss improved from inf to 1.20620, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 4s 255us/sample - loss: 1.7752 - val_loss: 1.2062\n",
      "Epoch 2/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.3199\n",
      "Epoch 00002: val_loss improved from 1.20620 to 1.13010, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 2s 176us/sample - loss: 1.3202 - val_loss: 1.1301\n",
      "Epoch 3/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.2246\n",
      "Epoch 00003: val_loss did not improve from 1.13010\n",
      "14152/14152 [==============================] - 2s 175us/sample - loss: 1.2237 - val_loss: 1.1368\n",
      "Epoch 4/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.1639\n",
      "Epoch 00004: val_loss did not improve from 1.13010\n",
      "14152/14152 [==============================] - 2s 173us/sample - loss: 1.1637 - val_loss: 1.1305\n",
      "Epoch 5/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.1315\n",
      "Epoch 00005: val_loss improved from 1.13010 to 1.12614, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 183us/sample - loss: 1.1314 - val_loss: 1.1261\n",
      "Epoch 6/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.1093\n",
      "Epoch 00006: val_loss improved from 1.12614 to 1.11562, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 183us/sample - loss: 1.1101 - val_loss: 1.1156\n",
      "Epoch 7/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.0928\n",
      "Epoch 00007: val_loss did not improve from 1.11562\n",
      "14152/14152 [==============================] - 3s 184us/sample - loss: 1.0925 - val_loss: 1.1268\n",
      "Epoch 8/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.0795\n",
      "Epoch 00008: val_loss did not improve from 1.11562\n",
      "14152/14152 [==============================] - 2s 177us/sample - loss: 1.0790 - val_loss: 1.1559\n",
      "Epoch 9/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.0527\n",
      "Epoch 00009: val_loss did not improve from 1.11562\n",
      "14152/14152 [==============================] - 2s 171us/sample - loss: 1.0541 - val_loss: 1.1297\n",
      "Epoch 10/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0367\n",
      "Epoch 00010: val_loss did not improve from 1.11562\n",
      "14152/14152 [==============================] - 2s 172us/sample - loss: 1.0362 - val_loss: 1.1190\n",
      "Epoch 11/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.0239\n",
      "Epoch 00011: val_loss did not improve from 1.11562\n",
      "14152/14152 [==============================] - 3s 179us/sample - loss: 1.0238 - val_loss: 1.1252\n",
      "Epoch 12/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.0130\n",
      "Epoch 00012: val_loss improved from 1.11562 to 1.11003, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 2s 167us/sample - loss: 1.0133 - val_loss: 1.1100\n",
      "Epoch 13/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0013\n",
      "Epoch 00013: val_loss did not improve from 1.11003\n",
      "14152/14152 [==============================] - 2s 170us/sample - loss: 0.9990 - val_loss: 1.1343\n",
      "Epoch 14/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9933\n",
      "Epoch 00014: val_loss did not improve from 1.11003\n",
      "14152/14152 [==============================] - 2s 167us/sample - loss: 0.9931 - val_loss: 1.1214\n",
      "Epoch 15/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.9902\n",
      "Epoch 00015: val_loss did not improve from 1.11003\n",
      "14152/14152 [==============================] - 2s 162us/sample - loss: 0.9889 - val_loss: 1.1190\n",
      "Epoch 16/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.9734\n",
      "Epoch 00016: val_loss did not improve from 1.11003\n",
      "14152/14152 [==============================] - 2s 166us/sample - loss: 0.9721 - val_loss: 1.1328\n",
      "Epoch 17/25\n",
      " 4736/14152 [=========>....................] - ETA: 1s - loss: 0.953911 [1.06877074 1.7481171  2.16254899] 0.56687459\n",
      "12 [1.1285956  1.73721008 2.13960865] 0.56766825\n",
      "13 [1.08753274 1.66930237 2.13951185] 0.56724855\n",
      "14 [1.14869128 1.74938745 2.17399501] 0.57062937\n",
      "15 [1.16112373 1.86796835 2.13947283] 0.57908422\n",
      "16 [1.16171269 1.66423999 2.17116117] 0.57133935\n",
      "17 [0.99438436 1.74971987 2.17105243] 0.57044894\n",
      "18 [0.9929721  1.74772858 2.16931256] 0.57044894\n",
      "19 [1.21669529 1.58966409 2.17220813] 0.57519138\n",
      "Fold 3 random try 18\n",
      "Train on 14152 samples, validate on 723 samples\n",
      "Epoch 1/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.8744\n",
      "Epoch 00001: val_loss improved from inf to 1.05254, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 239us/sample - loss: 1.8698 - val_loss: 1.0525\n",
      "Epoch 2/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.3064\n",
      "Epoch 00002: val_loss improved from 1.05254 to 1.04104, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 2s 167us/sample - loss: 1.3060 - val_loss: 1.0410\n",
      "Epoch 3/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.2160\n",
      "Epoch 00003: val_loss improved from 1.04104 to 1.03630, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 2s 165us/sample - loss: 1.2144 - val_loss: 1.0363\n",
      "Epoch 4/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.1674\n",
      "Epoch 00004: val_loss did not improve from 1.03630\n",
      "14152/14152 [==============================] - 2s 162us/sample - loss: 1.1679 - val_loss: 1.0446\n",
      "Epoch 5/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.1345\n",
      "Epoch 00005: val_loss improved from 1.03630 to 1.02384, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 2s 169us/sample - loss: 1.1350 - val_loss: 1.0238\n",
      "Epoch 6/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 1.1161\n",
      "Epoch 00006: val_loss did not improve from 1.02384\n",
      "14152/14152 [==============================] - 2s 176us/sample - loss: 1.1159 - val_loss: 1.0281\n",
      "Epoch 7/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 1.0990\n",
      "Epoch 00007: val_loss did not improve from 1.02384\n",
      "14152/14152 [==============================] - 2s 172us/sample - loss: 1.0977 - val_loss: 1.0326\n",
      "Epoch 8/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0772\n",
      "Epoch 00008: val_loss did not improve from 1.02384\n",
      "14152/14152 [==============================] - 2s 174us/sample - loss: 1.0780 - val_loss: 1.0747\n",
      "Epoch 9/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0643\n",
      "Epoch 00009: val_loss did not improve from 1.02384\n",
      "14152/14152 [==============================] - 2s 173us/sample - loss: 1.0655 - val_loss: 1.0491\n",
      "Epoch 10/25\n",
      "13856/14152 [============================>.] - ETA: 0s - loss: 1.0545\n",
      "Epoch 00010: val_loss did not improve from 1.02384\n",
      "14152/14152 [==============================] - 2s 173us/sample - loss: 1.0528 - val_loss: 1.0446\n",
      "Epoch 11/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9923\n",
      "Epoch 00014: val_loss did not improve from 1.13486\n",
      "14152/14152 [==============================] - 3s 192us/sample - loss: 0.9922 - val_loss: 1.1470\n",
      "Epoch 15/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.9840\n",
      "Epoch 00015: val_loss did not improve from 1.13486\n",
      "14152/14152 [==============================] - 3s 185us/sample - loss: 0.9838 - val_loss: 1.1571\n",
      "Epoch 16/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9745\n",
      "Epoch 00016: val_loss did not improve from 1.13486\n",
      "14152/14152 [==============================] - 3s 191us/sample - loss: 0.9735 - val_loss: 1.1473\n",
      "Epoch 17/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9566\n",
      "Epoch 00017: val_loss did not improve from 1.13486\n",
      "14152/14152 [==============================] - 4s 280us/sample - loss: 0.9565 - val_loss: 1.1610\n",
      "Epoch 18/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9468\n",
      "Epoch 00018: val_loss did not improve from 1.13486\n",
      "14152/14152 [==============================] - 3s 194us/sample - loss: 0.9464 - val_loss: 1.1925\n",
      "Epoch 19/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9420\n",
      "Epoch 00019: val_loss did not improve from 1.13486\n",
      "14152/14152 [==============================] - 3s 185us/sample - loss: 0.9415 - val_loss: 1.1688\n",
      "Epoch 20/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9280\n",
      "Epoch 00020: val_loss did not improve from 1.13486\n",
      "14152/14152 [==============================] - 3s 197us/sample - loss: 0.9278 - val_loss: 1.1728\n",
      "Epoch 21/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.9096\n",
      "Epoch 00021: val_loss did not improve from 1.13486\n",
      "14152/14152 [==============================] - 3s 195us/sample - loss: 0.9126 - val_loss: 1.1733\n",
      "Epoch 22/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9107\n",
      "Epoch 00022: val_loss did not improve from 1.13486\n",
      "14152/14152 [==============================] - 3s 191us/sample - loss: 0.9114 - val_loss: 1.1738\n",
      "Epoch 23/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.2821\n",
      "Epoch 00002: val_loss improved from 1.25779 to 1.21390, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 2s 175us/sample - loss: 1.2833 - val_loss: 1.2139\n",
      "Epoch 3/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.1982\n",
      "Epoch 00003: val_loss improved from 1.21390 to 1.19415, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 2s 176us/sample - loss: 1.1980 - val_loss: 1.1941\n",
      "Epoch 4/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.1515\n",
      "Epoch 00004: val_loss did not improve from 1.19415\n",
      "14152/14152 [==============================] - 2s 174us/sample - loss: 1.1524 - val_loss: 1.1974\n",
      "Epoch 5/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.1095\n",
      "Epoch 00005: val_loss did not improve from 1.19415\n",
      "14152/14152 [==============================] - 2s 171us/sample - loss: 1.1093 - val_loss: 1.2048\n",
      "Epoch 6/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.0935\n",
      "Epoch 00006: val_loss did not improve from 1.19415\n",
      "14152/14152 [==============================] - 3s 179us/sample - loss: 1.0924 - val_loss: 1.2047\n",
      "Epoch 7/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0666\n",
      "Epoch 00007: val_loss did not improve from 1.19415\n",
      "14152/14152 [==============================] - 2s 171us/sample - loss: 1.0689 - val_loss: 1.2046\n",
      "Epoch 8/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.0602\n",
      "Epoch 00008: val_loss did not improve from 1.19415\n",
      "14152/14152 [==============================] - 2s 172us/sample - loss: 1.0602 - val_loss: 1.2021\n",
      "Epoch 9/25\n",
      "13856/14152 [============================>.] - ETA: 0s - loss: 1.0417\n",
      "Epoch 00009: val_loss improved from 1.19415 to 1.18498, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 2s 172us/sample - loss: 1.0415 - val_loss: 1.1850\n",
      "Epoch 10/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.0310\n",
      "Epoch 00010: val_loss did not improve from 1.18498\n",
      "14152/14152 [==============================] - 2s 170us/sample - loss: 1.0326 - val_loss: 1.2014\n",
      "Epoch 11/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 1.0231\n",
      "Epoch 00011: val_loss did not improve from 1.18498\n",
      "14152/14152 [==============================] - 3s 178us/sample - loss: 1.0234 - val_loss: 1.1918\n",
      "Epoch 12/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.9627\n",
      "Epoch 00017: val_loss did not improve from 1.18233\n",
      "14152/14152 [==============================] - 3s 181us/sample - loss: 0.9626 - val_loss: 1.2093\n",
      "Epoch 18/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9548\n",
      "Epoch 00018: val_loss did not improve from 1.18233\n",
      "14152/14152 [==============================] - 3s 187us/sample - loss: 0.9541 - val_loss: 1.2024\n",
      "Epoch 19/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9461\n",
      "Epoch 00019: val_loss did not improve from 1.18233\n",
      "14152/14152 [==============================] - 3s 188us/sample - loss: 0.9467 - val_loss: 1.2191\n",
      "Epoch 20/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.9353\n",
      "Epoch 00020: val_loss did not improve from 1.18233\n",
      "14152/14152 [==============================] - 3s 186us/sample - loss: 0.9343 - val_loss: 1.2058\n",
      "Epoch 21/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9311\n",
      "Epoch 00021: val_loss improved from 1.18233 to 1.16997, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 188us/sample - loss: 0.9320 - val_loss: 1.1700\n",
      "Epoch 22/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9135\n",
      "Epoch 00022: val_loss did not improve from 1.16997\n",
      "14152/14152 [==============================] - 3s 180us/sample - loss: 0.9127 - val_loss: 1.1916\n",
      "Epoch 23/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9053\n",
      "Epoch 00023: val_loss did not improve from 1.16997\n",
      "14152/14152 [==============================] - 3s 183us/sample - loss: 0.9052 - val_loss: 1.1991\n",
      "Epoch 24/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.8921\n",
      "Epoch 00024: val_loss did not improve from 1.16997\n",
      "14152/14152 [==============================] - 3s 179us/sample - loss: 0.8963 - val_loss: 1.2185\n",
      "Epoch 25/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.8922\n",
      "Epoch 00025: val_loss did not improve from 1.16997\n",
      "14152/14152 [==============================] - 3s 181us/sample - loss: 0.8940 - val_loss: 1.2174\n",
      "0 [1.11598707 1.79280025 2.19745571] 0.53587257\n",
      "1 [1.04115324 1.67771228 2.19811178] 0.53790559\n",
      "2 [1.06785828 1.64556243 2.19780355] 0.54135317\n",
      "3 [1.128409   1.64543597 2.19798431] 0.54279551\n",
      "4 [1.07764515 1.68415082 2.19775329] 0.54074804\n",
      "5 [1.1025376  1.6725186  2.19771034] 0.542379\n",
      "6 [1.12046481 1.64464222 2.19730556] 0.54279551\n",
      "7 [1.10355589 1.67755992 2.19763583] 0.542379\n",
      "8 [1.03593914 1.68063152 2.20070231] 0.53815794\n",
      "9 [1.12609184 1.68039288 2.19755743] 0.54159954\n",
      "10 [1.11795629 1.67021999 2.19777611] 0.54159954\n",
      "11 [1.10125679 1.64651012 2.27956031] 0.53926423\n",
      "12 [0.97966168 1.79370375 2.21005712] 0.5330899\n",
      "13 [1.10653707 1.64225868 2.29734329] 0.53795873\n",
      "14 [1.07641627 1.64476107 2.19775145] 0.54135317\n",
      "15 [1.0088397  1.75590033 2.19813833] 0.53068512\n",
      "16 [1.10139608 1.68520248 2.20930428] 0.54122133\n",
      "17 [1.12451056 1.67431605 2.21004313] 0.53984825\n",
      "18 [1.0001157  1.64651384 2.19785309] 0.54147251\n",
      "19 [1.13188861 1.67852187 2.19810594] 0.54159954\n",
      "Fold 4 random try 8\n",
      "Train on 14152 samples, validate on 724 samples\n",
      "Epoch 1/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.7028\n",
      "Epoch 00001: val_loss improved from inf to 1.35139, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 4s 281us/sample - loss: 1.6987 - val_loss: 1.3514\n",
      "Epoch 2/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.0443\n",
      "Epoch 00009: val_loss did not improve from 1.20726\n",
      "14152/14152 [==============================] - 3s 193us/sample - loss: 1.0439 - val_loss: 1.2268\n",
      "Epoch 10/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0339\n",
      "Epoch 00010: val_loss did not improve from 1.20726\n",
      "14152/14152 [==============================] - 3s 187us/sample - loss: 1.0351 - val_loss: 1.2214\n",
      "Epoch 11/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.0220\n",
      "Epoch 00011: val_loss did not improve from 1.20726\n",
      "14152/14152 [==============================] - 3s 190us/sample - loss: 1.0217 - val_loss: 1.2495\n",
      "Epoch 12/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.0110\n",
      "Epoch 00012: val_loss did not improve from 1.20726\n",
      "14152/14152 [==============================] - 3s 181us/sample - loss: 1.0110 - val_loss: 1.2269\n",
      "Epoch 13/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.0032\n",
      "Epoch 00013: val_loss did not improve from 1.20726\n",
      "14152/14152 [==============================] - 3s 185us/sample - loss: 1.0025 - val_loss: 1.2260\n",
      "Epoch 14/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0026\n",
      "Epoch 00014: val_loss did not improve from 1.20726\n",
      "14152/14152 [==============================] - 3s 184us/sample - loss: 1.0005 - val_loss: 1.2242\n",
      "Epoch 15/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.9849\n",
      "Epoch 00015: val_loss did not improve from 1.20726\n",
      "14152/14152 [==============================] - 3s 198us/sample - loss: 0.9862 - val_loss: 1.2405\n",
      "Epoch 16/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.9828\n",
      "Epoch 00016: val_loss did not improve from 1.20726\n",
      "14152/14152 [==============================] - 3s 187us/sample - loss: 0.9818 - val_loss: 1.2578\n",
      "Epoch 17/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 0.9626\n",
      "Epoch 00017: val_loss did not improve from 1.20726\n",
      "14152/14152 [==============================] - 3s 198us/sample - loss: 0.9646 - val_loss: 1.2377\n",
      "Epoch 18/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.9559\n",
      "Epoch 00018: val_loss did not improve from 1.20726\n",
      "14152/14152 [==============================] - 3s 193us/sample - loss: 0.9552 - val_loss: 1.2682\n",
      "Epoch 19/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.9428\n",
      "Epoch 00019: val_loss did not improve from 1.20726\n",
      "14152/14152 [==============================] - 3s 191us/sample - loss: 0.9442 - val_loss: 1.2430\n",
      "Epoch 20/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9376\n",
      "Epoch 00020: val_loss did not improve from 1.20726\n",
      "14152/14152 [==============================] - 3s 186us/sample - loss: 0.9377 - val_loss: 1.2504\n",
      "Epoch 21/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9207\n",
      "Epoch 00021: val_loss did not improve from 1.20726\n",
      "14152/14152 [==============================] - 3s 189us/sample - loss: 0.9213 - val_loss: 1.2230\n",
      "Epoch 22/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9095\n",
      "Epoch 00022: val_loss did not improve from 1.20726\n",
      "14152/14152 [==============================] - 3s 189us/sample - loss: 0.9102 - val_loss: 1.2584\n",
      "Epoch 23/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.9137\n",
      "Epoch 00023: val_loss did not improve from 1.20726\n",
      "14152/14152 [==============================] - 3s 192us/sample - loss: 0.9130 - val_loss: 1.2482\n",
      "Epoch 24/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.8933\n",
      "Epoch 00024: val_loss did not improve from 1.20726\n",
      "14152/14152 [==============================] - 3s 184us/sample - loss: 0.8946 - val_loss: 1.2234\n",
      "Epoch 25/25\n",
      "13856/14152 [============================>.] - ETA: 0s - loss: 0.8913\n",
      "Epoch 00025: val_loss did not improve from 1.20726\n",
      "14152/14152 [==============================] - 3s 186us/sample - loss: 0.8926 - val_loss: 1.2633\n",
      "0 [0.99800156 1.80138866 2.1621931 ] 0.52462333\n",
      "1 [0.93838515 1.96724725 2.16512898] 0.52200276\n",
      "2 [0.98317963 1.78615093 2.33289761] 0.5257679\n",
      "3 [0.99263629 1.85264466 2.16170303] 0.52626038\n",
      "4 [0.9926581  1.85652507 2.28385691] 0.52289571\n",
      "5 [0.98922737 1.77027572 2.25761633] 0.52209957\n",
      "6 [0.99206923 1.77833834 2.15991038] 0.52501019\n",
      "7 [1.01099832 1.85726939 2.16278587] 0.5256803\n",
      "8 [0.99013372 1.85085059 2.15936042] 0.52626038\n",
      "9 [0.99004439 1.82798865 2.16208512] 0.5233505\n",
      "10 [0.94465414 1.8541539  2.25723756] 0.521825\n",
      "11 [0.9852203  1.8519767  2.16213848] 0.52615885\n",
      "12 [0.99949617 1.77056858 2.15944805] 0.52501019\n",
      "13 [0.99230787 1.77676649 2.16249846] 0.52501019\n",
      "14 [0.99000752 1.77825949 2.16261444] 0.52501019\n",
      "15 [0.96195111 1.86036388 2.28511214] 0.52249696\n",
      "16 [0.99537221 1.86095349 2.27299231] 0.52330221\n",
      "17 [0.99755895 1.77059519 2.14847456] 0.52456829\n",
      "18 [0.99795584 1.85757097 2.1611229 ] 0.52626038\n",
      "19 [0.98976849 1.88167718 2.16060445] 0.52308402\n",
      "Fold 4 random try 15\n",
      "Train on 14152 samples, validate on 724 samples\n",
      "Epoch 1/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.8301\n",
      "Epoch 00001: val_loss improved from inf to 1.24521, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 4s 264us/sample - loss: 1.8300 - val_loss: 1.2452\n",
      "Epoch 2/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.3423\n",
      "Epoch 00002: val_loss improved from 1.24521 to 1.18137, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 191us/sample - loss: 1.3447 - val_loss: 1.1814\n",
      "Epoch 3/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.2363\n",
      "Epoch 00003: val_loss did not improve from 1.18137\n",
      "14152/14152 [==============================] - 3s 192us/sample - loss: 1.2379 - val_loss: 1.1850\n",
      "Epoch 4/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.1618\n",
      "Epoch 00004: val_loss improved from 1.18137 to 1.17957, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 192us/sample - loss: 1.1616 - val_loss: 1.1796\n",
      "Epoch 5/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.1343\n",
      "Epoch 00005: val_loss improved from 1.17957 to 1.15982, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 199us/sample - loss: 1.1342 - val_loss: 1.1598\n",
      "Epoch 6/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 1.1010\n",
      "Epoch 00006: val_loss did not improve from 1.15982\n",
      "14152/14152 [==============================] - 3s 195us/sample - loss: 1.1005 - val_loss: 1.1882\n",
      "Epoch 7/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.0889\n",
      "Epoch 00007: val_loss did not improve from 1.15982\n",
      "14152/14152 [==============================] - 3s 199us/sample - loss: 1.0902 - val_loss: 1.1731\n",
      "Epoch 8/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.0693\n",
      "Epoch 00008: val_loss did not improve from 1.15982\n",
      "14152/14152 [==============================] - 3s 207us/sample - loss: 1.0691 - val_loss: 1.1675\n",
      "Epoch 9/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.0449\n",
      "Epoch 00009: val_loss improved from 1.15982 to 1.15888, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 194us/sample - loss: 1.0441 - val_loss: 1.1589\n",
      "Epoch 10/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0391\n",
      "Epoch 00010: val_loss did not improve from 1.15888\n",
      "14152/14152 [==============================] - 3s 194us/sample - loss: 1.0401 - val_loss: 1.1875\n",
      "Epoch 11/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0235\n",
      "Epoch 00011: val_loss did not improve from 1.15888\n",
      "14152/14152 [==============================] - 3s 197us/sample - loss: 1.0252 - val_loss: 1.1633\n",
      "Epoch 12/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.0095\n",
      "Epoch 00012: val_loss improved from 1.15888 to 1.13826, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 196us/sample - loss: 1.0071 - val_loss: 1.1383\n",
      "Epoch 13/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0009\n",
      "Epoch 00013: val_loss did not improve from 1.13826\n",
      "14152/14152 [==============================] - 3s 186us/sample - loss: 1.0012 - val_loss: 1.1568\n",
      "Epoch 14/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.9957\n",
      "Epoch 00014: val_loss did not improve from 1.13826\n",
      "14152/14152 [==============================] - 3s 190us/sample - loss: 0.9939 - val_loss: 1.1719\n",
      "Epoch 15/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9876\n",
      "Epoch 00015: val_loss did not improve from 1.13826\n",
      "14152/14152 [==============================] - 3s 189us/sample - loss: 0.9867 - val_loss: 1.1905\n",
      "Epoch 16/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9788\n",
      "Epoch 00016: val_loss did not improve from 1.13826\n",
      "14152/14152 [==============================] - 3s 189us/sample - loss: 0.9763 - val_loss: 1.1654\n",
      "Epoch 17/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.9558\n",
      "Epoch 00017: val_loss did not improve from 1.13826\n",
      "14152/14152 [==============================] - 3s 183us/sample - loss: 0.9561 - val_loss: 1.1641\n",
      "Epoch 18/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9441\n",
      "Epoch 00018: val_loss did not improve from 1.13826\n",
      "14152/14152 [==============================] - 3s 182us/sample - loss: 0.9436 - val_loss: 1.1974\n",
      "Epoch 19/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9343\n",
      "Epoch 00019: val_loss did not improve from 1.13826\n",
      "14152/14152 [==============================] - 2s 176us/sample - loss: 0.9343 - val_loss: 1.1765\n",
      "Epoch 20/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.9282\n",
      "Epoch 00020: val_loss did not improve from 1.13826\n",
      "14152/14152 [==============================] - 2s 169us/sample - loss: 0.9279 - val_loss: 1.1669\n",
      "Epoch 21/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9186\n",
      "Epoch 00021: val_loss did not improve from 1.13826\n",
      "14152/14152 [==============================] - 2s 174us/sample - loss: 0.9190 - val_loss: 1.1707\n",
      "Epoch 22/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.9093\n",
      "Epoch 00022: val_loss did not improve from 1.13826\n",
      "14152/14152 [==============================] - 2s 176us/sample - loss: 0.9086 - val_loss: 1.2019\n",
      "Epoch 23/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.8949\n",
      "Epoch 00023: val_loss did not improve from 1.13826\n",
      "14152/14152 [==============================] - 2s 176us/sample - loss: 0.8945 - val_loss: 1.1826\n",
      "Epoch 24/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.8854\n",
      "Epoch 00024: val_loss did not improve from 1.13826\n",
      "14152/14152 [==============================] - 2s 173us/sample - loss: 0.8866 - val_loss: 1.1912\n",
      "Epoch 25/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.8761\n",
      "Epoch 00025: val_loss did not improve from 1.13826\n",
      "14152/14152 [==============================] - 2s 174us/sample - loss: 0.8775 - val_loss: 1.1633\n",
      "0 [1.12814159 1.75573126 2.21521671] 0.53373639\n",
      "1 [1.10863371 1.83765125 2.2481502 ] 0.53157771\n",
      "2 [1.00240294 1.86296434 2.17434697] 0.53218164\n",
      "3 [0.99725111 1.73587036 2.21509865] 0.53341582\n",
      "4 [1.08240404 1.6342479  2.20955103] 0.53305061\n",
      "5 [1.10744795 1.75590437 2.16756296] 0.53403454\n",
      "6 [1.10731314 1.72258215 2.16718626] 0.5340258\n",
      "7 [1.11535486 1.72698848 2.24737649] 0.53362946\n",
      "8 [1.1228218  1.76696736 2.21595116] 0.53374549\n",
      "9 [0.99586936 1.73110764 2.24129263] 0.53392051\n",
      "10 [1.06506842 1.7660692  2.21164692] 0.5325315\n",
      "11 [1.10913309 1.75559153 2.16815483] 0.53403454\n",
      "12 [1.03584993 1.76451091 2.21614349] 0.53233971\n",
      "13 [1.00684067 1.75555276 2.23950358] 0.53331648\n",
      "14 [1.14933685 1.72565677 2.25785269] 0.53302937\n",
      "15 [1.08526049 1.72886766 2.24838775] 0.53259403\n",
      "16 [1.11228534 1.76326624 2.16593918] 0.53404326\n",
      "17 [1.08225307 1.73255834 2.2438399 ] 0.53259403\n",
      "18 [1.19962084 1.72965917 2.21429934] 0.53572622\n",
      "19 [0.99922282 1.72527236 2.21649594] 0.53462931\n",
      "Fold 4 random try 16\n",
      "Train on 14152 samples, validate on 724 samples\n",
      "Epoch 1/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.7290\n",
      "Epoch 00001: val_loss improved from inf to 1.31443, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 246us/sample - loss: 1.7274 - val_loss: 1.3144\n",
      "Epoch 2/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 1.2823\n",
      "Epoch 00002: val_loss improved from 1.31443 to 1.23315, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 189us/sample - loss: 1.2831 - val_loss: 1.2331\n",
      "Epoch 3/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 1.1893\n",
      "Epoch 00003: val_loss improved from 1.23315 to 1.22239, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 184us/sample - loss: 1.1909 - val_loss: 1.2224\n",
      "Epoch 4/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.1480\n",
      "Epoch 00004: val_loss did not improve from 1.22239\n",
      "14152/14152 [==============================] - 2s 176us/sample - loss: 1.1474 - val_loss: 1.2253\n",
      "Epoch 5/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.1112\n",
      "Epoch 00005: val_loss improved from 1.22239 to 1.21452, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 185us/sample - loss: 1.1113 - val_loss: 1.2145\n",
      "Epoch 6/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.0866\n",
      "Epoch 00006: val_loss did not improve from 1.21452\n",
      "14152/14152 [==============================] - 2s 173us/sample - loss: 1.0865 - val_loss: 1.2199\n",
      "Epoch 7/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0697\n",
      "Epoch 00007: val_loss improved from 1.21452 to 1.20366, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 2s 173us/sample - loss: 1.0713 - val_loss: 1.2037\n",
      "Epoch 8/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.0593\n",
      "Epoch 00008: val_loss improved from 1.20366 to 1.19380, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 2s 175us/sample - loss: 1.0597 - val_loss: 1.1938\n",
      "Epoch 9/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 1.0446\n",
      "Epoch 00009: val_loss did not improve from 1.19380\n",
      "14152/14152 [==============================] - 2s 174us/sample - loss: 1.0442 - val_loss: 1.1953\n",
      "Epoch 10/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.0491\n",
      "Epoch 00010: val_loss did not improve from 1.19380\n",
      "14152/14152 [==============================] - 3s 205us/sample - loss: 1.0498 - val_loss: 1.2078\n",
      "Epoch 11/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.0134\n",
      "Epoch 00011: val_loss did not improve from 1.19380\n",
      "14152/14152 [==============================] - 3s 215us/sample - loss: 1.0126 - val_loss: 1.1984\n",
      "Epoch 12/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.0106\n",
      "Epoch 00012: val_loss improved from 1.19380 to 1.18771, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 218us/sample - loss: 1.0091 - val_loss: 1.1877\n",
      "Epoch 13/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9987\n",
      "Epoch 00013: val_loss did not improve from 1.18771\n",
      "14152/14152 [==============================] - 3s 203us/sample - loss: 0.9995 - val_loss: 1.1881\n",
      "Epoch 14/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9992\n",
      "Epoch 00014: val_loss improved from 1.18771 to 1.17638, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 183us/sample - loss: 0.9974 - val_loss: 1.1764\n",
      "Epoch 15/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9831\n",
      "Epoch 00015: val_loss did not improve from 1.17638\n",
      "14152/14152 [==============================] - 2s 175us/sample - loss: 0.9847 - val_loss: 1.2046\n",
      "Epoch 16/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 0.9797\n",
      "Epoch 00016: val_loss did not improve from 1.17638\n",
      "14152/14152 [==============================] - 2s 174us/sample - loss: 0.9772 - val_loss: 1.2172\n",
      "Epoch 17/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9562\n",
      "Epoch 00017: val_loss did not improve from 1.17638\n",
      "14152/14152 [==============================] - 3s 229us/sample - loss: 0.9581 - val_loss: 1.1965\n",
      "Epoch 18/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.9553\n",
      "Epoch 00018: val_loss did not improve from 1.17638\n",
      "14152/14152 [==============================] - 2s 175us/sample - loss: 0.9549 - val_loss: 1.2367\n",
      "Epoch 19/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9414\n",
      "Epoch 00019: val_loss did not improve from 1.17638\n",
      "14152/14152 [==============================] - 2s 176us/sample - loss: 0.9418 - val_loss: 1.2079\n",
      "Epoch 20/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.9316\n",
      "Epoch 00020: val_loss did not improve from 1.17638\n",
      "14152/14152 [==============================] - 3s 181us/sample - loss: 0.9312 - val_loss: 1.1764\n",
      "Epoch 21/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9229\n",
      "Epoch 00021: val_loss did not improve from 1.17638\n",
      "14152/14152 [==============================] - 3s 186us/sample - loss: 0.9232 - val_loss: 1.1838\n",
      "Epoch 22/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9132\n",
      "Epoch 00022: val_loss did not improve from 1.17638\n",
      "14152/14152 [==============================] - 3s 184us/sample - loss: 0.9140 - val_loss: 1.2239\n",
      "Epoch 23/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.9016\n",
      "Epoch 00023: val_loss did not improve from 1.17638\n",
      "14152/14152 [==============================] - 3s 184us/sample - loss: 0.9015 - val_loss: 1.2339\n",
      "Epoch 24/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.8988\n",
      "Epoch 00024: val_loss did not improve from 1.17638\n",
      "14152/14152 [==============================] - 3s 182us/sample - loss: 0.9007 - val_loss: 1.2242\n",
      "Epoch 25/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.8928\n",
      "Epoch 00025: val_loss did not improve from 1.17638\n",
      "14152/14152 [==============================] - 3s 193us/sample - loss: 0.8926 - val_loss: 1.2131\n",
      "0 [1.11281549 1.68475312 2.10806624] 0.54815876\n",
      "1 [1.13006642 1.68244259 2.11287611] 0.54558064\n",
      "2 [1.03761905 1.74758864 2.15259466] 0.54023505\n",
      "3 [1.08988728 1.74350021 2.10813688] 0.54132051\n",
      "4 [1.14888141 1.53885382 2.10935999] 0.54625338\n",
      "5 [1.08225664 1.68239862 2.10815952] 0.54953175\n",
      "6 [1.08492884 1.68320373 2.10819563] 0.54953175\n",
      "7 [1.07355669 1.65500011 2.1080667 ] 0.54649317\n",
      "8 [1.04186804 1.57138094 2.28250544] 0.54223421\n",
      "9 [1.0385283  1.75062308 2.10827111] 0.5455703\n",
      "10 [1.02929588 1.76020061 2.15293697] 0.53894943\n",
      "11 [1.03481563 1.65725586 2.28319883] 0.5404984\n",
      "12 [1.01389998 1.68494246 2.11092101] 0.5507532\n",
      "13 [1.03458149 1.68248143 2.11108639] 0.55267506\n",
      "14 [1.08617722 1.78430843 2.10830569] 0.53897107\n",
      "15 [1.04127894 1.57149879 2.28643572] 0.54002251\n",
      "16 [1.03336873 1.66842971 2.10812616] 0.55219323\n",
      "17 [1.06683508 1.68500017 2.10818923] 0.55013683\n",
      "18 [1.14902554 1.68376006 2.09925742] 0.54252388\n",
      "19 [1.07565709 1.68408385 2.15230367] 0.54409658\n",
      "Fold 4 random try 17\n",
      "Train on 14152 samples, validate on 724 samples\n",
      "Epoch 1/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.7652\n",
      "Epoch 00001: val_loss improved from inf to 1.32672, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 4s 262us/sample - loss: 1.7651 - val_loss: 1.3267\n",
      "Epoch 2/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.2781\n",
      "Epoch 00002: val_loss improved from 1.32672 to 1.25584, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 185us/sample - loss: 1.2800 - val_loss: 1.2558\n",
      "Epoch 3/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.1877\n",
      "Epoch 00003: val_loss improved from 1.25584 to 1.21315, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 187us/sample - loss: 1.1879 - val_loss: 1.2132\n",
      "Epoch 4/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.1415\n",
      "Epoch 00004: val_loss improved from 1.21315 to 1.20787, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 193us/sample - loss: 1.1419 - val_loss: 1.2079\n",
      "Epoch 5/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.1121\n",
      "Epoch 00005: val_loss improved from 1.20787 to 1.18175, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 200us/sample - loss: 1.1130 - val_loss: 1.1818\n",
      "Epoch 6/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0874\n",
      "Epoch 00006: val_loss did not improve from 1.18175\n",
      "14152/14152 [==============================] - 3s 191us/sample - loss: 1.0860 - val_loss: 1.1917\n",
      "Epoch 7/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.0704\n",
      "Epoch 00007: val_loss improved from 1.18175 to 1.17716, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 186us/sample - loss: 1.0704 - val_loss: 1.1772\n",
      "Epoch 8/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.0568\n",
      "Epoch 00008: val_loss improved from 1.17716 to 1.16598, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 185us/sample - loss: 1.0564 - val_loss: 1.1660\n",
      "Epoch 9/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.0439\n",
      "Epoch 00009: val_loss did not improve from 1.16598\n",
      "14152/14152 [==============================] - 3s 191us/sample - loss: 1.0434 - val_loss: 1.1811\n",
      "Epoch 10/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.0367\n",
      "Epoch 00010: val_loss did not improve from 1.16598\n",
      "14152/14152 [==============================] - 3s 184us/sample - loss: 1.0380 - val_loss: 1.1842\n",
      "Epoch 11/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0201\n",
      "Epoch 00011: val_loss improved from 1.16598 to 1.16084, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 183us/sample - loss: 1.0216 - val_loss: 1.1608\n",
      "Epoch 12/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 0.9595\n",
      "Epoch 00015: val_loss did not improve from 1.13265\n",
      "14152/14152 [==============================] - 2s 174us/sample - loss: 0.9590 - val_loss: 1.1845\n",
      "Epoch 16/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.9494\n",
      "Epoch 00016: val_loss did not improve from 1.13265\n",
      "14152/14152 [==============================] - 2s 172us/sample - loss: 0.9506 - val_loss: 1.1845\n",
      "Epoch 17/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.9368\n",
      "Epoch 00017: val_loss did not improve from 1.13265\n",
      "14152/14152 [==============================] - 2s 175us/sample - loss: 0.9387 - val_loss: 1.1960\n",
      "Epoch 18/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9211\n",
      "Epoch 00018: val_loss did not improve from 1.13265\n",
      "14152/14152 [==============================] - 3s 204us/sample - loss: 0.9211 - val_loss: 1.1977\n",
      "Epoch 19/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9202\n",
      "Epoch 00019: val_loss did not improve from 1.13265\n",
      "14152/14152 [==============================] - 3s 215us/sample - loss: 0.9203 - val_loss: 1.1901\n",
      "Epoch 20/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.9184\n",
      "Epoch 00020: val_loss did not improve from 1.13265\n",
      "14152/14152 [==============================] - 3s 193us/sample - loss: 0.9185 - val_loss: 1.1824\n",
      "Epoch 21/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.8921\n",
      "Epoch 00021: val_loss did not improve from 1.13265\n",
      "14152/14152 [==============================] - 3s 191us/sample - loss: 0.8915 - val_loss: 1.2082\n",
      "Epoch 22/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.8858\n",
      "Epoch 00022: val_loss did not improve from 1.13265\n",
      "14152/14152 [==============================] - 2s 175us/sample - loss: 0.8850 - val_loss: 1.1974\n",
      "Epoch 23/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.8876\n",
      "Epoch 00023: val_loss did not improve from 1.13265\n",
      "14152/14152 [==============================] - 2s 173us/sample - loss: 0.8856 - val_loss: 1.1927\n",
      "Epoch 24/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.8779\n",
      "Epoch 00024: val_loss did not improve from 1.13265\n",
      "14152/14152 [==============================] - 2s 174us/sample - loss: 0.8776 - val_loss: 1.2011\n",
      "Epoch 25/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.8699\n",
      "Epoch 00025: val_loss did not improve from 1.13265\n",
      "14152/14152 [==============================] - 3s 181us/sample - loss: 0.8698 - val_loss: 1.2092\n",
      "0 [1.03408673 1.77026883 2.26691471] 0.53793289\n",
      "1 [0.97116338 1.79102428 2.28445242] 0.53964899\n",
      "2 [1.05837595 1.76587647 2.27977759] 0.53832868\n",
      "3 [1.0775601  1.71849726 2.27675235] 0.5373225\n",
      "4 [1.05845533 1.8171501  2.28381593] 0.54232246\n",
      "5 [1.08288343 1.77099625 2.14376457] 0.52741691\n",
      "6 [1.04835559 1.76531668 2.32664884] 0.53743967\n",
      "7 [1.1091856  1.72725765 2.14474797] 0.52440431\n",
      "8 [1.03695774 1.78444215 2.3368611 ] 0.53831801\n",
      "9 [1.04166453 1.719363   2.27550787] 0.53659348\n",
      "10 [1.05729562 1.80010231 2.32747116] 0.53832\n",
      "11 [0.97639587 1.81754858 2.33794409] 0.54220938\n",
      "12 [1.13753304 1.8164348  2.28340831] 0.54261784\n",
      "13 [1.17781076 1.61432367 2.34228685] 0.53734218\n",
      "14 [1.05284112 1.69280446 2.26592304] 0.53529624\n",
      "15 [1.00522174 1.82712552 2.32629425] 0.5402409\n",
      "16 [1.05953196 1.7710752  2.2672685 ] 0.53754032\n",
      "17 [0.98773612 1.82835126 2.2775596 ] 0.54255701\n",
      "18 [1.05275927 1.7196682  2.26780674] 0.53587698\n",
      "19 [1.05787654 1.75305333 2.33817475] 0.53776563\n",
      "Fold 5 random try 25\n",
      "Train on 14152 samples, validate on 724 samples\n",
      "Epoch 1/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.6717\n",
      "Epoch 00001: val_loss improved from inf to 1.21699, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 4s 254us/sample - loss: 1.6718 - val_loss: 1.2170\n",
      "Epoch 2/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 1.2870\n",
      "Epoch 00002: val_loss improved from 1.21699 to 1.18880, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 179us/sample - loss: 1.2869 - val_loss: 1.1888\n",
      "Epoch 3/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.1867\n",
      "Epoch 00003: val_loss did not improve from 1.18880\n",
      "14152/14152 [==============================] - 3s 178us/sample - loss: 1.1881 - val_loss: 1.1957\n",
      "Epoch 4/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.1428\n",
      "Epoch 00004: val_loss did not improve from 1.18880\n",
      "14152/14152 [==============================] - 2s 174us/sample - loss: 1.1432 - val_loss: 1.1959\n",
      "Epoch 5/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.1081\n",
      "Epoch 00005: val_loss did not improve from 1.18880\n",
      "14152/14152 [==============================] - 3s 179us/sample - loss: 1.1080 - val_loss: 1.1994\n",
      "Epoch 6/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.0839\n",
      "Epoch 00006: val_loss did not improve from 1.18880\n",
      "14152/14152 [==============================] - 3s 187us/sample - loss: 1.0831 - val_loss: 1.1988\n",
      "Epoch 7/25\n",
      "13856/14152 [============================>.] - ETA: 0s - loss: 1.0706\n",
      "Epoch 00007: val_loss did not improve from 1.18880\n",
      "14152/14152 [==============================] - 2s 174us/sample - loss: 1.0719 - val_loss: 1.1925\n",
      "Epoch 8/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.0581\n",
      "Epoch 00008: val_loss did not improve from 1.18880\n",
      "14152/14152 [==============================] - 2s 176us/sample - loss: 1.0585 - val_loss: 1.2109\n",
      "Epoch 9/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.0357\n",
      "Epoch 00009: val_loss did not improve from 1.18880\n",
      "14152/14152 [==============================] - 3s 177us/sample - loss: 1.0354 - val_loss: 1.2394\n",
      "Epoch 10/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 1.0297\n",
      "Epoch 00010: val_loss did not improve from 1.18880\n",
      "14152/14152 [==============================] - 3s 177us/sample - loss: 1.0265 - val_loss: 1.2177\n",
      "Epoch 11/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.0143\n",
      "Epoch 00011: val_loss did not improve from 1.18880\n",
      "14152/14152 [==============================] - 3s 177us/sample - loss: 1.0164 - val_loss: 1.2094\n",
      "Epoch 12/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0134\n",
      "Epoch 00012: val_loss did not improve from 1.18880\n",
      "14152/14152 [==============================] - 3s 189us/sample - loss: 1.0133 - val_loss: 1.2290\n",
      "Epoch 13/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.9890\n",
      "Epoch 00013: val_loss did not improve from 1.18880\n",
      "14152/14152 [==============================] - 3s 180us/sample - loss: 0.9871 - val_loss: 1.2111\n",
      "Epoch 14/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9800\n",
      "Epoch 00014: val_loss did not improve from 1.18880\n",
      "14152/14152 [==============================] - 3s 185us/sample - loss: 0.9836 - val_loss: 1.2316\n",
      "Epoch 15/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.9754\n",
      "Epoch 00015: val_loss did not improve from 1.18880\n",
      "14152/14152 [==============================] - 3s 183us/sample - loss: 0.9756 - val_loss: 1.2444\n",
      "Epoch 16/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.9629\n",
      "Epoch 00016: val_loss did not improve from 1.18880\n",
      "14152/14152 [==============================] - 3s 182us/sample - loss: 0.9624 - val_loss: 1.2105\n",
      "Epoch 17/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9463\n",
      "Epoch 00017: val_loss did not improve from 1.18880\n",
      "14152/14152 [==============================] - 2s 175us/sample - loss: 0.9455 - val_loss: 1.2328\n",
      "Epoch 18/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9331\n",
      "Epoch 00018: val_loss did not improve from 1.18880\n",
      "14152/14152 [==============================] - 3s 178us/sample - loss: 0.9327 - val_loss: 1.2174\n",
      "Epoch 19/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9378\n",
      "Epoch 00019: val_loss did not improve from 1.18880\n",
      "14152/14152 [==============================] - 3s 180us/sample - loss: 0.9373 - val_loss: 1.2145\n",
      "Epoch 20/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9307\n",
      "Epoch 00020: val_loss did not improve from 1.18880\n",
      "14152/14152 [==============================] - 2s 172us/sample - loss: 0.9319 - val_loss: 1.2488\n",
      "Epoch 21/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 0.9160\n",
      "Epoch 00021: val_loss did not improve from 1.18880\n",
      "14152/14152 [==============================] - 2s 175us/sample - loss: 0.9164 - val_loss: 1.2861\n",
      "Epoch 22/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.9078\n",
      "Epoch 00022: val_loss did not improve from 1.18880\n",
      "14152/14152 [==============================] - 2s 176us/sample - loss: 0.9082 - val_loss: 1.2471\n",
      "Epoch 23/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.8970\n",
      "Epoch 00023: val_loss did not improve from 1.18880\n",
      "14152/14152 [==============================] - 2s 175us/sample - loss: 0.8960 - val_loss: 1.2425\n",
      "Epoch 24/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 0.8887\n",
      "Epoch 00024: val_loss did not improve from 1.18880\n",
      "14152/14152 [==============================] - 2s 173us/sample - loss: 0.8903 - val_loss: 1.2500\n",
      "Epoch 25/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 0.8792\n",
      "Epoch 00025: val_loss did not improve from 1.18880\n",
      "14152/14152 [==============================] - 2s 172us/sample - loss: 0.8802 - val_loss: 1.2287\n",
      "0 [1.08672587 1.75298751 2.12064985] 0.52673022\n",
      "1 [1.06285882 1.77188609 2.1315091 ] 0.52459753\n",
      "2 [0.99827128 1.87148552 2.10753456] 0.52709852\n",
      "3 [1.05967266 1.76337802 2.11328159] 0.52705899\n",
      "4 [1.07997003 1.77258496 2.11628014] 0.52671353\n",
      "5 [1.05033331 1.76285087 2.11372745] 0.52705899\n",
      "6 [1.08304684 1.76334421 2.11865172] 0.52750787\n",
      "7 [1.02165172 1.7942759  2.1255009 ] 0.5248357\n",
      "8 [1.08005518 1.86941175 2.1258507 ] 0.52886721\n",
      "9 [1.06659381 1.76968406 2.12553646] 0.52666421\n",
      "10 [1.1516931  1.76341056 2.11151996] 0.52716591\n",
      "11 [1.04299037 1.7633091  2.13092561] 0.52554101\n",
      "12 [0.99583223 1.85111912 2.11550713] 0.52613066\n",
      "13 [1.07073808 1.79541995 2.10812185] 0.52577006\n",
      "14 [1.05558356 1.7759128  2.11422754] 0.52612168\n",
      "15 [1.05496497 1.78702957 2.11253793] 0.52697773\n",
      "16 [1.03274086 1.76333556 2.12576277] 0.52534489\n",
      "17 [1.04433808 1.84369556 2.10743887] 0.52561258\n",
      "18 [1.05451376 1.87504325 2.11372204] 0.52789657\n",
      "19 [1.08779031 1.78715536 2.12754357] 0.52806942\n",
      "Fold 5 random try 26\n",
      "Train on 14152 samples, validate on 724 samples\n",
      "Epoch 1/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.7436\n",
      "Epoch 00001: val_loss improved from inf to 1.28888, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 4s 247us/sample - loss: 1.7423 - val_loss: 1.2889\n",
      "Epoch 2/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.2911\n",
      "Epoch 00002: val_loss improved from 1.28888 to 1.23117, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 2s 172us/sample - loss: 1.2885 - val_loss: 1.2312\n",
      "Epoch 3/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 1.2041\n",
      "Epoch 00003: val_loss improved from 1.23117 to 1.20615, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 185us/sample - loss: 1.2059 - val_loss: 1.2061\n",
      "Epoch 4/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.1471\n",
      "Epoch 00004: val_loss did not improve from 1.20615\n",
      "14152/14152 [==============================] - 3s 177us/sample - loss: 1.1472 - val_loss: 1.2171\n",
      "Epoch 5/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.1117\n",
      "Epoch 00005: val_loss improved from 1.20615 to 1.19019, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 2s 176us/sample - loss: 1.1119 - val_loss: 1.1902\n",
      "Epoch 6/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 1.0798\n",
      "Epoch 00006: val_loss improved from 1.19019 to 1.18404, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 2s 175us/sample - loss: 1.0803 - val_loss: 1.1840\n",
      "Epoch 7/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0603\n",
      "Epoch 00007: val_loss improved from 1.18404 to 1.17231, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 188us/sample - loss: 1.0619 - val_loss: 1.1723\n",
      "Epoch 8/25\n",
      "13952/14152 [============================>.] - ETA: 0s - loss: 1.0486\n",
      "Epoch 00008: val_loss did not improve from 1.17231\n",
      "14152/14152 [==============================] - 3s 190us/sample - loss: 1.0492 - val_loss: 1.1803\n",
      "Epoch 9/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.0293\n",
      "Epoch 00009: val_loss did not improve from 1.17231\n",
      "14152/14152 [==============================] - 2s 177us/sample - loss: 1.0296 - val_loss: 1.1766\n",
      "Epoch 10/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 1.0216\n",
      "Epoch 00010: val_loss improved from 1.17231 to 1.17096, saving model to ./nn_model.h5\n",
      "14152/14152 [==============================] - 3s 188us/sample - loss: 1.0198 - val_loss: 1.1710\n",
      "Epoch 11/25\n",
      "14016/14152 [============================>.] - ETA: 0s - loss: 1.0053\n",
      "Epoch 00011: val_loss did not improve from 1.17096\n",
      "14152/14152 [==============================] - 3s 187us/sample - loss: 1.0057 - val_loss: 1.1814\n",
      "Epoch 12/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 1.0029\n",
      "Epoch 00012: val_loss did not improve from 1.17096\n",
      "14152/14152 [==============================] - 3s 180us/sample - loss: 1.0029 - val_loss: 1.1905\n",
      "Epoch 13/25\n",
      "13888/14152 [============================>.] - ETA: 0s - loss: 0.9851\n",
      "Epoch 00013: val_loss did not improve from 1.17096\n",
      "14152/14152 [==============================] - 2s 171us/sample - loss: 0.9838 - val_loss: 1.1866\n",
      "Epoch 14/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9728\n",
      "Epoch 00014: val_loss did not improve from 1.17096\n",
      "14152/14152 [==============================] - 3s 177us/sample - loss: 0.9752 - val_loss: 1.2030\n",
      "Epoch 15/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9690\n",
      "Epoch 00015: val_loss did not improve from 1.17096\n",
      "14152/14152 [==============================] - 3s 185us/sample - loss: 0.9686 - val_loss: 1.1866\n",
      "Epoch 16/25\n",
      "14144/14152 [============================>.] - ETA: 0s - loss: 0.9558\n",
      "Epoch 00016: val_loss did not improve from 1.17096\n",
      "14152/14152 [==============================] - 3s 185us/sample - loss: 0.9554 - val_loss: 1.1865\n",
      "Epoch 17/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9419\n",
      "Epoch 00017: val_loss did not improve from 1.17096\n",
      "14152/14152 [==============================] - 3s 179us/sample - loss: 0.9419 - val_loss: 1.1893\n",
      "Epoch 18/25\n",
      "14048/14152 [============================>.] - ETA: 0s - loss: 0.9320\n",
      "Epoch 00018: val_loss did not improve from 1.17096\n",
      "14152/14152 [==============================] - 3s 178us/sample - loss: 0.9317 - val_loss: 1.1768\n",
      "Epoch 19/25\n",
      "13920/14152 [============================>.] - ETA: 0s - loss: 0.9155\n",
      "Epoch 00019: val_loss did not improve from 1.17096\n",
      "14152/14152 [==============================] - 3s 179us/sample - loss: 0.9158 - val_loss: 1.1855\n",
      "Epoch 20/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.9187\n",
      "Epoch 00020: val_loss did not improve from 1.17096\n",
      "14152/14152 [==============================] - 3s 183us/sample - loss: 0.9217 - val_loss: 1.1842\n",
      "Epoch 21/25\n",
      "14080/14152 [============================>.] - ETA: 0s - loss: 0.9028\n",
      "Epoch 00021: val_loss did not improve from 1.17096\n",
      "14152/14152 [==============================] - 2s 174us/sample - loss: 0.9034 - val_loss: 1.2057\n",
      "Epoch 22/25\n",
      "13984/14152 [============================>.] - ETA: 0s - loss: 0.8943\n",
      "Epoch 00022: val_loss did not improve from 1.17096\n",
      "14152/14152 [==============================] - 2s 171us/sample - loss: 0.8947 - val_loss: 1.2150\n",
      "Epoch 23/25\n",
      "13856/14152 [============================>.] - ETA: 0s - loss: 0.8901\n",
      "Epoch 00023: val_loss did not improve from 1.17096\n",
      "14152/14152 [==============================] - 2s 170us/sample - loss: 0.8900 - val_loss: 1.1917\n",
      "Epoch 24/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.8756\n",
      "Epoch 00024: val_loss did not improve from 1.17096\n",
      "14152/14152 [==============================] - 3s 179us/sample - loss: 0.8754 - val_loss: 1.1722\n",
      "Epoch 25/25\n",
      "14112/14152 [============================>.] - ETA: 0s - loss: 0.8769\n",
      "Epoch 00025: val_loss did not improve from 1.17096\n",
      "14152/14152 [==============================] - 2s 174us/sample - loss: 0.8766 - val_loss: 1.1724\n",
      "0 [1.15132938 1.6564503  2.16236558] 0.54911299\n",
      "1 [1.0417123  1.65201343 2.17787906] 0.54937705\n",
      "2 [1.13199246 1.60823057 2.1621218 ] 0.54810318\n",
      "3 [1.1634037  1.65502096 2.10436392] 0.54875546\n",
      "4 [1.06192805 1.65493608 2.20547328] 0.54942233\n",
      "5 [1.2445594  1.57531546 2.10159685] 0.5525846\n",
      "6 [1.22332262 1.57998809 1.91966292] 0.54856993\n",
      "7 [1.10996753 1.63710213 2.1779664 ] 0.54705161\n",
      "8 [1.10663221 1.61595362 2.17758117] 0.54710285\n",
      "9 [1.03849902 1.69220692 2.16388392] 0.54747818\n",
      "10 [1.06192495 1.69367328 2.11122439] 0.54900727\n",
      "11 [1.06227767 1.67586283 2.17460478] 0.54718014\n",
      "12 [1.04127404 1.6546233  2.19246314] 0.5483051\n",
      "13 [1.05191193 1.60265732 2.17756121] 0.54834685\n",
      "14 [1.11339112 1.65634552 2.05232377] 0.5495166\n",
      "15 [1.03855885 1.6846521  2.1629807 ] 0.54747818\n",
      "16 [1.05357106 1.65665478 2.16261045] 0.54958606\n",
      "17 [1.06213361 1.68201444 2.09971257] 0.54902709\n",
      "18 [1.12142035 1.65677674 2.1627046 ] 0.5488616\n",
      "19 [1.03915713 1.65414861 2.17351659] 0.5488624\n",
      "Fold 5 random try 27\n",
      "Train on 14152 samples, validate on 724 samples\n",
      "Epoch 1/25\n",
      " 9664/14152 [===================>..........] - ETA: 1s - loss: 1.8321"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.metrics import *\n",
    "from tensorflow.keras.utils import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "n_folds=5\n",
    "\n",
    "skf=GroupKFold(n_splits = n_folds)\n",
    "models = []\n",
    "\n",
    "def get_lr(epoch): # change learning rate by epoch\n",
    "    if epoch < 20:\n",
    "        return 1e-3\n",
    "\n",
    "    return 1e-4\n",
    "\n",
    "def nn_modelling(train, test):\n",
    "    # to keep reproducible results ----------------\n",
    "    # https://keras.io/getting_started/faq/\n",
    "    import os\n",
    "    os.environ['PYTHONHASHSEED'] = '0'\n",
    "    np.random.seed(42)\n",
    "    random.seed(12345)\n",
    "    tf.random.set_seed(1234)\n",
    "    # ------------------------------------------\n",
    "    \n",
    "    features = [i for i in train.columns if i not in [\"installation_id\", \"accuracy_group\"]]\n",
    "    categoricals = ['session_title']\n",
    "    for cat in categoricals:\n",
    "        enc = OneHotEncoder()\n",
    "        train_cats = enc.fit_transform(train[[cat]])\n",
    "        test_cats = enc.transform(test[[cat]])\n",
    "        cat_cols = ['{}_{}'.format(cat, str(col)) for col in enc.active_features_]\n",
    "        features += cat_cols\n",
    "        train_cats = pd.DataFrame(train_cats.toarray(), columns=cat_cols)\n",
    "        test_cats = pd.DataFrame(test_cats.toarray(), columns=cat_cols)\n",
    "        train = pd.concat([train, train_cats], axis=1)\n",
    "        test = pd.concat([test, test_cats], axis=1)\n",
    "    # standardization -----\n",
    "    scalar = MinMaxScaler()\n",
    "    train[features] = scalar.fit_transform(train[features])\n",
    "    test[features] = scalar.transform(test[features])\n",
    "    # ---------------------\n",
    "    \n",
    "    X_train = train.drop(['accuracy_group'],axis=1) \n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(X_train[\"installation_id\"]))\n",
    "    X_train[\"installation_id\"] = lbl.transform(list(X_train[\"installation_id\"]))\n",
    "    remove_features = []\n",
    "    for i in categoricals:\n",
    "        remove_features.append(i)\n",
    "    for i in X_train.columns:\n",
    "        if X_train[i].std() == 0 and i not in remove_features:\n",
    "            remove_features.append(i)\n",
    "    for i in high_corr_features:\n",
    "        if i not in remove_features:\n",
    "            remove_features.append(i)\n",
    "    X_train = X_train.drop(remove_features, axis=1)\n",
    "    X_train = X_train[sorted(X_train.columns.tolist())]\n",
    "    y_train = new_train.accuracy_group\n",
    "    \n",
    "    X_test = test.drop([\"installation_id\",\"accuracy_group\"], axis=1)\n",
    "    X_test = X_test.drop(remove_features, axis=1)\n",
    "    X_test = X_test[sorted(X_test.columns.tolist())]\n",
    "    \n",
    "    random_try = 30\n",
    "    mean_qwk_score = 0\n",
    "    for i , (train_index, test_index) in enumerate(skf.split(X_train, y_train, X_train[\"installation_id\"])):    \n",
    "        X_train2 = X_train.iloc[train_index,:]\n",
    "        y_train2 = y_train.iloc[train_index]\n",
    "        X_train2 = X_train2.drop(['installation_id'],axis=1)\n",
    "    \n",
    "        for try_time in range(random_try): \n",
    "            print(\"Fold \"+str(i+1)+\" random try \" +str(try_time+1))\n",
    "            X_test2 = X_train.iloc[test_index,:]\n",
    "            y_test2 = y_train.iloc[test_index]\n",
    "            \n",
    "            X_test2, idx_val = get_random_assessment(X_test2)\n",
    "            X_test2.drop(['installation_id'], inplace=True, axis=1) # 'past_target'\n",
    "            y_test2 = y_test2.loc[idx_val]\n",
    "        \n",
    "            verbosity = 100\n",
    "            model = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Input(shape=(X_train2.shape[1],)),\n",
    "                tf.keras.layers.Dense(200, activation='relu'), #, kernel_regularizer=tf.keras.regularizers.l2(0.001)\n",
    "                tf.keras.layers.LayerNormalization(),\n",
    "                tf.keras.layers.Dropout(0.3),\n",
    "                tf.keras.layers.Dense(100, activation='tanh'),\n",
    "                tf.keras.layers.LayerNormalization(),\n",
    "                tf.keras.layers.Dropout(0.3),\n",
    "                #tf.keras.layers.Dense(50, activation='relu'),\n",
    "                #tf.keras.layers.LayerNormalization(),\n",
    "                #tf.keras.layers.Dropout(0.3),\n",
    "                tf.keras.layers.Dense(25, activation='relu'),\n",
    "                tf.keras.layers.LayerNormalization(),\n",
    "                tf.keras.layers.Dropout(0.3),\n",
    "                tf.keras.layers.Dense(1, activation='relu')\n",
    "            ])\n",
    "            model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=4e-4), loss='mse') #\n",
    "            #print(model.summary())\n",
    "            save_best = tf.keras.callbacks.ModelCheckpoint('./nn_model.h5', save_best_only=True, verbose=1)\n",
    "            early_stop = tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "        \n",
    "            model.fit(X_train2, y_train2, \n",
    "                     validation_data=(X_test2, y_test2),\n",
    "                    epochs=25,callbacks=[save_best]) #early_stop, LearningRateScheduler(get_lr)\n",
    "            model.load_weights('./nn_model.h5')\n",
    "\n",
    "            models.append(model)\n",
    "            valid = np.array(model.predict(X_test2).reshape(X_test2.shape[0],))\n",
    "            real = np.array(y_test2)\n",
    "    \n",
    "            # threshold optimization --------------\n",
    "            best_score = 0\n",
    "            for j in range(20):\n",
    "                optR = OptimizedRounder()\n",
    "                optR.fit(np.array(valid).reshape(-1,), real, random_flg=True)\n",
    "                coefficients = optR.coefficients()\n",
    "                final_valid_pred = optR.predict(np.array(valid).reshape(-1,), coefficients)\n",
    "                score = qwk(real, final_valid_pred)\n",
    "                print(j, np.sort(coefficients), score)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_coefficients = coefficients\n",
    "            mean_qwk_score += best_score / (random_try * n_folds)\n",
    "            if try_time == 0 and i == 0:\n",
    "                final_coefficients = np.sort(best_coefficients) / (random_try * n_folds)\n",
    "            else:\n",
    "                final_coefficients += np.sort(best_coefficients) / (random_try * n_folds)\n",
    "                           \n",
    "    print(\"MEAN QWK = \\t {}\".format(mean_qwk_score))\n",
    "    # test prediction  ------------------------\n",
    "    pred_value = np.zeros([X_test.shape[0]])\n",
    "    for model in models:\n",
    "        pred_value += model.predict(X_test).reshape(X_test.shape[0],) / len(models)\n",
    "    return pred_value, final_coefficients\n",
    "pred_value, final_coefficients = nn_modelling(new_train, new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    0.449\n",
       "2    0.210\n",
       "0    0.187\n",
       "1    0.154\n",
       "Name: accuracy_group, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_pred = pd.cut(np.array(pred_value).reshape(-1,), [-np.inf] + list(np.sort(final_coefficients)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "sample_submission[\"accuracy_group\"] = final_test_pred\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission[\"accuracy_group\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0ba976a8c1f04fae81908701bb699324": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Installation_id: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a759baf7b4f743558ece865ac9ab74d6",
       "max": 1000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e6fc591427814e48a83c0552edbdf8aa",
       "value": 1000
      }
     },
     "22b0b8aeb5674479a32fcbe13a7b23ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_89ff0495832a48bfaa6afd7eec36df26",
        "IPY_MODEL_b2efcd9fc7a04b2d89c924d587ce0199"
       ],
       "layout": "IPY_MODEL_4f2f99e831a64967a3340b7930b1caa1"
      }
     },
     "243644499aa74f15b6d68a7c8945e257": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0ba976a8c1f04fae81908701bb699324",
        "IPY_MODEL_dd81fe20efb747e98a78d18f2514a7fa"
       ],
       "layout": "IPY_MODEL_dcb24fe6c74e41db9760c2fd2e017efc"
      }
     },
     "301d7a7b905d49d8bd936434ef0b86a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "452dd486d8304d7588bc0c7bbac2888f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4eace29824c54fa588b8268a2b644741": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4f2f99e831a64967a3340b7930b1caa1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "89ff0495832a48bfaa6afd7eec36df26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Installation_id: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f873e5e5df514913b603b185721b4ce3",
       "max": 17000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_dbb33a03ab1044b2a7eeaced42eac751",
       "value": 17000
      }
     },
     "a759baf7b4f743558ece865ac9ab74d6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b2efcd9fc7a04b2d89c924d587ce0199": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b3f8ace6779a4ce795166255cfaae110",
       "placeholder": "​",
       "style": "IPY_MODEL_301d7a7b905d49d8bd936434ef0b86a0",
       "value": " 17000/17000 [14:15&lt;00:00, 19.88it/s]"
      }
     },
     "b3f8ace6779a4ce795166255cfaae110": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dbb33a03ab1044b2a7eeaced42eac751": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "dcb24fe6c74e41db9760c2fd2e017efc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dd81fe20efb747e98a78d18f2514a7fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4eace29824c54fa588b8268a2b644741",
       "placeholder": "​",
       "style": "IPY_MODEL_452dd486d8304d7588bc0c7bbac2888f",
       "value": " 1000/1000 [01:39&lt;00:00, 10.09it/s]"
      }
     },
     "e6fc591427814e48a83c0552edbdf8aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "f873e5e5df514913b603b185721b4ce3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
