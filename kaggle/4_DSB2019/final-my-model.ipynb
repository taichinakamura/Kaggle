{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- change initial value of nelder-mead optimization and validation scheme not to make the average of threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import datetime\n",
    "from time import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score, f1_score, confusion_matrix, cohen_kappa_score\n",
    "import lightgbm as lgb\n",
    "from functools import partial\n",
    "import json\n",
    "import copy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.max_rows\",1000)\n",
    "np.set_printoptions(precision=8)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qwk(a1, a2):\n",
    "    max_rat = 3\n",
    "    a1 = np.asarray(a1, dtype=int)\n",
    "    a2 = np.asarray(a2, dtype=int)\n",
    "    hist1 = np.zeros((max_rat + 1, ))\n",
    "    hist2 = np.zeros((max_rat + 1, ))\n",
    "    o = 0\n",
    "    for k in range(a1.shape[0]):\n",
    "        i, j = a1[k], a2[k]\n",
    "        hist1[i] += 1\n",
    "        hist2[j] += 1\n",
    "        o +=  (i - j) * (i - j)\n",
    "    e = 0\n",
    "    for i in range(max_rat + 1):\n",
    "        for j in range(max_rat + 1):\n",
    "            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n",
    "    e = e / a1.shape[0]\n",
    "    return np.round(1 - o / e, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "        return -qwk(y, X_p)\n",
    "    \n",
    "    def fit(self, X, y, random_flg = False):\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        if random_flg:\n",
    "            initial_coef = [np.random.uniform(0.4,0.5), np.random.uniform(0.5,0.6), np.random.uniform(0.6,0.7)]\n",
    "        else:\n",
    "            initial_coef = [1, 1.7, 2.3]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead') #Powell\n",
    "        \n",
    "    def predict(self, X, coef):\n",
    "        return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 12s, sys: 9.42 s, total: 1min 21s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv('../input/data-science-bowl-2019/train.csv')\n",
    "train_labels = pd.read_csv('../input/data-science-bowl-2019/train_labels.csv')\n",
    "test = pd.read_csv('../input/data-science-bowl-2019/test.csv')\n",
    "#specs = pd.read_csv('../input/data-science-bowl-2019/specs.csv')\n",
    "sample_submission = pd.read_csv('../input/data-science-bowl-2019/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_id = train[train.type == \"Assessment\"][['installation_id']].drop_duplicates()\n",
    "train = pd.merge(train, keep_id, on=\"installation_id\", how=\"inner\")\n",
    "train = train[train.installation_id.isin(train_labels.installation_id.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_title = ['Mushroom Sorter (Assessment)', 'Bird Measurer (Assessment)',\n",
    "       'Cauldron Filler (Assessment)', 'Cart Balancer (Assessment)', 'Chest Sorter (Assessment)']\n",
    "def remove_index_calc(df):\n",
    "    additional_remove_index = []\n",
    "    for i, session in df.groupby('installation_id', sort=False):\n",
    "        last_row = session.index[-1]\n",
    "        session = session[session.title.isin(assess_title)]\n",
    "        first_row = session.index[-1] + 1\n",
    "        for j in range(first_row, last_row+1):\n",
    "            additional_remove_index.append(j)                \n",
    "    return additional_remove_index\n",
    "additional_remove_index = remove_index_calc(train)\n",
    "train = train[~train.index.isin(additional_remove_index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess and Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.7 s, sys: 3.88 s, total: 1min 2s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def encode_title(train, test):\n",
    "    train['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), train['title'], train['event_code']))\n",
    "    test['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), test['title'], test['event_code']))\n",
    "    list_of_title_eventcode = sorted(list(set(train['title_event_code'].unique()).union(set(test['title_event_code'].unique()))))\n",
    "\n",
    "    list_of_user_activities = sorted(list(set(train['title'].unique()).union(set(test['title'].unique()))))\n",
    "    list_of_event_code = sorted(list(set(train['event_code'].unique()).union(set(test['event_code'].unique()))))\n",
    "    list_of_worlds = sorted(list(set(train['world'].unique()).union(set(test['world'].unique()))))\n",
    "    activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n",
    "    activities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\n",
    "    activities_world = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n",
    "    assess_titles = sorted(list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(set(test[test['type'] == 'Assessment']['title'].value_counts().index))))\n",
    "\n",
    "    train['title'] = train['title'].map(activities_map)\n",
    "    test['title'] = test['title'].map(activities_map)\n",
    "    train['world'] = train['world'].map(activities_world)\n",
    "    test['world'] = test['world'].map(activities_world)\n",
    "\n",
    "    win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\n",
    "    win_code[activities_map['Bird Measurer (Assessment)']] = 4110\n",
    "    \n",
    "    train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "    test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "    \n",
    "    train[\"misses\"] = train[\"event_data\"].apply(lambda x: json.loads(x)[\"misses\"] if \"\\\"misses\\\"\" in x else np.nan)\n",
    "    test[\"misses\"] = test[\"event_data\"].apply(lambda x: json.loads(x)[\"misses\"] if \"\\\"misses\\\"\" in x else np.nan)\n",
    "    \n",
    "    #train[\"level\"] = train[\"event_data\"].apply(lambda x: json.loads(x)[\"level\"] if \"\\\"level\\\"\" in x else np.nan)\n",
    "    #test[\"level\"] = test[\"event_data\"].apply(lambda x: json.loads(x)[\"level\"] if \"\\\"level\\\"\" in x else np.nan)\n",
    "    \n",
    "    #train[\"round\"] = train[\"event_data\"].apply(lambda x: json.loads(x)[\"round\"] if \"\\\"round\\\"\" in x else np.nan)\n",
    "    #test[\"round\"] = test[\"event_data\"].apply(lambda x: json.loads(x)[\"round\"] if \"\\\"round\\\"\" in x else np.nan)\n",
    "    \n",
    "    train[\"true\"] = train[\"event_data\"].apply(lambda x: 1 if \"true\" in x and \"correct\" in x else 0)\n",
    "    test[\"true\"] = test[\"event_data\"].apply(lambda x: 1 if \"true\" in x and \"correct\" in x else 0)\n",
    "\n",
    "    train[\"false\"] = train[\"event_data\"].apply(lambda x: 1 if \"false\" in x and \"correct\" in x else 0)\n",
    "    test[\"false\"] = test[\"event_data\"].apply(lambda x: 1 if \"false\" in x and \"correct\" in x else 0)\n",
    "    \n",
    "    train['hour'] = train['timestamp'].dt.hour\n",
    "    test['hour'] = test['timestamp'].dt.hour    \n",
    "    train[\"morning\"] = train[\"hour\"].apply(lambda x: 1 if x>=5 and x <=10 else 0)\n",
    "    test[\"morning\"] = test[\"hour\"].apply(lambda x: 1 if x>=5 and x <=10 else 0)\n",
    "                \n",
    "    return train, test, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, activities_world, list_of_title_eventcode\n",
    "\n",
    "train, test, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, activities_world, list_of_title_eventcode = encode_title(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def get_data(user_sample, test_set=False):\n",
    "    last_activity = 0\n",
    "    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "    title_eventcode_count = {str(ele): 0 for ele in list_of_title_eventcode}\n",
    "    user_world_count = {\"world_\"+str(wor) : 0 for wor in activities_world.values()}\n",
    "    event_code_count = {str(ev): 0 for ev in list_of_event_code}\n",
    "    title_count = {actv: 0 for actv in list_of_user_activities}\n",
    "    last_accuracy_title = {'acc_' + title: -1 for title in assess_titles}\n",
    "    morning_play = 0\n",
    "    \n",
    "    last_session_time_sec = 0\n",
    "    all_assessments = []\n",
    "    accuracy_groups = {\"0\":0, \"1\":0, \"2\":0, \"3\":0}\n",
    "    accumulated_accuracy_group = 0\n",
    "    accumulated_correct_attempts = 0 \n",
    "    accumulated_uncorrect_attempts = 0 \n",
    "    accumulated_actions = 0\n",
    "    counter = 0\n",
    "    time_first_activity = float(user_sample['timestamp'].values[0])\n",
    "    miss = 0\n",
    "    crys_game_true = 0; crys_game_false = 0\n",
    "    tree_game_true = 0; tree_game_false = 0\n",
    "    magma_game_true = 0; magma_game_false = 0\n",
    "    crys_game_acc = []; tree_game_acc = []; magma_game_acc = []\n",
    "    durations = []\n",
    "    \n",
    "    for i, session in user_sample.groupby('game_session', sort=False):      \n",
    "        session_type = session['type'].iloc[0]\n",
    "        session_title = session['title'].iloc[0]\n",
    "        session_title_text = activities_labels[session_title]\n",
    "        session_world = session[\"world\"].iloc[0]\n",
    "        \n",
    "        if session_type != 'Assessment':\n",
    "            if session_type == \"Game\":\n",
    "                true = session['true'].sum()\n",
    "                false = session['false'].sum() \n",
    "                if session_world == activities_world[\"CRYSTALCAVES\"]:\n",
    "                    crys_game_true += true\n",
    "                    crys_game_false += false\n",
    "                    crys_game_acc.append(true / (true + false) if (true + false) != 0 else 0)\n",
    "                elif session_world == activities_world[\"TREETOPCITY\"]:\n",
    "                    tree_game_true += true\n",
    "                    tree_game_false += false\n",
    "                    tree_game_acc.append(true / (true + false) if (true + false) != 0 else 0)\n",
    "                elif session_world == activities_world[\"MAGMAPEAK\"]:\n",
    "                    magma_game_true += true\n",
    "                    magma_game_false += false\n",
    "                    magma_game_acc.append(true / (true + false) if (true + false) != 0 else 0)\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "        if (session_type == 'Assessment') & (test_set or len(session)>1): # test set or session in train_label\n",
    "            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n",
    "            true_attempts = all_attempts['event_data'].str.contains('true').sum() # true in target assess\n",
    "            false_attempts = all_attempts['event_data'].str.contains('false').sum() # false in target assessment\n",
    "            \n",
    "            # from start of installation_id to the start of target assessment ------------------------\n",
    "            features = user_activities_count.copy() # appearance of each type without duplicates\n",
    "            features.update(title_eventcode_count.copy()) # apperance of combi of title and event_code\n",
    "            features.update(user_world_count.copy()) # appearance of world with duplicates\n",
    "            features.update(event_code_count.copy())\n",
    "            features.update(title_count.copy())\n",
    "            features.update(last_accuracy_title.copy())\n",
    "            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n",
    "            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n",
    "            accumulated_correct_attempts += true_attempts \n",
    "            accumulated_uncorrect_attempts += false_attempts\n",
    "            features[\"misses\"] = miss\n",
    "            features['accumulated_actions'] = accumulated_actions\n",
    "            features[\"morning_play\"] = morning_play\n",
    "            \n",
    "            if session_world == activities_world[\"CRYSTALCAVES\"]:\n",
    "                features[\"game_true\"] = crys_game_true\n",
    "                features[\"game_false\"] = crys_game_false\n",
    "                features['game_accuracy'] = crys_game_true / (crys_game_true + crys_game_false) if (crys_game_true + crys_game_false) != 0 else 0\n",
    "                features[\"game_accuracy_std\"] = np.std(crys_game_acc) if len(crys_game_acc) >=1 else 0\n",
    "                features[\"last_game_acc\"] = crys_game_acc[-1] if len(crys_game_acc) >=1 else 0\n",
    "            elif session_world == activities_world[\"TREETOPCITY\"]:\n",
    "                features[\"game_true\"] = tree_game_true\n",
    "                features[\"game_false\"] = tree_game_false\n",
    "                features['game_accuracy'] = tree_game_true / (tree_game_true + tree_game_false) if (tree_game_true + tree_game_false) != 0 else 0\n",
    "                features[\"game_accuracy_std\"] = np.std(tree_game_acc) if len(tree_game_acc) >=1 else 0\n",
    "                features[\"last_game_acc\"] = tree_game_acc[-1] if len(tree_game_acc) >=1 else 0\n",
    "            elif session_world == activities_world[\"MAGMAPEAK\"]:\n",
    "                features[\"game_true\"] = magma_game_true\n",
    "                features[\"game_false\"] = magma_game_false\n",
    "                features['game_accuracy'] = magma_game_true / (magma_game_true + magma_game_false) if (magma_game_true + magma_game_false) != 0 else 0\n",
    "                features[\"game_accuracy_std\"] = np.std(magma_game_acc) if len(magma_game_acc) >=1 else 0\n",
    "                features[\"last_game_acc\"] = magma_game_acc[-1] if len(magma_game_acc) >=1 else 0\n",
    "            \n",
    "            features['installation_id'] = session['installation_id'].iloc[-1]\n",
    "            features['session_title'] = session_title\n",
    "            \n",
    "            if durations == []: #span of timestamp in target assessment\n",
    "                features['duration_mean'] = 0\n",
    "                #features['duration_std'] = 0\n",
    "                #features['duration_max'] = 0\n",
    "            else:\n",
    "                features['duration_mean'] = np.mean(durations)\n",
    "                #features['duration_std'] = np.std(durations)\n",
    "                #features['duration_max'] = np.max(durations)\n",
    "            durations.append((session.iloc[-1, 2] - session.iloc[0, 2]).seconds) \n",
    "            \n",
    "            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "            last_accuracy_title['acc_' + session_title_text] = accuracy\n",
    "            if accuracy == 0:\n",
    "                features['accuracy_group'] = 0\n",
    "            elif accuracy == 1:\n",
    "                features['accuracy_group'] = 3\n",
    "            elif accuracy == 0.5:\n",
    "                features['accuracy_group'] = 2\n",
    "            else:\n",
    "                features['accuracy_group'] = 1\n",
    "            features.update(accuracy_groups)\n",
    "            accuracy_groups[str(features['accuracy_group'])] += 1\n",
    "            features['accumulated_accuracy_group'] = accumulated_accuracy_group/counter if counter > 0 else 0\n",
    "            accumulated_accuracy_group += features['accuracy_group']\n",
    "            \n",
    "            if test_set:\n",
    "                all_assessments.append(features)\n",
    "            elif true_attempts+false_attempts > 0:\n",
    "                all_assessments.append(features)\n",
    "                \n",
    "            counter += 1\n",
    "            \n",
    "        n_of_title = Counter(session['title']) \n",
    "        for key in n_of_title.keys():\n",
    "            title_count[activities_labels[key]] += n_of_title[key]\n",
    "            \n",
    "        n_of_eventcode = Counter(session['event_code']) \n",
    "        for key in n_of_eventcode.keys():\n",
    "            event_code_count[str(key)] += n_of_eventcode[key]\n",
    "                        \n",
    "        n_of_title_eventcode = Counter(session['title_event_code']) \n",
    "        for key in n_of_title_eventcode.keys():\n",
    "            title_eventcode_count[str(key)] += n_of_title_eventcode[key]\n",
    "        miss += np.sum(session[\"misses\"])\n",
    "        morning_play += np.sum(session[\"morning\"])  \n",
    "        user_world_count[\"world_\"+str(session_world)] += session.shape[0]\n",
    "\n",
    "        accumulated_actions += len(session)\n",
    "        if last_activity != session_type:\n",
    "            user_activities_count[session_type] += 1\n",
    "            last_activitiy = session_type\n",
    "    if test_set:\n",
    "        return all_assessments[-1], all_assessments[:-1]\n",
    "    return all_assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_test(train, test):\n",
    "    compiled_train = []\n",
    "    compiled_test = []\n",
    "    compiled_val = []\n",
    "\n",
    "    for i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort=False)), total=train.installation_id.nunique(), desc='Installation_id', position=0):\n",
    "        compiled_train += get_data(user_sample)\n",
    "    del train\n",
    "    for ins_id, user_sample in tqdm(test.groupby('installation_id', sort=False), total=test.installation_id.nunique(), desc='Installation_id', position=0):\n",
    "        test_data, val_data = get_data(user_sample, test_set=True)\n",
    "\n",
    "        compiled_test.append(test_data)\n",
    "        compiled_val += val_data\n",
    "    del test\n",
    "    reduce_train = pd.DataFrame(compiled_train)\n",
    "    reduce_test = pd.DataFrame(compiled_test)\n",
    "    reduce_val = pd.DataFrame(compiled_val)\n",
    "\n",
    "    categoricals = ['session_title']\n",
    "    return reduce_train, reduce_test, reduce_val, categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d75735dbda4459e96ad11509f0c066c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Installation_id', max=3614, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84d42ad19514640b65a5b84ad97262f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Installation_id', max=1000, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_train, new_test, new_val, categoricals = get_train_and_test(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adversarial validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_av(reduce_train, reduce_test, usefull_features):\n",
    "    \n",
    "    tr_data = reduce_train.copy()\n",
    "    tst_data = reduce_test.copy()\n",
    "    tr_data['target'] = 0 \n",
    "    tst_data['target'] = 1\n",
    "    av_data = pd.concat([tr_data[[col for col in tr_data.columns if col not in ['accuracy_group']]], tst_data[[col for col in tst_data.columns if col not in ['accuracy_group']]]], axis = 0)\n",
    "    \n",
    "    # undersample majority class\n",
    "    #positive = av_data[av_data['target']==1]\n",
    "    #negative = av_data[av_data['target']==0]\n",
    "    #negative = negative.sample(int(negative.shape[0] * 0.5), random_state = 42)\n",
    "    #av_data = pd.concat([negative, positive], axis = 0)\n",
    "    \n",
    "    # reset index and shuffle\n",
    "    av_data.reset_index(drop = True)\n",
    "    from sklearn.utils import shuffle\n",
    "    av_data = shuffle(av_data)\n",
    "    \n",
    "    params = {\n",
    "            'learning_rate': 0.05, \n",
    "            'n_jobs': -1,\n",
    "            'seed': 50,\n",
    "            'objective':'binary',\n",
    "            'boosting_type':'gbdt',\n",
    "            'is_unbalance': True,\n",
    "            'metric': 'auc',\n",
    "        }\n",
    "    \n",
    "    # define a KFold strategy\n",
    "    kf = GroupKFold(n_splits = 5)\n",
    "    target = 'target'\n",
    "    oof_pred = np.zeros(len(av_data))\n",
    "    important_features = pd.DataFrame()\n",
    "    fold_auc = []\n",
    "    \n",
    "    for fold, (tr_ind, val_ind) in enumerate(kf.split(av_data, groups = av_data['installation_id'])):\n",
    "        print('Fold {}'.format(fold + 1))\n",
    "        x_train, x_val = av_data[usefull_features].iloc[tr_ind], av_data[usefull_features].iloc[val_ind]\n",
    "        y_train, y_val = av_data[target].iloc[tr_ind], av_data[target].iloc[val_ind]\n",
    "        train_set = lgb.Dataset(x_train, y_train)\n",
    "        val_set = lgb.Dataset(x_val, y_val)\n",
    "        \n",
    "        model = lgb.train(params, train_set, num_boost_round = 100000, early_stopping_rounds = 20, \n",
    "                         valid_sets = [train_set, val_set], verbose_eval = 100)\n",
    "        \n",
    "        fold_importance = pd.DataFrame()\n",
    "        fold_importance['features'] = usefull_features\n",
    "        fold_importance['importance'] = model.feature_importance()\n",
    "        important_features = pd.concat([important_features, fold_importance], axis = 0)\n",
    "        \n",
    "        oof_pred[val_ind] = model.predict(x_val)\n",
    "        fold_auc.append(roc_auc_score(y_train, model.predict(x_train)))\n",
    "        \n",
    "    print('Our mean train roc auc score is :', np.mean(fold_auc))\n",
    "    print('Our oof roc auc score is :', roc_auc_score(av_data[target], oof_pred))\n",
    "    return important_features\n",
    "\n",
    "#features = [i for i in new_train.columns if i != \"installation_id\" and i != \"accuracy_group\"]\n",
    "#important_features = run_av(new_train, new_test, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize = (12,5))\n",
    "#important_features = important_features.groupby('features')['importance'].mean().reset_index().sort_values('importance')\n",
    "#sns.barplot(important_features['importance'][-30:], important_features['features'][-30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_av_check(reduce_train, reduce_test, usefull_features):\n",
    "    \n",
    "    tr_data = reduce_train.copy()\n",
    "    tst_data = reduce_test.copy()\n",
    "    tr_data['target'] = 0 \n",
    "    tst_data['target'] = 1\n",
    "    av_data = pd.concat([tr_data[[col for col in tr_data.columns if col not in ['accuracy_group']]], tst_data[[col for col in tst_data.columns if col not in ['accuracy_group']]]], axis = 0)\n",
    "    \n",
    "     # undersample majority class\n",
    "    positive = av_data[av_data['target']==1]\n",
    "    negative = av_data[av_data['target']==0]\n",
    "    negative = negative.sample(int(negative.shape[0] * 0.5), random_state = 42)\n",
    "    av_data = pd.concat([negative, positive], axis = 0)\n",
    "    \n",
    "    # reset index and shuffle\n",
    "    av_data.reset_index(drop = True)\n",
    "    from sklearn.utils import shuffle\n",
    "    av_data = shuffle(av_data)\n",
    "    \n",
    "    params = {\n",
    "            'learning_rate': 0.05, \n",
    "            'n_jobs': -1,\n",
    "            'seed': 50,\n",
    "            'objective':'binary',\n",
    "            'boosting_type':'gbdt',\n",
    "            'is_unbalance': True,\n",
    "            'metric': 'auc'\n",
    "        }\n",
    "    \n",
    "    # define a KFold strategy\n",
    "    kf = GroupKFold(n_splits = 5)\n",
    "    target = 'target'\n",
    "    \n",
    "    oof_pred = np.zeros(len(av_data))\n",
    "    for fold, (tr_ind, val_ind) in enumerate(kf.split(av_data, groups = av_data['installation_id'])):\n",
    "        \n",
    "        print('Fold {}'.format(fold + 1))\n",
    "        x_train, x_val = av_data[usefull_features].iloc[tr_ind], av_data[usefull_features].iloc[val_ind]\n",
    "        y_train, y_val = av_data[target].iloc[tr_ind], av_data[target].iloc[val_ind]\n",
    "        train_set = lgb.Dataset(x_train, y_train)\n",
    "        val_set = lgb.Dataset(x_val, y_val)\n",
    "        \n",
    "        model = lgb.train(params, train_set, num_boost_round = 100000, early_stopping_rounds = 20, \n",
    "                         valid_sets = [train_set, val_set], verbose_eval = 100)\n",
    "    \n",
    "        \n",
    "        oof_pred[val_ind] = model.predict(x_val)\n",
    "    \n",
    "    score = roc_auc_score(av_data[target], oof_pred)\n",
    "    \n",
    "    iter_features = usefull_features[::-1].copy()\n",
    "    drop_features = []\n",
    "    for i in iter_features:\n",
    "        oof_pred = np.zeros(len(av_data))\n",
    "        check_features = [col for col in iter_features if col not in drop_features + [i]]\n",
    "        for fold, (tr_ind, val_ind) in enumerate(kf.split(av_data, groups = av_data['installation_id'])):\n",
    "            x_train, x_val = av_data[check_features].iloc[tr_ind], av_data[check_features].iloc[val_ind]\n",
    "            y_train, y_val = av_data[target].iloc[tr_ind], av_data[target].iloc[val_ind]\n",
    "            train_set = lgb.Dataset(x_train, y_train)\n",
    "            val_set = lgb.Dataset(x_val, y_val)\n",
    "            \n",
    "            model = lgb.train(params, train_set, num_boost_round = 100000, early_stopping_rounds = 20, \n",
    "                             valid_sets = [train_set, val_set], verbose_eval = False)\n",
    "\n",
    "\n",
    "            oof_pred[val_ind] = model.predict(x_val)\n",
    "            \n",
    "        rauc = roc_auc_score(av_data[target], oof_pred)\n",
    "            \n",
    "        if rauc < score:\n",
    "            print('Dropping feature: ', i)\n",
    "            score = rauc\n",
    "            drop_features.append(i)\n",
    "        else:\n",
    "            print('Feature {} is useful'.format(i))\n",
    "        print('Out best roc auc score is :', score)\n",
    "            \n",
    "        print('-'*50)\n",
    "            \n",
    "    usefull_features = [col for col in usefull_features if col not in drop_features]\n",
    "    return usefull_features\n",
    "\n",
    "#usefull_features = run_av_check(new_train, new_test, list(important_features['features']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set(important_features['features']) - set(usefull_features)\n",
    "{'3010', 'Air Show_2000', 'Air Show_3110', 'Bird Measurer (Assessment)_2010', 'Bottle Filler (Activity)_3010',\n",
    " 'Bubble Bath_3120', 'Bubble Bath_4010', 'Bug Measurer (Activity)_2000', 'Bug Measurer (Activity)_4035',\n",
    " 'Chest Sorter (Assessment)_3021', 'Dino Drink_4020', 'Egg Dropper (Activity)_4070','Happy Camel_4095',\n",
    " 'Mushroom Sorter (Assessment)_3010', 'Mushroom Sorter (Assessment)_4035', 'Pan Balance_2030',\n",
    " 'Pan Balance_3010', 'Watering Hole (Activity)_3110', 'Watering Hole (Activity)_5000'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17690, 507)\n"
     ]
    }
   ],
   "source": [
    "X_train = new_train.drop(['accuracy_group'],axis=1) \n",
    "lbl = preprocessing.LabelEncoder()\n",
    "lbl.fit(list(X_train[\"installation_id\"]))\n",
    "X_train[\"installation_id\"] = lbl.transform(list(X_train[\"installation_id\"]))\n",
    "remove_features = [i for i in X_train.columns if \"_4235\" in i or i == \"world_\"+str(activities_world[\"NONE\"]) or \"acc_\" in i]\n",
    "for i in X_train.columns:\n",
    "    if X_train[i].std() == 0 and i not in remove_features:\n",
    "        remove_features.append(i)\n",
    "X_train = X_train.drop(remove_features, axis=1)\n",
    "X_train = X_train[sorted(X_train.columns.tolist())]\n",
    "y_train = new_train.accuracy_group\n",
    "print(X_train.shape)\n",
    "\n",
    "X_test = new_test.drop([\"installation_id\",\"accuracy_group\"], axis=1)\n",
    "X_test = X_test.drop(remove_features, axis=1)\n",
    "X_test = X_test[sorted(X_test.columns.tolist())]\n",
    "\n",
    "X_val = new_val.drop([\"installation_id\", \"accuracy_group\"], axis=1)\n",
    "X_val = X_val.drop(remove_features, axis=1)\n",
    "X_val = X_val[sorted(X_val.columns.tolist())]\n",
    "y_val = new_val[\"accuracy_group\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modelling and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[500]\ttraining's rmse: 0.964456\tvalid_1's rmse: 0.991724\n",
      "Early stopping, best iteration is:\n",
      "[800]\ttraining's rmse: 0.939123\tvalid_1's rmse: 0.984491\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[500]\ttraining's rmse: 0.962577\tvalid_1's rmse: 1.00329\n",
      "Early stopping, best iteration is:\n",
      "[892]\ttraining's rmse: 0.931545\tvalid_1's rmse: 0.996268\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[500]\ttraining's rmse: 0.96303\tvalid_1's rmse: 0.988146\n",
      "Early stopping, best iteration is:\n",
      "[634]\ttraining's rmse: 0.950671\tvalid_1's rmse: 0.985633\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[500]\ttraining's rmse: 0.956\tvalid_1's rmse: 1.0131\n",
      "Early stopping, best iteration is:\n",
      "[786]\ttraining's rmse: 0.932025\tvalid_1's rmse: 1.00851\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[500]\ttraining's rmse: 0.953338\tvalid_1's rmse: 1.01949\n",
      "Early stopping, best iteration is:\n",
      "[859]\ttraining's rmse: 0.922946\tvalid_1's rmse: 1.01414\n",
      "0.58846502 [1.15407824 1.69994628 2.12661402]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3    0.500\n",
       "2    0.230\n",
       "0    0.163\n",
       "1    0.107\n",
       "Name: accuracy_group, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oof approach\n",
    "def run_model(X_train, y_train, X_test):\n",
    "    n_folds=5\n",
    "    skf=GroupKFold(n_splits = n_folds)\n",
    "    models = []\n",
    "    train_qwk_scores = []\n",
    "    test_qwk_scores = []\n",
    "    scores = []\n",
    "\n",
    "    lgbm_params = {\n",
    "    'objective': 'regression','metric': 'rmse',\"tree_learner\": \"serial\", \n",
    "    \"max_depth\" : 5, \"boosting\": 'gbdt', \"num_leaves\" : 13, \"learning_rate\" : 0.01,\n",
    "}\n",
    "\n",
    "    valid = pd.DataFrame(np.zeros([X_train.shape[0]]))\n",
    "    features_list = [i for i in X_train.columns if i != \"installation_id\"]\n",
    "    feature_importance_df = pd.DataFrame(features_list, columns=[\"Feature\"])\n",
    "    for i , (train_index, test_index) in enumerate(skf.split(X_train, y_train, X_train[\"installation_id\"])):\n",
    "        print(\"Fold \"+str(i+1))\n",
    "        optR = OptimizedRounder()\n",
    "        X_train2 = X_train.iloc[train_index,:]\n",
    "        y_train2 = y_train.iloc[train_index]\n",
    "        X_train2 = X_train2.drop(['installation_id'],axis=1)\n",
    "    \n",
    "        X_test2 = X_train.iloc[test_index,:]\n",
    "        y_test2 = y_train.iloc[test_index]\n",
    "        X_test2 = X_test2.drop(['installation_id'],axis=1)\n",
    "    \n",
    "        lgb_train = lgb.Dataset(X_train2, y_train2)\n",
    "        lgb_eval = lgb.Dataset(X_test2, y_test2, reference=lgb_train)\n",
    "    \n",
    "        clf = lgb.train(\n",
    "        lgbm_params, lgb_train,valid_sets=[lgb_train, lgb_eval],\n",
    "        num_boost_round=10000,early_stopping_rounds=10,verbose_eval = 500,\n",
    "    )\n",
    "        \n",
    "        train_predict = clf.predict(X_train2, num_iteration = clf.best_iteration)\n",
    "        test_predict = clf.predict(X_test2, num_iteration = clf.best_iteration)\n",
    "        valid.iloc[test_index] = clf.predict(X_test2, num_iteration = clf.best_iteration).reshape(X_test2.shape[0], 1)\n",
    "        \n",
    "        models.append(clf)\n",
    "        feature_importance_df[\"Fold_\"+str(i+1)] = clf.feature_importance()\n",
    "\n",
    "    optR = OptimizedRounder()    \n",
    "    optR.fit(np.array(valid).reshape(-1, ), y_train)\n",
    "    coefficients = optR.coefficients()\n",
    "    opt_preds = optR.predict(np.array(valid).reshape(-1, ), coefficients)\n",
    "    qwk_score = qwk(y_train, opt_preds)\n",
    "    print(qwk_score, coefficients)\n",
    "    \n",
    "    pred_value = np.zeros([X_test.shape[0]])\n",
    "    for model in models:\n",
    "        pred_value += model.predict(X_test, num_iteration = model.best_iteration) / len(models)\n",
    "        \n",
    "    feature_importance_df[\"Average\"] = np.mean(feature_importance_df.iloc[:,1:n_folds+1], axis=1)\n",
    "    feature_importance_df[\"Std\"] = np.std(feature_importance_df.iloc[:,1:n_folds+1], axis=1)\n",
    "    feature_importance_df[\"Cv\"] = feature_importance_df[\"Std\"] / feature_importance_df[\"Average\"]\n",
    "    \n",
    "    return pred_value, coefficients, feature_importance_df\n",
    "\n",
    "pred_value = np.zeros([X_test.shape[0]])\n",
    "pred, coef, f_df = run_model(X_train, y_train, X_test)\n",
    "pred_value += pred \n",
    "\n",
    "test_pred_class = pd.cut(pred_value, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "sample_submission[\"accuracy_group\"] = test_pred_class.astype(int)\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission[\"accuracy_group\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average of regression output by CV truncation \n",
    "def run_model(X_train, y_train, X_test):\n",
    "    n_folds=5\n",
    "    skf=GroupKFold(n_splits = n_folds)\n",
    "    coefficients = []\n",
    "    models = []\n",
    "    train_qwk_scores = []\n",
    "    test_qwk_scores = []\n",
    "    scores = []\n",
    "\n",
    "    lgbm_params = {\n",
    "    'objective': 'regression','metric': 'rmse',\"tree_learner\": \"serial\", \n",
    "    \"max_depth\" : 5, \"boosting\": 'gbdt', \"num_leaves\" : 13, \"learning_rate\" : 0.01,\n",
    "}\n",
    "\n",
    "    features_list = [i for i in X_train.columns if i != \"installation_id\"]\n",
    "    feature_importance_df = pd.DataFrame(features_list, columns=[\"Feature\"])\n",
    "    for i , (train_index, test_index) in enumerate(skf.split(X_train, y_train, X_train[\"installation_id\"])):\n",
    "        print(\"Fold \"+str(i+1))\n",
    "        optR = OptimizedRounder()\n",
    "        X_train2 = X_train.iloc[train_index,:]\n",
    "        y_train2 = y_train.iloc[train_index]\n",
    "        X_train2 = X_train2.drop(['installation_id'],axis=1)\n",
    "    \n",
    "        X_test2 = X_train.iloc[test_index,:]\n",
    "        y_test2 = y_train.iloc[test_index]\n",
    "        \n",
    "        \n",
    "        test2 = pd.concat([X_test2, y_test2], axis=1)\n",
    "        #second_last_index = list(set(test2.groupby('installation_id').tail(2).index)- set(test2.groupby('installation_id').tail(1).index))\n",
    "        #third_last_index = list(set(test2.groupby('installation_id').tail(3).index)- set(test2.groupby('installation_id').tail(2).index))\n",
    "        #test_last2 = test2[test2.index.isin(second_last_index)]\n",
    "        #test_last3 = test2[test2.index.isin(third_last_index)]\n",
    "        test2 = test2.groupby('installation_id').tail(1)\n",
    "        X_test2 = test2.drop([\"accuracy_group\", \"installation_id\"], axis=1)\n",
    "        y_test2 = test2[\"accuracy_group\"]\n",
    "    \n",
    "        lgb_train = lgb.Dataset(X_train2, y_train2)\n",
    "        lgb_eval = lgb.Dataset(X_test2, y_test2, reference=lgb_train)\n",
    "    \n",
    "        clf = lgb.train(\n",
    "        lgbm_params, lgb_train,valid_sets=[lgb_train, lgb_eval],\n",
    "        num_boost_round=10000,early_stopping_rounds=10,verbose_eval = 500,\n",
    "    )\n",
    "        \n",
    "        train_predict = clf.predict(X_train2, num_iteration = clf.best_iteration)\n",
    "        test_predict = clf.predict(X_test2, num_iteration = clf.best_iteration)\n",
    "                \n",
    "        optR.fit(train_predict.reshape(-1,), y_train2)\n",
    "        tmp_coefficients = optR.coefficients()\n",
    "        opt_train_preds = optR.predict(train_predict.reshape(-1, ), tmp_coefficients)\n",
    "        train_qwk_score = qwk(y_train2, opt_train_preds)\n",
    "        opt_test_preds = optR.predict(test_predict.reshape(-1, ), tmp_coefficients)\n",
    "        test_qwk_score = qwk(y_test2, opt_test_preds)\n",
    "        train_qwk_scores.append(train_qwk_score)\n",
    "        test_qwk_scores.append(test_qwk_score)\n",
    "        coefficients.append(tmp_coefficients)\n",
    "        \n",
    "        models.append(clf)\n",
    "        feature_importance_df[\"Fold_\"+str(i+1)] = clf.feature_importance()\n",
    "    \n",
    "    print(\"-----------------------------\")\n",
    "    print('train qwk list: ', train_qwk_scores, np.mean(train_qwk_scores))\n",
    "    print('valid qwk list: ', test_qwk_scores, np.mean(test_qwk_scores))\n",
    "    \n",
    "    pred_value = np.zeros([X_test.shape[0]])\n",
    "    avg_coefficients = np.mean(coefficients, axis=0)\n",
    "    for model in models:\n",
    "        pred_value += model.predict(X_test, num_iteration = model.best_iteration) / len(models)\n",
    "        \n",
    "    feature_importance_df[\"Average\"] = np.mean(feature_importance_df.iloc[:,1:n_folds+1], axis=1)\n",
    "    feature_importance_df[\"Std\"] = np.std(feature_importance_df.iloc[:,1:n_folds+1], axis=1)\n",
    "    feature_importance_df[\"Cv\"] = feature_importance_df[\"Std\"] / feature_importance_df[\"Average\"]\n",
    "    \n",
    "    return pred_value, np.mean(train_qwk_scores), np.mean(test_qwk_scores), avg_coefficients, feature_importance_df\n",
    "\n",
    "# regression\n",
    "#pred_value = np.zeros([X_test.shape[0]])\n",
    "#tr_score = []; va_score = []; coefficients = []\n",
    "#num = 1\n",
    "#for i in range(num):\n",
    "#    pred, train_score, valid_score, coef, f_df = run_model(X_train, y_train, X_test)\n",
    "#    pred_value += pred / num\n",
    "#    tr_score.append(train_score)\n",
    "#    va_score.append(valid_score)\n",
    "#    coefficients.append(coef)\n",
    "#print(np.mean(tr_score), np.mean(va_score))\n",
    "\n",
    "#test_coefficients = np.mean(coefficients, axis=0)\n",
    "#test_pred_class = pd.cut(pred_value, [-np.inf] + list(np.sort(test_coefficients)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "#sample_submission[\"accuracy_group\"] = test_pred_class.astype(int)\n",
    "#sample_submission.to_csv('submission.csv', index=False)\n",
    "#sample_submission[\"accuracy_group\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1c86306cb0aa40c1830a4ab9b7dc3f91": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "320398d90f014b33a2d8f8820ad856e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Installation_id: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ffe9002888ad439d8963ec8b0923ad95",
       "max": 1000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1c86306cb0aa40c1830a4ab9b7dc3f91",
       "value": 1000
      }
     },
     "4e6b393dd8d84415b4ee44d22f046e88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Installation_id: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_540e9ed36f6b4bba87971eddb96ad9fb",
       "max": 3614,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c8bb3db9d6f24d6b8e4a196f80b492c2",
       "value": 3614
      }
     },
     "540e9ed36f6b4bba87971eddb96ad9fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "66dcfce27ab543dbbdbf2037f2c92180": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6724fa86ea6545a5b9e9b0cc662f084f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7173e302393d45e4822211e83aa2b063": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8d75735dbda4459e96ad11509f0c066c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4e6b393dd8d84415b4ee44d22f046e88",
        "IPY_MODEL_bb8ded848cef4e9a9c8070248b970605"
       ],
       "layout": "IPY_MODEL_a002be37ef584972a3b9f18dc54d9c41"
      }
     },
     "a002be37ef584972a3b9f18dc54d9c41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a3546736ef8a4ed5b6ad8c97aebf09c9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b2db09cdab42407abdf7b554fe524dc3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6724fa86ea6545a5b9e9b0cc662f084f",
       "placeholder": "​",
       "style": "IPY_MODEL_d1b85cdb5a634ecf8498ac7a9b63cdf5",
       "value": " 1000/1000 [02:51&lt;00:00,  5.83it/s]"
      }
     },
     "bb8ded848cef4e9a9c8070248b970605": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7173e302393d45e4822211e83aa2b063",
       "placeholder": "​",
       "style": "IPY_MODEL_66dcfce27ab543dbbdbf2037f2c92180",
       "value": " 3614/3614 [08:38&lt;00:00,  6.97it/s]"
      }
     },
     "c8bb3db9d6f24d6b8e4a196f80b492c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "d1b85cdb5a634ecf8498ac7a9b63cdf5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d84d42ad19514640b65a5b84ad97262f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_320398d90f014b33a2d8f8820ad856e8",
        "IPY_MODEL_b2db09cdab42407abdf7b554fe524dc3"
       ],
       "layout": "IPY_MODEL_a3546736ef8a4ed5b6ad8c97aebf09c9"
      }
     },
     "ffe9002888ad439d8963ec8b0923ad95": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
