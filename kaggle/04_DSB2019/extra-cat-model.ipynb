{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- modify mistake\n",
    "- implement permutation importance FE, null importance FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import datetime\n",
    "from time import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, log_loss, roc_auc_score, precision_score, recall_score, accuracy_score, f1_score, confusion_matrix, cohen_kappa_score\n",
    "import lightgbm as lgb\n",
    "from functools import partial\n",
    "import json\n",
    "import copy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "from hyperopt import hp, tpe, Trials, fmin, space_eval\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.max_rows\",1000)\n",
    "np.set_printoptions(precision=8)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qwk(a1, a2):\n",
    "    max_rat = 3\n",
    "    a1 = np.asarray(a1, dtype=int)\n",
    "    a2 = np.asarray(a2, dtype=int)\n",
    "    hist1 = np.zeros((max_rat + 1, ))\n",
    "    hist2 = np.zeros((max_rat + 1, ))\n",
    "    o = 0\n",
    "    for k in range(a1.shape[0]):\n",
    "        i, j = a1[k], a2[k]\n",
    "        hist1[i] += 1\n",
    "        hist2[j] += 1\n",
    "        o +=  (i - j) * (i - j)\n",
    "    e = 0\n",
    "    for i in range(max_rat + 1):\n",
    "        for j in range(max_rat + 1):\n",
    "            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n",
    "    e = e / a1.shape[0]\n",
    "    return np.round(1 - o / e, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "        return -qwk(y, X_p)\n",
    "        #return -mod_qwk(y, X_p, weights=weights)\n",
    "    \n",
    "    def fit(self, X, y, random_flg = False):\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        if random_flg:\n",
    "            initial_coef = [np.random.uniform(0.4,0.5), np.random.uniform(0.5,0.6), np.random.uniform(0.6,0.7)]\n",
    "        else:\n",
    "            initial_coef = [0.5, 1.5, 2.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead') #Powell\n",
    "        \n",
    "    def predict(self, X, coef):\n",
    "        return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_qwk_lgb_regr(y_pred, train_t):\n",
    "    dist = Counter(train_t['accuracy_group'])\n",
    "    for k in dist:\n",
    "        dist[k] /= len(train_t)\n",
    "    \n",
    "    acum = 0\n",
    "    bound = {}\n",
    "    for i in range(3):\n",
    "        acum += dist[i]\n",
    "        bound[i] = np.percentile(y_pred, acum * 100)\n",
    "\n",
    "    def classify(x):\n",
    "        if x <= bound[0]:\n",
    "            return 0\n",
    "        elif x <= bound[1]:\n",
    "            return 1\n",
    "        elif x <= bound[2]:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "\n",
    "    y_pred = np.array(list(map(classify, y_pred)))\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 22s, sys: 11.4 s, total: 1min 33s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv('../input/data-science-bowl-2019/train.csv')\n",
    "train_labels = pd.read_csv('../input/data-science-bowl-2019/train_labels.csv')\n",
    "test = pd.read_csv('../input/data-science-bowl-2019/test.csv')\n",
    "#specs = pd.read_csv('../input/data-science-bowl-2019/specs.csv')\n",
    "sample_submission = pd.read_csv('../input/data-science-bowl-2019/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess and Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 59s, sys: 12.4 s, total: 2min 11s\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def encode_title(train, test):\n",
    "    train['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), train['title'], train['event_code']))\n",
    "    test['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), test['title'], test['event_code']))\n",
    "    list_of_title_eventcode = sorted(list(set(train['title_event_code'].unique()).union(set(test['title_event_code'].unique()))))\n",
    "    \n",
    "    train['type_world'] = list(map(lambda x, y: str(x) + '_' + str(y), train['type'], train['world']))\n",
    "    test['type_world'] = list(map(lambda x, y: str(x) + '_' + str(y), test['type'], test['world']))\n",
    "    list_of_type_world = sorted(list(set(train['type_world'].unique()).union(set(test['type_world'].unique()))))\n",
    "    \n",
    "    list_of_user_activities = sorted(list(set(train['title'].unique()).union(set(test['title'].unique()))))\n",
    "    list_of_event_code = sorted(list(set(train['event_code'].unique()).union(set(test['event_code'].unique()))))\n",
    "    list_of_worlds = sorted(list(set(train['world'].unique()).union(set(test['world'].unique()))))\n",
    "    activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n",
    "    activities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\n",
    "    activities_world = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n",
    "    assess_titles = sorted(list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(set(test[test['type'] == 'Assessment']['title'].value_counts().index))))\n",
    "\n",
    "    train['title'] = train['title'].map(activities_map)\n",
    "    test['title'] = test['title'].map(activities_map)\n",
    "    train['world'] = train['world'].map(activities_world)\n",
    "    test['world'] = test['world'].map(activities_world)\n",
    "\n",
    "    win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\n",
    "    win_code[activities_map['Bird Measurer (Assessment)']] = 4110\n",
    "    \n",
    "    train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "    test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "    \n",
    "    train[\"misses\"] = train[\"event_data\"].apply(lambda x: json.loads(x)[\"misses\"] if \"\\\"misses\\\"\" in x else np.nan)\n",
    "    test[\"misses\"] = test[\"event_data\"].apply(lambda x: json.loads(x)[\"misses\"] if \"\\\"misses\\\"\" in x else np.nan)\n",
    "        \n",
    "    train[\"true\"] = train[\"event_data\"].apply(lambda x: 1 if \"true\" in x and \"correct\" in x else 0)\n",
    "    test[\"true\"] = test[\"event_data\"].apply(lambda x: 1 if \"true\" in x and \"correct\" in x else 0)\n",
    "\n",
    "    train[\"false\"] = train[\"event_data\"].apply(lambda x: 1 if \"false\" in x and \"correct\" in x else 0)\n",
    "    test[\"false\"] = test[\"event_data\"].apply(lambda x: 1 if \"false\" in x and \"correct\" in x else 0)\n",
    "    \n",
    "    train[\"game_complete\"] = train[\"event_data\"].apply(lambda x: 1 if \"game_completed\" in x else 0)\n",
    "    test[\"game_complete\"] = test[\"event_data\"].apply(lambda x: 1 if \"game_completed\" in x else 0)\n",
    "    \n",
    "    #train[\"level\"] = train[\"event_data\"].apply(lambda x: json.loads(x)[\"level\"] if \"\\\"level\\\"\" in x else np.nan)\n",
    "    #test[\"level\"] = test[\"event_data\"].apply(lambda x: json.loads(x)[\"level\"] if \"\\\"level\\\"\" in x else np.nan)\n",
    "    \n",
    "    #train[\"round\"] = train[\"event_data\"].apply(lambda x: json.loads(x)[\"round\"] if \"\\\"round\\\"\" in x else np.nan)\n",
    "    #test[\"round\"] = test[\"event_data\"].apply(lambda x: json.loads(x)[\"round\"] if \"\\\"round\\\"\" in x else np.nan)\n",
    "               \n",
    "    return train, test, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, activities_world, list_of_title_eventcode, list_of_type_world\n",
    "\n",
    "train, test, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, activities_world, list_of_title_eventcode, list_of_type_world = encode_title(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def get_data(user_sample, test_set=False):\n",
    "    last_activity = 0\n",
    "    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "    title_eventcode_count = {str(ele): 0 for ele in list_of_title_eventcode}\n",
    "    user_world_count = {\"world_\"+str(wor) : 0 for wor in activities_world.values()}\n",
    "    event_code_count = {str(ev): 0 for ev in list_of_event_code}\n",
    "    title_count = {actv: 0 for actv in list_of_user_activities}\n",
    "    type_world_count = {str(ev): 0 for ev in list_of_type_world}\n",
    "    last_accuracy_title = {'acc_' + title: -1 for title in assess_titles}\n",
    "    last_game_time_title = {'lgt_' + title: 0 for title in assess_titles}\n",
    "    ac_game_time_title = {'agt_' + title: 0 for title in assess_titles}\n",
    "    ac_true_attempts_title = {'ata_' + title: 0 for title in assess_titles}\n",
    "    ac_false_attempts_title = {'afa_' + title: 0 for title in assess_titles}\n",
    "    \n",
    "    all_assessments = []\n",
    "    accuracy_groups = {\"0\":0, \"1\":0, \"2\":0, \"3\":0}\n",
    "    accumulated_accuracy_group = 0\n",
    "    accumulated_correct_attempts = 0 \n",
    "    accumulated_uncorrect_attempts = 0 \n",
    "    accumulated_actions = 0\n",
    "    counter = 0\n",
    "    time_first_activity = user_sample.iloc[0]['timestamp']\n",
    "    miss = 0\n",
    "    crys_game_true = 0; crys_game_false = 0\n",
    "    tree_game_true = 0; tree_game_false = 0\n",
    "    magma_game_true = 0; magma_game_false = 0\n",
    "    crys_game_acc = []; tree_game_acc = []; magma_game_acc = []\n",
    "    durations = []\n",
    "    prev_assess_title = -999\n",
    "    assess_count = 1\n",
    "    last_accuracy = -999\n",
    "    prev_assess_start = -999; prev_assess_end = -999\n",
    "    real_prev_assess_start = -999; real_prev_assess_end = -999\n",
    "    real_assess_start = -999; real_assess_end = -999\n",
    "    complete_games = 0\n",
    "    no_result_count = 0\n",
    "    crys_game_level = np.array([]); tree_game_level = np.array([]); magma_game_level = np.array([])\n",
    "    crys_game_round = np.array([]); tree_game_round = np.array([]); magma_game_round = np.array([])\n",
    "    \n",
    "    for i, session in user_sample.groupby('game_session', sort=False):      \n",
    "        session_type = session['type'].iloc[0]\n",
    "        session_title = session['title'].iloc[0]\n",
    "        session_title_text = activities_labels[session_title]\n",
    "        session_world = session[\"world\"].iloc[0]\n",
    "        \n",
    "        if session_type != 'Assessment':\n",
    "            if session_type == \"Game\":\n",
    "                true = session['true'].sum()\n",
    "                false = session['false'].sum() \n",
    "                if session_world == activities_world[\"CRYSTALCAVES\"]:\n",
    "                    crys_game_true += true\n",
    "                    crys_game_false += false\n",
    "                    crys_game_acc.append(true / (true + false) if (true + false) != 0 else 0)\n",
    "                    #crys_game_level = np.concatenate([crys_game_level, session[\"level\"]], axis=0)\n",
    "                    #crys_game_round = np.concatenate([crys_game_round, session[\"round\"]], axis=0)\n",
    "                elif session_world == activities_world[\"TREETOPCITY\"]:\n",
    "                    tree_game_true += true\n",
    "                    tree_game_false += false\n",
    "                    tree_game_acc.append(true / (true + false) if (true + false) != 0 else 0)\n",
    "                    #tree_game_level = np.concatenate([tree_game_level, session[\"level\"]], axis=0)\n",
    "                    #tree_game_round = np.concatenate([tree_game_round, session[\"round\"]], axis=0)\n",
    "                elif session_world == activities_world[\"MAGMAPEAK\"]:\n",
    "                    magma_game_true += true\n",
    "                    magma_game_false += false\n",
    "                    magma_game_acc.append(true / (true + false) if (true + false) != 0 else 0)\n",
    "                    #magma_game_level = np.concatenate([magma_game_level, session[\"level\"]], axis=0)\n",
    "                    #magma_game_round = np.concatenate([magma_game_round, session[\"round\"]], axis=0)\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "        if (session_type == 'Assessment') & (test_set or len(session)>1): \n",
    "            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n",
    "            true_attempts = all_attempts['event_data'].str.contains('true').sum() # true in target assess\n",
    "            false_attempts = all_attempts['event_data'].str.contains('false').sum() # false in target assessment\n",
    "            assess_start = session.iloc[0,2]\n",
    "            assess_end = session.iloc[-1,2]\n",
    "            \n",
    "            # from start of installation_id to the start of target assessment ------------------------\n",
    "            features = user_activities_count.copy() # appearance of each type without duplicates\n",
    "            features.update(title_eventcode_count.copy()) # apperance of combi of title and event_code\n",
    "            features.update(user_world_count.copy()) # appearance of world with duplicates\n",
    "            features.update(event_code_count.copy())\n",
    "            features.update(title_count.copy())\n",
    "            features.update(type_world_count.copy())\n",
    "            features.update(last_accuracy_title.copy())\n",
    "            features.update(last_game_time_title.copy())\n",
    "            features.update(ac_game_time_title.copy())\n",
    "            features.update(ac_true_attempts_title.copy())\n",
    "            features.update(ac_false_attempts_title.copy())\n",
    "            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n",
    "            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n",
    "            accumulated_correct_attempts += true_attempts \n",
    "            accumulated_uncorrect_attempts += false_attempts\n",
    "            ac_true_attempts_title['ata_' + session_title_text] += true_attempts\n",
    "            ac_false_attempts_title['afa_' + session_title_text] += false_attempts\n",
    "            last_game_time_title['lgt_' + session_title_text] = session['game_time'].iloc[-1]\n",
    "            ac_game_time_title['agt_' + session_title_text] += session['game_time'].iloc[-1]\n",
    "            features[\"misses\"] = miss\n",
    "            features['accumulated_actions'] = accumulated_actions\n",
    "            features[\"no_complete_game\"] = complete_games\n",
    "            features[\"no_result_count\"] = no_result_count \n",
    "            \n",
    "            if true_attempts + false_attempts == 0:\n",
    "                no_result_count += 1\n",
    "            else:\n",
    "                real_assess_start = session.iloc[0,2]\n",
    "                real_assess_end = session.iloc[-1,2]\n",
    "\n",
    "            if session_world == activities_world[\"CRYSTALCAVES\"]:\n",
    "                features[\"game_true\"] = crys_game_true\n",
    "                features[\"game_false\"] = crys_game_false\n",
    "                features['game_accuracy'] = crys_game_true / (crys_game_true + crys_game_false) if (crys_game_true + crys_game_false) != 0 else 0\n",
    "                features[\"game_accuracy_std\"] = np.std(crys_game_acc) if len(crys_game_acc) >=1 else 0\n",
    "                features[\"last_game_acc\"] = crys_game_acc[-1] if len(crys_game_acc) >=1 else 0\n",
    "                #features[\"hightest_level\"] = np.nanmax(crys_game_level) if len(crys_game_level[~np.isnan(crys_game_level)]) >=1 else -1\n",
    "                #features[\"level_count\"] = len(crys_game_level[~np.isnan(crys_game_level)])\n",
    "                #features[\"round_count\"] = len(crys_game_round[~np.isnan(crys_game_round)])\n",
    "            elif session_world == activities_world[\"TREETOPCITY\"]:\n",
    "                features[\"game_true\"] = tree_game_true\n",
    "                features[\"game_false\"] = tree_game_false\n",
    "                features['game_accuracy'] = tree_game_true / (tree_game_true + tree_game_false) if (tree_game_true + tree_game_false) != 0 else 0\n",
    "                features[\"game_accuracy_std\"] = np.std(tree_game_acc) if len(tree_game_acc) >=1 else 0\n",
    "                features[\"last_game_acc\"] = tree_game_acc[-1] if len(tree_game_acc) >=1 else 0\n",
    "                #features[\"hightest_level\"] = np.nanmax(tree_game_level) if len(tree_game_level[~np.isnan(tree_game_level)]) >=1 else -1\n",
    "                #features[\"level_count\"] = len(tree_game_level[~np.isnan(tree_game_level)])\n",
    "                #features[\"round_count\"] = len(tree_game_round[~np.isnan(tree_game_round)])\n",
    "            elif session_world == activities_world[\"MAGMAPEAK\"]:\n",
    "                features[\"game_true\"] = magma_game_true\n",
    "                features[\"game_false\"] = magma_game_false\n",
    "                features['game_accuracy'] = magma_game_true / (magma_game_true + magma_game_false) if (magma_game_true + magma_game_false) != 0 else 0\n",
    "                features[\"game_accuracy_std\"] = np.std(magma_game_acc) if len(magma_game_acc) >=1 else 0\n",
    "                features[\"last_game_acc\"] = magma_game_acc[-1] if len(magma_game_acc) >=1 else 0\n",
    "                #features[\"hightest_level\"] = np.nanmax(magma_game_level) if len(magma_game_level[~np.isnan(magma_game_level)]) >=1 else -1\n",
    "                #features[\"level_count\"] = len(magma_game_level[~np.isnan(magma_game_level)])\n",
    "                #features[\"round_count\"] = len(magma_game_round[~np.isnan(magma_game_round)])\n",
    "            \n",
    "            features['installation_id'] = session['installation_id'].iloc[-1]\n",
    "            features['session_title'] = session_title\n",
    "            features[\"prev_assess_title\"] = prev_assess_title\n",
    "            prev_assess_title = session_title\n",
    "            features[\"first_assessment\"] = 1 if assess_count == 1 else 0\n",
    "            assess_count += 1\n",
    "            features[\"time_from_start\"] = (assess_start - time_first_activity).seconds\n",
    "\n",
    "            if prev_assess_end == -999:\n",
    "                features[\"time_bet_assess\"] = -999\n",
    "            else:\n",
    "                features[\"time_bet_assess\"] = (assess_start - prev_assess_end).seconds\n",
    "            prev_assess_start = assess_start\n",
    "            prev_assess_end = assess_end\n",
    "            if real_prev_assess_end == -999:\n",
    "                features[\"time_bet_real_assess\"] = -999\n",
    "            else:\n",
    "                features[\"time_bet_real_assess\"] = (real_assess_start - real_prev_assess_end).seconds\n",
    "            real_prev_assess_start = real_assess_start\n",
    "            real_prev_assess_end = real_assess_end\n",
    "            \n",
    "            if durations == []: #span of timestamp in target assessment\n",
    "                features['duration_mean'] = 0\n",
    "                features['duration_std'] = 0\n",
    "                features['duration_max'] = 0\n",
    "            else:\n",
    "                features['duration_mean'] = np.mean(durations)\n",
    "                features['duration_std'] = np.std(durations)\n",
    "                features['duration_max'] = np.max(durations)\n",
    "            durations.append((session.iloc[-1, 2] - session.iloc[0, 2]).seconds)\n",
    "            \n",
    "            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "            features['last_assess_acc'] = last_accuracy\n",
    "            last_accuracy_title['acc_' + session_title_text] = accuracy\n",
    "            last_accuracy = accuracy\n",
    "            if accuracy == 0:\n",
    "                features['accuracy_group'] = 0\n",
    "            elif accuracy == 1:\n",
    "                features['accuracy_group'] = 3\n",
    "            elif accuracy == 0.5:\n",
    "                features['accuracy_group'] = 2\n",
    "            else:\n",
    "                features['accuracy_group'] = 1\n",
    "            features.update(accuracy_groups)\n",
    "            accuracy_groups[str(features['accuracy_group'])] += 1\n",
    "            features['accumulated_accuracy_group'] = accumulated_accuracy_group/counter if counter > 0 else 0\n",
    "            accumulated_accuracy_group += features['accuracy_group']\n",
    "            \n",
    "            if test_set:\n",
    "                all_assessments.append(features)\n",
    "            elif true_attempts+false_attempts > 0:\n",
    "                all_assessments.append(features)\n",
    "                \n",
    "            counter += 1\n",
    "            \n",
    "        complete_games += np.sum(session[\"game_complete\"])\n",
    "        miss += np.sum(session[\"misses\"])\n",
    "        user_world_count[\"world_\"+str(session_world)] += session.shape[0]\n",
    "        \n",
    "        n_of_type_world = Counter(session['type_world']) \n",
    "        for key in n_of_type_world.keys():\n",
    "            type_world_count[str(key)] += n_of_type_world[key]\n",
    "            \n",
    "        n_of_title = Counter(session['title']) \n",
    "        for key in n_of_title.keys():\n",
    "            title_count[activities_labels[key]] += n_of_title[key]\n",
    "            \n",
    "        n_of_eventcode = Counter(session['event_code']) \n",
    "        for key in n_of_eventcode.keys():\n",
    "            event_code_count[str(key)] += n_of_eventcode[key]\n",
    "                        \n",
    "        n_of_title_eventcode = Counter(session['title_event_code']) \n",
    "        for key in n_of_title_eventcode.keys():\n",
    "            title_eventcode_count[str(key)] += n_of_title_eventcode[key]\n",
    "        \n",
    "        accumulated_actions += len(session)\n",
    "        if last_activity != session_type:\n",
    "            user_activities_count[session_type] += 1\n",
    "            last_activitiy = session_type\n",
    "    if test_set:\n",
    "        return all_assessments[-1], all_assessments[:-1] # test previous data to incorporate into training\n",
    "    return all_assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db111e1d7684415496d4e9bb20bb32ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Installation_id', max=17000, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e63f886b51049c1878a00a1f843ba69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Installation_id', max=1000, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_train_and_test(train, test):\n",
    "    compiled_train = []\n",
    "    compiled_test = []\n",
    "    compiled_val = []\n",
    "\n",
    "    for i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort=False)), total=train.installation_id.nunique(), desc='Installation_id', position=0):\n",
    "        compiled_train += get_data(user_sample)\n",
    "    del train\n",
    "    for ins_id, user_sample in tqdm(test.groupby('installation_id', sort=False), total=test.installation_id.nunique(), desc='Installation_id', position=0):\n",
    "        test_data, val_data = get_data(user_sample, test_set=True)\n",
    "        compiled_test.append(test_data)\n",
    "        compiled_val += val_data\n",
    "    del test\n",
    "    reduce_train = pd.DataFrame(compiled_train)\n",
    "    reduce_test = pd.DataFrame(compiled_test)\n",
    "    reduce_val = pd.DataFrame(compiled_val)\n",
    "\n",
    "    categoricals = ['session_title']\n",
    "    return reduce_train, reduce_test, reduce_val, categoricals\n",
    "new_train, new_test, new_val, categoricals = get_train_and_test(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = new_train[new_train.Game==0].copy()\n",
    "tmp = tmp[tmp.Activity == 0].copy()\n",
    "tmp = tmp[tmp.Clip == 0].copy()\n",
    "tmp = tmp[tmp.Assessment ==0].copy()\n",
    "remove_train_index = tmp.index\n",
    "new_train = new_train[~new_train.index.isin(remove_train_index)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17577, 563)\n",
      "(1000, 563)\n",
      "(2347, 563)\n"
     ]
    }
   ],
   "source": [
    "print(new_train.shape)\n",
    "print(new_test.shape)\n",
    "print(new_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Air Show_4080\n",
      "Bottle Filler (Activity)_2010\n",
      "Bubble Bath_4080\n",
      "Bubble Bath_4090\n",
      "Bug Measurer (Activity)_4080\n",
      "Cart Balancer (Assessment)_4080\n",
      "Chest Sorter (Assessment)_4080\n",
      "Crystals Rule_2010\n",
      "Dino Dive_4080\n",
      "Dino Drink_4080\n",
      "Egg Dropper (Activity)_4080\n",
      "Fireworks (Activity)_4080\n",
      "Happy Camel_4080\n",
      "Leaf Leader_4080\n",
      "Mushroom Sorter (Assessment)_4080\n",
      "Mushroom Sorter (Assessment)_4090\n",
      "Pan Balance_2010\n",
      "Pan Balance_4080\n",
      "Sandcastle Builder (Activity)_2010\n",
      "Scrub-A-Dub_4080\n",
      "Watering Hole (Activity)_2010\n",
      "acc_Cart Balancer (Assessment)\n"
     ]
    }
   ],
   "source": [
    "def exclude(reduce_train, reduce_test, features):\n",
    "    to_exclude = [] \n",
    "    ajusted_test = reduce_test.copy()\n",
    "    for feature in features:\n",
    "        if feature not in ['accuracy_group', 'installation_id', 'session_title', 'hightest_level']:\n",
    "            data = reduce_train[feature]\n",
    "            train_mean = data.mean()\n",
    "            data = ajusted_test[feature] \n",
    "            test_mean = data.mean()\n",
    "            try:\n",
    "                ajust_factor = train_mean / test_mean\n",
    "                if ajust_factor > 10 or ajust_factor < 0.1:# or error > 0.01:\n",
    "                    to_exclude.append(feature)\n",
    "                    print(feature)\n",
    "                else:\n",
    "                    ajusted_test[feature] *= ajust_factor\n",
    "            except:\n",
    "                to_exclude.append(feature)\n",
    "                print(feature)\n",
    "    return to_exclude, ajusted_test\n",
    "features = [i for i in new_train.columns if i not in [\"game_session\"]]\n",
    "to_exclude, ajusted_test = exclude(new_train, new_test, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score_mean</th>\n",
       "      <th>score_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>session_title</td>\n",
       "      <td>-0.046460</td>\n",
       "      <td>0.004225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>last_game_acc</td>\n",
       "      <td>-0.003497</td>\n",
       "      <td>0.007074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crystal Caves - Level 3_2000</td>\n",
       "      <td>-0.003429</td>\n",
       "      <td>0.005911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prev_assess_title</td>\n",
       "      <td>-0.002796</td>\n",
       "      <td>0.004488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accumulated_accuracy_group</td>\n",
       "      <td>-0.002579</td>\n",
       "      <td>0.008982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>time_bet_assess</td>\n",
       "      <td>-0.002306</td>\n",
       "      <td>0.005730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>game_true</td>\n",
       "      <td>-0.002035</td>\n",
       "      <td>0.006498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Assessment_MAGMAPEAK</td>\n",
       "      <td>-0.001857</td>\n",
       "      <td>0.007149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cart Balancer (Assessment)_4100</td>\n",
       "      <td>-0.001630</td>\n",
       "      <td>0.006027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>time_from_start</td>\n",
       "      <td>-0.001629</td>\n",
       "      <td>0.004627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feature  score_mean  score_std\n",
       "0                    session_title   -0.046460   0.004225\n",
       "1                    last_game_acc   -0.003497   0.007074\n",
       "2     Crystal Caves - Level 3_2000   -0.003429   0.005911\n",
       "3                prev_assess_title   -0.002796   0.004488\n",
       "4       accumulated_accuracy_group   -0.002579   0.008982\n",
       "5                  time_bet_assess   -0.002306   0.005730\n",
       "6                        game_true   -0.002035   0.006498\n",
       "7             Assessment_MAGMAPEAK   -0.001857   0.007149\n",
       "8  Cart Balancer (Assessment)_4100   -0.001630   0.006027\n",
       "9                  time_from_start   -0.001629   0.004627"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# permutation importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import defaultdict\n",
    "\n",
    "def permuted(df):\n",
    "    for column_name in df.columns:\n",
    "        permuted_df = df.copy()\n",
    "        permuted_df[column_name] = np.random.permutation(permuted_df[column_name])\n",
    "        yield column_name, permuted_df\n",
    "\n",
    "\n",
    "def pimp(clf, X, y, cv=None, eval_func=roc_auc_score):\n",
    "    base_scores = []\n",
    "    permuted_scores = defaultdict(list)\n",
    "\n",
    "    if cv is None:\n",
    "        #cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv = GroupKFold(n_splits=5)\n",
    "        \n",
    "    for train_index, test_index in cv.split(X, y, X[\"installation_id\"]):\n",
    "        # 学習用データと検証用データに分割する\n",
    "        X_train2, y_train2 = X.iloc[train_index], y.iloc[train_index]\n",
    "        X_test2, y_test2 = X.iloc[test_index], y.iloc[test_index]\n",
    "\n",
    "        # 学習用データでモデルを学習する\n",
    "        clf.fit(X_train2, y_train2)\n",
    "\n",
    "        # まずは何もシャッフルしていないときのスコアを計算する\n",
    "        y_pred_base = clf.predict(X_test2)\n",
    "        base_score = eval_func(y_test2, y_pred_base)\n",
    "        base_scores.append(base_score)\n",
    "\n",
    "        # 特定のカラムをシャッフルした状態で推論したときのスコアを計算する\n",
    "        permuted_X_test_gen = permuted(X_test2)\n",
    "        for column_name, permuted_X_test in permuted_X_test_gen:\n",
    "            y_pred_permuted = clf.predict(permuted_X_test)\n",
    "            permuted_score = eval_func(y_test2, y_pred_permuted)\n",
    "            permuted_scores[column_name].append(permuted_score)\n",
    "\n",
    "    # 基本のスコアとシャッフルしたときのスコアを返す\n",
    "    np_base_score = np.array(base_scores)\n",
    "    dict_permuted_score = {name: np.array(scores) for name, scores in permuted_scores.items()}\n",
    "    return np_base_score, dict_permuted_score\n",
    "\n",
    "def score_difference_statistics(base, permuted):\n",
    "    mean_base_score = base.mean()\n",
    "    for column_name, scores in permuted.items():\n",
    "        score_differences = scores - mean_base_score\n",
    "        yield column_name, score_differences.mean(), score_differences.std()\n",
    "\n",
    "# prepare for the data ---\n",
    "X_train = new_train.drop(['accuracy_group'],axis=1) \n",
    "y_train = new_train.accuracy_group.copy()\n",
    "y_train.loc[y_train <=1] = 0\n",
    "y_train.loc[y_train >=2] = 1\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "lbl.fit(list(X_train[\"installation_id\"]))\n",
    "X_train[\"installation_id\"] = lbl.transform(list(X_train[\"installation_id\"]))\n",
    "remove_features = [i for i in X_train.columns if i in to_exclude]\n",
    "for i in X_train.columns:\n",
    "    if X_train[i].std() == 0 and i not in remove_features:\n",
    "        remove_features.append(i)\n",
    "X_train = X_train.drop(remove_features, axis=1)\n",
    "X_train = X_train[sorted(X_train.columns.tolist())]    \n",
    "\n",
    "# execute permutation importance \n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "base_score, permuted_scores = pimp(clf, X_train, y_train)\n",
    "diff_stats = list(score_difference_statistics(base_score, permuted_scores))\n",
    "pimp_df = pd.DataFrame(diff_stats, columns = [\"feature\", \"score_mean\", \"score_std\"])\n",
    "pimp_df = pimp_df.sort_values(\"score_mean\", ascending=True).reset_index(drop=True)\n",
    "pimp_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with    1 of   80 (Spent   0.2 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with    2 of   80 (Spent   0.4 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with    3 of   80 (Spent   0.5 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with    4 of   80 (Spent   0.7 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with    5 of   80 (Spent   0.9 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with    6 of   80 (Spent   1.0 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with    7 of   80 (Spent   1.2 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with    8 of   80 (Spent   1.4 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with    9 of   80 (Spent   1.6 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   10 of   80 (Spent   1.7 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   11 of   80 (Spent   1.9 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   12 of   80 (Spent   2.1 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   13 of   80 (Spent   2.3 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   14 of   80 (Spent   2.5 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   15 of   80 (Spent   2.6 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   16 of   80 (Spent   2.8 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   17 of   80 (Spent   3.0 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   18 of   80 (Spent   3.2 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   19 of   80 (Spent   3.4 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   20 of   80 (Spent   3.5 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   21 of   80 (Spent   3.7 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   22 of   80 (Spent   3.9 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   23 of   80 (Spent   4.1 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   24 of   80 (Spent   4.2 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   25 of   80 (Spent   4.4 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   26 of   80 (Spent   4.6 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   27 of   80 (Spent   4.8 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   28 of   80 (Spent   5.0 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   29 of   80 (Spent   5.1 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   30 of   80 (Spent   5.3 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   31 of   80 (Spent   5.5 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   32 of   80 (Spent   5.7 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   33 of   80 (Spent   5.9 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   34 of   80 (Spent   6.0 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   35 of   80 (Spent   6.2 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   36 of   80 (Spent   6.4 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   37 of   80 (Spent   6.5 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   38 of   80 (Spent   6.7 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   39 of   80 (Spent   6.9 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   40 of   80 (Spent   7.0 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   41 of   80 (Spent   7.2 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   42 of   80 (Spent   7.4 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   43 of   80 (Spent   7.6 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   44 of   80 (Spent   7.8 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   45 of   80 (Spent   7.9 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   46 of   80 (Spent   8.1 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   47 of   80 (Spent   8.3 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   48 of   80 (Spent   8.4 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   49 of   80 (Spent   8.6 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   50 of   80 (Spent   8.8 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   51 of   80 (Spent   9.0 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   52 of   80 (Spent   9.2 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   53 of   80 (Spent   9.3 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   54 of   80 (Spent   9.5 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   55 of   80 (Spent   9.7 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   56 of   80 (Spent   9.9 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   57 of   80 (Spent  10.0 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   58 of   80 (Spent  10.2 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   59 of   80 (Spent  10.4 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   60 of   80 (Spent  10.6 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   61 of   80 (Spent  10.8 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   62 of   80 (Spent  10.9 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   63 of   80 (Spent  11.1 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   64 of   80 (Spent  11.3 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   65 of   80 (Spent  11.5 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   66 of   80 (Spent  11.7 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   67 of   80 (Spent  11.8 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   68 of   80 (Spent  12.0 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   69 of   80 (Spent  12.2 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   70 of   80 (Spent  12.4 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   71 of   80 (Spent  12.6 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   72 of   80 (Spent  12.7 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   73 of   80 (Spent  12.9 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   74 of   80 (Spent  13.1 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   75 of   80 (Spent  13.2 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   76 of   80 (Spent  13.4 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   77 of   80 (Spent  13.6 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   78 of   80 (Spent  13.8 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   79 of   80 (Spent  14.0 min)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bDone with   80 of   80 (Spent  14.1 min)"
     ]
    }
   ],
   "source": [
    "# null importance\n",
    "# https://www.kaggle.com/ogrellier/feature-selection-with-null-importances\n",
    "def get_feature_importances(data, shuffle, target, id_var, seed=None):\n",
    "    # Gather real features\n",
    "    train_features = [f for f in data if f not in [target, id_var]]\n",
    "    # Go over fold and keep track of CV score (train and valid) and feature importances\n",
    "    \n",
    "    # Shuffle target if required\n",
    "    y = data[target].copy()\n",
    "    if shuffle:\n",
    "        # Here you could as well use a binomial distribution\n",
    "        y = data[target].copy().sample(frac=1.0)\n",
    "    \n",
    "    categorical_feats = [\"session_title\"]\n",
    "    # Fit LightGBM in RF mode, yes it's quicker than sklearn RandomForest\n",
    "    dtrain = lgb.Dataset(data[train_features], y, free_raw_data=False, silent=True)\n",
    "    lgb_params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting_type': 'rf',\n",
    "        'subsample': 0.623,\n",
    "        'colsample_bytree': 0.7,\n",
    "        'num_leaves': 127,\n",
    "        'max_depth': 8,\n",
    "        'seed': seed,\n",
    "        'bagging_freq': 1,\n",
    "        'n_jobs': 4\n",
    "    }\n",
    "    \n",
    "    # Fit the model\n",
    "    clf = lgb.train(params=lgb_params, train_set=dtrain, num_boost_round=200, categorical_feature=categorical_feats)\n",
    "\n",
    "    # Get feature importances\n",
    "    imp_df = pd.DataFrame()\n",
    "    imp_df[\"feature\"] = list(train_features)\n",
    "    imp_df[\"importance_gain\"] = clf.feature_importance(importance_type='gain')\n",
    "    imp_df[\"importance_split\"] = clf.feature_importance(importance_type='split')\n",
    "    imp_df['trn_score'] = roc_auc_score(y, clf.predict(data[train_features]))\n",
    "    \n",
    "    return imp_df\n",
    "\n",
    "def build_null_df(data, target, id_var):\n",
    "    import time\n",
    "    null_imp_df = pd.DataFrame()\n",
    "    nb_runs = 80\n",
    "    start = time.time()\n",
    "    dsp = ''\n",
    "    for i in range(nb_runs):\n",
    "        # Get current run importances\n",
    "        imp_df = get_feature_importances(data=data, target=target, id_var=id_var, shuffle=True)\n",
    "        imp_df['run'] = i + 1 \n",
    "        # Concat the latest importances with the old ones\n",
    "        null_imp_df = pd.concat([null_imp_df, imp_df], axis=0)\n",
    "        # Erase previous message\n",
    "        for l in range(len(dsp)):\n",
    "            print('\\b', end='', flush=True)\n",
    "        # Display current run and time used\n",
    "        spent = (time.time() - start) / 60\n",
    "        dsp = 'Done with %4d of %4d (Spent %5.1f min)' % (i + 1, nb_runs, spent)\n",
    "        print(dsp, end='', flush=True)\n",
    "    return null_imp_df\n",
    "\n",
    "def calculate_imp(actual_imp_df, null_imp_df):\n",
    "    feature_scores = []\n",
    "    for _f in actual_imp_df['feature'].unique():\n",
    "        f_null_imps_gain = null_imp_df.loc[null_imp_df['feature'] == _f, 'importance_gain'].values\n",
    "        f_act_imps_gain = actual_imp_df.loc[actual_imp_df['feature'] == _f, 'importance_gain'].mean()\n",
    "        gain_score = np.log(1e-10 + f_act_imps_gain / (1 + np.percentile(f_null_imps_gain, 75)))  # Avoid didvide by zero\n",
    "        f_null_imps_split = null_imp_df.loc[null_imp_df['feature'] == _f, 'importance_split'].values\n",
    "        f_act_imps_split = actual_imp_df.loc[actual_imp_df['feature'] == _f, 'importance_split'].mean()\n",
    "        split_score = np.log(1e-10 + f_act_imps_split / (1 + np.percentile(f_null_imps_split, 75)))  # Avoid didvide by zero\n",
    "        feature_scores.append((_f, split_score, gain_score))\n",
    "\n",
    "    scores_df = pd.DataFrame(feature_scores, columns=['feature', 'split_score', 'gain_score'])\n",
    "    return scores_df\n",
    "\n",
    "# prepare for the data\n",
    "np.random.seed(123)\n",
    "train_df = new_train.copy()\n",
    "train_df.accuracy_group.loc[train_df.accuracy_group <=1] = 0\n",
    "train_df.accuracy_group.loc[train_df.accuracy_group >=2] = 1\n",
    "\n",
    "# execute null importance\n",
    "actual_imp_df = get_feature_importances(train_df, shuffle=False, target=\"accuracy_group\", id_var = \"installation_id\", seed=123)\n",
    "null_imp_df = build_null_df(data=train_df, target=\"accuracy_group\", id_var = \"installation_id\")\n",
    "scores_df = calculate_imp(actual_imp_df, null_imp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_calculate_imp(actual_imp_df, null_imp_df):\n",
    "    correlation_scores = []\n",
    "    for _f in actual_imp_df['feature'].unique():\n",
    "        f_null_imps = null_imp_df.loc[null_imp_df['feature'] == _f, 'importance_gain'].values\n",
    "        f_act_imps = actual_imp_df.loc[actual_imp_df['feature'] == _f, 'importance_gain'].values\n",
    "        gain_score = 100 * (f_null_imps < np.percentile(f_act_imps, 25)).sum() / f_null_imps.size\n",
    "        f_null_imps = null_imp_df.loc[null_imp_df['feature'] == _f, 'importance_split'].values\n",
    "        f_act_imps = actual_imp_df.loc[actual_imp_df['feature'] == _f, 'importance_split'].values\n",
    "        split_score = 100 * (f_null_imps < np.percentile(f_act_imps, 25)).sum() / f_null_imps.size\n",
    "        correlation_scores.append((_f, split_score, gain_score))\n",
    "\n",
    "    corr_scores_df = pd.DataFrame(correlation_scores, columns=['feature', 'split_score', 'gain_score'])\n",
    "    return corr_scores_df\n",
    "corr_scores_df = corr_calculate_imp(actual_imp_df, null_imp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for threshold   0\n",
      "\t SPLIT : 0.831613 +/- 0.008996\n",
      "\t GAIN  : 0.831613 +/- 0.008996\n",
      "Results for threshold  10\n",
      "\t SPLIT : 0.831520 +/- 0.008201\n",
      "\t GAIN  : 0.832110 +/- 0.009035\n",
      "Results for threshold  20\n",
      "\t SPLIT : 0.832069 +/- 0.007369\n",
      "\t GAIN  : 0.832512 +/- 0.009771\n",
      "Results for threshold  30\n",
      "\t SPLIT : 0.833748 +/- 0.009030\n",
      "\t GAIN  : 0.832049 +/- 0.009323\n",
      "Results for threshold  40\n",
      "\t SPLIT : 0.832629 +/- 0.009572\n",
      "\t GAIN  : 0.832330 +/- 0.009571\n",
      "Results for threshold  50\n",
      "\t SPLIT : 0.832750 +/- 0.008536\n",
      "\t GAIN  : 0.832602 +/- 0.007724\n",
      "Results for threshold  60\n",
      "\t SPLIT : 0.832769 +/- 0.009414\n",
      "\t GAIN  : 0.832319 +/- 0.008316\n",
      "Results for threshold  70\n",
      "\t SPLIT : 0.831842 +/- 0.009055\n",
      "\t GAIN  : 0.832466 +/- 0.009186\n",
      "Results for threshold  80\n",
      "\t SPLIT : 0.832186 +/- 0.008802\n",
      "\t GAIN  : 0.833393 +/- 0.009017\n",
      "Results for threshold  90\n",
      "\t SPLIT : 0.832527 +/- 0.008716\n",
      "\t GAIN  : 0.833009 +/- 0.008128\n",
      "Results for threshold  95\n",
      "\t SPLIT : 0.831620 +/- 0.008747\n",
      "\t GAIN  : 0.832304 +/- 0.009451\n",
      "Results for threshold  99\n",
      "\t SPLIT : 0.830976 +/- 0.008406\n",
      "\t GAIN  : 0.832959 +/- 0.008847\n"
     ]
    }
   ],
   "source": [
    "def score_feature_selection(df=None, train_features=None, cat_feats=None, target=None):\n",
    "    # Fit LightGBM \n",
    "    dtrain = lgb.Dataset(df[train_features], target, free_raw_data=False, silent=True)\n",
    "    lgb_params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': .1,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'num_leaves': 31,\n",
    "        'max_depth': -1,\n",
    "        'seed': 13,\n",
    "        'n_jobs': 4,\n",
    "        'min_split_gain': .00001,\n",
    "        'reg_alpha': .00001,\n",
    "        'reg_lambda': .00001,\n",
    "        'metric': 'auc'\n",
    "    }\n",
    "    \n",
    "    # Fit the model\n",
    "    hist = lgb.cv(\n",
    "        params=lgb_params, \n",
    "        train_set=dtrain, \n",
    "        num_boost_round=2000,\n",
    "        categorical_feature=cat_feats,\n",
    "        nfold=5,\n",
    "        stratified=True,\n",
    "        shuffle=True,\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=0,\n",
    "        seed=17\n",
    "    )\n",
    "    # Return the last mean / std values \n",
    "    return hist['auc-mean'][-1], hist['auc-stdv'][-1]\n",
    "\n",
    "categorical_feats = [\"session_title\"]\n",
    "for threshold in [0, 10, 20, 30 , 40, 50 ,60 , 70, 80 , 90, 95, 99]:\n",
    "    split_feats = sorted(list(corr_scores_df[corr_scores_df.split_score >= threshold][\"feature\"]))\n",
    "    split_cat_feats = sorted(list(set(corr_scores_df[corr_scores_df.split_score >= threshold][\"feature\"]) & set(categorical_feats)))\n",
    "    gain_feats = sorted(list(corr_scores_df[corr_scores_df.gain_score >= threshold][\"feature\"]) )\n",
    "    gain_cat_feats = sorted(list(set(corr_scores_df[corr_scores_df.gain_score >= threshold][\"feature\"]) & set(categorical_feats)))\n",
    "                                                                                             \n",
    "    print('Results for threshold %3d' % threshold)\n",
    "    split_results = score_feature_selection(df=train_df, train_features=split_feats, cat_feats=split_cat_feats, target=train_df['accuracy_group'])\n",
    "    print('\\t SPLIT : %.6f +/- %.6f' % (split_results[0], split_results[1]))\n",
    "    gain_results = score_feature_selection(df=train_df, train_features=gain_feats, cat_feats=gain_cat_feats, target=train_df['accuracy_group'])\n",
    "    print('\\t GAIN  : %.6f +/- %.6f' % (gain_results[0], gain_results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores_df.sort_values(\"gain_score\", ascending = False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoost\n",
    "from catboost import Pool\n",
    "# https://catboost.ai/docs/concepts/python-reference_catboost_predict.html\n",
    "# https://catboost.ai/docs/concepts/python-reference_catboostclassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "0:\tlearn: 0.6899418\ttest: 0.6899418\ttest1: 0.6901186\tbest: 0.6901186 (0)\ttotal: 98.5ms\tremaining: 2h 44m 10s\n",
      "300:\tlearn: 0.5109190\ttest: 0.5109190\ttest1: 0.5224478\tbest: 0.5224478 (300)\ttotal: 13.3s\tremaining: 1h 13m 18s\n",
      "600:\tlearn: 0.4887568\ttest: 0.4887568\ttest1: 0.5037096\tbest: 0.5037096 (600)\ttotal: 26.6s\tremaining: 1h 13m 26s\n",
      "900:\tlearn: 0.4768182\ttest: 0.4768182\ttest1: 0.4956070\tbest: 0.4956070 (900)\ttotal: 39.5s\tremaining: 1h 12m 22s\n",
      "1200:\tlearn: 0.4638097\ttest: 0.4638097\ttest1: 0.4910713\tbest: 0.4910433 (1198)\ttotal: 52.2s\tremaining: 1h 11m 33s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.4906463515\n",
      "bestIteration = 1241\n",
      "\n",
      "Shrink model to first 1242 iterations.\n",
      "Fold 2\n",
      "0:\tlearn: 0.6900306\ttest: 0.6900306\ttest1: 0.6900942\tbest: 0.6900942 (0)\ttotal: 43.2ms\tremaining: 1h 12m 1s\n",
      "300:\tlearn: 0.5115867\ttest: 0.5115867\ttest1: 0.5197172\tbest: 0.5197172 (300)\ttotal: 12.9s\tremaining: 1h 11m 26s\n",
      "600:\tlearn: 0.4892546\ttest: 0.4892546\ttest1: 0.5031422\tbest: 0.5031422 (600)\ttotal: 26.5s\tremaining: 1h 13m 6s\n",
      "900:\tlearn: 0.4774059\ttest: 0.4774059\ttest1: 0.4969140\tbest: 0.4969140 (900)\ttotal: 39.1s\tremaining: 1h 11m 45s\n",
      "1200:\tlearn: 0.4651441\ttest: 0.4651441\ttest1: 0.4914917\tbest: 0.4914917 (1200)\ttotal: 51.6s\tremaining: 1h 10m 45s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.4890082135\n",
      "bestIteration = 1415\n",
      "\n",
      "Shrink model to first 1416 iterations.\n",
      "Fold 3\n",
      "0:\tlearn: 0.6897738\ttest: 0.6897738\ttest1: 0.6896525\tbest: 0.6896525 (0)\ttotal: 43.8ms\tremaining: 1h 13m 3s\n",
      "300:\tlearn: 0.5131346\ttest: 0.5131346\ttest1: 0.5149060\tbest: 0.5149060 (300)\ttotal: 13.4s\tremaining: 1h 13m 53s\n",
      "600:\tlearn: 0.4896630\ttest: 0.4896630\ttest1: 0.4976237\tbest: 0.4976237 (600)\ttotal: 27s\tremaining: 1h 14m 21s\n",
      "900:\tlearn: 0.4774824\ttest: 0.4774824\ttest1: 0.4915851\tbest: 0.4915851 (900)\ttotal: 39.9s\tremaining: 1h 13m 5s\n",
      "1200:\tlearn: 0.4645246\ttest: 0.4645246\ttest1: 0.4866947\tbest: 0.4866903 (1199)\ttotal: 53.2s\tremaining: 1h 12m 55s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.4850805391\n",
      "bestIteration = 1434\n",
      "\n",
      "Shrink model to first 1435 iterations.\n",
      "Fold 4\n",
      "0:\tlearn: 0.6899839\ttest: 0.6899839\ttest1: 0.6901674\tbest: 0.6901674 (0)\ttotal: 44.3ms\tremaining: 1h 13m 47s\n",
      "300:\tlearn: 0.5127787\ttest: 0.5127787\ttest1: 0.5180767\tbest: 0.5180767 (300)\ttotal: 14.1s\tremaining: 1h 17m 50s\n",
      "600:\tlearn: 0.4899682\ttest: 0.4899682\ttest1: 0.4991547\tbest: 0.4991547 (600)\ttotal: 27.2s\tremaining: 1h 14m 57s\n",
      "900:\tlearn: 0.4779516\ttest: 0.4779516\ttest1: 0.4918745\tbest: 0.4918745 (900)\ttotal: 40.1s\tremaining: 1h 13m 26s\n",
      "1200:\tlearn: 0.4655845\ttest: 0.4655845\ttest1: 0.4858137\tbest: 0.4858137 (1200)\ttotal: 53.4s\tremaining: 1h 13m 15s\n",
      "1500:\tlearn: 0.4546721\ttest: 0.4546721\ttest1: 0.4820830\tbest: 0.4820830 (1500)\ttotal: 1m 6s\tremaining: 1h 12m 25s\n",
      "1800:\tlearn: 0.4452666\ttest: 0.4452666\ttest1: 0.4799771\tbest: 0.4799771 (1800)\ttotal: 1m 19s\tremaining: 1h 12m 33s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.4799467776\n",
      "bestIteration = 1803\n",
      "\n",
      "Shrink model to first 1804 iterations.\n",
      "Fold 5\n",
      "0:\tlearn: 0.6900237\ttest: 0.6900237\ttest1: 0.6900507\tbest: 0.6900507 (0)\ttotal: 41.7ms\tremaining: 1h 9m 34s\n",
      "300:\tlearn: 0.5116787\ttest: 0.5116787\ttest1: 0.5238392\tbest: 0.5238392 (300)\ttotal: 13.1s\tremaining: 1h 12m 16s\n",
      "600:\tlearn: 0.4886998\ttest: 0.4886998\ttest1: 0.5062317\tbest: 0.5062317 (600)\ttotal: 26.2s\tremaining: 1h 12m 20s\n",
      "900:\tlearn: 0.4763130\ttest: 0.4763130\ttest1: 0.4997068\tbest: 0.4997068 (900)\ttotal: 39.4s\tremaining: 1h 12m 13s\n",
      "1200:\tlearn: 0.4638803\ttest: 0.4638803\ttest1: 0.4942064\tbest: 0.4942064 (1200)\ttotal: 53.1s\tremaining: 1h 12m 44s\n",
      "1500:\tlearn: 0.4531494\ttest: 0.4531494\ttest1: 0.4915212\tbest: 0.4915139 (1496)\ttotal: 1m 5s\tremaining: 1h 12m 7s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.4900440711\n",
      "bestIteration = 1726\n",
      "\n",
      "Shrink model to first 1727 iterations.\n",
      "logloss = \t 0.48694551848045076\n",
      "ROC = \t 0.8280862294015229\n"
     ]
    }
   ],
   "source": [
    "def feature_selection(train):\n",
    "    X_train = train.drop(['accuracy_group'],axis=1) \n",
    "    y_train = train.accuracy_group.copy()\n",
    "    y_train.loc[y_train <=1] = 0\n",
    "    y_train.loc[y_train >=2] = 1\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(X_train[\"installation_id\"]))\n",
    "    X_train[\"installation_id\"] = lbl.transform(list(X_train[\"installation_id\"]))\n",
    "    remove_features = [i for i in X_train.columns if \"_4235\" in i or i == \"world_\"+str(activities_world[\"NONE\"])\n",
    "                      or i in to_exclude]\n",
    "    for i in X_train.columns:\n",
    "        if X_train[i].std() == 0 and i not in remove_features:\n",
    "            remove_features.append(i)\n",
    "    X_train = X_train.drop(remove_features, axis=1)\n",
    "    X_train = X_train[sorted(X_train.columns.tolist())]\n",
    "\n",
    "    n_folds=5\n",
    "    skf=GroupKFold(n_splits = n_folds)\n",
    "    cat_params = {\n",
    "    'loss_function': 'Logloss',\n",
    "    'depth': 4,\n",
    "    \"num_boost_round\":100000,\n",
    "    'learning_rate': 0.01,\n",
    "    \"early_stopping_rounds\":10,}\n",
    "\n",
    "    valid = pd.DataFrame(np.zeros([X_train.shape[0]]))\n",
    "    features_list = [i for i in X_train.columns if i != \"installation_id\"]\n",
    "    feature_importance_df = pd.DataFrame(features_list, columns=[\"Feature\"])\n",
    "    for i , (train_index, test_index) in enumerate(skf.split(X_train, y_train, X_train[\"installation_id\"])):\n",
    "        print(\"Fold \"+str(i+1))\n",
    "        X_train2 = X_train.iloc[train_index,:]\n",
    "        y_train2 = y_train.iloc[train_index]\n",
    "        X_train2 = X_train2.drop(['installation_id'],axis=1)\n",
    "    \n",
    "        X_test2 = X_train.iloc[test_index,:]\n",
    "        y_test2 = y_train.iloc[test_index]\n",
    "        X_test2 = X_test2.drop(['installation_id'],axis=1)\n",
    "            \n",
    "        train_pool = Pool(X_train2, label=y_train2)\n",
    "        test_pool = Pool(X_test2, label=y_test2)\n",
    "        clf = CatBoost(cat_params)\n",
    "        clf.fit(train_pool, eval_set=[train_pool, test_pool], use_best_model=True, verbose_eval = 300)\n",
    "        test_predict = clf.predict(X_test2, prediction_type = \"Probability\")\n",
    "        valid.iloc[test_index] = test_predict[:,1].reshape(X_test2.shape[0], 1)\n",
    "        feature_importance_df[\"Fold_\"+str(i+1)] = clf.get_feature_importance()\n",
    "                \n",
    "    print(\"logloss = \\t {}\".format(log_loss(y_train, valid)))\n",
    "    print(\"ROC = \\t {}\".format(roc_auc_score(y_train, valid)))\n",
    "    feature_importance_df[\"Average\"] = np.mean(feature_importance_df.iloc[:,1:n_folds+1], axis=1)\n",
    "    feature_importance_df[\"Std\"] = np.std(feature_importance_df.iloc[:,1:n_folds+1], axis=1)\n",
    "    feature_importance_df[\"Cv\"] = feature_importance_df[\"Std\"] / feature_importance_df[\"Average\"]\n",
    "    return feature_importance_df\n",
    "df_for_classification = feature_selection(new_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537\n",
      "Fold 1\n",
      "0:\tlearn: 0.6899418\ttest: 0.6899418\ttest1: 0.6901186\tbest: 0.6901186 (0)\ttotal: 44.3ms\tremaining: 1h 13m 54s\n",
      "300:\tlearn: 0.5109190\ttest: 0.5109190\ttest1: 0.5224478\tbest: 0.5224478 (300)\ttotal: 13.1s\tremaining: 1h 12m 9s\n",
      "600:\tlearn: 0.4887568\ttest: 0.4887568\ttest1: 0.5037096\tbest: 0.5037096 (600)\ttotal: 26.2s\tremaining: 1h 12m 6s\n",
      "900:\tlearn: 0.4768182\ttest: 0.4768182\ttest1: 0.4956070\tbest: 0.4956070 (900)\ttotal: 39.8s\tremaining: 1h 12m 53s\n",
      "1200:\tlearn: 0.4638097\ttest: 0.4638097\ttest1: 0.4910713\tbest: 0.4910433 (1198)\ttotal: 52.6s\tremaining: 1h 12m 10s\n",
      "1500:\tlearn: 0.4526600\ttest: 0.4526600\ttest1: 0.4890793\tbest: 0.4890793 (1500)\ttotal: 1m 5s\tremaining: 1h 11m 26s\n",
      "1800:\tlearn: 0.4430370\ttest: 0.4430370\ttest1: 0.4879908\tbest: 0.4879908 (1800)\ttotal: 1m 18s\tremaining: 1h 10m 57s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.4877186947\n",
      "bestIteration = 1925\n",
      "\n",
      "Shrink model to first 1926 iterations.\n",
      "Fold 2\n",
      "0:\tlearn: 0.6900306\ttest: 0.6900306\ttest1: 0.6900942\tbest: 0.6900942 (0)\ttotal: 44.8ms\tremaining: 1h 14m 43s\n",
      "300:\tlearn: 0.5115867\ttest: 0.5115867\ttest1: 0.5197172\tbest: 0.5197172 (300)\ttotal: 13.3s\tremaining: 1h 13m 28s\n",
      "600:\tlearn: 0.4892546\ttest: 0.4892546\ttest1: 0.5031422\tbest: 0.5031422 (600)\ttotal: 26.1s\tremaining: 1h 11m 54s\n",
      "900:\tlearn: 0.4774059\ttest: 0.4774059\ttest1: 0.4969140\tbest: 0.4969140 (900)\ttotal: 38.8s\tremaining: 1h 11m 5s\n",
      "1200:\tlearn: 0.4651441\ttest: 0.4651441\ttest1: 0.4914917\tbest: 0.4914917 (1200)\ttotal: 51.4s\tremaining: 1h 10m 25s\n",
      "1500:\tlearn: 0.4545044\ttest: 0.4545044\ttest1: 0.4882444\tbest: 0.4882000 (1495)\ttotal: 1m 4s\tremaining: 1h 11m 4s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.4877889205\n",
      "bestIteration = 1685\n",
      "\n",
      "Shrink model to first 1686 iterations.\n",
      "Fold 3\n",
      "0:\tlearn: 0.6897738\ttest: 0.6897738\ttest1: 0.6896525\tbest: 0.6896525 (0)\ttotal: 44.8ms\tremaining: 1h 14m 35s\n",
      "300:\tlearn: 0.5131346\ttest: 0.5131346\ttest1: 0.5149060\tbest: 0.5149060 (300)\ttotal: 13.1s\tremaining: 1h 12m 18s\n",
      "600:\tlearn: 0.4896630\ttest: 0.4896630\ttest1: 0.4976237\tbest: 0.4976237 (600)\ttotal: 26.6s\tremaining: 1h 13m 20s\n",
      "900:\tlearn: 0.4774824\ttest: 0.4774824\ttest1: 0.4915851\tbest: 0.4915851 (900)\ttotal: 39.5s\tremaining: 1h 12m 26s\n",
      "1200:\tlearn: 0.4645246\ttest: 0.4645246\ttest1: 0.4866947\tbest: 0.4866903 (1199)\ttotal: 53.2s\tremaining: 1h 12m 56s\n",
      "1500:\tlearn: 0.4535800\ttest: 0.4535800\ttest1: 0.4845797\tbest: 0.4845797 (1500)\ttotal: 1m 5s\tremaining: 1h 11m 56s\n",
      "1800:\tlearn: 0.4447804\ttest: 0.4447804\ttest1: 0.4836249\tbest: 0.4836209 (1799)\ttotal: 1m 18s\tremaining: 1h 11m 4s\n",
      "2100:\tlearn: 0.4365331\ttest: 0.4365331\ttest1: 0.4829232\tbest: 0.4829198 (2099)\ttotal: 1m 30s\tremaining: 1h 10m 39s\n",
      "2400:\tlearn: 0.4287973\ttest: 0.4287973\ttest1: 0.4827485\tbest: 0.4826973 (2359)\ttotal: 1m 44s\tremaining: 1h 10m 32s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.4826441118\n",
      "bestIteration = 2430\n",
      "\n",
      "Shrink model to first 2431 iterations.\n",
      "Fold 4\n",
      "0:\tlearn: 0.6899839\ttest: 0.6899839\ttest1: 0.6901674\tbest: 0.6901674 (0)\ttotal: 42.6ms\tremaining: 1h 10m 57s\n",
      "300:\tlearn: 0.5127787\ttest: 0.5127787\ttest1: 0.5180767\tbest: 0.5180767 (300)\ttotal: 13.1s\tremaining: 1h 12m 16s\n",
      "600:\tlearn: 0.4899682\ttest: 0.4899682\ttest1: 0.4991547\tbest: 0.4991547 (600)\ttotal: 26.1s\tremaining: 1h 11m 48s\n",
      "900:\tlearn: 0.4779516\ttest: 0.4779516\ttest1: 0.4918745\tbest: 0.4918745 (900)\ttotal: 39.2s\tremaining: 1h 11m 50s\n",
      "1200:\tlearn: 0.4655845\ttest: 0.4655845\ttest1: 0.4858137\tbest: 0.4858137 (1200)\ttotal: 52.6s\tremaining: 1h 12m 10s\n",
      "1500:\tlearn: 0.4546721\ttest: 0.4546721\ttest1: 0.4820830\tbest: 0.4820830 (1500)\ttotal: 1m 5s\tremaining: 1h 11m 45s\n",
      "1800:\tlearn: 0.4452666\ttest: 0.4452666\ttest1: 0.4799771\tbest: 0.4799771 (1800)\ttotal: 1m 18s\tremaining: 1h 11m 20s\n",
      "2100:\tlearn: 0.4367398\ttest: 0.4367398\ttest1: 0.4787111\tbest: 0.4787111 (2100)\ttotal: 1m 31s\tremaining: 1h 10m 51s\n",
      "2400:\tlearn: 0.4287374\ttest: 0.4287374\ttest1: 0.4779903\tbest: 0.4779903 (2400)\ttotal: 1m 43s\tremaining: 1h 10m 25s\n",
      "2700:\tlearn: 0.4212196\ttest: 0.4212196\ttest1: 0.4774059\tbest: 0.4774027 (2699)\ttotal: 1m 57s\tremaining: 1h 10m 28s\n",
      "3000:\tlearn: 0.4140797\ttest: 0.4140797\ttest1: 0.4771804\tbest: 0.4770942 (2980)\ttotal: 2m 10s\tremaining: 1h 10m 6s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.4770942261\n",
      "bestIteration = 2980\n",
      "\n",
      "Shrink model to first 2981 iterations.\n",
      "Fold 5\n",
      "0:\tlearn: 0.6900237\ttest: 0.6900237\ttest1: 0.6900507\tbest: 0.6900507 (0)\ttotal: 43ms\tremaining: 1h 11m 43s\n",
      "300:\tlearn: 0.5116787\ttest: 0.5116787\ttest1: 0.5238392\tbest: 0.5238392 (300)\ttotal: 13.3s\tremaining: 1h 13m 24s\n",
      "600:\tlearn: 0.4886998\ttest: 0.4886998\ttest1: 0.5062317\tbest: 0.5062317 (600)\ttotal: 26.5s\tremaining: 1h 12m 59s\n",
      "900:\tlearn: 0.4763130\ttest: 0.4763130\ttest1: 0.4997068\tbest: 0.4997068 (900)\ttotal: 40.2s\tremaining: 1h 13m 45s\n",
      "1200:\tlearn: 0.4638803\ttest: 0.4638803\ttest1: 0.4942064\tbest: 0.4942064 (1200)\ttotal: 53.3s\tremaining: 1h 13m 7s\n",
      "1500:\tlearn: 0.4531494\ttest: 0.4531494\ttest1: 0.4915212\tbest: 0.4915139 (1496)\ttotal: 1m 6s\tremaining: 1h 12m 48s\n",
      "1800:\tlearn: 0.4438502\ttest: 0.4438502\ttest1: 0.4898905\tbest: 0.4898612 (1788)\ttotal: 1m 19s\tremaining: 1h 12m 11s\n",
      "2100:\tlearn: 0.4355914\ttest: 0.4355914\ttest1: 0.4889237\tbest: 0.4889129 (2098)\ttotal: 1m 32s\tremaining: 1h 11m 46s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.4886198324\n",
      "bestIteration = 2219\n",
      "\n",
      "Shrink model to first 2220 iterations.\n",
      "logloss = \t 0.4847734962527184\n",
      "ROC = \t 0.8289700057116722\n",
      "Accuracy score = \t 0.7756727541673778\n",
      "Precision score = \t 0.786260162601626\n",
      "Recall score =   \t 0.8803823395539372\n",
      "F1 score =      \t 0.8306635172858062\n",
      "[[3963 2629]\n",
      " [1314 9671]]\n"
     ]
    }
   ],
   "source": [
    "def accuracy_class(train, test, fea, select_flg):\n",
    "    X_train = train.drop(['accuracy_group'],axis=1) \n",
    "    y_train = train.accuracy_group.copy()\n",
    "    y_train.loc[y_train <=1] = 0\n",
    "    y_train.loc[y_train >=2] = 1\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(X_train[\"installation_id\"]))\n",
    "    X_train[\"installation_id\"] = lbl.transform(list(X_train[\"installation_id\"]))\n",
    "    remove_features = [i for i in X_train.columns if \"_4235\" in i or i == \"world_\"+str(activities_world[\"NONE\"])\n",
    "                      or i in to_exclude]\n",
    "    for i in X_train.columns:\n",
    "        if X_train[i].std() == 0 and i not in remove_features:\n",
    "            remove_features.append(i)\n",
    "    X_train = X_train.drop(remove_features, axis=1)\n",
    "    X_train = X_train[sorted(X_train.columns.tolist())]\n",
    "\n",
    "    X_test = test.drop([\"installation_id\",\"accuracy_group\"], axis=1)\n",
    "    X_test = X_test.drop(remove_features, axis=1)\n",
    "    X_test = X_test[sorted(X_test.columns.tolist())]\n",
    "    if select_flg == True:\n",
    "        X_test = X_test[fea]\n",
    "    print(X_test.shape[1])\n",
    "    \n",
    "    n_folds=5\n",
    "    skf=GroupKFold(n_splits = n_folds)\n",
    "    models = []\n",
    "    cat_params = {\n",
    "    'loss_function': 'Logloss',\n",
    "    'depth': 4,\n",
    "    \"num_boost_round\":100000,\n",
    "    'learning_rate': 0.01,\n",
    "    \"early_stopping_rounds\":100,}\n",
    "\n",
    "    valid = pd.DataFrame(np.zeros([X_train.shape[0]]))\n",
    "    for i , (train_index, test_index) in enumerate(skf.split(X_train, y_train, X_train[\"installation_id\"])):\n",
    "        print(\"Fold \"+str(i+1))\n",
    "        X_train2 = X_train.iloc[train_index,:]\n",
    "        y_train2 = y_train.iloc[train_index]\n",
    "        X_train2 = X_train2.drop(['installation_id'],axis=1)\n",
    "    \n",
    "        X_test2 = X_train.iloc[test_index,:]\n",
    "        y_test2 = y_train.iloc[test_index]\n",
    "        X_test2 = X_test2.drop(['installation_id'],axis=1)\n",
    "        if select_flg == True:\n",
    "            X_train2 = X_train2[fea] \n",
    "            X_test2 = X_test2[fea]\n",
    "            \n",
    "        train_pool = Pool(X_train2, label=y_train2)\n",
    "        test_pool = Pool(X_test2, label=y_test2)\n",
    "        clf = CatBoost(cat_params)\n",
    "        clf.fit(train_pool, eval_set=[train_pool, test_pool], use_best_model=True, verbose_eval = 300)\n",
    "        test_predict = clf.predict(X_test2, prediction_type = \"Probability\")\n",
    "        \n",
    "        models.append(clf)\n",
    "        valid.iloc[test_index] = test_predict[:,1].reshape(X_test2.shape[0], 1)\n",
    "                \n",
    "    print(\"logloss = \\t {}\".format(log_loss(y_train, valid)))\n",
    "    print(\"ROC = \\t {}\".format(roc_auc_score(y_train, valid)))\n",
    "    print('Accuracy score = \\t {}'.format(accuracy_score(y_train, np.round(valid))))\n",
    "    print('Precision score = \\t {}'.format(precision_score(y_train, np.round(valid))))\n",
    "    print('Recall score =   \\t {}'.format(recall_score(y_train, np.round(valid))))\n",
    "    print('F1 score =      \\t {}'.format(f1_score(y_train, np.round(valid))))\n",
    "    print(confusion_matrix(y_train, np.round(valid)))\n",
    "    pred_value = np.zeros([X_test.shape[0]])\n",
    "    for model in models:\n",
    "        pred_value += model.predict(X_test, prediction_type = \"Probability\")[:,1] / len(models)\n",
    "    return pred_value, valid\n",
    "\n",
    "tmp = df_for_classification.sort_values(\"Cv\", ascending = True).reset_index(drop=True).copy()\n",
    "feat = tmp[tmp.index <= 120][\"Feature\"]\n",
    "pred_value, valid = accuracy_class(new_train, new_test, feat, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.35956246 0.52791334 0.74837277] 0.59014357\n",
      "1 [0.38723163 0.5291244  0.74916191] 0.59048583\n",
      "2 [0.3733441  0.51992717 0.74992837] 0.58997539\n",
      "3 [0.3746515  0.55209225 0.74994618] 0.58963858\n",
      "4 [0.3867983  0.5499634  0.74895577] 0.58980931\n",
      "5 [0.37664827 0.52984829 0.74965131] 0.59020788\n",
      "6 [0.38696398 0.5497763  0.74842302] 0.58989818\n",
      "7 [0.38587198 0.54652947 0.74916004] 0.58999843\n",
      "8 [0.3331923  0.52789184 0.74838247] 0.59034532\n",
      "9 [0.37307028 0.5090121  0.74966794] 0.58968999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3    0.468\n",
       "2    0.265\n",
       "0    0.184\n",
       "1    0.083\n",
       "Name: accuracy_group, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score = 0\n",
    "for i in range(10):\n",
    "    optR = OptimizedRounder()\n",
    "    optR.fit(np.array(valid).reshape(-1,), new_train.accuracy_group, random_flg=True)\n",
    "    coefficients = optR.coefficients()\n",
    "    final_valid_pred = optR.predict(np.array(valid).reshape(-1,), coefficients)\n",
    "    score = qwk(new_train.accuracy_group, final_valid_pred)\n",
    "    print(i, np.sort(coefficients), score)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_coefficients = coefficients\n",
    "final_test_pred = pd.cut(np.array(pred_value).reshape(-1,), [-np.inf] + list(np.sort(best_coefficients)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "#final_test_pred = pd.cut(np.array(test_exp_accuracy).reshape(-1,), [-np.inf] + list(np.sort([0.30278718, 0.42545025, 0.56396292])) + [np.inf], labels = [0, 1, 2, 3])\n",
    "\n",
    "sample_submission[\"accuracy_group\"] = final_test_pred.astype(int)\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission[\"accuracy_group\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1ca9e3ea103b4068a160eb19cff0d75a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "2650288a71f6475eab7ab69b0dee9d96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Installation_id: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7c1765cf52d34fee9e6f39acaf4698ab",
       "max": 1000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f9e2edfb875241dea6aae49377d41056",
       "value": 1000
      }
     },
     "266a764e59b449f7b7b7ec547e629f5d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4c7a89951b20492b9fb45449803dc930": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Installation_id: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f48439550bfd43c9b761ee02691a567e",
       "max": 17000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1ca9e3ea103b4068a160eb19cff0d75a",
       "value": 17000
      }
     },
     "6b5e9d8b88e644c3b3d84d0528357c0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7c1765cf52d34fee9e6f39acaf4698ab": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "81b311e054d645969f69f4d83d07bb52": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dd25eff6c5d446568640ac18bfab3c84",
       "placeholder": "​",
       "style": "IPY_MODEL_bcf9c19516b745b0b6af98dcdd241b61",
       "value": " 17000/17000 [14:14&lt;00:00, 19.89it/s]"
      }
     },
     "8e63f886b51049c1878a00a1f843ba69": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2650288a71f6475eab7ab69b0dee9d96",
        "IPY_MODEL_c18a5e371c1045b19d0690178e59c5ff"
       ],
       "layout": "IPY_MODEL_aa8f0b773f4540159af582e1b364b0d8"
      }
     },
     "a2e3ab3eae654326958a9e37be7a442d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aa8f0b773f4540159af582e1b364b0d8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bcf9c19516b745b0b6af98dcdd241b61": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c18a5e371c1045b19d0690178e59c5ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a2e3ab3eae654326958a9e37be7a442d",
       "placeholder": "​",
       "style": "IPY_MODEL_6b5e9d8b88e644c3b3d84d0528357c0d",
       "value": " 1000/1000 [01:34&lt;00:00, 10.59it/s]"
      }
     },
     "db111e1d7684415496d4e9bb20bb32ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4c7a89951b20492b9fb45449803dc930",
        "IPY_MODEL_81b311e054d645969f69f4d83d07bb52"
       ],
       "layout": "IPY_MODEL_266a764e59b449f7b7b7ec547e629f5d"
      }
     },
     "dd25eff6c5d446568640ac18bfab3c84": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f48439550bfd43c9b761ee02691a567e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f9e2edfb875241dea6aae49377d41056": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
