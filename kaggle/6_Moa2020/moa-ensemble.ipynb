{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022585,
     "end_time": "2020-10-27T11:46:32.718434",
     "exception": false,
     "start_time": "2020-10-27T11:46:32.695849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- try 2nd layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T11:46:32.770631Z",
     "iopub.status.busy": "2020-10-27T11:46:32.769818Z",
     "iopub.status.idle": "2020-10-27T11:46:41.544928Z",
     "shell.execute_reply": "2020-10-27T11:46:41.544207Z"
    },
    "papermill": {
     "duration": 8.804345,
     "end_time": "2020-10-27T11:46:41.545089",
     "exception": false,
     "start_time": "2020-10-27T11:46:32.740744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl\r\n",
      "Processing /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: tqdm<5.0,>=4.36 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (4.45.0)\r\n",
      "Requirement already satisfied: scikit_learn>0.21 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (0.23.2)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.18.5)\r\n",
      "Requirement already satisfied: torch<2.0,>=1.2 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.6.0)\r\n",
      "Requirement already satisfied: scipy>1.4 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.4.1)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (0.14.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (2.1.0)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch<2.0,>=1.2->pytorch-tabnet) (0.18.2)\r\n",
      "Installing collected packages: pytorch-tabnet\r\n",
      "Successfully installed pytorch-tabnet-2.0.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-index --find-links /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T11:46:41.636107Z",
     "iopub.status.busy": "2020-10-27T11:46:41.628174Z",
     "iopub.status.idle": "2020-10-27T11:48:32.193201Z",
     "shell.execute_reply": "2020-10-27T11:48:32.192549Z"
    },
    "papermill": {
     "duration": 110.607163,
     "end_time": "2020-10-27T11:48:32.193327",
     "exception": false,
     "start_time": "2020-10-27T11:46:41.586164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!cp ../input/rapids/rapids.0.15.0 /opt/conda/envs/rapids.tar.gz\n",
    "!cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\n",
    "sys.path = [\"/opt/conda/envs/rapids/lib/python3.7/site-packages\"] + sys.path\n",
    "sys.path = [\"/opt/conda/envs/rapids/lib/python3.7\"] + sys.path\n",
    "sys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path\n",
    "!cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-27T11:48:32.262321Z",
     "iopub.status.busy": "2020-10-27T11:48:32.261325Z",
     "iopub.status.idle": "2020-10-27T11:48:40.908544Z",
     "shell.execute_reply": "2020-10-27T11:48:40.907971Z"
    },
    "papermill": {
     "duration": 8.682753,
     "end_time": "2020-10-27T11:48:40.908702",
     "exception": false,
     "start_time": "2020-10-27T11:48:32.225949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from category_encoders import CountEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "sys.path.append('../input/multilabelstraifier/')\n",
    "from ml_stratifiers import MultilabelStratifiedKFold\n",
    "warnings.filterwarnings('ignore')\n",
    "import xgboost as xgb\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from cuml.svm import SVC, SVR\n",
    "\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02384,
     "end_time": "2020-10-27T11:48:40.957194",
     "exception": false,
     "start_time": "2020-10-27T11:48:40.933354",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-10-27T11:48:41.023881Z",
     "iopub.status.busy": "2020-10-27T11:48:41.022743Z",
     "iopub.status.idle": "2020-10-27T11:48:46.777211Z",
     "shell.execute_reply": "2020-10-27T11:48:46.776239Z"
    },
    "papermill": {
     "duration": 5.794682,
     "end_time": "2020-10-27T11:48:46.777331",
     "exception": false,
     "start_time": "2020-10-27T11:48:40.982649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/lish-moa/'\n",
    "train = pd.read_csv(DATA_DIR + 'train_features.csv')\n",
    "targets = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "test = pd.read_csv(DATA_DIR + 'test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T11:48:46.832399Z",
     "iopub.status.busy": "2020-10-27T11:48:46.831692Z",
     "iopub.status.idle": "2020-10-27T11:48:46.835583Z",
     "shell.execute_reply": "2020-10-27T11:48:46.835039Z"
    },
    "papermill": {
     "duration": 0.033875,
     "end_time": "2020-10-27T11:48:46.835739",
     "exception": false,
     "start_time": "2020-10-27T11:48:46.801864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_feats = [ i for i in targets.columns if i != \"sig_id\"]\n",
    "g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "c_feats = [i for i in train.columns if \"c-\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T11:48:46.903417Z",
     "iopub.status.busy": "2020-10-27T11:48:46.902645Z",
     "iopub.status.idle": "2020-10-27T11:48:47.336762Z",
     "shell.execute_reply": "2020-10-27T11:48:47.336118Z"
    },
    "papermill": {
     "duration": 0.47648,
     "end_time": "2020-10-27T11:48:47.336885",
     "exception": false,
     "start_time": "2020-10-27T11:48:46.860405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cons_train_index = train[train.cp_type!=\"ctl_vehicle\"].index\n",
    "noncons_test_index = test[test.cp_type==\"ctl_vehicle\"].index\n",
    "cons_test_index = test[test.cp_type!=\"ctl_vehicle\"].index\n",
    "\n",
    "test = test[test.index.isin(cons_test_index)].reset_index(drop=True)\n",
    "train = train[train.index.isin(cons_train_index)].reset_index(drop=True)\n",
    "fn_targets = targets.drop(\"sig_id\", axis=1).copy()\n",
    "fn_targets = fn_targets[fn_targets.index.isin(cons_train_index)].copy().reset_index(drop=True).to_numpy()\n",
    "y = targets.drop(\"sig_id\", axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026465,
     "end_time": "2020-10-27T11:48:47.391388",
     "exception": false,
     "start_time": "2020-10-27T11:48:47.364923",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T11:48:47.455628Z",
     "iopub.status.busy": "2020-10-27T11:48:47.445171Z",
     "iopub.status.idle": "2020-10-27T11:48:47.494390Z",
     "shell.execute_reply": "2020-10-27T11:48:47.493775Z"
    },
    "papermill": {
     "duration": 0.077783,
     "end_time": "2020-10-27T11:48:47.494503",
     "exception": false,
     "start_time": "2020-10-27T11:48:47.416720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe_simple(df, remove_features):\n",
    "    tmp = df.copy()\n",
    "    tmp.loc[:, 'cp_dose'] = tmp.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "    tmp.drop(remove_features, axis=1, inplace=True)\n",
    "    return tmp\n",
    "\n",
    "def fe_mlp(df_train, df_test):\n",
    "    tmp_train = df_train.copy()\n",
    "    tmp_test = df_test.copy()\n",
    "    X = tmp_train.iloc[:,4:].copy().values\n",
    "    select = VarianceThreshold(threshold=0.7)\n",
    "    X_new = select.fit_transform(X)\n",
    "    drop_feats = list(np.array(tmp_train.iloc[:,4:].columns)[select.get_support()==False])\n",
    "    \n",
    "    tmp_train.drop(drop_feats, axis=1, inplace=True)\n",
    "    tmp_test.drop(drop_feats, axis=1, inplace=True)\n",
    "\n",
    "    modg_feats = [i for i in tmp_train.columns if \"g-\" in i]\n",
    "    modc_feats = [i for i in tmp_train.columns if \"c-\" in i]\n",
    "    \n",
    "    for i in modc_feats + modg_feats:\n",
    "        ss = preprocessing.QuantileTransformer(n_quantiles=1000, random_state=0, output_distribution=\"normal\")\n",
    "        ss.fit(tmp_train[i].values.reshape(-1,1))\n",
    "        tmp_train[i] = ss.transform(tmp_train[i].values.reshape(-1,1))\n",
    "        tmp_test[i] = ss.transform(tmp_test[i].values.reshape(-1,1))\n",
    "    \n",
    "    c_num = 10\n",
    "    pca_c_cols = [\"pca-c\"+str(i+1) for i in range(c_num)]\n",
    "    pca = PCA(n_components=c_num,random_state=42)\n",
    "    c_train = pca.fit_transform(tmp_train[modc_feats])\n",
    "    c_test = pca.transform(tmp_test[modc_feats])\n",
    "    c_train = pd.DataFrame(c_train, columns=pca_c_cols)\n",
    "    c_test = pd.DataFrame(c_test, columns=pca_c_cols)\n",
    "\n",
    "    g_num = 60\n",
    "    pca_g_cols = [\"pca-g\"+str(i+1) for i in range(g_num)]\n",
    "    pca = PCA(n_components=g_num, random_state=42)\n",
    "    g_train = pca.fit_transform(tmp_train[modg_feats])\n",
    "    g_test = pca.transform(tmp_test[modg_feats])\n",
    "    g_train = pd.DataFrame(g_train, columns=pca_g_cols)\n",
    "    g_test = pd.DataFrame(g_test, columns=pca_g_cols)\n",
    "\n",
    "    tmp_train = pd.concat([tmp_train, c_train],axis=1)\n",
    "    tmp_test = pd.concat([tmp_test, c_test],axis=1)\n",
    "    tmp_train = pd.concat([tmp_train, g_train],axis=1)\n",
    "    tmp_test = pd.concat([tmp_test, g_test],axis=1)\n",
    "    \n",
    "    return tmp_train, tmp_test\n",
    "\n",
    "def fe_mlp2(df):\n",
    "    tmp = df.copy()\n",
    "    modg_feats = [i for i in tmp.columns if \"g-\" in i]\n",
    "    modc_feats = [i for i in tmp.columns if \"c-\" in i]\n",
    "    tmp['g_sum'] = tmp[modg_feats].sum(axis = 1)\n",
    "    tmp['g_mean'] = tmp[modg_feats].mean(axis = 1)\n",
    "    tmp['g_std'] = tmp[modg_feats].std(axis = 1)\n",
    "    tmp['g_kurt'] = tmp[modg_feats].kurtosis(axis = 1)\n",
    "    tmp['g_skew'] = tmp[modg_feats].skew(axis = 1)\n",
    "    tmp['c_sum'] = tmp[modc_feats].sum(axis = 1)\n",
    "    tmp['c_mean'] = tmp[modc_feats].mean(axis = 1)\n",
    "    tmp['c_std'] = tmp[modc_feats].std(axis = 1)\n",
    "    tmp['c_kurt'] = tmp[modc_feats].kurtosis(axis = 1)\n",
    "    tmp['c_skew'] = tmp[modc_feats].skew(axis = 1)\n",
    "    tmp['gc_sum'] = tmp[modc_feats + modg_feats].sum(axis = 1)\n",
    "    tmp['gc_mean'] = tmp[modc_feats + modg_feats].mean(axis = 1)\n",
    "    tmp['gc_std'] = tmp[modc_feats + modg_feats].std(axis = 1)\n",
    "    tmp['gc_kurt'] = tmp[modc_feats + modg_feats].kurtosis(axis = 1)\n",
    "    tmp['gc_skew'] = tmp[modc_feats + modg_feats].skew(axis = 1)\n",
    "    tmp = pd.get_dummies(tmp, columns=['cp_time','cp_dose'])\n",
    "    tmp.drop([\"cp_type\", \"sig_id\"], axis=1, inplace=True) \n",
    "    return tmp\n",
    "\n",
    "def fe_tabnet(df_train, df_test):\n",
    "    tmp_train = df_train.copy()\n",
    "    tmp_test = df_test.copy()\n",
    "    X = tmp_train.iloc[:,4:].copy().values\n",
    "    select = VarianceThreshold(threshold=0.7)\n",
    "    X_new = select.fit_transform(X)\n",
    "    drop_feats = list(np.array(tmp_train.iloc[:,4:].columns)[select.get_support()==False])\n",
    "    \n",
    "    tmp_train.drop(drop_feats, axis=1, inplace=True)\n",
    "    tmp_test.drop(drop_feats, axis=1, inplace=True)\n",
    "\n",
    "    modg_feats = [i for i in tmp_train.columns if \"g-\" in i]\n",
    "    modc_feats = [i for i in tmp_train.columns if \"c-\" in i]\n",
    "    \n",
    "    for i in modc_feats + modg_feats:\n",
    "        ss = preprocessing.QuantileTransformer(n_quantiles=1000, random_state=0, output_distribution=\"normal\")\n",
    "        ss.fit(tmp_train[i].values.reshape(-1,1))\n",
    "        tmp_train[i] = ss.transform(tmp_train[i].values.reshape(-1,1))\n",
    "        tmp_test[i] = ss.transform(tmp_test[i].values.reshape(-1,1))\n",
    "        \n",
    "    tmp_train = pd.get_dummies(tmp_train, columns=['cp_time','cp_dose'])\n",
    "    tmp_train.drop([\"cp_type\", \"sig_id\"], axis=1, inplace=True)\n",
    "    tmp_test = pd.get_dummies(tmp_test, columns=['cp_time','cp_dose'])\n",
    "    tmp_test.drop([\"cp_type\", \"sig_id\"], axis=1, inplace=True)\n",
    "    return tmp_train, tmp_test\n",
    "\n",
    "remove_features = [\"cp_type\" , \"sig_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T11:48:47.555602Z",
     "iopub.status.busy": "2020-10-27T11:48:47.554312Z",
     "iopub.status.idle": "2020-10-27T11:49:11.872593Z",
     "shell.execute_reply": "2020-10-27T11:49:11.873835Z"
    },
    "papermill": {
     "duration": 24.353744,
     "end_time": "2020-10-27T11:49:11.874027",
     "exception": false,
     "start_time": "2020-10-27T11:48:47.520283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fn_train = fe_simple(train, remove_features)\n",
    "fn_test = fe_simple(test, remove_features)\n",
    "\n",
    "# pytorch mlp -----------------------------------\n",
    "mlp_train, mlp_test = fe_mlp(train, test)\n",
    "mlp_train = fe_mlp2(mlp_train).to_numpy()\n",
    "mlp_test = fe_mlp2(mlp_test).to_numpy()\n",
    "\n",
    "# pytorch tabnet ----------------------------------\n",
    "py_train = fn_train.copy()\n",
    "py_test = fn_test.copy()\n",
    "\n",
    "ss = preprocessing.RobustScaler()\n",
    "py_train= ss.fit_transform(py_train)\n",
    "py_test = ss.transform(py_test)\n",
    "\n",
    "# svm-----------------------\n",
    "ss = preprocessing.StandardScaler()\n",
    "fn_train= ss.fit_transform(fn_train)\n",
    "fn_test = ss.transform(fn_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.039184,
     "end_time": "2020-10-27T11:49:11.956725",
     "exception": false,
     "start_time": "2020-10-27T11:49:11.917541",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1st pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T11:49:12.045959Z",
     "iopub.status.busy": "2020-10-27T11:49:12.044966Z",
     "iopub.status.idle": "2020-10-27T11:49:12.054237Z",
     "shell.execute_reply": "2020-10-27T11:49:12.055276Z"
    },
    "papermill": {
     "duration": 0.058718,
     "end_time": "2020-10-27T11:49:12.055434",
     "exception": false,
     "start_time": "2020-10-27T11:49:11.996716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SmoothCrossEntropyLoss(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets, n_classes, smoothing=0.0):\n",
    "        assert 0 <= smoothing <= 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1 - smoothing) + torch.ones_like(targets).to(device) * smoothing / n_classes\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothCrossEntropyLoss()._smooth(targets, inputs.shape[1], self.smoothing)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            inputs = inputs * self.weight.unsqueeze(0)\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T11:49:12.148419Z",
     "iopub.status.busy": "2020-10-27T11:49:12.137762Z",
     "iopub.status.idle": "2020-10-27T11:49:12.219704Z",
     "shell.execute_reply": "2020-10-27T11:49:12.220301Z"
    },
    "papermill": {
     "duration": 0.125554,
     "end_time": "2020-10-27T11:49:12.220456",
     "exception": false,
     "start_time": "2020-10-27T11:49:12.094902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 128\n",
    "n_folds=7\n",
    "train_epochs = 20\n",
    "smoothing = 0.001\n",
    "p_min = smoothing\n",
    "p_max = 1 - smoothing\n",
    "\n",
    "def mean_log_loss(y_true, y_pred):\n",
    "    metrics = []\n",
    "    for i, target in enumerate(target_feats):\n",
    "        metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float), labels=[0,1]))\n",
    "    return np.mean(metrics)\n",
    "\n",
    "def seed_everything(seed=1234): \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "class MoaModel(nn.Module):\n",
    "    def __init__(self, num_columns, last_num):\n",
    "        super(MoaModel, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_columns)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_columns, 1024))\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(1024)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(1024, 1024))\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(1024)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(1024, last_num))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu1(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.relu2(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "def modelling_torch(X_train, y_train, X_test, sample_seed, last_num):\n",
    "    seed_everything(seed=sample_seed) \n",
    "\n",
    "    test_len = X_test.shape[0]\n",
    "    \n",
    "    mskf=MultilabelStratifiedKFold(n_splits = n_folds, shuffle=True, random_state=224)\n",
    "    metric = lambda inputs, targets : F.binary_cross_entropy((torch.clamp(torch.sigmoid(inputs), p_min, p_max)), targets)\n",
    "\n",
    "    models = []\n",
    "    \n",
    "    X_test2 = torch.tensor(X_test, dtype=torch.float32)\n",
    "    test = torch.utils.data.TensorDataset(X_test2) \n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    oof = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    oof_targets = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    pred_value = np.zeros([test_len, y_train.shape[1]])\n",
    "    scores = []\n",
    "    for fold, (train_index, valid_index) in enumerate(mskf.split(X_train, y_train)):\n",
    "        print(\"Fold \"+str(fold+1))\n",
    "        X_train2 = torch.tensor(X_train[train_index,:], dtype=torch.float32)\n",
    "        X_valid2 = torch.tensor(X_train[valid_index,:], dtype=torch.float32)\n",
    "\n",
    "        y_train2 = torch.tensor(y_train[train_index], dtype=torch.float32)\n",
    "        y_valid2 = torch.tensor(y_train[valid_index], dtype=torch.float32)\n",
    "        \n",
    "        train = torch.utils.data.TensorDataset(X_train2, y_train2)\n",
    "        valid = torch.utils.data.TensorDataset(X_valid2, y_valid2)\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True) \n",
    "        valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "            \n",
    "        clf = MoaModel(mlp_train.shape[1], last_num)\n",
    "        loss_fn = SmoothCrossEntropyLoss(smoothing=smoothing)\n",
    "        \n",
    "        optimizer = optim.Adam(clf.parameters(), lr = 0.001, weight_decay=1e-5) \n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=train_epochs, steps_per_epoch=len(train_loader))\n",
    "        \n",
    "        clf.to(device)\n",
    "        \n",
    "        best_val_loss = np.inf\n",
    "        \n",
    "        for epoch in range(train_epochs):\n",
    "            clf.train()\n",
    "            sm_avg_loss = 0.\n",
    "            for x_batch, y_batch in tqdm(train_loader, disable=True):\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch) \n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                sm_avg_loss += metric(y_pred, y_batch) / len(train_loader) \n",
    "                \n",
    "            clf.eval()\n",
    "            sm_avg_val_loss = 0.\n",
    "            \n",
    "            for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch).detach()\n",
    "                sm_avg_val_loss += metric(y_pred, y_batch) / len(valid_loader)\n",
    "                            \n",
    "            if sm_avg_val_loss < best_val_loss:\n",
    "                best_val_loss = sm_avg_val_loss\n",
    "                print('Epoch {} sm_loss={:.5f}  sm_val_loss={:.5f}'.format(epoch + 1, sm_avg_loss, sm_avg_val_loss))\n",
    "                torch.save(clf.state_dict(), 'best-model-parameters.pt')\n",
    "                \n",
    "        pred_model = MoaModel(mlp_train.shape[1], last_num)\n",
    "        pred_model.load_state_dict(torch.load('best-model-parameters.pt'))         \n",
    "        pred_model.eval()\n",
    "        \n",
    "        # validation check ----------------\n",
    "        oof_epoch = np.zeros([X_valid2.size(0), y_train.shape[1]])\n",
    "        target_epoch = np.zeros([X_valid2.size(0), y_train.shape[1]])\n",
    "        for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "            y_pred = pred_model(x_batch).detach()\n",
    "            oof_epoch[i * batch_size:(i+1) * batch_size,:] = torch.clamp(torch.sigmoid(y_pred.cpu()), p_min, p_max)\n",
    "            target_epoch[i * batch_size:(i+1) * batch_size,:] = y_batch.cpu().numpy()\n",
    "        oof[valid_index,:] = oof_epoch\n",
    "        oof_targets[valid_index,:] = target_epoch\n",
    "        #-----------------------------------\n",
    "        \n",
    "        # test predcition --------------\n",
    "        test_preds = np.zeros([test_len, y_train.shape[1]])\n",
    "        for i, (x_batch,) in enumerate(test_loader): \n",
    "            y_pred = pred_model(x_batch).detach()\n",
    "            test_preds[i * batch_size:(i+1) * batch_size, :] = torch.clamp(torch.sigmoid(y_pred.cpu()), p_min, p_max)\n",
    "        pred_value += test_preds / n_folds\n",
    "        # ------------------------------\n",
    "        \n",
    "    print(\"Seed {}\".format(seed_))\n",
    "    print(\"Total log loss: {}\".format(mean_log_loss(oof_targets, oof)))\n",
    "    \n",
    "    return oof, pred_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T11:49:12.302170Z",
     "iopub.status.busy": "2020-10-27T11:49:12.301364Z",
     "iopub.status.idle": "2020-10-27T12:02:13.613049Z",
     "shell.execute_reply": "2020-10-27T12:02:13.612388Z"
    },
    "papermill": {
     "duration": 781.350881,
     "end_time": "2020-10-27T12:02:13.613188",
     "exception": false,
     "start_time": "2020-10-27T11:49:12.262307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1 sm_loss=0.41417  sm_val_loss=0.02222\n",
      "Epoch 2 sm_loss=0.02011  sm_val_loss=0.01953\n",
      "Epoch 3 sm_loss=0.01818  sm_val_loss=0.01902\n",
      "Epoch 4 sm_loss=0.01763  sm_val_loss=0.01781\n",
      "Epoch 5 sm_loss=0.01750  sm_val_loss=0.01770\n",
      "Epoch 6 sm_loss=0.01744  sm_val_loss=0.01759\n",
      "Epoch 7 sm_loss=0.01743  sm_val_loss=0.01740\n",
      "Epoch 8 sm_loss=0.01734  sm_val_loss=0.01735\n",
      "Epoch 11 sm_loss=0.01707  sm_val_loss=0.01709\n",
      "Epoch 12 sm_loss=0.01687  sm_val_loss=0.01680\n",
      "Epoch 13 sm_loss=0.01671  sm_val_loss=0.01674\n",
      "Epoch 14 sm_loss=0.01642  sm_val_loss=0.01673\n",
      "Epoch 15 sm_loss=0.01609  sm_val_loss=0.01636\n",
      "Epoch 16 sm_loss=0.01566  sm_val_loss=0.01632\n",
      "Epoch 17 sm_loss=0.01520  sm_val_loss=0.01608\n",
      "Epoch 18 sm_loss=0.01475  sm_val_loss=0.01598\n",
      "Epoch 19 sm_loss=0.01437  sm_val_loss=0.01595\n",
      "Epoch 20 sm_loss=0.01419  sm_val_loss=0.01592\n",
      "Fold 2\n",
      "Epoch 1 sm_loss=0.41399  sm_val_loss=0.02262\n",
      "Epoch 2 sm_loss=0.02004  sm_val_loss=0.02017\n",
      "Epoch 4 sm_loss=0.01781  sm_val_loss=0.01759\n",
      "Epoch 7 sm_loss=0.01742  sm_val_loss=0.01745\n",
      "Epoch 8 sm_loss=0.01737  sm_val_loss=0.01740\n",
      "Epoch 11 sm_loss=0.01709  sm_val_loss=0.01712\n",
      "Epoch 12 sm_loss=0.01686  sm_val_loss=0.01711\n",
      "Epoch 13 sm_loss=0.01666  sm_val_loss=0.01691\n",
      "Epoch 15 sm_loss=0.01607  sm_val_loss=0.01647\n",
      "Epoch 16 sm_loss=0.01561  sm_val_loss=0.01637\n",
      "Epoch 17 sm_loss=0.01516  sm_val_loss=0.01629\n",
      "Epoch 18 sm_loss=0.01472  sm_val_loss=0.01620\n",
      "Epoch 19 sm_loss=0.01431  sm_val_loss=0.01614\n",
      "Fold 3\n",
      "Epoch 1 sm_loss=0.41327  sm_val_loss=0.02234\n",
      "Epoch 2 sm_loss=0.02013  sm_val_loss=0.01860\n",
      "Epoch 3 sm_loss=0.01823  sm_val_loss=0.01806\n",
      "Epoch 4 sm_loss=0.01771  sm_val_loss=0.01723\n",
      "Epoch 6 sm_loss=0.01746  sm_val_loss=0.01707\n",
      "Epoch 10 sm_loss=0.01719  sm_val_loss=0.01691\n",
      "Epoch 11 sm_loss=0.01709  sm_val_loss=0.01670\n",
      "Epoch 13 sm_loss=0.01670  sm_val_loss=0.01643\n",
      "Epoch 14 sm_loss=0.01641  sm_val_loss=0.01634\n",
      "Epoch 15 sm_loss=0.01607  sm_val_loss=0.01615\n",
      "Epoch 16 sm_loss=0.01569  sm_val_loss=0.01598\n",
      "Epoch 17 sm_loss=0.01523  sm_val_loss=0.01591\n",
      "Epoch 18 sm_loss=0.01474  sm_val_loss=0.01582\n",
      "Epoch 19 sm_loss=0.01433  sm_val_loss=0.01572\n",
      "Fold 4\n",
      "Epoch 1 sm_loss=0.41474  sm_val_loss=0.02265\n",
      "Epoch 2 sm_loss=0.02026  sm_val_loss=0.01899\n",
      "Epoch 3 sm_loss=0.01819  sm_val_loss=0.01783\n",
      "Epoch 4 sm_loss=0.01763  sm_val_loss=0.01759\n",
      "Epoch 5 sm_loss=0.01744  sm_val_loss=0.01758\n",
      "Epoch 9 sm_loss=0.01728  sm_val_loss=0.01755\n",
      "Epoch 10 sm_loss=0.01717  sm_val_loss=0.01707\n",
      "Epoch 12 sm_loss=0.01680  sm_val_loss=0.01702\n",
      "Epoch 13 sm_loss=0.01665  sm_val_loss=0.01690\n",
      "Epoch 14 sm_loss=0.01628  sm_val_loss=0.01663\n",
      "Epoch 15 sm_loss=0.01605  sm_val_loss=0.01659\n",
      "Epoch 16 sm_loss=0.01558  sm_val_loss=0.01639\n",
      "Epoch 17 sm_loss=0.01509  sm_val_loss=0.01626\n",
      "Epoch 18 sm_loss=0.01463  sm_val_loss=0.01617\n",
      "Epoch 19 sm_loss=0.01422  sm_val_loss=0.01613\n",
      "Epoch 20 sm_loss=0.01398  sm_val_loss=0.01613\n",
      "Fold 5\n",
      "Epoch 1 sm_loss=0.41454  sm_val_loss=0.02291\n",
      "Epoch 2 sm_loss=0.02000  sm_val_loss=0.01854\n",
      "Epoch 3 sm_loss=0.01808  sm_val_loss=0.01815\n",
      "Epoch 4 sm_loss=0.01752  sm_val_loss=0.01771\n",
      "Epoch 8 sm_loss=0.01733  sm_val_loss=0.01769\n",
      "Epoch 9 sm_loss=0.01725  sm_val_loss=0.01764\n",
      "Epoch 10 sm_loss=0.01713  sm_val_loss=0.01755\n",
      "Epoch 11 sm_loss=0.01701  sm_val_loss=0.01733\n",
      "Epoch 13 sm_loss=0.01662  sm_val_loss=0.01710\n",
      "Epoch 14 sm_loss=0.01634  sm_val_loss=0.01686\n",
      "Epoch 15 sm_loss=0.01601  sm_val_loss=0.01664\n",
      "Epoch 16 sm_loss=0.01555  sm_val_loss=0.01654\n",
      "Epoch 17 sm_loss=0.01508  sm_val_loss=0.01645\n",
      "Epoch 18 sm_loss=0.01458  sm_val_loss=0.01637\n",
      "Epoch 19 sm_loss=0.01420  sm_val_loss=0.01631\n",
      "Fold 6\n",
      "Epoch 1 sm_loss=0.41390  sm_val_loss=0.02243\n",
      "Epoch 2 sm_loss=0.02009  sm_val_loss=0.01890\n",
      "Epoch 3 sm_loss=0.01825  sm_val_loss=0.01855\n",
      "Epoch 4 sm_loss=0.01764  sm_val_loss=0.01738\n",
      "Epoch 7 sm_loss=0.01742  sm_val_loss=0.01735\n",
      "Epoch 8 sm_loss=0.01740  sm_val_loss=0.01724\n",
      "Epoch 9 sm_loss=0.01738  sm_val_loss=0.01722\n",
      "Epoch 10 sm_loss=0.01727  sm_val_loss=0.01702\n",
      "Epoch 11 sm_loss=0.01706  sm_val_loss=0.01682\n",
      "Epoch 13 sm_loss=0.01675  sm_val_loss=0.01660\n",
      "Epoch 14 sm_loss=0.01646  sm_val_loss=0.01650\n",
      "Epoch 15 sm_loss=0.01611  sm_val_loss=0.01624\n",
      "Epoch 16 sm_loss=0.01578  sm_val_loss=0.01608\n",
      "Epoch 17 sm_loss=0.01530  sm_val_loss=0.01591\n",
      "Epoch 18 sm_loss=0.01483  sm_val_loss=0.01581\n",
      "Epoch 19 sm_loss=0.01448  sm_val_loss=0.01576\n",
      "Epoch 20 sm_loss=0.01428  sm_val_loss=0.01576\n",
      "Fold 7\n",
      "Epoch 1 sm_loss=0.41471  sm_val_loss=0.02247\n",
      "Epoch 2 sm_loss=0.02007  sm_val_loss=0.01854\n",
      "Epoch 3 sm_loss=0.01824  sm_val_loss=0.01780\n",
      "Epoch 4 sm_loss=0.01768  sm_val_loss=0.01753\n",
      "Epoch 5 sm_loss=0.01747  sm_val_loss=0.01750\n",
      "Epoch 8 sm_loss=0.01741  sm_val_loss=0.01728\n",
      "Epoch 10 sm_loss=0.01725  sm_val_loss=0.01708\n",
      "Epoch 11 sm_loss=0.01708  sm_val_loss=0.01707\n",
      "Epoch 12 sm_loss=0.01691  sm_val_loss=0.01689\n",
      "Epoch 13 sm_loss=0.01674  sm_val_loss=0.01682\n",
      "Epoch 14 sm_loss=0.01638  sm_val_loss=0.01651\n",
      "Epoch 15 sm_loss=0.01601  sm_val_loss=0.01632\n",
      "Epoch 16 sm_loss=0.01571  sm_val_loss=0.01622\n",
      "Epoch 17 sm_loss=0.01519  sm_val_loss=0.01611\n",
      "Epoch 18 sm_loss=0.01469  sm_val_loss=0.01602\n",
      "Epoch 19 sm_loss=0.01431  sm_val_loss=0.01597\n",
      "Epoch 20 sm_loss=0.01409  sm_val_loss=0.01596\n",
      "Seed 0\n",
      "Total log loss: 0.016019747647044533\n",
      "Fold 1\n",
      "Epoch 1 sm_loss=0.41406  sm_val_loss=0.02259\n",
      "Epoch 2 sm_loss=0.02008  sm_val_loss=0.01875\n",
      "Epoch 3 sm_loss=0.01814  sm_val_loss=0.01821\n",
      "Epoch 4 sm_loss=0.01764  sm_val_loss=0.01760\n",
      "Epoch 5 sm_loss=0.01741  sm_val_loss=0.01749\n",
      "Epoch 8 sm_loss=0.01739  sm_val_loss=0.01733\n",
      "Epoch 10 sm_loss=0.01723  sm_val_loss=0.01732\n",
      "Epoch 11 sm_loss=0.01704  sm_val_loss=0.01726\n",
      "Epoch 12 sm_loss=0.01695  sm_val_loss=0.01699\n",
      "Epoch 13 sm_loss=0.01667  sm_val_loss=0.01669\n",
      "Epoch 15 sm_loss=0.01604  sm_val_loss=0.01644\n",
      "Epoch 16 sm_loss=0.01573  sm_val_loss=0.01623\n",
      "Epoch 17 sm_loss=0.01526  sm_val_loss=0.01612\n",
      "Epoch 18 sm_loss=0.01478  sm_val_loss=0.01604\n",
      "Epoch 19 sm_loss=0.01440  sm_val_loss=0.01595\n",
      "Fold 2\n",
      "Epoch 1 sm_loss=0.41428  sm_val_loss=0.02257\n",
      "Epoch 2 sm_loss=0.02041  sm_val_loss=0.01965\n",
      "Epoch 3 sm_loss=0.01836  sm_val_loss=0.01791\n",
      "Epoch 5 sm_loss=0.01759  sm_val_loss=0.01762\n",
      "Epoch 6 sm_loss=0.01751  sm_val_loss=0.01755\n",
      "Epoch 9 sm_loss=0.01735  sm_val_loss=0.01721\n",
      "Epoch 12 sm_loss=0.01688  sm_val_loss=0.01697\n",
      "Epoch 14 sm_loss=0.01641  sm_val_loss=0.01671\n",
      "Epoch 15 sm_loss=0.01604  sm_val_loss=0.01651\n",
      "Epoch 16 sm_loss=0.01567  sm_val_loss=0.01632\n",
      "Epoch 17 sm_loss=0.01516  sm_val_loss=0.01629\n",
      "Epoch 18 sm_loss=0.01471  sm_val_loss=0.01613\n",
      "Epoch 19 sm_loss=0.01429  sm_val_loss=0.01610\n",
      "Epoch 20 sm_loss=0.01407  sm_val_loss=0.01608\n",
      "Fold 3\n",
      "Epoch 1 sm_loss=0.41425  sm_val_loss=0.02221\n",
      "Epoch 2 sm_loss=0.02001  sm_val_loss=0.01817\n",
      "Epoch 3 sm_loss=0.01825  sm_val_loss=0.01739\n",
      "Epoch 4 sm_loss=0.01763  sm_val_loss=0.01736\n",
      "Epoch 6 sm_loss=0.01754  sm_val_loss=0.01725\n",
      "Epoch 8 sm_loss=0.01742  sm_val_loss=0.01714\n",
      "Epoch 9 sm_loss=0.01735  sm_val_loss=0.01711\n",
      "Epoch 10 sm_loss=0.01724  sm_val_loss=0.01706\n",
      "Epoch 11 sm_loss=0.01718  sm_val_loss=0.01695\n",
      "Epoch 12 sm_loss=0.01690  sm_val_loss=0.01663\n",
      "Epoch 13 sm_loss=0.01673  sm_val_loss=0.01641\n",
      "Epoch 14 sm_loss=0.01644  sm_val_loss=0.01628\n",
      "Epoch 15 sm_loss=0.01606  sm_val_loss=0.01617\n",
      "Epoch 16 sm_loss=0.01564  sm_val_loss=0.01604\n",
      "Epoch 17 sm_loss=0.01521  sm_val_loss=0.01585\n",
      "Epoch 18 sm_loss=0.01473  sm_val_loss=0.01582\n",
      "Epoch 19 sm_loss=0.01434  sm_val_loss=0.01578\n",
      "Epoch 20 sm_loss=0.01411  sm_val_loss=0.01574\n",
      "Fold 4\n",
      "Epoch 1 sm_loss=0.41363  sm_val_loss=0.02255\n",
      "Epoch 2 sm_loss=0.02003  sm_val_loss=0.01884\n",
      "Epoch 3 sm_loss=0.01806  sm_val_loss=0.01802\n",
      "Epoch 4 sm_loss=0.01760  sm_val_loss=0.01797\n",
      "Epoch 5 sm_loss=0.01740  sm_val_loss=0.01777\n",
      "Epoch 6 sm_loss=0.01737  sm_val_loss=0.01750\n",
      "Epoch 8 sm_loss=0.01738  sm_val_loss=0.01711\n",
      "Epoch 13 sm_loss=0.01659  sm_val_loss=0.01687\n",
      "Epoch 14 sm_loss=0.01637  sm_val_loss=0.01667\n",
      "Epoch 15 sm_loss=0.01607  sm_val_loss=0.01661\n",
      "Epoch 16 sm_loss=0.01564  sm_val_loss=0.01643\n",
      "Epoch 17 sm_loss=0.01519  sm_val_loss=0.01633\n",
      "Epoch 18 sm_loss=0.01472  sm_val_loss=0.01618\n",
      "Epoch 19 sm_loss=0.01432  sm_val_loss=0.01612\n",
      "Fold 5\n",
      "Epoch 1 sm_loss=0.41480  sm_val_loss=0.02265\n",
      "Epoch 2 sm_loss=0.02000  sm_val_loss=0.01896\n",
      "Epoch 3 sm_loss=0.01819  sm_val_loss=0.01833\n",
      "Epoch 4 sm_loss=0.01755  sm_val_loss=0.01783\n",
      "Epoch 5 sm_loss=0.01743  sm_val_loss=0.01764\n",
      "Epoch 11 sm_loss=0.01708  sm_val_loss=0.01749\n",
      "Epoch 12 sm_loss=0.01685  sm_val_loss=0.01723\n",
      "Epoch 13 sm_loss=0.01662  sm_val_loss=0.01709\n",
      "Epoch 14 sm_loss=0.01637  sm_val_loss=0.01682\n",
      "Epoch 15 sm_loss=0.01602  sm_val_loss=0.01678\n",
      "Epoch 16 sm_loss=0.01564  sm_val_loss=0.01660\n",
      "Epoch 17 sm_loss=0.01522  sm_val_loss=0.01645\n",
      "Epoch 18 sm_loss=0.01477  sm_val_loss=0.01634\n",
      "Epoch 19 sm_loss=0.01439  sm_val_loss=0.01631\n",
      "Fold 6\n",
      "Epoch 1 sm_loss=0.41438  sm_val_loss=0.02245\n",
      "Epoch 2 sm_loss=0.02007  sm_val_loss=0.01876\n",
      "Epoch 3 sm_loss=0.01855  sm_val_loss=0.01770\n",
      "Epoch 4 sm_loss=0.01766  sm_val_loss=0.01750\n",
      "Epoch 6 sm_loss=0.01756  sm_val_loss=0.01739\n",
      "Epoch 7 sm_loss=0.01752  sm_val_loss=0.01730\n",
      "Epoch 9 sm_loss=0.01734  sm_val_loss=0.01716\n",
      "Epoch 10 sm_loss=0.01723  sm_val_loss=0.01714\n",
      "Epoch 11 sm_loss=0.01714  sm_val_loss=0.01688\n",
      "Epoch 12 sm_loss=0.01693  sm_val_loss=0.01683\n",
      "Epoch 13 sm_loss=0.01666  sm_val_loss=0.01669\n",
      "Epoch 14 sm_loss=0.01650  sm_val_loss=0.01649\n",
      "Epoch 15 sm_loss=0.01611  sm_val_loss=0.01637\n",
      "Epoch 16 sm_loss=0.01579  sm_val_loss=0.01617\n",
      "Epoch 17 sm_loss=0.01533  sm_val_loss=0.01599\n",
      "Epoch 18 sm_loss=0.01487  sm_val_loss=0.01588\n",
      "Epoch 19 sm_loss=0.01450  sm_val_loss=0.01580\n",
      "Fold 7\n",
      "Epoch 1 sm_loss=0.41382  sm_val_loss=0.02258\n",
      "Epoch 2 sm_loss=0.02019  sm_val_loss=0.01870\n",
      "Epoch 3 sm_loss=0.01818  sm_val_loss=0.01759\n",
      "Epoch 4 sm_loss=0.01759  sm_val_loss=0.01755\n",
      "Epoch 6 sm_loss=0.01750  sm_val_loss=0.01739\n",
      "Epoch 7 sm_loss=0.01743  sm_val_loss=0.01738\n",
      "Epoch 8 sm_loss=0.01739  sm_val_loss=0.01734\n",
      "Epoch 11 sm_loss=0.01712  sm_val_loss=0.01724\n",
      "Epoch 12 sm_loss=0.01690  sm_val_loss=0.01695\n",
      "Epoch 13 sm_loss=0.01666  sm_val_loss=0.01667\n",
      "Epoch 14 sm_loss=0.01641  sm_val_loss=0.01658\n",
      "Epoch 15 sm_loss=0.01609  sm_val_loss=0.01638\n",
      "Epoch 16 sm_loss=0.01566  sm_val_loss=0.01633\n",
      "Epoch 17 sm_loss=0.01523  sm_val_loss=0.01609\n",
      "Epoch 18 sm_loss=0.01475  sm_val_loss=0.01603\n",
      "Epoch 19 sm_loss=0.01437  sm_val_loss=0.01600\n",
      "Seed 1\n",
      "Total log loss: 0.01602759954171412\n",
      "Fold 1\n",
      "Epoch 1 sm_loss=0.41478  sm_val_loss=0.02309\n",
      "Epoch 2 sm_loss=0.02020  sm_val_loss=0.01892\n",
      "Epoch 3 sm_loss=0.01807  sm_val_loss=0.01786\n",
      "Epoch 5 sm_loss=0.01740  sm_val_loss=0.01766\n",
      "Epoch 6 sm_loss=0.01742  sm_val_loss=0.01750\n",
      "Epoch 8 sm_loss=0.01731  sm_val_loss=0.01745\n",
      "Epoch 9 sm_loss=0.01726  sm_val_loss=0.01733\n",
      "Epoch 12 sm_loss=0.01688  sm_val_loss=0.01695\n",
      "Epoch 13 sm_loss=0.01665  sm_val_loss=0.01682\n",
      "Epoch 14 sm_loss=0.01634  sm_val_loss=0.01664\n",
      "Epoch 15 sm_loss=0.01603  sm_val_loss=0.01645\n",
      "Epoch 16 sm_loss=0.01557  sm_val_loss=0.01626\n",
      "Epoch 17 sm_loss=0.01515  sm_val_loss=0.01611\n",
      "Epoch 18 sm_loss=0.01467  sm_val_loss=0.01602\n",
      "Epoch 19 sm_loss=0.01422  sm_val_loss=0.01595\n",
      "Fold 2\n",
      "Epoch 1 sm_loss=0.41456  sm_val_loss=0.02264\n",
      "Epoch 2 sm_loss=0.02006  sm_val_loss=0.01966\n",
      "Epoch 3 sm_loss=0.01812  sm_val_loss=0.01795\n",
      "Epoch 4 sm_loss=0.01755  sm_val_loss=0.01789\n",
      "Epoch 5 sm_loss=0.01748  sm_val_loss=0.01773\n",
      "Epoch 8 sm_loss=0.01744  sm_val_loss=0.01752\n",
      "Epoch 10 sm_loss=0.01722  sm_val_loss=0.01721\n",
      "Epoch 11 sm_loss=0.01709  sm_val_loss=0.01717\n",
      "Epoch 13 sm_loss=0.01664  sm_val_loss=0.01696\n",
      "Epoch 14 sm_loss=0.01640  sm_val_loss=0.01661\n",
      "Epoch 15 sm_loss=0.01609  sm_val_loss=0.01654\n",
      "Epoch 16 sm_loss=0.01571  sm_val_loss=0.01640\n",
      "Epoch 17 sm_loss=0.01521  sm_val_loss=0.01628\n",
      "Epoch 18 sm_loss=0.01476  sm_val_loss=0.01622\n",
      "Epoch 19 sm_loss=0.01438  sm_val_loss=0.01614\n",
      "Epoch 20 sm_loss=0.01419  sm_val_loss=0.01612\n",
      "Fold 3\n",
      "Epoch 1 sm_loss=0.41348  sm_val_loss=0.02245\n",
      "Epoch 2 sm_loss=0.02000  sm_val_loss=0.01825\n",
      "Epoch 3 sm_loss=0.01824  sm_val_loss=0.01755\n",
      "Epoch 4 sm_loss=0.01770  sm_val_loss=0.01739\n",
      "Epoch 5 sm_loss=0.01754  sm_val_loss=0.01733\n",
      "Epoch 6 sm_loss=0.01757  sm_val_loss=0.01721\n",
      "Epoch 7 sm_loss=0.01752  sm_val_loss=0.01719\n",
      "Epoch 8 sm_loss=0.01750  sm_val_loss=0.01714\n",
      "Epoch 9 sm_loss=0.01738  sm_val_loss=0.01703\n",
      "Epoch 10 sm_loss=0.01729  sm_val_loss=0.01693\n",
      "Epoch 11 sm_loss=0.01716  sm_val_loss=0.01681\n",
      "Epoch 12 sm_loss=0.01698  sm_val_loss=0.01657\n",
      "Epoch 14 sm_loss=0.01652  sm_val_loss=0.01634\n",
      "Epoch 15 sm_loss=0.01619  sm_val_loss=0.01623\n",
      "Epoch 16 sm_loss=0.01580  sm_val_loss=0.01601\n",
      "Epoch 17 sm_loss=0.01536  sm_val_loss=0.01586\n",
      "Epoch 18 sm_loss=0.01496  sm_val_loss=0.01575\n",
      "Epoch 19 sm_loss=0.01460  sm_val_loss=0.01574\n",
      "Epoch 20 sm_loss=0.01441  sm_val_loss=0.01573\n",
      "Fold 4\n",
      "Epoch 1 sm_loss=0.41455  sm_val_loss=0.02231\n",
      "Epoch 2 sm_loss=0.02003  sm_val_loss=0.01863\n",
      "Epoch 3 sm_loss=0.01818  sm_val_loss=0.01835\n",
      "Epoch 4 sm_loss=0.01752  sm_val_loss=0.01828\n",
      "Epoch 5 sm_loss=0.01745  sm_val_loss=0.01768\n",
      "Epoch 6 sm_loss=0.01744  sm_val_loss=0.01749\n",
      "Epoch 8 sm_loss=0.01740  sm_val_loss=0.01738\n",
      "Epoch 10 sm_loss=0.01718  sm_val_loss=0.01732\n",
      "Epoch 11 sm_loss=0.01701  sm_val_loss=0.01725\n",
      "Epoch 12 sm_loss=0.01681  sm_val_loss=0.01707\n",
      "Epoch 13 sm_loss=0.01664  sm_val_loss=0.01704\n",
      "Epoch 14 sm_loss=0.01633  sm_val_loss=0.01674\n",
      "Epoch 15 sm_loss=0.01600  sm_val_loss=0.01657\n",
      "Epoch 16 sm_loss=0.01564  sm_val_loss=0.01652\n",
      "Epoch 17 sm_loss=0.01516  sm_val_loss=0.01632\n",
      "Epoch 18 sm_loss=0.01470  sm_val_loss=0.01621\n",
      "Epoch 19 sm_loss=0.01432  sm_val_loss=0.01617\n",
      "Epoch 20 sm_loss=0.01414  sm_val_loss=0.01614\n",
      "Fold 5\n",
      "Epoch 1 sm_loss=0.41370  sm_val_loss=0.02295\n",
      "Epoch 2 sm_loss=0.02015  sm_val_loss=0.02016\n",
      "Epoch 3 sm_loss=0.01823  sm_val_loss=0.01784\n",
      "Epoch 5 sm_loss=0.01744  sm_val_loss=0.01762\n",
      "Epoch 9 sm_loss=0.01721  sm_val_loss=0.01756\n",
      "Epoch 10 sm_loss=0.01717  sm_val_loss=0.01743\n",
      "Epoch 11 sm_loss=0.01705  sm_val_loss=0.01725\n",
      "Epoch 12 sm_loss=0.01679  sm_val_loss=0.01721\n",
      "Epoch 13 sm_loss=0.01662  sm_val_loss=0.01699\n",
      "Epoch 15 sm_loss=0.01606  sm_val_loss=0.01667\n",
      "Epoch 16 sm_loss=0.01565  sm_val_loss=0.01656\n",
      "Epoch 17 sm_loss=0.01521  sm_val_loss=0.01639\n",
      "Epoch 18 sm_loss=0.01477  sm_val_loss=0.01639\n",
      "Epoch 19 sm_loss=0.01440  sm_val_loss=0.01630\n",
      "Epoch 20 sm_loss=0.01418  sm_val_loss=0.01630\n",
      "Fold 6\n",
      "Epoch 1 sm_loss=0.41409  sm_val_loss=0.02212\n",
      "Epoch 2 sm_loss=0.02030  sm_val_loss=0.01864\n",
      "Epoch 3 sm_loss=0.01817  sm_val_loss=0.01765\n",
      "Epoch 4 sm_loss=0.01761  sm_val_loss=0.01746\n",
      "Epoch 7 sm_loss=0.01745  sm_val_loss=0.01741\n",
      "Epoch 9 sm_loss=0.01743  sm_val_loss=0.01735\n",
      "Epoch 10 sm_loss=0.01731  sm_val_loss=0.01710\n",
      "Epoch 12 sm_loss=0.01697  sm_val_loss=0.01684\n",
      "Epoch 13 sm_loss=0.01676  sm_val_loss=0.01654\n",
      "Epoch 14 sm_loss=0.01645  sm_val_loss=0.01645\n",
      "Epoch 15 sm_loss=0.01622  sm_val_loss=0.01628\n",
      "Epoch 16 sm_loss=0.01578  sm_val_loss=0.01613\n",
      "Epoch 17 sm_loss=0.01540  sm_val_loss=0.01598\n",
      "Epoch 18 sm_loss=0.01492  sm_val_loss=0.01586\n",
      "Epoch 19 sm_loss=0.01454  sm_val_loss=0.01581\n",
      "Fold 7\n",
      "Epoch 1 sm_loss=0.41460  sm_val_loss=0.02264\n",
      "Epoch 2 sm_loss=0.02007  sm_val_loss=0.01872\n",
      "Epoch 3 sm_loss=0.01818  sm_val_loss=0.01775\n",
      "Epoch 4 sm_loss=0.01762  sm_val_loss=0.01770\n",
      "Epoch 5 sm_loss=0.01752  sm_val_loss=0.01741\n",
      "Epoch 8 sm_loss=0.01739  sm_val_loss=0.01740\n",
      "Epoch 9 sm_loss=0.01728  sm_val_loss=0.01726\n",
      "Epoch 10 sm_loss=0.01724  sm_val_loss=0.01724\n",
      "Epoch 11 sm_loss=0.01702  sm_val_loss=0.01697\n",
      "Epoch 12 sm_loss=0.01693  sm_val_loss=0.01693\n",
      "Epoch 13 sm_loss=0.01669  sm_val_loss=0.01669\n",
      "Epoch 14 sm_loss=0.01633  sm_val_loss=0.01654\n",
      "Epoch 15 sm_loss=0.01601  sm_val_loss=0.01645\n",
      "Epoch 16 sm_loss=0.01562  sm_val_loss=0.01623\n",
      "Epoch 17 sm_loss=0.01521  sm_val_loss=0.01616\n",
      "Epoch 18 sm_loss=0.01470  sm_val_loss=0.01603\n",
      "Epoch 19 sm_loss=0.01436  sm_val_loss=0.01597\n",
      "Epoch 20 sm_loss=0.01412  sm_val_loss=0.01596\n",
      "Seed 2\n",
      "Total log loss: 0.016031838518680914\n",
      "Fold 1\n",
      "Epoch 1 sm_loss=0.41534  sm_val_loss=0.02231\n",
      "Epoch 2 sm_loss=0.01989  sm_val_loss=0.01894\n",
      "Epoch 3 sm_loss=0.01799  sm_val_loss=0.01773\n",
      "Epoch 6 sm_loss=0.01745  sm_val_loss=0.01761\n",
      "Epoch 7 sm_loss=0.01747  sm_val_loss=0.01747\n",
      "Epoch 9 sm_loss=0.01736  sm_val_loss=0.01737\n",
      "Epoch 11 sm_loss=0.01708  sm_val_loss=0.01736\n",
      "Epoch 12 sm_loss=0.01689  sm_val_loss=0.01696\n",
      "Epoch 13 sm_loss=0.01669  sm_val_loss=0.01676\n",
      "Epoch 14 sm_loss=0.01645  sm_val_loss=0.01666\n",
      "Epoch 15 sm_loss=0.01608  sm_val_loss=0.01655\n",
      "Epoch 16 sm_loss=0.01572  sm_val_loss=0.01632\n",
      "Epoch 17 sm_loss=0.01524  sm_val_loss=0.01609\n",
      "Epoch 18 sm_loss=0.01480  sm_val_loss=0.01602\n",
      "Epoch 19 sm_loss=0.01443  sm_val_loss=0.01596\n",
      "Epoch 20 sm_loss=0.01422  sm_val_loss=0.01595\n",
      "Fold 2\n",
      "Epoch 1 sm_loss=0.41378  sm_val_loss=0.02261\n",
      "Epoch 2 sm_loss=0.02012  sm_val_loss=0.01925\n",
      "Epoch 3 sm_loss=0.01806  sm_val_loss=0.01794\n",
      "Epoch 4 sm_loss=0.01758  sm_val_loss=0.01769\n",
      "Epoch 5 sm_loss=0.01752  sm_val_loss=0.01764\n",
      "Epoch 8 sm_loss=0.01739  sm_val_loss=0.01743\n",
      "Epoch 11 sm_loss=0.01706  sm_val_loss=0.01723\n",
      "Epoch 12 sm_loss=0.01689  sm_val_loss=0.01703\n",
      "Epoch 13 sm_loss=0.01665  sm_val_loss=0.01699\n",
      "Epoch 14 sm_loss=0.01641  sm_val_loss=0.01675\n",
      "Epoch 15 sm_loss=0.01609  sm_val_loss=0.01668\n",
      "Epoch 16 sm_loss=0.01567  sm_val_loss=0.01636\n",
      "Epoch 17 sm_loss=0.01528  sm_val_loss=0.01630\n",
      "Epoch 18 sm_loss=0.01475  sm_val_loss=0.01619\n",
      "Epoch 19 sm_loss=0.01436  sm_val_loss=0.01617\n",
      "Epoch 20 sm_loss=0.01415  sm_val_loss=0.01616\n",
      "Fold 3\n",
      "Epoch 1 sm_loss=0.41496  sm_val_loss=0.02223\n",
      "Epoch 2 sm_loss=0.02010  sm_val_loss=0.02017\n",
      "Epoch 3 sm_loss=0.01825  sm_val_loss=0.01754\n",
      "Epoch 4 sm_loss=0.01756  sm_val_loss=0.01724\n",
      "Epoch 6 sm_loss=0.01747  sm_val_loss=0.01705\n",
      "Epoch 10 sm_loss=0.01720  sm_val_loss=0.01704\n",
      "Epoch 11 sm_loss=0.01711  sm_val_loss=0.01671\n",
      "Epoch 13 sm_loss=0.01665  sm_val_loss=0.01647\n",
      "Epoch 14 sm_loss=0.01649  sm_val_loss=0.01629\n",
      "Epoch 15 sm_loss=0.01606  sm_val_loss=0.01620\n",
      "Epoch 16 sm_loss=0.01570  sm_val_loss=0.01605\n",
      "Epoch 17 sm_loss=0.01525  sm_val_loss=0.01591\n",
      "Epoch 18 sm_loss=0.01477  sm_val_loss=0.01578\n",
      "Epoch 19 sm_loss=0.01440  sm_val_loss=0.01577\n",
      "Epoch 20 sm_loss=0.01419  sm_val_loss=0.01575\n",
      "Fold 4\n",
      "Epoch 1 sm_loss=0.41302  sm_val_loss=0.02299\n",
      "Epoch 2 sm_loss=0.02002  sm_val_loss=0.02096\n",
      "Epoch 3 sm_loss=0.01845  sm_val_loss=0.01824\n",
      "Epoch 4 sm_loss=0.01767  sm_val_loss=0.01764\n",
      "Epoch 6 sm_loss=0.01741  sm_val_loss=0.01759\n",
      "Epoch 8 sm_loss=0.01742  sm_val_loss=0.01747\n",
      "Epoch 9 sm_loss=0.01734  sm_val_loss=0.01740\n",
      "Epoch 10 sm_loss=0.01718  sm_val_loss=0.01733\n",
      "Epoch 11 sm_loss=0.01704  sm_val_loss=0.01721\n",
      "Epoch 12 sm_loss=0.01689  sm_val_loss=0.01716\n",
      "Epoch 13 sm_loss=0.01660  sm_val_loss=0.01678\n",
      "Epoch 15 sm_loss=0.01607  sm_val_loss=0.01666\n",
      "Epoch 16 sm_loss=0.01567  sm_val_loss=0.01648\n",
      "Epoch 17 sm_loss=0.01527  sm_val_loss=0.01623\n",
      "Epoch 18 sm_loss=0.01477  sm_val_loss=0.01618\n",
      "Epoch 19 sm_loss=0.01435  sm_val_loss=0.01615\n",
      "Fold 5\n",
      "Epoch 1 sm_loss=0.41413  sm_val_loss=0.02258\n",
      "Epoch 2 sm_loss=0.02008  sm_val_loss=0.01920\n",
      "Epoch 3 sm_loss=0.01822  sm_val_loss=0.01871\n",
      "Epoch 4 sm_loss=0.01749  sm_val_loss=0.01788\n",
      "Epoch 5 sm_loss=0.01749  sm_val_loss=0.01778\n",
      "Epoch 6 sm_loss=0.01743  sm_val_loss=0.01767\n",
      "Epoch 9 sm_loss=0.01730  sm_val_loss=0.01762\n",
      "Epoch 10 sm_loss=0.01716  sm_val_loss=0.01753\n",
      "Epoch 11 sm_loss=0.01706  sm_val_loss=0.01733\n",
      "Epoch 13 sm_loss=0.01666  sm_val_loss=0.01702\n",
      "Epoch 14 sm_loss=0.01636  sm_val_loss=0.01689\n",
      "Epoch 15 sm_loss=0.01600  sm_val_loss=0.01676\n",
      "Epoch 16 sm_loss=0.01563  sm_val_loss=0.01655\n",
      "Epoch 17 sm_loss=0.01520  sm_val_loss=0.01647\n",
      "Epoch 18 sm_loss=0.01475  sm_val_loss=0.01637\n",
      "Epoch 19 sm_loss=0.01438  sm_val_loss=0.01632\n",
      "Fold 6\n",
      "Epoch 1 sm_loss=0.41444  sm_val_loss=0.02202\n",
      "Epoch 2 sm_loss=0.02005  sm_val_loss=0.01875\n",
      "Epoch 3 sm_loss=0.01826  sm_val_loss=0.01735\n",
      "Epoch 9 sm_loss=0.01732  sm_val_loss=0.01705\n",
      "Epoch 11 sm_loss=0.01713  sm_val_loss=0.01700\n",
      "Epoch 12 sm_loss=0.01695  sm_val_loss=0.01697\n",
      "Epoch 13 sm_loss=0.01676  sm_val_loss=0.01656\n",
      "Epoch 15 sm_loss=0.01612  sm_val_loss=0.01636\n",
      "Epoch 16 sm_loss=0.01578  sm_val_loss=0.01609\n",
      "Epoch 17 sm_loss=0.01537  sm_val_loss=0.01595\n",
      "Epoch 18 sm_loss=0.01488  sm_val_loss=0.01586\n",
      "Epoch 19 sm_loss=0.01450  sm_val_loss=0.01581\n",
      "Fold 7\n",
      "Epoch 1 sm_loss=0.41483  sm_val_loss=0.02235\n",
      "Epoch 2 sm_loss=0.02015  sm_val_loss=0.01904\n",
      "Epoch 3 sm_loss=0.01819  sm_val_loss=0.01764\n",
      "Epoch 4 sm_loss=0.01755  sm_val_loss=0.01748\n",
      "Epoch 5 sm_loss=0.01748  sm_val_loss=0.01738\n",
      "Epoch 10 sm_loss=0.01715  sm_val_loss=0.01721\n",
      "Epoch 11 sm_loss=0.01707  sm_val_loss=0.01707\n",
      "Epoch 12 sm_loss=0.01690  sm_val_loss=0.01681\n",
      "Epoch 14 sm_loss=0.01640  sm_val_loss=0.01665\n",
      "Epoch 15 sm_loss=0.01610  sm_val_loss=0.01646\n",
      "Epoch 16 sm_loss=0.01568  sm_val_loss=0.01619\n",
      "Epoch 17 sm_loss=0.01524  sm_val_loss=0.01607\n",
      "Epoch 18 sm_loss=0.01477  sm_val_loss=0.01598\n",
      "Epoch 19 sm_loss=0.01441  sm_val_loss=0.01592\n",
      "Seed 3\n",
      "Total log loss: 0.016037907744538272\n",
      "Fold 1\n",
      "Epoch 1 sm_loss=0.41379  sm_val_loss=0.02282\n",
      "Epoch 2 sm_loss=0.02008  sm_val_loss=0.01954\n",
      "Epoch 3 sm_loss=0.01812  sm_val_loss=0.01798\n",
      "Epoch 4 sm_loss=0.01750  sm_val_loss=0.01761\n",
      "Epoch 5 sm_loss=0.01739  sm_val_loss=0.01747\n",
      "Epoch 10 sm_loss=0.01713  sm_val_loss=0.01707\n",
      "Epoch 12 sm_loss=0.01686  sm_val_loss=0.01704\n",
      "Epoch 13 sm_loss=0.01667  sm_val_loss=0.01674\n",
      "Epoch 14 sm_loss=0.01639  sm_val_loss=0.01661\n",
      "Epoch 15 sm_loss=0.01606  sm_val_loss=0.01645\n",
      "Epoch 16 sm_loss=0.01564  sm_val_loss=0.01626\n",
      "Epoch 17 sm_loss=0.01520  sm_val_loss=0.01611\n",
      "Epoch 18 sm_loss=0.01471  sm_val_loss=0.01598\n",
      "Epoch 19 sm_loss=0.01433  sm_val_loss=0.01597\n",
      "Fold 2\n",
      "Epoch 1 sm_loss=0.41524  sm_val_loss=0.02247\n",
      "Epoch 2 sm_loss=0.01994  sm_val_loss=0.01952\n",
      "Epoch 3 sm_loss=0.01807  sm_val_loss=0.01794\n",
      "Epoch 4 sm_loss=0.01757  sm_val_loss=0.01786\n",
      "Epoch 5 sm_loss=0.01748  sm_val_loss=0.01774\n",
      "Epoch 6 sm_loss=0.01745  sm_val_loss=0.01756\n",
      "Epoch 10 sm_loss=0.01724  sm_val_loss=0.01719\n",
      "Epoch 12 sm_loss=0.01688  sm_val_loss=0.01703\n",
      "Epoch 13 sm_loss=0.01670  sm_val_loss=0.01698\n",
      "Epoch 14 sm_loss=0.01639  sm_val_loss=0.01676\n",
      "Epoch 15 sm_loss=0.01604  sm_val_loss=0.01662\n",
      "Epoch 16 sm_loss=0.01569  sm_val_loss=0.01645\n",
      "Epoch 17 sm_loss=0.01522  sm_val_loss=0.01628\n",
      "Epoch 18 sm_loss=0.01475  sm_val_loss=0.01620\n",
      "Epoch 19 sm_loss=0.01434  sm_val_loss=0.01617\n",
      "Fold 3\n",
      "Epoch 1 sm_loss=0.41405  sm_val_loss=0.02261\n",
      "Epoch 2 sm_loss=0.02014  sm_val_loss=0.01858\n",
      "Epoch 3 sm_loss=0.01821  sm_val_loss=0.01788\n",
      "Epoch 4 sm_loss=0.01774  sm_val_loss=0.01737\n",
      "Epoch 6 sm_loss=0.01748  sm_val_loss=0.01731\n",
      "Epoch 8 sm_loss=0.01743  sm_val_loss=0.01707\n",
      "Epoch 9 sm_loss=0.01731  sm_val_loss=0.01704\n",
      "Epoch 10 sm_loss=0.01726  sm_val_loss=0.01676\n",
      "Epoch 11 sm_loss=0.01706  sm_val_loss=0.01672\n",
      "Epoch 12 sm_loss=0.01694  sm_val_loss=0.01671\n",
      "Epoch 13 sm_loss=0.01666  sm_val_loss=0.01649\n",
      "Epoch 14 sm_loss=0.01641  sm_val_loss=0.01637\n",
      "Epoch 15 sm_loss=0.01606  sm_val_loss=0.01616\n",
      "Epoch 16 sm_loss=0.01568  sm_val_loss=0.01601\n",
      "Epoch 17 sm_loss=0.01528  sm_val_loss=0.01580\n",
      "Epoch 18 sm_loss=0.01479  sm_val_loss=0.01579\n",
      "Epoch 19 sm_loss=0.01441  sm_val_loss=0.01570\n",
      "Fold 4\n",
      "Epoch 1 sm_loss=0.41399  sm_val_loss=0.02237\n",
      "Epoch 2 sm_loss=0.02001  sm_val_loss=0.01914\n",
      "Epoch 3 sm_loss=0.01812  sm_val_loss=0.01852\n",
      "Epoch 4 sm_loss=0.01770  sm_val_loss=0.01747\n",
      "Epoch 10 sm_loss=0.01717  sm_val_loss=0.01717\n",
      "Epoch 12 sm_loss=0.01685  sm_val_loss=0.01694\n",
      "Epoch 13 sm_loss=0.01661  sm_val_loss=0.01671\n",
      "Epoch 15 sm_loss=0.01602  sm_val_loss=0.01665\n",
      "Epoch 16 sm_loss=0.01563  sm_val_loss=0.01646\n",
      "Epoch 17 sm_loss=0.01513  sm_val_loss=0.01634\n",
      "Epoch 18 sm_loss=0.01468  sm_val_loss=0.01616\n",
      "Epoch 19 sm_loss=0.01430  sm_val_loss=0.01611\n",
      "Epoch 20 sm_loss=0.01408  sm_val_loss=0.01611\n",
      "Fold 5\n",
      "Epoch 1 sm_loss=0.41480  sm_val_loss=0.02310\n",
      "Epoch 2 sm_loss=0.02002  sm_val_loss=0.01839\n",
      "Epoch 3 sm_loss=0.01841  sm_val_loss=0.01785\n",
      "Epoch 6 sm_loss=0.01740  sm_val_loss=0.01752\n",
      "Epoch 8 sm_loss=0.01739  sm_val_loss=0.01747\n",
      "Epoch 10 sm_loss=0.01716  sm_val_loss=0.01744\n",
      "Epoch 11 sm_loss=0.01701  sm_val_loss=0.01735\n",
      "Epoch 12 sm_loss=0.01700  sm_val_loss=0.01729\n",
      "Epoch 13 sm_loss=0.01666  sm_val_loss=0.01721\n",
      "Epoch 14 sm_loss=0.01638  sm_val_loss=0.01695\n",
      "Epoch 15 sm_loss=0.01609  sm_val_loss=0.01676\n",
      "Epoch 16 sm_loss=0.01567  sm_val_loss=0.01666\n",
      "Epoch 17 sm_loss=0.01523  sm_val_loss=0.01648\n",
      "Epoch 18 sm_loss=0.01481  sm_val_loss=0.01640\n",
      "Epoch 19 sm_loss=0.01441  sm_val_loss=0.01636\n",
      "Epoch 20 sm_loss=0.01424  sm_val_loss=0.01630\n",
      "Fold 6\n",
      "Epoch 1 sm_loss=0.41412  sm_val_loss=0.02232\n",
      "Epoch 2 sm_loss=0.02019  sm_val_loss=0.01857\n",
      "Epoch 3 sm_loss=0.01807  sm_val_loss=0.01779\n",
      "Epoch 4 sm_loss=0.01771  sm_val_loss=0.01747\n",
      "Epoch 5 sm_loss=0.01759  sm_val_loss=0.01741\n",
      "Epoch 6 sm_loss=0.01751  sm_val_loss=0.01740\n",
      "Epoch 8 sm_loss=0.01746  sm_val_loss=0.01721\n",
      "Epoch 10 sm_loss=0.01726  sm_val_loss=0.01705\n",
      "Epoch 11 sm_loss=0.01712  sm_val_loss=0.01696\n",
      "Epoch 12 sm_loss=0.01699  sm_val_loss=0.01689\n",
      "Epoch 13 sm_loss=0.01677  sm_val_loss=0.01664\n",
      "Epoch 14 sm_loss=0.01648  sm_val_loss=0.01647\n",
      "Epoch 15 sm_loss=0.01613  sm_val_loss=0.01628\n",
      "Epoch 16 sm_loss=0.01573  sm_val_loss=0.01611\n",
      "Epoch 17 sm_loss=0.01529  sm_val_loss=0.01594\n",
      "Epoch 18 sm_loss=0.01483  sm_val_loss=0.01584\n",
      "Epoch 19 sm_loss=0.01445  sm_val_loss=0.01578\n",
      "Fold 7\n",
      "Epoch 1 sm_loss=0.41370  sm_val_loss=0.02277\n",
      "Epoch 2 sm_loss=0.02010  sm_val_loss=0.01848\n",
      "Epoch 3 sm_loss=0.01819  sm_val_loss=0.01783\n",
      "Epoch 4 sm_loss=0.01791  sm_val_loss=0.01782\n",
      "Epoch 5 sm_loss=0.01762  sm_val_loss=0.01743\n",
      "Epoch 7 sm_loss=0.01750  sm_val_loss=0.01734\n",
      "Epoch 9 sm_loss=0.01738  sm_val_loss=0.01729\n",
      "Epoch 10 sm_loss=0.01722  sm_val_loss=0.01726\n",
      "Epoch 11 sm_loss=0.01712  sm_val_loss=0.01711\n",
      "Epoch 12 sm_loss=0.01692  sm_val_loss=0.01699\n",
      "Epoch 13 sm_loss=0.01668  sm_val_loss=0.01686\n",
      "Epoch 14 sm_loss=0.01644  sm_val_loss=0.01654\n",
      "Epoch 15 sm_loss=0.01606  sm_val_loss=0.01637\n",
      "Epoch 16 sm_loss=0.01573  sm_val_loss=0.01625\n",
      "Epoch 17 sm_loss=0.01528  sm_val_loss=0.01608\n",
      "Epoch 18 sm_loss=0.01483  sm_val_loss=0.01596\n",
      "Epoch 19 sm_loss=0.01443  sm_val_loss=0.01592\n",
      "Seed 4\n",
      "Total log loss: 0.01601924208855057\n"
     ]
    }
   ],
   "source": [
    "seeds = [0,1,2,3,4]\n",
    "pytorch1_oof = np.zeros([len(mlp_train),fn_targets.shape[1]])\n",
    "pytorch1_test = np.zeros([len(mlp_test),fn_targets.shape[1]])\n",
    "\n",
    "for seed_ in seeds:\n",
    "    oof, pytorch_pred = modelling_torch(mlp_train, fn_targets, mlp_test, seed_, fn_targets.shape[1])\n",
    "    pytorch1_oof += oof / len(seeds)\n",
    "    pytorch1_test += pytorch_pred / len(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T12:02:14.106750Z",
     "iopub.status.busy": "2020-10-27T12:02:14.105085Z",
     "iopub.status.idle": "2020-10-27T12:02:15.564486Z",
     "shell.execute_reply": "2020-10-27T12:02:15.565300Z"
    },
    "papermill": {
     "duration": 1.708023,
     "end_time": "2020-10-27T12:02:15.565471",
     "exception": false,
     "start_time": "2020-10-27T12:02:13.857448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF log loss:  0.014597014592739207\n"
     ]
    }
   ],
   "source": [
    "check_mlp = np.zeros([targets.shape[0], targets.shape[1]-1])\n",
    "check_mlp[cons_train_index,:] = pytorch1_oof\n",
    "print('OOF log loss: ', log_loss(np.ravel(y), np.ravel(check_mlp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.247726,
     "end_time": "2020-10-27T12:02:16.069377",
     "exception": false,
     "start_time": "2020-10-27T12:02:15.821651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1st tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T12:02:16.564927Z",
     "iopub.status.busy": "2020-10-27T12:02:16.564132Z",
     "iopub.status.idle": "2020-10-27T12:02:16.567794Z",
     "shell.execute_reply": "2020-10-27T12:02:16.567284Z"
    },
    "papermill": {
     "duration": 0.251525,
     "end_time": "2020-10-27T12:02:16.567909",
     "exception": false,
     "start_time": "2020-10-27T12:02:16.316384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LogitsLogLoss(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"logits_ll\"\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        logits = 1 / (1 + np.exp(-y_pred))\n",
    "        aux = (1-y_true)*np.log(1-logits+1e-15) + y_true*np.log(logits+1e-15)\n",
    "        return np.mean(-aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T12:02:17.122112Z",
     "iopub.status.busy": "2020-10-27T12:02:17.121203Z",
     "iopub.status.idle": "2020-10-27T12:02:17.125129Z",
     "shell.execute_reply": "2020-10-27T12:02:17.124248Z"
    },
    "papermill": {
     "duration": 0.312323,
     "end_time": "2020-10-27T12:02:17.125233",
     "exception": false,
     "start_time": "2020-10-27T12:02:16.812910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_EPOCH=200\n",
    "\n",
    "def seed_tabnet_everything(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "def modelling_tabnet(tr, target, te, sample_seed):\n",
    "    seed_tabnet_everything(sample_seed) \n",
    "    tabnet_params = dict(n_d=12, n_a=12, n_steps=1, gamma=1.3, seed = sample_seed,\n",
    "                     lambda_sparse=0, optimizer_fn=torch.optim.Adam,\n",
    "                     optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
    "                     mask_type='entmax',\n",
    "                     scheduler_params=dict(mode=\"min\",\n",
    "                                           patience=5,\n",
    "                                           min_lr=1e-5,\n",
    "                                           factor=0.9,),\n",
    "                     scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                     verbose=10,\n",
    "                     )\n",
    "    test_cv_preds = []\n",
    "    \n",
    "    NB_SPLITS = 5\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=NB_SPLITS, random_state=0, shuffle=True)\n",
    "    oof_preds = np.zeros([len(tr),target.shape[1]])\n",
    "    for fold_nb, (train_idx, val_idx) in enumerate(mskf.split(train, target)):\n",
    "        print(\"FOLDS : \", fold_nb+1)\n",
    "\n",
    "        ## model\n",
    "        X_train, y_train = tr[train_idx, :], target[train_idx, :]\n",
    "        X_val, y_val = tr[val_idx, :], target[val_idx, :]\n",
    "        model = TabNetRegressor(**tabnet_params)\n",
    "        \n",
    "        model.fit(X_train=X_train,\n",
    "              y_train=y_train,\n",
    "              eval_set=[(X_val, y_val)],\n",
    "              eval_name = [\"val\"],\n",
    "              eval_metric = [\"logits_ll\"],\n",
    "              max_epochs=MAX_EPOCH,\n",
    "              patience=20, batch_size=1024, virtual_batch_size=128,\n",
    "              num_workers=1, drop_last=False,\n",
    "              # use binary cross entropy as this is not a regression problem\n",
    "              loss_fn=torch.nn.functional.binary_cross_entropy_with_logits)\n",
    "        \n",
    "        preds_val = model.predict(X_val)\n",
    "        preds =  1 / (1 + np.exp(-preds_val))\n",
    "        oof_preds[val_idx,:] = preds\n",
    "        \n",
    "        # preds on test\n",
    "        preds_test = model.predict(te)\n",
    "        test_cv_preds.append(1 / (1 + np.exp(-preds_test)))\n",
    "\n",
    "    test_preds_all = np.stack(test_cv_preds)\n",
    "    return oof_preds, test_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T12:02:17.619032Z",
     "iopub.status.busy": "2020-10-27T12:02:17.617403Z",
     "iopub.status.idle": "2020-10-27T12:28:53.306953Z",
     "shell.execute_reply": "2020-10-27T12:28:53.306190Z"
    },
    "papermill": {
     "duration": 1595.939959,
     "end_time": "2020-10-27T12:28:53.307093",
     "exception": false,
     "start_time": "2020-10-27T12:02:17.367134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLDS :  1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.56805 | val_logits_ll: 0.30547 |  0:00:01s\n",
      "epoch 10 | loss: 0.02066 | val_logits_ll: 0.02053 |  0:00:12s\n",
      "epoch 20 | loss: 0.01902 | val_logits_ll: 0.01885 |  0:00:23s\n",
      "epoch 30 | loss: 0.01782 | val_logits_ll: 0.01842 |  0:00:34s\n",
      "epoch 40 | loss: 0.01723 | val_logits_ll: 0.01774 |  0:00:47s\n",
      "epoch 50 | loss: 0.01699 | val_logits_ll: 0.01863 |  0:00:58s\n",
      "epoch 60 | loss: 0.01669 | val_logits_ll: 0.01722 |  0:01:09s\n",
      "epoch 70 | loss: 0.0167  | val_logits_ll: 0.0171  |  0:01:20s\n",
      "epoch 80 | loss: 0.01643 | val_logits_ll: 0.01703 |  0:01:31s\n",
      "epoch 90 | loss: 0.01611 | val_logits_ll: 0.01693 |  0:01:44s\n",
      "epoch 100| loss: 0.01599 | val_logits_ll: 0.01745 |  0:01:55s\n",
      "\n",
      "Early stopping occured at epoch 104 with best_epoch = 84 and best_val_logits_ll = 0.01675\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.56657 | val_logits_ll: 0.30328 |  0:00:01s\n",
      "epoch 10 | loss: 0.02066 | val_logits_ll: 0.02041 |  0:00:12s\n",
      "epoch 20 | loss: 0.01867 | val_logits_ll: 0.0188  |  0:00:23s\n",
      "epoch 30 | loss: 0.01749 | val_logits_ll: 0.01904 |  0:00:34s\n",
      "epoch 40 | loss: 0.017   | val_logits_ll: 0.01937 |  0:00:47s\n",
      "epoch 50 | loss: 0.01662 | val_logits_ll: 0.01784 |  0:00:57s\n",
      "epoch 60 | loss: 0.01631 | val_logits_ll: 0.01738 |  0:01:08s\n",
      "epoch 70 | loss: 0.01606 | val_logits_ll: 0.01742 |  0:01:20s\n",
      "epoch 80 | loss: 0.0158  | val_logits_ll: 0.01729 |  0:01:31s\n",
      "epoch 90 | loss: 0.01559 | val_logits_ll: 0.01755 |  0:01:43s\n",
      "\n",
      "Early stopping occured at epoch 94 with best_epoch = 74 and best_val_logits_ll = 0.01715\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.56895 | val_logits_ll: 0.29383 |  0:00:01s\n",
      "epoch 10 | loss: 0.02061 | val_logits_ll: 0.02049 |  0:00:11s\n",
      "epoch 20 | loss: 0.01867 | val_logits_ll: 0.01884 |  0:00:22s\n",
      "epoch 30 | loss: 0.01788 | val_logits_ll: 0.01938 |  0:00:34s\n",
      "epoch 40 | loss: 0.01737 | val_logits_ll: 0.01834 |  0:00:45s\n",
      "epoch 50 | loss: 0.01688 | val_logits_ll: 0.01768 |  0:00:57s\n",
      "epoch 60 | loss: 0.01663 | val_logits_ll: 0.01734 |  0:01:08s\n",
      "epoch 70 | loss: 0.01632 | val_logits_ll: 0.01753 |  0:01:19s\n",
      "epoch 80 | loss: 0.01608 | val_logits_ll: 0.01765 |  0:01:30s\n",
      "epoch 90 | loss: 0.01596 | val_logits_ll: 0.01717 |  0:01:42s\n",
      "epoch 100| loss: 0.01578 | val_logits_ll: 0.01717 |  0:01:54s\n",
      "epoch 110| loss: 0.01548 | val_logits_ll: 0.01752 |  0:02:05s\n",
      "epoch 120| loss: 0.0153  | val_logits_ll: 0.01721 |  0:02:16s\n",
      "\n",
      "Early stopping occured at epoch 122 with best_epoch = 102 and best_val_logits_ll = 0.01708\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.56326 | val_logits_ll: 0.30779 |  0:00:01s\n",
      "epoch 10 | loss: 0.02077 | val_logits_ll: 0.02068 |  0:00:11s\n",
      "epoch 20 | loss: 0.01976 | val_logits_ll: 0.02129 |  0:00:23s\n",
      "epoch 30 | loss: 0.01805 | val_logits_ll: 0.01843 |  0:00:35s\n",
      "epoch 40 | loss: 0.01747 | val_logits_ll: 0.01914 |  0:00:45s\n",
      "epoch 50 | loss: 0.01699 | val_logits_ll: 0.01756 |  0:00:57s\n",
      "epoch 60 | loss: 0.01654 | val_logits_ll: 0.01726 |  0:01:08s\n",
      "epoch 70 | loss: 0.01631 | val_logits_ll: 0.01722 |  0:01:18s\n",
      "epoch 80 | loss: 0.01591 | val_logits_ll: 0.01715 |  0:01:31s\n",
      "epoch 90 | loss: 0.01603 | val_logits_ll: 0.01704 |  0:01:42s\n",
      "epoch 100| loss: 0.01577 | val_logits_ll: 0.01713 |  0:01:53s\n",
      "epoch 110| loss: 0.01563 | val_logits_ll: 0.01701 |  0:02:04s\n",
      "epoch 120| loss: 0.01537 | val_logits_ll: 0.01705 |  0:02:15s\n",
      "\n",
      "Early stopping occured at epoch 125 with best_epoch = 105 and best_val_logits_ll = 0.01688\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  5\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.56189 | val_logits_ll: 0.28975 |  0:00:01s\n",
      "epoch 10 | loss: 0.02054 | val_logits_ll: 0.02081 |  0:00:13s\n",
      "epoch 20 | loss: 0.01905 | val_logits_ll: 0.01913 |  0:00:24s\n",
      "epoch 30 | loss: 0.01762 | val_logits_ll: 0.01857 |  0:00:35s\n",
      "epoch 40 | loss: 0.01701 | val_logits_ll: 0.01784 |  0:00:47s\n",
      "epoch 50 | loss: 0.01699 | val_logits_ll: 0.01773 |  0:00:58s\n",
      "epoch 60 | loss: 0.01657 | val_logits_ll: 0.01721 |  0:01:10s\n",
      "epoch 70 | loss: 0.01625 | val_logits_ll: 0.01729 |  0:01:21s\n",
      "epoch 80 | loss: 0.01593 | val_logits_ll: 0.01703 |  0:01:32s\n",
      "epoch 90 | loss: 0.01571 | val_logits_ll: 0.01721 |  0:01:44s\n",
      "epoch 100| loss: 0.01557 | val_logits_ll: 0.01708 |  0:01:55s\n",
      "epoch 110| loss: 0.01529 | val_logits_ll: 0.01707 |  0:02:07s\n",
      "\n",
      "Early stopping occured at epoch 118 with best_epoch = 98 and best_val_logits_ll = 0.01687\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.52289 | val_logits_ll: 0.23849 |  0:00:01s\n",
      "epoch 10 | loss: 0.02073 | val_logits_ll: 0.02061 |  0:00:15s\n",
      "epoch 20 | loss: 0.01939 | val_logits_ll: 0.01925 |  0:00:30s\n",
      "epoch 30 | loss: 0.01785 | val_logits_ll: 0.01818 |  0:00:44s\n",
      "epoch 40 | loss: 0.01726 | val_logits_ll: 0.01789 |  0:00:59s\n",
      "epoch 50 | loss: 0.01705 | val_logits_ll: 0.01764 |  0:01:14s\n",
      "epoch 60 | loss: 0.01672 | val_logits_ll: 0.0175  |  0:01:28s\n",
      "epoch 70 | loss: 0.01653 | val_logits_ll: 0.01733 |  0:01:43s\n",
      "epoch 80 | loss: 0.01632 | val_logits_ll: 0.01724 |  0:01:57s\n",
      "epoch 90 | loss: 0.01614 | val_logits_ll: 0.01725 |  0:02:12s\n",
      "epoch 100| loss: 0.01588 | val_logits_ll: 0.01706 |  0:02:26s\n",
      "epoch 110| loss: 0.01555 | val_logits_ll: 0.01718 |  0:02:41s\n",
      "epoch 120| loss: 0.01531 | val_logits_ll: 0.0176  |  0:02:56s\n",
      "epoch 130| loss: 0.01533 | val_logits_ll: 0.01713 |  0:03:11s\n",
      "\n",
      "Early stopping occured at epoch 138 with best_epoch = 118 and best_val_logits_ll = 0.01687\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.5229  | val_logits_ll: 0.27514 |  0:00:01s\n",
      "epoch 10 | loss: 0.02097 | val_logits_ll: 0.02081 |  0:00:15s\n",
      "epoch 20 | loss: 0.019   | val_logits_ll: 0.01919 |  0:00:31s\n",
      "epoch 30 | loss: 0.01772 | val_logits_ll: 0.01825 |  0:00:45s\n",
      "epoch 40 | loss: 0.01713 | val_logits_ll: 0.01945 |  0:01:00s\n",
      "epoch 50 | loss: 0.01679 | val_logits_ll: 0.01774 |  0:01:14s\n",
      "epoch 60 | loss: 0.01654 | val_logits_ll: 0.01737 |  0:01:30s\n",
      "epoch 70 | loss: 0.01625 | val_logits_ll: 0.01729 |  0:01:44s\n",
      "epoch 80 | loss: 0.01592 | val_logits_ll: 0.01743 |  0:01:59s\n",
      "epoch 90 | loss: 0.0156  | val_logits_ll: 0.01744 |  0:02:13s\n",
      "epoch 100| loss: 0.01577 | val_logits_ll: 0.01742 |  0:02:29s\n",
      "epoch 110| loss: 0.01544 | val_logits_ll: 0.01716 |  0:02:43s\n",
      "\n",
      "Early stopping occured at epoch 116 with best_epoch = 96 and best_val_logits_ll = 0.01707\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.52711 | val_logits_ll: 0.24486 |  0:00:01s\n",
      "epoch 10 | loss: 0.02102 | val_logits_ll: 0.02098 |  0:00:15s\n",
      "epoch 20 | loss: 0.01939 | val_logits_ll: 0.01982 |  0:00:29s\n",
      "epoch 30 | loss: 0.01826 | val_logits_ll: 0.01886 |  0:00:45s\n",
      "epoch 40 | loss: 0.01732 | val_logits_ll: 0.01927 |  0:00:59s\n",
      "epoch 50 | loss: 0.01668 | val_logits_ll: 0.01857 |  0:01:13s\n",
      "epoch 60 | loss: 0.01631 | val_logits_ll: 0.01774 |  0:01:28s\n",
      "epoch 70 | loss: 0.01621 | val_logits_ll: 0.01733 |  0:01:44s\n",
      "epoch 80 | loss: 0.01584 | val_logits_ll: 0.01716 |  0:01:57s\n",
      "epoch 90 | loss: 0.01559 | val_logits_ll: 0.01726 |  0:02:12s\n",
      "epoch 100| loss: 0.01526 | val_logits_ll: 0.01714 |  0:02:27s\n",
      "epoch 110| loss: 0.01501 | val_logits_ll: 0.01741 |  0:02:41s\n",
      "\n",
      "Early stopping occured at epoch 111 with best_epoch = 91 and best_val_logits_ll = 0.01708\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.52426 | val_logits_ll: 0.24755 |  0:00:01s\n",
      "epoch 10 | loss: 0.0207  | val_logits_ll: 0.02274 |  0:00:15s\n",
      "epoch 20 | loss: 0.01917 | val_logits_ll: 0.0192  |  0:00:29s\n",
      "epoch 30 | loss: 0.01796 | val_logits_ll: 0.01816 |  0:00:45s\n",
      "epoch 40 | loss: 0.01715 | val_logits_ll: 0.01777 |  0:00:59s\n",
      "epoch 50 | loss: 0.01664 | val_logits_ll: 0.01925 |  0:01:14s\n",
      "epoch 60 | loss: 0.01647 | val_logits_ll: 0.01749 |  0:01:28s\n",
      "epoch 70 | loss: 0.01624 | val_logits_ll: 0.0172  |  0:01:43s\n",
      "epoch 80 | loss: 0.01589 | val_logits_ll: 0.01719 |  0:01:58s\n",
      "epoch 90 | loss: 0.01576 | val_logits_ll: 0.01722 |  0:02:13s\n",
      "epoch 100| loss: 0.01579 | val_logits_ll: 0.01707 |  0:02:27s\n",
      "epoch 110| loss: 0.01549 | val_logits_ll: 0.01701 |  0:02:42s\n",
      "epoch 120| loss: 0.015   | val_logits_ll: 0.01707 |  0:02:57s\n",
      "epoch 130| loss: 0.01489 | val_logits_ll: 0.01712 |  0:03:10s\n",
      "\n",
      "Early stopping occured at epoch 139 with best_epoch = 119 and best_val_logits_ll = 0.0169\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  5\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.52766 | val_logits_ll: 0.21611 |  0:00:02s\n",
      "epoch 10 | loss: 0.0207  | val_logits_ll: 0.0206  |  0:00:20s\n",
      "epoch 20 | loss: 0.01905 | val_logits_ll: 0.01908 |  0:00:39s\n",
      "epoch 30 | loss: 0.01771 | val_logits_ll: 0.01814 |  0:00:57s\n",
      "epoch 40 | loss: 0.01721 | val_logits_ll: 0.01794 |  0:01:16s\n",
      "epoch 50 | loss: 0.01662 | val_logits_ll: 0.01877 |  0:01:35s\n",
      "epoch 60 | loss: 0.01631 | val_logits_ll: 0.01729 |  0:01:53s\n",
      "epoch 70 | loss: 0.01608 | val_logits_ll: 0.01723 |  0:02:11s\n",
      "epoch 80 | loss: 0.01597 | val_logits_ll: 0.01711 |  0:02:30s\n",
      "epoch 90 | loss: 0.0159  | val_logits_ll: 0.01717 |  0:02:48s\n",
      "epoch 100| loss: 0.01545 | val_logits_ll: 0.01713 |  0:03:06s\n",
      "\n",
      "Early stopping occured at epoch 103 with best_epoch = 83 and best_val_logits_ll = 0.01703\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "tabnet1_oof = np.zeros([len(py_train),fn_targets.shape[1]])\n",
    "tabnet1_test = np.zeros([len(py_test),fn_targets.shape[1]])\n",
    "\n",
    "seeds = [0,1]\n",
    "for seed_ in seeds:\n",
    "    oof_preds, test_preds_all = modelling_tabnet(py_train, fn_targets, py_test, seed_)\n",
    "    tabnet1_oof += oof_preds / len(seeds)\n",
    "    tabnet1_test += test_preds_all.mean(axis=0) / len(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T12:28:53.893859Z",
     "iopub.status.busy": "2020-10-27T12:28:53.892703Z",
     "iopub.status.idle": "2020-10-27T12:28:55.657268Z",
     "shell.execute_reply": "2020-10-27T12:28:55.657852Z"
    },
    "papermill": {
     "duration": 2.060818,
     "end_time": "2020-10-27T12:28:55.658015",
     "exception": false,
     "start_time": "2020-10-27T12:28:53.597197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF log loss:  0.015328942805464933\n"
     ]
    }
   ],
   "source": [
    "check_tabnet = np.zeros([targets.shape[0], targets.shape[1]-1])\n",
    "check_tabnet[cons_train_index,:] = tabnet1_oof\n",
    "print('OOF log loss: ', log_loss(np.ravel(y), np.ravel(check_tabnet)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.30064,
     "end_time": "2020-10-27T12:28:56.249220",
     "exception": false,
     "start_time": "2020-10-27T12:28:55.948580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1st SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T12:28:56.869589Z",
     "iopub.status.busy": "2020-10-27T12:28:56.868551Z",
     "iopub.status.idle": "2020-10-27T12:38:03.552104Z",
     "shell.execute_reply": "2020-10-27T12:38:03.551320Z"
    },
    "papermill": {
     "duration": 547.004929,
     "end_time": "2020-10-27T12:38:03.552264",
     "exception": false,
     "start_time": "2020-10-27T12:28:56.547335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c527d35e2bd94e52a672d85aedd03b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=206.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N_STARTS = 1\n",
    "N_SPLITS = 5\n",
    "\n",
    "svm0_oof = np.zeros([len(fn_train), fn_targets.shape[1]])\n",
    "svm0_test = np.zeros([len(fn_test), fn_targets.shape[1]])\n",
    "\n",
    "svm1_test = np.zeros([len(fn_test),fn_targets.shape[1]])\n",
    "svm1_oof = np.zeros([fn_targets.shape[0],fn_targets.shape[1]]) \n",
    "\n",
    "for ind in tqdm(range(fn_targets.shape[1])):\n",
    "    ind_target_sum = fn_targets[:, ind].sum()\n",
    "    if ind_target_sum >= N_SPLITS:\n",
    "        for seed in range(N_STARTS):\n",
    "            skf = StratifiedKFold(n_splits = N_SPLITS, random_state = seed, shuffle = True)\n",
    "\n",
    "            for n, (train_index, val_index) in enumerate(skf.split(fn_train, fn_targets[:,ind])):\n",
    "                \n",
    "                x_tr, x_val = fn_train[train_index], fn_train[val_index]\n",
    "                y_tr, y_val = fn_targets[train_index,ind], fn_targets[val_index,ind]\n",
    "\n",
    "                model = SVC(C = 40, cache_size = 2000)\n",
    "                model.fit(x_tr, y_tr)\n",
    "                svm0_test[:, ind] += model.decision_function(fn_test) / (N_SPLITS * N_STARTS)\n",
    "                svm0_oof[val_index, ind] += model.decision_function(x_val) / N_STARTS\n",
    "\n",
    "        for seed in range(N_STARTS):\n",
    "            skf = StratifiedKFold(n_splits = N_SPLITS, random_state = seed, shuffle = True)\n",
    "            \n",
    "            for n, (train_index, val_index) in enumerate(skf.split(svm0_oof, fn_targets[:,ind])):\n",
    "\n",
    "                x_tr, x_val = svm0_oof[train_index, ind].reshape(-1, 1), svm0_oof[val_index, ind].reshape(-1, 1)\n",
    "                y_tr, y_val = fn_targets[train_index,ind], fn_targets[val_index,ind]\n",
    "\n",
    "                model = LogisticRegression(C = 35, max_iter = 1000)\n",
    "                model.fit(x_tr, y_tr)\n",
    "                svm1_test[:, ind] += model.predict_proba(svm0_test[:, ind].reshape(-1, 1))[:, 1] / (N_SPLITS * N_STARTS)\n",
    "                svm1_oof[val_index, ind] += model.predict_proba(x_val)[:, 1] / N_STARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T12:38:04.215206Z",
     "iopub.status.busy": "2020-10-27T12:38:04.214118Z",
     "iopub.status.idle": "2020-10-27T12:38:05.632629Z",
     "shell.execute_reply": "2020-10-27T12:38:05.631501Z"
    },
    "papermill": {
     "duration": 1.729692,
     "end_time": "2020-10-27T12:38:05.632776",
     "exception": false,
     "start_time": "2020-10-27T12:38:03.903084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF log loss:  0.015414626688103106\n"
     ]
    }
   ],
   "source": [
    "check_svm = np.zeros([targets.shape[0], targets.shape[1]-1])\n",
    "check_svm[cons_train_index,:] = svm1_oof\n",
    "print('OOF log loss: ', log_loss(np.ravel(y), np.ravel(check_svm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.312734,
     "end_time": "2020-10-27T12:38:06.250358",
     "exception": false,
     "start_time": "2020-10-27T12:38:05.937624",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T12:38:06.888333Z",
     "iopub.status.busy": "2020-10-27T12:38:06.886983Z",
     "iopub.status.idle": "2020-10-27T12:38:08.292462Z",
     "shell.execute_reply": "2020-10-27T12:38:08.293169Z"
    },
    "papermill": {
     "duration": 1.728852,
     "end_time": "2020-10-27T12:38:08.293364",
     "exception": false,
     "start_time": "2020-10-27T12:38:06.564512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF log loss:  0.014544548696347878\n"
     ]
    }
   ],
   "source": [
    "check = 0.1 * check_svm + 0.2 * check_tabnet + 0.7 * check_mlp\n",
    "print('OOF log loss: ', log_loss(np.ravel(y), np.ravel(check)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T12:38:09.172477Z",
     "iopub.status.busy": "2020-10-27T12:38:09.171358Z",
     "iopub.status.idle": "2020-10-27T12:38:09.802719Z",
     "shell.execute_reply": "2020-10-27T12:38:09.801906Z"
    },
    "papermill": {
     "duration": 1.133873,
     "end_time": "2020-10-27T12:38:09.802851",
     "exception": false,
     "start_time": "2020-10-27T12:38:08.668978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(DATA_DIR + 'sample_submission.csv')\n",
    "sub.loc[cons_test_index,target_feats] =  0.1 * svm1_test + 0.2 * tabnet1_test + 0.7 * pytorch1_test\n",
    "sub.loc[noncons_test_index,target_feats] = 0\n",
    "\n",
    "#sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.320244,
     "end_time": "2020-10-27T12:38:10.448303",
     "exception": false,
     "start_time": "2020-10-27T12:38:10.128059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2nd layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T12:38:11.066648Z",
     "iopub.status.busy": "2020-10-27T12:38:11.065385Z",
     "iopub.status.idle": "2020-10-27T12:38:11.212061Z",
     "shell.execute_reply": "2020-10-27T12:38:11.211382Z"
    },
    "papermill": {
     "duration": 0.457763,
     "end_time": "2020-10-27T12:38:11.212174",
     "exception": false,
     "start_time": "2020-10-27T12:38:10.754411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_feat = check[cons_train_index,:].copy()\n",
    "test_feat = sub[sub.index.isin(cons_test_index)].copy()\n",
    "final = pd.read_csv(DATA_DIR+\"sample_submission.csv\")\n",
    "test_feat.drop(\"sig_id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T12:38:11.834084Z",
     "iopub.status.busy": "2020-10-27T12:38:11.833205Z",
     "iopub.status.idle": "2020-10-27T12:38:11.838201Z",
     "shell.execute_reply": "2020-10-27T12:38:11.837595Z"
    },
    "papermill": {
     "duration": 0.318843,
     "end_time": "2020-10-27T12:38:11.838311",
     "exception": false,
     "start_time": "2020-10-27T12:38:11.519468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_params = {'tree_method': 'gpu_hist', 'max_depth': 5, 'alpha': 0.1,\n",
    "          'gamma': 0.3, 'scale_pos_weight': 1, 'learning_rate': 0.01, \n",
    "           'objective':'binary:logistic', 'eval_metric': 'logloss'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T12:38:12.474089Z",
     "iopub.status.busy": "2020-10-27T12:38:12.472652Z",
     "iopub.status.idle": "2020-10-27T13:21:18.630567Z",
     "shell.execute_reply": "2020-10-27T13:21:18.631251Z"
    },
    "papermill": {
     "duration": 2586.478442,
     "end_time": "2020-10-27T13:21:18.631464",
     "exception": false,
     "start_time": "2020-10-27T12:38:12.153022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5-alpha_reductase_inhibitor\n",
      "oof log_loss= 0.00555630927817114, all log_loss= 0.0051209320583397175\n",
      "1 11-beta-hsd1_inhibitor\n",
      "oof log_loss= 0.006359590306148017, all log_loss= 0.005861270178858592\n",
      "2 acat_inhibitor\n",
      "oof log_loss= 0.008508684204857684, all log_loss= 0.007841966949198718\n",
      "3 acetylcholine_receptor_agonist\n",
      "oof log_loss= 0.04792794593688219, all log_loss= 0.04417244299247048\n",
      "4 acetylcholine_receptor_antagonist\n",
      "oof log_loss= 0.06786289814563587, all log_loss= 0.06254534679182068\n",
      "5 acetylcholinesterase_inhibitor\n",
      "oof log_loss= 0.0220127392655799, all log_loss= 0.02028788113718609\n",
      "6 adenosine_receptor_agonist\n",
      "oof log_loss= 0.01646122549066518, all log_loss= 0.015171368819565018\n",
      "7 adenosine_receptor_antagonist\n",
      "oof log_loss= 0.026183719167370396, all log_loss= 0.02413203444551303\n",
      "8 adenylyl_cyclase_activator\n",
      "oof log_loss= 0.0017596419638544099, all log_loss= 0.0016217612254421122\n",
      "9 adrenergic_receptor_agonist\n",
      "oof log_loss= 0.05234734440718525, all log_loss= 0.048245549468753826\n",
      "10 adrenergic_receptor_antagonist\n",
      "oof log_loss= 0.07989045379668705, all log_loss= 0.07363045603131305\n",
      "11 akt_inhibitor\n",
      "oof log_loss= 0.010840769643376165, all log_loss= 0.009991316542068612\n",
      "12 aldehyde_dehydrogenase_inhibitor\n",
      "oof log_loss= 0.0013180152214098482, all log_loss= 0.0012147391483793236\n",
      "13 alk_inhibitor\n",
      "oof log_loss= 0.00985283373498403, all log_loss= 0.009080792593240588\n",
      "14 ampk_activator\n",
      "oof log_loss= 0.00476780406831704, all log_loss= 0.004394211963190738\n",
      "15 analgesic\n",
      "oof log_loss= 0.004726972728451418, all log_loss= 0.004356580055599798\n",
      "16 androgen_receptor_agonist\n",
      "oof log_loss= 0.014914310934900542, all log_loss= 0.013745666263508817\n",
      "17 androgen_receptor_antagonist\n",
      "oof log_loss= 0.025644048273299615, all log_loss= 0.023634650688770544\n",
      "18 anesthetic_-_local\n",
      "oof log_loss= 0.023151605237216138, all log_loss= 0.02133750868171755\n",
      "19 angiogenesis_inhibitor\n",
      "oof log_loss= 0.01165924906978581, all log_loss= 0.010745662156028422\n",
      "20 angiotensin_receptor_antagonist\n",
      "oof log_loss= 0.012196800026575687, all log_loss= 0.01124109208798543\n",
      "21 anti-inflammatory\n",
      "oof log_loss= 0.020794257465501294, all log_loss= 0.019164876243084918\n",
      "22 antiarrhythmic\n",
      "oof log_loss= 0.0025290904268219197, all log_loss= 0.002330917808343385\n",
      "23 antibiotic\n",
      "oof log_loss= 0.012849160507481147, all log_loss= 0.011842335383312258\n",
      "24 anticonvulsant\n",
      "oof log_loss= 0.004554443803580081, all log_loss= 0.004197570026076152\n",
      "25 antifungal\n",
      "oof log_loss= 0.004726665666043871, all log_loss= 0.004356297053763867\n",
      "26 antihistamine\n",
      "oof log_loss= 0.004543665272677504, all log_loss= 0.004187636071417138\n",
      "27 antimalarial\n",
      "oof log_loss= 0.005972712904777411, all log_loss= 0.005504707434032774\n",
      "28 antioxidant\n",
      "oof log_loss= 0.02152340102182975, all log_loss= 0.019836886101751966\n",
      "29 antiprotozoal\n",
      "oof log_loss= 0.012232284421194154, all log_loss= 0.011273796022355382\n",
      "30 antiviral\n",
      "oof log_loss= 0.008335895387290215, all log_loss= 0.0076827173914608025\n",
      "31 apoptosis_stimulant\n",
      "oof log_loss= 0.014579217905072625, all log_loss= 0.013436830208303345\n",
      "32 aromatase_inhibitor\n",
      "oof log_loss= 0.01504639643601299, all log_loss= 0.013867401905501592\n",
      "33 atm_kinase_inhibitor\n",
      "oof log_loss= 0.0012628765037039406, all log_loss= 0.00116392094999983\n",
      "34 atp-sensitive_potassium_channel_antagonist\n",
      "oof log_loss= 0.0004836011791334374, all log_loss= 0.00044570751153197904\n",
      "35 atp_synthase_inhibitor\n",
      "oof log_loss= 0.0020166573197138893, all log_loss= 0.0018586375599681823\n",
      "36 atpase_inhibitor\n",
      "oof log_loss= 0.021057544113220104, all log_loss= 0.019407532468168162\n",
      "37 atr_kinase_inhibitor\n",
      "oof log_loss= 0.0033247272576441677, all log_loss= 0.0030642107101190915\n",
      "38 aurora_kinase_inhibitor\n",
      "oof log_loss= 0.009900940825569412, all log_loss= 0.009125130143596175\n",
      "39 autotaxin_inhibitor\n",
      "oof log_loss= 0.0019887340512315345, all log_loss= 0.0018329022825410088\n",
      "40 bacterial_30s_ribosomal_subunit_inhibitor\n",
      "oof log_loss= 0.018675662318226257, all log_loss= 0.017212288425314175\n",
      "41 bacterial_50s_ribosomal_subunit_inhibitor\n",
      "oof log_loss= 0.022979657979713467, all log_loss= 0.021179034741696193\n",
      "42 bacterial_antifolate\n",
      "oof log_loss= 0.011561404958876947, all log_loss= 0.010655484842421814\n",
      "43 bacterial_cell_wall_synthesis_inhibitor\n",
      "oof log_loss= 0.048829218728516956, all log_loss= 0.045003094509678855\n",
      "44 bacterial_dna_gyrase_inhibitor\n",
      "oof log_loss= 0.0247043223995103, all log_loss= 0.022768559167903504\n",
      "45 bacterial_dna_inhibitor\n",
      "oof log_loss= 0.0310655491552734, all log_loss= 0.02863133756865467\n",
      "46 bacterial_membrane_integrity_inhibitor\n",
      "oof log_loss= 0.0017583382221941987, all log_loss= 0.0016205596414176587\n",
      "47 bcl_inhibitor\n",
      "oof log_loss= 0.007688147734223625, all log_loss= 0.007085725475381791\n",
      "48 bcr-abl_inhibitor\n",
      "oof log_loss= 0.009221049493944629, all log_loss= 0.008498513239821053\n",
      "49 benzodiazepine_receptor_agonist\n",
      "oof log_loss= 0.019765795298241073, all log_loss= 0.018217001562349754\n",
      "50 beta_amyloid_inhibitor\n",
      "oof log_loss= 0.008584263366581472, all log_loss= 0.00791162393422911\n",
      "51 bromodomain_inhibitor\n",
      "oof log_loss= 0.012776215554910722, all log_loss= 0.011775106198000438\n",
      "52 btk_inhibitor\n",
      "oof log_loss= 0.0064577659648982965, all log_loss= 0.005951753061123275\n",
      "53 calcineurin_inhibitor\n",
      "oof log_loss= 0.002330199505184173, all log_loss= 0.002147611436120941\n",
      "54 calcium_channel_blocker\n",
      "oof log_loss= 0.06405014188538277, all log_loss= 0.0590313476988487\n",
      "55 cannabinoid_receptor_agonist\n",
      "oof log_loss= 0.013734744464080538, all log_loss= 0.012658527399749788\n",
      "56 cannabinoid_receptor_antagonist\n",
      "oof log_loss= 0.01672057269310089, all log_loss= 0.015410394283538258\n",
      "57 carbonic_anhydrase_inhibitor\n",
      "oof log_loss= 0.011413815826386627, all log_loss= 0.010519460391262935\n",
      "58 casein_kinase_inhibitor\n",
      "oof log_loss= 0.011858634418510846, all log_loss= 0.010929424213381955\n",
      "59 caspase_activator\n",
      "oof log_loss= 0.0064787634557099075, all log_loss= 0.005971105245902534\n",
      "60 catechol_o_methyltransferase_inhibitor\n",
      "oof log_loss= 0.004731378688413788, all log_loss= 0.004360640776572926\n",
      "61 cc_chemokine_receptor_antagonist\n",
      "oof log_loss= 0.029151850756752903, all log_loss= 0.02686759135001321\n",
      "62 cck_receptor_antagonist\n",
      "oof log_loss= 0.006519591383144493, all log_loss= 0.006008734008451214\n",
      "63 cdk_inhibitor\n",
      "oof log_loss= 0.017900119804358204, all log_loss= 0.01649751530469706\n",
      "64 chelating_agent\n",
      "oof log_loss= 0.016843836190693937, all log_loss= 0.01552399919011306\n",
      "65 chk_inhibitor\n",
      "oof log_loss= 0.002895146959371485, all log_loss= 0.00266829115076372\n",
      "66 chloride_channel_blocker\n",
      "oof log_loss= 0.013089877588687463, all log_loss= 0.012064190531473683\n",
      "67 cholesterol_inhibitor\n",
      "oof log_loss= 0.015334408925889866, all log_loss= 0.014132846523281794\n",
      "68 cholinergic_receptor_antagonist\n",
      "oof log_loss= 0.01679504647721701, all log_loss= 0.01547903250533135\n",
      "69 coagulation_factor_inhibitor\n",
      "oof log_loss= 0.002607269627783882, all log_loss= 0.0024029711006383855\n",
      "70 corticosteroid_agonist\n",
      "oof log_loss= 0.008514014606907436, all log_loss= 0.00784687967550207\n",
      "71 cyclooxygenase_inhibitor\n",
      "oof log_loss= 0.09002701074467354, all log_loss= 0.08297274006148049\n",
      "72 cytochrome_p450_inhibitor\n",
      "oof log_loss= 0.029378944863946616, all log_loss= 0.027076890983199056\n",
      "73 dihydrofolate_reductase_inhibitor\n",
      "oof log_loss= 0.0091903089258492, all log_loss= 0.008470181418683971\n",
      "74 dipeptidyl_peptidase_inhibitor\n",
      "oof log_loss= 0.008651969245493189, all log_loss= 0.007974024565385335\n",
      "75 diuretic\n",
      "oof log_loss= 0.0024446201952643765, all log_loss= 0.0022530664334284205\n",
      "76 dna_alkylating_agent\n",
      "oof log_loss= 0.015411741831387563, all log_loss= 0.014204119833513733\n",
      "77 dna_inhibitor\n",
      "oof log_loss= 0.08085450953325071, all log_loss= 0.07451897099335636\n",
      "78 dopamine_receptor_agonist\n",
      "oof log_loss= 0.03333558084848725, all log_loss= 0.03072349577822289\n",
      "79 dopamine_receptor_antagonist\n",
      "oof log_loss= 0.08664277459508421, all log_loss= 0.07985368341366045\n",
      "80 egfr_inhibitor\n",
      "oof log_loss= 0.013889937107693212, all log_loss= 0.012801559571665932\n",
      "81 elastase_inhibitor\n",
      "oof log_loss= 0.0023559389327426914, all log_loss= 0.0021713339924346376\n",
      "82 erbb2_inhibitor\n",
      "oof log_loss= 0.0004829166551909625, all log_loss= 0.0004450766250160877\n",
      "83 estrogen_receptor_agonist\n",
      "oof log_loss= 0.03983170682505215, all log_loss= 0.036710603065266086\n",
      "84 estrogen_receptor_antagonist\n",
      "oof log_loss= 0.014003092105756936, all log_loss= 0.012905848053126527\n",
      "85 faah_inhibitor\n",
      "oof log_loss= 0.01098477180073171, all log_loss= 0.01012403508366765\n",
      "86 farnesyltransferase_inhibitor\n",
      "oof log_loss= 0.002442125176756244, all log_loss= 0.0022507669177562737\n",
      "87 fatty_acid_receptor_agonist\n",
      "oof log_loss= 0.008211830329938531, all log_loss= 0.007568373733160861\n",
      "88 fgfr_inhibitor\n",
      "oof log_loss= 0.009687060748264574, all log_loss= 0.008928009125006832\n",
      "89 flt3_inhibitor\n",
      "oof log_loss= 0.017745192879156855, all log_loss= 0.01635472803022325\n",
      "90 focal_adhesion_kinase_inhibitor\n",
      "oof log_loss= 0.0018235403385217608, all log_loss= 0.0016806526979876322\n",
      "91 free_radical_scavenger\n",
      "oof log_loss= 0.00654449269121217, all log_loss= 0.006031684118028325\n",
      "92 fungal_squalene_epoxidase_inhibitor\n",
      "oof log_loss= 0.007389497439916618, all log_loss= 0.006810476602472991\n",
      "93 gaba_receptor_agonist\n",
      "oof log_loss= 0.029572294046060734, all log_loss= 0.02725508985147153\n",
      "94 gaba_receptor_antagonist\n",
      "oof log_loss= 0.04250471152014033, all log_loss= 0.03917415841286813\n",
      "95 gamma_secretase_inhibitor\n",
      "oof log_loss= 0.00925743974688192, all log_loss= 0.00853205205192602\n",
      "96 glucocorticoid_receptor_agonist\n",
      "oof log_loss= 0.014761590797250625, all log_loss= 0.013604912858741014\n",
      "97 glutamate_inhibitor\n",
      "oof log_loss= 0.004591272965962872, all log_loss= 0.004231513355881204\n",
      "98 glutamate_receptor_agonist\n",
      "oof log_loss= 0.022331917759723673, all log_loss= 0.020582049676258377\n",
      "99 glutamate_receptor_antagonist\n",
      "oof log_loss= 0.08146208897449564, all log_loss= 0.07507894216898597\n",
      "100 gonadotropin_receptor_agonist\n",
      "oof log_loss= 0.006437944760662402, all log_loss= 0.005933484992316295\n",
      "101 gsk_inhibitor\n",
      "oof log_loss= 0.009946841082014704, all log_loss= 0.00916743378130766\n",
      "102 hcv_inhibitor\n",
      "oof log_loss= 0.021182228421266977, all log_loss= 0.019522446854370098\n",
      "103 hdac_inhibitor\n",
      "oof log_loss= 0.010704473376446134, all log_loss= 0.009865700078367413\n",
      "104 histamine_receptor_agonist\n",
      "oof log_loss= 0.018289436569489764, all log_loss= 0.01685632627140183\n",
      "105 histamine_receptor_antagonist\n",
      "oof log_loss= 0.05809514343357319, all log_loss= 0.05354296666163041\n",
      "106 histone_lysine_demethylase_inhibitor\n",
      "oof log_loss= 0.003711196872789789, all log_loss= 0.003420397621734785\n",
      "107 histone_lysine_methyltransferase_inhibitor\n",
      "oof log_loss= 0.008136572786771691, all log_loss= 0.007499013165535691\n",
      "108 hiv_inhibitor\n",
      "oof log_loss= 0.020455655416375465, all log_loss= 0.01885280612575\n",
      "109 hmgcr_inhibitor\n",
      "oof log_loss= 0.009029639340717948, all log_loss= 0.00832210146342821\n",
      "110 hsp_inhibitor\n",
      "oof log_loss= 0.007681481206652634, all log_loss= 0.007079581318703866\n",
      "111 igf-1_inhibitor\n",
      "oof log_loss= 0.00889939804398528, all log_loss= 0.008202065518996842\n",
      "112 ikk_inhibitor\n",
      "oof log_loss= 0.006791421209760774, all log_loss= 0.006259263992266369\n",
      "113 imidazoline_receptor_agonist\n",
      "oof log_loss= 0.010120307204607068, all log_loss= 0.009327307572298556\n",
      "114 immunosuppressant\n",
      "oof log_loss= 0.018790263484895348, all log_loss= 0.017317909757557946\n",
      "115 insulin_secretagogue\n",
      "oof log_loss= 0.010059989641497765, all log_loss= 0.009271716328697187\n",
      "116 insulin_sensitizer\n",
      "oof log_loss= 0.01120538427897098, all log_loss= 0.010327360970641509\n",
      "117 integrin_inhibitor\n",
      "oof log_loss= 0.013642878247179371, all log_loss= 0.01257385956870306\n",
      "118 jak_inhibitor\n",
      "oof log_loss= 0.011019074037245242, all log_loss= 0.010155649490613101\n",
      "119 kit_inhibitor\n",
      "oof log_loss= 0.01566350623488183, all log_loss= 0.014436156665960709\n",
      "120 laxative\n",
      "oof log_loss= 0.0023968084591607713, all log_loss= 0.0022090010943840795\n",
      "121 leukotriene_inhibitor\n",
      "oof log_loss= 0.0025575327944282315, all log_loss= 0.0023571315097049086\n",
      "122 leukotriene_receptor_antagonist\n",
      "oof log_loss= 0.01872480176571837, all log_loss= 0.01725757743990882\n",
      "123 lipase_inhibitor\n",
      "oof log_loss= 0.004386090891186203, all log_loss= 0.0040424087880976175\n",
      "124 lipoxygenase_inhibitor\n",
      "oof log_loss= 0.017739353033069116, all log_loss= 0.016349345778525353\n",
      "125 lxr_agonist\n",
      "oof log_loss= 0.001348727923594384, all log_loss= 0.0012430452871021837\n",
      "126 mdm_inhibitor\n",
      "oof log_loss= 0.0035955028870280474, all log_loss= 0.0033137691007177903\n",
      "127 mek_inhibitor\n",
      "oof log_loss= 0.006954603249578956, all log_loss= 0.006409659533121725\n",
      "128 membrane_integrity_inhibitor\n",
      "oof log_loss= 0.021746673111502263, all log_loss= 0.020042663200270996\n",
      "129 mineralocorticoid_receptor_antagonist\n",
      "oof log_loss= 0.00835339709818676, all log_loss= 0.007698847716091577\n",
      "130 monoacylglycerol_lipase_inhibitor\n",
      "oof log_loss= 0.004755937027821584, all log_loss= 0.004383274791577642\n",
      "131 monoamine_oxidase_inhibitor\n",
      "oof log_loss= 0.02517965454982387, all log_loss= 0.02320664558912976\n",
      "132 monopolar_spindle_1_kinase_inhibitor\n",
      "oof log_loss= 0.004964934321056631, all log_loss= 0.004575895627721206\n",
      "133 mtor_inhibitor\n",
      "oof log_loss= 0.015155339214496223, all log_loss= 0.013967808225403751\n",
      "134 mucolytic_agent\n",
      "oof log_loss= 0.015540815992468966, all log_loss= 0.014323080095855825\n",
      "135 neuropeptide_receptor_antagonist\n",
      "oof log_loss= 0.011681595890427799, all log_loss= 0.010766257940837793\n",
      "136 nfkb_inhibitor\n",
      "oof log_loss= 0.03219414575792066, all log_loss= 0.029671500423903777\n",
      "137 nicotinic_receptor_agonist\n",
      "oof log_loss= 0.0023813947145326655, all log_loss= 0.0021947951286875288\n",
      "138 nitric_oxide_donor\n",
      "oof log_loss= 0.008972392515834803, all log_loss= 0.008269340343392294\n",
      "139 nitric_oxide_production_inhibitor\n",
      "oof log_loss= 0.0035011625184729256, all log_loss= 0.003226820985783389\n",
      "140 nitric_oxide_synthase_inhibitor\n",
      "oof log_loss= 0.009086434518310078, all log_loss= 0.008374446326021308\n",
      "141 norepinephrine_reuptake_inhibitor\n",
      "oof log_loss= 0.0028101478276018024, all log_loss= 0.002589952318812724\n",
      "142 nrf2_activator\n",
      "oof log_loss= 0.004723259075227483, all log_loss= 0.0043531573940998845\n",
      "143 opioid_receptor_agonist\n",
      "oof log_loss= 0.018936383225474168, all log_loss= 0.017452579954342354\n",
      "144 opioid_receptor_antagonist\n",
      "oof log_loss= 0.026822941563519456, all log_loss= 0.02472116912052267\n",
      "145 orexin_receptor_antagonist\n",
      "oof log_loss= 0.012031641381388097, all log_loss= 0.011088874823158972\n",
      "146 p38_mapk_inhibitor\n",
      "oof log_loss= 0.008085788623329454, all log_loss= 0.007452208310440782\n",
      "147 p-glycoprotein_inhibitor\n",
      "oof log_loss= 0.007592793920955145, all log_loss= 0.006997843326493885\n",
      "148 parp_inhibitor\n",
      "oof log_loss= 0.01705025797335053, all log_loss= 0.015714246325652947\n",
      "149 pdgfr_inhibitor\n",
      "oof log_loss= 0.017235679314774096, all log_loss= 0.01588513855717913\n",
      "150 pdk_inhibitor\n",
      "oof log_loss= 0.005868580223995252, all log_loss= 0.005408734305713011\n",
      "151 phosphodiesterase_inhibitor\n",
      "oof log_loss= 0.06070600194345158, all log_loss= 0.05594924542936412\n",
      "152 phospholipase_inhibitor\n",
      "oof log_loss= 0.008785516921171174, all log_loss= 0.008097107809938138\n",
      "153 pi3k_inhibitor\n",
      "oof log_loss= 0.02384828069287089, all log_loss= 0.021979594551403886\n",
      "154 pkc_inhibitor\n",
      "oof log_loss= 0.009211517406269566, all log_loss= 0.008489728060502489\n",
      "155 potassium_channel_activator\n",
      "oof log_loss= 0.017137935000599017, all log_loss= 0.015795053220506807\n",
      "156 potassium_channel_antagonist\n",
      "oof log_loss= 0.027807984967096962, all log_loss= 0.025629027213313425\n",
      "157 ppar_receptor_agonist\n",
      "oof log_loss= 0.02186288638554229, all log_loss= 0.020149770319555057\n",
      "158 ppar_receptor_antagonist\n",
      "oof log_loss= 0.009175897616474873, all log_loss= 0.00845689934015253\n",
      "159 progesterone_receptor_agonist\n",
      "oof log_loss= 0.029031531938771168, all log_loss= 0.026756700385997798\n",
      "160 progesterone_receptor_antagonist\n",
      "oof log_loss= 0.005224807854918086, all log_loss= 0.004815406181227178\n",
      "161 prostaglandin_inhibitor\n",
      "oof log_loss= 0.011896796234987964, all log_loss= 0.010964595774146204\n",
      "162 prostanoid_receptor_antagonist\n",
      "oof log_loss= 0.024080023580784257, all log_loss= 0.02219317869954878\n",
      "163 proteasome_inhibitor\n",
      "oof log_loss= 0.000982051404622173, all log_loss= 0.0009051005387019955\n",
      "164 protein_kinase_inhibitor\n",
      "oof log_loss= 0.014832533453259512, all log_loss= 0.013670296641981255\n",
      "165 protein_phosphatase_inhibitor\n",
      "oof log_loss= 0.002126515080220971, all log_loss= 0.0019598871664017695\n",
      "166 protein_synthesis_inhibitor\n",
      "oof log_loss= 0.023372429022011604, all log_loss= 0.02154102931784297\n",
      "167 protein_tyrosine_kinase_inhibitor\n",
      "oof log_loss= 0.006315255432401888, all log_loss= 0.005820409264733287\n",
      "168 radiopaque_medium\n",
      "oof log_loss= 0.016993811936905523, all log_loss= 0.015662223246460244\n",
      "169 raf_inhibitor\n",
      "oof log_loss= 0.005405074348534044, all log_loss= 0.004981547484741204\n",
      "170 ras_gtpase_inhibitor\n",
      "oof log_loss= 0.004502785676429537, all log_loss= 0.0041499596886821755\n",
      "171 retinoid_receptor_agonist\n",
      "oof log_loss= 0.009502807213048907, all log_loss= 0.008758193193583577\n",
      "172 retinoid_receptor_antagonist\n",
      "oof log_loss= 0.0023897905288958795, all log_loss= 0.0022025330699676085\n",
      "173 rho_associated_kinase_inhibitor\n",
      "oof log_loss= 0.007939879757823188, all log_loss= 0.007317732465134173\n",
      "174 ribonucleoside_reductase_inhibitor\n",
      "oof log_loss= 0.009979580225608284, all log_loss= 0.0091976075750253\n",
      "175 rna_polymerase_inhibitor\n",
      "oof log_loss= 0.008543586529167634, all log_loss= 0.0078741344226998\n",
      "176 serotonin_receptor_agonist\n",
      "oof log_loss= 0.057486194244471794, all log_loss= 0.05298173306784533\n",
      "177 serotonin_receptor_antagonist\n",
      "oof log_loss= 0.08438195482170106, all log_loss= 0.0777700153030443\n",
      "178 serotonin_reuptake_inhibitor\n",
      "oof log_loss= 0.014057199919285869, all log_loss= 0.012955716126164779\n",
      "179 sigma_receptor_agonist\n",
      "oof log_loss= 0.01174326799166334, all log_loss= 0.010823097584657295\n",
      "180 sigma_receptor_antagonist\n",
      "oof log_loss= 0.011845621467257594, all log_loss= 0.010917430921448375\n",
      "181 smoothened_receptor_antagonist\n",
      "oof log_loss= 0.008416621779928824, all log_loss= 0.00775711828444947\n",
      "182 sodium_channel_inhibitor\n",
      "oof log_loss= 0.06397340955333591, all log_loss= 0.058960627902772254\n",
      "183 sphingosine_receptor_agonist\n",
      "oof log_loss= 0.008486542922398253, all log_loss= 0.00782156059716128\n",
      "184 src_inhibitor\n",
      "oof log_loss= 0.014651851924547387, all log_loss= 0.013503772824387665\n",
      "185 steroid\n",
      "oof log_loss= 0.0024791535927809138, all log_loss= 0.0022848938882320223\n",
      "186 syk_inhibitor\n",
      "oof log_loss= 0.005834762038492393, all log_loss= 0.005377566020863059\n",
      "187 tachykinin_antagonist\n",
      "oof log_loss= 0.018905969111007233, all log_loss= 0.01742454900681904\n",
      "188 tgf-beta_receptor_inhibitor\n",
      "oof log_loss= 0.0031690940218119805, all log_loss= 0.0029207724695864286\n",
      "189 thrombin_inhibitor\n",
      "oof log_loss= 0.006732295633453043, all log_loss= 0.0062047713346363165\n",
      "190 thymidylate_synthase_inhibitor\n",
      "oof log_loss= 0.010687579204176446, all log_loss= 0.00985012968729598\n",
      "191 tlr_agonist\n",
      "oof log_loss= 0.010152577023049426, all log_loss= 0.00935704881590202\n",
      "192 tlr_antagonist\n",
      "oof log_loss= 0.002605474352297943, all log_loss= 0.002401316498036328\n",
      "193 tnf_inhibitor\n",
      "oof log_loss= 0.011627749140876602, all log_loss= 0.010716630475516986\n",
      "194 topoisomerase_inhibitor\n",
      "oof log_loss= 0.01333115516133515, all log_loss= 0.01228656225249793\n",
      "195 transient_receptor_potential_channel_antagonist\n",
      "oof log_loss= 0.006485769752607278, all log_loss= 0.0059775625485103895\n",
      "196 tropomyosin_receptor_kinase_inhibitor\n",
      "oof log_loss= 0.0026100435842966083, all log_loss= 0.0024055276974949114\n",
      "197 trpv_agonist\n",
      "oof log_loss= 0.006351526580431039, all log_loss= 0.005853838304665419\n",
      "198 trpv_antagonist\n",
      "oof log_loss= 0.015177476466885989, all log_loss= 0.013988210863156776\n",
      "199 tubulin_inhibitor\n",
      "oof log_loss= 0.02053138916337851, all log_loss= 0.018922605583179365\n",
      "200 tyrosine_kinase_inhibitor\n",
      "oof log_loss= 0.019305695189981494, all log_loss= 0.017792953641963365\n",
      "201 ubiquitin_specific_protease_inhibitor\n",
      "oof log_loss= 0.002281208322171909, all log_loss= 0.002102459068406438\n",
      "202 vegfr_inhibitor\n",
      "oof log_loss= 0.022345912028882267, all log_loss= 0.020594947392706387\n",
      "203 vitamin_b\n",
      "oof log_loss= 0.009007043120597746, all log_loss= 0.008301275821402587\n",
      "204 vitamin_d_receptor_agonist\n",
      "oof log_loss= 0.00465312891248781, all log_loss= 0.0042885224393753385\n",
      "205 wnt_inhibitor\n",
      "oof log_loss= 0.00978072262914428, all log_loss= 0.009014331916707\n",
      "CPU times: user 42min 18s, sys: 25 s, total: 42min 43s\n",
      "Wall time: 43min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def modelling_xgb(X_train, target_train, X_test, ind):\n",
    "    \n",
    "    y_train = target_train[:,ind]\n",
    "    pred_value = np.zeros(X_test.shape[0])\n",
    "    valid = np.zeros([X_train.shape[0]])\n",
    "    X_test = xgb.DMatrix(X_test.values)\n",
    "    \n",
    "    n_folds=5\n",
    "    if y_train.sum() >= n_folds:\n",
    "        skf=StratifiedKFold(n_splits = n_folds, shuffle=True, random_state=0)\n",
    "    else:\n",
    "        skf=KFold(n_splits = n_folds, shuffle=True, random_state=0) \n",
    "        \n",
    "    for i , (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        X_train2 = X_train[train_index,:]\n",
    "        y_train2 = y_train[train_index]\n",
    "\n",
    "        X_test2 = X_train[test_index,:]\n",
    "        y_test2 = y_train[test_index]\n",
    "            \n",
    "        xgb_train = xgb.DMatrix(X_train2, label = y_train2)\n",
    "        xgb_eval = xgb.DMatrix(X_test2, label = y_test2)\n",
    "        watchlist = [(xgb_train, \"train\"), (xgb_eval, \"eval\")]\n",
    "        \n",
    "        clf = xgb.train(\n",
    "        xgb_params, xgb_train, 100000, watchlist,\n",
    "        early_stopping_rounds=25, verbose_eval = False\n",
    "    )\n",
    "\n",
    "        valid[test_index] = clf.predict(xgb_eval, ntree_limit=clf.best_ntree_limit)    \n",
    "        pred_value += clf.predict(X_test, ntree_limit=clf.best_ntree_limit) / n_folds\n",
    "\n",
    "    score = log_loss(y_train, valid)\n",
    "        \n",
    "    return valid, pred_value, score\n",
    "\n",
    "checkscore2 = targets.copy()\n",
    "\n",
    "for ind, target in enumerate(target_feats):\n",
    "    print(ind, target)\n",
    "    valid, pred_value, score = modelling_xgb(train_feat, fn_targets, test_feat, ind)\n",
    "    checkscore2.loc[cons_train_index, target] = valid\n",
    "    checkscore2.loc[~checkscore2.index.isin(cons_train_index), target] = 0\n",
    "    print(\"oof log_loss= {}, all log_loss= {}\".format(score, log_loss(targets[target], checkscore2[target])))\n",
    "    final.loc[cons_test_index, target] = pred_value\n",
    "    final.loc[~final.index.isin(cons_test_index), target] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T13:21:19.331202Z",
     "iopub.status.busy": "2020-10-27T13:21:19.330315Z",
     "iopub.status.idle": "2020-10-27T13:21:20.271542Z",
     "shell.execute_reply": "2020-10-27T13:21:20.272488Z"
    },
    "papermill": {
     "duration": 1.290885,
     "end_time": "2020-10-27T13:21:20.272649",
     "exception": false,
     "start_time": "2020-10-27T13:21:18.981764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014609845656039927\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for target_col in target_feats:\n",
    "    scores.append(log_loss(targets[target_col], checkscore2[target_col]))\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T13:21:20.967769Z",
     "iopub.status.busy": "2020-10-27T13:21:20.967121Z",
     "iopub.status.idle": "2020-10-27T13:21:22.960100Z",
     "shell.execute_reply": "2020-10-27T13:21:22.959489Z"
    },
    "papermill": {
     "duration": 2.340463,
     "end_time": "2020-10-27T13:21:22.960218",
     "exception": false,
     "start_time": "2020-10-27T13:21:20.619755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 5696.524332,
   "end_time": "2020-10-27T13:21:24.735451",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-27T11:46:28.211119",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0960761f2e67430cad52456fffe42dd8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "63468778dcb54009bf9afc12b1cd6497": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7ca924b9c1364ccdbaa8f1ba227619d5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f958b81d5d634d59a1f19c5543d35355",
       "max": 206.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0960761f2e67430cad52456fffe42dd8",
       "value": 206.0
      }
     },
     "7f3ba958334d49aa907e8e1932e30ffd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d03355e2b47a42839cb6eb4fd634f32e",
       "placeholder": "​",
       "style": "IPY_MODEL_eb3351ca4cf44cb590d5f3a8b9a84977",
       "value": " 206/206 [09:06&lt;00:00,  2.65s/it]"
      }
     },
     "c527d35e2bd94e52a672d85aedd03b6a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7ca924b9c1364ccdbaa8f1ba227619d5",
        "IPY_MODEL_7f3ba958334d49aa907e8e1932e30ffd"
       ],
       "layout": "IPY_MODEL_63468778dcb54009bf9afc12b1cd6497"
      }
     },
     "d03355e2b47a42839cb6eb4fd634f32e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eb3351ca4cf44cb590d5f3a8b9a84977": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f958b81d5d634d59a1f19c5543d35355": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
