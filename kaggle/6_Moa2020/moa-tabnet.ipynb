{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020913,
     "end_time": "2020-11-08T08:50:41.861167",
     "exception": false,
     "start_time": "2020-11-08T08:50:41.840254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- fold 5, 1 ensemble\n",
    "- cancel any fe\n",
    "- extract train oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:50:41.906600Z",
     "iopub.status.busy": "2020-11-08T08:50:41.905704Z",
     "iopub.status.idle": "2020-11-08T08:50:51.383172Z",
     "shell.execute_reply": "2020-11-08T08:50:51.382629Z"
    },
    "papermill": {
     "duration": 9.502624,
     "end_time": "2020-11-08T08:50:51.383290",
     "exception": false,
     "start_time": "2020-11-08T08:50:41.880666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl\r\n",
      "Processing /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: tqdm<5.0,>=4.36 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (4.45.0)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.18.5)\r\n",
      "Requirement already satisfied: scipy>1.4 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.4.1)\r\n",
      "Requirement already satisfied: scikit_learn>0.21 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (0.23.2)\r\n",
      "Requirement already satisfied: torch<2.0,>=1.2 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.6.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (0.14.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (2.1.0)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch<2.0,>=1.2->pytorch-tabnet) (0.18.2)\r\n",
      "Installing collected packages: pytorch-tabnet\r\n",
      "Successfully installed pytorch-tabnet-2.0.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-index --find-links /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-08T08:50:51.438943Z",
     "iopub.status.busy": "2020-11-08T08:50:51.438047Z",
     "iopub.status.idle": "2020-11-08T08:51:01.746589Z",
     "shell.execute_reply": "2020-11-08T08:51:01.745064Z"
    },
    "papermill": {
     "duration": 10.338908,
     "end_time": "2020-11-08T08:51:01.746708",
     "exception": false,
     "start_time": "2020-11-08T08:50:51.407800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from umap import UMAP\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss,roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "sys.path.append('../input/multilabelstraifier/')\n",
    "from ml_stratifiers import MultilabelStratifiedKFold\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:51:01.798604Z",
     "iopub.status.busy": "2020-11-08T08:51:01.797644Z",
     "iopub.status.idle": "2020-11-08T08:51:08.633064Z",
     "shell.execute_reply": "2020-11-08T08:51:08.631926Z"
    },
    "papermill": {
     "duration": 6.865564,
     "end_time": "2020-11-08T08:51:08.633225",
     "exception": false,
     "start_time": "2020-11-08T08:51:01.767661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/lish-moa/'\n",
    "train = pd.read_csv(DATA_DIR + 'train_features.csv')\n",
    "targets = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "non_targets = pd.read_csv(DATA_DIR + 'train_targets_nonscored.csv')\n",
    "test = pd.read_csv(DATA_DIR + 'test_features.csv')\n",
    "sub = pd.read_csv(DATA_DIR + 'sample_submission.csv')\n",
    "drug = pd.read_csv(DATA_DIR + 'train_drug.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:51:08.685579Z",
     "iopub.status.busy": "2020-11-08T08:51:08.684602Z",
     "iopub.status.idle": "2020-11-08T08:51:08.810166Z",
     "shell.execute_reply": "2020-11-08T08:51:08.809426Z"
    },
    "papermill": {
     "duration": 0.156696,
     "end_time": "2020-11-08T08:51:08.810300",
     "exception": false,
     "start_time": "2020-11-08T08:51:08.653604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_feats = [ i for i in targets.columns if i != \"sig_id\"]\n",
    "g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "c_feats = [i for i in train.columns if \"c-\" in i]\n",
    "\n",
    "noncons_train_index = train[train.cp_type==\"ctl_vehicle\"].index\n",
    "cons_train_index = train[~train.index.isin(noncons_train_index)].index\n",
    "noncons_test_index = test[test.cp_type==\"ctl_vehicle\"].index\n",
    "cons_test_index = test[test.cp_type!=\"ctl_vehicle\"].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033982,
     "end_time": "2020-11-08T08:51:08.885212",
     "exception": false,
     "start_time": "2020-11-08T08:51:08.851230",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:51:08.969680Z",
     "iopub.status.busy": "2020-11-08T08:51:08.968791Z",
     "iopub.status.idle": "2020-11-08T08:51:09.232183Z",
     "shell.execute_reply": "2020-11-08T08:51:09.231319Z"
    },
    "papermill": {
     "duration": 0.310646,
     "end_time": "2020-11-08T08:51:09.232342",
     "exception": false,
     "start_time": "2020-11-08T08:51:08.921696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train[train.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "targets = targets[targets.index.isin(cons_train_index)].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:51:09.306167Z",
     "iopub.status.busy": "2020-11-08T08:51:09.305129Z",
     "iopub.status.idle": "2020-11-08T08:51:10.073856Z",
     "shell.execute_reply": "2020-11-08T08:51:10.074431Z"
    },
    "papermill": {
     "duration": 0.809401,
     "end_time": "2020-11-08T08:51:10.074628",
     "exception": false,
     "start_time": "2020-11-08T08:51:09.265227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 4, 1, ..., 0, 1, 4]], dtype=int8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/c/lish-moa/discussion/195195\n",
    "NB_SPLITS = 5\n",
    "seed = 14\n",
    "\n",
    "folds = []\n",
    "    \n",
    "# LOAD FILES\n",
    "train_score = targets.merge(drug, on='sig_id', how='left') \n",
    "\n",
    "# LOCATE DRUGS\n",
    "vc = train_score.drug_id.value_counts()\n",
    "vc1 = vc.loc[vc <= 19].index.sort_values()\n",
    "vc2 = vc.loc[vc > 19].index.sort_values()\n",
    "    \n",
    "# STRATIFY DRUGS 18X OR LESS\n",
    "dct1 = {}; dct2 = {}\n",
    "skf = MultilabelStratifiedKFold(n_splits = NB_SPLITS, shuffle = True, random_state = seed)\n",
    "tmp = train_score.groupby('drug_id')[target_feats].mean().loc[vc1]\n",
    "for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_feats])):\n",
    "    dd = {k:fold for k in tmp.index[idxV].values}\n",
    "    dct1.update(dd)\n",
    "\n",
    "# STRATIFY DRUGS MORE THAN 18X\n",
    "skf = MultilabelStratifiedKFold(n_splits = NB_SPLITS, shuffle = True, random_state = seed)\n",
    "tmp = train_score.loc[train_score.drug_id.isin(vc2)].reset_index(drop = True)\n",
    "for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_feats])):\n",
    "    dd = {k:fold for k in tmp.sig_id[idxV].values}\n",
    "    dct2.update(dd)\n",
    "\n",
    "# ASSIGN FOLDS\n",
    "train_score['fold'] = train_score.drug_id.map(dct1)\n",
    "train_score.loc[train_score.fold.isna(),'fold'] = train_score.loc[train_score.fold.isna(),'sig_id'].map(dct2)\n",
    "train_score.fold = train_score.fold.astype('int8')\n",
    "folds.append(train_score.fold.values)\n",
    "    \n",
    "np.array(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022112,
     "end_time": "2020-11-08T08:51:10.126322",
     "exception": false,
     "start_time": "2020-11-08T08:51:10.104210",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:51:10.175806Z",
     "iopub.status.busy": "2020-11-08T08:51:10.173814Z",
     "iopub.status.idle": "2020-11-08T08:51:10.176616Z",
     "shell.execute_reply": "2020-11-08T08:51:10.177139Z"
    },
    "papermill": {
     "duration": 0.029238,
     "end_time": "2020-11-08T08:51:10.177259",
     "exception": false,
     "start_time": "2020-11-08T08:51:10.148021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#X = train[g_feats+c_feats].copy().values\n",
    "#select = VarianceThreshold(threshold=0.7)\n",
    "#X_new = select.fit_transform(X)\n",
    "#drop_feats = list(np.array(train[g_feats+c_feats].columns)[select.get_support()==False])\n",
    "#len(drop_feats)\n",
    "\n",
    "#train.drop(drop_feats, axis=1, inplace=True)\n",
    "#test.drop(drop_feats, axis=1, inplace=True)\n",
    "\n",
    "#g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "#c_feats = [i for i in train.columns if \"c-\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:51:10.227553Z",
     "iopub.status.busy": "2020-11-08T08:51:10.225666Z",
     "iopub.status.idle": "2020-11-08T08:51:10.228287Z",
     "shell.execute_reply": "2020-11-08T08:51:10.228830Z"
    },
    "papermill": {
     "duration": 0.029175,
     "end_time": "2020-11-08T08:51:10.228961",
     "exception": false,
     "start_time": "2020-11-08T08:51:10.199786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for i in c_feats + g_feats:\n",
    "    #ss = preprocessing.QuantileTransformer(n_quantiles=100, random_state=0, output_distribution=\"normal\")\n",
    "#    ss = preprocessing.RobustScaler()\n",
    "#    ss.fit(train[i].values.reshape(-1,1))\n",
    "#    train[i] = ss.transform(train[i].values.reshape(-1,1))\n",
    "#    test[i] = ss.transform(test[i].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:51:10.276615Z",
     "iopub.status.busy": "2020-11-08T08:51:10.275889Z",
     "iopub.status.idle": "2020-11-08T08:51:10.280130Z",
     "shell.execute_reply": "2020-11-08T08:51:10.279662Z"
    },
    "papermill": {
     "duration": 0.028858,
     "end_time": "2020-11-08T08:51:10.280245",
     "exception": false,
     "start_time": "2020-11-08T08:51:10.251387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#c_num = 1\n",
    "#pca_c_cols = [\"pca-c\"+str(i+1) for i in range(c_num)]\n",
    "#pca = PCA(n_components=c_num,random_state=42)\n",
    "#c_train = pca.fit_transform(train[c_feats])\n",
    "#c_test = pca.transform(test[c_feats])\n",
    "#c_train = pd.DataFrame(c_train, columns=pca_c_cols)\n",
    "#c_test = pd.DataFrame(c_test, columns=pca_c_cols)\n",
    "\n",
    "#g_num = 10\n",
    "#pca_g_cols = [\"pca-g\"+str(i+1) for i in range(g_num)]\n",
    "#pca = PCA(n_components=g_num, random_state=42)\n",
    "#g_train = pca.fit_transform(train[g_feats])\n",
    "#g_test = pca.transform(test[g_feats])\n",
    "#g_train = pd.DataFrame(g_train, columns=pca_g_cols)\n",
    "#g_test = pd.DataFrame(g_test, columns=pca_g_cols)\n",
    "\n",
    "#train = pd.concat([train, c_train],axis=1)\n",
    "#test = pd.concat([test, c_test],axis=1)\n",
    "#train = pd.concat([train, g_train],axis=1)\n",
    "#test = pd.concat([test, g_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:51:10.328452Z",
     "iopub.status.busy": "2020-11-08T08:51:10.327544Z",
     "iopub.status.idle": "2020-11-08T08:51:10.330148Z",
     "shell.execute_reply": "2020-11-08T08:51:10.330837Z"
    },
    "papermill": {
     "duration": 0.029772,
     "end_time": "2020-11-08T08:51:10.330973",
     "exception": false,
     "start_time": "2020-11-08T08:51:10.301201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#uc_num = 1\n",
    "#um = UMAP(n_neighbors=30, n_components=uc_num, random_state=42)\n",
    "#um_c_cols = [\"um-c\"+str(i+1) for i in range(uc_num)]#\n",
    "#uc_train = um.fit_transform(train[c_feats])\n",
    "#uc_test = um.transform(test[c_feats])\n",
    "#uc_train = pd.DataFrame(uc_train, columns=um_c_cols)\n",
    "#uc_test = pd.DataFrame(uc_test, columns=um_c_cols)\n",
    "\n",
    "#ug_num = 10\n",
    "#um = UMAP(n_neighbors=30, n_components=ug_num, random_state=42)\n",
    "#um_g_cols = [\"um-g\"+str(i+1) for i in range(ug_num)]\n",
    "#ug_train = um.fit_transform(train[g_feats])\n",
    "#ug_test = um.transform(test[g_feats])\n",
    "#ug_train = pd.DataFrame(ug_train, columns=um_g_cols)\n",
    "#ug_test = pd.DataFrame(ug_test, columns=um_g_cols)\n",
    "\n",
    "#train = pd.concat([train, uc_train],axis=1)\n",
    "#test = pd.concat([test, uc_test],axis=1)\n",
    "#train = pd.concat([train, ug_train],axis=1)\n",
    "#test = pd.concat([test, ug_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:51:10.380507Z",
     "iopub.status.busy": "2020-11-08T08:51:10.378679Z",
     "iopub.status.idle": "2020-11-08T08:51:10.381176Z",
     "shell.execute_reply": "2020-11-08T08:51:10.381662Z"
    },
    "papermill": {
     "duration": 0.028657,
     "end_time": "2020-11-08T08:51:10.381775",
     "exception": false,
     "start_time": "2020-11-08T08:51:10.353118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#n_clusters_g = 15\n",
    "#n_clusters_c = 5\n",
    "#def create_cluster(train, test, kind, n_clusters):\n",
    "#    if kind == \"g\":\n",
    "#        train_ = train[pca_g_cols].copy()\n",
    "#        test_ = test[pca_g_cols].copy()\n",
    "#    else:\n",
    "#        train_ = train[pca_c_cols].copy()\n",
    "#        test_ = test[pca_c_cols].copy()    \n",
    "#    kmeans = KMeans(n_clusters = n_clusters, random_state = 0).fit(train_)\n",
    "#    train[f'clusters_{kind}'] = kmeans.labels_\n",
    "#    test[f'clusters_{kind}'] = kmeans.predict(test_)\n",
    "#    train = pd.get_dummies(train, columns = [f'clusters_{kind}'])\n",
    "#    test = pd.get_dummies(test, columns = [f'clusters_{kind}'])\n",
    "#    return train, test\n",
    "    \n",
    "#train, test = create_cluster(train, test, kind = 'g', n_clusters = n_clusters_g)\n",
    "#train, test = create_cluster(train, test, kind = 'c', n_clusters = n_clusters_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:51:10.435306Z",
     "iopub.status.busy": "2020-11-08T08:51:10.433935Z",
     "iopub.status.idle": "2020-11-08T08:51:10.579623Z",
     "shell.execute_reply": "2020-11-08T08:51:10.580204Z"
    },
    "papermill": {
     "duration": 0.176231,
     "end_time": "2020-11-08T08:51:10.580346",
     "exception": false,
     "start_time": "2020-11-08T08:51:10.404115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 874) (3982, 874)\n"
     ]
    }
   ],
   "source": [
    "def fe(df):\n",
    "    tmp = df.copy()\n",
    "    tmp.loc[:, 'cp_dose'] = tmp.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})      \n",
    "    tmp.drop([\"sig_id\", \"cp_type\"], axis=1, inplace=True)\n",
    "    return tmp\n",
    "\n",
    "train = fe(train)\n",
    "test = fe(test)\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:51:10.633936Z",
     "iopub.status.busy": "2020-11-08T08:51:10.633054Z",
     "iopub.status.idle": "2020-11-08T08:51:10.636040Z",
     "shell.execute_reply": "2020-11-08T08:51:10.636544Z"
    },
    "papermill": {
     "duration": 0.032494,
     "end_time": "2020-11-08T08:51:10.636681",
     "exception": false,
     "start_time": "2020-11-08T08:51:10.604187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[\"fold\"] = np.array(folds).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:51:10.687783Z",
     "iopub.status.busy": "2020-11-08T08:51:10.686603Z",
     "iopub.status.idle": "2020-11-08T08:51:10.849844Z",
     "shell.execute_reply": "2020-11-08T08:51:10.849232Z"
    },
    "papermill": {
     "duration": 0.190595,
     "end_time": "2020-11-08T08:51:10.849963",
     "exception": false,
     "start_time": "2020-11-08T08:51:10.659368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fn_train = train.copy().to_numpy()\n",
    "fn_test = test.copy().to_numpy()\n",
    "    \n",
    "fn_targets = targets.drop(\"sig_id\", axis=1).copy().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:51:10.902375Z",
     "iopub.status.busy": "2020-11-08T08:51:10.901541Z",
     "iopub.status.idle": "2020-11-08T08:51:10.905337Z",
     "shell.execute_reply": "2020-11-08T08:51:10.905905Z"
    },
    "papermill": {
     "duration": 0.033313,
     "end_time": "2020-11-08T08:51:10.906038",
     "exception": false,
     "start_time": "2020-11-08T08:51:10.872725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21948, 875), (3982, 874), (21948, 206))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_train.shape, fn_test.shape, fn_targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024099,
     "end_time": "2020-11-08T08:51:10.954386",
     "exception": false,
     "start_time": "2020-11-08T08:51:10.930287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:51:11.011466Z",
     "iopub.status.busy": "2020-11-08T08:51:11.010555Z",
     "iopub.status.idle": "2020-11-08T08:51:11.014813Z",
     "shell.execute_reply": "2020-11-08T08:51:11.014191Z"
    },
    "papermill": {
     "duration": 0.036164,
     "end_time": "2020-11-08T08:51:11.014929",
     "exception": false,
     "start_time": "2020-11-08T08:51:10.978765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LogitsLogLoss(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"logits_ll\"\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "\n",
    "        logits = 1 / (1 + np.exp(-y_pred))\n",
    "        \n",
    "        aux = (1-y_true)*np.log(1-logits+1e-15) + y_true*np.log(logits+1e-15)\n",
    "        return np.mean(-aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:51:11.077620Z",
     "iopub.status.busy": "2020-11-08T08:51:11.072373Z",
     "iopub.status.idle": "2020-11-08T08:59:39.596101Z",
     "shell.execute_reply": "2020-11-08T08:59:39.596631Z"
    },
    "papermill": {
     "duration": 508.557471,
     "end_time": "2020-11-08T08:59:39.596791",
     "exception": false,
     "start_time": "2020-11-08T08:51:11.039320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLDS :  1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.56822 | val_logits_ll: 0.32031 |  0:00:01s\n",
      "epoch 10 | loss: 0.02073 | val_logits_ll: 0.02057 |  0:00:11s\n",
      "epoch 20 | loss: 0.01911 | val_logits_ll: 0.01923 |  0:00:22s\n",
      "epoch 30 | loss: 0.01795 | val_logits_ll: 0.01885 |  0:00:32s\n",
      "epoch 40 | loss: 0.01726 | val_logits_ll: 0.01974 |  0:00:44s\n",
      "epoch 50 | loss: 0.01696 | val_logits_ll: 0.01791 |  0:00:55s\n",
      "epoch 60 | loss: 0.01648 | val_logits_ll: 0.01779 |  0:01:05s\n",
      "epoch 70 | loss: 0.01624 | val_logits_ll: 0.01918 |  0:01:15s\n",
      "epoch 80 | loss: 0.01608 | val_logits_ll: 0.01816 |  0:01:26s\n",
      "epoch 90 | loss: 0.01591 | val_logits_ll: 0.01762 |  0:01:38s\n",
      "\n",
      "Early stopping occured at epoch 92 with best_epoch = 72 and best_val_logits_ll = 0.01751\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.56335 | val_logits_ll: 0.30359 |  0:00:01s\n",
      "epoch 10 | loss: 0.02052 | val_logits_ll: 0.02025 |  0:00:11s\n",
      "epoch 20 | loss: 0.01904 | val_logits_ll: 0.01894 |  0:00:22s\n",
      "epoch 30 | loss: 0.01772 | val_logits_ll: 0.01812 |  0:00:32s\n",
      "epoch 40 | loss: 0.01701 | val_logits_ll: 0.01985 |  0:00:43s\n",
      "epoch 50 | loss: 0.01656 | val_logits_ll: 0.02032 |  0:00:54s\n",
      "epoch 60 | loss: 0.01603 | val_logits_ll: 0.01783 |  0:01:05s\n",
      "epoch 70 | loss: 0.01587 | val_logits_ll: 0.01754 |  0:01:15s\n",
      "epoch 80 | loss: 0.01563 | val_logits_ll: 0.01765 |  0:01:26s\n",
      "\n",
      "Early stopping occured at epoch 89 with best_epoch = 69 and best_val_logits_ll = 0.01752\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.5625  | val_logits_ll: 0.2968  |  0:00:00s\n",
      "epoch 10 | loss: 0.02049 | val_logits_ll: 0.02139 |  0:00:11s\n",
      "epoch 20 | loss: 0.01836 | val_logits_ll: 0.01972 |  0:00:23s\n",
      "epoch 30 | loss: 0.01722 | val_logits_ll: 0.01938 |  0:00:34s\n",
      "epoch 40 | loss: 0.01676 | val_logits_ll: 0.02025 |  0:00:44s\n",
      "epoch 50 | loss: 0.01643 | val_logits_ll: 0.01891 |  0:00:55s\n",
      "epoch 60 | loss: 0.01633 | val_logits_ll: 0.02013 |  0:01:05s\n",
      "epoch 70 | loss: 0.01582 | val_logits_ll: 0.01848 |  0:01:17s\n",
      "epoch 80 | loss: 0.01553 | val_logits_ll: 0.02074 |  0:01:28s\n",
      "epoch 90 | loss: 0.01515 | val_logits_ll: 0.01862 |  0:01:39s\n",
      "\n",
      "Early stopping occured at epoch 90 with best_epoch = 70 and best_val_logits_ll = 0.01848\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.57363 | val_logits_ll: 0.31949 |  0:00:01s\n",
      "epoch 10 | loss: 0.02078 | val_logits_ll: 0.02061 |  0:00:11s\n",
      "epoch 20 | loss: 0.0188  | val_logits_ll: 0.01908 |  0:00:22s\n",
      "epoch 30 | loss: 0.01781 | val_logits_ll: 0.01827 |  0:00:33s\n",
      "epoch 40 | loss: 0.01703 | val_logits_ll: 0.01794 |  0:00:44s\n",
      "epoch 50 | loss: 0.01658 | val_logits_ll: 0.01932 |  0:00:55s\n",
      "epoch 60 | loss: 0.0163  | val_logits_ll: 0.01771 |  0:01:06s\n",
      "epoch 70 | loss: 0.01585 | val_logits_ll: 0.01757 |  0:01:16s\n",
      "epoch 80 | loss: 0.01553 | val_logits_ll: 0.0177  |  0:01:27s\n",
      "\n",
      "Early stopping occured at epoch 85 with best_epoch = 65 and best_val_logits_ll = 0.01756\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  5\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.57439 | val_logits_ll: 0.28826 |  0:00:01s\n",
      "epoch 10 | loss: 0.02083 | val_logits_ll: 0.0208  |  0:00:12s\n",
      "epoch 20 | loss: 0.01893 | val_logits_ll: 0.01969 |  0:00:23s\n",
      "epoch 30 | loss: 0.01752 | val_logits_ll: 0.01812 |  0:00:34s\n",
      "epoch 40 | loss: 0.01707 | val_logits_ll: 0.0178  |  0:00:44s\n",
      "epoch 50 | loss: 0.01662 | val_logits_ll: 0.01901 |  0:00:54s\n",
      "epoch 60 | loss: 0.0164  | val_logits_ll: 0.01769 |  0:01:06s\n",
      "epoch 70 | loss: 0.01633 | val_logits_ll: 0.01776 |  0:01:16s\n",
      "epoch 80 | loss: 0.016   | val_logits_ll: 0.01768 |  0:01:26s\n",
      "epoch 90 | loss: 0.01573 | val_logits_ll: 0.01754 |  0:01:37s\n",
      "\n",
      "Early stopping occured at epoch 99 with best_epoch = 79 and best_val_logits_ll = 0.01747\n",
      "Best weights from best epoch are automatically used!\n",
      "OOF log loss: 0.017705284061671496\n",
      "Overall AUC : 0.6175376498318935\n"
     ]
    }
   ],
   "source": [
    "MAX_EPOCH=200\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def seed_everything(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def modelling_tabnet(tr, target, te, sample_seed):\n",
    "    seed_everything(sample_seed) \n",
    "    tabnet_params = dict(n_d=12, n_a=12, n_steps=1, gamma=1.3, seed = sample_seed,\n",
    "                     lambda_sparse=0, optimizer_fn=torch.optim.Adam,\n",
    "                     optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
    "                     mask_type='entmax',\n",
    "                     scheduler_params=dict(mode=\"min\",\n",
    "                                           patience=5,\n",
    "                                           min_lr=1e-5,\n",
    "                                           factor=0.9,),\n",
    "                     scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                     verbose=10,\n",
    "                     )\n",
    "    test_cv_preds = []\n",
    "\n",
    "    oof_preds = np.zeros([len(tr),target.shape[1]])\n",
    "    scores = []\n",
    "    for fold_nb in range(NB_SPLITS):\n",
    "        print(\"FOLDS : \", fold_nb+1)\n",
    "        \n",
    "        ## model\n",
    "        val_idx = tr[:,-1] == fold_nb\n",
    "        train_idx = tr[:,-1] != fold_nb\n",
    "        X_train, y_train = tr[train_idx, :], target[train_idx, :]\n",
    "        X_val, y_val = tr[val_idx, :], target[val_idx, :]\n",
    "        X_train = np.delete(X_train, -1, 1)\n",
    "        X_val = np.delete(X_val, -1, 1)\n",
    "        model = TabNetRegressor(**tabnet_params)\n",
    "    \n",
    "        model.fit(X_train=X_train,\n",
    "              y_train=y_train,\n",
    "              eval_set=[(X_val, y_val)],\n",
    "              eval_name = [\"val\"],\n",
    "              eval_metric = [\"logits_ll\"],\n",
    "              max_epochs=MAX_EPOCH,\n",
    "              patience=20, batch_size=1024, virtual_batch_size=128,\n",
    "              num_workers=1, drop_last=False,\n",
    "              # use binary cross entropy as this is not a regression problem\n",
    "              loss_fn=torch.nn.functional.binary_cross_entropy_with_logits)\n",
    "    \n",
    "        preds_val = model.predict(X_val)\n",
    "        # Apply sigmoid to the predictions\n",
    "        preds =  1 / (1 + np.exp(-preds_val))\n",
    "        score = np.min(model.history[\"val_logits_ll\"])\n",
    "        oof_preds[val_idx,:] = preds\n",
    "        scores.append(score)\n",
    "\n",
    "        # preds on test\n",
    "        preds_test = model.predict(te)\n",
    "        test_cv_preds.append(1 / (1 + np.exp(-preds_test)))\n",
    "        \n",
    "    test_preds_all = np.stack(test_cv_preds)\n",
    "    print(\"OOF log loss:\", log_loss(np.ravel(target), np.ravel(np.array(oof_preds))))\n",
    "    aucs = []\n",
    "    for task_id in range(206):\n",
    "        aucs.append(roc_auc_score(y_true=target[:, task_id],y_score=oof_preds[:, task_id]))\n",
    "    print(f\"Overall AUC : {np.mean(aucs)}\")\n",
    "    return oof_preds, test_preds_all\n",
    "\n",
    "target_oof = np.zeros([len(fn_train),fn_targets.shape[1]])\n",
    "target_pred = np.zeros([len(fn_test),fn_targets.shape[1]])\n",
    "\n",
    "seeds = [0]\n",
    "for seed_ in seeds:\n",
    "    oof_preds, test_preds_all = modelling_tabnet(fn_train, fn_targets, fn_test, seed_)\n",
    "    target_oof += oof_preds / len(seeds)\n",
    "    target_pred += test_preds_all.mean(axis=0) / len(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:59:39.696273Z",
     "iopub.status.busy": "2020-11-08T08:59:39.695313Z",
     "iopub.status.idle": "2020-11-08T08:59:40.983792Z",
     "shell.execute_reply": "2020-11-08T08:59:40.982770Z"
    },
    "papermill": {
     "duration": 1.34297,
     "end_time": "2020-11-08T08:59:40.983921",
     "exception": false,
     "start_time": "2020-11-08T08:59:39.640951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AUC : 0.6175376498318935\n"
     ]
    }
   ],
   "source": [
    "aucs = []\n",
    "for task_id in range(targets.shape[1]-1):\n",
    "    aucs.append(roc_auc_score(y_true=targets.iloc[:, task_id+1].values,\n",
    "                              y_score=target_oof[:, task_id]))\n",
    "print(f\"Overall AUC : {np.mean(aucs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:59:41.089311Z",
     "iopub.status.busy": "2020-11-08T08:59:41.088340Z",
     "iopub.status.idle": "2020-11-08T08:59:48.897395Z",
     "shell.execute_reply": "2020-11-08T08:59:48.896329Z"
    },
    "papermill": {
     "duration": 7.867596,
     "end_time": "2020-11-08T08:59:48.897571",
     "exception": false,
     "start_time": "2020-11-08T08:59:41.029975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF log loss:  0.016317946358678424\n",
      "OOF log loss:  0.01632044573911291\n"
     ]
    }
   ],
   "source": [
    "p_min = 0.00005\n",
    "p_max = 1 - p_min\n",
    "\n",
    "t = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "train_checkscore = t.copy()\n",
    "train_checkscore.loc[train_checkscore.index.isin(cons_train_index),target_feats] = target_oof\n",
    "train_checkscore.loc[train_checkscore.index.isin(noncons_train_index),target_feats] = 0\n",
    "\n",
    "t.drop(\"sig_id\", axis=1, inplace=True)\n",
    "print('OOF log loss: ', log_loss(np.ravel(t), np.ravel(np.array(train_checkscore.iloc[:,1:]))))\n",
    "print('OOF log loss: ', log_loss(np.ravel(t), np.ravel(np.clip(np.array(train_checkscore.iloc[:,1:]),p_min, p_max))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:59:48.997923Z",
     "iopub.status.busy": "2020-11-08T08:59:48.997024Z",
     "iopub.status.idle": "2020-11-08T09:00:02.678264Z",
     "shell.execute_reply": "2020-11-08T09:00:02.677655Z"
    },
    "papermill": {
     "duration": 13.733604,
     "end_time": "2020-11-08T09:00:02.678387",
     "exception": false,
     "start_time": "2020-11-08T08:59:48.944783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_checkscore.to_csv(\"tab_newval_oof.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T09:00:02.782280Z",
     "iopub.status.busy": "2020-11-08T09:00:02.781410Z",
     "iopub.status.idle": "2020-11-08T09:00:05.163650Z",
     "shell.execute_reply": "2020-11-08T09:00:05.163069Z"
    },
    "papermill": {
     "duration": 2.437501,
     "end_time": "2020-11-08T09:00:05.163777",
     "exception": false,
     "start_time": "2020-11-08T09:00:02.726276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub[target_feats] = target_pred\n",
    "sub.loc[noncons_test_index,target_feats] = 0\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.047727,
     "end_time": "2020-11-08T09:00:05.259861",
     "exception": false,
     "start_time": "2020-11-08T09:00:05.212134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 568.933148,
   "end_time": "2020-11-08T09:00:06.776269",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-08T08:50:37.843121",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
