{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014921,
     "end_time": "2020-10-21T10:59:00.725280",
     "exception": false,
     "start_time": "2020-10-21T10:59:00.710359",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- credit: https://www.kaggle.com/optimo/tabnetregressor-2-0-train-infer/data\n",
    "- https://github.com/dreamquark-ai/tabnet\n",
    "- change virtual_batch_size to 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-21T10:59:00.761086Z",
     "iopub.status.busy": "2020-10-21T10:59:00.760203Z",
     "iopub.status.idle": "2020-10-21T10:59:10.121396Z",
     "shell.execute_reply": "2020-10-21T10:59:10.119548Z"
    },
    "papermill": {
     "duration": 9.382147,
     "end_time": "2020-10-21T10:59:10.121545",
     "exception": false,
     "start_time": "2020-10-21T10:59:00.739398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl\r\n",
      "Processing /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: torch<2.0,>=1.2 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.6.0)\r\n",
      "Requirement already satisfied: tqdm<5.0,>=4.36 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (4.45.0)\r\n",
      "Requirement already satisfied: scipy>1.4 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.4.1)\r\n",
      "Requirement already satisfied: scikit_learn>0.21 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (0.23.2)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.18.5)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch<2.0,>=1.2->pytorch-tabnet) (0.18.2)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (0.14.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (2.1.0)\r\n",
      "Installing collected packages: pytorch-tabnet\r\n",
      "Successfully installed pytorch-tabnet-2.0.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-index --find-links /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-21T10:59:10.168581Z",
     "iopub.status.busy": "2020-10-21T10:59:10.167654Z",
     "iopub.status.idle": "2020-10-21T10:59:17.688743Z",
     "shell.execute_reply": "2020-10-21T10:59:17.688158Z"
    },
    "papermill": {
     "duration": 7.549741,
     "end_time": "2020-10-21T10:59:17.688909",
     "exception": false,
     "start_time": "2020-10-21T10:59:10.139168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss,roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "sys.path.append('../input/multilabelstraifier/')\n",
    "from ml_stratifiers import MultilabelStratifiedKFold\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-21T10:59:17.730618Z",
     "iopub.status.busy": "2020-10-21T10:59:17.729930Z",
     "iopub.status.idle": "2020-10-21T10:59:26.009291Z",
     "shell.execute_reply": "2020-10-21T10:59:26.008009Z"
    },
    "papermill": {
     "duration": 8.303194,
     "end_time": "2020-10-21T10:59:26.009427",
     "exception": false,
     "start_time": "2020-10-21T10:59:17.706233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/lish-moa/'\n",
    "train = pd.read_csv(DATA_DIR + 'train_features.csv')\n",
    "targets = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "non_targets = pd.read_csv(DATA_DIR + 'train_targets_nonscored.csv')\n",
    "test = pd.read_csv(DATA_DIR + 'test_features.csv')\n",
    "sub = pd.read_csv(DATA_DIR + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-21T10:59:26.056222Z",
     "iopub.status.busy": "2020-10-21T10:59:26.055270Z",
     "iopub.status.idle": "2020-10-21T10:59:26.150258Z",
     "shell.execute_reply": "2020-10-21T10:59:26.149614Z"
    },
    "papermill": {
     "duration": 0.123208,
     "end_time": "2020-10-21T10:59:26.150389",
     "exception": false,
     "start_time": "2020-10-21T10:59:26.027181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_feats = [ i for i in targets.columns if i != \"sig_id\"]\n",
    "g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "c_feats = [i for i in train.columns if \"c-\" in i]\n",
    "\n",
    "noncons_train_index = train[train.cp_type==\"ctl_vehicle\"].index\n",
    "cons_train_index = train[~train.index.isin(noncons_train_index)].index\n",
    "noncons_test_index = test[test.cp_type==\"ctl_vehicle\"].index\n",
    "cons_test_index = test[test.cp_type!=\"ctl_vehicle\"].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017189,
     "end_time": "2020-10-21T10:59:26.185313",
     "exception": false,
     "start_time": "2020-10-21T10:59:26.168124",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-21T10:59:26.239208Z",
     "iopub.status.busy": "2020-10-21T10:59:26.235055Z",
     "iopub.status.idle": "2020-10-21T10:59:26.630587Z",
     "shell.execute_reply": "2020-10-21T10:59:26.631674Z"
    },
    "papermill": {
     "duration": 0.42968,
     "end_time": "2020-10-21T10:59:26.631868",
     "exception": false,
     "start_time": "2020-10-21T10:59:26.202188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first drop 71\n",
      "shape after 1st drop: (21948, 332)\n",
      "331\n"
     ]
    }
   ],
   "source": [
    "train = train[train.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "targets = targets[targets.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "non_targets = non_targets[non_targets.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "\n",
    "non_target_feats = [i for i in non_targets.columns if i != \"sig_id\"]\n",
    "nontarget_dists = pd.DataFrame(np.sum(non_targets[non_target_feats])).reset_index(drop=False)\n",
    "nontarget_dists.columns = [\"target\", \"number\"]\n",
    "nontarget_dists = nontarget_dists.sort_values(\"number\", ascending=False).reset_index(drop=True)\n",
    "drop_list1 = list(nontarget_dists[nontarget_dists.number==0][\"target\"].values)\n",
    "print(\"first drop\", len(drop_list1))\n",
    "non_targets.drop(drop_list1, axis=1, inplace=True)\n",
    "print(\"shape after 1st drop:\", non_targets.shape)\n",
    "non_target_feats = [i for i in non_targets.columns if i != \"sig_id\"]\n",
    "print(len(non_target_feats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017988,
     "end_time": "2020-10-21T10:59:26.667730",
     "exception": false,
     "start_time": "2020-10-21T10:59:26.649742",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-21T10:59:26.736714Z",
     "iopub.status.busy": "2020-10-21T10:59:26.735533Z",
     "iopub.status.idle": "2020-10-21T10:59:26.741586Z",
     "shell.execute_reply": "2020-10-21T10:59:26.742790Z"
    },
    "papermill": {
     "duration": 0.047152,
     "end_time": "2020-10-21T10:59:26.743063",
     "exception": false,
     "start_time": "2020-10-21T10:59:26.695911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_clusters_g = 15\n",
    "n_clusters_c = 5\n",
    "def create_cluster(train, test, kind, n_clusters):\n",
    "    if kind == \"g\":\n",
    "        train_ = train[g_feats].copy()\n",
    "        test_ = test[g_feats].copy()\n",
    "    else:\n",
    "        train_ = train[c_feats].copy()\n",
    "        test_ = test[c_feats].copy()    \n",
    "    kmeans = KMeans(n_clusters = n_clusters, random_state = 0).fit(train_)\n",
    "    train[f'clusters_{kind}'] = kmeans.labels_\n",
    "    test[f'clusters_{kind}'] = kmeans.predict(test_)\n",
    "    train = pd.get_dummies(train, columns = [f'clusters_{kind}'])\n",
    "    test = pd.get_dummies(test, columns = [f'clusters_{kind}'])\n",
    "    return train, test\n",
    "    \n",
    "#train, test = create_cluster(train, test, kind = 'g', n_clusters = n_clusters_g)\n",
    "#train, test = create_cluster(train, test, kind = 'c', n_clusters = n_clusters_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-21T10:59:26.807472Z",
     "iopub.status.busy": "2020-10-21T10:59:26.806241Z",
     "iopub.status.idle": "2020-10-21T10:59:26.812188Z",
     "shell.execute_reply": "2020-10-21T10:59:26.813076Z"
    },
    "papermill": {
     "duration": 0.03854,
     "end_time": "2020-10-21T10:59:26.813282",
     "exception": false,
     "start_time": "2020-10-21T10:59:26.774742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#num = 10\n",
    "#pca_c_cols = [\"pca-c\"+str(i+1) for i in range(num)]\n",
    "#pca = PCA(n_components=num,random_state=42)\n",
    "#c_train = pca.fit_transform(train[c_feats])\n",
    "#c_test = pca.transform(test[c_feats])\n",
    "#c_train = pd.DataFrame(c_train, columns=pca_c_cols)\n",
    "#c_test = pd.DataFrame(c_test, columns=pca_c_cols)\n",
    "\n",
    "#num = 30\n",
    "#pca_g_cols = [\"pca-g\"+str(i+1) for i in range(num)]\n",
    "#pca = PCA(n_components=num, random_state=42)\n",
    "#g_train = pca.fit_transform(train[g_feats])\n",
    "#g_test = pca.transform(test[g_feats])\n",
    "#g_train = pd.DataFrame(g_train, columns=pca_g_cols)\n",
    "#g_test = pd.DataFrame(g_test, columns=pca_g_cols)\n",
    "\n",
    "#train = pd.concat([train, c_train],axis=1)\n",
    "#test = pd.concat([test, c_test],axis=1)\n",
    "#train = pd.concat([train, g_train],axis=1)\n",
    "#test = pd.concat([test, g_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-21T10:59:26.886738Z",
     "iopub.status.busy": "2020-10-21T10:59:26.885730Z",
     "iopub.status.idle": "2020-10-21T10:59:27.050769Z",
     "shell.execute_reply": "2020-10-21T10:59:27.051786Z"
    },
    "papermill": {
     "duration": 0.199533,
     "end_time": "2020-10-21T10:59:27.052002",
     "exception": false,
     "start_time": "2020-10-21T10:59:26.852469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 874) (3982, 874)\n"
     ]
    }
   ],
   "source": [
    "def fe(df):\n",
    "    tmp = df.copy()\n",
    "    tmp.loc[:, 'cp_dose'] = tmp.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})        \n",
    "    tmp.drop([\"cp_type\", \"sig_id\"], axis=1, inplace=True)\n",
    "    return tmp\n",
    "\n",
    "train = fe(train)\n",
    "test = fe(test)\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-21T10:59:27.116791Z",
     "iopub.status.busy": "2020-10-21T10:59:27.115413Z",
     "iopub.status.idle": "2020-10-21T10:59:28.642571Z",
     "shell.execute_reply": "2020-10-21T10:59:28.641504Z"
    },
    "papermill": {
     "duration": 1.56346,
     "end_time": "2020-10-21T10:59:28.642709",
     "exception": false,
     "start_time": "2020-10-21T10:59:27.079249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fn_train = train.copy().to_numpy()\n",
    "fn_test = test.copy().to_numpy()\n",
    "\n",
    "ss = preprocessing.RobustScaler()\n",
    "fn_train= ss.fit_transform(fn_train)\n",
    "fn_test = ss.transform(fn_test)\n",
    "\n",
    "fn_non_targets = non_targets.drop(\"sig_id\", axis=1).copy().to_numpy()\n",
    "fn_targets = targets.drop(\"sig_id\", axis=1).copy().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-21T10:59:28.690403Z",
     "iopub.status.busy": "2020-10-21T10:59:28.689092Z",
     "iopub.status.idle": "2020-10-21T10:59:28.693620Z",
     "shell.execute_reply": "2020-10-21T10:59:28.694191Z"
    },
    "papermill": {
     "duration": 0.032118,
     "end_time": "2020-10-21T10:59:28.694324",
     "exception": false,
     "start_time": "2020-10-21T10:59:28.662206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21948, 874), (3982, 874), (21948, 206), (21948, 331))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_train.shape, fn_test.shape, fn_targets.shape, fn_non_targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019058,
     "end_time": "2020-10-21T10:59:28.732523",
     "exception": false,
     "start_time": "2020-10-21T10:59:28.713465",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-21T10:59:28.781980Z",
     "iopub.status.busy": "2020-10-21T10:59:28.781161Z",
     "iopub.status.idle": "2020-10-21T10:59:28.785194Z",
     "shell.execute_reply": "2020-10-21T10:59:28.784568Z"
    },
    "papermill": {
     "duration": 0.032584,
     "end_time": "2020-10-21T10:59:28.785310",
     "exception": false,
     "start_time": "2020-10-21T10:59:28.752726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LogitsLogLoss(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"logits_ll\"\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Compute LogLoss of predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true: np.ndarray\n",
    "            Target matrix or vector\n",
    "        y_score: np.ndarray\n",
    "            Score matrix or vector\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            float\n",
    "            LogLoss of predictions vs targets.\n",
    "        \"\"\"\n",
    "        logits = 1 / (1 + np.exp(-y_pred))\n",
    "        aux = (1-y_true)*np.log(1-logits+1e-15) + y_true*np.log(logits+1e-15)\n",
    "        return np.mean(-aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-21T10:59:28.837175Z",
     "iopub.status.busy": "2020-10-21T10:59:28.836186Z",
     "iopub.status.idle": "2020-10-21T12:05:43.007848Z",
     "shell.execute_reply": "2020-10-21T12:05:43.008452Z"
    },
    "papermill": {
     "duration": 3974.202986,
     "end_time": "2020-10-21T12:05:43.008640",
     "exception": false,
     "start_time": "2020-10-21T10:59:28.805654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLDS :  1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.56095 | val_logits_ll: 0.24957 |  0:00:02s\n",
      "epoch 10 | loss: 0.02106 | val_logits_ll: 0.02071 |  0:00:20s\n",
      "epoch 20 | loss: 0.01907 | val_logits_ll: 0.01886 |  0:00:37s\n",
      "epoch 30 | loss: 0.01791 | val_logits_ll: 0.01791 |  0:00:54s\n",
      "epoch 40 | loss: 0.01749 | val_logits_ll: 0.0178  |  0:01:12s\n",
      "epoch 50 | loss: 0.01725 | val_logits_ll: 0.01898 |  0:01:29s\n",
      "epoch 60 | loss: 0.01719 | val_logits_ll: 0.01759 |  0:01:46s\n",
      "epoch 70 | loss: 0.0168  | val_logits_ll: 0.01712 |  0:02:04s\n",
      "epoch 80 | loss: 0.01657 | val_logits_ll: 0.01689 |  0:02:20s\n",
      "epoch 90 | loss: 0.0163  | val_logits_ll: 0.01693 |  0:02:37s\n",
      "epoch 100| loss: 0.01612 | val_logits_ll: 0.01691 |  0:02:53s\n",
      "epoch 110| loss: 0.01604 | val_logits_ll: 0.01711 |  0:03:10s\n",
      "epoch 120| loss: 0.01599 | val_logits_ll: 0.01698 |  0:03:26s\n",
      "epoch 130| loss: 0.01568 | val_logits_ll: 0.01685 |  0:03:42s\n",
      "epoch 140| loss: 0.01545 | val_logits_ll: 0.0177  |  0:03:59s\n",
      "\n",
      "Early stopping occured at epoch 146 with best_epoch = 126 and best_val_logits_ll = 0.01673\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.56388 | val_logits_ll: 0.25532 |  0:00:01s\n",
      "epoch 10 | loss: 0.02058 | val_logits_ll: 0.02029 |  0:00:18s\n",
      "epoch 20 | loss: 0.01896 | val_logits_ll: 0.01888 |  0:00:34s\n",
      "epoch 30 | loss: 0.01803 | val_logits_ll: 0.01841 |  0:00:50s\n",
      "epoch 40 | loss: 0.01773 | val_logits_ll: 0.01788 |  0:01:07s\n",
      "epoch 50 | loss: 0.01728 | val_logits_ll: 0.01755 |  0:01:23s\n",
      "epoch 60 | loss: 0.01704 | val_logits_ll: 0.01795 |  0:01:39s\n",
      "epoch 70 | loss: 0.01699 | val_logits_ll: 0.01797 |  0:01:56s\n",
      "epoch 80 | loss: 0.01686 | val_logits_ll: 0.01771 |  0:02:12s\n",
      "epoch 90 | loss: 0.01664 | val_logits_ll: 0.02009 |  0:02:28s\n",
      "epoch 100| loss: 0.01646 | val_logits_ll: 0.01721 |  0:02:44s\n",
      "epoch 110| loss: 0.01617 | val_logits_ll: 0.01725 |  0:03:01s\n",
      "epoch 120| loss: 0.01602 | val_logits_ll: 0.0171  |  0:03:17s\n",
      "epoch 130| loss: 0.01582 | val_logits_ll: 0.01699 |  0:03:33s\n",
      "epoch 140| loss: 0.01566 | val_logits_ll: 0.01701 |  0:03:49s\n",
      "\n",
      "Early stopping occured at epoch 147 with best_epoch = 127 and best_val_logits_ll = 0.01695\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.55537 | val_logits_ll: 0.241   |  0:00:01s\n",
      "epoch 10 | loss: 0.02085 | val_logits_ll: 0.02061 |  0:00:17s\n",
      "epoch 20 | loss: 0.01911 | val_logits_ll: 0.02099 |  0:00:33s\n",
      "epoch 30 | loss: 0.01802 | val_logits_ll: 0.01899 |  0:00:50s\n",
      "epoch 40 | loss: 0.01752 | val_logits_ll: 0.01799 |  0:01:06s\n",
      "epoch 50 | loss: 0.0173  | val_logits_ll: 0.01804 |  0:01:21s\n",
      "epoch 60 | loss: 0.01711 | val_logits_ll: 0.01754 |  0:01:37s\n",
      "epoch 70 | loss: 0.01699 | val_logits_ll: 0.0174  |  0:01:54s\n",
      "epoch 80 | loss: 0.0166  | val_logits_ll: 0.01733 |  0:02:10s\n",
      "epoch 90 | loss: 0.01662 | val_logits_ll: 0.0172  |  0:02:26s\n",
      "epoch 100| loss: 0.01635 | val_logits_ll: 0.01715 |  0:02:43s\n",
      "epoch 110| loss: 0.01596 | val_logits_ll: 0.01707 |  0:03:00s\n",
      "\n",
      "Early stopping occured at epoch 117 with best_epoch = 97 and best_val_logits_ll = 0.01699\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.562   | val_logits_ll: 0.2569  |  0:00:01s\n",
      "epoch 10 | loss: 0.02078 | val_logits_ll: 0.02067 |  0:00:17s\n",
      "epoch 20 | loss: 0.0189  | val_logits_ll: 0.01879 |  0:00:35s\n",
      "epoch 30 | loss: 0.01811 | val_logits_ll: 0.02052 |  0:00:52s\n",
      "epoch 40 | loss: 0.01767 | val_logits_ll: 0.01783 |  0:01:09s\n",
      "epoch 50 | loss: 0.01741 | val_logits_ll: 0.01804 |  0:01:25s\n",
      "epoch 60 | loss: 0.01729 | val_logits_ll: 0.01742 |  0:01:43s\n",
      "epoch 70 | loss: 0.0171  | val_logits_ll: 0.01728 |  0:02:00s\n",
      "epoch 80 | loss: 0.01683 | val_logits_ll: 0.01713 |  0:02:17s\n",
      "epoch 90 | loss: 0.01665 | val_logits_ll: 0.01707 |  0:02:34s\n",
      "epoch 100| loss: 0.01644 | val_logits_ll: 0.01691 |  0:02:52s\n",
      "epoch 110| loss: 0.01629 | val_logits_ll: 0.01693 |  0:03:09s\n",
      "epoch 120| loss: 0.01618 | val_logits_ll: 0.01686 |  0:03:26s\n",
      "epoch 130| loss: 0.01596 | val_logits_ll: 0.01689 |  0:03:44s\n",
      "epoch 140| loss: 0.01567 | val_logits_ll: 0.01676 |  0:04:01s\n",
      "epoch 150| loss: 0.01568 | val_logits_ll: 0.01682 |  0:04:18s\n",
      "epoch 160| loss: 0.01536 | val_logits_ll: 0.01694 |  0:04:37s\n",
      "\n",
      "Early stopping occured at epoch 164 with best_epoch = 144 and best_val_logits_ll = 0.01668\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  5\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.5528  | val_logits_ll: 0.22714 |  0:00:01s\n",
      "epoch 10 | loss: 0.02094 | val_logits_ll: 0.02067 |  0:00:19s\n",
      "epoch 20 | loss: 0.01903 | val_logits_ll: 0.01951 |  0:00:36s\n",
      "epoch 30 | loss: 0.01806 | val_logits_ll: 0.021   |  0:00:56s\n",
      "epoch 40 | loss: 0.0176  | val_logits_ll: 0.01876 |  0:01:13s\n",
      "epoch 50 | loss: 0.01726 | val_logits_ll: 0.01758 |  0:01:30s\n",
      "epoch 60 | loss: 0.01707 | val_logits_ll: 0.01841 |  0:01:48s\n",
      "epoch 70 | loss: 0.01685 | val_logits_ll: 0.01731 |  0:02:05s\n",
      "epoch 80 | loss: 0.01671 | val_logits_ll: 0.01731 |  0:02:22s\n",
      "epoch 90 | loss: 0.01661 | val_logits_ll: 0.01713 |  0:02:38s\n",
      "epoch 100| loss: 0.0163  | val_logits_ll: 0.01705 |  0:02:56s\n",
      "epoch 110| loss: 0.01623 | val_logits_ll: 0.01715 |  0:03:12s\n",
      "epoch 120| loss: 0.01607 | val_logits_ll: 0.01721 |  0:03:29s\n",
      "epoch 130| loss: 0.01579 | val_logits_ll: 0.0169  |  0:03:46s\n",
      "epoch 140| loss: 0.01551 | val_logits_ll: 0.01701 |  0:04:04s\n",
      "epoch 150| loss: 0.01548 | val_logits_ll: 0.01697 |  0:04:20s\n",
      "\n",
      "Early stopping occured at epoch 158 with best_epoch = 138 and best_val_logits_ll = 0.01684\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.52269 | val_logits_ll: 0.23405 |  0:00:01s\n",
      "epoch 10 | loss: 0.02133 | val_logits_ll: 0.02125 |  0:00:18s\n",
      "epoch 20 | loss: 0.01968 | val_logits_ll: 0.02069 |  0:00:35s\n",
      "epoch 30 | loss: 0.01824 | val_logits_ll: 0.01926 |  0:00:51s\n",
      "epoch 40 | loss: 0.01778 | val_logits_ll: 0.01787 |  0:01:07s\n",
      "epoch 50 | loss: 0.01747 | val_logits_ll: 0.01755 |  0:01:25s\n",
      "epoch 60 | loss: 0.01714 | val_logits_ll: 0.01759 |  0:01:41s\n",
      "epoch 70 | loss: 0.01704 | val_logits_ll: 0.01724 |  0:01:57s\n",
      "epoch 80 | loss: 0.01672 | val_logits_ll: 0.01712 |  0:02:15s\n",
      "epoch 90 | loss: 0.01667 | val_logits_ll: 0.01739 |  0:02:31s\n",
      "epoch 100| loss: 0.01659 | val_logits_ll: 0.01718 |  0:02:48s\n",
      "epoch 110| loss: 0.01619 | val_logits_ll: 0.01706 |  0:03:04s\n",
      "epoch 120| loss: 0.01613 | val_logits_ll: 0.01766 |  0:03:21s\n",
      "epoch 130| loss: 0.01604 | val_logits_ll: 0.01692 |  0:03:37s\n",
      "epoch 140| loss: 0.01587 | val_logits_ll: 0.01681 |  0:03:54s\n",
      "epoch 150| loss: 0.0157  | val_logits_ll: 0.01696 |  0:04:10s\n",
      "epoch 160| loss: 0.01539 | val_logits_ll: 0.01684 |  0:04:27s\n",
      "epoch 170| loss: 0.01547 | val_logits_ll: 0.01682 |  0:04:43s\n",
      "\n",
      "Early stopping occured at epoch 176 with best_epoch = 156 and best_val_logits_ll = 0.01674\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.522   | val_logits_ll: 0.22375 |  0:00:01s\n",
      "epoch 10 | loss: 0.02112 | val_logits_ll: 0.02086 |  0:00:18s\n",
      "epoch 20 | loss: 0.01966 | val_logits_ll: 0.01938 |  0:00:35s\n",
      "epoch 30 | loss: 0.0182  | val_logits_ll: 0.01944 |  0:00:52s\n",
      "epoch 40 | loss: 0.01779 | val_logits_ll: 0.01847 |  0:01:08s\n",
      "epoch 50 | loss: 0.01748 | val_logits_ll: 0.01781 |  0:01:25s\n",
      "epoch 60 | loss: 0.01732 | val_logits_ll: 0.01754 |  0:01:41s\n",
      "epoch 70 | loss: 0.01704 | val_logits_ll: 0.01747 |  0:01:57s\n",
      "epoch 80 | loss: 0.01686 | val_logits_ll: 0.01777 |  0:02:14s\n",
      "epoch 90 | loss: 0.01662 | val_logits_ll: 0.01731 |  0:02:31s\n",
      "epoch 100| loss: 0.01647 | val_logits_ll: 0.01732 |  0:02:47s\n",
      "epoch 110| loss: 0.01682 | val_logits_ll: 0.01737 |  0:03:04s\n",
      "epoch 120| loss: 0.01627 | val_logits_ll: 0.01731 |  0:03:21s\n",
      "epoch 130| loss: 0.01591 | val_logits_ll: 0.01721 |  0:03:38s\n",
      "epoch 140| loss: 0.0159  | val_logits_ll: 0.01714 |  0:03:54s\n",
      "\n",
      "Early stopping occured at epoch 149 with best_epoch = 129 and best_val_logits_ll = 0.01703\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.52725 | val_logits_ll: 0.22959 |  0:00:01s\n",
      "epoch 10 | loss: 0.02125 | val_logits_ll: 0.02114 |  0:00:19s\n",
      "epoch 20 | loss: 0.01969 | val_logits_ll: 0.01963 |  0:00:36s\n",
      "epoch 30 | loss: 0.01836 | val_logits_ll: 0.01877 |  0:00:52s\n",
      "epoch 40 | loss: 0.01789 | val_logits_ll: 0.01821 |  0:01:10s\n",
      "epoch 50 | loss: 0.01748 | val_logits_ll: 0.01806 |  0:01:28s\n",
      "epoch 60 | loss: 0.01726 | val_logits_ll: 0.01788 |  0:01:44s\n",
      "epoch 70 | loss: 0.01701 | val_logits_ll: 0.01748 |  0:02:02s\n",
      "epoch 80 | loss: 0.01672 | val_logits_ll: 0.01731 |  0:02:19s\n",
      "epoch 90 | loss: 0.01651 | val_logits_ll: 0.01729 |  0:02:36s\n",
      "epoch 100| loss: 0.01623 | val_logits_ll: 0.01718 |  0:02:53s\n",
      "epoch 110| loss: 0.01617 | val_logits_ll: 0.01712 |  0:03:12s\n",
      "epoch 120| loss: 0.01598 | val_logits_ll: 0.01705 |  0:03:28s\n",
      "epoch 130| loss: 0.01571 | val_logits_ll: 0.01709 |  0:03:45s\n",
      "epoch 140| loss: 0.01556 | val_logits_ll: 0.01697 |  0:04:02s\n",
      "epoch 150| loss: 0.01534 | val_logits_ll: 0.01712 |  0:04:21s\n",
      "\n",
      "Early stopping occured at epoch 153 with best_epoch = 133 and best_val_logits_ll = 0.01697\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.52707 | val_logits_ll: 0.21809 |  0:00:01s\n",
      "epoch 10 | loss: 0.02105 | val_logits_ll: 0.02072 |  0:00:18s\n",
      "epoch 20 | loss: 0.0195  | val_logits_ll: 0.02172 |  0:00:35s\n",
      "epoch 30 | loss: 0.01834 | val_logits_ll: 0.01826 |  0:00:53s\n",
      "epoch 40 | loss: 0.01782 | val_logits_ll: 0.01789 |  0:01:10s\n",
      "epoch 50 | loss: 0.01745 | val_logits_ll: 0.01756 |  0:01:27s\n",
      "epoch 60 | loss: 0.01714 | val_logits_ll: 0.01736 |  0:01:45s\n",
      "epoch 70 | loss: 0.01704 | val_logits_ll: 0.0173  |  0:02:02s\n",
      "epoch 80 | loss: 0.01671 | val_logits_ll: 0.01711 |  0:02:19s\n",
      "epoch 90 | loss: 0.01672 | val_logits_ll: 0.0171  |  0:02:36s\n",
      "epoch 100| loss: 0.01665 | val_logits_ll: 0.01707 |  0:02:54s\n",
      "epoch 110| loss: 0.01645 | val_logits_ll: 0.01719 |  0:03:12s\n",
      "epoch 120| loss: 0.0161  | val_logits_ll: 0.01711 |  0:03:30s\n",
      "epoch 130| loss: 0.01596 | val_logits_ll: 0.01694 |  0:03:49s\n",
      "epoch 140| loss: 0.01577 | val_logits_ll: 0.01685 |  0:04:07s\n",
      "epoch 150| loss: 0.01567 | val_logits_ll: 0.01702 |  0:04:24s\n",
      "\n",
      "Early stopping occured at epoch 154 with best_epoch = 134 and best_val_logits_ll = 0.01674\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  5\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.52388 | val_logits_ll: 0.2208  |  0:00:01s\n",
      "epoch 10 | loss: 0.02099 | val_logits_ll: 0.02065 |  0:00:19s\n",
      "epoch 20 | loss: 0.01962 | val_logits_ll: 0.01943 |  0:00:37s\n",
      "epoch 30 | loss: 0.01815 | val_logits_ll: 0.02056 |  0:00:54s\n",
      "epoch 40 | loss: 0.01777 | val_logits_ll: 0.01799 |  0:01:12s\n",
      "epoch 50 | loss: 0.01739 | val_logits_ll: 0.01892 |  0:01:29s\n",
      "epoch 60 | loss: 0.01729 | val_logits_ll: 0.01907 |  0:01:45s\n",
      "epoch 70 | loss: 0.01701 | val_logits_ll: 0.01734 |  0:02:02s\n",
      "epoch 80 | loss: 0.01698 | val_logits_ll: 0.01734 |  0:02:21s\n",
      "epoch 90 | loss: 0.01677 | val_logits_ll: 0.01724 |  0:02:37s\n",
      "epoch 100| loss: 0.01659 | val_logits_ll: 0.01712 |  0:02:55s\n",
      "epoch 110| loss: 0.01643 | val_logits_ll: 0.0171  |  0:03:13s\n",
      "epoch 120| loss: 0.0162  | val_logits_ll: 0.01705 |  0:03:30s\n",
      "epoch 130| loss: 0.01631 | val_logits_ll: 0.01708 |  0:03:47s\n",
      "epoch 140| loss: 0.016   | val_logits_ll: 0.01701 |  0:04:05s\n",
      "epoch 150| loss: 0.01576 | val_logits_ll: 0.01698 |  0:04:22s\n",
      "epoch 160| loss: 0.01551 | val_logits_ll: 0.01709 |  0:04:39s\n",
      "\n",
      "Early stopping occured at epoch 167 with best_epoch = 147 and best_val_logits_ll = 0.01688\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.61163 | val_logits_ll: 0.37169 |  0:00:02s\n",
      "epoch 10 | loss: 0.02073 | val_logits_ll: 0.02047 |  0:00:20s\n",
      "epoch 20 | loss: 0.01924 | val_logits_ll: 0.01905 |  0:00:37s\n",
      "epoch 30 | loss: 0.01806 | val_logits_ll: 0.01803 |  0:00:55s\n",
      "epoch 40 | loss: 0.01767 | val_logits_ll: 0.01776 |  0:01:13s\n",
      "epoch 50 | loss: 0.01748 | val_logits_ll: 0.01761 |  0:01:31s\n",
      "epoch 60 | loss: 0.01737 | val_logits_ll: 0.01749 |  0:01:48s\n",
      "epoch 70 | loss: 0.01707 | val_logits_ll: 0.0173  |  0:02:06s\n",
      "epoch 80 | loss: 0.01707 | val_logits_ll: 0.01712 |  0:02:24s\n",
      "epoch 90 | loss: 0.01679 | val_logits_ll: 0.01712 |  0:02:41s\n",
      "epoch 100| loss: 0.01652 | val_logits_ll: 0.01689 |  0:02:59s\n",
      "epoch 110| loss: 0.0163  | val_logits_ll: 0.01683 |  0:03:17s\n",
      "epoch 120| loss: 0.01615 | val_logits_ll: 0.01686 |  0:03:35s\n",
      "epoch 130| loss: 0.01583 | val_logits_ll: 0.01676 |  0:03:52s\n",
      "epoch 140| loss: 0.01571 | val_logits_ll: 0.01694 |  0:04:10s\n",
      "epoch 150| loss: 0.01547 | val_logits_ll: 0.01674 |  0:04:28s\n",
      "epoch 160| loss: 0.01529 | val_logits_ll: 0.01672 |  0:04:45s\n",
      "\n",
      "Early stopping occured at epoch 162 with best_epoch = 142 and best_val_logits_ll = 0.01667\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.60695 | val_logits_ll: 0.3628  |  0:00:01s\n",
      "epoch 10 | loss: 0.02088 | val_logits_ll: 0.02046 |  0:00:19s\n",
      "epoch 20 | loss: 0.01947 | val_logits_ll: 0.01998 |  0:00:37s\n",
      "epoch 30 | loss: 0.01811 | val_logits_ll: 0.01833 |  0:00:55s\n",
      "epoch 40 | loss: 0.01772 | val_logits_ll: 0.01787 |  0:01:13s\n",
      "epoch 50 | loss: 0.01729 | val_logits_ll: 0.01768 |  0:01:32s\n",
      "epoch 60 | loss: 0.01729 | val_logits_ll: 0.0177  |  0:01:50s\n",
      "epoch 70 | loss: 0.01693 | val_logits_ll: 0.01742 |  0:02:07s\n",
      "epoch 80 | loss: 0.01682 | val_logits_ll: 0.01731 |  0:02:25s\n",
      "epoch 90 | loss: 0.0167  | val_logits_ll: 0.01731 |  0:02:43s\n",
      "epoch 100| loss: 0.01663 | val_logits_ll: 0.01714 |  0:03:00s\n",
      "epoch 110| loss: 0.0165  | val_logits_ll: 0.01709 |  0:03:18s\n",
      "epoch 120| loss: 0.0162  | val_logits_ll: 0.01708 |  0:03:36s\n",
      "epoch 130| loss: 0.01602 | val_logits_ll: 0.0171  |  0:03:53s\n",
      "epoch 140| loss: 0.01579 | val_logits_ll: 0.0171  |  0:04:10s\n",
      "\n",
      "Early stopping occured at epoch 141 with best_epoch = 121 and best_val_logits_ll = 0.01702\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.61037 | val_logits_ll: 0.37064 |  0:00:01s\n",
      "epoch 10 | loss: 0.02101 | val_logits_ll: 0.02083 |  0:00:19s\n",
      "epoch 20 | loss: 0.01948 | val_logits_ll: 0.01937 |  0:00:36s\n",
      "epoch 30 | loss: 0.01805 | val_logits_ll: 0.02054 |  0:00:53s\n",
      "epoch 40 | loss: 0.01755 | val_logits_ll: 0.01829 |  0:01:12s\n",
      "epoch 50 | loss: 0.01736 | val_logits_ll: 0.01921 |  0:01:29s\n",
      "epoch 60 | loss: 0.01716 | val_logits_ll: 0.01774 |  0:01:46s\n",
      "epoch 70 | loss: 0.01691 | val_logits_ll: 0.01742 |  0:02:03s\n",
      "epoch 80 | loss: 0.0169  | val_logits_ll: 0.01741 |  0:02:21s\n",
      "epoch 90 | loss: 0.01668 | val_logits_ll: 0.01745 |  0:02:39s\n",
      "epoch 100| loss: 0.0162  | val_logits_ll: 0.01736 |  0:02:56s\n",
      "epoch 110| loss: 0.01629 | val_logits_ll: 0.01709 |  0:03:14s\n",
      "epoch 120| loss: 0.01607 | val_logits_ll: 0.01715 |  0:03:31s\n",
      "epoch 130| loss: 0.01588 | val_logits_ll: 0.01709 |  0:03:49s\n",
      "epoch 140| loss: 0.0156  | val_logits_ll: 0.01761 |  0:04:06s\n",
      "\n",
      "Early stopping occured at epoch 148 with best_epoch = 128 and best_val_logits_ll = 0.01701\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.60906 | val_logits_ll: 0.35933 |  0:00:01s\n",
      "epoch 10 | loss: 0.02089 | val_logits_ll: 0.02066 |  0:00:18s\n",
      "epoch 20 | loss: 0.01931 | val_logits_ll: 0.01908 |  0:00:36s\n",
      "epoch 30 | loss: 0.01825 | val_logits_ll: 0.01914 |  0:00:55s\n",
      "epoch 40 | loss: 0.01776 | val_logits_ll: 0.01782 |  0:01:12s\n",
      "epoch 50 | loss: 0.01743 | val_logits_ll: 0.01786 |  0:01:29s\n",
      "epoch 60 | loss: 0.01738 | val_logits_ll: 0.01741 |  0:01:48s\n",
      "epoch 70 | loss: 0.01698 | val_logits_ll: 0.01729 |  0:02:06s\n",
      "epoch 80 | loss: 0.0168  | val_logits_ll: 0.01717 |  0:02:24s\n",
      "epoch 90 | loss: 0.01668 | val_logits_ll: 0.01705 |  0:02:42s\n",
      "epoch 100| loss: 0.01647 | val_logits_ll: 0.0169  |  0:03:00s\n",
      "epoch 110| loss: 0.01643 | val_logits_ll: 0.01697 |  0:03:18s\n",
      "epoch 120| loss: 0.0164  | val_logits_ll: 0.01711 |  0:03:35s\n",
      "epoch 130| loss: 0.01606 | val_logits_ll: 0.01684 |  0:03:54s\n",
      "epoch 140| loss: 0.01577 | val_logits_ll: 0.01694 |  0:04:11s\n",
      "epoch 150| loss: 0.01551 | val_logits_ll: 0.01678 |  0:04:28s\n",
      "epoch 160| loss: 0.01543 | val_logits_ll: 0.01694 |  0:04:46s\n",
      "\n",
      "Early stopping occured at epoch 162 with best_epoch = 142 and best_val_logits_ll = 0.01674\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  5\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.60553 | val_logits_ll: 0.35504 |  0:00:01s\n",
      "epoch 10 | loss: 0.02086 | val_logits_ll: 0.02063 |  0:00:19s\n",
      "epoch 20 | loss: 0.01949 | val_logits_ll: 0.01965 |  0:00:36s\n",
      "epoch 30 | loss: 0.01812 | val_logits_ll: 0.01956 |  0:00:54s\n",
      "epoch 40 | loss: 0.01764 | val_logits_ll: 0.01896 |  0:01:12s\n",
      "epoch 50 | loss: 0.01721 | val_logits_ll: 0.01754 |  0:01:30s\n",
      "epoch 60 | loss: 0.01716 | val_logits_ll: 0.01763 |  0:01:47s\n",
      "epoch 70 | loss: 0.01681 | val_logits_ll: 0.01721 |  0:02:06s\n",
      "epoch 80 | loss: 0.0165  | val_logits_ll: 0.01714 |  0:02:24s\n",
      "epoch 90 | loss: 0.01639 | val_logits_ll: 0.01706 |  0:02:41s\n",
      "epoch 100| loss: 0.01645 | val_logits_ll: 0.01708 |  0:03:00s\n",
      "epoch 110| loss: 0.01615 | val_logits_ll: 0.01699 |  0:03:18s\n",
      "epoch 120| loss: 0.01587 | val_logits_ll: 0.01698 |  0:03:35s\n",
      "epoch 130| loss: 0.01581 | val_logits_ll: 0.01707 |  0:03:54s\n",
      "\n",
      "Early stopping occured at epoch 131 with best_epoch = 111 and best_val_logits_ll = 0.01688\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "MAX_EPOCH=200\n",
    "\n",
    "def seed_everything(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def modelling_tabnet(tr, target, te, sample_seed):\n",
    "    seed_everything(sample_seed) \n",
    "    tabnet_params = dict(n_d=12, n_a=12, n_steps=1, gamma=1.3, seed = sample_seed,\n",
    "                     lambda_sparse=0, optimizer_fn=torch.optim.Adam,\n",
    "                     optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
    "                     mask_type='entmax',\n",
    "                     scheduler_params=dict(mode=\"min\",\n",
    "                                           patience=5,\n",
    "                                           min_lr=1e-5,\n",
    "                                           factor=0.9,),\n",
    "                     scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                     verbose=10,\n",
    "                     )\n",
    "    test_cv_preds = []\n",
    "\n",
    "    NB_SPLITS = 5\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=NB_SPLITS, random_state=0, shuffle=True)\n",
    "    oof_preds = np.zeros([len(tr),target.shape[1]])\n",
    "    scores = []\n",
    "    for fold_nb, (train_idx, val_idx) in enumerate(mskf.split(train, target)):\n",
    "        print(\"FOLDS : \", fold_nb+1)\n",
    "\n",
    "        ## model\n",
    "        X_train, y_train = tr[train_idx, :], target[train_idx, :]\n",
    "        X_val, y_val = tr[val_idx, :], target[val_idx, :]\n",
    "        model = TabNetRegressor(**tabnet_params)\n",
    "    \n",
    "        model.fit(X_train=X_train,\n",
    "              y_train=y_train,\n",
    "              eval_set=[(X_val, y_val)],\n",
    "              eval_name = [\"val\"],\n",
    "              eval_metric = [\"logits_ll\"],\n",
    "              max_epochs=MAX_EPOCH,\n",
    "              patience=20, batch_size=1024, virtual_batch_size=32,\n",
    "              num_workers=1, drop_last=False,\n",
    "              # use binary cross entropy as this is not a regression problem\n",
    "              loss_fn=torch.nn.functional.binary_cross_entropy_with_logits)\n",
    "    \n",
    "        preds_val = model.predict(X_val)\n",
    "        # Apply sigmoid to the predictions\n",
    "        preds =  1 / (1 + np.exp(-preds_val))\n",
    "        score = np.min(model.history[\"val_logits_ll\"])\n",
    "    #     name = cfg.save_name + f\"_fold{fold_nb}\"\n",
    "    #     model.save_model(name)\n",
    "        oof_preds[val_idx,:] = preds\n",
    "        scores.append(score)\n",
    "\n",
    "        # preds on test\n",
    "        preds_test = model.predict(te)\n",
    "        test_cv_preds.append(1 / (1 + np.exp(-preds_test)))\n",
    "\n",
    "    test_preds_all = np.stack(test_cv_preds)\n",
    "    return oof_preds, test_preds_all\n",
    "\n",
    "target_oof = np.zeros([len(fn_train),fn_targets.shape[1]])\n",
    "target_pred = np.zeros([len(fn_test),fn_targets.shape[1]])\n",
    "\n",
    "seeds = [0,1,2]\n",
    "for seed_ in seeds:\n",
    "    oof_preds, test_preds_all = modelling_tabnet(fn_train, fn_targets, fn_test, seed_)\n",
    "    target_oof += oof_preds / len(seeds)\n",
    "    target_pred += test_preds_all.mean(axis=0) / len(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-21T12:05:43.269432Z",
     "iopub.status.busy": "2020-10-21T12:05:43.268499Z",
     "iopub.status.idle": "2020-10-21T12:05:50.051770Z",
     "shell.execute_reply": "2020-10-21T12:05:50.052417Z"
    },
    "papermill": {
     "duration": 6.921091,
     "end_time": "2020-10-21T12:05:50.052576",
     "exception": false,
     "start_time": "2020-10-21T12:05:43.131485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF log loss:  0.015210066757773144\n"
     ]
    }
   ],
   "source": [
    "t = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "train_checkscore = t.copy()\n",
    "train_checkscore.loc[train_checkscore.index.isin(cons_train_index),target_feats] = target_oof\n",
    "train_checkscore.loc[train_checkscore.index.isin(noncons_train_index),target_feats] = 0\n",
    "\n",
    "t.drop(\"sig_id\", axis=1, inplace=True)\n",
    "print('OOF log loss: ', log_loss(np.ravel(t), np.ravel(np.array(train_checkscore.iloc[:,1:]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-21T12:05:50.313783Z",
     "iopub.status.busy": "2020-10-21T12:05:50.312637Z",
     "iopub.status.idle": "2020-10-21T12:05:53.068350Z",
     "shell.execute_reply": "2020-10-21T12:05:53.067650Z"
    },
    "papermill": {
     "duration": 2.887074,
     "end_time": "2020-10-21T12:05:53.068488",
     "exception": false,
     "start_time": "2020-10-21T12:05:50.181414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub[target_feats] = target_pred\n",
    "sub.loc[noncons_test_index,target_feats] = 0\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.121645,
     "end_time": "2020-10-21T12:05:53.318160",
     "exception": false,
     "start_time": "2020-10-21T12:05:53.196515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 4018.331628,
   "end_time": "2020-10-21T12:05:54.456747",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-21T10:58:56.125119",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
