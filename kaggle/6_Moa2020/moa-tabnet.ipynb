{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017154,
     "end_time": "2020-11-08T08:28:27.927698",
     "exception": false,
     "start_time": "2020-11-08T08:28:27.910544",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- fold 5, 1 ensemble\n",
    "- cancel any fe\n",
    "- extract train oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:28:27.966745Z",
     "iopub.status.busy": "2020-11-08T08:28:27.966039Z",
     "iopub.status.idle": "2020-11-08T08:28:36.115958Z",
     "shell.execute_reply": "2020-11-08T08:28:36.115360Z"
    },
    "papermill": {
     "duration": 8.171893,
     "end_time": "2020-11-08T08:28:36.116085",
     "exception": false,
     "start_time": "2020-11-08T08:28:27.944192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl\r\n",
      "Processing /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.18.5)\r\n",
      "Requirement already satisfied: scikit_learn>0.21 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (0.23.2)\r\n",
      "Requirement already satisfied: scipy>1.4 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.4.1)\r\n",
      "Requirement already satisfied: torch<2.0,>=1.2 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.6.0)\r\n",
      "Requirement already satisfied: tqdm<5.0,>=4.36 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (4.45.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (0.14.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (2.1.0)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch<2.0,>=1.2->pytorch-tabnet) (0.18.2)\r\n",
      "Installing collected packages: pytorch-tabnet\r\n",
      "Successfully installed pytorch-tabnet-2.0.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-index --find-links /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-08T08:28:36.165619Z",
     "iopub.status.busy": "2020-11-08T08:28:36.164803Z",
     "iopub.status.idle": "2020-11-08T08:28:44.816056Z",
     "shell.execute_reply": "2020-11-08T08:28:44.815490Z"
    },
    "papermill": {
     "duration": 8.679242,
     "end_time": "2020-11-08T08:28:44.816180",
     "exception": false,
     "start_time": "2020-11-08T08:28:36.136938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from umap import UMAP\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss,roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "sys.path.append('../input/multilabelstraifier/')\n",
    "from ml_stratifiers import MultilabelStratifiedKFold\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:28:44.861225Z",
     "iopub.status.busy": "2020-11-08T08:28:44.860581Z",
     "iopub.status.idle": "2020-11-08T08:28:50.737156Z",
     "shell.execute_reply": "2020-11-08T08:28:50.736158Z"
    },
    "papermill": {
     "duration": 5.902147,
     "end_time": "2020-11-08T08:28:50.737287",
     "exception": false,
     "start_time": "2020-11-08T08:28:44.835140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/lish-moa/'\n",
    "train = pd.read_csv(DATA_DIR + 'train_features.csv')\n",
    "targets = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "non_targets = pd.read_csv(DATA_DIR + 'train_targets_nonscored.csv')\n",
    "test = pd.read_csv(DATA_DIR + 'test_features.csv')\n",
    "sub = pd.read_csv(DATA_DIR + 'sample_submission.csv')\n",
    "drug = pd.read_csv(DATA_DIR + 'train_drug.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:28:50.785572Z",
     "iopub.status.busy": "2020-11-08T08:28:50.784895Z",
     "iopub.status.idle": "2020-11-08T08:28:50.877244Z",
     "shell.execute_reply": "2020-11-08T08:28:50.876693Z"
    },
    "papermill": {
     "duration": 0.121139,
     "end_time": "2020-11-08T08:28:50.877361",
     "exception": false,
     "start_time": "2020-11-08T08:28:50.756222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_feats = [ i for i in targets.columns if i != \"sig_id\"]\n",
    "g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "c_feats = [i for i in train.columns if \"c-\" in i]\n",
    "\n",
    "noncons_train_index = train[train.cp_type==\"ctl_vehicle\"].index\n",
    "cons_train_index = train[~train.index.isin(noncons_train_index)].index\n",
    "noncons_test_index = test[test.cp_type==\"ctl_vehicle\"].index\n",
    "cons_test_index = test[test.cp_type!=\"ctl_vehicle\"].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018421,
     "end_time": "2020-11-08T08:28:50.915134",
     "exception": false,
     "start_time": "2020-11-08T08:28:50.896713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:28:50.964644Z",
     "iopub.status.busy": "2020-11-08T08:28:50.963690Z",
     "iopub.status.idle": "2020-11-08T08:28:51.181659Z",
     "shell.execute_reply": "2020-11-08T08:28:51.180986Z"
    },
    "papermill": {
     "duration": 0.248073,
     "end_time": "2020-11-08T08:28:51.181820",
     "exception": false,
     "start_time": "2020-11-08T08:28:50.933747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train[train.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "targets = targets[targets.index.isin(cons_train_index)].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:28:51.237036Z",
     "iopub.status.busy": "2020-11-08T08:28:51.227977Z",
     "iopub.status.idle": "2020-11-08T08:28:51.716863Z",
     "shell.execute_reply": "2020-11-08T08:28:51.715952Z"
    },
    "papermill": {
     "duration": 0.515685,
     "end_time": "2020-11-08T08:28:51.716976",
     "exception": false,
     "start_time": "2020-11-08T08:28:51.201291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 4, 1, ..., 0, 1, 4]], dtype=int8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/c/lish-moa/discussion/195195\n",
    "NB_SPLITS = 5\n",
    "seed = 14\n",
    "\n",
    "folds = []\n",
    "    \n",
    "# LOAD FILES\n",
    "train_score = targets.merge(drug, on='sig_id', how='left') \n",
    "\n",
    "# LOCATE DRUGS\n",
    "vc = train_score.drug_id.value_counts()\n",
    "vc1 = vc.loc[vc <= 19].index.sort_values()\n",
    "vc2 = vc.loc[vc > 19].index.sort_values()\n",
    "    \n",
    "# STRATIFY DRUGS 18X OR LESS\n",
    "dct1 = {}; dct2 = {}\n",
    "skf = MultilabelStratifiedKFold(n_splits = NB_SPLITS, shuffle = True, random_state = seed)\n",
    "tmp = train_score.groupby('drug_id')[target_feats].mean().loc[vc1]\n",
    "for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_feats])):\n",
    "    dd = {k:fold for k in tmp.index[idxV].values}\n",
    "    dct1.update(dd)\n",
    "\n",
    "# STRATIFY DRUGS MORE THAN 18X\n",
    "skf = MultilabelStratifiedKFold(n_splits = NB_SPLITS, shuffle = True, random_state = seed)\n",
    "tmp = train_score.loc[train_score.drug_id.isin(vc2)].reset_index(drop = True)\n",
    "for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_feats])):\n",
    "    dd = {k:fold for k in tmp.sig_id[idxV].values}\n",
    "    dct2.update(dd)\n",
    "\n",
    "# ASSIGN FOLDS\n",
    "train_score['fold'] = train_score.drug_id.map(dct1)\n",
    "train_score.loc[train_score.fold.isna(),'fold'] = train_score.loc[train_score.fold.isna(),'sig_id'].map(dct2)\n",
    "train_score.fold = train_score.fold.astype('int8')\n",
    "folds.append(train_score.fold.values)\n",
    "    \n",
    "np.array(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01916,
     "end_time": "2020-11-08T08:28:51.756237",
     "exception": false,
     "start_time": "2020-11-08T08:28:51.737077",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:28:51.800210Z",
     "iopub.status.busy": "2020-11-08T08:28:51.798446Z",
     "iopub.status.idle": "2020-11-08T08:28:51.800897Z",
     "shell.execute_reply": "2020-11-08T08:28:51.801353Z"
    },
    "papermill": {
     "duration": 0.025969,
     "end_time": "2020-11-08T08:28:51.801463",
     "exception": false,
     "start_time": "2020-11-08T08:28:51.775494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#X = train[g_feats+c_feats].copy().values\n",
    "#select = VarianceThreshold(threshold=0.7)\n",
    "#X_new = select.fit_transform(X)\n",
    "#drop_feats = list(np.array(train[g_feats+c_feats].columns)[select.get_support()==False])\n",
    "#len(drop_feats)\n",
    "\n",
    "#train.drop(drop_feats, axis=1, inplace=True)\n",
    "#test.drop(drop_feats, axis=1, inplace=True)\n",
    "\n",
    "#g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "#c_feats = [i for i in train.columns if \"c-\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:28:51.844266Z",
     "iopub.status.busy": "2020-11-08T08:28:51.843562Z",
     "iopub.status.idle": "2020-11-08T08:28:51.847371Z",
     "shell.execute_reply": "2020-11-08T08:28:51.846882Z"
    },
    "papermill": {
     "duration": 0.026669,
     "end_time": "2020-11-08T08:28:51.847460",
     "exception": false,
     "start_time": "2020-11-08T08:28:51.820791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for i in c_feats + g_feats:\n",
    "    #ss = preprocessing.QuantileTransformer(n_quantiles=100, random_state=0, output_distribution=\"normal\")\n",
    "#    ss = preprocessing.RobustScaler()\n",
    "#    ss.fit(train[i].values.reshape(-1,1))\n",
    "#    train[i] = ss.transform(train[i].values.reshape(-1,1))\n",
    "#    test[i] = ss.transform(test[i].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:28:51.891853Z",
     "iopub.status.busy": "2020-11-08T08:28:51.890350Z",
     "iopub.status.idle": "2020-11-08T08:28:51.893010Z",
     "shell.execute_reply": "2020-11-08T08:28:51.893471Z"
    },
    "papermill": {
     "duration": 0.026584,
     "end_time": "2020-11-08T08:28:51.893576",
     "exception": false,
     "start_time": "2020-11-08T08:28:51.866992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#c_num = 1\n",
    "#pca_c_cols = [\"pca-c\"+str(i+1) for i in range(c_num)]\n",
    "#pca = PCA(n_components=c_num,random_state=42)\n",
    "#c_train = pca.fit_transform(train[c_feats])\n",
    "#c_test = pca.transform(test[c_feats])\n",
    "#c_train = pd.DataFrame(c_train, columns=pca_c_cols)\n",
    "#c_test = pd.DataFrame(c_test, columns=pca_c_cols)\n",
    "\n",
    "#g_num = 10\n",
    "#pca_g_cols = [\"pca-g\"+str(i+1) for i in range(g_num)]\n",
    "#pca = PCA(n_components=g_num, random_state=42)\n",
    "#g_train = pca.fit_transform(train[g_feats])\n",
    "#g_test = pca.transform(test[g_feats])\n",
    "#g_train = pd.DataFrame(g_train, columns=pca_g_cols)\n",
    "#g_test = pd.DataFrame(g_test, columns=pca_g_cols)\n",
    "\n",
    "#train = pd.concat([train, c_train],axis=1)\n",
    "#test = pd.concat([test, c_test],axis=1)\n",
    "#train = pd.concat([train, g_train],axis=1)\n",
    "#test = pd.concat([test, g_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:28:51.938416Z",
     "iopub.status.busy": "2020-11-08T08:28:51.936692Z",
     "iopub.status.idle": "2020-11-08T08:28:51.939179Z",
     "shell.execute_reply": "2020-11-08T08:28:51.939641Z"
    },
    "papermill": {
     "duration": 0.026394,
     "end_time": "2020-11-08T08:28:51.939743",
     "exception": false,
     "start_time": "2020-11-08T08:28:51.913349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#uc_num = 1\n",
    "#um = UMAP(n_neighbors=30, n_components=uc_num, random_state=42)\n",
    "#um_c_cols = [\"um-c\"+str(i+1) for i in range(uc_num)]#\n",
    "#uc_train = um.fit_transform(train[c_feats])\n",
    "#uc_test = um.transform(test[c_feats])\n",
    "#uc_train = pd.DataFrame(uc_train, columns=um_c_cols)\n",
    "#uc_test = pd.DataFrame(uc_test, columns=um_c_cols)\n",
    "\n",
    "#ug_num = 10\n",
    "#um = UMAP(n_neighbors=30, n_components=ug_num, random_state=42)\n",
    "#um_g_cols = [\"um-g\"+str(i+1) for i in range(ug_num)]\n",
    "#ug_train = um.fit_transform(train[g_feats])\n",
    "#ug_test = um.transform(test[g_feats])\n",
    "#ug_train = pd.DataFrame(ug_train, columns=um_g_cols)\n",
    "#ug_test = pd.DataFrame(ug_test, columns=um_g_cols)\n",
    "\n",
    "#train = pd.concat([train, uc_train],axis=1)\n",
    "#test = pd.concat([test, uc_test],axis=1)\n",
    "#train = pd.concat([train, ug_train],axis=1)\n",
    "#test = pd.concat([test, ug_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:28:51.983194Z",
     "iopub.status.busy": "2020-11-08T08:28:51.982576Z",
     "iopub.status.idle": "2020-11-08T08:28:51.986446Z",
     "shell.execute_reply": "2020-11-08T08:28:51.985957Z"
    },
    "papermill": {
     "duration": 0.027038,
     "end_time": "2020-11-08T08:28:51.986551",
     "exception": false,
     "start_time": "2020-11-08T08:28:51.959513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#n_clusters_g = 15\n",
    "#n_clusters_c = 5\n",
    "#def create_cluster(train, test, kind, n_clusters):\n",
    "#    if kind == \"g\":\n",
    "#        train_ = train[pca_g_cols].copy()\n",
    "#        test_ = test[pca_g_cols].copy()\n",
    "#    else:\n",
    "#        train_ = train[pca_c_cols].copy()\n",
    "#        test_ = test[pca_c_cols].copy()    \n",
    "#    kmeans = KMeans(n_clusters = n_clusters, random_state = 0).fit(train_)\n",
    "#    train[f'clusters_{kind}'] = kmeans.labels_\n",
    "#    test[f'clusters_{kind}'] = kmeans.predict(test_)\n",
    "#    train = pd.get_dummies(train, columns = [f'clusters_{kind}'])\n",
    "#    test = pd.get_dummies(test, columns = [f'clusters_{kind}'])\n",
    "#    return train, test\n",
    "    \n",
    "#train, test = create_cluster(train, test, kind = 'g', n_clusters = n_clusters_g)\n",
    "#train, test = create_cluster(train, test, kind = 'c', n_clusters = n_clusters_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:28:52.034256Z",
     "iopub.status.busy": "2020-11-08T08:28:52.032995Z",
     "iopub.status.idle": "2020-11-08T08:28:52.166413Z",
     "shell.execute_reply": "2020-11-08T08:28:52.165901Z"
    },
    "papermill": {
     "duration": 0.159733,
     "end_time": "2020-11-08T08:28:52.166533",
     "exception": false,
     "start_time": "2020-11-08T08:28:52.006800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 874) (3982, 874)\n"
     ]
    }
   ],
   "source": [
    "def fe(df):\n",
    "    tmp = df.copy()\n",
    "    tmp.loc[:, 'cp_dose'] = tmp.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})      \n",
    "    tmp.drop([\"sig_id\", \"cp_type\"], axis=1, inplace=True)\n",
    "    return tmp\n",
    "\n",
    "train = fe(train)\n",
    "test = fe(test)\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:28:52.214481Z",
     "iopub.status.busy": "2020-11-08T08:28:52.213241Z",
     "iopub.status.idle": "2020-11-08T08:28:52.215751Z",
     "shell.execute_reply": "2020-11-08T08:28:52.216236Z"
    },
    "papermill": {
     "duration": 0.029137,
     "end_time": "2020-11-08T08:28:52.216345",
     "exception": false,
     "start_time": "2020-11-08T08:28:52.187208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[\"fold\"] = np.array(folds).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:28:52.263612Z",
     "iopub.status.busy": "2020-11-08T08:28:52.262326Z",
     "iopub.status.idle": "2020-11-08T08:28:52.416057Z",
     "shell.execute_reply": "2020-11-08T08:28:52.415522Z"
    },
    "papermill": {
     "duration": 0.179249,
     "end_time": "2020-11-08T08:28:52.416173",
     "exception": false,
     "start_time": "2020-11-08T08:28:52.236924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fn_train = train.copy().to_numpy()\n",
    "fn_test = test.copy().to_numpy()\n",
    "    \n",
    "fn_targets = targets.drop(\"sig_id\", axis=1).copy().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:28:52.462625Z",
     "iopub.status.busy": "2020-11-08T08:28:52.462045Z",
     "iopub.status.idle": "2020-11-08T08:28:52.467718Z",
     "shell.execute_reply": "2020-11-08T08:28:52.467252Z"
    },
    "papermill": {
     "duration": 0.030719,
     "end_time": "2020-11-08T08:28:52.467843",
     "exception": false,
     "start_time": "2020-11-08T08:28:52.437124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21948, 875), (3982, 874), (21948, 206))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_train.shape, fn_test.shape, fn_targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021239,
     "end_time": "2020-11-08T08:28:52.510534",
     "exception": false,
     "start_time": "2020-11-08T08:28:52.489295",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:28:52.560134Z",
     "iopub.status.busy": "2020-11-08T08:28:52.559432Z",
     "iopub.status.idle": "2020-11-08T08:28:52.562820Z",
     "shell.execute_reply": "2020-11-08T08:28:52.563254Z"
    },
    "papermill": {
     "duration": 0.031523,
     "end_time": "2020-11-08T08:28:52.563372",
     "exception": false,
     "start_time": "2020-11-08T08:28:52.531849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LogitsLogLoss(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"logits_ll\"\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "\n",
    "        logits = 1 / (1 + np.exp(-y_pred))\n",
    "        \n",
    "        aux = (1-y_true)*np.log(1-logits+1e-15) + y_true*np.log(logits+1e-15)\n",
    "        return np.mean(-aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:28:52.977737Z",
     "iopub.status.busy": "2020-11-08T08:28:52.624259Z",
     "iopub.status.idle": "2020-11-08T08:36:13.123541Z",
     "shell.execute_reply": "2020-11-08T08:36:13.123016Z"
    },
    "papermill": {
     "duration": 440.538676,
     "end_time": "2020-11-08T08:36:13.123661",
     "exception": false,
     "start_time": "2020-11-08T08:28:52.584985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLDS :  1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.56822 | val_logits_ll: 0.32031 |  0:00:01s\n",
      "epoch 10 | loss: 0.02073 | val_logits_ll: 0.02057 |  0:00:11s\n",
      "epoch 20 | loss: 0.01911 | val_logits_ll: 0.01923 |  0:00:20s\n",
      "epoch 30 | loss: 0.01795 | val_logits_ll: 0.01885 |  0:00:29s\n",
      "epoch 40 | loss: 0.01726 | val_logits_ll: 0.01974 |  0:00:38s\n",
      "epoch 50 | loss: 0.01696 | val_logits_ll: 0.01791 |  0:00:47s\n",
      "epoch 60 | loss: 0.01648 | val_logits_ll: 0.01779 |  0:00:56s\n",
      "epoch 70 | loss: 0.01624 | val_logits_ll: 0.01918 |  0:01:05s\n",
      "epoch 80 | loss: 0.01608 | val_logits_ll: 0.01816 |  0:01:16s\n",
      "epoch 90 | loss: 0.01591 | val_logits_ll: 0.01762 |  0:01:25s\n",
      "\n",
      "Early stopping occured at epoch 92 with best_epoch = 72 and best_val_logits_ll = 0.01751\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.56335 | val_logits_ll: 0.30359 |  0:00:00s\n",
      "epoch 10 | loss: 0.02052 | val_logits_ll: 0.02025 |  0:00:09s\n",
      "epoch 20 | loss: 0.01904 | val_logits_ll: 0.01894 |  0:00:19s\n",
      "epoch 30 | loss: 0.01772 | val_logits_ll: 0.01812 |  0:00:28s\n",
      "epoch 40 | loss: 0.01701 | val_logits_ll: 0.01985 |  0:00:37s\n",
      "epoch 50 | loss: 0.01656 | val_logits_ll: 0.02032 |  0:00:47s\n",
      "epoch 60 | loss: 0.01603 | val_logits_ll: 0.01783 |  0:00:56s\n",
      "epoch 70 | loss: 0.01587 | val_logits_ll: 0.01754 |  0:01:05s\n",
      "epoch 80 | loss: 0.01563 | val_logits_ll: 0.01765 |  0:01:14s\n",
      "\n",
      "Early stopping occured at epoch 89 with best_epoch = 69 and best_val_logits_ll = 0.01752\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.5625  | val_logits_ll: 0.2968  |  0:00:01s\n",
      "epoch 10 | loss: 0.02049 | val_logits_ll: 0.02139 |  0:00:09s\n",
      "epoch 20 | loss: 0.01836 | val_logits_ll: 0.01972 |  0:00:19s\n",
      "epoch 30 | loss: 0.01722 | val_logits_ll: 0.01938 |  0:00:29s\n",
      "epoch 40 | loss: 0.01676 | val_logits_ll: 0.02025 |  0:00:38s\n",
      "epoch 50 | loss: 0.01643 | val_logits_ll: 0.01891 |  0:00:47s\n",
      "epoch 60 | loss: 0.01633 | val_logits_ll: 0.02013 |  0:00:56s\n",
      "epoch 70 | loss: 0.01582 | val_logits_ll: 0.01848 |  0:01:05s\n",
      "epoch 80 | loss: 0.01553 | val_logits_ll: 0.02074 |  0:01:14s\n",
      "epoch 90 | loss: 0.01515 | val_logits_ll: 0.01862 |  0:01:24s\n",
      "\n",
      "Early stopping occured at epoch 90 with best_epoch = 70 and best_val_logits_ll = 0.01848\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.57363 | val_logits_ll: 0.31949 |  0:00:00s\n",
      "epoch 10 | loss: 0.02078 | val_logits_ll: 0.02061 |  0:00:10s\n",
      "epoch 20 | loss: 0.0188  | val_logits_ll: 0.01908 |  0:00:19s\n",
      "epoch 30 | loss: 0.01781 | val_logits_ll: 0.01827 |  0:00:28s\n",
      "epoch 40 | loss: 0.01703 | val_logits_ll: 0.01794 |  0:00:37s\n",
      "epoch 50 | loss: 0.01658 | val_logits_ll: 0.01932 |  0:00:46s\n",
      "epoch 60 | loss: 0.0163  | val_logits_ll: 0.01771 |  0:00:56s\n",
      "epoch 70 | loss: 0.01585 | val_logits_ll: 0.01757 |  0:01:05s\n",
      "epoch 80 | loss: 0.01553 | val_logits_ll: 0.0177  |  0:01:15s\n",
      "\n",
      "Early stopping occured at epoch 85 with best_epoch = 65 and best_val_logits_ll = 0.01756\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  5\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.57439 | val_logits_ll: 0.28826 |  0:00:00s\n",
      "epoch 10 | loss: 0.02083 | val_logits_ll: 0.0208  |  0:00:09s\n",
      "epoch 20 | loss: 0.01893 | val_logits_ll: 0.01969 |  0:00:18s\n",
      "epoch 30 | loss: 0.01752 | val_logits_ll: 0.01812 |  0:00:28s\n",
      "epoch 40 | loss: 0.01707 | val_logits_ll: 0.0178  |  0:00:38s\n",
      "epoch 50 | loss: 0.01662 | val_logits_ll: 0.01901 |  0:00:47s\n",
      "epoch 60 | loss: 0.0164  | val_logits_ll: 0.01769 |  0:00:56s\n",
      "epoch 70 | loss: 0.01633 | val_logits_ll: 0.01776 |  0:01:05s\n",
      "epoch 80 | loss: 0.016   | val_logits_ll: 0.01768 |  0:01:14s\n",
      "epoch 90 | loss: 0.01573 | val_logits_ll: 0.01754 |  0:01:23s\n",
      "\n",
      "Early stopping occured at epoch 99 with best_epoch = 79 and best_val_logits_ll = 0.01747\n",
      "Best weights from best epoch are automatically used!\n",
      "OOF log loss: 0.017705284061671496\n",
      "Overall AUC : 0.6175376498318935\n"
     ]
    }
   ],
   "source": [
    "MAX_EPOCH=200\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def seed_everything(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def modelling_tabnet(tr, target, te, sample_seed):\n",
    "    seed_everything(sample_seed) \n",
    "    tabnet_params = dict(n_d=12, n_a=12, n_steps=1, gamma=1.3, seed = sample_seed,\n",
    "                     lambda_sparse=0, optimizer_fn=torch.optim.Adam,\n",
    "                     optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
    "                     mask_type='entmax',\n",
    "                     scheduler_params=dict(mode=\"min\",\n",
    "                                           patience=5,\n",
    "                                           min_lr=1e-5,\n",
    "                                           factor=0.9,),\n",
    "                     scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                     verbose=10,\n",
    "                     )\n",
    "    test_cv_preds = []\n",
    "\n",
    "    oof_preds = np.zeros([len(tr),target.shape[1]])\n",
    "    scores = []\n",
    "    for fold_nb in range(NB_SPLITS):\n",
    "        print(\"FOLDS : \", fold_nb+1)\n",
    "        \n",
    "        ## model\n",
    "        val_idx = tr[:,-1] == fold_nb\n",
    "        train_idx = tr[:,-1] != fold_nb\n",
    "        X_train, y_train = tr[train_idx, :], target[train_idx, :]\n",
    "        X_val, y_val = tr[val_idx, :], target[val_idx, :]\n",
    "        X_train = np.delete(X_train, -1, 1)\n",
    "        X_val = np.delete(X_val, -1, 1)\n",
    "        model = TabNetRegressor(**tabnet_params)\n",
    "    \n",
    "        model.fit(X_train=X_train,\n",
    "              y_train=y_train,\n",
    "              eval_set=[(X_val, y_val)],\n",
    "              eval_name = [\"val\"],\n",
    "              eval_metric = [\"logits_ll\"],\n",
    "              max_epochs=MAX_EPOCH,\n",
    "              patience=20, batch_size=1024, virtual_batch_size=128,\n",
    "              num_workers=1, drop_last=False,\n",
    "              # use binary cross entropy as this is not a regression problem\n",
    "              loss_fn=torch.nn.functional.binary_cross_entropy_with_logits)\n",
    "    \n",
    "        preds_val = model.predict(X_val)\n",
    "        # Apply sigmoid to the predictions\n",
    "        preds =  1 / (1 + np.exp(-preds_val))\n",
    "        score = np.min(model.history[\"val_logits_ll\"])\n",
    "        oof_preds[val_idx,:] = preds\n",
    "        scores.append(score)\n",
    "\n",
    "        # preds on test\n",
    "        preds_test = model.predict(te)\n",
    "        test_cv_preds.append(1 / (1 + np.exp(-preds_test)))\n",
    "        \n",
    "    test_preds_all = np.stack(test_cv_preds)\n",
    "    print(\"OOF log loss:\", log_loss(np.ravel(target), np.ravel(np.array(oof_preds))))\n",
    "    aucs = []\n",
    "    for task_id in range(206):\n",
    "        aucs.append(roc_auc_score(y_true=target[:, task_id],y_score=oof_preds[:, task_id]))\n",
    "    print(f\"Overall AUC : {np.mean(aucs)}\")\n",
    "    return oof_preds, test_preds_all\n",
    "\n",
    "target_oof = np.zeros([len(fn_train),fn_targets.shape[1]])\n",
    "target_pred = np.zeros([len(fn_test),fn_targets.shape[1]])\n",
    "\n",
    "seeds = [0]\n",
    "for seed_ in seeds:\n",
    "    oof_preds, test_preds_all = modelling_tabnet(fn_train, fn_targets, fn_test, seed_)\n",
    "    target_oof += oof_preds / len(seeds)\n",
    "    target_pred += test_preds_all.mean(axis=0) / len(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:36:13.211607Z",
     "iopub.status.busy": "2020-11-08T08:36:13.211019Z",
     "iopub.status.idle": "2020-11-08T08:36:23.952820Z",
     "shell.execute_reply": "2020-11-08T08:36:23.952230Z"
    },
    "papermill": {
     "duration": 10.787827,
     "end_time": "2020-11-08T08:36:23.952939",
     "exception": false,
     "start_time": "2020-11-08T08:36:13.165112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(target_oof).to_csv(\"tab_newval_oof.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:36:24.044068Z",
     "iopub.status.busy": "2020-11-08T08:36:24.043196Z",
     "iopub.status.idle": "2020-11-08T08:36:25.237084Z",
     "shell.execute_reply": "2020-11-08T08:36:25.237550Z"
    },
    "papermill": {
     "duration": 1.242976,
     "end_time": "2020-11-08T08:36:25.237696",
     "exception": false,
     "start_time": "2020-11-08T08:36:23.994720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AUC : 0.6175376498318935\n"
     ]
    }
   ],
   "source": [
    "aucs = []\n",
    "for task_id in range(targets.shape[1]-1):\n",
    "    aucs.append(roc_auc_score(y_true=targets.iloc[:, task_id+1].values,\n",
    "                              y_score=target_oof[:, task_id]))\n",
    "print(f\"Overall AUC : {np.mean(aucs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:36:25.332249Z",
     "iopub.status.busy": "2020-11-08T08:36:25.331434Z",
     "iopub.status.idle": "2020-11-08T08:36:32.378436Z",
     "shell.execute_reply": "2020-11-08T08:36:32.377843Z"
    },
    "papermill": {
     "duration": 7.099118,
     "end_time": "2020-11-08T08:36:32.378562",
     "exception": false,
     "start_time": "2020-11-08T08:36:25.279444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF log loss:  0.016317946358678424\n",
      "OOF log loss:  0.01632044573911291\n"
     ]
    }
   ],
   "source": [
    "p_min = 0.00005\n",
    "p_max = 1 - p_min\n",
    "\n",
    "t = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "train_checkscore = t.copy()\n",
    "train_checkscore.loc[train_checkscore.index.isin(cons_train_index),target_feats] = target_oof\n",
    "train_checkscore.loc[train_checkscore.index.isin(noncons_train_index),target_feats] = 0\n",
    "\n",
    "t.drop(\"sig_id\", axis=1, inplace=True)\n",
    "print('OOF log loss: ', log_loss(np.ravel(t), np.ravel(np.array(train_checkscore.iloc[:,1:]))))\n",
    "print('OOF log loss: ', log_loss(np.ravel(t), np.ravel(np.clip(np.array(train_checkscore.iloc[:,1:]),p_min, p_max))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-08T08:36:32.471540Z",
     "iopub.status.busy": "2020-11-08T08:36:32.470720Z",
     "iopub.status.idle": "2020-11-08T08:36:34.611379Z",
     "shell.execute_reply": "2020-11-08T08:36:34.610744Z"
    },
    "papermill": {
     "duration": 2.189598,
     "end_time": "2020-11-08T08:36:34.611492",
     "exception": false,
     "start_time": "2020-11-08T08:36:32.421894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub[target_feats] = target_pred\n",
    "sub.loc[noncons_test_index,target_feats] = 0\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.043038,
     "end_time": "2020-11-08T08:36:34.697888",
     "exception": false,
     "start_time": "2020-11-08T08:36:34.654850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 491.903089,
   "end_time": "2020-11-08T08:36:35.751018",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-08T08:28:23.847929",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
