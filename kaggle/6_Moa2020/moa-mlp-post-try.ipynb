{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018573,
     "end_time": "2021-03-19T08:11:20.045819",
     "exception": false,
     "start_time": "2021-03-19T08:11:20.027246",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Late submission**\n",
    "- solve as a multiclass classification problem\n",
    "- cancel label smoothing because it is for multilabel task\n",
    "- change learning shceduler parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-03-19T08:11:20.091432Z",
     "iopub.status.busy": "2021-03-19T08:11:20.090835Z",
     "iopub.status.idle": "2021-03-19T08:11:29.784921Z",
     "shell.execute_reply": "2021-03-19T08:11:29.784361Z"
    },
    "papermill": {
     "duration": 9.721657,
     "end_time": "2021-03-19T08:11:29.785035",
     "exception": false,
     "start_time": "2021-03-19T08:11:20.063378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:21: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from umap import UMAP\n",
    "import networkx as nx\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss,roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.compose import make_column_transformer,ColumnTransformer\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from sklearn.pipeline import make_pipeline,make_union\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "\n",
    "sys.path.append('../input/multilabelstraifier/')\n",
    "from ml_stratifiers import MultilabelStratifiedKFold\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "from sklearn.utils import check_random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020617,
     "end_time": "2021-03-19T08:11:29.826170",
     "exception": false,
     "start_time": "2021-03-19T08:11:29.805553",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# final engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T08:11:29.867791Z",
     "iopub.status.busy": "2021-03-19T08:11:29.866896Z",
     "iopub.status.idle": "2021-03-19T08:11:37.994593Z",
     "shell.execute_reply": "2021-03-19T08:11:37.993515Z"
    },
    "papermill": {
     "duration": 8.149285,
     "end_time": "2021-03-19T08:11:37.994708",
     "exception": false,
     "start_time": "2021-03-19T08:11:29.845423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/lish-moa/'\n",
    "train = pd.read_csv(DATA_DIR + 'train_features.csv')\n",
    "targets = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "non_targets = pd.read_csv(DATA_DIR + 'train_targets_nonscored.csv')\n",
    "test = pd.read_csv(DATA_DIR + 'test_features.csv')\n",
    "sub = pd.read_csv(DATA_DIR + 'sample_submission.csv')\n",
    "drug = pd.read_csv(DATA_DIR + 'train_drug.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T08:11:38.039026Z",
     "iopub.status.busy": "2021-03-19T08:11:38.037075Z",
     "iopub.status.idle": "2021-03-19T08:11:38.039643Z",
     "shell.execute_reply": "2021-03-19T08:11:38.040075Z"
    },
    "papermill": {
     "duration": 0.027411,
     "end_time": "2021-03-19T08:11:38.040188",
     "exception": false,
     "start_time": "2021-03-19T08:11:38.012777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_feats = [ i for i in targets.columns if i != \"sig_id\"]\n",
    "g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "c_feats = [i for i in train.columns if \"c-\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T08:11:38.083985Z",
     "iopub.status.busy": "2021-03-19T08:11:38.083266Z",
     "iopub.status.idle": "2021-03-19T08:11:38.175927Z",
     "shell.execute_reply": "2021-03-19T08:11:38.175445Z"
    },
    "papermill": {
     "duration": 0.117792,
     "end_time": "2021-03-19T08:11:38.176035",
     "exception": false,
     "start_time": "2021-03-19T08:11:38.058243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "noncons_train_index = train[train.cp_type==\"ctl_vehicle\"].index\n",
    "cons_train_index = train[train.cp_type!=\"ctl_vehicle\"].index\n",
    "noncons_test_index = test[test.cp_type==\"ctl_vehicle\"].index\n",
    "cons_test_index = test[test.cp_type!=\"ctl_vehicle\"].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01782,
     "end_time": "2021-03-19T08:11:38.212093",
     "exception": false,
     "start_time": "2021-03-19T08:11:38.194273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# target group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T08:11:38.266257Z",
     "iopub.status.busy": "2021-03-19T08:11:38.265558Z",
     "iopub.status.idle": "2021-03-19T08:11:38.269067Z",
     "shell.execute_reply": "2021-03-19T08:11:38.269446Z"
    },
    "papermill": {
     "duration": 0.039474,
     "end_time": "2021-03-19T08:11:38.269566",
     "exception": false,
     "start_time": "2021-03-19T08:11:38.230092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = targets.drop(\"sig_id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T08:11:38.314797Z",
     "iopub.status.busy": "2021-03-19T08:11:38.312912Z",
     "iopub.status.idle": "2021-03-19T08:11:49.883853Z",
     "shell.execute_reply": "2021-03-19T08:11:49.884261Z"
    },
    "papermill": {
     "duration": 11.596807,
     "end_time": "2021-03-19T08:11:49.884404",
     "exception": false,
     "start_time": "2021-03-19T08:11:38.287597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23814, 328), (328, 206))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_string(row):\n",
    "    return str(row[1:].values).replace('[','').replace(']','').replace('\\n','').replace(' ','')\n",
    "\n",
    "targets[\"target_pair\"] = targets.apply(make_string, axis=1)\n",
    "targetpair_id = dict(enumerate(targets[\"target_pair\"].unique()))\n",
    "id_targetpair = {y:x for x,y in targetpair_id.items()}\n",
    "targets[\"target_pair_num\"] = targets[\"target_pair\"].map(id_targetpair)\n",
    "\n",
    "multiclass_targets = pd.get_dummies(targets[\"target_pair_num\"])\n",
    "\n",
    "for i in range(len(id_targetpair.keys())):\n",
    "    if i == 0:\n",
    "        classid_target = np.array(list((targetpair_id[i]))).reshape(1,-1)      \n",
    "    else:\n",
    "        classid_target = np.vstack([classid_target, np.array(list((targetpair_id[i]))).reshape(1,-1)])\n",
    "        \n",
    "multiclass_targets.shape, classid_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T08:11:49.963659Z",
     "iopub.status.busy": "2021-03-19T08:11:49.962263Z",
     "iopub.status.idle": "2021-03-19T08:11:49.964716Z",
     "shell.execute_reply": "2021-03-19T08:11:49.965145Z"
    },
    "papermill": {
     "duration": 0.061945,
     "end_time": "2021-03-19T08:11:49.965250",
     "exception": false,
     "start_time": "2021-03-19T08:11:49.903305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classid_target = classid_target.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T08:11:50.006794Z",
     "iopub.status.busy": "2021-03-19T08:11:50.005905Z",
     "iopub.status.idle": "2021-03-19T08:11:50.008384Z",
     "shell.execute_reply": "2021-03-19T08:11:50.008763Z"
    },
    "papermill": {
     "duration": 0.02471,
     "end_time": "2021-03-19T08:11:50.008890",
     "exception": false,
     "start_time": "2021-03-19T08:11:49.984180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_num = multiclass_targets.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018574,
     "end_time": "2021-03-19T08:11:50.045923",
     "exception": false,
     "start_time": "2021-03-19T08:11:50.027349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T08:11:50.095868Z",
     "iopub.status.busy": "2021-03-19T08:11:50.094916Z",
     "iopub.status.idle": "2021-03-19T08:11:50.361381Z",
     "shell.execute_reply": "2021-03-19T08:11:50.360866Z"
    },
    "papermill": {
     "duration": 0.296837,
     "end_time": "2021-03-19T08:11:50.361480",
     "exception": false,
     "start_time": "2021-03-19T08:11:50.064643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train[train.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "test = test[test.index.isin(cons_test_index)].copy().reset_index(drop=True)\n",
    "targets = targets[targets.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "\n",
    "# no need to change to one-hot encoding form\n",
    "# https://discuss.pytorch.org/t/runtimeerror-multi-target-not-supported-newbie/10216\n",
    "multiclass_targets = targets[\"target_pair_num\"].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018729,
     "end_time": "2021-03-19T08:11:50.399406",
     "exception": false,
     "start_time": "2021-03-19T08:11:50.380677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T08:11:50.491237Z",
     "iopub.status.busy": "2021-03-19T08:11:50.489891Z",
     "iopub.status.idle": "2021-03-19T08:11:50.857050Z",
     "shell.execute_reply": "2021-03-19T08:11:50.856576Z"
    },
    "papermill": {
     "duration": 0.438929,
     "end_time": "2021-03-19T08:11:50.857149",
     "exception": false,
     "start_time": "2021-03-19T08:11:50.418220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "#importance = pd.read_csv('../input/moa-feat-importance-rapids/output_source.csv')\n",
    "#importance = importance.set_index(\"Feature\")\n",
    "\n",
    "#imp_scaled = importance.copy(deep=True)\n",
    "#for c in imp_scaled.columns:\n",
    "#    imp_scaled[c] = (1 - preprocessing.MinMaxScaler().fit_transform(imp_scaled[[c]])).round(14)\n",
    "\n",
    "#print(imp_scaled.min().min(), imp_scaled.max().max(), imp_scaled.std().mean())\n",
    "\n",
    "#imp_scaled[\"MeanImp\"] = imp_scaled[target_feats].mean(axis=1)\n",
    "#imp_scaled[\"MaxImp\"]  = imp_scaled[target_feats].max(axis=1)\n",
    "\n",
    "#thresh_mean, thresh_max = 0.3, 0.95\n",
    "#fs_both = imp_scaled.loc[(imp_scaled.MeanImp >= thresh_mean) & (imp_scaled.MaxImp >= thresh_max), Targets]\n",
    "#fs_any = list(imp_scaled.loc[(imp_scaled.MeanImp >= thresh_mean) | (imp_scaled.MaxImp >= thresh_max), target_feats].index)\n",
    "#print(len(fs_any))\n",
    "\n",
    "#least_contribution = list(imp_scaled.sort_values(\"MeanImp\", ascending=True).index)\n",
    "#least_contribution2 = list(imp_scaled.sort_values(\"MaxImp\", ascending=True).index)\n",
    "#drop_feats = [i for i in c_feats+g_feats if i not in fs_any]\n",
    "\n",
    "X = train.iloc[:,4:].copy().values\n",
    "select = VarianceThreshold(threshold=0.7)\n",
    "X_new = select.fit_transform(X)\n",
    "drop_feats = list(np.array(train.iloc[:,4:].columns)[select.get_support()==False])\n",
    "print(len(drop_feats))\n",
    "\n",
    "#drop_feats = least_contribution[:10]\n",
    "#drop_feats += least_contribution2[:10]\n",
    "\n",
    "train.drop(drop_feats, axis=1, inplace=True)\n",
    "test.drop(drop_feats, axis=1, inplace=True)\n",
    "\n",
    "g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "c_feats = [i for i in train.columns if \"c-\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T08:11:50.904192Z",
     "iopub.status.busy": "2021-03-19T08:11:50.903095Z",
     "iopub.status.idle": "2021-03-19T08:11:58.978932Z",
     "shell.execute_reply": "2021-03-19T08:11:58.978397Z"
    },
    "papermill": {
     "duration": 8.102207,
     "end_time": "2021-03-19T08:11:58.979055",
     "exception": false,
     "start_time": "2021-03-19T08:11:50.876848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rank gauss\n",
    "for i in c_feats + g_feats:\n",
    "    ss = preprocessing.QuantileTransformer(n_quantiles=100, random_state=0, output_distribution=\"normal\")\n",
    "    ss.fit(pd.concat([train[i], test[i]]).values.reshape(-1,1))\n",
    "    train[i] = ss.transform(train[i].values.reshape(-1,1))\n",
    "    test[i] = ss.transform(test[i].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T08:11:59.044657Z",
     "iopub.status.busy": "2021-03-19T08:11:59.043864Z",
     "iopub.status.idle": "2021-03-19T08:11:59.045921Z",
     "shell.execute_reply": "2021-03-19T08:11:59.045341Z"
    },
    "papermill": {
     "duration": 0.036954,
     "end_time": "2021-03-19T08:11:59.046030",
     "exception": false,
     "start_time": "2021-03-19T08:11:59.009076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # data augmentation by cutmix\n",
    "# random.seed(0)\n",
    "# np.random.seed(0)\n",
    "# def cutmix_for_tabular(x, y=None, alpha=1.0, p=1.0, random_state=None):\n",
    "#     x_ = x.copy()\n",
    "#     n, d = x.shape\n",
    "\n",
    "#     if n is not None and random.random() < p:\n",
    "#         random_state = check_random_state(random_state)\n",
    "#         l = random_state.beta(alpha, alpha)\n",
    "#         mask = random_state.choice([False, True], size=d, p=[l, 1.0 - l])\n",
    "#         mask = np.where(mask)[0]\n",
    "#         shuffle = random_state.choice(n, n, replace=False)\n",
    "#         x_[:,mask] = x_[np.ix_(shuffle,mask)]\n",
    "        \n",
    "#         if y is not None:\n",
    "#             y = l * y + (1.0 - l) * y[shuffle]\n",
    "        \n",
    "#     return x_, y\n",
    "\n",
    "# train_mod, y_mod = cutmix_for_tabular(train.values, y.values, alpha=1, p=1)\n",
    "\n",
    "# assert np.sum(y_mod != y.values).sum() != 0 \n",
    "# assert np.sum(train_mod != train.values).sum() != 0\n",
    "\n",
    "# train_mod = pd.DataFrame(train_mod, columns = train.columns)\n",
    "# train = pd.concat([train, train_mod], axis=0).reset_index(drop=True)\n",
    "\n",
    "# y_mod = pd.DataFrame(y_mod, columns = y.columns)\n",
    "# y = pd.concat([y, y_mod], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T08:11:59.117651Z",
     "iopub.status.busy": "2021-03-19T08:11:59.116940Z",
     "iopub.status.idle": "2021-03-19T08:12:01.156756Z",
     "shell.execute_reply": "2021-03-19T08:12:01.155856Z"
    },
    "papermill": {
     "duration": 2.081458,
     "end_time": "2021-03-19T08:12:01.156878",
     "exception": false,
     "start_time": "2021-03-19T08:11:59.075420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_num = 10\n",
    "pca_c_cols = [\"pca-c\"+str(i+1) for i in range(c_num)]\n",
    "pca = PCA(n_components=c_num,random_state=42)\n",
    "c_train = pca.fit_transform(train[c_feats])\n",
    "c_test = pca.transform(test[c_feats])\n",
    "c_train = pd.DataFrame(c_train, columns=pca_c_cols)\n",
    "c_test = pd.DataFrame(c_test, columns=pca_c_cols)\n",
    "\n",
    "g_num = 60\n",
    "pca_g_cols = [\"pca-g\"+str(i+1) for i in range(g_num)]\n",
    "pca = PCA(n_components=g_num, random_state=42)\n",
    "g_train = pca.fit_transform(train[g_feats])\n",
    "g_test = pca.transform(test[g_feats])\n",
    "g_train = pd.DataFrame(g_train, columns=pca_g_cols)\n",
    "g_test = pd.DataFrame(g_test, columns=pca_g_cols)\n",
    "\n",
    "train = pd.concat([train, c_train],axis=1)\n",
    "test = pd.concat([test, c_test],axis=1)\n",
    "train = pd.concat([train, g_train],axis=1)\n",
    "test = pd.concat([test, g_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T08:12:01.205834Z",
     "iopub.status.busy": "2021-03-19T08:12:01.204675Z",
     "iopub.status.idle": "2021-03-19T08:12:02.996730Z",
     "shell.execute_reply": "2021-03-19T08:12:02.996141Z"
    },
    "papermill": {
     "duration": 1.819935,
     "end_time": "2021-03-19T08:12:02.996869",
     "exception": false,
     "start_time": "2021-03-19T08:12:01.176934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe(df):\n",
    "    tmp = df.copy()\n",
    "    tmp['g_kurt'] = tmp[g_feats].kurtosis(axis = 1)\n",
    "    tmp['g_skew'] = tmp[g_feats].skew(axis = 1)\n",
    "    tmp['c_kurt'] = tmp[c_feats].kurtosis(axis = 1)\n",
    "    tmp['c_skew'] = tmp[c_feats].skew(axis = 1)\n",
    "    tmp = pd.get_dummies(tmp, columns=['cp_time','cp_dose'])\n",
    "    tmp.drop([\"cp_type\", \"sig_id\"], axis=1, inplace=True)\n",
    "    return tmp\n",
    "\n",
    "train = fe(train)\n",
    "test = fe(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T08:12:03.045512Z",
     "iopub.status.busy": "2021-03-19T08:12:03.044304Z",
     "iopub.status.idle": "2021-03-19T08:12:03.198193Z",
     "shell.execute_reply": "2021-03-19T08:12:03.197664Z"
    },
    "papermill": {
     "duration": 0.179293,
     "end_time": "2021-03-19T08:12:03.198292",
     "exception": false,
     "start_time": "2021-03-19T08:12:03.018999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fn_train = train.copy().to_numpy()\n",
    "fn_test = test.copy().to_numpy()\n",
    "fn_targets = y.copy().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T08:12:03.243539Z",
     "iopub.status.busy": "2021-03-19T08:12:03.242743Z",
     "iopub.status.idle": "2021-03-19T08:12:03.245445Z",
     "shell.execute_reply": "2021-03-19T08:12:03.245043Z"
    },
    "papermill": {
     "duration": 0.026895,
     "end_time": "2021-03-19T08:12:03.245531",
     "exception": false,
     "start_time": "2021-03-19T08:12:03.218636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fn_multiclass_targets = multiclass_targets.copy().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T08:12:03.289992Z",
     "iopub.status.busy": "2021-03-19T08:12:03.289136Z",
     "iopub.status.idle": "2021-03-19T08:12:03.294180Z",
     "shell.execute_reply": "2021-03-19T08:12:03.293472Z"
    },
    "papermill": {
     "duration": 0.028872,
     "end_time": "2021-03-19T08:12:03.294315",
     "exception": false,
     "start_time": "2021-03-19T08:12:03.265443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 918) (3624, 918) (23814, 206) (21948,)\n"
     ]
    }
   ],
   "source": [
    "print(fn_train.shape, fn_test.shape, fn_targets.shape, fn_multiclass_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020448,
     "end_time": "2021-03-19T08:12:03.335989",
     "exception": false,
     "start_time": "2021-03-19T08:12:03.315541",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T08:12:03.733941Z",
     "iopub.status.busy": "2021-03-19T08:12:03.733176Z",
     "iopub.status.idle": "2021-03-19T08:12:03.737062Z",
     "shell.execute_reply": "2021-03-19T08:12:03.737754Z"
    },
    "papermill": {
     "duration": 0.381104,
     "end_time": "2021-03-19T08:12:03.737900",
     "exception": false,
     "start_time": "2021-03-19T08:12:03.356796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T08:12:03.789579Z",
     "iopub.status.busy": "2021-03-19T08:12:03.788444Z",
     "iopub.status.idle": "2021-03-19T08:12:03.790991Z",
     "shell.execute_reply": "2021-03-19T08:12:03.791367Z"
    },
    "papermill": {
     "duration": 0.032687,
     "end_time": "2021-03-19T08:12:03.791480",
     "exception": false,
     "start_time": "2021-03-19T08:12:03.758793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SmoothCrossEntropyLoss(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets, n_classes, smoothing=0.0):\n",
    "        assert 0 <= smoothing <= 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1 - smoothing) + torch.ones_like(targets).to(device) * smoothing / n_classes\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothCrossEntropyLoss()._smooth(targets, inputs.shape[1], self.smoothing)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            inputs = inputs * self.weight.unsqueeze(0)\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T08:12:03.847452Z",
     "iopub.status.busy": "2021-03-19T08:12:03.846905Z",
     "iopub.status.idle": "2021-03-19T08:12:03.849947Z",
     "shell.execute_reply": "2021-03-19T08:12:03.850629Z"
    },
    "papermill": {
     "duration": 0.038629,
     "end_time": "2021-03-19T08:12:03.850766",
     "exception": false,
     "start_time": "2021-03-19T08:12:03.812137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "def seed_everything(seed=42): \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "class MoaModel(nn.Module):\n",
    "    def __init__(self, num_columns, last_num):\n",
    "        super(MoaModel, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_columns)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_columns, 1024))\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(1024)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(1024, 1024))\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(1024)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(1024, last_num))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu1(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.relu2(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021387,
     "end_time": "2021-03-19T08:12:03.894056",
     "exception": false,
     "start_time": "2021-03-19T08:12:03.872669",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T08:12:03.964924Z",
     "iopub.status.busy": "2021-03-19T08:12:03.954459Z",
     "iopub.status.idle": "2021-03-19T08:12:03.973077Z",
     "shell.execute_reply": "2021-03-19T08:12:03.972614Z"
    },
    "papermill": {
     "duration": 0.057959,
     "end_time": "2021-03-19T08:12:03.973169",
     "exception": false,
     "start_time": "2021-03-19T08:12:03.915210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_folds=7\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "smoothing = 0.001\n",
    "p_min = smoothing\n",
    "p_max = 1 - smoothing\n",
    "train_epochs = 10\n",
    "\n",
    "def multi_log_loss(y_true, y_pred):\n",
    "    metrics = []\n",
    "    for i, target in enumerate(target_feats):\n",
    "        metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float), labels=[0,1]))\n",
    "    return np.mean(metrics)\n",
    "    \n",
    "def modelling_torch(tr, target, te, sample_seed, init_num, last_num):\n",
    "    seed_everything(seed=sample_seed) \n",
    "    X_train = tr.copy()\n",
    "    y_train = target.copy()\n",
    "    X_test = te.copy()\n",
    "    test_len = X_test.shape[0]\n",
    "    \n",
    "    mskf=KFold(n_splits = n_folds, shuffle=True, random_state=224)\n",
    "    #metric = lambda inputs, targets : F.binary_cross_entropy((torch.clamp(torch.sigmoid(inputs), p_min, p_max)), targets)\n",
    "\n",
    "    models = []\n",
    "    \n",
    "    X_test2 = torch.tensor(X_test, dtype=torch.float32)\n",
    "    test = torch.utils.data.TensorDataset(X_test2) \n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    oof = np.zeros([len(X_train),last_num])\n",
    "    oof_targets = np.zeros([len(X_train),last_num])\n",
    "    pred_value = np.zeros([test_len, last_num])\n",
    "    for fold, (train_index, valid_index) in enumerate(mskf.split(X_train, y_train)):\n",
    "        print(\"Seed \"+str(sample_seed)+\"_Fold \"+str(fold+1))\n",
    "        X_train2 = torch.tensor(X_train[train_index,:], dtype=torch.float32)\n",
    "        y_train2 = torch.tensor(y_train[train_index], dtype=torch.long)\n",
    "\n",
    "        X_valid2 = torch.tensor(X_train[valid_index,:], dtype=torch.float32)\n",
    "        y_valid2 = torch.tensor(y_train[valid_index], dtype=torch.long)\n",
    "        \n",
    "        train = torch.utils.data.TensorDataset(X_train2, y_train2)\n",
    "        valid = torch.utils.data.TensorDataset(X_valid2, y_valid2)\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True) \n",
    "        valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "            \n",
    "        clf = MoaModel(init_num, last_num)\n",
    "        loss_fn = nn.CrossEntropyLoss() #SmoothCrossEntropyLoss(smoothing=smoothing)\n",
    "\n",
    "        optimizer = optim.Adam(clf.parameters(), lr = 0.01, weight_decay=1e-5) \n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=train_epochs, steps_per_epoch=len(train_loader))\n",
    "        \n",
    "        clf.to(device)\n",
    "        \n",
    "        best_val_loss = np.inf\n",
    "        stop_counts = 0\n",
    "        for epoch in range(train_epochs):\n",
    "            start_time = time.time()\n",
    "            clf.train()\n",
    "            avg_loss = 0.\n",
    "            #sm_avg_loss = 0.\n",
    "            for x_batch, y_batch in tqdm(train_loader, disable=True):\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch)\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                avg_loss += loss.item() / len(train_loader)  \n",
    "                #sm_avg_loss += metric(y_pred, y_batch) / len(train_loader) \n",
    "                \n",
    "            clf.eval()\n",
    "            avg_val_loss = 0.\n",
    "            #sm_avg_val_loss = 0.\n",
    "            for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch).detach()\n",
    "                avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "                #sm_avg_val_loss += metric(y_pred, y_batch) / len(valid_loader)\n",
    "        \n",
    "            elapsed_time = time.time() - start_time \n",
    "                    \n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                print('Epoch {}  loss={:.5f}  val_loss={:.5f}  time={:.2f}s'.format(\n",
    "                    epoch + 1, avg_loss, avg_val_loss, elapsed_time))\n",
    "                torch.save(clf.state_dict(), 'best-model-parameters.pt')\n",
    "                stop_counts = 0\n",
    "            else:\n",
    "                stop_counts += 1\n",
    "                \n",
    "            if stop_counts >= EARLY_STOPPING_STEPS:\n",
    "                break\n",
    "        \n",
    "        pred_model = MoaModel(init_num, last_num)\n",
    "        pred_model.load_state_dict(torch.load('best-model-parameters.pt'))         \n",
    "        pred_model.eval()\n",
    "        \n",
    "        # validation check ----------------\n",
    "        oof_epoch = np.zeros([X_valid2.size(0), last_num])\n",
    "        target_epoch = np.zeros([X_valid2.size(0), last_num])\n",
    "        for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "            y_pred = pred_model(x_batch).detach()\n",
    "            oof_epoch[i * batch_size:(i+1) * batch_size,:] = F.softmax(y_pred.cpu()) #torch.clamp(torch.sigmoid(y_pred.cpu()), p_min, p_max)\n",
    "        oof[valid_index,:] = oof_epoch\n",
    "        #-----------------------------------\n",
    "        \n",
    "        # test predcition --------------\n",
    "        test_preds = np.zeros([test_len, last_num])\n",
    "        for i, (x_batch,) in enumerate(test_loader): \n",
    "            y_pred = pred_model(x_batch).detach()\n",
    "            test_preds[i * batch_size:(i+1) * batch_size, :] = F.softmax(y_pred.cpu()) #torch.clamp(torch.sigmoid(y_pred.cpu()), p_min, p_max)\n",
    "        pred_value += test_preds / n_folds\n",
    "        # ------------------------------\n",
    "    \n",
    "    return oof, pred_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T08:12:04.024757Z",
     "iopub.status.busy": "2021-03-19T08:12:04.023800Z",
     "iopub.status.idle": "2021-03-19T08:17:07.163327Z",
     "shell.execute_reply": "2021-03-19T08:17:07.162198Z"
    },
    "papermill": {
     "duration": 303.169009,
     "end_time": "2021-03-19T08:17:07.163454",
     "exception": false,
     "start_time": "2021-03-19T08:12:03.994445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 0_Fold 1\n",
      "Epoch 1  loss=4.02374  val_loss=3.22342  time=1.40s\n",
      "Epoch 2  loss=3.02348  val_loss=3.06554  time=0.72s\n",
      "Epoch 3  loss=2.71118  val_loss=3.01691  time=0.72s\n",
      "Epoch 4  loss=2.39664  val_loss=3.01194  time=1.02s\n",
      "Seed 0_Fold 2\n",
      "Epoch 1  loss=4.03544  val_loss=3.16366  time=0.73s\n",
      "Epoch 2  loss=3.04173  val_loss=2.91803  time=0.71s\n",
      "Epoch 3  loss=2.70489  val_loss=2.89831  time=0.93s\n",
      "Seed 0_Fold 3\n",
      "Epoch 1  loss=4.00880  val_loss=3.32399  time=0.71s\n",
      "Epoch 2  loss=3.02552  val_loss=3.08844  time=0.72s\n",
      "Epoch 3  loss=2.70134  val_loss=3.05753  time=0.72s\n",
      "Seed 0_Fold 4\n",
      "Epoch 1  loss=3.99025  val_loss=3.31618  time=0.74s\n",
      "Epoch 2  loss=3.03162  val_loss=3.10843  time=0.71s\n",
      "Epoch 3  loss=2.68957  val_loss=3.08388  time=0.72s\n",
      "Seed 0_Fold 5\n",
      "Epoch 1  loss=3.99746  val_loss=3.22073  time=0.82s\n",
      "Epoch 2  loss=3.05963  val_loss=2.97591  time=1.00s\n",
      "Epoch 3  loss=2.72356  val_loss=2.96130  time=0.76s\n",
      "Seed 0_Fold 6\n",
      "Epoch 1  loss=4.01855  val_loss=3.18836  time=0.73s\n",
      "Epoch 2  loss=3.04384  val_loss=2.99424  time=1.06s\n",
      "Epoch 3  loss=2.70935  val_loss=2.94055  time=0.79s\n",
      "Seed 0_Fold 7\n",
      "Epoch 1  loss=3.99862  val_loss=3.19152  time=0.73s\n",
      "Epoch 2  loss=3.05442  val_loss=2.98733  time=0.74s\n",
      "Epoch 3  loss=2.70410  val_loss=2.92281  time=0.73s\n",
      "Seed 1_Fold 1\n",
      "Epoch 1  loss=3.98675  val_loss=3.24928  time=0.74s\n",
      "Epoch 2  loss=3.03772  val_loss=3.03364  time=0.71s\n",
      "Epoch 3  loss=2.71188  val_loss=2.97805  time=0.72s\n",
      "Seed 1_Fold 2\n",
      "Epoch 1  loss=4.01387  val_loss=3.13016  time=0.72s\n",
      "Epoch 2  loss=3.04305  val_loss=2.94162  time=0.72s\n",
      "Epoch 3  loss=2.71659  val_loss=2.91225  time=0.71s\n",
      "Seed 1_Fold 3\n",
      "Epoch 1  loss=4.01102  val_loss=3.27539  time=0.79s\n",
      "Epoch 2  loss=3.02833  val_loss=3.08915  time=0.73s\n",
      "Epoch 3  loss=2.69416  val_loss=3.08021  time=0.72s\n",
      "Seed 1_Fold 4\n",
      "Epoch 1  loss=3.99692  val_loss=3.36005  time=0.73s\n",
      "Epoch 2  loss=3.01489  val_loss=3.12647  time=0.74s\n",
      "Epoch 3  loss=2.70045  val_loss=3.07874  time=0.72s\n",
      "Seed 1_Fold 5\n",
      "Epoch 1  loss=4.01496  val_loss=3.21609  time=0.74s\n",
      "Epoch 2  loss=3.04556  val_loss=3.00641  time=0.71s\n",
      "Epoch 3  loss=2.71457  val_loss=2.92517  time=0.72s\n",
      "Seed 1_Fold 6\n",
      "Epoch 1  loss=3.98491  val_loss=3.17989  time=0.77s\n",
      "Epoch 2  loss=3.03982  val_loss=2.97640  time=0.76s\n",
      "Epoch 3  loss=2.73066  val_loss=2.93206  time=0.72s\n",
      "Epoch 4  loss=2.42865  val_loss=2.91104  time=0.73s\n",
      "Seed 1_Fold 7\n",
      "Epoch 1  loss=4.01588  val_loss=3.24953  time=0.72s\n",
      "Epoch 2  loss=3.04472  val_loss=2.96989  time=0.72s\n",
      "Epoch 3  loss=2.70728  val_loss=2.96761  time=0.72s\n",
      "Epoch 4  loss=2.39663  val_loss=2.96732  time=0.72s\n",
      "Seed 2_Fold 1\n",
      "Epoch 1  loss=4.00992  val_loss=3.26317  time=0.72s\n",
      "Epoch 2  loss=3.04398  val_loss=3.05093  time=0.92s\n",
      "Epoch 3  loss=2.72580  val_loss=3.00471  time=0.73s\n",
      "Epoch 4  loss=2.42015  val_loss=2.98086  time=0.72s\n",
      "Seed 2_Fold 2\n",
      "Epoch 1  loss=4.02134  val_loss=3.16412  time=0.76s\n",
      "Epoch 2  loss=3.04605  val_loss=2.92984  time=0.72s\n",
      "Epoch 3  loss=2.71511  val_loss=2.89287  time=0.72s\n",
      "Seed 2_Fold 3\n",
      "Epoch 1  loss=4.03434  val_loss=3.32453  time=0.72s\n",
      "Epoch 2  loss=3.03210  val_loss=3.11838  time=0.72s\n",
      "Epoch 3  loss=2.68843  val_loss=3.05816  time=0.72s\n",
      "Seed 2_Fold 4\n",
      "Epoch 1  loss=3.97117  val_loss=3.36274  time=0.72s\n",
      "Epoch 2  loss=3.04042  val_loss=3.13319  time=0.72s\n",
      "Epoch 3  loss=2.70568  val_loss=3.05622  time=0.72s\n",
      "Seed 2_Fold 5\n",
      "Epoch 1  loss=4.01774  val_loss=3.19385  time=0.88s\n",
      "Epoch 2  loss=3.03480  val_loss=2.98904  time=0.80s\n",
      "Epoch 3  loss=2.72650  val_loss=2.90836  time=0.72s\n",
      "Seed 2_Fold 6\n",
      "Epoch 1  loss=4.00219  val_loss=3.21794  time=0.93s\n",
      "Epoch 2  loss=3.02960  val_loss=2.97403  time=0.73s\n",
      "Epoch 3  loss=2.70919  val_loss=2.92102  time=0.99s\n",
      "Seed 2_Fold 7\n",
      "Epoch 1  loss=4.00282  val_loss=3.22008  time=0.72s\n",
      "Epoch 2  loss=3.03783  val_loss=2.97202  time=0.73s\n",
      "Epoch 3  loss=2.71996  val_loss=2.93142  time=0.72s\n",
      "Seed 3_Fold 1\n",
      "Epoch 1  loss=4.01744  val_loss=3.28508  time=0.83s\n",
      "Epoch 2  loss=3.03784  val_loss=3.08088  time=0.77s\n",
      "Epoch 3  loss=2.70776  val_loss=3.00119  time=0.75s\n",
      "Seed 3_Fold 2\n",
      "Epoch 1  loss=4.00933  val_loss=3.19062  time=0.72s\n",
      "Epoch 2  loss=3.05879  val_loss=2.95551  time=0.72s\n",
      "Epoch 3  loss=2.72173  val_loss=2.91112  time=0.73s\n",
      "Seed 3_Fold 3\n",
      "Epoch 1  loss=4.02546  val_loss=3.28266  time=0.81s\n",
      "Epoch 2  loss=3.02542  val_loss=3.10500  time=0.82s\n",
      "Epoch 3  loss=2.70425  val_loss=3.04514  time=0.86s\n",
      "Seed 3_Fold 4\n",
      "Epoch 1  loss=3.96257  val_loss=3.36356  time=0.72s\n",
      "Epoch 2  loss=3.01418  val_loss=3.13640  time=0.71s\n",
      "Epoch 3  loss=2.69504  val_loss=3.09529  time=0.72s\n",
      "Seed 3_Fold 5\n",
      "Epoch 1  loss=4.04575  val_loss=3.21041  time=0.74s\n",
      "Epoch 2  loss=3.04384  val_loss=2.98065  time=0.73s\n",
      "Epoch 3  loss=2.71694  val_loss=2.94071  time=0.72s\n",
      "Seed 3_Fold 6\n",
      "Epoch 1  loss=4.00781  val_loss=3.15956  time=0.71s\n",
      "Epoch 2  loss=3.05078  val_loss=2.97558  time=0.72s\n",
      "Epoch 3  loss=2.71276  val_loss=2.92318  time=0.73s\n",
      "Seed 3_Fold 7\n",
      "Epoch 1  loss=3.98167  val_loss=3.20488  time=0.82s\n",
      "Epoch 2  loss=3.05034  val_loss=2.95995  time=0.83s\n",
      "Epoch 3  loss=2.71361  val_loss=2.94163  time=0.72s\n",
      "Seed 4_Fold 1\n",
      "Epoch 1  loss=4.02272  val_loss=3.28294  time=0.72s\n",
      "Epoch 2  loss=3.04491  val_loss=3.03441  time=0.75s\n",
      "Epoch 3  loss=2.72520  val_loss=3.00905  time=0.74s\n",
      "Seed 4_Fold 2\n",
      "Epoch 1  loss=4.02243  val_loss=3.14021  time=0.74s\n",
      "Epoch 2  loss=3.04719  val_loss=2.97174  time=0.72s\n",
      "Epoch 3  loss=2.73324  val_loss=2.90719  time=0.72s\n",
      "Seed 4_Fold 3\n",
      "Epoch 1  loss=4.02389  val_loss=3.32324  time=0.72s\n",
      "Epoch 2  loss=3.03442  val_loss=3.07503  time=0.71s\n",
      "Epoch 3  loss=2.70117  val_loss=3.05539  time=0.73s\n",
      "Seed 4_Fold 4\n",
      "Epoch 1  loss=3.98235  val_loss=3.31583  time=0.93s\n",
      "Epoch 2  loss=3.02942  val_loss=3.12047  time=0.71s\n",
      "Epoch 3  loss=2.70496  val_loss=3.09500  time=0.72s\n",
      "Seed 4_Fold 5\n",
      "Epoch 1  loss=4.00342  val_loss=3.21924  time=0.73s\n",
      "Epoch 2  loss=3.02212  val_loss=3.02169  time=0.72s\n",
      "Epoch 3  loss=2.70986  val_loss=2.93403  time=0.76s\n",
      "Seed 4_Fold 6\n",
      "Epoch 1  loss=3.99514  val_loss=3.22424  time=0.77s\n",
      "Epoch 2  loss=3.04122  val_loss=3.04216  time=0.72s\n",
      "Epoch 3  loss=2.72599  val_loss=2.94997  time=0.72s\n",
      "Epoch 4  loss=2.41763  val_loss=2.94286  time=0.73s\n",
      "Seed 4_Fold 7\n",
      "Epoch 1  loss=3.99849  val_loss=3.21155  time=0.73s\n",
      "Epoch 2  loss=3.04661  val_loss=3.03639  time=0.72s\n",
      "Epoch 3  loss=2.73766  val_loss=2.97870  time=0.72s\n"
     ]
    }
   ],
   "source": [
    "seeds = [0,1,2,3,4]\n",
    "target_oof = np.zeros([len(fn_train), class_num])\n",
    "target_pred = np.zeros([len(fn_test), class_num])\n",
    "\n",
    "for seed_ in seeds:\n",
    "    best_oof, pytorch_pred = modelling_torch(fn_train, fn_multiclass_targets, fn_test, seed_, fn_train.shape[1], class_num)\n",
    "    target_oof += best_oof / len(seeds)\n",
    "    target_pred += pytorch_pred / len(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T08:17:07.296753Z",
     "iopub.status.busy": "2021-03-19T08:17:07.295621Z",
     "iopub.status.idle": "2021-03-19T08:17:07.362740Z",
     "shell.execute_reply": "2021-03-19T08:17:07.362256Z"
    },
    "papermill": {
     "duration": 0.137875,
     "end_time": "2021-03-19T08:17:07.362860",
     "exception": false,
     "start_time": "2021-03-19T08:17:07.224985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_oof = np.dot(target_oof, classid_target)\n",
    "target_pred = np.dot(target_pred, classid_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T08:17:07.496589Z",
     "iopub.status.busy": "2021-03-19T08:17:07.495744Z",
     "iopub.status.idle": "2021-03-19T08:17:13.343235Z",
     "shell.execute_reply": "2021-03-19T08:17:13.342598Z"
    },
    "papermill": {
     "duration": 5.919161,
     "end_time": "2021-03-19T08:17:13.343383",
     "exception": false,
     "start_time": "2021-03-19T08:17:07.424222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF log loss:  0.014375414266327437\n"
     ]
    }
   ],
   "source": [
    "t = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "train_checkscore = t.copy()\n",
    "train_checkscore.loc[train_checkscore.index.isin(cons_train_index),target_feats] = target_oof\n",
    "train_checkscore.loc[train_checkscore.index.isin(noncons_train_index),target_feats] = 0\n",
    "t.drop(\"sig_id\", axis=1, inplace=True)\n",
    "print('OOF log loss: ', log_loss(np.ravel(t), np.ravel(np.array(train_checkscore.iloc[:,1:]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T08:17:13.471071Z",
     "iopub.status.busy": "2021-03-19T08:17:13.470355Z",
     "iopub.status.idle": "2021-03-19T08:17:24.613727Z",
     "shell.execute_reply": "2021-03-19T08:17:24.613143Z"
    },
    "papermill": {
     "duration": 11.20844,
     "end_time": "2021-03-19T08:17:24.613885",
     "exception": false,
     "start_time": "2021-03-19T08:17:13.405445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_checkscore.to_csv(\"mlp_oof.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T08:17:24.744488Z",
     "iopub.status.busy": "2021-03-19T08:17:24.743540Z",
     "iopub.status.idle": "2021-03-19T08:17:26.992939Z",
     "shell.execute_reply": "2021-03-19T08:17:26.992442Z"
    },
    "papermill": {
     "duration": 2.316386,
     "end_time": "2021-03-19T08:17:26.993053",
     "exception": false,
     "start_time": "2021-03-19T08:17:24.676667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.loc[cons_test_index,target_feats] = target_pred\n",
    "sub.loc[noncons_test_index,target_feats] = 0\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.063743,
     "end_time": "2021-03-19T08:17:27.119607",
     "exception": false,
     "start_time": "2021-03-19T08:17:27.055864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 371.916782,
   "end_time": "2021-03-19T08:17:28.255114",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-03-19T08:11:16.338332",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
