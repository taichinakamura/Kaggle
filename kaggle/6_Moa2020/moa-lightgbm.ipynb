{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010076,
     "end_time": "2020-10-01T03:14:39.136077",
     "exception": false,
     "start_time": "2020-10-01T03:14:39.126001",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- code refactoring to select features by rfecv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-01T03:14:39.161890Z",
     "iopub.status.busy": "2020-10-01T03:14:39.161103Z",
     "iopub.status.idle": "2020-10-01T03:14:40.445613Z",
     "shell.execute_reply": "2020-10-01T03:14:40.446782Z"
    },
    "papermill": {
     "duration": 1.301717,
     "end_time": "2020-10-01T03:14:40.447036",
     "exception": false,
     "start_time": "2020-10-01T03:14:39.145319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/tqdm/std.py:666: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss, mutual_info_score\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "tqdm_notebook.pandas(desc=\"progress\")\n",
    "pd.set_option(\"max_columns\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-10-01T03:14:40.477543Z",
     "iopub.status.busy": "2020-10-01T03:14:40.476820Z",
     "iopub.status.idle": "2020-10-01T03:14:45.025008Z",
     "shell.execute_reply": "2020-10-01T03:14:45.025507Z"
    },
    "papermill": {
     "duration": 4.567509,
     "end_time": "2020-10-01T03:14:45.025680",
     "exception": false,
     "start_time": "2020-10-01T03:14:40.458171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIR = \"/kaggle/input/lish-moa/\"\n",
    "train_feat = pd.read_csv(DIR+\"train_features.csv\")\n",
    "test_feat = pd.read_csv(DIR+\"test_features.csv\")\n",
    "#train_nonscore = pd.read_csv(DIR+\"train_targets_nonscored.csv\")\n",
    "train_score = pd.read_csv(DIR+\"train_targets_scored.csv\")\n",
    "sub = pd.read_csv(DIR+\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T03:14:45.056900Z",
     "iopub.status.busy": "2020-10-01T03:14:45.055952Z",
     "iopub.status.idle": "2020-10-01T03:14:45.101110Z",
     "shell.execute_reply": "2020-10-01T03:14:45.100526Z"
    },
    "papermill": {
     "duration": 0.065623,
     "end_time": "2020-10-01T03:14:45.101280",
     "exception": false,
     "start_time": "2020-10-01T03:14:45.035657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# features after rfecv\n",
    "df = pd.read_csv(\"/kaggle/input/moagcvariables/feats.csv\", header=None, sep='\\n')\n",
    "df = df[0].str.split(',', expand=True)\n",
    "df[0] = df[0].astype(int)\n",
    "df = df.sort_values(0, ascending=True).reset_index(drop=True)\n",
    "decreased_vars = df[0].values\n",
    "df = df.set_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T03:14:45.129536Z",
     "iopub.status.busy": "2020-10-01T03:14:45.128485Z",
     "iopub.status.idle": "2020-10-01T03:14:45.132249Z",
     "shell.execute_reply": "2020-10-01T03:14:45.131747Z"
    },
    "papermill": {
     "duration": 0.020731,
     "end_time": "2020-10-01T03:14:45.132384",
     "exception": false,
     "start_time": "2020-10-01T03:14:45.111653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_feats = [ i for i in train_score.columns if i != \"sig_id\"]\n",
    "g_feats = [i for i in train_feat.columns if \"g-\" in i]\n",
    "c_feats = [i for i in train_feat.columns if \"c-\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T03:14:45.160051Z",
     "iopub.status.busy": "2020-10-01T03:14:45.159378Z",
     "iopub.status.idle": "2020-10-01T03:14:45.271692Z",
     "shell.execute_reply": "2020-10-01T03:14:45.271116Z"
    },
    "papermill": {
     "duration": 0.129357,
     "end_time": "2020-10-01T03:14:45.271799",
     "exception": false,
     "start_time": "2020-10-01T03:14:45.142442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "noncons_train_index = train_feat[train_feat.cp_type==\"ctl_vehicle\"].index\n",
    "cons_train_index = train_feat[train_feat.cp_type!=\"ctl_vehicle\"].index\n",
    "noncons_test_index = test_feat[test_feat.cp_type==\"ctl_vehicle\"].index\n",
    "cons_test_index = test_feat[test_feat.cp_type!=\"ctl_vehicle\"].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012551,
     "end_time": "2020-10-01T03:14:45.294345",
     "exception": false,
     "start_time": "2020-10-01T03:14:45.281794",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T03:14:45.324047Z",
     "iopub.status.busy": "2020-10-01T03:14:45.323375Z",
     "iopub.status.idle": "2020-10-01T03:14:53.289479Z",
     "shell.execute_reply": "2020-10-01T03:14:53.288765Z"
    },
    "papermill": {
     "duration": 7.985098,
     "end_time": "2020-10-01T03:14:53.289615",
     "exception": false,
     "start_time": "2020-10-01T03:14:45.304517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# normalization by ctl group\n",
    "train_ctl = train_feat[train_feat.index.isin(noncons_train_index)].copy().reset_index(drop=True)\n",
    "test_ctl = test_feat[test_feat.index.isin(noncons_test_index)].copy().reset_index(drop=True)\n",
    "ctl_df = pd.concat([train_ctl, test_ctl])\n",
    "\n",
    "ctl_group_data = ctl_df.groupby([\"cp_dose\", \"cp_time\"]).agg({\"mean\"}).reset_index()\n",
    "mean_g_feats = [\"mean-\" + i for i in g_feats]\n",
    "mean_c_feats = [\"mean-\" + i for i in c_feats]\n",
    "columns = [\"cp_dose\", \"cp_time\"] + mean_g_feats + mean_c_feats\n",
    "ctl_group_data.columns = columns\n",
    "\n",
    "train_cons = train_feat[train_feat.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "test_cons = test_feat[test_feat.index.isin(cons_test_index)].copy().reset_index(drop=True)\n",
    "n_train_score = train_score[train_score.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "#n_train_nonscore = train_nonscore[train_nonscore.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "\n",
    "train_cons = pd.merge(train_cons, ctl_group_data, on=[\"cp_time\", \"cp_dose\"], how=\"left\")\n",
    "test_cons = pd.merge(test_cons, ctl_group_data, on=[\"cp_time\", \"cp_dose\"], how=\"left\")\n",
    "\n",
    "for i in range(len(g_feats)):\n",
    "    train_cons[\"diff-g-\"+str(i)] = train_cons[\"g-\"+str(i)] - train_cons[\"mean-g-\"+str(i)]\n",
    "    test_cons[\"diff-g-\"+str(i)] = test_cons[\"g-\"+str(i)] - test_cons[\"mean-g-\"+str(i)]\n",
    "    \n",
    "for i in range(len(c_feats)):\n",
    "    train_cons[\"diff-c-\"+str(i)] = train_cons[\"c-\"+str(i)] - train_cons[\"mean-c-\"+str(i)]\n",
    "    test_cons[\"diff-c-\"+str(i)] = test_cons[\"c-\"+str(i)] - test_cons[\"mean-c-\"+str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T03:14:53.321010Z",
     "iopub.status.busy": "2020-10-01T03:14:53.320381Z",
     "iopub.status.idle": "2020-10-01T03:14:53.348555Z",
     "shell.execute_reply": "2020-10-01T03:14:53.347846Z"
    },
    "papermill": {
     "duration": 0.048563,
     "end_time": "2020-10-01T03:14:53.348683",
     "exception": false,
     "start_time": "2020-10-01T03:14:53.300120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "categoricals = [\"cp_dose\"]\n",
    "\n",
    "def encoding(tr, te):\n",
    "    for f in categoricals:\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(tr[f]))\n",
    "        tr[f] = lbl.transform(list(tr[f]))\n",
    "        te[f] = lbl.transform(list(te[f])) \n",
    "        \n",
    "    return tr, te\n",
    "\n",
    "n_train_feat, n_test_feat = encoding(train_cons, test_cons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009881,
     "end_time": "2020-10-01T03:14:53.369061",
     "exception": false,
     "start_time": "2020-10-01T03:14:53.359180",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T03:14:53.402679Z",
     "iopub.status.busy": "2020-10-01T03:14:53.397138Z",
     "iopub.status.idle": "2020-10-01T03:14:54.275932Z",
     "shell.execute_reply": "2020-10-01T03:14:54.276476Z"
    },
    "papermill": {
     "duration": 0.897456,
     "end_time": "2020-10-01T03:14:54.276664",
     "exception": false,
     "start_time": "2020-10-01T03:14:53.379208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 875) (3624, 875)\n"
     ]
    }
   ],
   "source": [
    "def fe(df, remove_features):\n",
    "    df.drop(remove_features, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "remove_features = [\"cp_type\"] + mean_g_feats + mean_c_feats + g_feats + c_feats \n",
    "for i in [i for i in n_train_feat.columns if i != \"sig_id\"]:\n",
    "    if i not in remove_features and (n_train_feat[i].std() == 0):\n",
    "        remove_features.append(i)\n",
    "        \n",
    "n_train_feat = fe(n_train_feat, remove_features)\n",
    "n_test_feat = fe(n_test_feat, remove_features)\n",
    "    \n",
    "print(n_train_feat.shape, n_test_feat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010942,
     "end_time": "2020-10-01T03:14:54.299693",
     "exception": false,
     "start_time": "2020-10-01T03:14:54.288751",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T03:14:54.339033Z",
     "iopub.status.busy": "2020-10-01T03:14:54.338149Z",
     "iopub.status.idle": "2020-10-01T03:14:54.405999Z",
     "shell.execute_reply": "2020-10-01T03:14:54.405452Z"
    },
    "papermill": {
     "duration": 0.093755,
     "end_time": "2020-10-01T03:14:54.406128",
     "exception": false,
     "start_time": "2020-10-01T03:14:54.312373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "params = {'objective': 'binary', 'boosting_type': 'gbdt', 'tree_learner': 'serial', \n",
    "          'learning_rate': 0.01, \"num_leaves\": 10, 'random_seed':44, 'max_depth': 5}\n",
    "\n",
    "lgbm_params = {'objective': 'binary', 'boosting_type': 'gbdt', 'tree_learner': 'serial', 'learning_rate': 0.01, \n",
    "               \"num_leaves\": 10, 'random_seed':44, 'max_depth': 5}\n",
    "\n",
    "#diff_feats = [\"acetylcholine_receptor_agonist\",\"acetylcholine_receptor_antagonist\",\"adrenergic_receptor_agonist\",\"adrenergic_receptor_antagonist\",\n",
    "# \"bacterial_cell_wall_synthesis_inhibitor\",\"calcium_channel_blocker\",\"cyclooxygenase_inhibitor\",\"dna_inhibitor\",\"dopamine_receptor_antagonist\",\n",
    "# \"estrogen_receptor_agonist\",\"glutamate_receptor_antagonist\",\"histamine_receptor_antagonist\",\"phosphodiesterase_inhibitor\",\n",
    "# \"serotonin_receptor_agonist\",\"serotonin_receptor_antagonist\",\"sodium_channel_inhibitor\",\"tubulin_inhibitor\"]\n",
    "\n",
    "diff_var = [\"histamine_receptor_antagonist\",\"phosphodiesterase_inhibitor\",\n",
    " \"serotonin_receptor_agonist\",\"serotonin_receptor_antagonist\",\"sodium_channel_inhibitor\",\"tubulin_inhibitor\"]\n",
    "\n",
    "def check(new_train, target_train, target, selected_features):\n",
    "    \n",
    "    X_train = new_train.drop(['sig_id'],axis=1).copy()\n",
    "    y_train = target_train[target].copy()        \n",
    "        \n",
    "    remove_features = []\n",
    "    for i in X_train.columns: \n",
    "        if i not in selected_features:\n",
    "            remove_features.append(i)\n",
    "    X_train.drop(remove_features, axis=1, inplace=True)\n",
    "        \n",
    "    n_folds=4\n",
    "    if target not in [\"erbb2_inhibitor\", \"atp-sensitive_potassium_channel_antagonist\"]:\n",
    "        skf=StratifiedKFold(n_splits = n_folds, shuffle=True, random_state=0)\n",
    "    else:\n",
    "        skf=KFold(n_splits = n_folds, shuffle=True, random_state=0)\n",
    "\n",
    "    valid = np.zeros([X_train.shape[0]])\n",
    "    for i , (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        print(\"Fold \"+str(i+1))\n",
    "        X_train2 = X_train.iloc[train_index,:]\n",
    "        y_train2 = y_train.iloc[train_index]\n",
    "\n",
    "        X_valid2 = X_train.iloc[test_index,:]\n",
    "        y_valid2 = y_train.iloc[test_index]\n",
    "        \n",
    "        lgb_train = lgb.Dataset(X_train2, y_train2)\n",
    "        lgb_eval = lgb.Dataset(X_valid2, y_valid2, reference=lgb_train)\n",
    "        \n",
    "        clf = lgb.train(lgbm_params, lgb_train,valid_sets=[lgb_train, lgb_eval], \n",
    "               num_boost_round=10000,early_stopping_rounds=50,verbose_eval = 1000) \n",
    "\n",
    "        valid_predict = clf.predict(X_valid2, num_iteration = clf.best_iteration)\n",
    "        valid[test_index] = valid_predict\n",
    "    \n",
    "    score = log_loss(y_train, valid)\n",
    "    \n",
    "    return score\n",
    "\n",
    "#for target in diff_var:\n",
    "#    feature_selector = RFECV(lgb.LGBMClassifier(**params),\n",
    "#                         step=10, min_features_to_select=200, scoring='neg_log_loss',\n",
    "#                         cv=4, verbose=1, n_jobs=-1)\n",
    "\n",
    "    #X_train = n_train_feat.drop(['sig_id'],axis=1).copy()\n",
    "    #y_train = n_train_score[target].copy()\n",
    "\n",
    "    #feature_selector.fit(X_train, y_train)\n",
    "    #print('Features selected:', feature_selector.n_features_)\n",
    "    #selected_features = [f for f in X_train.columns[feature_selector.ranking_ == 1]]\n",
    "\n",
    "    #print(target, selected_features)\n",
    "\n",
    "#    score = check(n_train_feat, n_train_score, target, selected_features)\n",
    "#    print(target, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011739,
     "end_time": "2020-10-01T03:14:54.429290",
     "exception": false,
     "start_time": "2020-10-01T03:14:54.417551",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T03:14:54.463462Z",
     "iopub.status.busy": "2020-10-01T03:14:54.462581Z",
     "iopub.status.idle": "2020-10-01T03:14:54.466460Z",
     "shell.execute_reply": "2020-10-01T03:14:54.465859Z"
    },
    "papermill": {
     "duration": 0.026463,
     "end_time": "2020-10-01T03:14:54.466574",
     "exception": false,
     "start_time": "2020-10-01T03:14:54.440111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import optuna.integration.lightgbm as lgb\n",
    "#import json\n",
    "\n",
    "def modelling_optuna(new_train, target_train, target):\n",
    "    X_train = new_train.drop(['sig_id'],axis=1).copy()\n",
    "    y_train = target_train[target].copy()\n",
    "    \n",
    "    n_folds=4\n",
    "    skf=StratifiedKFold(n_splits = n_folds, shuffle=True, random_state=0)\n",
    "\n",
    "    valid = np.zeros([X_train.shape[0]])\n",
    "    best_params_list = []\n",
    "    for i , (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        print(\"Fold \"+str(i+1))\n",
    "        X_train2 = X_train.iloc[train_index,:]\n",
    "        y_train2 = y_train.iloc[train_index]\n",
    "        \n",
    "        X_valid2 = X_train.iloc[test_index,:]\n",
    "        y_valid2 = y_train.iloc[test_index]\n",
    "        \n",
    "        lgb_train = lgb.Dataset(X_train2, y_train2)\n",
    "        lgb_eval = lgb.Dataset(X_valid2, y_valid2, reference=lgb_train)\n",
    "\n",
    "        best_params, tuning_history = dict(), list()\n",
    "        lgbm_params = {'objective': 'binary', 'boosting_type': 'gbdt', 'tree_learner': 'serial'}\n",
    "        \n",
    "        clf = lgb.train(lgbm_params, lgb_train,valid_sets=[lgb_train, lgb_eval],\n",
    "           num_boost_round=10000,early_stopping_rounds=100,verbose_eval = 1000, \n",
    "                    best_params=best_params, tuning_history=tuning_history) \n",
    "        \n",
    "        valid_predict = clf.predict(X_valid2, num_iteration = clf.best_iteration)\n",
    "        valid[test_index] = valid_predict\n",
    "            \n",
    "        #pd.DataFrame(tuning_history).to_csv('./tuning_history.csv')\n",
    "        best_params_list.append(best_params)\n",
    "        \n",
    "    #for j in range(n_folds):\n",
    "    #    print('Fold: ' + str(j+1) + ' Best parameters: ' + json.dumps(best_params_list[j], indent=4))\n",
    "\n",
    "    #print('Best parameters: ' + json.dumps(best_params, indent=4))\n",
    "\n",
    "    score = log_loss(y_train, valid)\n",
    "    print(\"score = {}\".format(score))\n",
    "    return best_params_list\n",
    "\n",
    "#best_params_list = modelling_optuna(new_train,n_train_score, target)\n",
    "#best_params_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011662,
     "end_time": "2020-10-01T03:14:54.489421",
     "exception": false,
     "start_time": "2020-10-01T03:14:54.477759",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T03:14:54.531836Z",
     "iopub.status.busy": "2020-10-01T03:14:54.529829Z",
     "iopub.status.idle": "2020-10-01T04:23:48.427641Z",
     "shell.execute_reply": "2020-10-01T04:23:48.428546Z"
    },
    "papermill": {
     "duration": 4133.928087,
     "end_time": "2020-10-01T04:23:48.428736",
     "exception": false,
     "start_time": "2020-10-01T03:14:54.500649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5-alpha_reductase_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00595763\tvalid_1's binary_logloss: 0.0058469\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's binary_logloss: 0.00127755\tvalid_1's binary_logloss: 0.00596482\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's binary_logloss: 0.00100471\tvalid_1's binary_logloss: 0.00537319\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[109]\ttraining's binary_logloss: 0.000664927\tvalid_1's binary_logloss: 0.0071177\n",
      "oof log_loss= 0.006075651377849975 \n",
      "all log_loss= 0.005599579929497485 \n",
      "1 11-beta-hsd1_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's binary_logloss: 0.00196787\tvalid_1's binary_logloss: 0.00600179\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's binary_logloss: 0.00146041\tvalid_1's binary_logloss: 0.00586683\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00579401\tvalid_1's binary_logloss: 0.00731033\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00592575\tvalid_1's binary_logloss: 0.00730861\n",
      "oof log_loss= 0.006621889513430006 \n",
      "all log_loss= 0.006103016336640785 \n",
      "2 acat_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00785434\tvalid_1's binary_logloss: 0.00841639\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's binary_logloss: 0.00298169\tvalid_1's binary_logloss: 0.00839555\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's binary_logloss: 0.00345311\tvalid_1's binary_logloss: 0.00838947\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's binary_logloss: 0.00563184\tvalid_1's binary_logloss: 0.00855351\n",
      "oof log_loss= 0.008438730061039538 \n",
      "all log_loss= 0.007777494221033746 \n",
      "3 acetylcholine_receptor_agonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[430]\ttraining's binary_logloss: 0.0175784\tvalid_1's binary_logloss: 0.0467099\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[379]\ttraining's binary_logloss: 0.0198256\tvalid_1's binary_logloss: 0.0470534\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[299]\ttraining's binary_logloss: 0.0227917\tvalid_1's binary_logloss: 0.0473668\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[370]\ttraining's binary_logloss: 0.0187824\tvalid_1's binary_logloss: 0.0473868\n",
      "oof log_loss= 0.047129216721057715 \n",
      "all log_loss= 0.043436300016535506 \n",
      "4 acetylcholine_receptor_antagonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[385]\ttraining's binary_logloss: 0.0409194\tvalid_1's binary_logloss: 0.0683687\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[322]\ttraining's binary_logloss: 0.0431097\tvalid_1's binary_logloss: 0.0688396\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[240]\ttraining's binary_logloss: 0.0470522\tvalid_1's binary_logloss: 0.0697356\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[433]\ttraining's binary_logloss: 0.0380082\tvalid_1's binary_logloss: 0.0693926\n",
      "oof log_loss= 0.06908413363544817 \n",
      "all log_loss= 0.06367088960404882 \n",
      "5 acetylcholinesterase_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[152]\ttraining's binary_logloss: 0.00668282\tvalid_1's binary_logloss: 0.0213674\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[118]\ttraining's binary_logloss: 0.00822097\tvalid_1's binary_logloss: 0.0217435\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0217382\tvalid_1's binary_logloss: 0.0220572\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's binary_logloss: 0.0106459\tvalid_1's binary_logloss: 0.0224361\n",
      "oof log_loss= 0.02190104237992398 \n",
      "all log_loss= 0.02018493651442737 \n",
      "6 adenosine_receptor_agonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's binary_logloss: 0.00544335\tvalid_1's binary_logloss: 0.0165341\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.017029\tvalid_1's binary_logloss: 0.0166949\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's binary_logloss: 0.014942\tvalid_1's binary_logloss: 0.0177765\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0166086\tvalid_1's binary_logloss: 0.0177272\n",
      "oof log_loss= 0.017183173005502768 \n",
      "all log_loss= 0.015836746498898824 \n",
      "7 adenosine_receptor_antagonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[154]\ttraining's binary_logloss: 0.00999784\tvalid_1's binary_logloss: 0.0277957\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[147]\ttraining's binary_logloss: 0.0107364\tvalid_1's binary_logloss: 0.0279106\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[177]\ttraining's binary_logloss: 0.00923144\tvalid_1's binary_logloss: 0.0273635\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's binary_logloss: 0.0275178\tvalid_1's binary_logloss: 0.0280307\n",
      "oof log_loss= 0.027775128783140857 \n",
      "all log_loss= 0.02559874555019642 \n",
      "8 adenylyl_cyclase_activator\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[184]\ttraining's binary_logloss: 0.000192136\tvalid_1's binary_logloss: 0.00358951\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[201]\ttraining's binary_logloss: 0.000161198\tvalid_1's binary_logloss: 0.00344273\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.000987293\tvalid_1's binary_logloss: 0.00368096\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's binary_logloss: 0.00262172\tvalid_1's binary_logloss: 0.00463288\n",
      "oof log_loss= 0.0038365206998609135 \n",
      "all log_loss= 0.0035359014159968595 \n",
      "9 adrenergic_receptor_agonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[566]\ttraining's binary_logloss: 0.0236097\tvalid_1's binary_logloss: 0.0593756\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[761]\ttraining's binary_logloss: 0.0188685\tvalid_1's binary_logloss: 0.0558683\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[454]\ttraining's binary_logloss: 0.0262666\tvalid_1's binary_logloss: 0.0613261\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[556]\ttraining's binary_logloss: 0.0231767\tvalid_1's binary_logloss: 0.0608373\n",
      "oof log_loss= 0.059351819904901626 \n",
      "all log_loss= 0.05470117339685827 \n",
      "10 adrenergic_receptor_antagonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[362]\ttraining's binary_logloss: 0.0520467\tvalid_1's binary_logloss: 0.0803411\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[679]\ttraining's binary_logloss: 0.0370601\tvalid_1's binary_logloss: 0.0769589\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[582]\ttraining's binary_logloss: 0.0399868\tvalid_1's binary_logloss: 0.079046\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[650]\ttraining's binary_logloss: 0.0371603\tvalid_1's binary_logloss: 0.0778694\n",
      "oof log_loss= 0.07855386537590799 \n",
      "all log_loss= 0.07239859902874068 \n",
      "11 akt_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[151]\ttraining's binary_logloss: 0.0037648\tvalid_1's binary_logloss: 0.0159362\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[171]\ttraining's binary_logloss: 0.00312318\tvalid_1's binary_logloss: 0.0158368\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[138]\ttraining's binary_logloss: 0.00375652\tvalid_1's binary_logloss: 0.0152442\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[213]\ttraining's binary_logloss: 0.0024659\tvalid_1's binary_logloss: 0.0151378\n",
      "oof log_loss= 0.01553874176112739 \n",
      "all log_loss= 0.014321168395617109 \n",
      "12 aldehyde_dehydrogenase_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[694]\ttraining's binary_logloss: 8.22283e-07\tvalid_1's binary_logloss: 0.000580563\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\ttraining's binary_logloss: 0.000295794\tvalid_1's binary_logloss: 0.00284387\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00178716\tvalid_1's binary_logloss: 0.00267471\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's binary_logloss: 0.00102552\tvalid_1's binary_logloss: 0.00325973\n",
      "oof log_loss= 0.002339718824972451 \n",
      "all log_loss= 0.0021563848480094577 \n",
      "13 alk_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[156]\ttraining's binary_logloss: 0.00174191\tvalid_1's binary_logloss: 0.0111658\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's binary_logloss: 0.00333669\tvalid_1's binary_logloss: 0.0120907\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\ttraining's binary_logloss: 0.00273515\tvalid_1's binary_logloss: 0.0130802\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[126]\ttraining's binary_logloss: 0.00217816\tvalid_1's binary_logloss: 0.0110391\n",
      "oof log_loss= 0.011843943897428693 \n",
      "all log_loss= 0.010915884801409542 \n",
      "14 ampk_activator\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00408864\tvalid_1's binary_logloss: 0.0046647\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00393389\tvalid_1's binary_logloss: 0.00466793\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's binary_logloss: 0.0020377\tvalid_1's binary_logloss: 0.0045437\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's binary_logloss: 0.00244672\tvalid_1's binary_logloss: 0.00446902\n",
      "oof log_loss= 0.0045863347347203706 \n",
      "all log_loss= 0.004226962070951732 \n",
      "15 analgesic\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[124]\ttraining's binary_logloss: 0.000431382\tvalid_1's binary_logloss: 0.00442948\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's binary_logloss: 0.000925483\tvalid_1's binary_logloss: 0.00430936\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00374931\tvalid_1's binary_logloss: 0.00466605\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00346122\tvalid_1's binary_logloss: 0.00468084\n",
      "oof log_loss= 0.004521432582869225 \n",
      "all log_loss= 0.004167145474461057 \n",
      "16 androgen_receptor_agonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.015115\tvalid_1's binary_logloss: 0.0155928\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0150653\tvalid_1's binary_logloss: 0.0155958\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's binary_logloss: 0.00626318\tvalid_1's binary_logloss: 0.0152649\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's binary_logloss: 0.00581586\tvalid_1's binary_logloss: 0.0152102\n",
      "oof log_loss= 0.01541592772157174 \n",
      "all log_loss= 0.014207977728775441 \n",
      "17 androgen_receptor_antagonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0258547\tvalid_1's binary_logloss: 0.0261542\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0262122\tvalid_1's binary_logloss: 0.0261377\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[103]\ttraining's binary_logloss: 0.0120964\tvalid_1's binary_logloss: 0.0259203\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's binary_logloss: 0.0206815\tvalid_1's binary_logloss: 0.0270445\n",
      "oof log_loss= 0.02631416710216259 \n",
      "all log_loss= 0.02425226083640994 \n",
      "18 anesthetic_-_local\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\ttraining's binary_logloss: 0.00769592\tvalid_1's binary_logloss: 0.0237586\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's binary_logloss: 0.020555\tvalid_1's binary_logloss: 0.0240478\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0239011\tvalid_1's binary_logloss: 0.0241107\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's binary_logloss: 0.011571\tvalid_1's binary_logloss: 0.0237295\n",
      "oof log_loss= 0.02391165557810419 \n",
      "all log_loss= 0.022038003553717676 \n",
      "19 angiogenesis_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0117353\tvalid_1's binary_logloss: 0.012166\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\ttraining's binary_logloss: 0.00293522\tvalid_1's binary_logloss: 0.0119656\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's binary_logloss: 0.00545751\tvalid_1's binary_logloss: 0.0120779\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.011563\tvalid_1's binary_logloss: 0.0121782\n",
      "oof log_loss= 0.01209690484093904 \n",
      "all log_loss= 0.011149024416264882 \n",
      "20 angiotensin_receptor_antagonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.00710617\tvalid_1's binary_logloss: 0.0121383\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's binary_logloss: 0.0116\tvalid_1's binary_logloss: 0.0121557\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's binary_logloss: 0.00778576\tvalid_1's binary_logloss: 0.0121396\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's binary_logloss: 0.00512336\tvalid_1's binary_logloss: 0.0132312\n",
      "oof log_loss= 0.012416202490667015 \n",
      "all log_loss= 0.011443302774215234 \n",
      "21 anti-inflammatory\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's binary_logloss: 0.0199369\tvalid_1's binary_logloss: 0.0216588\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[150]\ttraining's binary_logloss: 0.00612654\tvalid_1's binary_logloss: 0.0202875\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\ttraining's binary_logloss: 0.00858763\tvalid_1's binary_logloss: 0.0214984\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's binary_logloss: 0.0169468\tvalid_1's binary_logloss: 0.0228361\n",
      "oof log_loss= 0.021570186464001245 \n",
      "all log_loss= 0.01988000556445373 \n",
      "22 antiarrhythmic\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's binary_logloss: 0.000446271\tvalid_1's binary_logloss: 0.00176595\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's binary_logloss: 0.000441199\tvalid_1's binary_logloss: 0.00176738\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00177319\tvalid_1's binary_logloss: 0.00328606\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00177319\tvalid_1's binary_logloss: 0.00328906\n",
      "oof log_loss= 0.002527114723373622 \n",
      "all log_loss= 0.00232909691562132 \n",
      "23 antibiotic\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.00590368\tvalid_1's binary_logloss: 0.0127854\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's binary_logloss: 0.00467511\tvalid_1's binary_logloss: 0.0136537\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's binary_logloss: 0.0039181\tvalid_1's binary_logloss: 0.0124796\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0130617\tvalid_1's binary_logloss: 0.0144715\n",
      "oof log_loss= 0.013347530096960712 \n",
      "all log_loss= 0.012301654092890548 \n",
      "24 anticonvulsant\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00411633\tvalid_1's binary_logloss: 0.00466022\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00441829\tvalid_1's binary_logloss: 0.00466015\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00425448\tvalid_1's binary_logloss: 0.00466117\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00425417\tvalid_1's binary_logloss: 0.00466198\n",
      "oof log_loss= 0.0046608812497954165 \n",
      "all log_loss= 0.004295667324704446 \n",
      "25 antifungal\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00445097\tvalid_1's binary_logloss: 0.00467025\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00422191\tvalid_1's binary_logloss: 0.00467627\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[131]\ttraining's binary_logloss: 0.000436953\tvalid_1's binary_logloss: 0.00432061\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's binary_logloss: 0.00118259\tvalid_1's binary_logloss: 0.00583705\n",
      "oof log_loss= 0.00487604710199394 \n",
      "all log_loss= 0.004493973368378468 \n",
      "26 antihistamine\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00383561\tvalid_1's binary_logloss: 0.00466163\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00425505\tvalid_1's binary_logloss: 0.00466274\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00422725\tvalid_1's binary_logloss: 0.00466216\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00403575\tvalid_1's binary_logloss: 0.00466443\n",
      "oof log_loss= 0.004662741803360044 \n",
      "all log_loss= 0.004297382090373229 \n",
      "27 antimalarial\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's binary_logloss: 0.00187762\tvalid_1's binary_logloss: 0.0059464\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's binary_logloss: 0.00200495\tvalid_1's binary_logloss: 0.00593538\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's binary_logloss: 0.00276667\tvalid_1's binary_logloss: 0.00695894\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00592745\tvalid_1's binary_logloss: 0.00708373\n",
      "oof log_loss= 0.006481109869776041 \n",
      "all log_loss= 0.0059732678013708915 \n",
      "28 antioxidant\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[196]\ttraining's binary_logloss: 0.00525048\tvalid_1's binary_logloss: 0.0214961\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[131]\ttraining's binary_logloss: 0.00708483\tvalid_1's binary_logloss: 0.0217426\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[138]\ttraining's binary_logloss: 0.00677499\tvalid_1's binary_logloss: 0.0218849\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's binary_logloss: 0.0142339\tvalid_1's binary_logloss: 0.0230306\n",
      "oof log_loss= 0.022038535548357982 \n",
      "all log_loss= 0.020311656093699622 \n",
      "29 antiprotozoal\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's binary_logloss: 0.00442087\tvalid_1's binary_logloss: 0.0120913\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.011703\tvalid_1's binary_logloss: 0.0121738\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0116768\tvalid_1's binary_logloss: 0.0121736\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's binary_logloss: 0.00466409\tvalid_1's binary_logloss: 0.0118273\n",
      "oof log_loss= 0.012066512183019629 \n",
      "all log_loss= 0.011121013244012627 \n",
      "30 antiviral\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00813212\tvalid_1's binary_logloss: 0.00732086\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's binary_logloss: 0.00314791\tvalid_1's binary_logloss: 0.00845783\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00762095\tvalid_1's binary_logloss: 0.00856453\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00746112\tvalid_1's binary_logloss: 0.00856748\n",
      "oof log_loss= 0.00822767375969943 \n",
      "all log_loss= 0.00758297571503674 \n",
      "31 apoptosis_stimulant\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's binary_logloss: 0.0110755\tvalid_1's binary_logloss: 0.0152898\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\ttraining's binary_logloss: 0.00521465\tvalid_1's binary_logloss: 0.0149523\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0154344\tvalid_1's binary_logloss: 0.01559\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\ttraining's binary_logloss: 0.0052738\tvalid_1's binary_logloss: 0.0160633\n",
      "oof log_loss= 0.01547386592457018 \n",
      "all log_loss= 0.014261376052425806 \n",
      "32 aromatase_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttraining's binary_logloss: 0.00556246\tvalid_1's binary_logloss: 0.0142622\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0145519\tvalid_1's binary_logloss: 0.0155945\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0147372\tvalid_1's binary_logloss: 0.0155931\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0148842\tvalid_1's binary_logloss: 0.0155949\n",
      "oof log_loss= 0.0152611712553686 \n",
      "all log_loss= 0.0140653475565983 \n",
      "33 atm_kinase_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's binary_logloss: 0.000396233\tvalid_1's binary_logloss: 0.00178111\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's binary_logloss: 0.000429444\tvalid_1's binary_logloss: 0.00176762\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's binary_logloss: 0.000661623\tvalid_1's binary_logloss: 0.00326671\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00177319\tvalid_1's binary_logloss: 0.00328666\n",
      "oof log_loss= 0.0025255234636515043 \n",
      "all log_loss= 0.002327630342665032 \n",
      "34 atp-sensitive_potassium_channel_antagonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[837]\ttraining's binary_logloss: 1.20942e-07\tvalid_1's binary_logloss: 1.00714e-07\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[837]\ttraining's binary_logloss: 1.20924e-07\tvalid_1's binary_logloss: 2.27571e-07\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[837]\ttraining's binary_logloss: 1.21021e-07\tvalid_1's binary_logloss: 4.92322e-08\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0\tvalid_1's binary_logloss: 0.00629466\n",
      "oof log_loss= 0.0015737583301767136 \n",
      "all log_loss= 0.0014504429256202394 \n",
      "35 atp_synthase_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[229]\ttraining's binary_logloss: 0.000122651\tvalid_1's binary_logloss: 0.00340503\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\ttraining's binary_logloss: 0.000651497\tvalid_1's binary_logloss: 0.00432603\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\ttraining's binary_logloss: 0.000403627\tvalid_1's binary_logloss: 0.00124986\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[163]\ttraining's binary_logloss: 0.000246124\tvalid_1's binary_logloss: 0.00426712\n",
      "oof log_loss= 0.003312008045364948 \n",
      "all log_loss= 0.0030524881405757853 \n",
      "36 atpase_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[248]\ttraining's binary_logloss: 0.00536695\tvalid_1's binary_logloss: 0.021974\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\ttraining's binary_logloss: 0.00973974\tvalid_1's binary_logloss: 0.0226568\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[203]\ttraining's binary_logloss: 0.00666872\tvalid_1's binary_logloss: 0.022814\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[145]\ttraining's binary_logloss: 0.00808126\tvalid_1's binary_logloss: 0.025274\n",
      "oof log_loss= 0.0231797202242571 \n",
      "all log_loss= 0.02136342065516069 \n",
      "37 atr_kinase_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's binary_logloss: 0.000888763\tvalid_1's binary_logloss: 0.00504591\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.000772617\tvalid_1's binary_logloss: 0.00603013\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\ttraining's binary_logloss: 0.000725534\tvalid_1's binary_logloss: 0.0057061\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[166]\ttraining's binary_logloss: 0.000389645\tvalid_1's binary_logloss: 0.00598973\n",
      "oof log_loss= 0.005692966118467383 \n",
      "all log_loss= 0.005246880841862937 \n",
      "38 aurora_kinase_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[282]\ttraining's binary_logloss: 0.00216241\tvalid_1's binary_logloss: 0.0162277\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[305]\ttraining's binary_logloss: 0.00197578\tvalid_1's binary_logloss: 0.0159497\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[253]\ttraining's binary_logloss: 0.0026629\tvalid_1's binary_logloss: 0.0172865\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[352]\ttraining's binary_logloss: 0.00158594\tvalid_1's binary_logloss: 0.0150159\n",
      "oof log_loss= 0.01611997382638188 \n",
      "all log_loss= 0.014856856703679824 \n",
      "39 autotaxin_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's binary_logloss: 0.000432504\tvalid_1's binary_logloss: 0.00176759\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's binary_logloss: 0.000442997\tvalid_1's binary_logloss: 0.00176211\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00153664\tvalid_1's binary_logloss: 0.00330903\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00114961\tvalid_1's binary_logloss: 0.00334124\n",
      "oof log_loss= 0.00254499257764474 \n",
      "all log_loss= 0.0023455739100591514 \n",
      "40 bacterial_30s_ribosomal_subunit_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.00922294\tvalid_1's binary_logloss: 0.0188323\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\ttraining's binary_logloss: 0.00680654\tvalid_1's binary_logloss: 0.0185513\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's binary_logloss: 0.012171\tvalid_1's binary_logloss: 0.0188673\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's binary_logloss: 0.0118864\tvalid_1's binary_logloss: 0.0187868\n",
      "oof log_loss= 0.01875941501282092 \n",
      "all log_loss= 0.017289478487502955 \n",
      "41 bacterial_50s_ribosomal_subunit_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[150]\ttraining's binary_logloss: 0.00720129\tvalid_1's binary_logloss: 0.0238238\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's binary_logloss: 0.0227913\tvalid_1's binary_logloss: 0.0240568\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's binary_logloss: 0.0202456\tvalid_1's binary_logloss: 0.024069\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[150]\ttraining's binary_logloss: 0.00740105\tvalid_1's binary_logloss: 0.0235348\n",
      "oof log_loss= 0.023871111538981537 \n",
      "all log_loss= 0.022000636434768142 \n",
      "42 bacterial_antifolate\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.00411713\tvalid_1's binary_logloss: 0.0120065\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's binary_logloss: 0.00304232\tvalid_1's binary_logloss: 0.0118825\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0115095\tvalid_1's binary_logloss: 0.0121703\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\ttraining's binary_logloss: 0.00271046\tvalid_1's binary_logloss: 0.0120541\n",
      "oof log_loss= 0.012028365711722406 \n",
      "all log_loss= 0.011085855826021888 \n",
      "43 bacterial_cell_wall_synthesis_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[368]\ttraining's binary_logloss: 0.0192286\tvalid_1's binary_logloss: 0.0479024\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[352]\ttraining's binary_logloss: 0.0196638\tvalid_1's binary_logloss: 0.0479731\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[332]\ttraining's binary_logloss: 0.0205614\tvalid_1's binary_logloss: 0.0481333\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[336]\ttraining's binary_logloss: 0.0211286\tvalid_1's binary_logloss: 0.0489368\n",
      "oof log_loss= 0.048236398732991986 \n",
      "all log_loss= 0.04445672626991307 \n",
      "44 bacterial_dna_gyrase_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[114]\ttraining's binary_logloss: 0.0111121\tvalid_1's binary_logloss: 0.0257246\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[244]\ttraining's binary_logloss: 0.00623808\tvalid_1's binary_logloss: 0.0258422\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0261616\tvalid_1's binary_logloss: 0.0261372\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[130]\ttraining's binary_logloss: 0.00941794\tvalid_1's binary_logloss: 0.0269332\n",
      "oof log_loss= 0.026159273525793753 \n",
      "all log_loss= 0.024109504297645214 \n",
      "45 bacterial_dna_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[185]\ttraining's binary_logloss: 0.0122442\tvalid_1's binary_logloss: 0.0309584\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\ttraining's binary_logloss: 0.0173168\tvalid_1's binary_logloss: 0.032436\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[172]\ttraining's binary_logloss: 0.0126725\tvalid_1's binary_logloss: 0.0319969\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[197]\ttraining's binary_logloss: 0.0112392\tvalid_1's binary_logloss: 0.0320573\n",
      "oof log_loss= 0.03186216964879581 \n",
      "all log_loss= 0.029365537056007904 \n",
      "46 bacterial_membrane_integrity_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[287]\ttraining's binary_logloss: 5.29771e-05\tvalid_1's binary_logloss: 0.00179369\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's binary_logloss: 0.000586323\tvalid_1's binary_logloss: 0.00290963\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[179]\ttraining's binary_logloss: 0.000117183\tvalid_1's binary_logloss: 0.00275957\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's binary_logloss: 0.000448843\tvalid_1's binary_logloss: 0.00353831\n",
      "oof log_loss= 0.002750298919275171 \n",
      "all log_loss= 0.002534793007485231 \n",
      "47 bcl_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's binary_logloss: 0.0021063\tvalid_1's binary_logloss: 0.00892086\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's binary_logloss: 0.00325508\tvalid_1's binary_logloss: 0.00957732\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\ttraining's binary_logloss: 0.0017516\tvalid_1's binary_logloss: 0.00936988\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's binary_logloss: 0.00238809\tvalid_1's binary_logloss: 0.0105855\n",
      "oof log_loss= 0.009613397417363018 \n",
      "all log_loss= 0.0088601178515279 \n",
      "48 bcr-abl_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\ttraining's binary_logloss: 0.00255979\tvalid_1's binary_logloss: 0.0103298\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\ttraining's binary_logloss: 0.00174099\tvalid_1's binary_logloss: 0.0107328\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's binary_logloss: 0.00297827\tvalid_1's binary_logloss: 0.012676\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[114]\ttraining's binary_logloss: 0.00198217\tvalid_1's binary_logloss: 0.0115303\n",
      "oof log_loss= 0.011317211974376153 \n",
      "all log_loss= 0.010430426153254794 \n",
      "49 benzodiazepine_receptor_agonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[193]\ttraining's binary_logloss: 0.0047433\tvalid_1's binary_logloss: 0.0189815\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0203207\tvalid_1's binary_logloss: 0.021001\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's binary_logloss: 0.00926528\tvalid_1's binary_logloss: 0.0207314\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0202479\tvalid_1's binary_logloss: 0.0210008\n",
      "oof log_loss= 0.020428682855344698 \n",
      "all log_loss= 0.01882794706093505 \n",
      "50 beta_amyloid_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00781629\tvalid_1's binary_logloss: 0.00855741\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00791762\tvalid_1's binary_logloss: 0.00855945\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00787492\tvalid_1's binary_logloss: 0.00856345\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's binary_logloss: 0.00329041\tvalid_1's binary_logloss: 0.00854475\n",
      "oof log_loss= 0.00855626443559041 \n",
      "all log_loss= 0.007885818923000762 \n",
      "51 bromodomain_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[211]\ttraining's binary_logloss: 0.00242391\tvalid_1's binary_logloss: 0.0146155\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[189]\ttraining's binary_logloss: 0.00259381\tvalid_1's binary_logloss: 0.0147559\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[147]\ttraining's binary_logloss: 0.00355068\tvalid_1's binary_logloss: 0.0161262\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[188]\ttraining's binary_logloss: 0.00273495\tvalid_1's binary_logloss: 0.0143515\n",
      "oof log_loss= 0.014962281861711179 \n",
      "all log_loss= 0.013789878319511163 \n",
      "52 btk_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's binary_logloss: 0.00290044\tvalid_1's binary_logloss: 0.0097446\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\ttraining's binary_logloss: 0.00185642\tvalid_1's binary_logloss: 0.00940976\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's binary_logloss: 0.00636012\tvalid_1's binary_logloss: 0.00937249\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's binary_logloss: 0.00304311\tvalid_1's binary_logloss: 0.00987823\n",
      "oof log_loss= 0.009601270585463013 \n",
      "all log_loss= 0.008848941245055184 \n",
      "53 calcineurin_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's binary_logloss: 0.000394642\tvalid_1's binary_logloss: 0.00177693\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[109]\ttraining's binary_logloss: 0.000235398\tvalid_1's binary_logloss: 0.00174297\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00153664\tvalid_1's binary_logloss: 0.00329853\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00177319\tvalid_1's binary_logloss: 0.00328397\n",
      "oof log_loss= 0.002525599324971194 \n",
      "all log_loss= 0.002327700259698901 \n",
      "54 calcium_channel_blocker\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[328]\ttraining's binary_logloss: 0.0373691\tvalid_1's binary_logloss: 0.0656569\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[324]\ttraining's binary_logloss: 0.0383343\tvalid_1's binary_logloss: 0.0660614\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[384]\ttraining's binary_logloss: 0.03459\tvalid_1's binary_logloss: 0.0646656\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[859]\ttraining's binary_logloss: 0.0194353\tvalid_1's binary_logloss: 0.0639998\n",
      "oof log_loss= 0.0650958985112122 \n",
      "all log_loss= 0.05999516169161364 \n",
      "55 cannabinoid_receptor_agonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0134342\tvalid_1's binary_logloss: 0.0133325\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's binary_logloss: 0.00487694\tvalid_1's binary_logloss: 0.0132295\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0127567\tvalid_1's binary_logloss: 0.0144797\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's binary_logloss: 0.00783351\tvalid_1's binary_logloss: 0.0143734\n",
      "oof log_loss= 0.013853767709127093 \n",
      "all log_loss= 0.012768224308386802 \n",
      "56 cannabinoid_receptor_antagonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[189]\ttraining's binary_logloss: 0.00318228\tvalid_1's binary_logloss: 0.016065\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[121]\ttraining's binary_logloss: 0.00485507\tvalid_1's binary_logloss: 0.0170817\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[123]\ttraining's binary_logloss: 0.00476973\tvalid_1's binary_logloss: 0.0175292\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.017057\tvalid_1's binary_logloss: 0.0177926\n",
      "oof log_loss= 0.01711712862947583 \n",
      "all log_loss= 0.01577587717979917 \n",
      "57 carbonic_anhydrase_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0116519\tvalid_1's binary_logloss: 0.0121688\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's binary_logloss: 0.00835626\tvalid_1's binary_logloss: 0.0120992\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's binary_logloss: 0.00583767\tvalid_1's binary_logloss: 0.0121334\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0116341\tvalid_1's binary_logloss: 0.0121719\n",
      "oof log_loss= 0.012143330320734995 \n",
      "all log_loss= 0.011191812122259745 \n",
      "58 casein_kinase_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's binary_logloss: 0.00421561\tvalid_1's binary_logloss: 0.0118876\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[118]\ttraining's binary_logloss: 0.00206794\tvalid_1's binary_logloss: 0.0115089\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's binary_logloss: 0.00365122\tvalid_1's binary_logloss: 0.0116295\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's binary_logloss: 0.00600696\tvalid_1's binary_logloss: 0.0120604\n",
      "oof log_loss= 0.011771596738618526 \n",
      "all log_loss= 0.010849206568371598 \n",
      "59 caspase_activator\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\ttraining's binary_logloss: 0.0010051\tvalid_1's binary_logloss: 0.00575609\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00599171\tvalid_1's binary_logloss: 0.00601738\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00593299\tvalid_1's binary_logloss: 0.00730843\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00601339\tvalid_1's binary_logloss: 0.00730787\n",
      "oof log_loss= 0.006597442630079989 \n",
      "all log_loss= 0.006080485044301566 \n",
      "60 catechol_o_methyltransferase_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00441948\tvalid_1's binary_logloss: 0.00465851\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00425477\tvalid_1's binary_logloss: 0.00466039\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00414383\tvalid_1's binary_logloss: 0.00466514\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0042147\tvalid_1's binary_logloss: 0.0046602\n",
      "oof log_loss= 0.0046610588241826475 \n",
      "all log_loss= 0.004295830984847677 \n",
      "61 cc_chemokine_receptor_antagonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\ttraining's binary_logloss: 0.0115341\tvalid_1's binary_logloss: 0.0284702\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's binary_logloss: 0.019762\tvalid_1's binary_logloss: 0.0287461\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's binary_logloss: 0.0173142\tvalid_1's binary_logloss: 0.0298293\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's binary_logloss: 0.0246977\tvalid_1's binary_logloss: 0.0299582\n",
      "oof log_loss= 0.02925092550837234 \n",
      "all log_loss= 0.026958902874685393 \n",
      "62 cck_receptor_antagonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00639628\tvalid_1's binary_logloss: 0.00601071\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0063256\tvalid_1's binary_logloss: 0.00601211\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00592794\tvalid_1's binary_logloss: 0.00730596\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00615668\tvalid_1's binary_logloss: 0.00730564\n",
      "oof log_loss= 0.006658604400040379 \n",
      "all log_loss= 0.006136854345010837 \n",
      "63 cdk_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[642]\ttraining's binary_logloss: 0.00230916\tvalid_1's binary_logloss: 0.0196872\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[466]\ttraining's binary_logloss: 0.00411244\tvalid_1's binary_logloss: 0.0205034\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[442]\ttraining's binary_logloss: 0.00438401\tvalid_1's binary_logloss: 0.0241338\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[481]\ttraining's binary_logloss: 0.00377382\tvalid_1's binary_logloss: 0.0221876\n",
      "oof log_loss= 0.0216279811906428 \n",
      "all log_loss= 0.019933271654162678 \n",
      "64 chelating_agent\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's binary_logloss: 0.0162727\tvalid_1's binary_logloss: 0.0166956\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's binary_logloss: 0.00824409\tvalid_1's binary_logloss: 0.0166293\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0165921\tvalid_1's binary_logloss: 0.017799\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's binary_logloss: 0.0155422\tvalid_1's binary_logloss: 0.0177422\n",
      "oof log_loss= 0.01721651050747514 \n",
      "all log_loss= 0.01586747176526691 \n",
      "65 chk_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[121]\ttraining's binary_logloss: 0.000757985\tvalid_1's binary_logloss: 0.00668478\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[412]\ttraining's binary_logloss: 4.44949e-05\tvalid_1's binary_logloss: 0.00439179\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\ttraining's binary_logloss: 0.00122057\tvalid_1's binary_logloss: 0.00490518\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[124]\ttraining's binary_logloss: 0.000732036\tvalid_1's binary_logloss: 0.00560157\n",
      "oof log_loss= 0.005395829725807306 \n",
      "all log_loss= 0.00497302724540273 \n",
      "66 chloride_channel_blocker\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's binary_logloss: 0.00662858\tvalid_1's binary_logloss: 0.0130708\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's binary_logloss: 0.00621485\tvalid_1's binary_logloss: 0.0132696\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's binary_logloss: 0.00509874\tvalid_1's binary_logloss: 0.0143105\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[97]\ttraining's binary_logloss: 0.00337747\tvalid_1's binary_logloss: 0.014334\n",
      "oof log_loss= 0.01374621324743552 \n",
      "all log_loss= 0.012669097520564235 \n",
      "67 cholesterol_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0152307\tvalid_1's binary_logloss: 0.0155915\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's binary_logloss: 0.0133381\tvalid_1's binary_logloss: 0.0155192\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's binary_logloss: 0.014499\tvalid_1's binary_logloss: 0.0155703\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's binary_logloss: 0.00603076\tvalid_1's binary_logloss: 0.0153987\n",
      "oof log_loss= 0.01551992740234313 \n",
      "all log_loss= 0.014303828278602035 \n",
      "68 cholinergic_receptor_antagonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0168934\tvalid_1's binary_logloss: 0.0167039\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's binary_logloss: 0.0073004\tvalid_1's binary_logloss: 0.0166333\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's binary_logloss: 0.0111236\tvalid_1's binary_logloss: 0.017471\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0166545\tvalid_1's binary_logloss: 0.0177995\n",
      "oof log_loss= 0.017151933901436437 \n",
      "all log_loss= 0.015807955205707935 \n",
      "69 coagulation_factor_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's binary_logloss: 0.000438185\tvalid_1's binary_logloss: 0.00176568\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's binary_logloss: 0.000426656\tvalid_1's binary_logloss: 0.00176961\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00177319\tvalid_1's binary_logloss: 0.00328846\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00177319\tvalid_1's binary_logloss: 0.00328786\n",
      "oof log_loss= 0.002527900709755789 \n",
      "all log_loss= 0.0023298213142572397 \n",
      "70 corticosteroid_agonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttraining's binary_logloss: 0.00217434\tvalid_1's binary_logloss: 0.0107434\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's binary_logloss: 0.0023901\tvalid_1's binary_logloss: 0.0102924\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\ttraining's binary_logloss: 0.00162489\tvalid_1's binary_logloss: 0.0101736\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[220]\ttraining's binary_logloss: 0.000785046\tvalid_1's binary_logloss: 0.00734442\n",
      "oof log_loss= 0.009638447447878448 \n",
      "all log_loss= 0.008883205030067945 \n",
      "71 cyclooxygenase_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[298]\ttraining's binary_logloss: 0.0666873\tvalid_1's binary_logloss: 0.0934659\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[662]\ttraining's binary_logloss: 0.0469908\tvalid_1's binary_logloss: 0.0928462\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[606]\ttraining's binary_logloss: 0.0502731\tvalid_1's binary_logloss: 0.0904202\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[474]\ttraining's binary_logloss: 0.0555517\tvalid_1's binary_logloss: 0.0932497\n",
      "oof log_loss= 0.09249550017498114 \n",
      "all log_loss= 0.08524780540188494 \n",
      "72 cytochrome_p450_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[194]\ttraining's binary_logloss: 0.00994989\tvalid_1's binary_logloss: 0.028806\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[236]\ttraining's binary_logloss: 0.00806405\tvalid_1's binary_logloss: 0.0297484\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's binary_logloss: 0.0248001\tvalid_1's binary_logloss: 0.0298952\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's binary_logloss: 0.0224261\tvalid_1's binary_logloss: 0.0297379\n",
      "oof log_loss= 0.029546870191977163 \n",
      "all log_loss= 0.02723165814115716 \n",
      "73 dihydrofolate_reductase_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\ttraining's binary_logloss: 0.00249625\tvalid_1's binary_logloss: 0.01136\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\ttraining's binary_logloss: 0.0014398\tvalid_1's binary_logloss: 0.00973925\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[151]\ttraining's binary_logloss: 0.00142592\tvalid_1's binary_logloss: 0.00949631\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[144]\ttraining's binary_logloss: 0.0014174\tvalid_1's binary_logloss: 0.0107262\n",
      "oof log_loss= 0.01033045774630508 \n",
      "all log_loss= 0.009520991291505241 \n",
      "74 dipeptidyl_peptidase_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[131]\ttraining's binary_logloss: 0.00120315\tvalid_1's binary_logloss: 0.00808366\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's binary_logloss: 0.00671957\tvalid_1's binary_logloss: 0.00836525\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's binary_logloss: 0.00769302\tvalid_1's binary_logloss: 0.00836463\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00809375\tvalid_1's binary_logloss: 0.00980014\n",
      "oof log_loss= 0.008653420077154035 \n",
      "all log_loss= 0.0079753617138397 \n",
      "75 diuretic\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's binary_logloss: 0.000443962\tvalid_1's binary_logloss: 0.00176667\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's binary_logloss: 0.000440716\tvalid_1's binary_logloss: 0.00176566\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00153664\tvalid_1's binary_logloss: 0.0033221\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00177319\tvalid_1's binary_logloss: 0.00291187\n",
      "oof log_loss= 0.0024415748059186133 \n",
      "all log_loss= 0.0022502596724743255 \n",
      "76 dna_alkylating_agent\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.014845\tvalid_1's binary_logloss: 0.0155923\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0150239\tvalid_1's binary_logloss: 0.0155909\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's binary_logloss: 0.00479417\tvalid_1's binary_logloss: 0.0149303\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's binary_logloss: 0.00746758\tvalid_1's binary_logloss: 0.0150132\n",
      "oof log_loss= 0.015281662996055769 \n",
      "all log_loss= 0.014084233620451579 \n",
      "77 dna_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[702]\ttraining's binary_logloss: 0.0388347\tvalid_1's binary_logloss: 0.079906\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[643]\ttraining's binary_logloss: 0.0388694\tvalid_1's binary_logloss: 0.0845209\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[454]\ttraining's binary_logloss: 0.0481906\tvalid_1's binary_logloss: 0.0859363\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[585]\ttraining's binary_logloss: 0.0415305\tvalid_1's binary_logloss: 0.0835514\n",
      "oof log_loss= 0.08347866225013115 \n",
      "all log_loss= 0.07693750227034014 \n",
      "78 dopamine_receptor_agonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[175]\ttraining's binary_logloss: 0.0145916\tvalid_1's binary_logloss: 0.0332009\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\ttraining's binary_logloss: 0.0185481\tvalid_1's binary_logloss: 0.0335133\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\ttraining's binary_logloss: 0.0215438\tvalid_1's binary_logloss: 0.0333981\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[130]\ttraining's binary_logloss: 0.0170339\tvalid_1's binary_logloss: 0.0342055\n",
      "oof log_loss= 0.033579453446077594 \n",
      "all log_loss= 0.03094825918512274 \n",
      "79 dopamine_receptor_antagonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[703]\ttraining's binary_logloss: 0.0430503\tvalid_1's binary_logloss: 0.0852414\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[707]\ttraining's binary_logloss: 0.0435113\tvalid_1's binary_logloss: 0.0839501\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[700]\ttraining's binary_logloss: 0.042273\tvalid_1's binary_logloss: 0.0868077\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[565]\ttraining's binary_logloss: 0.0479278\tvalid_1's binary_logloss: 0.0895347\n",
      "oof log_loss= 0.08638346241807988 \n",
      "all log_loss= 0.07961469023062144 \n",
      "80 egfr_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[843]\ttraining's binary_logloss: 0.00199426\tvalid_1's binary_logloss: 0.0266828\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[714]\ttraining's binary_logloss: 0.00283474\tvalid_1's binary_logloss: 0.0262285\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[637]\ttraining's binary_logloss: 0.00370445\tvalid_1's binary_logloss: 0.0272957\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[784]\ttraining's binary_logloss: 0.00231499\tvalid_1's binary_logloss: 0.0253595\n",
      "oof log_loss= 0.026391621492472424 \n",
      "all log_loss= 0.024323646112235937 \n",
      "81 elastase_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's binary_logloss: 0.000457948\tvalid_1's binary_logloss: 0.00176926\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's binary_logloss: 0.000428638\tvalid_1's binary_logloss: 0.00176758\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00149857\tvalid_1's binary_logloss: 0.0033125\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00177319\tvalid_1's binary_logloss: 0.00328786\n",
      "oof log_loss= 0.0025342977122328534 \n",
      "all log_loss= 0.0023357170650914814 \n",
      "82 erbb2_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[851]\ttraining's binary_logloss: 1.20976e-07\tvalid_1's binary_logloss: 1.23057e-06\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0\tvalid_1's binary_logloss: 0.00629466\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[847]\ttraining's binary_logloss: 1.2169e-07\tvalid_1's binary_logloss: 3.38464e-07\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[846]\ttraining's binary_logloss: 1.21542e-07\tvalid_1's binary_logloss: 1.66812e-06\n",
      "oof log_loss= 0.001574473239880036 \n",
      "all log_loss= 0.0014511018169517467 \n",
      "83 estrogen_receptor_agonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[412]\ttraining's binary_logloss: 0.0127045\tvalid_1's binary_logloss: 0.0399085\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[345]\ttraining's binary_logloss: 0.0149354\tvalid_1's binary_logloss: 0.040628\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[300]\ttraining's binary_logloss: 0.0165382\tvalid_1's binary_logloss: 0.0405046\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[396]\ttraining's binary_logloss: 0.0127264\tvalid_1's binary_logloss: 0.0400023\n",
      "oof log_loss= 0.040260848240594886 \n",
      "all log_loss= 0.037106118131543554 \n",
      "84 estrogen_receptor_antagonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's binary_logloss: 0.00702281\tvalid_1's binary_logloss: 0.015044\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's binary_logloss: 0.0108439\tvalid_1's binary_logloss: 0.015236\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's binary_logloss: 0.00495855\tvalid_1's binary_logloss: 0.0154768\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's binary_logloss: 0.00605612\tvalid_1's binary_logloss: 0.0148567\n",
      "oof log_loss= 0.015153355245797157 \n",
      "all log_loss= 0.013965979715073394 \n",
      "85 faah_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's binary_logloss: 0.00332696\tvalid_1's binary_logloss: 0.0118838\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's binary_logloss: 0.00363258\tvalid_1's binary_logloss: 0.0119668\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\ttraining's binary_logloss: 0.00179848\tvalid_1's binary_logloss: 0.0116886\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\ttraining's binary_logloss: 0.00197591\tvalid_1's binary_logloss: 0.0119777\n",
      "oof log_loss= 0.011879234767007436 \n",
      "all log_loss= 0.010948410374833337 \n",
      "86 farnesyltransferase_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's binary_logloss: 0.0024771\tvalid_1's binary_logloss: 0.00588566\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\ttraining's binary_logloss: 0.000771363\tvalid_1's binary_logloss: 0.00549339\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\ttraining's binary_logloss: 0.000352402\tvalid_1's binary_logloss: 0.00612811\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttraining's binary_logloss: 0.00101264\tvalid_1's binary_logloss: 0.00677842\n",
      "oof log_loss= 0.006071395601989694 \n",
      "all log_loss= 0.005595657624610384 \n",
      "87 fatty_acid_receptor_agonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's binary_logloss: 0.00365785\tvalid_1's binary_logloss: 0.00850964\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's binary_logloss: 0.00224431\tvalid_1's binary_logloss: 0.00840276\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00865813\tvalid_1's binary_logloss: 0.00855815\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00808728\tvalid_1's binary_logloss: 0.00980204\n",
      "oof log_loss= 0.008818147484082987 \n",
      "all log_loss= 0.008127181531059683 \n",
      "88 fgfr_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.00158804\tvalid_1's binary_logloss: 0.012314\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[161]\ttraining's binary_logloss: 0.00205258\tvalid_1's binary_logloss: 0.0120144\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[130]\ttraining's binary_logloss: 0.00238855\tvalid_1's binary_logloss: 0.0126892\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[162]\ttraining's binary_logloss: 0.00196631\tvalid_1's binary_logloss: 0.0115902\n",
      "oof log_loss= 0.012151935460671698 \n",
      "all log_loss= 0.011199742986933076 \n",
      "89 flt3_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[536]\ttraining's binary_logloss: 0.00508089\tvalid_1's binary_logloss: 0.0305911\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[506]\ttraining's binary_logloss: 0.00608332\tvalid_1's binary_logloss: 0.0269695\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[507]\ttraining's binary_logloss: 0.00571777\tvalid_1's binary_logloss: 0.0283458\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[414]\ttraining's binary_logloss: 0.00749383\tvalid_1's binary_logloss: 0.0315856\n",
      "oof log_loss= 0.02937300059890853 \n",
      "all log_loss= 0.027071412494534576 \n",
      "90 focal_adhesion_kinase_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's binary_logloss: 0.00154092\tvalid_1's binary_logloss: 0.00477465\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[240]\ttraining's binary_logloss: 0.000177882\tvalid_1's binary_logloss: 0.00261769\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.00124373\tvalid_1's binary_logloss: 0.00692442\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[110]\ttraining's binary_logloss: 0.000621903\tvalid_1's binary_logloss: 0.0050517\n",
      "oof log_loss= 0.004842116034857568 \n",
      "all log_loss= 0.004462701046991507 \n",
      "91 free_radical_scavenger\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00639781\tvalid_1's binary_logloss: 0.00600976\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00609213\tvalid_1's binary_logloss: 0.0060202\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00623463\tvalid_1's binary_logloss: 0.00730838\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00573743\tvalid_1's binary_logloss: 0.00731323\n",
      "oof log_loss= 0.006662892201924521 \n",
      "all log_loss= 0.006140806166450041 \n",
      "92 fungal_squalene_epoxidase_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00803852\tvalid_1's binary_logloss: 0.00732134\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's binary_logloss: 0.00481681\tvalid_1's binary_logloss: 0.00852454\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's binary_logloss: 0.00386274\tvalid_1's binary_logloss: 0.00856074\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's binary_logloss: 0.00312354\tvalid_1's binary_logloss: 0.00851164\n",
      "oof log_loss= 0.008229564834834745 \n",
      "all log_loss= 0.007584718610689293 \n",
      "93 gaba_receptor_agonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's binary_logloss: 0.0225053\tvalid_1's binary_logloss: 0.029877\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[125]\ttraining's binary_logloss: 0.0135085\tvalid_1's binary_logloss: 0.0295835\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[130]\ttraining's binary_logloss: 0.0129266\tvalid_1's binary_logloss: 0.0304367\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's binary_logloss: 0.0290824\tvalid_1's binary_logloss: 0.0309991\n",
      "oof log_loss= 0.030224072160482535 \n",
      "all log_loss= 0.027855796412961802 \n",
      "94 gaba_receptor_antagonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[244]\ttraining's binary_logloss: 0.0182678\tvalid_1's binary_logloss: 0.0424252\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[336]\ttraining's binary_logloss: 0.0137593\tvalid_1's binary_logloss: 0.0424164\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[212]\ttraining's binary_logloss: 0.0193628\tvalid_1's binary_logloss: 0.0431461\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[228]\ttraining's binary_logloss: 0.0194275\tvalid_1's binary_logloss: 0.0432752\n",
      "oof log_loss= 0.04281574239391953 \n",
      "all log_loss= 0.039460817756855116 \n",
      "95 gamma_secretase_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[211]\ttraining's binary_logloss: 0.00162048\tvalid_1's binary_logloss: 0.0113141\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[139]\ttraining's binary_logloss: 0.00273983\tvalid_1's binary_logloss: 0.0124349\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[143]\ttraining's binary_logloss: 0.00254639\tvalid_1's binary_logloss: 0.014196\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[125]\ttraining's binary_logloss: 0.00293147\tvalid_1's binary_logloss: 0.0139232\n",
      "oof log_loss= 0.01296703146690906 \n",
      "all log_loss= 0.01195097029628462 \n",
      "96 glucocorticoid_receptor_agonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[265]\ttraining's binary_logloss: 0.00517477\tvalid_1's binary_logloss: 0.018503\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[359]\ttraining's binary_logloss: 0.00371376\tvalid_1's binary_logloss: 0.0157061\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[570]\ttraining's binary_logloss: 0.00158691\tvalid_1's binary_logloss: 0.0133009\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[362]\ttraining's binary_logloss: 0.00366207\tvalid_1's binary_logloss: 0.0133446\n",
      "oof log_loss= 0.015213666094083922 \n",
      "all log_loss= 0.01402156477000738 \n",
      "97 glutamate_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00450481\tvalid_1's binary_logloss: 0.00466676\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00477752\tvalid_1's binary_logloss: 0.00466643\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00448874\tvalid_1's binary_logloss: 0.00466602\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0039987\tvalid_1's binary_logloss: 0.00603438\n",
      "oof log_loss= 0.005008395942774549 \n",
      "all log_loss= 0.004615951715462235 \n",
      "98 glutamate_receptor_agonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's binary_logloss: 0.0158986\tvalid_1's binary_logloss: 0.0216525\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's binary_logloss: 0.0125163\tvalid_1's binary_logloss: 0.0218646\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0219336\tvalid_1's binary_logloss: 0.0230887\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[105]\ttraining's binary_logloss: 0.00853961\tvalid_1's binary_logloss: 0.022534\n",
      "oof log_loss= 0.02228494980299592 \n",
      "all log_loss= 0.0205387620003425 \n",
      "99 glutamate_receptor_antagonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[350]\ttraining's binary_logloss: 0.0519234\tvalid_1's binary_logloss: 0.0808673\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[399]\ttraining's binary_logloss: 0.0473732\tvalid_1's binary_logloss: 0.0818275\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[378]\ttraining's binary_logloss: 0.0516827\tvalid_1's binary_logloss: 0.0813173\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[382]\ttraining's binary_logloss: 0.0501217\tvalid_1's binary_logloss: 0.0819769\n",
      "oof log_loss= 0.08149725984463571 \n",
      "all log_loss= 0.07511135714579938 \n",
      "100 gonadotropin_receptor_agonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00588032\tvalid_1's binary_logloss: 0.00603092\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0062588\tvalid_1's binary_logloss: 0.00601325\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00587037\tvalid_1's binary_logloss: 0.00731219\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's binary_logloss: 0.00197541\tvalid_1's binary_logloss: 0.00726796\n",
      "oof log_loss= 0.006656079708038192 \n",
      "all log_loss= 0.006134527480978588 \n",
      "101 gsk_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[138]\ttraining's binary_logloss: 0.00279099\tvalid_1's binary_logloss: 0.0148889\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[175]\ttraining's binary_logloss: 0.00228984\tvalid_1's binary_logloss: 0.0122838\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\ttraining's binary_logloss: 0.00246658\tvalid_1's binary_logloss: 0.0136435\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[237]\ttraining's binary_logloss: 0.00139661\tvalid_1's binary_logloss: 0.013075\n",
      "oof log_loss= 0.013472803520686156 \n",
      "all log_loss= 0.012417111433275452 \n",
      "102 hcv_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's binary_logloss: 0.0134841\tvalid_1's binary_logloss: 0.021861\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttraining's binary_logloss: 0.0100836\tvalid_1's binary_logloss: 0.0219172\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0217626\tvalid_1's binary_logloss: 0.0220486\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.021629\tvalid_1's binary_logloss: 0.0220527\n",
      "oof log_loss= 0.021969888087019926 \n",
      "all log_loss= 0.020248387659944366 \n",
      "103 hdac_inhibitor\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[322]\ttraining's binary_logloss: 0.00143903\tvalid_1's binary_logloss: 0.010246\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[216]\ttraining's binary_logloss: 0.00279674\tvalid_1's binary_logloss: 0.0159105\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[324]\ttraining's binary_logloss: 0.00147573\tvalid_1's binary_logloss: 0.0106461\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[225]\ttraining's binary_logloss: 0.00243679\tvalid_1's binary_logloss: 0.0169478\n",
      "oof log_loss= 0.013437613363471889 \n",
      "all log_loss= 0.012384678680670313 \n",
      "104 histamine_receptor_agonist\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's binary_logloss: 0.00763805\tvalid_1's binary_logloss: 0.0173371\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's binary_logloss: 0.00871013\tvalid_1's binary_logloss: 0.0184537\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's binary_logloss: 0.0063534\tvalid_1's binary_logloss: 0.0187969\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[122]\ttraining's binary_logloss: 0.00502395\tvalid_1's binary_logloss: 0.0187207\n",
      "oof log_loss= 0.018327090031943313 \n",
      "all log_loss= 0.0168910293113754 \n",
      "105 histamine_receptor_antagonist\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'[\"\\'diff-g-669\", \"\\'diff-g-182\", \"\\'diff-g-679\", \"\\'diff-g-494\", \"\\'diff-g-680\", \"\\'diff-g-71\", \"\\'diff-g-509\", \"\\'diff-g-555\", \"\\'diff-g-686\", \"\\'diff-g-8\", \"\\'diff-g-171\", \"\\'diff-g-191\", \"\\'diff-g-368\", \"\\'diff-g-54\", \"\\'diff-g-309\", \"\\'diff-g-698\", \"\\'diff-g-263\", \"\\'diff-g-159\", \"\\'diff-c-67\", \"\\'diff-c-31\", \"\\'diff-g-137\", \"\\'diff-c-50\", \"\\'diff-g-436\", \"\\'diff-g-57\", \"\\'diff-g-535\", \"\\'diff-g-156\", \"\\'diff-g-154\", \"\\'diff-g-400\", \"\\'diff-c-51\", \"\\'diff-c-98\", \"\\'diff-g-81\", \"\\'diff-g-750\", \"\\'diff-g-515\", \"\\'diff-g-643\", \"\\'diff-g-702\", \"\\'diff-g-756\", \"\\'diff-g-729\", \"\\'diff-g-622\", \"\\'diff-g-344\", \"\\'diff-g-599\", \"\\'diff-g-533\", \"\\'diff-g-505\", \"\\'diff-g-604\", \"\\'diff-g-695\", \"\\'diff-g-66\", \"\\'diff-g-160\", \"\\'diff-g-26\", \"\\'diff-g-284\", \"\\'diff-c-57\", \"\\'diff-g-407\", \"\\'diff-g-32\", \"\\'diff-g-84\", \"\\'diff-g-501\", \"\\'diff-g-435\", \"\\'diff-g-138\", \"\\'diff-g-397\", \"\\'diff-g-72\", \"\\'diff-c-35\", \"\\'diff-g-247\", \"\\'diff-g-402\", \"\\'diff-g-406\", \"\\'diff-g-468\", \"\\'diff-g-168\", \"\\'diff-g-596\", \"\\'diff-g-86\", \"\\'diff-g-80\", \"\\'diff-g-249\", \"\\'diff-g-43\", \"\\'diff-g-538\", \"\\'diff-g-629\", \"\\'diff-g-697\", \"\\'diff-c-49\", \"\\'diff-g-44\", \"\\'diff-g-496\", \"\\'diff-g-266\", \"\\'diff-g-614\", \"\\'diff-g-282\", \"\\'diff-g-508\", \"\\'diff-g-97\", \"\\'diff-g-712\", \"\\'diff-g-645\", \"\\'diff-g-513\", \"\\'diff-g-299\", \"\\'diff-c-27\", \"\\'diff-g-116\", \"\\'diff-g-521\", \"\\'diff-g-577\", \"\\'diff-c-46\", \"\\'diff-g-375\", \"\\'diff-g-130\", \"\\'diff-g-211\", \"\\'diff-g-236\", \"\\'diff-g-317\", \"\\'diff-g-261\", \"\\'diff-g-611\", \"\\'diff-g-625\", \"\\'diff-c-81\", \"\\'diff-g-552\", \"\\'diff-g-34\", \"\\'diff-g-189\", \"\\'diff-g-206\", \"\\'diff-g-310\", \"\\'diff-g-144\", \"\\'diff-g-148\", \"\\'diff-g-128\", \"\\'diff-g-126\", \"\\'diff-g-564\", \"\\'diff-g-360\", \"\\'diff-g-581\", \"\\'diff-g-157\", \"\\'diff-g-745\", \"\\'diff-g-264\", \"\\'diff-c-68\", \"\\'diff-g-655\", \"\\'diff-g-91\", \"\\'diff-g-771\", \"\\'diff-c-38\", \"\\'diff-g-664\", \"\\'diff-g-466\", \"\\'diff-c-20\", \"\\'diff-c-77\", \"\\'diff-g-382\", \"\\'diff-g-709\", \"\\'diff-g-219\", \"\\'diff-g-145\", \"\\'diff-g-619\", \"\\'diff-g-183\", \"\\'diff-g-141\", \"\\'diff-g-320\", \"\\'diff-g-730\", \"\\'diff-g-759\", \"\\'diff-g-361\", \"\\'diff-g-429\", \"\\'diff-g-38\", \"\\'diff-g-395\", \"\\'diff-g-165\", \"\\'diff-g-225\", \"\\'diff-g-232\", \"\\'diff-g-631\", \"\\'diff-g-82\", \"\\'diff-g-503\", \"\\'diff-g-95\", \"\\'diff-g-248\", \"\\'diff-g-527\", \"\\'diff-g-202\", \"\\'diff-g-274\", \"\\'diff-g-300\", \"\\'diff-g-660\", \"\\'diff-g-200\", \"\\'diff-g-448\", \"\\'diff-g-401\", \"\\'diff-g-499\", \"\\'diff-g-651\", \"\\'diff-g-760\", \"\\'diff-g-403\", \"\\'diff-g-70\", \"\\'diff-g-204\", \"\\'diff-g-327\", \"\\'diff-g-725\", \"\\'diff-c-63\", \"\\'diff-g-502\", \"\\'diff-g-388\", \"\\'diff-g-276\", \"\\'diff-g-589\", \"\\'diff-g-140\", \"\\'diff-g-713\", \"\\'diff-g-173\", \"\\'diff-g-147\", \"\\'diff-g-591\", \"\\'diff-g-100\", \"\\'diff-g-357\", \"\\'diff-g-409\", \"\\'diff-g-470\", \"\\'diff-g-14\", \"\\'diff-g-307\", \"\\'diff-g-743\", \"\\'diff-g-765\", \"\\'diff-g-453\", \"\\'diff-g-737\", \"\\'diff-g-656\", \"\\'diff-c-37\", \"\\'diff-g-220\", \"\\'diff-g-511\", \"\\'diff-g-294\", \"\\'diff-g-203\", \"\\'diff-g-230\", \"\\'diff-g-223\", \"\\'diff-c-2\", \"\\'diff-c-76\", \"\\'diff-g-358\", \"\\'diff-c-83\", \"\\'diff-g-363\", \"\\'diff-c-62\", \"\\'diff-g-323\", \"\\'diff-c-92\", \"\\'diff-g-37\", \"\\'diff-g-231\", \"\\'diff-g-371\", \"\\'diff-g-681\", \"\\'diff-g-703\", \"\\'diff-g-259\", \"\\'diff-g-155\", \"\\'diff-g-544\", \"\\'diff-g-178\", \"\\'diff-g-352\", \"\\'diff-g-767\", \"\\'diff-g-444\", \"\\'diff-g-617\", \"\\'diff-g-50\", \"\\'diff-c-58\", \"\\'diff-c-78\", \"\\'diff-c-10\", \"\\'diff-c-23\", \"\\'diff-g-378\", \"\\'diff-g-65\", \"\\'diff-g-271\", \"\\'diff-g-356\", \"\\'diff-g-723\", \"\\'diff-g-605\", \"\\'diff-g-135\", \"\\'diff-g-716\", \"\\'diff-g-641\", \"\\'diff-g-711\", \"\\'diff-g-736\", \"\\'diff-g-254\", \"\\'diff-g-404\", \"\\'diff-g-582\", \"\\'diff-g-567\", \"\\'diff-g-224\", \"\\'diff-c-89\", \"\\'diff-g-446\", \"\\'diff-c-61\", \"\\'diff-g-3\", \"\\'diff-g-682\", \"\\'diff-g-318\", \"\\'diff-g-325\", \"\\'diff-g-93\", \"\\'diff-g-657\", \"\\'diff-g-608\", \"\\'diff-c-7\", \"\\'diff-g-504\", \"\\'diff-g-497\", \"\\'diff-g-253\", \"\\'diff-g-440\", \"\\'diff-g-414\", \"\\'diff-g-11\", \"\\'diff-g-488\", \"\\'diff-g-531\", \"\\'diff-g-355\", \"\\'diff-c-54\", \"\\'diff-g-291\", \"\\'diff-c-3\", \"\\'diff-g-226\", \"\\'diff-g-376\", \"\\'diff-g-719\", \"\\'diff-g-728\", \"\\'diff-g-733\", \"\\'diff-g-460\", \"\\'diff-g-667\", \"\\'diff-g-613\", \"\\'diff-g-442\", \"\\'diff-g-672\", \"\\'diff-g-749\"] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a94e4103174d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_feats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelling_lgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_train_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_train_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_test_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mtrain_checkscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcons_train_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mtrain_checkscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnoncons_train_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-a94e4103174d>\u001b[0m in \u001b[0;36mmodelling_lgb\u001b[0;34m(new_train, target_train, new_test, target, ind)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecreased_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mselected_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2906\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2908\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2910\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1302\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;31m# we skip the warning on Categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '[\"\\'diff-g-669\", \"\\'diff-g-182\", \"\\'diff-g-679\", \"\\'diff-g-494\", \"\\'diff-g-680\", \"\\'diff-g-71\", \"\\'diff-g-509\", \"\\'diff-g-555\", \"\\'diff-g-686\", \"\\'diff-g-8\", \"\\'diff-g-171\", \"\\'diff-g-191\", \"\\'diff-g-368\", \"\\'diff-g-54\", \"\\'diff-g-309\", \"\\'diff-g-698\", \"\\'diff-g-263\", \"\\'diff-g-159\", \"\\'diff-c-67\", \"\\'diff-c-31\", \"\\'diff-g-137\", \"\\'diff-c-50\", \"\\'diff-g-436\", \"\\'diff-g-57\", \"\\'diff-g-535\", \"\\'diff-g-156\", \"\\'diff-g-154\", \"\\'diff-g-400\", \"\\'diff-c-51\", \"\\'diff-c-98\", \"\\'diff-g-81\", \"\\'diff-g-750\", \"\\'diff-g-515\", \"\\'diff-g-643\", \"\\'diff-g-702\", \"\\'diff-g-756\", \"\\'diff-g-729\", \"\\'diff-g-622\", \"\\'diff-g-344\", \"\\'diff-g-599\", \"\\'diff-g-533\", \"\\'diff-g-505\", \"\\'diff-g-604\", \"\\'diff-g-695\", \"\\'diff-g-66\", \"\\'diff-g-160\", \"\\'diff-g-26\", \"\\'diff-g-284\", \"\\'diff-c-57\", \"\\'diff-g-407\", \"\\'diff-g-32\", \"\\'diff-g-84\", \"\\'diff-g-501\", \"\\'diff-g-435\", \"\\'diff-g-138\", \"\\'diff-g-397\", \"\\'diff-g-72\", \"\\'diff-c-35\", \"\\'diff-g-247\", \"\\'diff-g-402\", \"\\'diff-g-406\", \"\\'diff-g-468\", \"\\'diff-g-168\", \"\\'diff-g-596\", \"\\'diff-g-86\", \"\\'diff-g-80\", \"\\'diff-g-249\", \"\\'diff-g-43\", \"\\'diff-g-538\", \"\\'diff-g-629\", \"\\'diff-g-697\", \"\\'diff-c-49\", \"\\'diff-g-44\", \"\\'diff-g-496\", \"\\'diff-g-266\", \"\\'diff-g-614\", \"\\'diff-g-282\", \"\\'diff-g-508\", \"\\'diff-g-97\", \"\\'diff-g-712\", \"\\'diff-g-645\", \"\\'diff-g-513\", \"\\'diff-g-299\", \"\\'diff-c-27\", \"\\'diff-g-116\", \"\\'diff-g-521\", \"\\'diff-g-577\", \"\\'diff-c-46\", \"\\'diff-g-375\", \"\\'diff-g-130\", \"\\'diff-g-211\", \"\\'diff-g-236\", \"\\'diff-g-317\", \"\\'diff-g-261\", \"\\'diff-g-611\", \"\\'diff-g-625\", \"\\'diff-c-81\", \"\\'diff-g-552\", \"\\'diff-g-34\", \"\\'diff-g-189\", \"\\'diff-g-206\", \"\\'diff-g-310\", \"\\'diff-g-144\", \"\\'diff-g-148\", \"\\'diff-g-128\", \"\\'diff-g-126\", \"\\'diff-g-564\", \"\\'diff-g-360\", \"\\'diff-g-581\", \"\\'diff-g-157\", \"\\'diff-g-745\", \"\\'diff-g-264\", \"\\'diff-c-68\", \"\\'diff-g-655\", \"\\'diff-g-91\", \"\\'diff-g-771\", \"\\'diff-c-38\", \"\\'diff-g-664\", \"\\'diff-g-466\", \"\\'diff-c-20\", \"\\'diff-c-77\", \"\\'diff-g-382\", \"\\'diff-g-709\", \"\\'diff-g-219\", \"\\'diff-g-145\", \"\\'diff-g-619\", \"\\'diff-g-183\", \"\\'diff-g-141\", \"\\'diff-g-320\", \"\\'diff-g-730\", \"\\'diff-g-759\", \"\\'diff-g-361\", \"\\'diff-g-429\", \"\\'diff-g-38\", \"\\'diff-g-395\", \"\\'diff-g-165\", \"\\'diff-g-225\", \"\\'diff-g-232\", \"\\'diff-g-631\", \"\\'diff-g-82\", \"\\'diff-g-503\", \"\\'diff-g-95\", \"\\'diff-g-248\", \"\\'diff-g-527\", \"\\'diff-g-202\", \"\\'diff-g-274\", \"\\'diff-g-300\", \"\\'diff-g-660\", \"\\'diff-g-200\", \"\\'diff-g-448\", \"\\'diff-g-401\", \"\\'diff-g-499\", \"\\'diff-g-651\", \"\\'diff-g-760\", \"\\'diff-g-403\", \"\\'diff-g-70\", \"\\'diff-g-204\", \"\\'diff-g-327\", \"\\'diff-g-725\", \"\\'diff-c-63\", \"\\'diff-g-502\", \"\\'diff-g-388\", \"\\'diff-g-276\", \"\\'diff-g-589\", \"\\'diff-g-140\", \"\\'diff-g-713\", \"\\'diff-g-173\", \"\\'diff-g-147\", \"\\'diff-g-591\", \"\\'diff-g-100\", \"\\'diff-g-357\", \"\\'diff-g-409\", \"\\'diff-g-470\", \"\\'diff-g-14\", \"\\'diff-g-307\", \"\\'diff-g-743\", \"\\'diff-g-765\", \"\\'diff-g-453\", \"\\'diff-g-737\", \"\\'diff-g-656\", \"\\'diff-c-37\", \"\\'diff-g-220\", \"\\'diff-g-511\", \"\\'diff-g-294\", \"\\'diff-g-203\", \"\\'diff-g-230\", \"\\'diff-g-223\", \"\\'diff-c-2\", \"\\'diff-c-76\", \"\\'diff-g-358\", \"\\'diff-c-83\", \"\\'diff-g-363\", \"\\'diff-c-62\", \"\\'diff-g-323\", \"\\'diff-c-92\", \"\\'diff-g-37\", \"\\'diff-g-231\", \"\\'diff-g-371\", \"\\'diff-g-681\", \"\\'diff-g-703\", \"\\'diff-g-259\", \"\\'diff-g-155\", \"\\'diff-g-544\", \"\\'diff-g-178\", \"\\'diff-g-352\", \"\\'diff-g-767\", \"\\'diff-g-444\", \"\\'diff-g-617\", \"\\'diff-g-50\", \"\\'diff-c-58\", \"\\'diff-c-78\", \"\\'diff-c-10\", \"\\'diff-c-23\", \"\\'diff-g-378\", \"\\'diff-g-65\", \"\\'diff-g-271\", \"\\'diff-g-356\", \"\\'diff-g-723\", \"\\'diff-g-605\", \"\\'diff-g-135\", \"\\'diff-g-716\", \"\\'diff-g-641\", \"\\'diff-g-711\", \"\\'diff-g-736\", \"\\'diff-g-254\", \"\\'diff-g-404\", \"\\'diff-g-582\", \"\\'diff-g-567\", \"\\'diff-g-224\", \"\\'diff-c-89\", \"\\'diff-g-446\", \"\\'diff-c-61\", \"\\'diff-g-3\", \"\\'diff-g-682\", \"\\'diff-g-318\", \"\\'diff-g-325\", \"\\'diff-g-93\", \"\\'diff-g-657\", \"\\'diff-g-608\", \"\\'diff-c-7\", \"\\'diff-g-504\", \"\\'diff-g-497\", \"\\'diff-g-253\", \"\\'diff-g-440\", \"\\'diff-g-414\", \"\\'diff-g-11\", \"\\'diff-g-488\", \"\\'diff-g-531\", \"\\'diff-g-355\", \"\\'diff-c-54\", \"\\'diff-g-291\", \"\\'diff-c-3\", \"\\'diff-g-226\", \"\\'diff-g-376\", \"\\'diff-g-719\", \"\\'diff-g-728\", \"\\'diff-g-733\", \"\\'diff-g-460\", \"\\'diff-g-667\", \"\\'diff-g-613\", \"\\'diff-g-442\", \"\\'diff-g-672\", \"\\'diff-g-749\"] not in index'"
     ]
    }
   ],
   "source": [
    "lgbm_params = {'objective': 'binary', 'boosting_type': 'gbdt', 'tree_learner': 'serial', 'learning_rate': 0.01, \n",
    "               \"num_leaves\": 10, 'random_seed':44, 'max_depth': 5}\n",
    "\n",
    "def modelling_lgb(new_train, target_train, new_test, target, ind):\n",
    "    \n",
    "    X_train = new_train.drop(['sig_id'],axis=1).copy()\n",
    "    y_train = target_train[target].copy()\n",
    "    X_test = new_test.copy()\n",
    "    X_test = new_test.drop(['sig_id'],axis=1).copy()\n",
    "        \n",
    "    pred_value = np.zeros(X_test.shape[0])\n",
    "        \n",
    "    if ind in decreased_vars:\n",
    "        selected_features = [i[1:-1] for i in df.loc[ind,:][df.loc[ind,:].notna()]]\n",
    "        X_train = X_train[selected_features]\n",
    "        X_test = X_test[selected_features]\n",
    "        \n",
    "    n_folds=4\n",
    "    if target not in [\"erbb2_inhibitor\", \"atp-sensitive_potassium_channel_antagonist\"]:\n",
    "        skf=StratifiedKFold(n_splits = n_folds, shuffle=True, random_state=0)\n",
    "    else:\n",
    "        skf=KFold(n_splits = n_folds, shuffle=True, random_state=0)\n",
    "\n",
    "    models = []\n",
    "\n",
    "    valid = np.zeros([X_train.shape[0]])\n",
    "    for i , (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        print(\"Fold \"+str(i+1))\n",
    "        X_train2 = X_train.iloc[train_index,:]\n",
    "        y_train2 = y_train.iloc[train_index]\n",
    "\n",
    "        X_valid2 = X_train.iloc[test_index,:]\n",
    "        y_valid2 = y_train.iloc[test_index]\n",
    "        \n",
    "        lgb_train = lgb.Dataset(X_train2, y_train2)\n",
    "        lgb_eval = lgb.Dataset(X_valid2, y_valid2, reference=lgb_train)\n",
    "        \n",
    "        clf = lgb.train(lgbm_params, lgb_train,valid_sets=[lgb_train, lgb_eval], \n",
    "               num_boost_round=10000,early_stopping_rounds=50,verbose_eval = 1000) \n",
    "\n",
    "        valid_predict = clf.predict(X_valid2, num_iteration = clf.best_iteration)\n",
    "        valid[test_index] = valid_predict\n",
    "        pred_value += clf.predict(X_test, num_iteration = clf.best_iteration) / n_folds\n",
    "\n",
    "    score = log_loss(y_train, valid)\n",
    "            \n",
    "    return valid, pred_value, score\n",
    "\n",
    "train_checkscore = train_score.copy()\n",
    "target_list = []\n",
    "log_loss_list = []\n",
    "\n",
    "for ind, target in enumerate(target_feats):\n",
    "    print(ind, target)\n",
    "    valid, pred_value, score = modelling_lgb(n_train_feat, n_train_score, n_test_feat, target, ind)\n",
    "    train_checkscore.loc[cons_train_index, target] = valid\n",
    "    train_checkscore.loc[noncons_train_index, target] = 0\n",
    "    print(\"oof log_loss= {} \".format(score))\n",
    "    print(\"all log_loss= {} \".format(log_loss(train_score[target], train_checkscore[target])))\n",
    "    target_list.append(target)\n",
    "    log_loss_list.append(score)\n",
    "    sub.loc[cons_test_index, target] = pred_value\n",
    "    sub.loc[noncons_test_index, target] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T04:23:48.895504Z",
     "iopub.status.busy": "2020-10-01T04:23:48.894884Z",
     "iopub.status.idle": "2020-10-01T04:23:49.959091Z",
     "shell.execute_reply": "2020-10-01T04:23:49.958512Z"
    },
    "papermill": {
     "duration": 1.300031,
     "end_time": "2020-10-01T04:23:49.959225",
     "exception": false,
     "start_time": "2020-10-01T04:23:48.659194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008911002480320321\n"
     ]
    }
   ],
   "source": [
    "# local score\n",
    "scores = []\n",
    "for target_col in target_feats:\n",
    "    scores.append(log_loss(train_score[target_col], train_checkscore[target_col]))\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T04:23:50.471148Z",
     "iopub.status.busy": "2020-10-01T04:23:50.435205Z",
     "iopub.status.idle": "2020-10-01T04:23:50.510556Z",
     "shell.execute_reply": "2020-10-01T04:23:50.511032Z"
    },
    "papermill": {
     "duration": 0.319365,
     "end_time": "2020-10-01T04:23:50.511178",
     "exception": false,
     "start_time": "2020-10-01T04:23:50.191813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>5-alpha_reductase_inhibitor</td>\n",
       "      <td>11-beta-hsd1_inhibitor</td>\n",
       "      <td>acat_inhibitor</td>\n",
       "      <td>acetylcholine_receptor_agonist</td>\n",
       "      <td>acetylcholine_receptor_antagonist</td>\n",
       "      <td>acetylcholinesterase_inhibitor</td>\n",
       "      <td>adenosine_receptor_agonist</td>\n",
       "      <td>adenosine_receptor_antagonist</td>\n",
       "      <td>adenylyl_cyclase_activator</td>\n",
       "      <td>adrenergic_receptor_agonist</td>\n",
       "      <td>adrenergic_receptor_antagonist</td>\n",
       "      <td>akt_inhibitor</td>\n",
       "      <td>aldehyde_dehydrogenase_inhibitor</td>\n",
       "      <td>alk_inhibitor</td>\n",
       "      <td>ampk_activator</td>\n",
       "      <td>analgesic</td>\n",
       "      <td>androgen_receptor_agonist</td>\n",
       "      <td>androgen_receptor_antagonist</td>\n",
       "      <td>anesthetic_-_local</td>\n",
       "      <td>angiogenesis_inhibitor</td>\n",
       "      <td>angiotensin_receptor_antagonist</td>\n",
       "      <td>anti-inflammatory</td>\n",
       "      <td>antiarrhythmic</td>\n",
       "      <td>antibiotic</td>\n",
       "      <td>anticonvulsant</td>\n",
       "      <td>antifungal</td>\n",
       "      <td>antihistamine</td>\n",
       "      <td>antimalarial</td>\n",
       "      <td>antioxidant</td>\n",
       "      <td>antiprotozoal</td>\n",
       "      <td>antiviral</td>\n",
       "      <td>apoptosis_stimulant</td>\n",
       "      <td>aromatase_inhibitor</td>\n",
       "      <td>atm_kinase_inhibitor</td>\n",
       "      <td>atp-sensitive_potassium_channel_antagonist</td>\n",
       "      <td>atp_synthase_inhibitor</td>\n",
       "      <td>atpase_inhibitor</td>\n",
       "      <td>atr_kinase_inhibitor</td>\n",
       "      <td>aurora_kinase_inhibitor</td>\n",
       "      <td>autotaxin_inhibitor</td>\n",
       "      <td>bacterial_30s_ribosomal_subunit_inhibitor</td>\n",
       "      <td>bacterial_50s_ribosomal_subunit_inhibitor</td>\n",
       "      <td>bacterial_antifolate</td>\n",
       "      <td>bacterial_cell_wall_synthesis_inhibitor</td>\n",
       "      <td>bacterial_dna_gyrase_inhibitor</td>\n",
       "      <td>bacterial_dna_inhibitor</td>\n",
       "      <td>bacterial_membrane_integrity_inhibitor</td>\n",
       "      <td>bcl_inhibitor</td>\n",
       "      <td>bcr-abl_inhibitor</td>\n",
       "      <td>benzodiazepine_receptor_agonist</td>\n",
       "      <td>beta_amyloid_inhibitor</td>\n",
       "      <td>bromodomain_inhibitor</td>\n",
       "      <td>btk_inhibitor</td>\n",
       "      <td>calcineurin_inhibitor</td>\n",
       "      <td>calcium_channel_blocker</td>\n",
       "      <td>cannabinoid_receptor_agonist</td>\n",
       "      <td>cannabinoid_receptor_antagonist</td>\n",
       "      <td>carbonic_anhydrase_inhibitor</td>\n",
       "      <td>casein_kinase_inhibitor</td>\n",
       "      <td>caspase_activator</td>\n",
       "      <td>catechol_o_methyltransferase_inhibitor</td>\n",
       "      <td>cc_chemokine_receptor_antagonist</td>\n",
       "      <td>cck_receptor_antagonist</td>\n",
       "      <td>cdk_inhibitor</td>\n",
       "      <td>chelating_agent</td>\n",
       "      <td>chk_inhibitor</td>\n",
       "      <td>chloride_channel_blocker</td>\n",
       "      <td>cholesterol_inhibitor</td>\n",
       "      <td>cholinergic_receptor_antagonist</td>\n",
       "      <td>coagulation_factor_inhibitor</td>\n",
       "      <td>corticosteroid_agonist</td>\n",
       "      <td>cyclooxygenase_inhibitor</td>\n",
       "      <td>cytochrome_p450_inhibitor</td>\n",
       "      <td>dihydrofolate_reductase_inhibitor</td>\n",
       "      <td>dipeptidyl_peptidase_inhibitor</td>\n",
       "      <td>diuretic</td>\n",
       "      <td>dna_alkylating_agent</td>\n",
       "      <td>dna_inhibitor</td>\n",
       "      <td>dopamine_receptor_agonist</td>\n",
       "      <td>dopamine_receptor_antagonist</td>\n",
       "      <td>egfr_inhibitor</td>\n",
       "      <td>elastase_inhibitor</td>\n",
       "      <td>erbb2_inhibitor</td>\n",
       "      <td>estrogen_receptor_agonist</td>\n",
       "      <td>estrogen_receptor_antagonist</td>\n",
       "      <td>faah_inhibitor</td>\n",
       "      <td>farnesyltransferase_inhibitor</td>\n",
       "      <td>fatty_acid_receptor_agonist</td>\n",
       "      <td>fgfr_inhibitor</td>\n",
       "      <td>flt3_inhibitor</td>\n",
       "      <td>focal_adhesion_kinase_inhibitor</td>\n",
       "      <td>free_radical_scavenger</td>\n",
       "      <td>fungal_squalene_epoxidase_inhibitor</td>\n",
       "      <td>gaba_receptor_agonist</td>\n",
       "      <td>gaba_receptor_antagonist</td>\n",
       "      <td>gamma_secretase_inhibitor</td>\n",
       "      <td>glucocorticoid_receptor_agonist</td>\n",
       "      <td>glutamate_inhibitor</td>\n",
       "      <td>glutamate_receptor_agonist</td>\n",
       "      <td>glutamate_receptor_antagonist</td>\n",
       "      <td>gonadotropin_receptor_agonist</td>\n",
       "      <td>gsk_inhibitor</td>\n",
       "      <td>hcv_inhibitor</td>\n",
       "      <td>hdac_inhibitor</td>\n",
       "      <td>histamine_receptor_agonist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.00607565</td>\n",
       "      <td>0.00662189</td>\n",
       "      <td>0.00843873</td>\n",
       "      <td>0.0471292</td>\n",
       "      <td>0.0690841</td>\n",
       "      <td>0.021901</td>\n",
       "      <td>0.0171832</td>\n",
       "      <td>0.0277751</td>\n",
       "      <td>0.00383652</td>\n",
       "      <td>0.0593518</td>\n",
       "      <td>0.0785539</td>\n",
       "      <td>0.0155387</td>\n",
       "      <td>0.00233972</td>\n",
       "      <td>0.0118439</td>\n",
       "      <td>0.00458633</td>\n",
       "      <td>0.00452143</td>\n",
       "      <td>0.0154159</td>\n",
       "      <td>0.0263142</td>\n",
       "      <td>0.0239117</td>\n",
       "      <td>0.0120969</td>\n",
       "      <td>0.0124162</td>\n",
       "      <td>0.0215702</td>\n",
       "      <td>0.00252711</td>\n",
       "      <td>0.0133475</td>\n",
       "      <td>0.00466088</td>\n",
       "      <td>0.00487605</td>\n",
       "      <td>0.00466274</td>\n",
       "      <td>0.00648111</td>\n",
       "      <td>0.0220385</td>\n",
       "      <td>0.0120665</td>\n",
       "      <td>0.00822767</td>\n",
       "      <td>0.0154739</td>\n",
       "      <td>0.0152612</td>\n",
       "      <td>0.00252552</td>\n",
       "      <td>0.00157376</td>\n",
       "      <td>0.00331201</td>\n",
       "      <td>0.0231797</td>\n",
       "      <td>0.00569297</td>\n",
       "      <td>0.01612</td>\n",
       "      <td>0.00254499</td>\n",
       "      <td>0.0187594</td>\n",
       "      <td>0.0238711</td>\n",
       "      <td>0.0120284</td>\n",
       "      <td>0.0482364</td>\n",
       "      <td>0.0261593</td>\n",
       "      <td>0.0318622</td>\n",
       "      <td>0.0027503</td>\n",
       "      <td>0.0096134</td>\n",
       "      <td>0.0113172</td>\n",
       "      <td>0.0204287</td>\n",
       "      <td>0.00855626</td>\n",
       "      <td>0.0149623</td>\n",
       "      <td>0.00960127</td>\n",
       "      <td>0.0025256</td>\n",
       "      <td>0.0650959</td>\n",
       "      <td>0.0138538</td>\n",
       "      <td>0.0171171</td>\n",
       "      <td>0.0121433</td>\n",
       "      <td>0.0117716</td>\n",
       "      <td>0.00659744</td>\n",
       "      <td>0.00466106</td>\n",
       "      <td>0.0292509</td>\n",
       "      <td>0.0066586</td>\n",
       "      <td>0.021628</td>\n",
       "      <td>0.0172165</td>\n",
       "      <td>0.00539583</td>\n",
       "      <td>0.0137462</td>\n",
       "      <td>0.0155199</td>\n",
       "      <td>0.0171519</td>\n",
       "      <td>0.0025279</td>\n",
       "      <td>0.00963845</td>\n",
       "      <td>0.0924955</td>\n",
       "      <td>0.0295469</td>\n",
       "      <td>0.0103305</td>\n",
       "      <td>0.00865342</td>\n",
       "      <td>0.00244157</td>\n",
       "      <td>0.0152817</td>\n",
       "      <td>0.0834787</td>\n",
       "      <td>0.0335795</td>\n",
       "      <td>0.0863835</td>\n",
       "      <td>0.0263916</td>\n",
       "      <td>0.0025343</td>\n",
       "      <td>0.00157447</td>\n",
       "      <td>0.0402608</td>\n",
       "      <td>0.0151534</td>\n",
       "      <td>0.0118792</td>\n",
       "      <td>0.0060714</td>\n",
       "      <td>0.00881815</td>\n",
       "      <td>0.0121519</td>\n",
       "      <td>0.029373</td>\n",
       "      <td>0.00484212</td>\n",
       "      <td>0.00666289</td>\n",
       "      <td>0.00822956</td>\n",
       "      <td>0.0302241</td>\n",
       "      <td>0.0428157</td>\n",
       "      <td>0.012967</td>\n",
       "      <td>0.0152137</td>\n",
       "      <td>0.0050084</td>\n",
       "      <td>0.0222849</td>\n",
       "      <td>0.0814973</td>\n",
       "      <td>0.00665608</td>\n",
       "      <td>0.0134728</td>\n",
       "      <td>0.0219699</td>\n",
       "      <td>0.0134376</td>\n",
       "      <td>0.0183271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0                       1               2    \\\n",
       "Target  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  acat_inhibitor   \n",
       "score                    0.00607565              0.00662189      0.00843873   \n",
       "\n",
       "                                   3                                  4    \\\n",
       "Target  acetylcholine_receptor_agonist  acetylcholine_receptor_antagonist   \n",
       "score                        0.0471292                          0.0690841   \n",
       "\n",
       "                                   5                           6    \\\n",
       "Target  acetylcholinesterase_inhibitor  adenosine_receptor_agonist   \n",
       "score                         0.021901                   0.0171832   \n",
       "\n",
       "                                  7                           8    \\\n",
       "Target  adenosine_receptor_antagonist  adenylyl_cyclase_activator   \n",
       "score                       0.0277751                  0.00383652   \n",
       "\n",
       "                                9                               10   \\\n",
       "Target  adrenergic_receptor_agonist  adrenergic_receptor_antagonist   \n",
       "score                     0.0593518                       0.0785539   \n",
       "\n",
       "                  11                                12             13   \\\n",
       "Target  akt_inhibitor  aldehyde_dehydrogenase_inhibitor  alk_inhibitor   \n",
       "score       0.0155387                        0.00233972      0.0118439   \n",
       "\n",
       "                   14          15                         16   \\\n",
       "Target  ampk_activator   analgesic  androgen_receptor_agonist   \n",
       "score       0.00458633  0.00452143                  0.0154159   \n",
       "\n",
       "                                 17                  18   \\\n",
       "Target  androgen_receptor_antagonist  anesthetic_-_local   \n",
       "score                      0.0263142           0.0239117   \n",
       "\n",
       "                           19                               20   \\\n",
       "Target  angiogenesis_inhibitor  angiotensin_receptor_antagonist   \n",
       "score                0.0120969                        0.0124162   \n",
       "\n",
       "                      21              22          23              24   \\\n",
       "Target  anti-inflammatory  antiarrhythmic  antibiotic  anticonvulsant   \n",
       "score           0.0215702      0.00252711   0.0133475      0.00466088   \n",
       "\n",
       "               25             26            27           28             29   \\\n",
       "Target  antifungal  antihistamine  antimalarial  antioxidant  antiprotozoal   \n",
       "score   0.00487605     0.00466274    0.00648111    0.0220385      0.0120665   \n",
       "\n",
       "               30                   31                   32   \\\n",
       "Target   antiviral  apoptosis_stimulant  aromatase_inhibitor   \n",
       "score   0.00822767            0.0154739            0.0152612   \n",
       "\n",
       "                         33                                          34   \\\n",
       "Target  atm_kinase_inhibitor  atp-sensitive_potassium_channel_antagonist   \n",
       "score             0.00252552                                  0.00157376   \n",
       "\n",
       "                           35                36                    37   \\\n",
       "Target  atp_synthase_inhibitor  atpase_inhibitor  atr_kinase_inhibitor   \n",
       "score               0.00331201         0.0231797            0.00569297   \n",
       "\n",
       "                            38                   39   \\\n",
       "Target  aurora_kinase_inhibitor  autotaxin_inhibitor   \n",
       "score                   0.01612           0.00254499   \n",
       "\n",
       "                                              40   \\\n",
       "Target  bacterial_30s_ribosomal_subunit_inhibitor   \n",
       "score                                   0.0187594   \n",
       "\n",
       "                                              41                    42   \\\n",
       "Target  bacterial_50s_ribosomal_subunit_inhibitor  bacterial_antifolate   \n",
       "score                                   0.0238711             0.0120284   \n",
       "\n",
       "                                            43   \\\n",
       "Target  bacterial_cell_wall_synthesis_inhibitor   \n",
       "score                                 0.0482364   \n",
       "\n",
       "                                   44                       45   \\\n",
       "Target  bacterial_dna_gyrase_inhibitor  bacterial_dna_inhibitor   \n",
       "score                        0.0261593                0.0318622   \n",
       "\n",
       "                                           46             47   \\\n",
       "Target  bacterial_membrane_integrity_inhibitor  bcl_inhibitor   \n",
       "score                                0.0027503      0.0096134   \n",
       "\n",
       "                      48                               49   \\\n",
       "Target  bcr-abl_inhibitor  benzodiazepine_receptor_agonist   \n",
       "score           0.0113172                        0.0204287   \n",
       "\n",
       "                           50                     51             52   \\\n",
       "Target  beta_amyloid_inhibitor  bromodomain_inhibitor  btk_inhibitor   \n",
       "score               0.00855626              0.0149623     0.00960127   \n",
       "\n",
       "                          53                       54   \\\n",
       "Target  calcineurin_inhibitor  calcium_channel_blocker   \n",
       "score               0.0025256                0.0650959   \n",
       "\n",
       "                                 55                               56   \\\n",
       "Target  cannabinoid_receptor_agonist  cannabinoid_receptor_antagonist   \n",
       "score                      0.0138538                        0.0171171   \n",
       "\n",
       "                                 57                       58   \\\n",
       "Target  carbonic_anhydrase_inhibitor  casein_kinase_inhibitor   \n",
       "score                      0.0121433                0.0117716   \n",
       "\n",
       "                      59                                      60   \\\n",
       "Target  caspase_activator  catechol_o_methyltransferase_inhibitor   \n",
       "score          0.00659744                              0.00466106   \n",
       "\n",
       "                                     61                       62   \\\n",
       "Target  cc_chemokine_receptor_antagonist  cck_receptor_antagonist   \n",
       "score                          0.0292509                0.0066586   \n",
       "\n",
       "                  63               64             65   \\\n",
       "Target  cdk_inhibitor  chelating_agent  chk_inhibitor   \n",
       "score        0.021628        0.0172165     0.00539583   \n",
       "\n",
       "                             66                     67   \\\n",
       "Target  chloride_channel_blocker  cholesterol_inhibitor   \n",
       "score                  0.0137462              0.0155199   \n",
       "\n",
       "                                    68                            69   \\\n",
       "Target  cholinergic_receptor_antagonist  coagulation_factor_inhibitor   \n",
       "score                         0.0171519                     0.0025279   \n",
       "\n",
       "                           70                        71   \\\n",
       "Target  corticosteroid_agonist  cyclooxygenase_inhibitor   \n",
       "score               0.00963845                 0.0924955   \n",
       "\n",
       "                              72                                 73   \\\n",
       "Target  cytochrome_p450_inhibitor  dihydrofolate_reductase_inhibitor   \n",
       "score                   0.0295469                          0.0103305   \n",
       "\n",
       "                                   74          75                    76   \\\n",
       "Target  dipeptidyl_peptidase_inhibitor    diuretic  dna_alkylating_agent   \n",
       "score                       0.00865342  0.00244157             0.0152817   \n",
       "\n",
       "                  77                         78   \\\n",
       "Target  dna_inhibitor  dopamine_receptor_agonist   \n",
       "score       0.0834787                  0.0335795   \n",
       "\n",
       "                                 79              80                  81   \\\n",
       "Target  dopamine_receptor_antagonist  egfr_inhibitor  elastase_inhibitor   \n",
       "score                      0.0863835       0.0263916           0.0025343   \n",
       "\n",
       "                    82                         83   \\\n",
       "Target  erbb2_inhibitor  estrogen_receptor_agonist   \n",
       "score        0.00157447                  0.0402608   \n",
       "\n",
       "                                 84              85   \\\n",
       "Target  estrogen_receptor_antagonist  faah_inhibitor   \n",
       "score                      0.0151534       0.0118792   \n",
       "\n",
       "                                  86                           87   \\\n",
       "Target  farnesyltransferase_inhibitor  fatty_acid_receptor_agonist   \n",
       "score                       0.0060714                   0.00881815   \n",
       "\n",
       "                   88              89                               90   \\\n",
       "Target  fgfr_inhibitor  flt3_inhibitor  focal_adhesion_kinase_inhibitor   \n",
       "score        0.0121519        0.029373                       0.00484212   \n",
       "\n",
       "                           91                                   92   \\\n",
       "Target  free_radical_scavenger  fungal_squalene_epoxidase_inhibitor   \n",
       "score               0.00666289                           0.00822956   \n",
       "\n",
       "                          93                        94   \\\n",
       "Target  gaba_receptor_agonist  gaba_receptor_antagonist   \n",
       "score               0.0302241                 0.0428157   \n",
       "\n",
       "                              95                               96   \\\n",
       "Target  gamma_secretase_inhibitor  glucocorticoid_receptor_agonist   \n",
       "score                    0.012967                        0.0152137   \n",
       "\n",
       "                        97                          98   \\\n",
       "Target  glutamate_inhibitor  glutamate_receptor_agonist   \n",
       "score             0.0050084                   0.0222849   \n",
       "\n",
       "                                  99                             100  \\\n",
       "Target  glutamate_receptor_antagonist  gonadotropin_receptor_agonist   \n",
       "score                       0.0814973                     0.00665608   \n",
       "\n",
       "                  101            102             103  \\\n",
       "Target  gsk_inhibitor  hcv_inhibitor  hdac_inhibitor   \n",
       "score       0.0134728      0.0219699       0.0134376   \n",
       "\n",
       "                               104  \n",
       "Target  histamine_receptor_agonist  \n",
       "score                    0.0183271  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difficult_list = pd.DataFrame(target_list, columns=[\"Target\"])\n",
    "difficult_list[\"score\"] = log_loss_list\n",
    "np.transpose(difficult_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T04:23:50.982287Z",
     "iopub.status.busy": "2020-10-01T04:23:50.981551Z",
     "iopub.status.idle": "2020-10-01T04:23:52.526201Z",
     "shell.execute_reply": "2020-10-01T04:23:52.526771Z"
    },
    "papermill": {
     "duration": 1.780796,
     "end_time": "2020-10-01T04:23:52.526920",
     "exception": false,
     "start_time": "2020-10-01T04:23:50.746124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 4158.272994,
   "end_time": "2020-10-01T04:23:52.872486",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-01T03:14:34.599492",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
