{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011693,
     "end_time": "2020-10-05T13:30:12.267535",
     "exception": false,
     "start_time": "2020-10-05T13:30:12.255842",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- change first layer dropout to 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-05T13:30:12.297794Z",
     "iopub.status.busy": "2020-10-05T13:30:12.297000Z",
     "iopub.status.idle": "2020-10-05T13:30:20.335551Z",
     "shell.execute_reply": "2020-10-05T13:30:20.333777Z"
    },
    "papermill": {
     "duration": 8.057426,
     "end_time": "2020-10-05T13:30:20.335694",
     "exception": false,
     "start_time": "2020-10-05T13:30:12.278268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "sys.path.append('../input/multilabelstraifier/')\n",
    "from ml_stratifiers import MultilabelStratifiedKFold\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T13:30:20.368171Z",
     "iopub.status.busy": "2020-10-05T13:30:20.367276Z",
     "iopub.status.idle": "2020-10-05T13:30:26.210358Z",
     "shell.execute_reply": "2020-10-05T13:30:26.209344Z"
    },
    "papermill": {
     "duration": 5.86305,
     "end_time": "2020-10-05T13:30:26.210506",
     "exception": false,
     "start_time": "2020-10-05T13:30:20.347456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/lish-moa/'\n",
    "train = pd.read_csv(DATA_DIR + 'train_features.csv')\n",
    "targets = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "#non_targets = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "test = pd.read_csv(DATA_DIR + 'test_features.csv')\n",
    "sub = pd.read_csv(DATA_DIR + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T13:30:26.240425Z",
     "iopub.status.busy": "2020-10-05T13:30:26.239606Z",
     "iopub.status.idle": "2020-10-05T13:30:26.244083Z",
     "shell.execute_reply": "2020-10-05T13:30:26.243523Z"
    },
    "papermill": {
     "duration": 0.022488,
     "end_time": "2020-10-05T13:30:26.244214",
     "exception": false,
     "start_time": "2020-10-05T13:30:26.221726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_feats = [ i for i in targets.columns if i != \"sig_id\"]\n",
    "g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "c_feats = [i for i in train.columns if \"c-\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T13:30:26.276019Z",
     "iopub.status.busy": "2020-10-05T13:30:26.275287Z",
     "iopub.status.idle": "2020-10-05T13:30:26.378785Z",
     "shell.execute_reply": "2020-10-05T13:30:26.378140Z"
    },
    "papermill": {
     "duration": 0.123139,
     "end_time": "2020-10-05T13:30:26.378893",
     "exception": false,
     "start_time": "2020-10-05T13:30:26.255754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "noncons_train_index = train[train.cp_type==\"ctl_vehicle\"].index\n",
    "cons_train_index = train[train.cp_type!=\"ctl_vehicle\"].index\n",
    "noncons_test_index = test[test.cp_type==\"ctl_vehicle\"].index\n",
    "cons_test_index = test[test.cp_type!=\"ctl_vehicle\"].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011183,
     "end_time": "2020-10-05T13:30:26.402002",
     "exception": false,
     "start_time": "2020-10-05T13:30:26.390819",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T13:30:26.438276Z",
     "iopub.status.busy": "2020-10-05T13:30:26.437525Z",
     "iopub.status.idle": "2020-10-05T13:30:29.005770Z",
     "shell.execute_reply": "2020-10-05T13:30:29.007341Z"
    },
    "papermill": {
     "duration": 2.594062,
     "end_time": "2020-10-05T13:30:29.007597",
     "exception": false,
     "start_time": "2020-10-05T13:30:26.413535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# normalization by ctl group\n",
    "train_ctl = train[train.index.isin(noncons_train_index)].copy().reset_index(drop=True)\n",
    "test_ctl = test[test.index.isin(noncons_test_index)].copy().reset_index(drop=True)\n",
    "ctl_df = pd.concat([train_ctl, test_ctl])\n",
    "\n",
    "ctl_group_data = ctl_df.groupby([\"cp_dose\", \"cp_time\"]).agg({\"mean\"}).reset_index()\n",
    "mean_g_feats = [\"mean-\" + i for i in g_feats]\n",
    "mean_c_feats = [\"mean-\" + i for i in c_feats]\n",
    "columns = [\"cp_dose\", \"cp_time\"] + mean_g_feats + mean_c_feats\n",
    "ctl_group_data.columns = columns\n",
    "\n",
    "train = train[train.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "targets = targets[targets.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "#non_targets = non_targets[non_targets.index.isin(cons_train_index)].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020831,
     "end_time": "2020-10-05T13:30:29.048970",
     "exception": false,
     "start_time": "2020-10-05T13:30:29.028139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T13:30:29.098777Z",
     "iopub.status.busy": "2020-10-05T13:30:29.097782Z",
     "iopub.status.idle": "2020-10-05T13:30:34.992860Z",
     "shell.execute_reply": "2020-10-05T13:30:34.993613Z"
    },
    "papermill": {
     "duration": 5.925873,
     "end_time": "2020-10-05T13:30:34.993782",
     "exception": false,
     "start_time": "2020-10-05T13:30:29.067909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 874) (3982, 874)\n"
     ]
    }
   ],
   "source": [
    "def fe(df, remove_features):\n",
    "    df = pd.merge(df, ctl_group_data, on=[\"cp_time\", \"cp_dose\"], how=\"left\")\n",
    "    for i in range(len(g_feats)):\n",
    "        df[\"diff-g-\"+str(i)] = df[\"g-\"+str(i)] - df[\"mean-g-\"+str(i)]\n",
    "    for i in range(len(c_feats)):\n",
    "        df[\"diff-c-\"+str(i)] = df[\"c-\"+str(i)] - df[\"mean-c-\"+str(i)]\n",
    "    \n",
    "    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "        \n",
    "    df.drop(remove_features, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "remove_features = [\"cp_type\" , \"sig_id\"] + mean_g_feats + mean_c_feats + g_feats + c_feats \n",
    "\n",
    "train = fe(train, remove_features)\n",
    "test = fe(test, remove_features)\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013344,
     "end_time": "2020-10-05T13:30:35.021294",
     "exception": false,
     "start_time": "2020-10-05T13:30:35.007950",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T13:30:35.074059Z",
     "iopub.status.busy": "2020-10-05T13:30:35.063703Z",
     "iopub.status.idle": "2020-10-05T13:30:35.471111Z",
     "shell.execute_reply": "2020-10-05T13:30:35.470568Z"
    },
    "papermill": {
     "duration": 0.435718,
     "end_time": "2020-10-05T13:30:35.471228",
     "exception": false,
     "start_time": "2020-10-05T13:30:35.035510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "batch_size = 128\n",
    "train_epochs = 40\n",
    "n_folds=5\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "\n",
    "def mean_log_loss(y_true, y_pred):\n",
    "    metrics = []\n",
    "    for i, target in enumerate(target_feats):\n",
    "        metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float), labels=[0,1]))\n",
    "    return np.mean(metrics)\n",
    "\n",
    "def seed_everything(seed=1234): \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "class MoaModel(nn.Module):\n",
    "    def __init__(self, num_columns):\n",
    "        super(MoaModel, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_columns)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_columns, 2048))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(2048)\n",
    "        self.dropout2 = nn.Dropout(0.6)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(2048, 1048))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(1048)\n",
    "        self.dropout3 = nn.Dropout(0.6)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(1048, 206))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "def modelling_torch(tr, target, te, sample_seed, init_num):\n",
    "    seed_everything(seed=sample_seed) \n",
    "    X_train = tr.copy()\n",
    "    y_train = target.copy()\n",
    "    X_test = te.copy()\n",
    "    test_len = X_test.shape[0]\n",
    "\n",
    "    mskf=MultilabelStratifiedKFold(n_splits = n_folds, shuffle=True, random_state=2)\n",
    "    models = []\n",
    "    \n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    X_test = torch.utils.data.TensorDataset(X_test) \n",
    "    test_loader = torch.utils.data.DataLoader(X_test, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    oof = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    oof_targets = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    pred_value = np.zeros([test_len, y_train.shape[1]])\n",
    "    scores = []\n",
    "    for fold, (train_index, valid_index) in enumerate(mskf.split(X_train, y_train)):\n",
    "        print(\"Fold \"+str(fold+1))\n",
    "        X_train2 = torch.tensor(X_train[train_index,:], dtype=torch.float32)\n",
    "        y_train2 = torch.tensor(y_train[train_index], dtype=torch.float32)\n",
    "\n",
    "        X_valid2 = torch.tensor(X_train[valid_index,:], dtype=torch.float32)\n",
    "        y_valid2 = torch.tensor(y_train[valid_index], dtype=torch.float32)\n",
    "            \n",
    "        clf = MoaModel(num_columns=init_num)\n",
    "        loss_fn = torch.nn.BCEWithLogitsLoss() \n",
    "        optimizer = optim.Adam(clf.parameters(), lr = 0.001, weight_decay=1e-5) \n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, eps=1e-4, verbose=True)\n",
    "        \n",
    "        train = torch.utils.data.TensorDataset(X_train2, y_train2)\n",
    "        valid = torch.utils.data.TensorDataset(X_valid2, y_valid2)\n",
    "        \n",
    "        clf.to(device)\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True) \n",
    "        valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        best_val_loss = np.inf\n",
    "        stop_counts = 0\n",
    "        for epoch in range(train_epochs):\n",
    "            start_time = time.time()\n",
    "            clf.train()\n",
    "            avg_loss = 0.\n",
    "            for x_batch, y_batch in tqdm(train_loader, disable=True):\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch) \n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                avg_loss += loss.item() / len(train_loader)        \n",
    "            \n",
    "            clf.eval()\n",
    "            avg_val_loss = 0.\n",
    "            for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch).detach()\n",
    "                avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "        \n",
    "            elapsed_time = time.time() - start_time \n",
    "            scheduler.step(avg_val_loss)\n",
    "            #print('Epoch-{0} lr: {1}'.format(epoch, optimizer.param_groups[0]['lr']))\n",
    "                    \n",
    "            if avg_val_loss < best_val_loss:\n",
    "                stop_counts = 0\n",
    "                best_val_loss = avg_val_loss\n",
    "                print('Best model: Epoch {} \\t loss={:.6f} \\t val_loss={:.6f} \\t time={:.2f}s'.format(\n",
    "                    epoch + 1, avg_loss, avg_val_loss, elapsed_time))\n",
    "                torch.save(clf.state_dict(), 'best-model-parameters.pt')\n",
    "            else:\n",
    "                stop_counts += 1\n",
    "     \n",
    "        pred_model = MoaModel(num_columns=init_num)\n",
    "        pred_model.load_state_dict(torch.load('best-model-parameters.pt'))\n",
    "        pred_model.eval()\n",
    "        \n",
    "        # validation check ----------------\n",
    "        oof_epoch = np.zeros([X_valid2.size(0), y_train.shape[1]])\n",
    "        target_epoch = np.zeros([X_valid2.size(0), y_train.shape[1]])\n",
    "        for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "                y_pred = pred_model(x_batch).sigmoid().detach()\n",
    "                oof_epoch[i * batch_size:(i+1) * batch_size,:] = y_pred.cpu().numpy()\n",
    "                target_epoch[i * batch_size:(i+1) * batch_size,:] = y_batch.cpu().numpy()\n",
    "        #print(\"Fold {} log loss: {}\".format(fold+1, mean_log_loss(target_epoch, oof_epoch)))\n",
    "        scores.append(mean_log_loss(target_epoch, oof_epoch))\n",
    "        oof[valid_index,:] = oof_epoch\n",
    "        oof_targets[valid_index,:] = target_epoch\n",
    "        #-----------------------------------\n",
    "        \n",
    "        # test predcition --------------\n",
    "        test_preds = np.zeros([test_len, y_train.shape[1]])\n",
    "        for i, (x_batch,) in enumerate(test_loader): \n",
    "            y_pred = pred_model(x_batch).sigmoid().detach()\n",
    "            test_preds[i * batch_size:(i+1) * batch_size, :] = y_pred.cpu().numpy()\n",
    "        pred_value += test_preds / n_folds\n",
    "        # ------------------------------\n",
    "        \n",
    "    print(\"Seed {}\".format(seed_))\n",
    "    for i, ele in enumerate(scores):\n",
    "        print(\"Fold {} log loss: {}\".format(i+1, scores[i]))\n",
    "    print(\"Std of log loss: {}\".format(np.std(scores)))\n",
    "    print(\"Total log loss: {}\".format(mean_log_loss(oof_targets, oof)))\n",
    "    \n",
    "    return oof, oof_targets, pred_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T13:30:35.507120Z",
     "iopub.status.busy": "2020-10-05T13:30:35.505728Z",
     "iopub.status.idle": "2020-10-05T13:52:46.230972Z",
     "shell.execute_reply": "2020-10-05T13:52:46.230380Z"
    },
    "papermill": {
     "duration": 1330.747847,
     "end_time": "2020-10-05T13:52:46.231118",
     "exception": false,
     "start_time": "2020-10-05T13:30:35.483271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.414384 \t val_loss=0.076418 \t time=1.56s\n",
      "Best model: Epoch 2 \t loss=0.048934 \t val_loss=0.029227 \t time=0.82s\n",
      "Best model: Epoch 3 \t loss=0.026792 \t val_loss=0.023422 \t time=0.82s\n",
      "Best model: Epoch 4 \t loss=0.023461 \t val_loss=0.021245 \t time=0.85s\n",
      "Best model: Epoch 5 \t loss=0.021476 \t val_loss=0.019857 \t time=0.81s\n",
      "Best model: Epoch 6 \t loss=0.020581 \t val_loss=0.019203 \t time=0.82s\n",
      "Best model: Epoch 7 \t loss=0.020049 \t val_loss=0.019054 \t time=0.84s\n",
      "Best model: Epoch 8 \t loss=0.019525 \t val_loss=0.018649 \t time=1.03s\n",
      "Best model: Epoch 9 \t loss=0.019215 \t val_loss=0.018443 \t time=0.88s\n",
      "Best model: Epoch 10 \t loss=0.018847 \t val_loss=0.018098 \t time=0.94s\n",
      "Best model: Epoch 11 \t loss=0.018290 \t val_loss=0.017817 \t time=0.95s\n",
      "Best model: Epoch 12 \t loss=0.018013 \t val_loss=0.017615 \t time=0.84s\n",
      "Best model: Epoch 13 \t loss=0.017724 \t val_loss=0.017353 \t time=0.86s\n",
      "Best model: Epoch 15 \t loss=0.017391 \t val_loss=0.017048 \t time=0.82s\n",
      "Best model: Epoch 17 \t loss=0.016977 \t val_loss=0.016873 \t time=0.84s\n",
      "Best model: Epoch 18 \t loss=0.016835 \t val_loss=0.016786 \t time=0.85s\n",
      "Best model: Epoch 19 \t loss=0.016586 \t val_loss=0.016776 \t time=0.84s\n",
      "Best model: Epoch 20 \t loss=0.016567 \t val_loss=0.016765 \t time=1.09s\n",
      "Best model: Epoch 21 \t loss=0.016289 \t val_loss=0.016643 \t time=0.85s\n",
      "Best model: Epoch 22 \t loss=0.016155 \t val_loss=0.016501 \t time=0.85s\n",
      "Best model: Epoch 23 \t loss=0.015982 \t val_loss=0.016443 \t time=0.85s\n",
      "Best model: Epoch 26 \t loss=0.015779 \t val_loss=0.016421 \t time=0.82s\n",
      "Best model: Epoch 28 \t loss=0.015613 \t val_loss=0.016396 \t time=0.83s\n",
      "Best model: Epoch 29 \t loss=0.015535 \t val_loss=0.016383 \t time=0.85s\n",
      "Best model: Epoch 30 \t loss=0.015533 \t val_loss=0.016296 \t time=0.85s\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 35 \t loss=0.014698 \t val_loss=0.016191 \t time=0.85s\n",
      "Best model: Epoch 36 \t loss=0.014388 \t val_loss=0.016121 \t time=0.84s\n",
      "Best model: Epoch 37 \t loss=0.014238 \t val_loss=0.016102 \t time=0.84s\n",
      "Best model: Epoch 38 \t loss=0.014140 \t val_loss=0.016081 \t time=0.83s\n",
      "Best model: Epoch 39 \t loss=0.013953 \t val_loss=0.016027 \t time=0.82s\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.413190 \t val_loss=0.080251 \t time=0.84s\n",
      "Best model: Epoch 2 \t loss=0.048712 \t val_loss=0.027921 \t time=1.18s\n",
      "Best model: Epoch 3 \t loss=0.027481 \t val_loss=0.023775 \t time=0.94s\n",
      "Best model: Epoch 4 \t loss=0.023235 \t val_loss=0.020620 \t time=0.83s\n",
      "Best model: Epoch 5 \t loss=0.021514 \t val_loss=0.020127 \t time=0.83s\n",
      "Best model: Epoch 6 \t loss=0.020926 \t val_loss=0.019363 \t time=1.25s\n",
      "Best model: Epoch 8 \t loss=0.019556 \t val_loss=0.018575 \t time=0.82s\n",
      "Best model: Epoch 9 \t loss=0.019049 \t val_loss=0.018234 \t time=0.97s\n",
      "Best model: Epoch 10 \t loss=0.018450 \t val_loss=0.018063 \t time=1.04s\n",
      "Best model: Epoch 11 \t loss=0.018282 \t val_loss=0.017843 \t time=0.91s\n",
      "Best model: Epoch 12 \t loss=0.018025 \t val_loss=0.017496 \t time=0.89s\n",
      "Best model: Epoch 13 \t loss=0.017615 \t val_loss=0.017311 \t time=1.19s\n",
      "Best model: Epoch 14 \t loss=0.017485 \t val_loss=0.017241 \t time=0.91s\n",
      "Best model: Epoch 15 \t loss=0.017169 \t val_loss=0.017018 \t time=0.95s\n",
      "Best model: Epoch 16 \t loss=0.017123 \t val_loss=0.016941 \t time=0.85s\n",
      "Best model: Epoch 17 \t loss=0.016812 \t val_loss=0.016769 \t time=0.84s\n",
      "Best model: Epoch 18 \t loss=0.016593 \t val_loss=0.016761 \t time=0.85s\n",
      "Best model: Epoch 19 \t loss=0.016309 \t val_loss=0.016620 \t time=0.87s\n",
      "Best model: Epoch 20 \t loss=0.016226 \t val_loss=0.016516 \t time=0.84s\n",
      "Best model: Epoch 22 \t loss=0.015960 \t val_loss=0.016486 \t time=0.83s\n",
      "Best model: Epoch 23 \t loss=0.015990 \t val_loss=0.016397 \t time=0.84s\n",
      "Best model: Epoch 25 \t loss=0.015804 \t val_loss=0.016381 \t time=1.07s\n",
      "Best model: Epoch 27 \t loss=0.015670 \t val_loss=0.016352 \t time=0.87s\n",
      "Best model: Epoch 28 \t loss=0.015485 \t val_loss=0.016303 \t time=0.86s\n",
      "Best model: Epoch 29 \t loss=0.015483 \t val_loss=0.016264 \t time=0.86s\n",
      "Best model: Epoch 30 \t loss=0.015448 \t val_loss=0.016261 \t time=0.85s\n",
      "Best model: Epoch 31 \t loss=0.015331 \t val_loss=0.016247 \t time=0.85s\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 36 \t loss=0.014658 \t val_loss=0.016136 \t time=0.98s\n",
      "Best model: Epoch 37 \t loss=0.014302 \t val_loss=0.016078 \t time=1.06s\n",
      "Best model: Epoch 38 \t loss=0.014071 \t val_loss=0.016062 \t time=0.85s\n",
      "Best model: Epoch 39 \t loss=0.013936 \t val_loss=0.016023 \t time=0.82s\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.413767 \t val_loss=0.081646 \t time=0.84s\n",
      "Best model: Epoch 2 \t loss=0.049415 \t val_loss=0.028332 \t time=0.81s\n",
      "Best model: Epoch 3 \t loss=0.026878 \t val_loss=0.022165 \t time=0.84s\n",
      "Best model: Epoch 4 \t loss=0.023048 \t val_loss=0.020732 \t time=0.81s\n",
      "Best model: Epoch 5 \t loss=0.021624 \t val_loss=0.019999 \t time=0.84s\n",
      "Best model: Epoch 6 \t loss=0.020557 \t val_loss=0.019307 \t time=0.82s\n",
      "Best model: Epoch 7 \t loss=0.019941 \t val_loss=0.018842 \t time=1.04s\n",
      "Best model: Epoch 8 \t loss=0.019389 \t val_loss=0.018431 \t time=0.85s\n",
      "Best model: Epoch 9 \t loss=0.019258 \t val_loss=0.018298 \t time=0.80s\n",
      "Best model: Epoch 10 \t loss=0.018855 \t val_loss=0.018104 \t time=0.81s\n",
      "Best model: Epoch 11 \t loss=0.018511 \t val_loss=0.017856 \t time=0.81s\n",
      "Best model: Epoch 12 \t loss=0.018021 \t val_loss=0.017525 \t time=0.82s\n",
      "Best model: Epoch 13 \t loss=0.017824 \t val_loss=0.017350 \t time=0.81s\n",
      "Best model: Epoch 14 \t loss=0.017605 \t val_loss=0.017207 \t time=0.86s\n",
      "Best model: Epoch 15 \t loss=0.017476 \t val_loss=0.017046 \t time=0.81s\n",
      "Best model: Epoch 16 \t loss=0.017083 \t val_loss=0.016962 \t time=0.80s\n",
      "Best model: Epoch 17 \t loss=0.016912 \t val_loss=0.016819 \t time=0.80s\n",
      "Best model: Epoch 18 \t loss=0.016730 \t val_loss=0.016754 \t time=0.81s\n",
      "Best model: Epoch 19 \t loss=0.016653 \t val_loss=0.016651 \t time=0.94s\n",
      "Best model: Epoch 21 \t loss=0.016465 \t val_loss=0.016641 \t time=0.79s\n",
      "Best model: Epoch 22 \t loss=0.016399 \t val_loss=0.016500 \t time=0.80s\n",
      "Best model: Epoch 23 \t loss=0.016219 \t val_loss=0.016423 \t time=0.80s\n",
      "Best model: Epoch 24 \t loss=0.015991 \t val_loss=0.016413 \t time=0.80s\n",
      "Best model: Epoch 25 \t loss=0.015853 \t val_loss=0.016316 \t time=0.81s\n",
      "Best model: Epoch 29 \t loss=0.015691 \t val_loss=0.016279 \t time=1.20s\n",
      "Best model: Epoch 30 \t loss=0.015550 \t val_loss=0.016240 \t time=1.08s\n",
      "Best model: Epoch 33 \t loss=0.015428 \t val_loss=0.016219 \t time=1.14s\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 38 \t loss=0.014660 \t val_loss=0.016094 \t time=0.83s\n",
      "Best model: Epoch 39 \t loss=0.014423 \t val_loss=0.016029 \t time=0.85s\n",
      "Best model: Epoch 40 \t loss=0.014273 \t val_loss=0.016015 \t time=0.86s\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.415313 \t val_loss=0.084411 \t time=0.95s\n",
      "Best model: Epoch 2 \t loss=0.049036 \t val_loss=0.029780 \t time=0.80s\n",
      "Best model: Epoch 3 \t loss=0.027673 \t val_loss=0.023360 \t time=0.80s\n",
      "Best model: Epoch 4 \t loss=0.023182 \t val_loss=0.020674 \t time=0.80s\n",
      "Best model: Epoch 5 \t loss=0.021532 \t val_loss=0.019658 \t time=0.80s\n",
      "Best model: Epoch 6 \t loss=0.021044 \t val_loss=0.019597 \t time=0.80s\n",
      "Best model: Epoch 7 \t loss=0.020155 \t val_loss=0.018724 \t time=0.80s\n",
      "Best model: Epoch 8 \t loss=0.019694 \t val_loss=0.018205 \t time=0.79s\n",
      "Best model: Epoch 9 \t loss=0.019189 \t val_loss=0.018110 \t time=0.82s\n",
      "Best model: Epoch 10 \t loss=0.018866 \t val_loss=0.017966 \t time=0.79s\n",
      "Best model: Epoch 11 \t loss=0.018415 \t val_loss=0.017545 \t time=0.79s\n",
      "Best model: Epoch 12 \t loss=0.018179 \t val_loss=0.017433 \t time=0.81s\n",
      "Best model: Epoch 13 \t loss=0.017859 \t val_loss=0.017388 \t time=1.00s\n",
      "Best model: Epoch 14 \t loss=0.017504 \t val_loss=0.017101 \t time=0.86s\n",
      "Best model: Epoch 15 \t loss=0.017390 \t val_loss=0.016994 \t time=0.84s\n",
      "Best model: Epoch 17 \t loss=0.017043 \t val_loss=0.016763 \t time=0.82s\n",
      "Best model: Epoch 18 \t loss=0.016944 \t val_loss=0.016713 \t time=0.81s\n",
      "Best model: Epoch 19 \t loss=0.016643 \t val_loss=0.016504 \t time=0.81s\n",
      "Best model: Epoch 20 \t loss=0.016368 \t val_loss=0.016475 \t time=0.81s\n",
      "Best model: Epoch 21 \t loss=0.016351 \t val_loss=0.016462 \t time=0.83s\n",
      "Best model: Epoch 22 \t loss=0.016241 \t val_loss=0.016404 \t time=0.92s\n",
      "Best model: Epoch 23 \t loss=0.016151 \t val_loss=0.016390 \t time=0.83s\n",
      "Best model: Epoch 25 \t loss=0.015991 \t val_loss=0.016271 \t time=0.81s\n",
      "Best model: Epoch 27 \t loss=0.015779 \t val_loss=0.016244 \t time=0.84s\n",
      "Best model: Epoch 28 \t loss=0.015682 \t val_loss=0.016202 \t time=0.86s\n",
      "Best model: Epoch 31 \t loss=0.015531 \t val_loss=0.016171 \t time=0.81s\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 36 \t loss=0.014740 \t val_loss=0.016051 \t time=0.82s\n",
      "Best model: Epoch 37 \t loss=0.014424 \t val_loss=0.015965 \t time=0.81s\n",
      "Best model: Epoch 38 \t loss=0.014260 \t val_loss=0.015943 \t time=0.81s\n",
      "Best model: Epoch 39 \t loss=0.014097 \t val_loss=0.015942 \t time=1.05s\n",
      "Best model: Epoch 40 \t loss=0.013981 \t val_loss=0.015885 \t time=0.81s\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.412712 \t val_loss=0.091216 \t time=0.83s\n",
      "Best model: Epoch 2 \t loss=0.048296 \t val_loss=0.028267 \t time=0.81s\n",
      "Best model: Epoch 3 \t loss=0.027678 \t val_loss=0.024042 \t time=0.81s\n",
      "Best model: Epoch 4 \t loss=0.023277 \t val_loss=0.020834 \t time=0.80s\n",
      "Best model: Epoch 5 \t loss=0.021546 \t val_loss=0.020218 \t time=0.80s\n",
      "Best model: Epoch 6 \t loss=0.020600 \t val_loss=0.019333 \t time=0.80s\n",
      "Best model: Epoch 7 \t loss=0.019981 \t val_loss=0.018891 \t time=0.80s\n",
      "Best model: Epoch 8 \t loss=0.019544 \t val_loss=0.018533 \t time=0.84s\n",
      "Best model: Epoch 9 \t loss=0.019042 \t val_loss=0.018285 \t time=1.03s\n",
      "Best model: Epoch 10 \t loss=0.018665 \t val_loss=0.018043 \t time=0.81s\n",
      "Best model: Epoch 11 \t loss=0.018239 \t val_loss=0.017713 \t time=1.00s\n",
      "Best model: Epoch 12 \t loss=0.018007 \t val_loss=0.017521 \t time=1.02s\n",
      "Best model: Epoch 13 \t loss=0.017647 \t val_loss=0.017289 \t time=0.84s\n",
      "Best model: Epoch 14 \t loss=0.017427 \t val_loss=0.017234 \t time=0.84s\n",
      "Best model: Epoch 15 \t loss=0.017293 \t val_loss=0.017143 \t time=1.12s\n",
      "Best model: Epoch 16 \t loss=0.017119 \t val_loss=0.017123 \t time=1.12s\n",
      "Best model: Epoch 17 \t loss=0.016965 \t val_loss=0.017005 \t time=0.84s\n",
      "Best model: Epoch 18 \t loss=0.016723 \t val_loss=0.016789 \t time=0.83s\n",
      "Best model: Epoch 19 \t loss=0.016677 \t val_loss=0.016711 \t time=0.94s\n",
      "Best model: Epoch 21 \t loss=0.016286 \t val_loss=0.016646 \t time=0.90s\n",
      "Best model: Epoch 22 \t loss=0.016146 \t val_loss=0.016623 \t time=0.82s\n",
      "Best model: Epoch 23 \t loss=0.015995 \t val_loss=0.016576 \t time=0.85s\n",
      "Best model: Epoch 24 \t loss=0.016017 \t val_loss=0.016499 \t time=0.82s\n",
      "Best model: Epoch 27 \t loss=0.015743 \t val_loss=0.016494 \t time=0.82s\n",
      "Best model: Epoch 28 \t loss=0.015717 \t val_loss=0.016413 \t time=0.81s\n",
      "Best model: Epoch 32 \t loss=0.015445 \t val_loss=0.016394 \t time=0.85s\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 37 \t loss=0.014673 \t val_loss=0.016324 \t time=0.81s\n",
      "Best model: Epoch 38 \t loss=0.014354 \t val_loss=0.016249 \t time=0.80s\n",
      "Best model: Epoch 39 \t loss=0.014128 \t val_loss=0.016237 \t time=0.81s\n",
      "Best model: Epoch 40 \t loss=0.013977 \t val_loss=0.016168 \t time=0.81s\n",
      "Seed 0\n",
      "Fold 1 log loss: 0.01612040075566347\n",
      "Fold 2 log loss: 0.016075442668701336\n",
      "Fold 3 log loss: 0.01600695759647269\n",
      "Fold 4 log loss: 0.015941252010922717\n",
      "Fold 5 log loss: 0.016170407113733527\n",
      "Std of log loss: 8.117785459670379e-05\n",
      "Total log loss: 0.01606288655863564\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.412766 \t val_loss=0.079561 \t time=0.81s\n",
      "Best model: Epoch 2 \t loss=0.048779 \t val_loss=0.027908 \t time=0.81s\n",
      "Best model: Epoch 3 \t loss=0.027431 \t val_loss=0.023675 \t time=0.80s\n",
      "Best model: Epoch 4 \t loss=0.023341 \t val_loss=0.021721 \t time=0.83s\n",
      "Best model: Epoch 5 \t loss=0.021438 \t val_loss=0.020163 \t time=0.98s\n",
      "Best model: Epoch 6 \t loss=0.020596 \t val_loss=0.019285 \t time=0.85s\n",
      "Best model: Epoch 7 \t loss=0.020271 \t val_loss=0.019137 \t time=0.88s\n",
      "Best model: Epoch 8 \t loss=0.019435 \t val_loss=0.018491 \t time=0.83s\n",
      "Best model: Epoch 9 \t loss=0.018973 \t val_loss=0.018242 \t time=0.81s\n",
      "Best model: Epoch 11 \t loss=0.018296 \t val_loss=0.017815 \t time=0.84s\n",
      "Best model: Epoch 12 \t loss=0.018076 \t val_loss=0.017496 \t time=1.04s\n",
      "Best model: Epoch 13 \t loss=0.017720 \t val_loss=0.017342 \t time=0.81s\n",
      "Best model: Epoch 14 \t loss=0.017479 \t val_loss=0.017255 \t time=0.84s\n",
      "Best model: Epoch 16 \t loss=0.017024 \t val_loss=0.017052 \t time=0.81s\n",
      "Best model: Epoch 17 \t loss=0.016843 \t val_loss=0.016831 \t time=0.81s\n",
      "Best model: Epoch 19 \t loss=0.016412 \t val_loss=0.016763 \t time=0.79s\n",
      "Best model: Epoch 20 \t loss=0.016329 \t val_loss=0.016607 \t time=0.83s\n",
      "Best model: Epoch 21 \t loss=0.016187 \t val_loss=0.016570 \t time=0.80s\n",
      "Best model: Epoch 22 \t loss=0.016021 \t val_loss=0.016521 \t time=0.79s\n",
      "Best model: Epoch 26 \t loss=0.015651 \t val_loss=0.016425 \t time=0.79s\n",
      "Best model: Epoch 29 \t loss=0.015408 \t val_loss=0.016425 \t time=0.81s\n",
      "Best model: Epoch 30 \t loss=0.015411 \t val_loss=0.016380 \t time=0.83s\n",
      "Best model: Epoch 32 \t loss=0.015315 \t val_loss=0.016328 \t time=0.81s\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 37 \t loss=0.014581 \t val_loss=0.016164 \t time=1.00s\n",
      "Best model: Epoch 38 \t loss=0.014248 \t val_loss=0.016111 \t time=0.91s\n",
      "Best model: Epoch 39 \t loss=0.013993 \t val_loss=0.016098 \t time=0.86s\n",
      "Best model: Epoch 40 \t loss=0.013910 \t val_loss=0.016056 \t time=1.07s\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.414773 \t val_loss=0.083490 \t time=0.83s\n",
      "Best model: Epoch 2 \t loss=0.048283 \t val_loss=0.028798 \t time=0.82s\n",
      "Best model: Epoch 3 \t loss=0.027075 \t val_loss=0.022620 \t time=0.85s\n",
      "Best model: Epoch 4 \t loss=0.023056 \t val_loss=0.021269 \t time=0.97s\n",
      "Best model: Epoch 5 \t loss=0.021534 \t val_loss=0.019996 \t time=0.87s\n",
      "Best model: Epoch 6 \t loss=0.020723 \t val_loss=0.019455 \t time=0.84s\n",
      "Best model: Epoch 7 \t loss=0.019962 \t val_loss=0.018982 \t time=0.80s\n",
      "Best model: Epoch 8 \t loss=0.019391 \t val_loss=0.018337 \t time=0.84s\n",
      "Best model: Epoch 9 \t loss=0.019161 \t val_loss=0.018301 \t time=0.81s\n",
      "Best model: Epoch 10 \t loss=0.018844 \t val_loss=0.017902 \t time=0.80s\n",
      "Best model: Epoch 11 \t loss=0.018250 \t val_loss=0.017589 \t time=0.82s\n",
      "Best model: Epoch 12 \t loss=0.017950 \t val_loss=0.017406 \t time=0.81s\n",
      "Best model: Epoch 13 \t loss=0.017812 \t val_loss=0.017302 \t time=0.82s\n",
      "Best model: Epoch 14 \t loss=0.017431 \t val_loss=0.017072 \t time=0.84s\n",
      "Best model: Epoch 15 \t loss=0.017281 \t val_loss=0.016919 \t time=0.81s\n",
      "Best model: Epoch 18 \t loss=0.016811 \t val_loss=0.016778 \t time=0.81s\n",
      "Best model: Epoch 19 \t loss=0.016600 \t val_loss=0.016676 \t time=0.80s\n",
      "Best model: Epoch 20 \t loss=0.016386 \t val_loss=0.016600 \t time=0.83s\n",
      "Best model: Epoch 21 \t loss=0.016265 \t val_loss=0.016575 \t time=0.79s\n",
      "Best model: Epoch 22 \t loss=0.016073 \t val_loss=0.016508 \t time=0.79s\n",
      "Best model: Epoch 23 \t loss=0.016059 \t val_loss=0.016461 \t time=0.79s\n",
      "Best model: Epoch 24 \t loss=0.015881 \t val_loss=0.016388 \t time=0.80s\n",
      "Best model: Epoch 27 \t loss=0.015627 \t val_loss=0.016361 \t time=0.81s\n",
      "Best model: Epoch 29 \t loss=0.015622 \t val_loss=0.016278 \t time=0.78s\n",
      "Best model: Epoch 31 \t loss=0.015415 \t val_loss=0.016268 \t time=0.82s\n",
      "Best model: Epoch 32 \t loss=0.015339 \t val_loss=0.016239 \t time=0.84s\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 37 \t loss=0.014685 \t val_loss=0.016160 \t time=0.78s\n",
      "Best model: Epoch 38 \t loss=0.014345 \t val_loss=0.016058 \t time=0.83s\n",
      "Best model: Epoch 40 \t loss=0.013985 \t val_loss=0.016042 \t time=0.79s\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.413650 \t val_loss=0.081184 \t time=0.81s\n",
      "Best model: Epoch 2 \t loss=0.048987 \t val_loss=0.030389 \t time=0.78s\n",
      "Best model: Epoch 3 \t loss=0.027074 \t val_loss=0.022555 \t time=0.77s\n",
      "Best model: Epoch 4 \t loss=0.023324 \t val_loss=0.020899 \t time=0.78s\n",
      "Best model: Epoch 5 \t loss=0.021552 \t val_loss=0.020068 \t time=0.82s\n",
      "Best model: Epoch 6 \t loss=0.020620 \t val_loss=0.019335 \t time=0.81s\n",
      "Best model: Epoch 7 \t loss=0.020134 \t val_loss=0.019076 \t time=0.80s\n",
      "Best model: Epoch 8 \t loss=0.019448 \t val_loss=0.018516 \t time=0.85s\n",
      "Best model: Epoch 9 \t loss=0.019107 \t val_loss=0.018366 \t time=0.80s\n",
      "Best model: Epoch 10 \t loss=0.018622 \t val_loss=0.017898 \t time=0.80s\n",
      "Best model: Epoch 11 \t loss=0.018168 \t val_loss=0.017713 \t time=0.80s\n",
      "Best model: Epoch 12 \t loss=0.018185 \t val_loss=0.017452 \t time=0.81s\n",
      "Best model: Epoch 13 \t loss=0.017880 \t val_loss=0.017402 \t time=1.03s\n",
      "Best model: Epoch 14 \t loss=0.017533 \t val_loss=0.017142 \t time=0.84s\n",
      "Best model: Epoch 15 \t loss=0.017306 \t val_loss=0.017032 \t time=0.99s\n",
      "Best model: Epoch 16 \t loss=0.017021 \t val_loss=0.016847 \t time=1.00s\n",
      "Best model: Epoch 18 \t loss=0.016942 \t val_loss=0.016838 \t time=0.80s\n",
      "Best model: Epoch 19 \t loss=0.016759 \t val_loss=0.016720 \t time=1.10s\n",
      "Best model: Epoch 20 \t loss=0.016529 \t val_loss=0.016533 \t time=0.80s\n",
      "Best model: Epoch 21 \t loss=0.016360 \t val_loss=0.016528 \t time=0.89s\n",
      "Best model: Epoch 22 \t loss=0.016161 \t val_loss=0.016358 \t time=0.82s\n",
      "Best model: Epoch 25 \t loss=0.015874 \t val_loss=0.016310 \t time=1.07s\n",
      "Best model: Epoch 29 \t loss=0.015548 \t val_loss=0.016297 \t time=0.77s\n",
      "Best model: Epoch 30 \t loss=0.015553 \t val_loss=0.016215 \t time=0.85s\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 35 \t loss=0.014784 \t val_loss=0.016119 \t time=0.79s\n",
      "Best model: Epoch 36 \t loss=0.014449 \t val_loss=0.016042 \t time=0.78s\n",
      "Best model: Epoch 37 \t loss=0.014330 \t val_loss=0.016006 \t time=0.78s\n",
      "Best model: Epoch 38 \t loss=0.014093 \t val_loss=0.015981 \t time=1.03s\n",
      "Best model: Epoch 39 \t loss=0.013968 \t val_loss=0.015971 \t time=0.82s\n",
      "Best model: Epoch 40 \t loss=0.013792 \t val_loss=0.015960 \t time=0.83s\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.413795 \t val_loss=0.074537 \t time=0.79s\n",
      "Best model: Epoch 2 \t loss=0.048744 \t val_loss=0.028212 \t time=0.78s\n",
      "Best model: Epoch 3 \t loss=0.027717 \t val_loss=0.022908 \t time=0.78s\n",
      "Best model: Epoch 4 \t loss=0.023472 \t val_loss=0.021124 \t time=0.78s\n",
      "Best model: Epoch 5 \t loss=0.021921 \t val_loss=0.020605 \t time=0.77s\n",
      "Best model: Epoch 6 \t loss=0.021015 \t val_loss=0.019296 \t time=0.77s\n",
      "Best model: Epoch 7 \t loss=0.019966 \t val_loss=0.018627 \t time=0.77s\n",
      "Best model: Epoch 8 \t loss=0.019427 \t val_loss=0.018214 \t time=0.98s\n",
      "Best model: Epoch 9 \t loss=0.019183 \t val_loss=0.017990 \t time=0.80s\n",
      "Best model: Epoch 11 \t loss=0.018694 \t val_loss=0.017537 \t time=0.77s\n",
      "Best model: Epoch 12 \t loss=0.018274 \t val_loss=0.017369 \t time=0.78s\n",
      "Best model: Epoch 13 \t loss=0.017901 \t val_loss=0.017185 \t time=0.78s\n",
      "Best model: Epoch 14 \t loss=0.017664 \t val_loss=0.017162 \t time=0.77s\n",
      "Best model: Epoch 15 \t loss=0.017536 \t val_loss=0.016955 \t time=0.77s\n",
      "Best model: Epoch 16 \t loss=0.017173 \t val_loss=0.016788 \t time=0.85s\n",
      "Best model: Epoch 17 \t loss=0.017074 \t val_loss=0.016689 \t time=0.77s\n",
      "Best model: Epoch 18 \t loss=0.016751 \t val_loss=0.016601 \t time=0.77s\n",
      "Best model: Epoch 19 \t loss=0.016581 \t val_loss=0.016511 \t time=0.77s\n",
      "Best model: Epoch 20 \t loss=0.016525 \t val_loss=0.016467 \t time=0.80s\n",
      "Best model: Epoch 21 \t loss=0.016351 \t val_loss=0.016418 \t time=0.99s\n",
      "Best model: Epoch 22 \t loss=0.016300 \t val_loss=0.016375 \t time=0.97s\n",
      "Best model: Epoch 23 \t loss=0.016101 \t val_loss=0.016306 \t time=0.77s\n",
      "Best model: Epoch 26 \t loss=0.015854 \t val_loss=0.016229 \t time=0.76s\n",
      "Best model: Epoch 28 \t loss=0.015597 \t val_loss=0.016226 \t time=0.80s\n",
      "Best model: Epoch 29 \t loss=0.015523 \t val_loss=0.016187 \t time=0.77s\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 34 \t loss=0.014667 \t val_loss=0.016015 \t time=0.76s\n",
      "Best model: Epoch 35 \t loss=0.014475 \t val_loss=0.015950 \t time=1.00s\n",
      "Best model: Epoch 36 \t loss=0.014271 \t val_loss=0.015932 \t time=0.78s\n",
      "Best model: Epoch 37 \t loss=0.014072 \t val_loss=0.015927 \t time=0.77s\n",
      "Best model: Epoch 38 \t loss=0.013946 \t val_loss=0.015907 \t time=0.77s\n",
      "Best model: Epoch 40 \t loss=0.013703 \t val_loss=0.015907 \t time=0.78s\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.413827 \t val_loss=0.078522 \t time=1.12s\n",
      "Best model: Epoch 2 \t loss=0.050069 \t val_loss=0.029413 \t time=0.79s\n",
      "Best model: Epoch 3 \t loss=0.027333 \t val_loss=0.022248 \t time=0.78s\n",
      "Best model: Epoch 4 \t loss=0.023392 \t val_loss=0.020844 \t time=1.20s\n",
      "Best model: Epoch 5 \t loss=0.021701 \t val_loss=0.020824 \t time=0.88s\n",
      "Best model: Epoch 6 \t loss=0.020560 \t val_loss=0.019323 \t time=0.81s\n",
      "Best model: Epoch 7 \t loss=0.019871 \t val_loss=0.018844 \t time=0.79s\n",
      "Best model: Epoch 8 \t loss=0.019389 \t val_loss=0.018519 \t time=0.82s\n",
      "Best model: Epoch 9 \t loss=0.019050 \t val_loss=0.018424 \t time=0.87s\n",
      "Best model: Epoch 10 \t loss=0.018651 \t val_loss=0.017868 \t time=0.80s\n",
      "Best model: Epoch 11 \t loss=0.018315 \t val_loss=0.017622 \t time=0.80s\n",
      "Best model: Epoch 12 \t loss=0.018095 \t val_loss=0.017529 \t time=0.79s\n",
      "Best model: Epoch 13 \t loss=0.017849 \t val_loss=0.017420 \t time=0.81s\n",
      "Best model: Epoch 14 \t loss=0.017649 \t val_loss=0.017348 \t time=0.83s\n",
      "Best model: Epoch 15 \t loss=0.017443 \t val_loss=0.017194 \t time=0.95s\n",
      "Best model: Epoch 16 \t loss=0.017084 \t val_loss=0.016967 \t time=0.83s\n",
      "Best model: Epoch 18 \t loss=0.016699 \t val_loss=0.016788 \t time=0.77s\n",
      "Best model: Epoch 19 \t loss=0.016499 \t val_loss=0.016735 \t time=0.78s\n",
      "Best model: Epoch 20 \t loss=0.016410 \t val_loss=0.016690 \t time=0.83s\n",
      "Best model: Epoch 22 \t loss=0.016115 \t val_loss=0.016589 \t time=0.80s\n",
      "Best model: Epoch 23 \t loss=0.016025 \t val_loss=0.016534 \t time=0.79s\n",
      "Best model: Epoch 24 \t loss=0.015843 \t val_loss=0.016532 \t time=0.79s\n",
      "Best model: Epoch 25 \t loss=0.015890 \t val_loss=0.016457 \t time=0.79s\n",
      "Best model: Epoch 26 \t loss=0.015769 \t val_loss=0.016418 \t time=0.83s\n",
      "Best model: Epoch 29 \t loss=0.015531 \t val_loss=0.016382 \t time=0.79s\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 34 \t loss=0.014725 \t val_loss=0.016246 \t time=0.78s\n",
      "Best model: Epoch 35 \t loss=0.014361 \t val_loss=0.016234 \t time=0.77s\n",
      "Best model: Epoch 36 \t loss=0.014181 \t val_loss=0.016148 \t time=0.79s\n",
      "Best model: Epoch 37 \t loss=0.014030 \t val_loss=0.016116 \t time=0.78s\n",
      "Best model: Epoch 38 \t loss=0.013875 \t val_loss=0.016105 \t time=0.78s\n",
      "Seed 1\n",
      "Fold 1 log loss: 0.016161327527585343\n",
      "Fold 2 log loss: 0.0160992537367054\n",
      "Fold 3 log loss: 0.015951520852747987\n",
      "Fold 4 log loss: 0.015961468076995555\n",
      "Fold 5 log loss: 0.01610542097130225\n",
      "Std of log loss: 8.397520984032056e-05\n",
      "Total log loss: 0.016055793992214296\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.415869 \t val_loss=0.076559 \t time=0.80s\n",
      "Best model: Epoch 2 \t loss=0.049595 \t val_loss=0.027955 \t time=0.81s\n",
      "Best model: Epoch 3 \t loss=0.027354 \t val_loss=0.022139 \t time=0.79s\n",
      "Best model: Epoch 4 \t loss=0.023503 \t val_loss=0.021084 \t time=0.79s\n",
      "Best model: Epoch 5 \t loss=0.021434 \t val_loss=0.020134 \t time=0.81s\n",
      "Best model: Epoch 6 \t loss=0.020657 \t val_loss=0.019595 \t time=0.89s\n",
      "Best model: Epoch 7 \t loss=0.019900 \t val_loss=0.019082 \t time=0.92s\n",
      "Best model: Epoch 9 \t loss=0.019113 \t val_loss=0.018369 \t time=0.84s\n",
      "Best model: Epoch 10 \t loss=0.018751 \t val_loss=0.018021 \t time=1.08s\n",
      "Best model: Epoch 11 \t loss=0.018423 \t val_loss=0.017777 \t time=0.83s\n",
      "Best model: Epoch 12 \t loss=0.018038 \t val_loss=0.017460 \t time=0.85s\n",
      "Best model: Epoch 14 \t loss=0.017516 \t val_loss=0.017356 \t time=0.80s\n",
      "Best model: Epoch 15 \t loss=0.017222 \t val_loss=0.017027 \t time=0.77s\n",
      "Best model: Epoch 16 \t loss=0.017083 \t val_loss=0.017009 \t time=0.78s\n",
      "Best model: Epoch 17 \t loss=0.016808 \t val_loss=0.016880 \t time=0.77s\n",
      "Best model: Epoch 18 \t loss=0.016685 \t val_loss=0.016779 \t time=0.77s\n",
      "Best model: Epoch 19 \t loss=0.016533 \t val_loss=0.016753 \t time=0.77s\n",
      "Best model: Epoch 20 \t loss=0.016378 \t val_loss=0.016647 \t time=0.77s\n",
      "Best model: Epoch 22 \t loss=0.016167 \t val_loss=0.016586 \t time=0.81s\n",
      "Best model: Epoch 23 \t loss=0.016001 \t val_loss=0.016572 \t time=0.98s\n",
      "Best model: Epoch 24 \t loss=0.015875 \t val_loss=0.016547 \t time=1.14s\n",
      "Best model: Epoch 25 \t loss=0.015756 \t val_loss=0.016445 \t time=0.78s\n",
      "Best model: Epoch 26 \t loss=0.015672 \t val_loss=0.016386 \t time=0.79s\n",
      "Best model: Epoch 28 \t loss=0.015649 \t val_loss=0.016360 \t time=1.00s\n",
      "Best model: Epoch 29 \t loss=0.015515 \t val_loss=0.016349 \t time=0.81s\n",
      "Best model: Epoch 30 \t loss=0.015372 \t val_loss=0.016319 \t time=0.85s\n",
      "Best model: Epoch 31 \t loss=0.015374 \t val_loss=0.016310 \t time=0.81s\n",
      "Best model: Epoch 35 \t loss=0.015194 \t val_loss=0.016302 \t time=1.12s\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 40 \t loss=0.014479 \t val_loss=0.016169 \t time=0.84s\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.413105 \t val_loss=0.085657 \t time=0.88s\n",
      "Best model: Epoch 2 \t loss=0.048649 \t val_loss=0.028306 \t time=0.78s\n",
      "Best model: Epoch 3 \t loss=0.027051 \t val_loss=0.022554 \t time=0.82s\n",
      "Best model: Epoch 4 \t loss=0.023445 \t val_loss=0.021120 \t time=0.78s\n",
      "Best model: Epoch 5 \t loss=0.021482 \t val_loss=0.020063 \t time=1.00s\n",
      "Best model: Epoch 6 \t loss=0.020892 \t val_loss=0.019342 \t time=0.80s\n",
      "Best model: Epoch 7 \t loss=0.019757 \t val_loss=0.018720 \t time=0.82s\n",
      "Best model: Epoch 8 \t loss=0.019363 \t val_loss=0.018411 \t time=0.78s\n",
      "Best model: Epoch 9 \t loss=0.019271 \t val_loss=0.018371 \t time=0.79s\n",
      "Best model: Epoch 10 \t loss=0.018781 \t val_loss=0.017907 \t time=0.80s\n",
      "Best model: Epoch 11 \t loss=0.018471 \t val_loss=0.017805 \t time=0.77s\n",
      "Best model: Epoch 12 \t loss=0.018311 \t val_loss=0.017478 \t time=0.78s\n",
      "Best model: Epoch 13 \t loss=0.017910 \t val_loss=0.017272 \t time=0.80s\n",
      "Best model: Epoch 15 \t loss=0.017229 \t val_loss=0.016960 \t time=0.80s\n",
      "Best model: Epoch 17 \t loss=0.017094 \t val_loss=0.016904 \t time=0.78s\n",
      "Best model: Epoch 18 \t loss=0.016789 \t val_loss=0.016821 \t time=1.01s\n",
      "Best model: Epoch 19 \t loss=0.016576 \t val_loss=0.016685 \t time=0.82s\n",
      "Best model: Epoch 20 \t loss=0.016336 \t val_loss=0.016645 \t time=0.80s\n",
      "Best model: Epoch 21 \t loss=0.016291 \t val_loss=0.016550 \t time=0.85s\n",
      "Best model: Epoch 23 \t loss=0.016102 \t val_loss=0.016467 \t time=0.80s\n",
      "Best model: Epoch 24 \t loss=0.015995 \t val_loss=0.016450 \t time=0.82s\n",
      "Best model: Epoch 25 \t loss=0.015852 \t val_loss=0.016361 \t time=0.81s\n",
      "Best model: Epoch 27 \t loss=0.015695 \t val_loss=0.016360 \t time=0.84s\n",
      "Best model: Epoch 28 \t loss=0.015660 \t val_loss=0.016355 \t time=0.83s\n",
      "Best model: Epoch 29 \t loss=0.015566 \t val_loss=0.016257 \t time=0.82s\n",
      "Best model: Epoch 30 \t loss=0.015566 \t val_loss=0.016250 \t time=1.05s\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 35 \t loss=0.014674 \t val_loss=0.016077 \t time=0.89s\n",
      "Best model: Epoch 37 \t loss=0.014171 \t val_loss=0.016010 \t time=0.78s\n",
      "Best model: Epoch 38 \t loss=0.014113 \t val_loss=0.015984 \t time=0.78s\n",
      "Best model: Epoch 39 \t loss=0.014034 \t val_loss=0.015975 \t time=0.79s\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.409957 \t val_loss=0.080477 \t time=0.83s\n",
      "Best model: Epoch 2 \t loss=0.050062 \t val_loss=0.029009 \t time=0.82s\n",
      "Best model: Epoch 3 \t loss=0.027705 \t val_loss=0.023088 \t time=0.83s\n",
      "Best model: Epoch 4 \t loss=0.023326 \t val_loss=0.021020 \t time=0.81s\n",
      "Best model: Epoch 5 \t loss=0.021566 \t val_loss=0.019973 \t time=0.81s\n",
      "Best model: Epoch 6 \t loss=0.020652 \t val_loss=0.019472 \t time=0.98s\n",
      "Best model: Epoch 7 \t loss=0.020003 \t val_loss=0.019007 \t time=1.09s\n",
      "Best model: Epoch 8 \t loss=0.019672 \t val_loss=0.018606 \t time=0.90s\n",
      "Best model: Epoch 10 \t loss=0.018711 \t val_loss=0.017975 \t time=0.85s\n",
      "Best model: Epoch 11 \t loss=0.018401 \t val_loss=0.017815 \t time=1.39s\n",
      "Best model: Epoch 12 \t loss=0.018037 \t val_loss=0.017577 \t time=0.89s\n",
      "Best model: Epoch 13 \t loss=0.017813 \t val_loss=0.017248 \t time=0.85s\n",
      "Best model: Epoch 14 \t loss=0.017620 \t val_loss=0.017227 \t time=0.86s\n",
      "Best model: Epoch 15 \t loss=0.017408 \t val_loss=0.017045 \t time=0.83s\n",
      "Best model: Epoch 16 \t loss=0.017192 \t val_loss=0.016916 \t time=0.90s\n",
      "Best model: Epoch 17 \t loss=0.017006 \t val_loss=0.016875 \t time=0.84s\n",
      "Best model: Epoch 18 \t loss=0.016795 \t val_loss=0.016762 \t time=0.83s\n",
      "Best model: Epoch 19 \t loss=0.016627 \t val_loss=0.016705 \t time=0.87s\n",
      "Best model: Epoch 20 \t loss=0.016451 \t val_loss=0.016559 \t time=0.83s\n",
      "Best model: Epoch 21 \t loss=0.016426 \t val_loss=0.016517 \t time=0.83s\n",
      "Best model: Epoch 22 \t loss=0.016223 \t val_loss=0.016457 \t time=0.83s\n",
      "Best model: Epoch 23 \t loss=0.016169 \t val_loss=0.016412 \t time=1.05s\n",
      "Best model: Epoch 24 \t loss=0.016030 \t val_loss=0.016345 \t time=0.81s\n",
      "Best model: Epoch 26 \t loss=0.015805 \t val_loss=0.016331 \t time=0.83s\n",
      "Best model: Epoch 27 \t loss=0.015775 \t val_loss=0.016283 \t time=0.89s\n",
      "Best model: Epoch 29 \t loss=0.015545 \t val_loss=0.016264 \t time=0.82s\n",
      "Best model: Epoch 30 \t loss=0.015579 \t val_loss=0.016206 \t time=0.81s\n",
      "Best model: Epoch 31 \t loss=0.015428 \t val_loss=0.016185 \t time=0.82s\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 36 \t loss=0.014699 \t val_loss=0.016056 \t time=0.98s\n",
      "Best model: Epoch 37 \t loss=0.014471 \t val_loss=0.015992 \t time=0.82s\n",
      "Best model: Epoch 38 \t loss=0.014190 \t val_loss=0.015957 \t time=0.81s\n",
      "Best model: Epoch 39 \t loss=0.014054 \t val_loss=0.015947 \t time=0.82s\n",
      "Best model: Epoch 40 \t loss=0.013978 \t val_loss=0.015911 \t time=0.80s\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.412177 \t val_loss=0.079757 \t time=0.80s\n",
      "Best model: Epoch 2 \t loss=0.049428 \t val_loss=0.029701 \t time=0.79s\n",
      "Best model: Epoch 3 \t loss=0.028111 \t val_loss=0.022984 \t time=0.78s\n",
      "Best model: Epoch 4 \t loss=0.023273 \t val_loss=0.020765 \t time=0.79s\n",
      "Best model: Epoch 5 \t loss=0.021679 \t val_loss=0.019898 \t time=0.85s\n",
      "Best model: Epoch 6 \t loss=0.020815 \t val_loss=0.019217 \t time=0.92s\n",
      "Best model: Epoch 7 \t loss=0.019944 \t val_loss=0.018622 \t time=0.80s\n",
      "Best model: Epoch 8 \t loss=0.019821 \t val_loss=0.018289 \t time=0.83s\n",
      "Best model: Epoch 9 \t loss=0.019082 \t val_loss=0.017993 \t time=0.78s\n",
      "Best model: Epoch 10 \t loss=0.018776 \t val_loss=0.017916 \t time=0.79s\n",
      "Best model: Epoch 11 \t loss=0.018629 \t val_loss=0.017558 \t time=0.79s\n",
      "Best model: Epoch 12 \t loss=0.018251 \t val_loss=0.017427 \t time=0.79s\n",
      "Best model: Epoch 13 \t loss=0.017935 \t val_loss=0.017300 \t time=0.80s\n",
      "Best model: Epoch 14 \t loss=0.017658 \t val_loss=0.017039 \t time=0.82s\n",
      "Best model: Epoch 15 \t loss=0.017360 \t val_loss=0.016951 \t time=0.78s\n",
      "Best model: Epoch 16 \t loss=0.017091 \t val_loss=0.016784 \t time=0.80s\n",
      "Best model: Epoch 18 \t loss=0.016870 \t val_loss=0.016639 \t time=0.83s\n",
      "Best model: Epoch 19 \t loss=0.016610 \t val_loss=0.016603 \t time=0.94s\n",
      "Best model: Epoch 20 \t loss=0.016373 \t val_loss=0.016479 \t time=0.89s\n",
      "Best model: Epoch 21 \t loss=0.016349 \t val_loss=0.016397 \t time=0.79s\n",
      "Best model: Epoch 22 \t loss=0.016147 \t val_loss=0.016361 \t time=0.95s\n",
      "Best model: Epoch 24 \t loss=0.015967 \t val_loss=0.016284 \t time=0.79s\n",
      "Best model: Epoch 27 \t loss=0.015633 \t val_loss=0.016278 \t time=0.78s\n",
      "Best model: Epoch 28 \t loss=0.015647 \t val_loss=0.016206 \t time=0.81s\n",
      "Best model: Epoch 29 \t loss=0.015567 \t val_loss=0.016166 \t time=0.79s\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 34 \t loss=0.014756 \t val_loss=0.016009 \t time=0.81s\n",
      "Best model: Epoch 35 \t loss=0.014463 \t val_loss=0.015949 \t time=0.82s\n",
      "Best model: Epoch 37 \t loss=0.014077 \t val_loss=0.015930 \t time=1.08s\n",
      "Best model: Epoch 38 \t loss=0.013959 \t val_loss=0.015921 \t time=0.81s\n",
      "Best model: Epoch 40 \t loss=0.013760 \t val_loss=0.015909 \t time=0.82s\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.412655 \t val_loss=0.080654 \t time=0.87s\n",
      "Best model: Epoch 2 \t loss=0.049769 \t val_loss=0.028184 \t time=0.79s\n",
      "Best model: Epoch 3 \t loss=0.027551 \t val_loss=0.023240 \t time=0.78s\n",
      "Best model: Epoch 4 \t loss=0.023350 \t val_loss=0.021050 \t time=0.79s\n",
      "Best model: Epoch 5 \t loss=0.021585 \t val_loss=0.020006 \t time=0.80s\n",
      "Best model: Epoch 7 \t loss=0.020173 \t val_loss=0.019036 \t time=0.78s\n",
      "Best model: Epoch 8 \t loss=0.019572 \t val_loss=0.018686 \t time=0.80s\n",
      "Best model: Epoch 9 \t loss=0.019165 \t val_loss=0.018467 \t time=0.80s\n",
      "Best model: Epoch 10 \t loss=0.018682 \t val_loss=0.018067 \t time=0.82s\n",
      "Best model: Epoch 11 \t loss=0.018559 \t val_loss=0.017763 \t time=0.79s\n",
      "Best model: Epoch 12 \t loss=0.018123 \t val_loss=0.017608 \t time=0.89s\n",
      "Best model: Epoch 13 \t loss=0.017846 \t val_loss=0.017524 \t time=1.05s\n",
      "Best model: Epoch 14 \t loss=0.017697 \t val_loss=0.017459 \t time=0.96s\n",
      "Best model: Epoch 15 \t loss=0.017483 \t val_loss=0.017207 \t time=0.81s\n",
      "Best model: Epoch 16 \t loss=0.017158 \t val_loss=0.017097 \t time=0.84s\n",
      "Best model: Epoch 17 \t loss=0.016868 \t val_loss=0.016944 \t time=0.80s\n",
      "Best model: Epoch 18 \t loss=0.016827 \t val_loss=0.016847 \t time=0.81s\n",
      "Best model: Epoch 19 \t loss=0.016591 \t val_loss=0.016762 \t time=0.82s\n",
      "Best model: Epoch 20 \t loss=0.016334 \t val_loss=0.016687 \t time=0.79s\n",
      "Best model: Epoch 21 \t loss=0.016250 \t val_loss=0.016678 \t time=0.80s\n",
      "Best model: Epoch 22 \t loss=0.016118 \t val_loss=0.016562 \t time=0.82s\n",
      "Best model: Epoch 23 \t loss=0.015993 \t val_loss=0.016556 \t time=0.79s\n",
      "Best model: Epoch 25 \t loss=0.015862 \t val_loss=0.016524 \t time=0.81s\n",
      "Best model: Epoch 27 \t loss=0.015625 \t val_loss=0.016479 \t time=0.82s\n",
      "Best model: Epoch 28 \t loss=0.015610 \t val_loss=0.016448 \t time=0.84s\n",
      "Best model: Epoch 29 \t loss=0.015479 \t val_loss=0.016399 \t time=0.82s\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 34 \t loss=0.014678 \t val_loss=0.016267 \t time=0.81s\n",
      "Best model: Epoch 35 \t loss=0.014372 \t val_loss=0.016219 \t time=0.79s\n",
      "Best model: Epoch 36 \t loss=0.014249 \t val_loss=0.016179 \t time=0.78s\n",
      "Best model: Epoch 37 \t loss=0.014025 \t val_loss=0.016176 \t time=0.79s\n",
      "Best model: Epoch 38 \t loss=0.013910 \t val_loss=0.016167 \t time=0.81s\n",
      "Best model: Epoch 39 \t loss=0.013743 \t val_loss=0.016164 \t time=0.95s\n",
      "Best model: Epoch 40 \t loss=0.013640 \t val_loss=0.016143 \t time=0.79s\n",
      "Seed 2\n",
      "Fold 1 log loss: 0.016270561077666418\n",
      "Fold 2 log loss: 0.01603936807605551\n",
      "Fold 3 log loss: 0.015906923807861958\n",
      "Fold 4 log loss: 0.015961962293421412\n",
      "Fold 5 log loss: 0.01614767126043937\n",
      "Std of log loss: 0.00013065320434747427\n",
      "Total log loss: 0.0160652947313407\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.412863 \t val_loss=0.078868 \t time=0.78s\n",
      "Best model: Epoch 2 \t loss=0.048751 \t val_loss=0.030543 \t time=0.86s\n",
      "Best model: Epoch 3 \t loss=0.027762 \t val_loss=0.023937 \t time=0.78s\n",
      "Best model: Epoch 4 \t loss=0.023204 \t val_loss=0.021470 \t time=0.82s\n",
      "Best model: Epoch 5 \t loss=0.021608 \t val_loss=0.020142 \t time=0.79s\n",
      "Best model: Epoch 6 \t loss=0.020807 \t val_loss=0.019736 \t time=1.21s\n",
      "Best model: Epoch 7 \t loss=0.019988 \t val_loss=0.018883 \t time=0.81s\n",
      "Best model: Epoch 8 \t loss=0.019738 \t val_loss=0.018747 \t time=0.84s\n",
      "Best model: Epoch 9 \t loss=0.019092 \t val_loss=0.018221 \t time=0.79s\n",
      "Best model: Epoch 10 \t loss=0.018570 \t val_loss=0.017981 \t time=0.81s\n",
      "Best model: Epoch 12 \t loss=0.018113 \t val_loss=0.017551 \t time=0.94s\n",
      "Best model: Epoch 13 \t loss=0.017673 \t val_loss=0.017300 \t time=0.97s\n",
      "Best model: Epoch 14 \t loss=0.017457 \t val_loss=0.017209 \t time=0.84s\n",
      "Best model: Epoch 15 \t loss=0.017265 \t val_loss=0.017110 \t time=0.84s\n",
      "Best model: Epoch 16 \t loss=0.017058 \t val_loss=0.016951 \t time=0.86s\n",
      "Best model: Epoch 17 \t loss=0.016828 \t val_loss=0.016912 \t time=0.92s\n",
      "Best model: Epoch 18 \t loss=0.016640 \t val_loss=0.016791 \t time=0.94s\n",
      "Best model: Epoch 19 \t loss=0.016496 \t val_loss=0.016743 \t time=0.92s\n",
      "Best model: Epoch 20 \t loss=0.016316 \t val_loss=0.016656 \t time=0.90s\n",
      "Best model: Epoch 24 \t loss=0.015985 \t val_loss=0.016433 \t time=0.78s\n",
      "Best model: Epoch 26 \t loss=0.015701 \t val_loss=0.016418 \t time=0.78s\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 31 \t loss=0.014811 \t val_loss=0.016188 \t time=0.83s\n",
      "Best model: Epoch 32 \t loss=0.014536 \t val_loss=0.016152 \t time=0.80s\n",
      "Best model: Epoch 33 \t loss=0.014410 \t val_loss=0.016119 \t time=0.79s\n",
      "Best model: Epoch 35 \t loss=0.014075 \t val_loss=0.016042 \t time=0.77s\n",
      "Best model: Epoch 38 \t loss=0.013752 \t val_loss=0.016034 \t time=0.79s\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.409684 \t val_loss=0.091866 \t time=0.96s\n",
      "Best model: Epoch 2 \t loss=0.048901 \t val_loss=0.030757 \t time=0.83s\n",
      "Best model: Epoch 3 \t loss=0.027241 \t val_loss=0.022378 \t time=0.83s\n",
      "Best model: Epoch 4 \t loss=0.023219 \t val_loss=0.020981 \t time=0.83s\n",
      "Best model: Epoch 5 \t loss=0.021722 \t val_loss=0.020082 \t time=0.79s\n",
      "Best model: Epoch 6 \t loss=0.020550 \t val_loss=0.019428 \t time=0.78s\n",
      "Best model: Epoch 7 \t loss=0.020011 \t val_loss=0.019093 \t time=0.77s\n",
      "Best model: Epoch 8 \t loss=0.019575 \t val_loss=0.018672 \t time=0.78s\n",
      "Best model: Epoch 9 \t loss=0.019030 \t val_loss=0.018245 \t time=0.83s\n",
      "Best model: Epoch 10 \t loss=0.018619 \t val_loss=0.017959 \t time=0.80s\n",
      "Best model: Epoch 11 \t loss=0.018406 \t val_loss=0.017584 \t time=0.85s\n",
      "Best model: Epoch 12 \t loss=0.017926 \t val_loss=0.017360 \t time=0.82s\n",
      "Best model: Epoch 13 \t loss=0.017710 \t val_loss=0.017208 \t time=1.01s\n",
      "Best model: Epoch 14 \t loss=0.017590 \t val_loss=0.017061 \t time=0.81s\n",
      "Best model: Epoch 17 \t loss=0.016885 \t val_loss=0.016835 \t time=0.81s\n",
      "Best model: Epoch 18 \t loss=0.016624 \t val_loss=0.016746 \t time=0.81s\n",
      "Best model: Epoch 19 \t loss=0.016456 \t val_loss=0.016631 \t time=0.82s\n",
      "Best model: Epoch 20 \t loss=0.016340 \t val_loss=0.016583 \t time=0.84s\n",
      "Best model: Epoch 21 \t loss=0.016292 \t val_loss=0.016542 \t time=0.83s\n",
      "Best model: Epoch 22 \t loss=0.016108 \t val_loss=0.016484 \t time=0.83s\n",
      "Best model: Epoch 24 \t loss=0.016031 \t val_loss=0.016377 \t time=0.78s\n",
      "Best model: Epoch 28 \t loss=0.015545 \t val_loss=0.016363 \t time=0.78s\n",
      "Best model: Epoch 29 \t loss=0.015549 \t val_loss=0.016343 \t time=0.78s\n",
      "Best model: Epoch 31 \t loss=0.015416 \t val_loss=0.016297 \t time=0.78s\n",
      "Best model: Epoch 35 \t loss=0.015302 \t val_loss=0.016277 \t time=0.93s\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 40 \t loss=0.014555 \t val_loss=0.016120 \t time=0.80s\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.416533 \t val_loss=0.081754 \t time=0.81s\n",
      "Best model: Epoch 2 \t loss=0.049490 \t val_loss=0.029278 \t time=0.92s\n",
      "Best model: Epoch 3 \t loss=0.026691 \t val_loss=0.022657 \t time=0.82s\n",
      "Best model: Epoch 4 \t loss=0.023528 \t val_loss=0.021823 \t time=0.82s\n",
      "Best model: Epoch 5 \t loss=0.021801 \t val_loss=0.020397 \t time=0.80s\n",
      "Best model: Epoch 6 \t loss=0.020565 \t val_loss=0.019468 \t time=0.80s\n",
      "Best model: Epoch 7 \t loss=0.020161 \t val_loss=0.019280 \t time=0.87s\n",
      "Best model: Epoch 8 \t loss=0.019491 \t val_loss=0.018699 \t time=0.94s\n",
      "Best model: Epoch 9 \t loss=0.019293 \t val_loss=0.018179 \t time=0.82s\n",
      "Best model: Epoch 10 \t loss=0.018870 \t val_loss=0.017968 \t time=0.79s\n",
      "Best model: Epoch 11 \t loss=0.018414 \t val_loss=0.017534 \t time=0.83s\n",
      "Best model: Epoch 13 \t loss=0.017881 \t val_loss=0.017312 \t time=0.79s\n",
      "Best model: Epoch 14 \t loss=0.017505 \t val_loss=0.017236 \t time=0.78s\n",
      "Best model: Epoch 15 \t loss=0.017398 \t val_loss=0.017119 \t time=0.79s\n",
      "Best model: Epoch 16 \t loss=0.017084 \t val_loss=0.016839 \t time=0.79s\n",
      "Best model: Epoch 18 \t loss=0.016674 \t val_loss=0.016637 \t time=0.80s\n",
      "Best model: Epoch 19 \t loss=0.016536 \t val_loss=0.016617 \t time=0.78s\n",
      "Best model: Epoch 20 \t loss=0.016367 \t val_loss=0.016546 \t time=0.86s\n",
      "Best model: Epoch 21 \t loss=0.016431 \t val_loss=0.016473 \t time=0.94s\n",
      "Best model: Epoch 23 \t loss=0.015998 \t val_loss=0.016432 \t time=0.80s\n",
      "Best model: Epoch 25 \t loss=0.015882 \t val_loss=0.016306 \t time=0.82s\n",
      "Best model: Epoch 26 \t loss=0.015741 \t val_loss=0.016272 \t time=0.83s\n",
      "Best model: Epoch 27 \t loss=0.015684 \t val_loss=0.016244 \t time=0.87s\n",
      "Best model: Epoch 28 \t loss=0.015562 \t val_loss=0.016230 \t time=0.84s\n",
      "Best model: Epoch 32 \t loss=0.015411 \t val_loss=0.016213 \t time=0.78s\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 37 \t loss=0.014639 \t val_loss=0.016070 \t time=0.80s\n",
      "Best model: Epoch 38 \t loss=0.014347 \t val_loss=0.016002 \t time=0.78s\n",
      "Best model: Epoch 40 \t loss=0.013946 \t val_loss=0.015996 \t time=0.78s\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.409906 \t val_loss=0.082902 \t time=0.78s\n",
      "Best model: Epoch 2 \t loss=0.048586 \t val_loss=0.028831 \t time=0.78s\n",
      "Best model: Epoch 3 \t loss=0.027978 \t val_loss=0.022802 \t time=0.79s\n",
      "Best model: Epoch 4 \t loss=0.023207 \t val_loss=0.020737 \t time=0.97s\n",
      "Best model: Epoch 5 \t loss=0.021687 \t val_loss=0.020091 \t time=0.80s\n",
      "Best model: Epoch 6 \t loss=0.020785 \t val_loss=0.019225 \t time=0.83s\n",
      "Best model: Epoch 7 \t loss=0.019992 \t val_loss=0.018502 \t time=0.78s\n",
      "Best model: Epoch 8 \t loss=0.019334 \t val_loss=0.018224 \t time=0.80s\n",
      "Best model: Epoch 9 \t loss=0.019696 \t val_loss=0.018114 \t time=0.81s\n",
      "Best model: Epoch 10 \t loss=0.018705 \t val_loss=0.017618 \t time=0.78s\n",
      "Best model: Epoch 11 \t loss=0.018418 \t val_loss=0.017464 \t time=0.78s\n",
      "Best model: Epoch 12 \t loss=0.017947 \t val_loss=0.017220 \t time=0.78s\n",
      "Best model: Epoch 13 \t loss=0.017883 \t val_loss=0.017189 \t time=0.79s\n",
      "Best model: Epoch 14 \t loss=0.017565 \t val_loss=0.017002 \t time=0.78s\n",
      "Best model: Epoch 15 \t loss=0.017338 \t val_loss=0.016907 \t time=0.79s\n",
      "Best model: Epoch 16 \t loss=0.017217 \t val_loss=0.016775 \t time=0.82s\n",
      "Best model: Epoch 17 \t loss=0.016924 \t val_loss=0.016621 \t time=0.97s\n",
      "Best model: Epoch 18 \t loss=0.016778 \t val_loss=0.016503 \t time=0.95s\n",
      "Best model: Epoch 21 \t loss=0.016405 \t val_loss=0.016417 \t time=1.20s\n",
      "Best model: Epoch 22 \t loss=0.016236 \t val_loss=0.016339 \t time=0.94s\n",
      "Best model: Epoch 23 \t loss=0.016116 \t val_loss=0.016261 \t time=0.81s\n",
      "Best model: Epoch 24 \t loss=0.015893 \t val_loss=0.016208 \t time=0.94s\n",
      "Best model: Epoch 25 \t loss=0.015813 \t val_loss=0.016189 \t time=0.90s\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 30 \t loss=0.014932 \t val_loss=0.016078 \t time=0.80s\n",
      "Best model: Epoch 31 \t loss=0.014769 \t val_loss=0.015974 \t time=0.88s\n",
      "Best model: Epoch 32 \t loss=0.014510 \t val_loss=0.015974 \t time=0.79s\n",
      "Best model: Epoch 33 \t loss=0.014356 \t val_loss=0.015916 \t time=0.79s\n",
      "Best model: Epoch 34 \t loss=0.014265 \t val_loss=0.015900 \t time=0.79s\n",
      "Best model: Epoch 36 \t loss=0.014029 \t val_loss=0.015892 \t time=0.77s\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.410816 \t val_loss=0.072817 \t time=0.78s\n",
      "Best model: Epoch 2 \t loss=0.050357 \t val_loss=0.029387 \t time=0.77s\n",
      "Best model: Epoch 3 \t loss=0.027431 \t val_loss=0.022462 \t time=0.77s\n",
      "Best model: Epoch 4 \t loss=0.022774 \t val_loss=0.020978 \t time=0.78s\n",
      "Best model: Epoch 5 \t loss=0.021559 \t val_loss=0.019895 \t time=0.77s\n",
      "Best model: Epoch 6 \t loss=0.020656 \t val_loss=0.019429 \t time=0.78s\n",
      "Best model: Epoch 7 \t loss=0.019938 \t val_loss=0.019066 \t time=0.78s\n",
      "Best model: Epoch 8 \t loss=0.020326 \t val_loss=0.019058 \t time=0.77s\n",
      "Best model: Epoch 9 \t loss=0.020009 \t val_loss=0.018489 \t time=0.82s\n",
      "Best model: Epoch 10 \t loss=0.018909 \t val_loss=0.018003 \t time=0.79s\n",
      "Best model: Epoch 11 \t loss=0.018460 \t val_loss=0.017815 \t time=0.90s\n",
      "Best model: Epoch 12 \t loss=0.018097 \t val_loss=0.017557 \t time=0.99s\n",
      "Best model: Epoch 13 \t loss=0.017637 \t val_loss=0.017334 \t time=0.79s\n",
      "Best model: Epoch 14 \t loss=0.017438 \t val_loss=0.017212 \t time=0.85s\n",
      "Best model: Epoch 15 \t loss=0.017236 \t val_loss=0.017189 \t time=0.78s\n",
      "Best model: Epoch 16 \t loss=0.017093 \t val_loss=0.016962 \t time=0.93s\n",
      "Best model: Epoch 18 \t loss=0.016665 \t val_loss=0.016807 \t time=0.77s\n",
      "Best model: Epoch 19 \t loss=0.016461 \t val_loss=0.016803 \t time=0.78s\n",
      "Best model: Epoch 20 \t loss=0.016260 \t val_loss=0.016720 \t time=0.78s\n",
      "Best model: Epoch 21 \t loss=0.016154 \t val_loss=0.016577 \t time=0.84s\n",
      "Best model: Epoch 22 \t loss=0.016067 \t val_loss=0.016522 \t time=0.77s\n",
      "Best model: Epoch 25 \t loss=0.015827 \t val_loss=0.016460 \t time=0.88s\n",
      "Best model: Epoch 26 \t loss=0.015638 \t val_loss=0.016442 \t time=0.77s\n",
      "Best model: Epoch 29 \t loss=0.015398 \t val_loss=0.016437 \t time=0.77s\n",
      "Best model: Epoch 31 \t loss=0.015336 \t val_loss=0.016388 \t time=0.77s\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 35 \t loss=0.015204 \t val_loss=0.016387 \t time=0.76s\n",
      "Best model: Epoch 36 \t loss=0.014438 \t val_loss=0.016241 \t time=0.78s\n",
      "Best model: Epoch 37 \t loss=0.014191 \t val_loss=0.016152 \t time=0.78s\n",
      "Best model: Epoch 38 \t loss=0.013968 \t val_loss=0.016118 \t time=0.98s\n",
      "Best model: Epoch 39 \t loss=0.013776 \t val_loss=0.016099 \t time=0.76s\n",
      "Best model: Epoch 40 \t loss=0.013699 \t val_loss=0.016074 \t time=0.77s\n",
      "Seed 3\n",
      "Fold 1 log loss: 0.01613569424632052\n",
      "Fold 2 log loss: 0.016176246832287043\n",
      "Fold 3 log loss: 0.01599319787182994\n",
      "Fold 4 log loss: 0.015948939795549295\n",
      "Fold 5 log loss: 0.016082576420584797\n",
      "Std of log loss: 8.51831119443617e-05\n",
      "Total log loss: 0.0160673253762528\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.415064 \t val_loss=0.076259 \t time=0.78s\n",
      "Best model: Epoch 2 \t loss=0.050389 \t val_loss=0.030108 \t time=1.31s\n",
      "Best model: Epoch 3 \t loss=0.027883 \t val_loss=0.023260 \t time=0.80s\n",
      "Best model: Epoch 4 \t loss=0.023005 \t val_loss=0.021026 \t time=0.84s\n",
      "Best model: Epoch 5 \t loss=0.021702 \t val_loss=0.020073 \t time=1.30s\n",
      "Best model: Epoch 6 \t loss=0.020519 \t val_loss=0.019555 \t time=0.82s\n",
      "Best model: Epoch 7 \t loss=0.019828 \t val_loss=0.018967 \t time=1.01s\n",
      "Best model: Epoch 8 \t loss=0.019467 \t val_loss=0.018532 \t time=0.79s\n",
      "Best model: Epoch 10 \t loss=0.018843 \t val_loss=0.017987 \t time=0.87s\n",
      "Best model: Epoch 11 \t loss=0.018340 \t val_loss=0.017825 \t time=0.84s\n",
      "Best model: Epoch 12 \t loss=0.017986 \t val_loss=0.017529 \t time=0.88s\n",
      "Best model: Epoch 14 \t loss=0.017452 \t val_loss=0.017240 \t time=0.78s\n",
      "Best model: Epoch 15 \t loss=0.017250 \t val_loss=0.017158 \t time=0.79s\n",
      "Best model: Epoch 16 \t loss=0.017022 \t val_loss=0.017026 \t time=0.99s\n",
      "Best model: Epoch 17 \t loss=0.016770 \t val_loss=0.016850 \t time=0.84s\n",
      "Best model: Epoch 18 \t loss=0.016732 \t val_loss=0.016796 \t time=0.80s\n",
      "Best model: Epoch 19 \t loss=0.016472 \t val_loss=0.016760 \t time=0.80s\n",
      "Best model: Epoch 20 \t loss=0.016411 \t val_loss=0.016630 \t time=0.78s\n",
      "Best model: Epoch 21 \t loss=0.016261 \t val_loss=0.016485 \t time=0.80s\n",
      "Best model: Epoch 23 \t loss=0.015997 \t val_loss=0.016463 \t time=0.77s\n",
      "Best model: Epoch 24 \t loss=0.015907 \t val_loss=0.016451 \t time=0.79s\n",
      "Best model: Epoch 25 \t loss=0.015823 \t val_loss=0.016431 \t time=0.78s\n",
      "Best model: Epoch 26 \t loss=0.015585 \t val_loss=0.016376 \t time=0.82s\n",
      "Best model: Epoch 30 \t loss=0.015408 \t val_loss=0.016364 \t time=0.89s\n",
      "Best model: Epoch 31 \t loss=0.015353 \t val_loss=0.016356 \t time=0.79s\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 36 \t loss=0.014564 \t val_loss=0.016197 \t time=0.78s\n",
      "Best model: Epoch 37 \t loss=0.014302 \t val_loss=0.016187 \t time=0.90s\n",
      "Best model: Epoch 38 \t loss=0.014003 \t val_loss=0.016114 \t time=0.79s\n",
      "Best model: Epoch 40 \t loss=0.013768 \t val_loss=0.016090 \t time=0.76s\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.410637 \t val_loss=0.085871 \t time=0.80s\n",
      "Best model: Epoch 2 \t loss=0.050125 \t val_loss=0.028487 \t time=0.98s\n",
      "Best model: Epoch 3 \t loss=0.027378 \t val_loss=0.023669 \t time=0.79s\n",
      "Best model: Epoch 4 \t loss=0.023339 \t val_loss=0.020953 \t time=0.78s\n",
      "Best model: Epoch 5 \t loss=0.021576 \t val_loss=0.019947 \t time=0.80s\n",
      "Best model: Epoch 6 \t loss=0.020623 \t val_loss=0.019269 \t time=0.80s\n",
      "Best model: Epoch 7 \t loss=0.019824 \t val_loss=0.018833 \t time=0.78s\n",
      "Best model: Epoch 8 \t loss=0.019512 \t val_loss=0.018453 \t time=0.78s\n",
      "Best model: Epoch 9 \t loss=0.018931 \t val_loss=0.018186 \t time=0.79s\n",
      "Best model: Epoch 10 \t loss=0.018747 \t val_loss=0.017931 \t time=0.83s\n",
      "Best model: Epoch 11 \t loss=0.018558 \t val_loss=0.017487 \t time=0.78s\n",
      "Best model: Epoch 12 \t loss=0.018067 \t val_loss=0.017429 \t time=0.78s\n",
      "Best model: Epoch 13 \t loss=0.017667 \t val_loss=0.017197 \t time=1.00s\n",
      "Best model: Epoch 14 \t loss=0.017805 \t val_loss=0.017171 \t time=0.80s\n",
      "Best model: Epoch 15 \t loss=0.017358 \t val_loss=0.017022 \t time=0.78s\n",
      "Best model: Epoch 16 \t loss=0.017062 \t val_loss=0.016900 \t time=0.82s\n",
      "Best model: Epoch 17 \t loss=0.016913 \t val_loss=0.016835 \t time=0.78s\n",
      "Best model: Epoch 18 \t loss=0.016718 \t val_loss=0.016747 \t time=0.78s\n",
      "Best model: Epoch 19 \t loss=0.016579 \t val_loss=0.016720 \t time=0.78s\n",
      "Best model: Epoch 20 \t loss=0.016440 \t val_loss=0.016601 \t time=0.78s\n",
      "Best model: Epoch 21 \t loss=0.016208 \t val_loss=0.016576 \t time=0.77s\n",
      "Best model: Epoch 22 \t loss=0.016205 \t val_loss=0.016501 \t time=0.80s\n",
      "Best model: Epoch 23 \t loss=0.016097 \t val_loss=0.016425 \t time=0.80s\n",
      "Best model: Epoch 24 \t loss=0.015997 \t val_loss=0.016394 \t time=0.78s\n",
      "Best model: Epoch 25 \t loss=0.015875 \t val_loss=0.016312 \t time=0.79s\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 30 \t loss=0.014956 \t val_loss=0.016147 \t time=0.99s\n",
      "Best model: Epoch 31 \t loss=0.014657 \t val_loss=0.016103 \t time=0.78s\n",
      "Best model: Epoch 32 \t loss=0.014483 \t val_loss=0.016067 \t time=0.79s\n",
      "Best model: Epoch 33 \t loss=0.014349 \t val_loss=0.016016 \t time=0.77s\n",
      "Best model: Epoch 35 \t loss=0.014128 \t val_loss=0.016003 \t time=0.95s\n",
      "Best model: Epoch 37 \t loss=0.013842 \t val_loss=0.015970 \t time=0.86s\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.413213 \t val_loss=0.079729 \t time=0.77s\n",
      "Best model: Epoch 2 \t loss=0.049745 \t val_loss=0.029520 \t time=0.78s\n",
      "Best model: Epoch 3 \t loss=0.027019 \t val_loss=0.022417 \t time=0.77s\n",
      "Best model: Epoch 4 \t loss=0.023154 \t val_loss=0.020863 \t time=0.78s\n",
      "Best model: Epoch 5 \t loss=0.021512 \t val_loss=0.019870 \t time=0.77s\n",
      "Best model: Epoch 6 \t loss=0.020636 \t val_loss=0.019706 \t time=0.78s\n",
      "Best model: Epoch 7 \t loss=0.020148 \t val_loss=0.018856 \t time=0.78s\n",
      "Best model: Epoch 8 \t loss=0.019539 \t val_loss=0.018518 \t time=0.83s\n",
      "Best model: Epoch 9 \t loss=0.018993 \t val_loss=0.018137 \t time=0.89s\n",
      "Best model: Epoch 10 \t loss=0.018805 \t val_loss=0.018117 \t time=0.78s\n",
      "Best model: Epoch 11 \t loss=0.018421 \t val_loss=0.017772 \t time=0.77s\n",
      "Best model: Epoch 12 \t loss=0.018028 \t val_loss=0.017527 \t time=0.78s\n",
      "Best model: Epoch 13 \t loss=0.017828 \t val_loss=0.017335 \t time=0.77s\n",
      "Best model: Epoch 14 \t loss=0.017640 \t val_loss=0.017212 \t time=0.78s\n",
      "Best model: Epoch 15 \t loss=0.017271 \t val_loss=0.016986 \t time=0.82s\n",
      "Best model: Epoch 16 \t loss=0.017083 \t val_loss=0.016853 \t time=0.78s\n",
      "Best model: Epoch 18 \t loss=0.016762 \t val_loss=0.016699 \t time=0.77s\n",
      "Best model: Epoch 19 \t loss=0.016505 \t val_loss=0.016660 \t time=0.78s\n",
      "Best model: Epoch 21 \t loss=0.016434 \t val_loss=0.016482 \t time=0.78s\n",
      "Best model: Epoch 22 \t loss=0.016277 \t val_loss=0.016461 \t time=1.02s\n",
      "Best model: Epoch 23 \t loss=0.016095 \t val_loss=0.016378 \t time=0.91s\n",
      "Best model: Epoch 24 \t loss=0.016034 \t val_loss=0.016354 \t time=0.76s\n",
      "Best model: Epoch 26 \t loss=0.015771 \t val_loss=0.016303 \t time=0.80s\n",
      "Best model: Epoch 30 \t loss=0.015495 \t val_loss=0.016264 \t time=0.81s\n",
      "Best model: Epoch 31 \t loss=0.015386 \t val_loss=0.016198 \t time=0.80s\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 36 \t loss=0.014660 \t val_loss=0.016110 \t time=0.81s\n",
      "Best model: Epoch 37 \t loss=0.014398 \t val_loss=0.016002 \t time=0.79s\n",
      "Best model: Epoch 38 \t loss=0.014221 \t val_loss=0.015987 \t time=0.79s\n",
      "Best model: Epoch 39 \t loss=0.014042 \t val_loss=0.015984 \t time=0.78s\n",
      "Best model: Epoch 40 \t loss=0.013944 \t val_loss=0.015981 \t time=0.78s\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.418001 \t val_loss=0.079323 \t time=0.79s\n",
      "Best model: Epoch 2 \t loss=0.049462 \t val_loss=0.028509 \t time=0.79s\n",
      "Best model: Epoch 3 \t loss=0.027742 \t val_loss=0.023061 \t time=0.78s\n",
      "Best model: Epoch 4 \t loss=0.023300 \t val_loss=0.020504 \t time=0.98s\n",
      "Best model: Epoch 5 \t loss=0.021840 \t val_loss=0.020098 \t time=0.79s\n",
      "Best model: Epoch 7 \t loss=0.020220 \t val_loss=0.018546 \t time=0.78s\n",
      "Best model: Epoch 8 \t loss=0.019639 \t val_loss=0.018400 \t time=0.81s\n",
      "Best model: Epoch 9 \t loss=0.019365 \t val_loss=0.018091 \t time=0.80s\n",
      "Best model: Epoch 10 \t loss=0.018940 \t val_loss=0.017865 \t time=0.78s\n",
      "Best model: Epoch 11 \t loss=0.018482 \t val_loss=0.017490 \t time=0.78s\n",
      "Best model: Epoch 12 \t loss=0.018008 \t val_loss=0.017240 \t time=0.77s\n",
      "Best model: Epoch 14 \t loss=0.017526 \t val_loss=0.016996 \t time=1.17s\n",
      "Best model: Epoch 15 \t loss=0.017292 \t val_loss=0.016823 \t time=0.82s\n",
      "Best model: Epoch 16 \t loss=0.017198 \t val_loss=0.016686 \t time=1.41s\n",
      "Best model: Epoch 18 \t loss=0.016786 \t val_loss=0.016562 \t time=0.79s\n",
      "Best model: Epoch 19 \t loss=0.016589 \t val_loss=0.016448 \t time=0.82s\n",
      "Best model: Epoch 20 \t loss=0.016421 \t val_loss=0.016374 \t time=0.78s\n",
      "Best model: Epoch 22 \t loss=0.016213 \t val_loss=0.016255 \t time=0.83s\n",
      "Best model: Epoch 25 \t loss=0.015863 \t val_loss=0.016218 \t time=0.82s\n",
      "Best model: Epoch 27 \t loss=0.015709 \t val_loss=0.016188 \t time=0.90s\n",
      "Best model: Epoch 28 \t loss=0.015629 \t val_loss=0.016162 \t time=1.04s\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 32 \t loss=0.015400 \t val_loss=0.016161 \t time=0.80s\n",
      "Best model: Epoch 33 \t loss=0.014823 \t val_loss=0.016014 \t time=0.82s\n",
      "Best model: Epoch 34 \t loss=0.014532 \t val_loss=0.015980 \t time=0.81s\n",
      "Best model: Epoch 35 \t loss=0.014296 \t val_loss=0.015909 \t time=0.81s\n",
      "Best model: Epoch 37 \t loss=0.014045 \t val_loss=0.015887 \t time=0.80s\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.410223 \t val_loss=0.074664 \t time=0.77s\n",
      "Best model: Epoch 2 \t loss=0.049392 \t val_loss=0.028881 \t time=0.79s\n",
      "Best model: Epoch 3 \t loss=0.027426 \t val_loss=0.022602 \t time=0.77s\n",
      "Best model: Epoch 4 \t loss=0.023585 \t val_loss=0.020938 \t time=0.78s\n",
      "Best model: Epoch 5 \t loss=0.021658 \t val_loss=0.020080 \t time=0.80s\n",
      "Best model: Epoch 6 \t loss=0.020585 \t val_loss=0.019409 \t time=0.79s\n",
      "Best model: Epoch 7 \t loss=0.020008 \t val_loss=0.018823 \t time=0.78s\n",
      "Best model: Epoch 9 \t loss=0.019061 \t val_loss=0.018414 \t time=0.77s\n",
      "Best model: Epoch 10 \t loss=0.018797 \t val_loss=0.018041 \t time=0.93s\n",
      "Best model: Epoch 11 \t loss=0.018273 \t val_loss=0.017777 \t time=0.97s\n",
      "Best model: Epoch 12 \t loss=0.018088 \t val_loss=0.017661 \t time=0.85s\n",
      "Best model: Epoch 13 \t loss=0.017831 \t val_loss=0.017548 \t time=0.82s\n",
      "Best model: Epoch 14 \t loss=0.017618 \t val_loss=0.017384 \t time=0.79s\n",
      "Best model: Epoch 15 \t loss=0.017353 \t val_loss=0.017091 \t time=0.78s\n",
      "Best model: Epoch 16 \t loss=0.017062 \t val_loss=0.016995 \t time=0.79s\n",
      "Best model: Epoch 17 \t loss=0.016972 \t val_loss=0.016914 \t time=0.83s\n",
      "Best model: Epoch 18 \t loss=0.016732 \t val_loss=0.016823 \t time=0.81s\n",
      "Best model: Epoch 19 \t loss=0.016499 \t val_loss=0.016743 \t time=0.79s\n",
      "Best model: Epoch 20 \t loss=0.016370 \t val_loss=0.016714 \t time=0.93s\n",
      "Best model: Epoch 21 \t loss=0.016350 \t val_loss=0.016640 \t time=0.80s\n",
      "Best model: Epoch 23 \t loss=0.016046 \t val_loss=0.016594 \t time=0.83s\n",
      "Best model: Epoch 24 \t loss=0.015864 \t val_loss=0.016541 \t time=1.03s\n",
      "Best model: Epoch 27 \t loss=0.015676 \t val_loss=0.016432 \t time=0.78s\n",
      "Best model: Epoch 30 \t loss=0.015392 \t val_loss=0.016409 \t time=0.80s\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 35 \t loss=0.014685 \t val_loss=0.016290 \t time=0.78s\n",
      "Best model: Epoch 36 \t loss=0.014342 \t val_loss=0.016218 \t time=0.77s\n",
      "Best model: Epoch 38 \t loss=0.013993 \t val_loss=0.016183 \t time=0.97s\n",
      "Best model: Epoch 39 \t loss=0.013849 \t val_loss=0.016180 \t time=0.78s\n",
      "Best model: Epoch 40 \t loss=0.013745 \t val_loss=0.016167 \t time=1.11s\n",
      "Seed 4\n",
      "Fold 1 log loss: 0.01618747392094121\n",
      "Fold 2 log loss: 0.01602449796242946\n",
      "Fold 3 log loss: 0.01596871523966361\n",
      "Fold 4 log loss: 0.015948510543870677\n",
      "Fold 5 log loss: 0.01616399941321857\n",
      "Std of log loss: 9.907514672763061e-05\n",
      "Total log loss: 0.01605863617114847\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.413015 \t val_loss=0.081460 \t time=1.12s\n",
      "Best model: Epoch 2 \t loss=0.048955 \t val_loss=0.030996 \t time=0.89s\n",
      "Best model: Epoch 3 \t loss=0.028129 \t val_loss=0.023408 \t time=0.97s\n",
      "Best model: Epoch 4 \t loss=0.023249 \t val_loss=0.021423 \t time=0.95s\n",
      "Best model: Epoch 5 \t loss=0.021629 \t val_loss=0.020116 \t time=0.78s\n",
      "Best model: Epoch 6 \t loss=0.020734 \t val_loss=0.019458 \t time=0.79s\n",
      "Best model: Epoch 7 \t loss=0.020304 \t val_loss=0.019046 \t time=0.90s\n",
      "Best model: Epoch 8 \t loss=0.019447 \t val_loss=0.018886 \t time=0.80s\n",
      "Best model: Epoch 9 \t loss=0.019112 \t val_loss=0.018439 \t time=0.78s\n",
      "Best model: Epoch 10 \t loss=0.018615 \t val_loss=0.018031 \t time=0.93s\n",
      "Best model: Epoch 11 \t loss=0.018305 \t val_loss=0.017732 \t time=0.78s\n",
      "Best model: Epoch 12 \t loss=0.017926 \t val_loss=0.017524 \t time=0.77s\n",
      "Best model: Epoch 14 \t loss=0.017607 \t val_loss=0.017247 \t time=0.78s\n",
      "Best model: Epoch 15 \t loss=0.017275 \t val_loss=0.017077 \t time=0.78s\n",
      "Best model: Epoch 16 \t loss=0.017069 \t val_loss=0.017019 \t time=1.01s\n",
      "Best model: Epoch 17 \t loss=0.016811 \t val_loss=0.016878 \t time=0.78s\n",
      "Best model: Epoch 18 \t loss=0.016663 \t val_loss=0.016718 \t time=0.77s\n",
      "Best model: Epoch 20 \t loss=0.016344 \t val_loss=0.016664 \t time=0.77s\n",
      "Best model: Epoch 21 \t loss=0.016237 \t val_loss=0.016597 \t time=0.77s\n",
      "Best model: Epoch 23 \t loss=0.016012 \t val_loss=0.016526 \t time=0.76s\n",
      "Best model: Epoch 24 \t loss=0.015965 \t val_loss=0.016410 \t time=0.77s\n",
      "Best model: Epoch 27 \t loss=0.015662 \t val_loss=0.016409 \t time=0.78s\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 29 \t loss=0.015042 \t val_loss=0.016221 \t time=0.86s\n",
      "Best model: Epoch 30 \t loss=0.014719 \t val_loss=0.016186 \t time=0.92s\n",
      "Best model: Epoch 31 \t loss=0.014541 \t val_loss=0.016158 \t time=0.79s\n",
      "Best model: Epoch 32 \t loss=0.014383 \t val_loss=0.016122 \t time=0.78s\n",
      "Best model: Epoch 33 \t loss=0.014255 \t val_loss=0.016091 \t time=0.77s\n",
      "Best model: Epoch 34 \t loss=0.014202 \t val_loss=0.016072 \t time=0.80s\n",
      "Best model: Epoch 35 \t loss=0.014029 \t val_loss=0.016061 \t time=0.78s\n",
      "Best model: Epoch 36 \t loss=0.013898 \t val_loss=0.016034 \t time=0.78s\n",
      "Best model: Epoch 37 \t loss=0.013790 \t val_loss=0.016034 \t time=0.97s\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.412023 \t val_loss=0.077150 \t time=0.78s\n",
      "Best model: Epoch 2 \t loss=0.048501 \t val_loss=0.027724 \t time=0.78s\n",
      "Best model: Epoch 3 \t loss=0.027512 \t val_loss=0.023328 \t time=0.80s\n",
      "Best model: Epoch 4 \t loss=0.023196 \t val_loss=0.021132 \t time=0.80s\n",
      "Best model: Epoch 5 \t loss=0.021811 \t val_loss=0.020225 \t time=0.92s\n",
      "Best model: Epoch 6 \t loss=0.020627 \t val_loss=0.019277 \t time=0.85s\n",
      "Best model: Epoch 7 \t loss=0.020218 \t val_loss=0.019156 \t time=0.81s\n",
      "Best model: Epoch 8 \t loss=0.019554 \t val_loss=0.018488 \t time=0.77s\n",
      "Best model: Epoch 9 \t loss=0.019009 \t val_loss=0.018180 \t time=0.78s\n",
      "Best model: Epoch 10 \t loss=0.018552 \t val_loss=0.017802 \t time=0.77s\n",
      "Best model: Epoch 12 \t loss=0.018088 \t val_loss=0.017564 \t time=0.76s\n",
      "Best model: Epoch 13 \t loss=0.017742 \t val_loss=0.017218 \t time=0.95s\n",
      "Best model: Epoch 14 \t loss=0.017528 \t val_loss=0.017050 \t time=0.77s\n",
      "Best model: Epoch 16 \t loss=0.017071 \t val_loss=0.016945 \t time=0.76s\n",
      "Best model: Epoch 17 \t loss=0.016891 \t val_loss=0.016790 \t time=0.79s\n",
      "Best model: Epoch 19 \t loss=0.016637 \t val_loss=0.016668 \t time=0.79s\n",
      "Best model: Epoch 20 \t loss=0.016479 \t val_loss=0.016607 \t time=0.77s\n",
      "Best model: Epoch 22 \t loss=0.016172 \t val_loss=0.016516 \t time=0.91s\n",
      "Best model: Epoch 24 \t loss=0.015880 \t val_loss=0.016395 \t time=0.81s\n",
      "Best model: Epoch 26 \t loss=0.015764 \t val_loss=0.016350 \t time=0.84s\n",
      "Best model: Epoch 27 \t loss=0.015626 \t val_loss=0.016303 \t time=0.82s\n",
      "Best model: Epoch 29 \t loss=0.015592 \t val_loss=0.016288 \t time=0.83s\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 34 \t loss=0.014759 \t val_loss=0.016163 \t time=0.78s\n",
      "Best model: Epoch 35 \t loss=0.014479 \t val_loss=0.016075 \t time=0.81s\n",
      "Best model: Epoch 36 \t loss=0.014318 \t val_loss=0.016053 \t time=0.79s\n",
      "Best model: Epoch 38 \t loss=0.013973 \t val_loss=0.016038 \t time=1.04s\n",
      "Best model: Epoch 39 \t loss=0.013864 \t val_loss=0.016038 \t time=0.80s\n",
      "Best model: Epoch 40 \t loss=0.013759 \t val_loss=0.015995 \t time=0.77s\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.412506 \t val_loss=0.077411 \t time=0.79s\n",
      "Best model: Epoch 2 \t loss=0.048638 \t val_loss=0.030213 \t time=0.80s\n",
      "Best model: Epoch 3 \t loss=0.027274 \t val_loss=0.022288 \t time=0.79s\n",
      "Best model: Epoch 4 \t loss=0.023217 \t val_loss=0.021791 \t time=0.78s\n",
      "Best model: Epoch 5 \t loss=0.021665 \t val_loss=0.020073 \t time=0.78s\n",
      "Best model: Epoch 6 \t loss=0.020530 \t val_loss=0.019245 \t time=0.78s\n",
      "Best model: Epoch 7 \t loss=0.019896 \t val_loss=0.019072 \t time=0.79s\n",
      "Best model: Epoch 8 \t loss=0.019441 \t val_loss=0.018365 \t time=1.05s\n",
      "Best model: Epoch 9 \t loss=0.019119 \t val_loss=0.018192 \t time=0.79s\n",
      "Best model: Epoch 10 \t loss=0.018772 \t val_loss=0.017834 \t time=0.81s\n",
      "Best model: Epoch 11 \t loss=0.018393 \t val_loss=0.017718 \t time=0.79s\n",
      "Best model: Epoch 12 \t loss=0.018065 \t val_loss=0.017349 \t time=0.79s\n",
      "Best model: Epoch 14 \t loss=0.017610 \t val_loss=0.017247 \t time=0.82s\n",
      "Best model: Epoch 15 \t loss=0.017309 \t val_loss=0.016977 \t time=0.78s\n",
      "Best model: Epoch 16 \t loss=0.017035 \t val_loss=0.016927 \t time=0.77s\n",
      "Best model: Epoch 17 \t loss=0.016871 \t val_loss=0.016767 \t time=0.77s\n",
      "Best model: Epoch 19 \t loss=0.016461 \t val_loss=0.016601 \t time=0.76s\n",
      "Best model: Epoch 20 \t loss=0.016410 \t val_loss=0.016564 \t time=0.78s\n",
      "Best model: Epoch 21 \t loss=0.016279 \t val_loss=0.016506 \t time=0.97s\n",
      "Best model: Epoch 22 \t loss=0.016208 \t val_loss=0.016497 \t time=0.94s\n",
      "Best model: Epoch 23 \t loss=0.016048 \t val_loss=0.016410 \t time=0.98s\n",
      "Best model: Epoch 24 \t loss=0.015887 \t val_loss=0.016336 \t time=0.82s\n",
      "Best model: Epoch 26 \t loss=0.015816 \t val_loss=0.016334 \t time=0.80s\n",
      "Best model: Epoch 27 \t loss=0.015648 \t val_loss=0.016301 \t time=0.79s\n",
      "Best model: Epoch 30 \t loss=0.015503 \t val_loss=0.016269 \t time=0.77s\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 35 \t loss=0.014656 \t val_loss=0.016116 \t time=0.80s\n",
      "Best model: Epoch 36 \t loss=0.014387 \t val_loss=0.016051 \t time=0.91s\n",
      "Best model: Epoch 37 \t loss=0.014246 \t val_loss=0.015996 \t time=0.78s\n",
      "Best model: Epoch 39 \t loss=0.013886 \t val_loss=0.015983 \t time=0.76s\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.414584 \t val_loss=0.082335 \t time=0.77s\n",
      "Best model: Epoch 2 \t loss=0.049711 \t val_loss=0.029518 \t time=0.77s\n",
      "Best model: Epoch 3 \t loss=0.027117 \t val_loss=0.023339 \t time=0.78s\n",
      "Best model: Epoch 4 \t loss=0.023117 \t val_loss=0.021092 \t time=0.77s\n",
      "Best model: Epoch 5 \t loss=0.021548 \t val_loss=0.019737 \t time=1.00s\n",
      "Best model: Epoch 6 \t loss=0.020499 \t val_loss=0.018971 \t time=1.14s\n",
      "Best model: Epoch 7 \t loss=0.020169 \t val_loss=0.018819 \t time=1.02s\n",
      "Best model: Epoch 8 \t loss=0.019469 \t val_loss=0.018286 \t time=0.80s\n",
      "Best model: Epoch 9 \t loss=0.018948 \t val_loss=0.017891 \t time=0.77s\n",
      "Best model: Epoch 10 \t loss=0.018628 \t val_loss=0.017664 \t time=0.79s\n",
      "Best model: Epoch 11 \t loss=0.018342 \t val_loss=0.017456 \t time=0.78s\n",
      "Best model: Epoch 12 \t loss=0.018015 \t val_loss=0.017229 \t time=0.82s\n",
      "Best model: Epoch 13 \t loss=0.017866 \t val_loss=0.017085 \t time=0.81s\n",
      "Best model: Epoch 14 \t loss=0.017528 \t val_loss=0.016909 \t time=0.88s\n",
      "Best model: Epoch 15 \t loss=0.017280 \t val_loss=0.016874 \t time=0.78s\n",
      "Best model: Epoch 16 \t loss=0.017076 \t val_loss=0.016679 \t time=0.79s\n",
      "Best model: Epoch 17 \t loss=0.016943 \t val_loss=0.016624 \t time=1.29s\n",
      "Best model: Epoch 18 \t loss=0.016749 \t val_loss=0.016566 \t time=0.84s\n",
      "Best model: Epoch 19 \t loss=0.016542 \t val_loss=0.016459 \t time=0.79s\n",
      "Best model: Epoch 21 \t loss=0.016295 \t val_loss=0.016388 \t time=0.78s\n",
      "Best model: Epoch 22 \t loss=0.016143 \t val_loss=0.016309 \t time=0.78s\n",
      "Best model: Epoch 23 \t loss=0.015980 \t val_loss=0.016293 \t time=0.79s\n",
      "Best model: Epoch 24 \t loss=0.015914 \t val_loss=0.016263 \t time=0.79s\n",
      "Best model: Epoch 25 \t loss=0.015778 \t val_loss=0.016212 \t time=0.77s\n",
      "Best model: Epoch 26 \t loss=0.015745 \t val_loss=0.016206 \t time=0.78s\n",
      "Best model: Epoch 27 \t loss=0.015732 \t val_loss=0.016174 \t time=0.82s\n",
      "Best model: Epoch 28 \t loss=0.015595 \t val_loss=0.016167 \t time=0.80s\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 33 \t loss=0.014829 \t val_loss=0.016002 \t time=0.78s\n",
      "Best model: Epoch 34 \t loss=0.014517 \t val_loss=0.015985 \t time=0.77s\n",
      "Best model: Epoch 35 \t loss=0.014321 \t val_loss=0.015933 \t time=0.77s\n",
      "Best model: Epoch 36 \t loss=0.014211 \t val_loss=0.015908 \t time=0.77s\n",
      "Best model: Epoch 38 \t loss=0.013914 \t val_loss=0.015885 \t time=0.77s\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.411934 \t val_loss=0.084869 \t time=0.88s\n",
      "Best model: Epoch 2 \t loss=0.048785 \t val_loss=0.029754 \t time=0.77s\n",
      "Best model: Epoch 3 \t loss=0.027070 \t val_loss=0.022880 \t time=0.77s\n",
      "Best model: Epoch 4 \t loss=0.023395 \t val_loss=0.021299 \t time=0.77s\n",
      "Best model: Epoch 5 \t loss=0.021702 \t val_loss=0.019915 \t time=0.77s\n",
      "Best model: Epoch 6 \t loss=0.020618 \t val_loss=0.019388 \t time=0.77s\n",
      "Best model: Epoch 7 \t loss=0.019931 \t val_loss=0.018905 \t time=0.80s\n",
      "Best model: Epoch 8 \t loss=0.019406 \t val_loss=0.018676 \t time=0.78s\n",
      "Best model: Epoch 9 \t loss=0.019032 \t val_loss=0.018264 \t time=0.81s\n",
      "Best model: Epoch 10 \t loss=0.018470 \t val_loss=0.017871 \t time=0.77s\n",
      "Best model: Epoch 11 \t loss=0.018295 \t val_loss=0.017738 \t time=0.94s\n",
      "Best model: Epoch 12 \t loss=0.018132 \t val_loss=0.017547 \t time=0.79s\n",
      "Best model: Epoch 13 \t loss=0.017656 \t val_loss=0.017336 \t time=0.93s\n",
      "Best model: Epoch 14 \t loss=0.017475 \t val_loss=0.017185 \t time=0.84s\n",
      "Best model: Epoch 15 \t loss=0.017199 \t val_loss=0.017107 \t time=0.82s\n",
      "Best model: Epoch 16 \t loss=0.016992 \t val_loss=0.017003 \t time=0.78s\n",
      "Best model: Epoch 17 \t loss=0.016782 \t val_loss=0.016892 \t time=0.79s\n",
      "Best model: Epoch 18 \t loss=0.016744 \t val_loss=0.016866 \t time=0.79s\n",
      "Best model: Epoch 19 \t loss=0.016530 \t val_loss=0.016668 \t time=0.85s\n",
      "Best model: Epoch 21 \t loss=0.016181 \t val_loss=0.016624 \t time=0.84s\n",
      "Best model: Epoch 22 \t loss=0.016118 \t val_loss=0.016570 \t time=0.86s\n",
      "Best model: Epoch 23 \t loss=0.015953 \t val_loss=0.016528 \t time=0.82s\n",
      "Best model: Epoch 25 \t loss=0.015730 \t val_loss=0.016496 \t time=0.78s\n",
      "Best model: Epoch 29 \t loss=0.015394 \t val_loss=0.016454 \t time=0.80s\n",
      "Best model: Epoch 32 \t loss=0.015384 \t val_loss=0.016405 \t time=0.76s\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 37 \t loss=0.014629 \t val_loss=0.016293 \t time=1.00s\n",
      "Best model: Epoch 38 \t loss=0.014265 \t val_loss=0.016220 \t time=0.78s\n",
      "Best model: Epoch 39 \t loss=0.014014 \t val_loss=0.016210 \t time=1.00s\n",
      "Best model: Epoch 40 \t loss=0.013926 \t val_loss=0.016205 \t time=0.81s\n",
      "Seed 5\n",
      "Fold 1 log loss: 0.01613091124603725\n",
      "Fold 2 log loss: 0.01605160109408642\n",
      "Fold 3 log loss: 0.01597392669501289\n",
      "Fold 4 log loss: 0.015947949903946726\n",
      "Fold 5 log loss: 0.016211428276791198\n",
      "Std of log loss: 9.792167322957682e-05\n",
      "Total log loss: 0.01606315721470376\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.410548 \t val_loss=0.076159 \t time=0.96s\n",
      "Best model: Epoch 2 \t loss=0.048675 \t val_loss=0.028416 \t time=0.81s\n",
      "Best model: Epoch 3 \t loss=0.027259 \t val_loss=0.022991 \t time=0.78s\n",
      "Best model: Epoch 4 \t loss=0.023068 \t val_loss=0.021106 \t time=0.78s\n",
      "Best model: Epoch 5 \t loss=0.021473 \t val_loss=0.020032 \t time=0.77s\n",
      "Best model: Epoch 6 \t loss=0.020396 \t val_loss=0.019406 \t time=1.00s\n",
      "Best model: Epoch 7 \t loss=0.019971 \t val_loss=0.018957 \t time=0.81s\n",
      "Best model: Epoch 8 \t loss=0.019402 \t val_loss=0.018444 \t time=0.82s\n",
      "Best model: Epoch 10 \t loss=0.018815 \t val_loss=0.018014 \t time=0.77s\n",
      "Best model: Epoch 11 \t loss=0.018322 \t val_loss=0.017770 \t time=0.78s\n",
      "Best model: Epoch 12 \t loss=0.018009 \t val_loss=0.017559 \t time=0.79s\n",
      "Best model: Epoch 13 \t loss=0.017820 \t val_loss=0.017363 \t time=0.80s\n",
      "Best model: Epoch 14 \t loss=0.017621 \t val_loss=0.017354 \t time=0.79s\n",
      "Best model: Epoch 15 \t loss=0.017333 \t val_loss=0.017296 \t time=0.96s\n",
      "Best model: Epoch 16 \t loss=0.017068 \t val_loss=0.017021 \t time=0.79s\n",
      "Best model: Epoch 17 \t loss=0.016883 \t val_loss=0.016941 \t time=0.78s\n",
      "Best model: Epoch 18 \t loss=0.016676 \t val_loss=0.016849 \t time=0.82s\n",
      "Best model: Epoch 19 \t loss=0.016466 \t val_loss=0.016727 \t time=0.97s\n",
      "Best model: Epoch 20 \t loss=0.016411 \t val_loss=0.016725 \t time=0.79s\n",
      "Best model: Epoch 21 \t loss=0.016317 \t val_loss=0.016638 \t time=0.79s\n",
      "Best model: Epoch 22 \t loss=0.016062 \t val_loss=0.016603 \t time=0.78s\n",
      "Best model: Epoch 23 \t loss=0.015963 \t val_loss=0.016548 \t time=0.78s\n",
      "Best model: Epoch 24 \t loss=0.015858 \t val_loss=0.016485 \t time=0.77s\n",
      "Best model: Epoch 27 \t loss=0.015642 \t val_loss=0.016340 \t time=0.77s\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 32 \t loss=0.014739 \t val_loss=0.016225 \t time=0.96s\n",
      "Best model: Epoch 33 \t loss=0.014491 \t val_loss=0.016193 \t time=0.78s\n",
      "Best model: Epoch 34 \t loss=0.014293 \t val_loss=0.016180 \t time=0.78s\n",
      "Best model: Epoch 35 \t loss=0.014224 \t val_loss=0.016117 \t time=0.79s\n",
      "Best model: Epoch 36 \t loss=0.014039 \t val_loss=0.016107 \t time=0.78s\n",
      "Best model: Epoch 38 \t loss=0.013855 \t val_loss=0.016102 \t time=0.77s\n",
      "Best model: Epoch 39 \t loss=0.013742 \t val_loss=0.016096 \t time=0.77s\n",
      "Best model: Epoch 40 \t loss=0.013574 \t val_loss=0.016056 \t time=0.80s\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.412380 \t val_loss=0.086316 \t time=0.78s\n",
      "Best model: Epoch 2 \t loss=0.048164 \t val_loss=0.028369 \t time=0.97s\n",
      "Best model: Epoch 3 \t loss=0.027507 \t val_loss=0.023616 \t time=0.78s\n",
      "Best model: Epoch 4 \t loss=0.023143 \t val_loss=0.020627 \t time=0.77s\n",
      "Best model: Epoch 5 \t loss=0.021520 \t val_loss=0.019837 \t time=0.78s\n",
      "Best model: Epoch 6 \t loss=0.020470 \t val_loss=0.019261 \t time=0.77s\n",
      "Best model: Epoch 7 \t loss=0.019897 \t val_loss=0.019011 \t time=0.79s\n",
      "Best model: Epoch 8 \t loss=0.019594 \t val_loss=0.018651 \t time=0.79s\n",
      "Best model: Epoch 9 \t loss=0.019125 \t val_loss=0.018166 \t time=0.95s\n",
      "Best model: Epoch 10 \t loss=0.018667 \t val_loss=0.017953 \t time=0.78s\n",
      "Best model: Epoch 11 \t loss=0.018459 \t val_loss=0.017806 \t time=0.79s\n",
      "Best model: Epoch 12 \t loss=0.018367 \t val_loss=0.017611 \t time=0.80s\n",
      "Best model: Epoch 13 \t loss=0.017887 \t val_loss=0.017417 \t time=0.81s\n",
      "Best model: Epoch 14 \t loss=0.017605 \t val_loss=0.017204 \t time=0.78s\n",
      "Best model: Epoch 15 \t loss=0.017397 \t val_loss=0.017075 \t time=1.48s\n",
      "Best model: Epoch 16 \t loss=0.017108 \t val_loss=0.016911 \t time=0.80s\n",
      "Best model: Epoch 17 \t loss=0.016944 \t val_loss=0.016757 \t time=0.79s\n",
      "Best model: Epoch 19 \t loss=0.016562 \t val_loss=0.016686 \t time=1.04s\n",
      "Best model: Epoch 20 \t loss=0.016383 \t val_loss=0.016666 \t time=0.79s\n",
      "Best model: Epoch 21 \t loss=0.016254 \t val_loss=0.016584 \t time=0.83s\n",
      "Best model: Epoch 22 \t loss=0.016109 \t val_loss=0.016442 \t time=0.85s\n",
      "Best model: Epoch 24 \t loss=0.015870 \t val_loss=0.016393 \t time=0.91s\n",
      "Best model: Epoch 25 \t loss=0.015809 \t val_loss=0.016366 \t time=0.86s\n",
      "Best model: Epoch 29 \t loss=0.015583 \t val_loss=0.016360 \t time=0.77s\n",
      "Best model: Epoch 30 \t loss=0.015529 \t val_loss=0.016315 \t time=0.95s\n",
      "Best model: Epoch 32 \t loss=0.015416 \t val_loss=0.016291 \t time=0.78s\n",
      "Best model: Epoch 33 \t loss=0.015290 \t val_loss=0.016276 \t time=0.79s\n",
      "Best model: Epoch 34 \t loss=0.015310 \t val_loss=0.016229 \t time=0.78s\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 39 \t loss=0.014601 \t val_loss=0.016072 \t time=0.89s\n",
      "Best model: Epoch 40 \t loss=0.014263 \t val_loss=0.015996 \t time=0.87s\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.409995 \t val_loss=0.082418 \t time=0.80s\n",
      "Best model: Epoch 2 \t loss=0.049255 \t val_loss=0.029069 \t time=0.98s\n",
      "Best model: Epoch 3 \t loss=0.027595 \t val_loss=0.023014 \t time=0.86s\n",
      "Best model: Epoch 4 \t loss=0.023091 \t val_loss=0.021010 \t time=0.82s\n",
      "Best model: Epoch 5 \t loss=0.021531 \t val_loss=0.020072 \t time=0.84s\n",
      "Best model: Epoch 6 \t loss=0.020662 \t val_loss=0.019388 \t time=0.79s\n",
      "Best model: Epoch 7 \t loss=0.019925 \t val_loss=0.018875 \t time=0.79s\n",
      "Best model: Epoch 8 \t loss=0.019809 \t val_loss=0.018390 \t time=0.87s\n",
      "Best model: Epoch 9 \t loss=0.019107 \t val_loss=0.018354 \t time=1.04s\n",
      "Best model: Epoch 10 \t loss=0.018737 \t val_loss=0.018019 \t time=0.83s\n",
      "Best model: Epoch 11 \t loss=0.018282 \t val_loss=0.017790 \t time=0.80s\n",
      "Best model: Epoch 12 \t loss=0.018144 \t val_loss=0.017454 \t time=0.77s\n",
      "Best model: Epoch 13 \t loss=0.017799 \t val_loss=0.017261 \t time=0.78s\n",
      "Best model: Epoch 14 \t loss=0.017531 \t val_loss=0.017091 \t time=0.80s\n",
      "Best model: Epoch 15 \t loss=0.017205 \t val_loss=0.016947 \t time=0.81s\n",
      "Best model: Epoch 16 \t loss=0.017118 \t val_loss=0.016871 \t time=0.77s\n",
      "Best model: Epoch 17 \t loss=0.017189 \t val_loss=0.016754 \t time=0.77s\n",
      "Best model: Epoch 18 \t loss=0.016772 \t val_loss=0.016721 \t time=0.77s\n",
      "Best model: Epoch 19 \t loss=0.016528 \t val_loss=0.016643 \t time=0.78s\n",
      "Best model: Epoch 20 \t loss=0.016480 \t val_loss=0.016552 \t time=0.78s\n",
      "Best model: Epoch 21 \t loss=0.016270 \t val_loss=0.016475 \t time=0.79s\n",
      "Best model: Epoch 22 \t loss=0.016107 \t val_loss=0.016406 \t time=0.99s\n",
      "Best model: Epoch 25 \t loss=0.015887 \t val_loss=0.016331 \t time=0.77s\n",
      "Best model: Epoch 26 \t loss=0.015811 \t val_loss=0.016303 \t time=0.80s\n",
      "Best model: Epoch 28 \t loss=0.015690 \t val_loss=0.016281 \t time=0.77s\n",
      "Best model: Epoch 30 \t loss=0.015553 \t val_loss=0.016281 \t time=0.77s\n",
      "Best model: Epoch 32 \t loss=0.015467 \t val_loss=0.016244 \t time=0.77s\n",
      "Best model: Epoch 36 \t loss=0.015346 \t val_loss=0.016213 \t time=0.84s\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.412607 \t val_loss=0.077458 \t time=0.77s\n",
      "Best model: Epoch 2 \t loss=0.048404 \t val_loss=0.029592 \t time=1.00s\n",
      "Best model: Epoch 3 \t loss=0.027643 \t val_loss=0.023730 \t time=0.77s\n",
      "Best model: Epoch 4 \t loss=0.023438 \t val_loss=0.021367 \t time=0.80s\n",
      "Best model: Epoch 5 \t loss=0.021601 \t val_loss=0.019680 \t time=0.92s\n",
      "Best model: Epoch 6 \t loss=0.020773 \t val_loss=0.019118 \t time=0.87s\n",
      "Best model: Epoch 7 \t loss=0.019886 \t val_loss=0.018749 \t time=0.81s\n",
      "Best model: Epoch 8 \t loss=0.019760 \t val_loss=0.018365 \t time=0.82s\n",
      "Best model: Epoch 9 \t loss=0.019047 \t val_loss=0.017947 \t time=0.79s\n",
      "Best model: Epoch 10 \t loss=0.018723 \t val_loss=0.017657 \t time=0.78s\n",
      "Best model: Epoch 13 \t loss=0.017910 \t val_loss=0.017055 \t time=0.80s\n",
      "Best model: Epoch 14 \t loss=0.017643 \t val_loss=0.017010 \t time=0.78s\n",
      "Best model: Epoch 15 \t loss=0.017398 \t val_loss=0.016802 \t time=0.78s\n",
      "Best model: Epoch 16 \t loss=0.017017 \t val_loss=0.016703 \t time=0.77s\n",
      "Best model: Epoch 17 \t loss=0.016897 \t val_loss=0.016664 \t time=0.97s\n",
      "Best model: Epoch 18 \t loss=0.016672 \t val_loss=0.016558 \t time=0.99s\n",
      "Best model: Epoch 19 \t loss=0.016531 \t val_loss=0.016409 \t time=0.77s\n",
      "Best model: Epoch 21 \t loss=0.016382 \t val_loss=0.016392 \t time=0.77s\n",
      "Best model: Epoch 22 \t loss=0.016133 \t val_loss=0.016338 \t time=0.77s\n",
      "Best model: Epoch 23 \t loss=0.015986 \t val_loss=0.016290 \t time=0.78s\n",
      "Best model: Epoch 24 \t loss=0.015881 \t val_loss=0.016191 \t time=0.79s\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 29 \t loss=0.014980 \t val_loss=0.016022 \t time=0.78s\n",
      "Best model: Epoch 30 \t loss=0.014763 \t val_loss=0.015967 \t time=0.80s\n",
      "Best model: Epoch 31 \t loss=0.014599 \t val_loss=0.015948 \t time=1.01s\n",
      "Best model: Epoch 33 \t loss=0.014235 \t val_loss=0.015924 \t time=0.78s\n",
      "Best model: Epoch 35 \t loss=0.014010 \t val_loss=0.015877 \t time=0.80s\n",
      "Best model: Epoch 37 \t loss=0.013814 \t val_loss=0.015870 \t time=0.78s\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.413470 \t val_loss=0.077215 \t time=0.98s\n",
      "Best model: Epoch 2 \t loss=0.048402 \t val_loss=0.027918 \t time=0.79s\n",
      "Best model: Epoch 3 \t loss=0.027494 \t val_loss=0.023155 \t time=0.77s\n",
      "Best model: Epoch 4 \t loss=0.023637 \t val_loss=0.021171 \t time=0.77s\n",
      "Best model: Epoch 5 \t loss=0.022008 \t val_loss=0.020150 \t time=0.77s\n",
      "Best model: Epoch 6 \t loss=0.021261 \t val_loss=0.019328 \t time=0.77s\n",
      "Best model: Epoch 8 \t loss=0.019583 \t val_loss=0.018739 \t time=0.77s\n",
      "Best model: Epoch 9 \t loss=0.019062 \t val_loss=0.018394 \t time=0.79s\n",
      "Best model: Epoch 10 \t loss=0.018614 \t val_loss=0.018117 \t time=0.78s\n",
      "Best model: Epoch 11 \t loss=0.018349 \t val_loss=0.017784 \t time=0.98s\n",
      "Best model: Epoch 12 \t loss=0.017979 \t val_loss=0.017725 \t time=0.77s\n",
      "Best model: Epoch 13 \t loss=0.017764 \t val_loss=0.017418 \t time=0.78s\n",
      "Best model: Epoch 14 \t loss=0.017518 \t val_loss=0.017373 \t time=0.98s\n",
      "Best model: Epoch 15 \t loss=0.017364 \t val_loss=0.017246 \t time=0.81s\n",
      "Best model: Epoch 16 \t loss=0.017157 \t val_loss=0.017085 \t time=0.78s\n",
      "Best model: Epoch 18 \t loss=0.016677 \t val_loss=0.016947 \t time=0.76s\n",
      "Best model: Epoch 19 \t loss=0.016601 \t val_loss=0.016793 \t time=0.77s\n",
      "Best model: Epoch 20 \t loss=0.016473 \t val_loss=0.016708 \t time=0.77s\n",
      "Best model: Epoch 22 \t loss=0.016187 \t val_loss=0.016614 \t time=0.80s\n",
      "Best model: Epoch 23 \t loss=0.016128 \t val_loss=0.016572 \t time=0.77s\n",
      "Best model: Epoch 24 \t loss=0.015994 \t val_loss=0.016538 \t time=0.79s\n",
      "Best model: Epoch 25 \t loss=0.015903 \t val_loss=0.016513 \t time=0.87s\n",
      "Best model: Epoch 26 \t loss=0.015816 \t val_loss=0.016505 \t time=1.03s\n",
      "Best model: Epoch 27 \t loss=0.015710 \t val_loss=0.016425 \t time=1.21s\n",
      "Best model: Epoch 30 \t loss=0.015504 \t val_loss=0.016421 \t time=0.79s\n",
      "Best model: Epoch 31 \t loss=0.015386 \t val_loss=0.016361 \t time=0.81s\n",
      "Best model: Epoch 32 \t loss=0.015360 \t val_loss=0.016355 \t time=0.77s\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 37 \t loss=0.014537 \t val_loss=0.016208 \t time=0.79s\n",
      "Best model: Epoch 38 \t loss=0.014348 \t val_loss=0.016168 \t time=0.79s\n",
      "Best model: Epoch 39 \t loss=0.014006 \t val_loss=0.016159 \t time=0.91s\n",
      "Best model: Epoch 40 \t loss=0.013966 \t val_loss=0.016136 \t time=0.88s\n",
      "Seed 6\n",
      "Fold 1 log loss: 0.016154516233354198\n",
      "Fold 2 log loss: 0.016054492896685344\n",
      "Fold 3 log loss: 0.016211218462279093\n",
      "Fold 4 log loss: 0.015934252100067155\n",
      "Fold 5 log loss: 0.01613258415894776\n",
      "Std of log loss: 9.582597503909173e-05\n",
      "Total log loss: 0.016097413123305024\n",
      "Total log loss: 0.015927397151846545\n"
     ]
    }
   ],
   "source": [
    "seeds = [0,1,2,3,4,5,6] \n",
    "nn_train = train.copy().to_numpy()\n",
    "nn_targets = targets.drop(\"sig_id\", axis=1).copy().to_numpy()\n",
    "nn_test = test.copy().to_numpy()\n",
    "\n",
    "oof_final = np.zeros([len(train),nn_targets.shape[1]])\n",
    "pred_final = np.zeros([len(test),nn_targets.shape[1]])\n",
    "\n",
    "for seed_ in seeds:\n",
    "    oof, oof_targets, pytorch_pred = modelling_torch(nn_train, nn_targets, nn_test, sample_seed = seed_, init_num = nn_train.shape[1])\n",
    "    oof_final += oof / len(seeds)\n",
    "    pred_final += pytorch_pred / len(seeds)\n",
    "print(\"Total log loss: {}\".format(mean_log_loss(oof_targets, oof_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T13:52:47.037649Z",
     "iopub.status.busy": "2020-10-05T13:52:47.036654Z",
     "iopub.status.idle": "2020-10-05T13:52:49.467185Z",
     "shell.execute_reply": "2020-10-05T13:52:49.465895Z"
    },
    "papermill": {
     "duration": 2.838274,
     "end_time": "2020-10-05T13:52:49.467329",
     "exception": false,
     "start_time": "2020-10-05T13:52:46.629055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub[target_feats] = pred_final\n",
    "sub.loc[noncons_test_index,target_feats] = 0\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.39767,
     "end_time": "2020-10-05T13:52:50.258240",
     "exception": false,
     "start_time": "2020-10-05T13:52:49.860570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 1363.34689,
   "end_time": "2020-10-05T13:52:51.167496",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-05T13:30:07.820606",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
