{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020441,
     "end_time": "2020-11-12T03:14:14.361423",
     "exception": false,
     "start_time": "2020-11-12T03:14:14.340982",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- go back to 3 layers\n",
    "- try label smoothing 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-12T03:14:14.411893Z",
     "iopub.status.busy": "2020-11-12T03:14:14.411026Z",
     "iopub.status.idle": "2020-11-12T03:14:25.215738Z",
     "shell.execute_reply": "2020-11-12T03:14:25.214210Z"
    },
    "papermill": {
     "duration": 10.834967,
     "end_time": "2020-11-12T03:14:25.215897",
     "exception": false,
     "start_time": "2020-11-12T03:14:14.380930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from umap import UMAP\n",
    "import networkx as nx\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss,roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.compose import make_column_transformer,ColumnTransformer\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from sklearn.pipeline import make_pipeline,make_union\n",
    "\n",
    "sys.path.append('../input/multilabelstraifier/')\n",
    "from ml_stratifiers import MultilabelStratifiedKFold\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "from torch.nn.modules.loss import _WeightedLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020643,
     "end_time": "2020-11-12T03:14:25.257872",
     "exception": false,
     "start_time": "2020-11-12T03:14:25.237229",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# final engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:14:25.308872Z",
     "iopub.status.busy": "2020-11-12T03:14:25.307842Z",
     "iopub.status.idle": "2020-11-12T03:14:32.611147Z",
     "shell.execute_reply": "2020-11-12T03:14:32.609843Z"
    },
    "papermill": {
     "duration": 7.332179,
     "end_time": "2020-11-12T03:14:32.611283",
     "exception": false,
     "start_time": "2020-11-12T03:14:25.279104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/lish-moa/'\n",
    "train = pd.read_csv(DATA_DIR + 'train_features.csv')\n",
    "targets = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "non_targets = pd.read_csv(DATA_DIR + 'train_targets_nonscored.csv')\n",
    "test = pd.read_csv(DATA_DIR + 'test_features.csv')\n",
    "sub = pd.read_csv(DATA_DIR + 'sample_submission.csv')\n",
    "drug = pd.read_csv(DATA_DIR + 'train_drug.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:14:32.661575Z",
     "iopub.status.busy": "2020-11-12T03:14:32.659596Z",
     "iopub.status.idle": "2020-11-12T03:14:32.662328Z",
     "shell.execute_reply": "2020-11-12T03:14:32.662878Z"
    },
    "papermill": {
     "duration": 0.030892,
     "end_time": "2020-11-12T03:14:32.663009",
     "exception": false,
     "start_time": "2020-11-12T03:14:32.632117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_feats = [ i for i in targets.columns if i != \"sig_id\"]\n",
    "g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "c_feats = [i for i in train.columns if \"c-\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:14:32.712435Z",
     "iopub.status.busy": "2020-11-12T03:14:32.711449Z",
     "iopub.status.idle": "2020-11-12T03:14:32.813610Z",
     "shell.execute_reply": "2020-11-12T03:14:32.812690Z"
    },
    "papermill": {
     "duration": 0.130021,
     "end_time": "2020-11-12T03:14:32.813754",
     "exception": false,
     "start_time": "2020-11-12T03:14:32.683733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "noncons_train_index = train[train.cp_type==\"ctl_vehicle\"].index\n",
    "cons_train_index = train[train.cp_type!=\"ctl_vehicle\"].index\n",
    "noncons_test_index = test[test.cp_type==\"ctl_vehicle\"].index\n",
    "cons_test_index = test[test.cp_type!=\"ctl_vehicle\"].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020584,
     "end_time": "2020-11-12T03:14:32.856157",
     "exception": false,
     "start_time": "2020-11-12T03:14:32.835573",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:14:32.912856Z",
     "iopub.status.busy": "2020-11-12T03:14:32.911782Z",
     "iopub.status.idle": "2020-11-12T03:14:33.170897Z",
     "shell.execute_reply": "2020-11-12T03:14:33.170306Z"
    },
    "papermill": {
     "duration": 0.294483,
     "end_time": "2020-11-12T03:14:33.171020",
     "exception": false,
     "start_time": "2020-11-12T03:14:32.876537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train[train.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "test = test[test.index.isin(cons_test_index)].copy().reset_index(drop=True)\n",
    "targets = targets[targets.index.isin(cons_train_index)].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:14:33.245831Z",
     "iopub.status.busy": "2020-11-12T03:14:33.233162Z",
     "iopub.status.idle": "2020-11-12T03:14:33.798284Z",
     "shell.execute_reply": "2020-11-12T03:14:33.797709Z"
    },
    "papermill": {
     "duration": 0.606186,
     "end_time": "2020-11-12T03:14:33.798415",
     "exception": false,
     "start_time": "2020-11-12T03:14:33.192229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 6, ..., 3, 4, 0]], dtype=int8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/c/lish-moa/discussion/195195\n",
    "NB_SPLITS = 7\n",
    "seed = 34\n",
    "\n",
    "folds = []\n",
    "    \n",
    "# LOAD FILES\n",
    "train_score = targets.merge(drug, on='sig_id', how='left') \n",
    "\n",
    "# LOCATE DRUGS\n",
    "vc = train_score.drug_id.value_counts()\n",
    "vc1 = vc.loc[vc <= 18].index.sort_values()\n",
    "vc2 = vc.loc[vc > 18].index.sort_values()\n",
    "    \n",
    "# STRATIFY DRUGS 18X OR LESS\n",
    "dct1 = {}; dct2 = {}\n",
    "skf = MultilabelStratifiedKFold(n_splits = NB_SPLITS, shuffle = True, random_state = seed)\n",
    "tmp = train_score.groupby('drug_id')[target_feats].mean().loc[vc1]\n",
    "for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_feats])):\n",
    "    dd = {k:fold for k in tmp.index[idxV].values}\n",
    "    dct1.update(dd)\n",
    "\n",
    "# STRATIFY DRUGS MORE THAN 18X\n",
    "skf = MultilabelStratifiedKFold(n_splits = NB_SPLITS, shuffle = True, random_state = seed)\n",
    "tmp = train_score.loc[train_score.drug_id.isin(vc2)].reset_index(drop = True)\n",
    "for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_feats])):\n",
    "    dd = {k:fold for k in tmp.sig_id[idxV].values}\n",
    "    dct2.update(dd)\n",
    "\n",
    "# ASSIGN FOLDS\n",
    "train_score['fold'] = train_score.drug_id.map(dct1)\n",
    "train_score.loc[train_score.fold.isna(),'fold'] = train_score.loc[train_score.fold.isna(),'sig_id'].map(dct2)\n",
    "train_score.fold = train_score.fold.astype('int8')\n",
    "folds.append(train_score.fold.values)\n",
    "    \n",
    "np.array(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021354,
     "end_time": "2020-11-12T03:14:33.842375",
     "exception": false,
     "start_time": "2020-11-12T03:14:33.821021",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:14:33.945331Z",
     "iopub.status.busy": "2020-11-12T03:14:33.943617Z",
     "iopub.status.idle": "2020-11-12T03:14:34.277319Z",
     "shell.execute_reply": "2020-11-12T03:14:34.276761Z"
    },
    "papermill": {
     "duration": 0.414359,
     "end_time": "2020-11-12T03:14:34.277431",
     "exception": false,
     "start_time": "2020-11-12T03:14:33.863072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "X = train.iloc[:,4:].copy().values\n",
    "select = VarianceThreshold(threshold=0.7)\n",
    "X_new = select.fit_transform(X)\n",
    "drop_feats = list(np.array(train.iloc[:,4:].columns)[select.get_support()==False])\n",
    "print(len(drop_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:14:34.325762Z",
     "iopub.status.busy": "2020-11-12T03:14:34.325134Z",
     "iopub.status.idle": "2020-11-12T03:14:34.329428Z",
     "shell.execute_reply": "2020-11-12T03:14:34.329939Z"
    },
    "papermill": {
     "duration": 0.030374,
     "end_time": "2020-11-12T03:14:34.330095",
     "exception": false,
     "start_time": "2020-11-12T03:14:34.299721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#correlations = train[c_feats].corr().abs()\n",
    "#correlations = (correlations.where(np.triu(np.ones(correlations.shape), k=1).astype(np.bool)).stack().sort_values(ascending=False))\n",
    "#pairs_df = (1-correlations).reset_index()\n",
    "#G = nx.from_pandas_edgelist(pairs_df[:20], source='level_0', target='level_1', edge_attr=0)\n",
    "#c_group = list(nx.algorithms.community.modularity_max.greedy_modularity_communities(G))\n",
    "\n",
    "#drop_c_feats = []\n",
    "#for i in range(len(c_group)):\n",
    "#    for j in list(c_group[i])[1:]:\n",
    "#        drop_c_feats.append(j)\n",
    "#en(drop_c_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:14:34.434549Z",
     "iopub.status.busy": "2020-11-12T03:14:34.432496Z",
     "iopub.status.idle": "2020-11-12T03:14:34.435282Z",
     "shell.execute_reply": "2020-11-12T03:14:34.435818Z"
    },
    "papermill": {
     "duration": 0.085137,
     "end_time": "2020-11-12T03:14:34.435974",
     "exception": false,
     "start_time": "2020-11-12T03:14:34.350837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.drop(drop_feats, axis=1, inplace=True)\n",
    "test.drop(drop_feats, axis=1, inplace=True)\n",
    "\n",
    "#train.drop(drop_c_feats, axis=1, inplace=True)\n",
    "#test.drop(drop_c_feats, axis=1, inplace=True)\n",
    "\n",
    "g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "c_feats = [i for i in train.columns if \"c-\" in i]\n",
    "#mean_g_feats = [i for i in train.columns if \"mean-g-\" in i]\n",
    "#mean_c_feats = [i for i in train.columns if \"mean-c-\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:14:34.489149Z",
     "iopub.status.busy": "2020-11-12T03:14:34.488424Z",
     "iopub.status.idle": "2020-11-12T03:14:45.653178Z",
     "shell.execute_reply": "2020-11-12T03:14:45.653808Z"
    },
    "papermill": {
     "duration": 11.196621,
     "end_time": "2020-11-12T03:14:45.653976",
     "exception": false,
     "start_time": "2020-11-12T03:14:34.457355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rank gauss\n",
    "for i in c_feats + g_feats:\n",
    "    ss = preprocessing.QuantileTransformer(n_quantiles=1000, random_state=0, output_distribution=\"normal\")\n",
    "    #    ss.fit(pd.concat([train[i], test[i]]).values.reshape(-1,1))\n",
    "    ss.fit(train[i].values.reshape(-1,1))\n",
    "    train[i] = ss.transform(train[i].values.reshape(-1,1))\n",
    "    test[i] = ss.transform(test[i].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:14:45.718913Z",
     "iopub.status.busy": "2020-11-12T03:14:45.717199Z",
     "iopub.status.idle": "2020-11-12T03:14:47.897938Z",
     "shell.execute_reply": "2020-11-12T03:14:47.897370Z"
    },
    "papermill": {
     "duration": 2.222405,
     "end_time": "2020-11-12T03:14:47.898094",
     "exception": false,
     "start_time": "2020-11-12T03:14:45.675689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_num = 10\n",
    "pca_c_cols = [\"pca-c\"+str(i+1) for i in range(c_num)]\n",
    "pca = PCA(n_components=c_num,random_state=42)\n",
    "c_train = pca.fit_transform(train[c_feats])\n",
    "c_test = pca.transform(test[c_feats])\n",
    "c_train = pd.DataFrame(c_train, columns=pca_c_cols)\n",
    "c_test = pd.DataFrame(c_test, columns=pca_c_cols)\n",
    "\n",
    "g_num = 60\n",
    "pca_g_cols = [\"pca-g\"+str(i+1) for i in range(g_num)]\n",
    "pca = PCA(n_components=g_num, random_state=42)\n",
    "g_train = pca.fit_transform(train[g_feats])\n",
    "g_test = pca.transform(test[g_feats])\n",
    "g_train = pd.DataFrame(g_train, columns=pca_g_cols)\n",
    "g_test = pd.DataFrame(g_test, columns=pca_g_cols)\n",
    "\n",
    "train = pd.concat([train, c_train],axis=1)\n",
    "test = pd.concat([test, c_test],axis=1)\n",
    "train = pd.concat([train, g_train],axis=1)\n",
    "test = pd.concat([test, g_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:14:47.952560Z",
     "iopub.status.busy": "2020-11-12T03:14:47.951393Z",
     "iopub.status.idle": "2020-11-12T03:14:49.829734Z",
     "shell.execute_reply": "2020-11-12T03:14:49.829155Z"
    },
    "papermill": {
     "duration": 1.909657,
     "end_time": "2020-11-12T03:14:49.829851",
     "exception": false,
     "start_time": "2020-11-12T03:14:47.920194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 918) (3624, 918)\n"
     ]
    }
   ],
   "source": [
    "def fe(df):\n",
    "    tmp = df.copy()\n",
    "    tmp['g_kurt'] = tmp[g_feats].kurtosis(axis = 1)\n",
    "    tmp['g_skew'] = tmp[g_feats].skew(axis = 1)\n",
    "    tmp['c_kurt'] = tmp[c_feats].kurtosis(axis = 1)\n",
    "    tmp['c_skew'] = tmp[c_feats].skew(axis = 1)\n",
    "    tmp = pd.get_dummies(tmp, columns=['cp_time','cp_dose'])\n",
    "    tmp.drop([\"cp_type\", \"sig_id\"], axis=1, inplace=True)\n",
    "    return tmp\n",
    "\n",
    "train = fe(train)\n",
    "test = fe(test)\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:14:49.882606Z",
     "iopub.status.busy": "2020-11-12T03:14:49.881847Z",
     "iopub.status.idle": "2020-11-12T03:14:49.885765Z",
     "shell.execute_reply": "2020-11-12T03:14:49.885262Z"
    },
    "papermill": {
     "duration": 0.030852,
     "end_time": "2020-11-12T03:14:49.885856",
     "exception": false,
     "start_time": "2020-11-12T03:14:49.855004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[\"fold\"] = np.array(folds).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:14:49.936695Z",
     "iopub.status.busy": "2020-11-12T03:14:49.935340Z",
     "iopub.status.idle": "2020-11-12T03:14:50.100133Z",
     "shell.execute_reply": "2020-11-12T03:14:50.099570Z"
    },
    "papermill": {
     "duration": 0.192465,
     "end_time": "2020-11-12T03:14:50.100252",
     "exception": false,
     "start_time": "2020-11-12T03:14:49.907787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fn_train = train.copy().to_numpy()\n",
    "fn_test = test.copy().to_numpy()\n",
    "\n",
    "fn_targets = targets.drop(\"sig_id\", axis=1).copy().to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023005,
     "end_time": "2020-11-12T03:14:50.145876",
     "exception": false,
     "start_time": "2020-11-12T03:14:50.122871",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:14:50.561483Z",
     "iopub.status.busy": "2020-11-12T03:14:50.560613Z",
     "iopub.status.idle": "2020-11-12T03:14:50.564635Z",
     "shell.execute_reply": "2020-11-12T03:14:50.563632Z"
    },
    "papermill": {
     "duration": 0.395815,
     "end_time": "2020-11-12T03:14:50.564750",
     "exception": false,
     "start_time": "2020-11-12T03:14:50.168935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:14:50.625916Z",
     "iopub.status.busy": "2020-11-12T03:14:50.624438Z",
     "iopub.status.idle": "2020-11-12T03:14:50.626812Z",
     "shell.execute_reply": "2020-11-12T03:14:50.627387Z"
    },
    "papermill": {
     "duration": 0.038775,
     "end_time": "2020-11-12T03:14:50.627562",
     "exception": false,
     "start_time": "2020-11-12T03:14:50.588787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SmoothCrossEntropyLoss(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets, n_classes, smoothing=0.0):\n",
    "        assert 0 <= smoothing <= 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1 - smoothing) + torch.ones_like(targets).to(device) * smoothing / n_classes\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothCrossEntropyLoss()._smooth(targets, inputs.shape[1], self.smoothing)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            inputs = inputs * self.weight.unsqueeze(0)\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:14:50.692180Z",
     "iopub.status.busy": "2020-11-12T03:14:50.691418Z",
     "iopub.status.idle": "2020-11-12T03:14:50.694929Z",
     "shell.execute_reply": "2020-11-12T03:14:50.695799Z"
    },
    "papermill": {
     "duration": 0.044711,
     "end_time": "2020-11-12T03:14:50.695939",
     "exception": false,
     "start_time": "2020-11-12T03:14:50.651228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "def seed_everything(seed=42): \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "class MoaModel(nn.Module):\n",
    "    def __init__(self, num_columns, last_num):\n",
    "        super(MoaModel, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_columns)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_columns, 1024))\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(1024)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(1024, 1024))\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(1024)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(1024, last_num))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu1(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.relu2(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024926,
     "end_time": "2020-11-12T03:14:50.745616",
     "exception": false,
     "start_time": "2020-11-12T03:14:50.720690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:14:50.833755Z",
     "iopub.status.busy": "2020-11-12T03:14:50.801960Z",
     "iopub.status.idle": "2020-11-12T03:14:50.849189Z",
     "shell.execute_reply": "2020-11-12T03:14:50.848611Z"
    },
    "papermill": {
     "duration": 0.079389,
     "end_time": "2020-11-12T03:14:50.849303",
     "exception": false,
     "start_time": "2020-11-12T03:14:50.769914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_folds=7\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "smoothing = 0.0005\n",
    "p_min = smoothing\n",
    "p_max = 1 - smoothing\n",
    "\n",
    "def mean_log_loss(y_true, y_pred):\n",
    "    metrics = []\n",
    "    for i, target in enumerate(target_feats):\n",
    "        metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float), labels=[0,1]))\n",
    "    return np.mean(metrics)\n",
    "\n",
    "def modelling_torch(tr, target, te, sample_seed, init_num, last_num, train_epochs):\n",
    "    seed_everything(seed=sample_seed) \n",
    "    X_train = tr.copy()\n",
    "    y_train = target.copy()\n",
    "    X_test = te.copy()\n",
    "    test_len = X_test.shape[0]\n",
    "    \n",
    "    mskf=MultilabelStratifiedKFold(n_splits = n_folds, shuffle=True, random_state=224)\n",
    "    metric = lambda inputs, targets : F.binary_cross_entropy((torch.clamp(torch.sigmoid(inputs), p_min, p_max)), targets)\n",
    "\n",
    "    models = []\n",
    "    \n",
    "    X_test2 = torch.tensor(X_test, dtype=torch.float32)\n",
    "    test = torch.utils.data.TensorDataset(X_test2) \n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    oof = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    oof_targets = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    pred_value = np.zeros([test_len, y_train.shape[1]])\n",
    "    scores = []\n",
    "    for fold in range(n_folds):\n",
    "        valid_index = X_train[:,-1] == fold\n",
    "        train_index = X_train[:,-1] != fold\n",
    "        print(\"Fold \"+str(fold+1))\n",
    "        X_train2 = torch.tensor(X_train[train_index,:], dtype=torch.float32)\n",
    "        X_valid2 = torch.tensor(X_train[valid_index,:], dtype=torch.float32)\n",
    "        X_train2 = X_train2[:,:-1]\n",
    "        X_valid2 = X_valid2[:,:-1]\n",
    "        \n",
    "        y_train2 = torch.tensor(y_train[train_index], dtype=torch.float32)\n",
    "        y_valid2 = torch.tensor(y_train[valid_index], dtype=torch.float32)\n",
    "        \n",
    "        train = torch.utils.data.TensorDataset(X_train2, y_train2)\n",
    "        valid = torch.utils.data.TensorDataset(X_valid2, y_valid2)\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True) \n",
    "        valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "            \n",
    "        clf = MoaModel(init_num, last_num)\n",
    "        loss_fn = SmoothCrossEntropyLoss(smoothing=smoothing)\n",
    "\n",
    "        optimizer = optim.Adam(clf.parameters(), lr = 0.001, weight_decay=1e-5) \n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=train_epochs, steps_per_epoch=len(train_loader))\n",
    "        \n",
    "        clf.to(device)\n",
    "        \n",
    "        best_val_loss = np.inf\n",
    "        stop_counts = 0\n",
    "        for epoch in range(train_epochs):\n",
    "            start_time = time.time()\n",
    "            clf.train()\n",
    "            avg_loss = 0.\n",
    "            sm_avg_loss = 0.\n",
    "            for x_batch, y_batch in tqdm(train_loader, disable=True):\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch) \n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                avg_loss += loss.item() / len(train_loader)  \n",
    "                sm_avg_loss += metric(y_pred, y_batch) / len(train_loader) \n",
    "                \n",
    "            clf.eval()\n",
    "            avg_val_loss = 0.\n",
    "            sm_avg_val_loss = 0.\n",
    "            for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch).detach()\n",
    "                avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "                sm_avg_val_loss += metric(y_pred, y_batch) / len(valid_loader)\n",
    "        \n",
    "            elapsed_time = time.time() - start_time \n",
    "            #scheduler.step() #avg_val_loss # maybe mistake\n",
    "                    \n",
    "            if sm_avg_val_loss < best_val_loss:\n",
    "                best_val_loss = sm_avg_val_loss\n",
    "                print('Epoch {}   loss={:.5f}   val_loss={:.5f}   sm_loss={:.5f}   sm_val_loss={:.5f}   time={:.2f}s'.format(\n",
    "                    epoch + 1, avg_loss, avg_val_loss, sm_avg_loss, sm_avg_val_loss, elapsed_time))\n",
    "                torch.save(clf.state_dict(), 'best-model-parameters.pt')\n",
    "            else:\n",
    "                stop_counts += 1\n",
    "        \n",
    "        pred_model = MoaModel(init_num, last_num)\n",
    "        pred_model.load_state_dict(torch.load('best-model-parameters.pt'))         \n",
    "        pred_model.eval()\n",
    "        \n",
    "        # validation check ----------------\n",
    "        oof_epoch = np.zeros([X_valid2.size(0), y_train.shape[1]])\n",
    "        target_epoch = np.zeros([X_valid2.size(0), y_train.shape[1]])\n",
    "        for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "                y_pred = pred_model(x_batch).detach()\n",
    "                oof_epoch[i * batch_size:(i+1) * batch_size,:] = torch.clamp(torch.sigmoid(y_pred.cpu()), p_min, p_max)\n",
    "                target_epoch[i * batch_size:(i+1) * batch_size,:] = y_batch.cpu().numpy()\n",
    "        print(\"Fold {} log loss: {}\".format(fold+1, mean_log_loss(target_epoch, oof_epoch)))\n",
    "        scores.append(mean_log_loss(target_epoch, oof_epoch))\n",
    "        oof[valid_index,:] = oof_epoch\n",
    "        oof_targets[valid_index,:] = target_epoch\n",
    "        #-----------------------------------\n",
    "        \n",
    "        # test predcition --------------\n",
    "        test_preds = np.zeros([test_len, y_train.shape[1]])\n",
    "        for i, (x_batch,) in enumerate(test_loader): \n",
    "            y_pred = pred_model(x_batch).detach()\n",
    "            test_preds[i * batch_size:(i+1) * batch_size, :] = torch.clamp(torch.sigmoid(y_pred.cpu()), p_min, p_max)\n",
    "        pred_value += test_preds / n_folds\n",
    "        # ------------------------------\n",
    "        \n",
    "    print(\"Seed {}\".format(seed_))\n",
    "    for i, ele in enumerate(scores):\n",
    "        print(\"Fold {} log loss: {}\".format(i+1, scores[i]))\n",
    "    print(\"Std of log loss: {}\".format(np.std(scores)))\n",
    "    print(\"Total log loss: {}\".format(mean_log_loss(oof_targets, oof)))\n",
    "    \n",
    "    return oof, oof_targets, pred_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:14:50.905533Z",
     "iopub.status.busy": "2020-11-12T03:14:50.904801Z",
     "iopub.status.idle": "2020-11-12T03:27:26.674355Z",
     "shell.execute_reply": "2020-11-12T03:27:26.673791Z"
    },
    "papermill": {
     "duration": 755.801071,
     "end_time": "2020-11-12T03:27:26.674480",
     "exception": false,
     "start_time": "2020-11-12T03:14:50.873409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1   loss=0.41273   val_loss=0.02248   sm_loss=0.41269   sm_val_loss=0.02244   time=1.55s\n",
      "Epoch 2   loss=0.02025   val_loss=0.01999   sm_loss=0.02019   sm_val_loss=0.01996   time=0.88s\n",
      "Epoch 3   loss=0.01818   val_loss=0.01793   sm_loss=0.01814   sm_val_loss=0.01792   time=0.91s\n",
      "Epoch 5   loss=0.01735   val_loss=0.01769   sm_loss=0.01738   sm_val_loss=0.01768   time=0.89s\n",
      "Epoch 9   loss=0.01712   val_loss=0.01762   sm_loss=0.01714   sm_val_loss=0.01760   time=0.89s\n",
      "Epoch 10   loss=0.01700   val_loss=0.01755   sm_loss=0.01703   sm_val_loss=0.01754   time=0.93s\n",
      "Epoch 11   loss=0.01695   val_loss=0.01735   sm_loss=0.01698   sm_val_loss=0.01732   time=0.95s\n",
      "Epoch 13   loss=0.01644   val_loss=0.01731   sm_loss=0.01647   sm_val_loss=0.01730   time=0.94s\n",
      "Epoch 14   loss=0.01610   val_loss=0.01725   sm_loss=0.01614   sm_val_loss=0.01724   time=0.92s\n",
      "Epoch 15   loss=0.01582   val_loss=0.01726   sm_loss=0.01586   sm_val_loss=0.01724   time=0.95s\n",
      "Epoch 16   loss=0.01533   val_loss=0.01706   sm_loss=0.01537   sm_val_loss=0.01704   time=0.93s\n",
      "Epoch 17   loss=0.01492   val_loss=0.01706   sm_loss=0.01497   sm_val_loss=0.01704   time=0.97s\n",
      "Epoch 18   loss=0.01437   val_loss=0.01704   sm_loss=0.01442   sm_val_loss=0.01701   time=1.57s\n",
      "Epoch 19   loss=0.01399   val_loss=0.01698   sm_loss=0.01404   sm_val_loss=0.01696   time=0.91s\n",
      "Fold 1 log loss: 0.017032921964905794\n",
      "Fold 2\n",
      "Epoch 1   loss=0.41405   val_loss=0.02276   sm_loss=0.41397   sm_val_loss=0.02273   time=1.43s\n",
      "Epoch 2   loss=0.02007   val_loss=0.01849   sm_loss=0.02004   sm_val_loss=0.01845   time=0.98s\n",
      "Epoch 3   loss=0.01804   val_loss=0.01782   sm_loss=0.01800   sm_val_loss=0.01783   time=1.00s\n",
      "Epoch 4   loss=0.01740   val_loss=0.01759   sm_loss=0.01742   sm_val_loss=0.01759   time=0.92s\n",
      "Epoch 5   loss=0.01739   val_loss=0.01747   sm_loss=0.01741   sm_val_loss=0.01744   time=0.98s\n",
      "Epoch 7   loss=0.01728   val_loss=0.01744   sm_loss=0.01730   sm_val_loss=0.01742   time=1.22s\n",
      "Epoch 9   loss=0.01714   val_loss=0.01740   sm_loss=0.01717   sm_val_loss=0.01739   time=0.99s\n",
      "Epoch 10   loss=0.01701   val_loss=0.01733   sm_loss=0.01704   sm_val_loss=0.01732   time=0.98s\n",
      "Epoch 12   loss=0.01667   val_loss=0.01709   sm_loss=0.01670   sm_val_loss=0.01707   time=0.91s\n",
      "Epoch 13   loss=0.01647   val_loss=0.01703   sm_loss=0.01650   sm_val_loss=0.01701   time=0.88s\n",
      "Epoch 14   loss=0.01613   val_loss=0.01694   sm_loss=0.01616   sm_val_loss=0.01692   time=0.89s\n",
      "Epoch 16   loss=0.01528   val_loss=0.01694   sm_loss=0.01533   sm_val_loss=0.01689   time=0.87s\n",
      "Epoch 17   loss=0.01482   val_loss=0.01682   sm_loss=0.01487   sm_val_loss=0.01680   time=1.05s\n",
      "Fold 2 log loss: 0.016775640171245495\n",
      "Fold 3\n",
      "Epoch 1   loss=0.41422   val_loss=0.02328   sm_loss=0.41419   sm_val_loss=0.02327   time=0.89s\n",
      "Epoch 2   loss=0.02011   val_loss=0.02001   sm_loss=0.02005   sm_val_loss=0.01995   time=0.88s\n",
      "Epoch 3   loss=0.01795   val_loss=0.01878   sm_loss=0.01794   sm_val_loss=0.01878   time=0.88s\n",
      "Epoch 5   loss=0.01725   val_loss=0.01843   sm_loss=0.01727   sm_val_loss=0.01842   time=1.09s\n",
      "Epoch 7   loss=0.01712   val_loss=0.01837   sm_loss=0.01715   sm_val_loss=0.01835   time=1.18s\n",
      "Epoch 10   loss=0.01689   val_loss=0.01827   sm_loss=0.01692   sm_val_loss=0.01825   time=0.94s\n",
      "Epoch 11   loss=0.01673   val_loss=0.01818   sm_loss=0.01676   sm_val_loss=0.01817   time=0.89s\n",
      "Epoch 13   loss=0.01626   val_loss=0.01803   sm_loss=0.01630   sm_val_loss=0.01800   time=0.88s\n",
      "Epoch 14   loss=0.01601   val_loss=0.01796   sm_loss=0.01605   sm_val_loss=0.01795   time=0.89s\n",
      "Epoch 15   loss=0.01562   val_loss=0.01795   sm_loss=0.01566   sm_val_loss=0.01793   time=0.89s\n",
      "Epoch 16   loss=0.01516   val_loss=0.01783   sm_loss=0.01520   sm_val_loss=0.01782   time=0.88s\n",
      "Epoch 17   loss=0.01472   val_loss=0.01772   sm_loss=0.01477   sm_val_loss=0.01771   time=1.11s\n",
      "Epoch 19   loss=0.01375   val_loss=0.01770   sm_loss=0.01380   sm_val_loss=0.01768   time=1.12s\n",
      "Fold 3 log loss: 0.017680168458417956\n",
      "Fold 4\n",
      "Epoch 1   loss=0.41441   val_loss=0.02215   sm_loss=0.41439   sm_val_loss=0.02215   time=1.01s\n",
      "Epoch 2   loss=0.02004   val_loss=0.01923   sm_loss=0.01999   sm_val_loss=0.01915   time=0.96s\n",
      "Epoch 3   loss=0.01798   val_loss=0.01799   sm_loss=0.01794   sm_val_loss=0.01802   time=0.89s\n",
      "Epoch 4   loss=0.01750   val_loss=0.01789   sm_loss=0.01750   sm_val_loss=0.01787   time=0.89s\n",
      "Epoch 6   loss=0.01722   val_loss=0.01784   sm_loss=0.01725   sm_val_loss=0.01783   time=0.93s\n",
      "Epoch 9   loss=0.01705   val_loss=0.01779   sm_loss=0.01708   sm_val_loss=0.01779   time=0.88s\n",
      "Epoch 12   loss=0.01667   val_loss=0.01774   sm_loss=0.01670   sm_val_loss=0.01774   time=1.07s\n",
      "Epoch 13   loss=0.01643   val_loss=0.01753   sm_loss=0.01647   sm_val_loss=0.01754   time=1.07s\n",
      "Epoch 14   loss=0.01612   val_loss=0.01752   sm_loss=0.01616   sm_val_loss=0.01752   time=0.89s\n",
      "Epoch 15   loss=0.01580   val_loss=0.01752   sm_loss=0.01584   sm_val_loss=0.01751   time=0.93s\n",
      "Epoch 16   loss=0.01540   val_loss=0.01733   sm_loss=0.01544   sm_val_loss=0.01732   time=0.90s\n",
      "Epoch 17   loss=0.01487   val_loss=0.01733   sm_loss=0.01492   sm_val_loss=0.01731   time=1.45s\n",
      "Epoch 18   loss=0.01431   val_loss=0.01726   sm_loss=0.01436   sm_val_loss=0.01724   time=1.25s\n",
      "Fold 4 log loss: 0.017299459313264286\n",
      "Fold 5\n",
      "Epoch 1   loss=0.41375   val_loss=0.02232   sm_loss=0.41371   sm_val_loss=0.02231   time=1.11s\n",
      "Epoch 2   loss=0.02016   val_loss=0.01864   sm_loss=0.02009   sm_val_loss=0.01865   time=0.99s\n",
      "Epoch 3   loss=0.01809   val_loss=0.01746   sm_loss=0.01806   sm_val_loss=0.01746   time=1.11s\n",
      "Epoch 8   loss=0.01716   val_loss=0.01744   sm_loss=0.01719   sm_val_loss=0.01742   time=0.93s\n",
      "Epoch 10   loss=0.01708   val_loss=0.01737   sm_loss=0.01711   sm_val_loss=0.01735   time=0.95s\n",
      "Epoch 11   loss=0.01691   val_loss=0.01726   sm_loss=0.01694   sm_val_loss=0.01725   time=0.91s\n",
      "Epoch 12   loss=0.01670   val_loss=0.01711   sm_loss=0.01673   sm_val_loss=0.01709   time=0.90s\n",
      "Epoch 13   loss=0.01645   val_loss=0.01701   sm_loss=0.01648   sm_val_loss=0.01699   time=1.11s\n",
      "Epoch 16   loss=0.01546   val_loss=0.01693   sm_loss=0.01550   sm_val_loss=0.01690   time=0.89s\n",
      "Epoch 20   loss=0.01390   val_loss=0.01692   sm_loss=0.01395   sm_val_loss=0.01688   time=0.89s\n",
      "Fold 5 log loss: 0.01690485190406242\n",
      "Fold 6\n",
      "Epoch 1   loss=0.41273   val_loss=0.02332   sm_loss=0.41271   sm_val_loss=0.02332   time=1.00s\n",
      "Epoch 2   loss=0.01989   val_loss=0.01970   sm_loss=0.01985   sm_val_loss=0.01954   time=1.17s\n",
      "Epoch 3   loss=0.01794   val_loss=0.01867   sm_loss=0.01793   sm_val_loss=0.01866   time=0.91s\n",
      "Epoch 5   loss=0.01715   val_loss=0.01858   sm_loss=0.01717   sm_val_loss=0.01854   time=1.10s\n",
      "Epoch 11   loss=0.01671   val_loss=0.01840   sm_loss=0.01674   sm_val_loss=0.01833   time=0.88s\n",
      "Epoch 12   loss=0.01650   val_loss=0.01821   sm_loss=0.01653   sm_val_loss=0.01817   time=0.94s\n",
      "Epoch 14   loss=0.01595   val_loss=0.01799   sm_loss=0.01599   sm_val_loss=0.01798   time=0.88s\n",
      "Epoch 16   loss=0.01519   val_loss=0.01794   sm_loss=0.01523   sm_val_loss=0.01792   time=0.89s\n",
      "Epoch 17   loss=0.01471   val_loss=0.01789   sm_loss=0.01476   sm_val_loss=0.01787   time=0.92s\n",
      "Epoch 18   loss=0.01421   val_loss=0.01782   sm_loss=0.01425   sm_val_loss=0.01781   time=0.94s\n",
      "Epoch 19   loss=0.01382   val_loss=0.01779   sm_loss=0.01387   sm_val_loss=0.01778   time=1.17s\n",
      "Fold 6 log loss: 0.01802168578713981\n",
      "Fold 7\n",
      "Epoch 1   loss=0.41456   val_loss=0.02243   sm_loss=0.41451   sm_val_loss=0.02240   time=0.92s\n",
      "Epoch 2   loss=0.01998   val_loss=0.01884   sm_loss=0.01994   sm_val_loss=0.01884   time=0.93s\n",
      "Epoch 3   loss=0.01810   val_loss=0.01771   sm_loss=0.01807   sm_val_loss=0.01771   time=0.88s\n",
      "Epoch 9   loss=0.01709   val_loss=0.01764   sm_loss=0.01712   sm_val_loss=0.01764   time=1.22s\n",
      "Epoch 10   loss=0.01697   val_loss=0.01750   sm_loss=0.01700   sm_val_loss=0.01750   time=0.90s\n",
      "Epoch 11   loss=0.01680   val_loss=0.01740   sm_loss=0.01683   sm_val_loss=0.01740   time=0.96s\n",
      "Epoch 13   loss=0.01638   val_loss=0.01714   sm_loss=0.01642   sm_val_loss=0.01715   time=1.37s\n",
      "Epoch 15   loss=0.01579   val_loss=0.01700   sm_loss=0.01582   sm_val_loss=0.01700   time=1.42s\n",
      "Epoch 17   loss=0.01485   val_loss=0.01688   sm_loss=0.01490   sm_val_loss=0.01688   time=0.97s\n",
      "Fold 7 log loss: 0.016905723080560462\n",
      "Seed 0\n",
      "Fold 1 log loss: 0.017032921964905794\n",
      "Fold 2 log loss: 0.016775640171245495\n",
      "Fold 3 log loss: 0.017680168458417956\n",
      "Fold 4 log loss: 0.017299459313264286\n",
      "Fold 5 log loss: 0.01690485190406242\n",
      "Fold 6 log loss: 0.01802168578713981\n",
      "Fold 7 log loss: 0.016905723080560462\n",
      "Std of log loss: 0.00042934941331572224\n",
      "Total log loss: 0.01723052869802381\n",
      "Fold 1\n",
      "Epoch 1   loss=0.41400   val_loss=0.02200   sm_loss=0.41397   sm_val_loss=0.02197   time=0.92s\n",
      "Epoch 2   loss=0.02020   val_loss=0.02008   sm_loss=0.02015   sm_val_loss=0.01973   time=0.88s\n",
      "Epoch 4   loss=0.01744   val_loss=0.01782   sm_loss=0.01746   sm_val_loss=0.01781   time=0.91s\n",
      "Epoch 6   loss=0.01719   val_loss=0.01779   sm_loss=0.01722   sm_val_loss=0.01778   time=0.87s\n",
      "Epoch 7   loss=0.01731   val_loss=0.01774   sm_loss=0.01734   sm_val_loss=0.01772   time=0.86s\n",
      "Epoch 8   loss=0.01719   val_loss=0.01766   sm_loss=0.01722   sm_val_loss=0.01765   time=1.12s\n",
      "Epoch 10   loss=0.01707   val_loss=0.01749   sm_loss=0.01710   sm_val_loss=0.01748   time=0.90s\n",
      "Epoch 12   loss=0.01670   val_loss=0.01738   sm_loss=0.01673   sm_val_loss=0.01736   time=0.91s\n",
      "Epoch 13   loss=0.01650   val_loss=0.01729   sm_loss=0.01654   sm_val_loss=0.01729   time=0.91s\n",
      "Epoch 14   loss=0.01621   val_loss=0.01728   sm_loss=0.01625   sm_val_loss=0.01727   time=0.96s\n",
      "Epoch 15   loss=0.01580   val_loss=0.01727   sm_loss=0.01584   sm_val_loss=0.01724   time=1.00s\n",
      "Epoch 16   loss=0.01542   val_loss=0.01700   sm_loss=0.01547   sm_val_loss=0.01698   time=0.91s\n",
      "Fold 1 log loss: 0.017053308968608336\n",
      "Fold 2\n",
      "Epoch 1   loss=0.41399   val_loss=0.02182   sm_loss=0.41395   sm_val_loss=0.02181   time=0.87s\n",
      "Epoch 2   loss=0.02012   val_loss=0.01863   sm_loss=0.02006   sm_val_loss=0.01858   time=0.87s\n",
      "Epoch 3   loss=0.01800   val_loss=0.01861   sm_loss=0.01800   sm_val_loss=0.01833   time=1.17s\n",
      "Epoch 4   loss=0.01747   val_loss=0.01818   sm_loss=0.01747   sm_val_loss=0.01817   time=0.94s\n",
      "Epoch 5   loss=0.01731   val_loss=0.01776   sm_loss=0.01733   sm_val_loss=0.01773   time=0.89s\n",
      "Epoch 7   loss=0.01723   val_loss=0.01763   sm_loss=0.01726   sm_val_loss=0.01763   time=0.91s\n",
      "Epoch 8   loss=0.01715   val_loss=0.01733   sm_loss=0.01718   sm_val_loss=0.01732   time=0.91s\n",
      "Epoch 11   loss=0.01681   val_loss=0.01728   sm_loss=0.01684   sm_val_loss=0.01727   time=0.87s\n",
      "Epoch 12   loss=0.01668   val_loss=0.01706   sm_loss=0.01671   sm_val_loss=0.01706   time=0.92s\n",
      "Epoch 13   loss=0.01637   val_loss=0.01704   sm_loss=0.01641   sm_val_loss=0.01703   time=0.91s\n",
      "Epoch 15   loss=0.01574   val_loss=0.01696   sm_loss=0.01579   sm_val_loss=0.01694   time=0.88s\n",
      "Epoch 16   loss=0.01537   val_loss=0.01683   sm_loss=0.01541   sm_val_loss=0.01683   time=0.89s\n",
      "Epoch 17   loss=0.01483   val_loss=0.01681   sm_loss=0.01487   sm_val_loss=0.01680   time=0.90s\n",
      "Epoch 18   loss=0.01432   val_loss=0.01681   sm_loss=0.01437   sm_val_loss=0.01679   time=0.90s\n",
      "Epoch 19   loss=0.01392   val_loss=0.01678   sm_loss=0.01397   sm_val_loss=0.01676   time=0.88s\n",
      "Fold 2 log loss: 0.016740286369548277\n",
      "Fold 3\n",
      "Epoch 1   loss=0.41375   val_loss=0.02307   sm_loss=0.41372   sm_val_loss=0.02306   time=0.87s\n",
      "Epoch 2   loss=0.02008   val_loss=0.02017   sm_loss=0.02001   sm_val_loss=0.02016   time=0.88s\n",
      "Epoch 3   loss=0.01787   val_loss=0.01892   sm_loss=0.01785   sm_val_loss=0.01891   time=0.87s\n",
      "Epoch 4   loss=0.01735   val_loss=0.01890   sm_loss=0.01735   sm_val_loss=0.01881   time=0.92s\n",
      "Epoch 5   loss=0.01730   val_loss=0.01824   sm_loss=0.01732   sm_val_loss=0.01821   time=1.11s\n",
      "Epoch 11   loss=0.01674   val_loss=0.01821   sm_loss=0.01677   sm_val_loss=0.01820   time=1.08s\n",
      "Epoch 12   loss=0.01657   val_loss=0.01800   sm_loss=0.01660   sm_val_loss=0.01800   time=1.17s\n",
      "Epoch 13   loss=0.01631   val_loss=0.01795   sm_loss=0.01634   sm_val_loss=0.01794   time=1.16s\n",
      "Epoch 15   loss=0.01568   val_loss=0.01789   sm_loss=0.01572   sm_val_loss=0.01786   time=0.90s\n",
      "Epoch 16   loss=0.01526   val_loss=0.01772   sm_loss=0.01530   sm_val_loss=0.01770   time=0.94s\n",
      "Epoch 17   loss=0.01474   val_loss=0.01772   sm_loss=0.01478   sm_val_loss=0.01769   time=0.93s\n",
      "Epoch 18   loss=0.01424   val_loss=0.01760   sm_loss=0.01429   sm_val_loss=0.01758   time=0.87s\n",
      "Fold 3 log loss: 0.017576017903490053\n",
      "Fold 4\n",
      "Epoch 1   loss=0.41473   val_loss=0.02188   sm_loss=0.41471   sm_val_loss=0.02188   time=0.93s\n",
      "Epoch 2   loss=0.02003   val_loss=0.01854   sm_loss=0.01999   sm_val_loss=0.01855   time=0.90s\n",
      "Epoch 3   loss=0.01866   val_loss=0.01824   sm_loss=0.01854   sm_val_loss=0.01823   time=0.92s\n",
      "Epoch 4   loss=0.01761   val_loss=0.01791   sm_loss=0.01761   sm_val_loss=0.01789   time=0.88s\n",
      "Epoch 8   loss=0.01720   val_loss=0.01783   sm_loss=0.01723   sm_val_loss=0.01781   time=1.06s\n",
      "Epoch 10   loss=0.01693   val_loss=0.01778   sm_loss=0.01696   sm_val_loss=0.01777   time=0.89s\n",
      "Epoch 11   loss=0.01686   val_loss=0.01750   sm_loss=0.01689   sm_val_loss=0.01750   time=0.87s\n",
      "Epoch 13   loss=0.01635   val_loss=0.01745   sm_loss=0.01638   sm_val_loss=0.01743   time=0.88s\n",
      "Epoch 15   loss=0.01571   val_loss=0.01726   sm_loss=0.01575   sm_val_loss=0.01726   time=0.90s\n",
      "Epoch 16   loss=0.01525   val_loss=0.01719   sm_loss=0.01529   sm_val_loss=0.01718   time=0.90s\n",
      "Fold 4 log loss: 0.017221081272781914\n",
      "Fold 5\n",
      "Epoch 1   loss=0.41407   val_loss=0.02193   sm_loss=0.41401   sm_val_loss=0.02192   time=0.94s\n",
      "Epoch 2   loss=0.02007   val_loss=0.02241   sm_loss=0.02000   sm_val_loss=0.02136   time=1.24s\n",
      "Epoch 3   loss=0.01820   val_loss=0.01751   sm_loss=0.01812   sm_val_loss=0.01750   time=1.11s\n",
      "Epoch 5   loss=0.01729   val_loss=0.01742   sm_loss=0.01732   sm_val_loss=0.01738   time=0.92s\n",
      "Epoch 9   loss=0.01718   val_loss=0.01739   sm_loss=0.01720   sm_val_loss=0.01738   time=0.90s\n",
      "Epoch 11   loss=0.01692   val_loss=0.01737   sm_loss=0.01695   sm_val_loss=0.01734   time=0.93s\n",
      "Epoch 12   loss=0.01672   val_loss=0.01724   sm_loss=0.01675   sm_val_loss=0.01723   time=0.92s\n",
      "Epoch 15   loss=0.01587   val_loss=0.01702   sm_loss=0.01591   sm_val_loss=0.01701   time=0.88s\n",
      "Epoch 17   loss=0.01491   val_loss=0.01692   sm_loss=0.01495   sm_val_loss=0.01689   time=0.92s\n",
      "Epoch 18   loss=0.01450   val_loss=0.01690   sm_loss=0.01455   sm_val_loss=0.01688   time=0.89s\n",
      "Fold 5 log loss: 0.016902000877534507\n",
      "Fold 6\n",
      "Epoch 1   loss=0.41331   val_loss=0.02365   sm_loss=0.41326   sm_val_loss=0.02365   time=1.05s\n",
      "Epoch 2   loss=0.01998   val_loss=0.02059   sm_loss=0.01993   sm_val_loss=0.02039   time=0.98s\n",
      "Epoch 3   loss=0.01779   val_loss=0.01916   sm_loss=0.01780   sm_val_loss=0.01913   time=1.46s\n",
      "Epoch 4   loss=0.01727   val_loss=0.01926   sm_loss=0.01728   sm_val_loss=0.01912   time=0.88s\n",
      "Epoch 5   loss=0.01715   val_loss=0.01896   sm_loss=0.01717   sm_val_loss=0.01888   time=0.93s\n",
      "Epoch 8   loss=0.01701   val_loss=0.01870   sm_loss=0.01703   sm_val_loss=0.01868   time=0.94s\n",
      "Epoch 9   loss=0.01702   val_loss=0.01853   sm_loss=0.01705   sm_val_loss=0.01852   time=0.92s\n",
      "Epoch 11   loss=0.01678   val_loss=0.01843   sm_loss=0.01680   sm_val_loss=0.01841   time=0.97s\n",
      "Epoch 12   loss=0.01651   val_loss=0.01836   sm_loss=0.01654   sm_val_loss=0.01835   time=1.40s\n",
      "Epoch 13   loss=0.01627   val_loss=0.01819   sm_loss=0.01630   sm_val_loss=0.01816   time=1.05s\n",
      "Epoch 15   loss=0.01562   val_loss=0.01798   sm_loss=0.01566   sm_val_loss=0.01796   time=0.90s\n",
      "Epoch 16   loss=0.01523   val_loss=0.01788   sm_loss=0.01527   sm_val_loss=0.01788   time=0.93s\n",
      "Epoch 17   loss=0.01479   val_loss=0.01773   sm_loss=0.01483   sm_val_loss=0.01772   time=1.08s\n",
      "Epoch 18   loss=0.01429   val_loss=0.01767   sm_loss=0.01434   sm_val_loss=0.01767   time=0.93s\n",
      "Fold 6 log loss: 0.017886025099748626\n",
      "Fold 7\n",
      "Epoch 1   loss=0.41475   val_loss=0.02214   sm_loss=0.41474   sm_val_loss=0.02213   time=1.00s\n",
      "Epoch 2   loss=0.02018   val_loss=0.01879   sm_loss=0.02012   sm_val_loss=0.01872   time=0.87s\n",
      "Epoch 3   loss=0.01811   val_loss=0.01854   sm_loss=0.01806   sm_val_loss=0.01854   time=0.90s\n",
      "Epoch 4   loss=0.01757   val_loss=0.01784   sm_loss=0.01758   sm_val_loss=0.01784   time=0.89s\n",
      "Epoch 6   loss=0.01730   val_loss=0.01768   sm_loss=0.01733   sm_val_loss=0.01768   time=0.87s\n",
      "Epoch 8   loss=0.01728   val_loss=0.01759   sm_loss=0.01730   sm_val_loss=0.01758   time=0.87s\n",
      "Epoch 12   loss=0.01668   val_loss=0.01726   sm_loss=0.01672   sm_val_loss=0.01727   time=0.88s\n",
      "Epoch 14   loss=0.01620   val_loss=0.01709   sm_loss=0.01624   sm_val_loss=0.01708   time=0.88s\n",
      "Epoch 16   loss=0.01537   val_loss=0.01707   sm_loss=0.01541   sm_val_loss=0.01705   time=0.88s\n",
      "Epoch 17   loss=0.01489   val_loss=0.01695   sm_loss=0.01493   sm_val_loss=0.01694   time=0.85s\n",
      "Epoch 18   loss=0.01443   val_loss=0.01694   sm_loss=0.01448   sm_val_loss=0.01692   time=0.92s\n",
      "Epoch 20   loss=0.01378   val_loss=0.01692   sm_loss=0.01383   sm_val_loss=0.01690   time=0.88s\n",
      "Fold 7 log loss: 0.016927289966022538\n",
      "Seed 1\n",
      "Fold 1 log loss: 0.017053308968608336\n",
      "Fold 2 log loss: 0.016740286369548277\n",
      "Fold 3 log loss: 0.017576017903490053\n",
      "Fold 4 log loss: 0.017221081272781914\n",
      "Fold 5 log loss: 0.016902000877534507\n",
      "Fold 6 log loss: 0.017886025099748626\n",
      "Fold 7 log loss: 0.016927289966022538\n",
      "Std of log loss: 0.00037932862435083374\n",
      "Total log loss: 0.01718568473533898\n",
      "Fold 1\n",
      "Epoch 1   loss=0.41386   val_loss=0.02309   sm_loss=0.41379   sm_val_loss=0.02307   time=1.26s\n",
      "Epoch 2   loss=0.02021   val_loss=0.01911   sm_loss=0.02014   sm_val_loss=0.01910   time=0.97s\n",
      "Epoch 3   loss=0.01814   val_loss=0.01808   sm_loss=0.01811   sm_val_loss=0.01808   time=0.93s\n",
      "Epoch 4   loss=0.01740   val_loss=0.01787   sm_loss=0.01741   sm_val_loss=0.01786   time=0.87s\n",
      "Epoch 6   loss=0.01738   val_loss=0.01773   sm_loss=0.01741   sm_val_loss=0.01768   time=0.88s\n",
      "Epoch 12   loss=0.01679   val_loss=0.01764   sm_loss=0.01682   sm_val_loss=0.01763   time=1.06s\n",
      "Epoch 13   loss=0.01638   val_loss=0.01747   sm_loss=0.01641   sm_val_loss=0.01745   time=0.93s\n",
      "Epoch 14   loss=0.01611   val_loss=0.01719   sm_loss=0.01615   sm_val_loss=0.01718   time=0.91s\n",
      "Epoch 16   loss=0.01538   val_loss=0.01711   sm_loss=0.01543   sm_val_loss=0.01709   time=0.90s\n",
      "Epoch 17   loss=0.01492   val_loss=0.01705   sm_loss=0.01496   sm_val_loss=0.01702   time=1.01s\n",
      "Fold 1 log loss: 0.017093704869406562\n",
      "Fold 2\n",
      "Epoch 1   loss=0.41439   val_loss=0.02222   sm_loss=0.41434   sm_val_loss=0.02222   time=1.46s\n",
      "Epoch 2   loss=0.02011   val_loss=0.01961   sm_loss=0.02004   sm_val_loss=0.01953   time=0.95s\n",
      "Epoch 3   loss=0.01821   val_loss=0.01821   sm_loss=0.01817   sm_val_loss=0.01823   time=0.91s\n",
      "Epoch 4   loss=0.01737   val_loss=0.01775   sm_loss=0.01740   sm_val_loss=0.01775   time=0.96s\n",
      "Epoch 6   loss=0.01732   val_loss=0.01765   sm_loss=0.01735   sm_val_loss=0.01763   time=0.91s\n",
      "Epoch 7   loss=0.01730   val_loss=0.01741   sm_loss=0.01733   sm_val_loss=0.01739   time=0.88s\n",
      "Epoch 11   loss=0.01693   val_loss=0.01726   sm_loss=0.01695   sm_val_loss=0.01724   time=0.99s\n",
      "Epoch 12   loss=0.01677   val_loss=0.01721   sm_loss=0.01680   sm_val_loss=0.01720   time=1.74s\n",
      "Epoch 13   loss=0.01650   val_loss=0.01714   sm_loss=0.01653   sm_val_loss=0.01713   time=1.11s\n",
      "Epoch 14   loss=0.01617   val_loss=0.01702   sm_loss=0.01621   sm_val_loss=0.01700   time=0.89s\n",
      "Epoch 15   loss=0.01582   val_loss=0.01674   sm_loss=0.01586   sm_val_loss=0.01674   time=1.02s\n",
      "Epoch 17   loss=0.01494   val_loss=0.01669   sm_loss=0.01499   sm_val_loss=0.01668   time=0.88s\n",
      "Epoch 18   loss=0.01442   val_loss=0.01668   sm_loss=0.01447   sm_val_loss=0.01666   time=0.90s\n",
      "Epoch 19   loss=0.01406   val_loss=0.01661   sm_loss=0.01411   sm_val_loss=0.01659   time=1.00s\n",
      "Fold 2 log loss: 0.016565946014738483\n",
      "Fold 3\n",
      "Epoch 1   loss=0.41518   val_loss=0.02353   sm_loss=0.41513   sm_val_loss=0.02353   time=1.12s\n",
      "Epoch 2   loss=0.01996   val_loss=0.01940   sm_loss=0.01992   sm_val_loss=0.01936   time=0.87s\n",
      "Epoch 3   loss=0.01792   val_loss=0.01894   sm_loss=0.01790   sm_val_loss=0.01886   time=0.88s\n",
      "Epoch 4   loss=0.01730   val_loss=0.01852   sm_loss=0.01731   sm_val_loss=0.01849   time=0.85s\n",
      "Epoch 7   loss=0.01715   val_loss=0.01844   sm_loss=0.01718   sm_val_loss=0.01844   time=0.91s\n",
      "Epoch 9   loss=0.01698   val_loss=0.01829   sm_loss=0.01701   sm_val_loss=0.01828   time=0.90s\n",
      "Epoch 10   loss=0.01693   val_loss=0.01823   sm_loss=0.01696   sm_val_loss=0.01823   time=0.91s\n",
      "Epoch 12   loss=0.01659   val_loss=0.01813   sm_loss=0.01662   sm_val_loss=0.01809   time=1.04s\n",
      "Epoch 14   loss=0.01607   val_loss=0.01800   sm_loss=0.01611   sm_val_loss=0.01799   time=0.99s\n",
      "Epoch 15   loss=0.01572   val_loss=0.01782   sm_loss=0.01576   sm_val_loss=0.01779   time=0.87s\n",
      "Epoch 17   loss=0.01483   val_loss=0.01768   sm_loss=0.01488   sm_val_loss=0.01766   time=0.85s\n",
      "Epoch 18   loss=0.01437   val_loss=0.01767   sm_loss=0.01442   sm_val_loss=0.01765   time=0.86s\n",
      "Epoch 19   loss=0.01399   val_loss=0.01766   sm_loss=0.01404   sm_val_loss=0.01763   time=0.88s\n",
      "Fold 3 log loss: 0.01762373257545795\n",
      "Fold 4\n",
      "Epoch 1   loss=0.41383   val_loss=0.02215   sm_loss=0.41381   sm_val_loss=0.02213   time=1.09s\n",
      "Epoch 2   loss=0.02004   val_loss=0.02108   sm_loss=0.02000   sm_val_loss=0.02101   time=1.33s\n",
      "Epoch 3   loss=0.01824   val_loss=0.01785   sm_loss=0.01819   sm_val_loss=0.01786   time=0.91s\n",
      "Epoch 7   loss=0.01719   val_loss=0.01778   sm_loss=0.01722   sm_val_loss=0.01778   time=0.88s\n",
      "Epoch 10   loss=0.01696   val_loss=0.01774   sm_loss=0.01699   sm_val_loss=0.01773   time=1.03s\n",
      "Epoch 11   loss=0.01673   val_loss=0.01752   sm_loss=0.01676   sm_val_loss=0.01751   time=1.08s\n",
      "Epoch 14   loss=0.01607   val_loss=0.01739   sm_loss=0.01611   sm_val_loss=0.01738   time=1.09s\n",
      "Epoch 16   loss=0.01522   val_loss=0.01729   sm_loss=0.01527   sm_val_loss=0.01728   time=0.92s\n",
      "Epoch 17   loss=0.01470   val_loss=0.01724   sm_loss=0.01475   sm_val_loss=0.01723   time=0.88s\n",
      "Fold 4 log loss: 0.01728488491238458\n",
      "Fold 5\n",
      "Epoch 1   loss=0.41394   val_loss=0.02210   sm_loss=0.41390   sm_val_loss=0.02209   time=0.98s\n",
      "Epoch 3   loss=0.01857   val_loss=0.01791   sm_loss=0.01845   sm_val_loss=0.01792   time=0.97s\n",
      "Epoch 4   loss=0.01760   val_loss=0.01770   sm_loss=0.01761   sm_val_loss=0.01770   time=1.14s\n",
      "Epoch 8   loss=0.01734   val_loss=0.01761   sm_loss=0.01737   sm_val_loss=0.01761   time=0.89s\n",
      "Epoch 9   loss=0.01728   val_loss=0.01757   sm_loss=0.01730   sm_val_loss=0.01753   time=1.04s\n",
      "Epoch 10   loss=0.01709   val_loss=0.01751   sm_loss=0.01711   sm_val_loss=0.01750   time=0.92s\n",
      "Epoch 12   loss=0.01675   val_loss=0.01720   sm_loss=0.01678   sm_val_loss=0.01717   time=1.24s\n",
      "Epoch 13   loss=0.01651   val_loss=0.01715   sm_loss=0.01655   sm_val_loss=0.01713   time=0.94s\n",
      "Epoch 14   loss=0.01628   val_loss=0.01703   sm_loss=0.01631   sm_val_loss=0.01700   time=1.26s\n",
      "Epoch 15   loss=0.01593   val_loss=0.01696   sm_loss=0.01597   sm_val_loss=0.01694   time=0.93s\n",
      "Epoch 16   loss=0.01559   val_loss=0.01693   sm_loss=0.01564   sm_val_loss=0.01690   time=1.04s\n",
      "Epoch 17   loss=0.01507   val_loss=0.01688   sm_loss=0.01511   sm_val_loss=0.01686   time=0.92s\n",
      "Fold 5 log loss: 0.016864753336892992\n",
      "Fold 6\n",
      "Epoch 1   loss=0.41337   val_loss=0.02329   sm_loss=0.41333   sm_val_loss=0.02328   time=0.88s\n",
      "Epoch 3   loss=0.01782   val_loss=0.01874   sm_loss=0.01782   sm_val_loss=0.01874   time=0.97s\n",
      "Epoch 4   loss=0.01729   val_loss=0.01870   sm_loss=0.01731   sm_val_loss=0.01862   time=1.06s\n",
      "Epoch 7   loss=0.01710   val_loss=0.01863   sm_loss=0.01713   sm_val_loss=0.01861   time=0.89s\n",
      "Epoch 10   loss=0.01684   val_loss=0.01848   sm_loss=0.01687   sm_val_loss=0.01843   time=0.86s\n",
      "Epoch 11   loss=0.01662   val_loss=0.01820   sm_loss=0.01666   sm_val_loss=0.01820   time=0.88s\n",
      "Epoch 12   loss=0.01654   val_loss=0.01818   sm_loss=0.01657   sm_val_loss=0.01818   time=0.85s\n",
      "Epoch 13   loss=0.01627   val_loss=0.01808   sm_loss=0.01630   sm_val_loss=0.01803   time=0.86s\n",
      "Epoch 15   loss=0.01567   val_loss=0.01773   sm_loss=0.01571   sm_val_loss=0.01771   time=1.14s\n",
      "Epoch 17   loss=0.01477   val_loss=0.01772   sm_loss=0.01482   sm_val_loss=0.01770   time=0.86s\n",
      "Epoch 18   loss=0.01427   val_loss=0.01767   sm_loss=0.01432   sm_val_loss=0.01765   time=0.89s\n",
      "Fold 6 log loss: 0.01790634020678191\n",
      "Fold 7\n",
      "Epoch 1   loss=0.41425   val_loss=0.02380   sm_loss=0.41421   sm_val_loss=0.02379   time=1.03s\n",
      "Epoch 2   loss=0.02007   val_loss=0.01922   sm_loss=0.02003   sm_val_loss=0.01922   time=1.24s\n",
      "Epoch 3   loss=0.01804   val_loss=0.01784   sm_loss=0.01799   sm_val_loss=0.01785   time=1.00s\n",
      "Epoch 4   loss=0.01741   val_loss=0.01764   sm_loss=0.01743   sm_val_loss=0.01766   time=0.94s\n",
      "Epoch 6   loss=0.01728   val_loss=0.01746   sm_loss=0.01731   sm_val_loss=0.01745   time=0.88s\n",
      "Epoch 12   loss=0.01671   val_loss=0.01730   sm_loss=0.01674   sm_val_loss=0.01728   time=1.30s\n",
      "Epoch 13   loss=0.01644   val_loss=0.01723   sm_loss=0.01648   sm_val_loss=0.01723   time=0.88s\n",
      "Epoch 15   loss=0.01577   val_loss=0.01699   sm_loss=0.01581   sm_val_loss=0.01699   time=0.92s\n",
      "Epoch 16   loss=0.01534   val_loss=0.01690   sm_loss=0.01538   sm_val_loss=0.01690   time=1.09s\n",
      "Fold 7 log loss: 0.01692604186734316\n",
      "Seed 2\n",
      "Fold 1 log loss: 0.017093704869406562\n",
      "Fold 2 log loss: 0.016565946014738483\n",
      "Fold 3 log loss: 0.01762373257545795\n",
      "Fold 4 log loss: 0.01728488491238458\n",
      "Fold 5 log loss: 0.016864753336892992\n",
      "Fold 6 log loss: 0.01790634020678191\n",
      "Fold 7 log loss: 0.01692604186734316\n",
      "Std of log loss: 0.0004282605525221154\n",
      "Total log loss: 0.017179849422669303\n",
      "Fold 1\n",
      "Epoch 1   loss=0.41418   val_loss=0.02231   sm_loss=0.41410   sm_val_loss=0.02229   time=1.01s\n",
      "Epoch 3   loss=0.01793   val_loss=0.01853   sm_loss=0.01792   sm_val_loss=0.01852   time=0.88s\n",
      "Epoch 4   loss=0.01742   val_loss=0.01828   sm_loss=0.01744   sm_val_loss=0.01827   time=0.88s\n",
      "Epoch 5   loss=0.01732   val_loss=0.01810   sm_loss=0.01735   sm_val_loss=0.01809   time=1.10s\n",
      "Epoch 6   loss=0.01722   val_loss=0.01778   sm_loss=0.01724   sm_val_loss=0.01775   time=0.86s\n",
      "Epoch 10   loss=0.01698   val_loss=0.01756   sm_loss=0.01701   sm_val_loss=0.01754   time=0.88s\n",
      "Epoch 12   loss=0.01667   val_loss=0.01747   sm_loss=0.01670   sm_val_loss=0.01746   time=1.10s\n",
      "Epoch 13   loss=0.01636   val_loss=0.01747   sm_loss=0.01639   sm_val_loss=0.01745   time=1.00s\n",
      "Epoch 14   loss=0.01617   val_loss=0.01710   sm_loss=0.01621   sm_val_loss=0.01708   time=0.89s\n",
      "Epoch 15   loss=0.01572   val_loss=0.01708   sm_loss=0.01576   sm_val_loss=0.01706   time=0.90s\n",
      "Epoch 19   loss=0.01399   val_loss=0.01707   sm_loss=0.01404   sm_val_loss=0.01703   time=0.89s\n",
      "Fold 1 log loss: 0.017097290536426012\n",
      "Fold 2\n",
      "Epoch 1   loss=0.41388   val_loss=0.02246   sm_loss=0.41384   sm_val_loss=0.02245   time=0.86s\n",
      "Epoch 2   loss=0.02013   val_loss=0.01840   sm_loss=0.02007   sm_val_loss=0.01834   time=0.96s\n",
      "Epoch 3   loss=0.01810   val_loss=0.01761   sm_loss=0.01808   sm_val_loss=0.01760   time=0.86s\n",
      "Epoch 8   loss=0.01726   val_loss=0.01752   sm_loss=0.01728   sm_val_loss=0.01751   time=0.85s\n",
      "Epoch 9   loss=0.01709   val_loss=0.01741   sm_loss=0.01712   sm_val_loss=0.01738   time=0.85s\n",
      "Epoch 10   loss=0.01700   val_loss=0.01737   sm_loss=0.01703   sm_val_loss=0.01736   time=0.84s\n",
      "Epoch 12   loss=0.01669   val_loss=0.01716   sm_loss=0.01672   sm_val_loss=0.01716   time=0.85s\n",
      "Epoch 13   loss=0.01644   val_loss=0.01714   sm_loss=0.01647   sm_val_loss=0.01709   time=0.93s\n",
      "Epoch 14   loss=0.01611   val_loss=0.01706   sm_loss=0.01615   sm_val_loss=0.01703   time=0.87s\n",
      "Epoch 15   loss=0.01579   val_loss=0.01700   sm_loss=0.01583   sm_val_loss=0.01696   time=0.86s\n",
      "Epoch 16   loss=0.01534   val_loss=0.01685   sm_loss=0.01538   sm_val_loss=0.01685   time=1.01s\n",
      "Epoch 17   loss=0.01482   val_loss=0.01682   sm_loss=0.01487   sm_val_loss=0.01678   time=0.86s\n",
      "Epoch 18   loss=0.01435   val_loss=0.01674   sm_loss=0.01440   sm_val_loss=0.01671   time=1.12s\n",
      "Fold 2 log loss: 0.01669065060705801\n",
      "Fold 3\n",
      "Epoch 1   loss=0.41522   val_loss=0.02282   sm_loss=0.41520   sm_val_loss=0.02280   time=0.86s\n",
      "Epoch 2   loss=0.02001   val_loss=0.01965   sm_loss=0.01996   sm_val_loss=0.01964   time=0.96s\n",
      "Epoch 3   loss=0.01811   val_loss=0.01896   sm_loss=0.01808   sm_val_loss=0.01893   time=1.12s\n",
      "Epoch 4   loss=0.01735   val_loss=0.01860   sm_loss=0.01738   sm_val_loss=0.01857   time=1.04s\n",
      "Epoch 6   loss=0.01718   val_loss=0.01845   sm_loss=0.01721   sm_val_loss=0.01843   time=0.87s\n",
      "Epoch 7   loss=0.01709   val_loss=0.01842   sm_loss=0.01712   sm_val_loss=0.01839   time=0.92s\n",
      "Epoch 8   loss=0.01717   val_loss=0.01827   sm_loss=0.01720   sm_val_loss=0.01824   time=1.50s\n",
      "Epoch 11   loss=0.01673   val_loss=0.01811   sm_loss=0.01677   sm_val_loss=0.01808   time=1.09s\n",
      "Epoch 13   loss=0.01639   val_loss=0.01788   sm_loss=0.01642   sm_val_loss=0.01786   time=1.08s\n",
      "Epoch 15   loss=0.01572   val_loss=0.01780   sm_loss=0.01576   sm_val_loss=0.01780   time=0.99s\n",
      "Epoch 16   loss=0.01527   val_loss=0.01776   sm_loss=0.01531   sm_val_loss=0.01774   time=0.93s\n",
      "Epoch 18   loss=0.01431   val_loss=0.01768   sm_loss=0.01436   sm_val_loss=0.01767   time=0.99s\n",
      "Epoch 19   loss=0.01390   val_loss=0.01767   sm_loss=0.01395   sm_val_loss=0.01765   time=0.86s\n",
      "Epoch 20   loss=0.01367   val_loss=0.01764   sm_loss=0.01372   sm_val_loss=0.01762   time=0.85s\n",
      "Fold 3 log loss: 0.017621920580601212\n",
      "Fold 4\n",
      "Epoch 1   loss=0.41474   val_loss=0.02253   sm_loss=0.41471   sm_val_loss=0.02253   time=1.00s\n",
      "Epoch 2   loss=0.01998   val_loss=0.01855   sm_loss=0.01994   sm_val_loss=0.01855   time=0.87s\n",
      "Epoch 3   loss=0.01794   val_loss=0.01804   sm_loss=0.01793   sm_val_loss=0.01807   time=0.85s\n",
      "Epoch 5   loss=0.01726   val_loss=0.01795   sm_loss=0.01729   sm_val_loss=0.01795   time=0.87s\n",
      "Epoch 9   loss=0.01710   val_loss=0.01782   sm_loss=0.01712   sm_val_loss=0.01782   time=0.87s\n",
      "Epoch 11   loss=0.01684   val_loss=0.01775   sm_loss=0.01688   sm_val_loss=0.01773   time=0.89s\n",
      "Epoch 12   loss=0.01660   val_loss=0.01749   sm_loss=0.01664   sm_val_loss=0.01748   time=1.18s\n",
      "Epoch 13   loss=0.01636   val_loss=0.01745   sm_loss=0.01640   sm_val_loss=0.01744   time=1.02s\n",
      "Epoch 15   loss=0.01577   val_loss=0.01739   sm_loss=0.01581   sm_val_loss=0.01738   time=0.98s\n",
      "Epoch 16   loss=0.01527   val_loss=0.01739   sm_loss=0.01531   sm_val_loss=0.01737   time=0.91s\n",
      "Epoch 17   loss=0.01478   val_loss=0.01723   sm_loss=0.01483   sm_val_loss=0.01720   time=0.89s\n",
      "Epoch 18   loss=0.01431   val_loss=0.01717   sm_loss=0.01436   sm_val_loss=0.01715   time=0.89s\n",
      "Fold 4 log loss: 0.01720126300809085\n",
      "Fold 5\n",
      "Epoch 1   loss=0.41434   val_loss=0.02217   sm_loss=0.41427   sm_val_loss=0.02216   time=1.04s\n",
      "Epoch 2   loss=0.02030   val_loss=0.02315   sm_loss=0.02024   sm_val_loss=0.02171   time=0.87s\n",
      "Epoch 3   loss=0.01844   val_loss=0.01794   sm_loss=0.01841   sm_val_loss=0.01794   time=0.95s\n",
      "Epoch 4   loss=0.01756   val_loss=0.01786   sm_loss=0.01758   sm_val_loss=0.01786   time=0.86s\n",
      "Epoch 6   loss=0.01735   val_loss=0.01759   sm_loss=0.01737   sm_val_loss=0.01758   time=0.88s\n",
      "Epoch 7   loss=0.01733   val_loss=0.01738   sm_loss=0.01735   sm_val_loss=0.01735   time=0.91s\n",
      "Epoch 13   loss=0.01642   val_loss=0.01713   sm_loss=0.01646   sm_val_loss=0.01711   time=0.91s\n",
      "Epoch 14   loss=0.01616   val_loss=0.01707   sm_loss=0.01620   sm_val_loss=0.01705   time=0.98s\n",
      "Epoch 15   loss=0.01581   val_loss=0.01705   sm_loss=0.01585   sm_val_loss=0.01702   time=0.87s\n",
      "Epoch 16   loss=0.01537   val_loss=0.01694   sm_loss=0.01541   sm_val_loss=0.01691   time=0.86s\n",
      "Epoch 18   loss=0.01434   val_loss=0.01692   sm_loss=0.01438   sm_val_loss=0.01689   time=0.86s\n",
      "Epoch 20   loss=0.01371   val_loss=0.01691   sm_loss=0.01376   sm_val_loss=0.01688   time=1.20s\n",
      "Fold 5 log loss: 0.016907210848371268\n",
      "Fold 6\n",
      "Epoch 1   loss=0.41211   val_loss=0.02343   sm_loss=0.41208   sm_val_loss=0.02341   time=0.98s\n",
      "Epoch 3   loss=0.01788   val_loss=0.01911   sm_loss=0.01788   sm_val_loss=0.01897   time=1.06s\n",
      "Epoch 4   loss=0.01723   val_loss=0.01892   sm_loss=0.01726   sm_val_loss=0.01882   time=1.42s\n",
      "Epoch 5   loss=0.01717   val_loss=0.01880   sm_loss=0.01720   sm_val_loss=0.01878   time=0.87s\n",
      "Epoch 6   loss=0.01708   val_loss=0.01865   sm_loss=0.01711   sm_val_loss=0.01860   time=1.08s\n",
      "Epoch 7   loss=0.01704   val_loss=0.01856   sm_loss=0.01706   sm_val_loss=0.01853   time=1.04s\n",
      "Epoch 9   loss=0.01697   val_loss=0.01840   sm_loss=0.01700   sm_val_loss=0.01837   time=1.22s\n",
      "Epoch 13   loss=0.01634   val_loss=0.01812   sm_loss=0.01638   sm_val_loss=0.01809   time=0.90s\n",
      "Epoch 14   loss=0.01601   val_loss=0.01808   sm_loss=0.01605   sm_val_loss=0.01805   time=0.88s\n",
      "Epoch 15   loss=0.01571   val_loss=0.01789   sm_loss=0.01574   sm_val_loss=0.01789   time=0.94s\n",
      "Epoch 16   loss=0.01528   val_loss=0.01782   sm_loss=0.01532   sm_val_loss=0.01781   time=0.87s\n",
      "Epoch 17   loss=0.01477   val_loss=0.01774   sm_loss=0.01481   sm_val_loss=0.01774   time=0.85s\n",
      "Epoch 18   loss=0.01426   val_loss=0.01769   sm_loss=0.01431   sm_val_loss=0.01770   time=0.86s\n",
      "Epoch 19   loss=0.01392   val_loss=0.01769   sm_loss=0.01396   sm_val_loss=0.01769   time=0.86s\n",
      "Fold 6 log loss: 0.01789692345686472\n",
      "Fold 7\n",
      "Epoch 1   loss=0.41562   val_loss=0.02226   sm_loss=0.41557   sm_val_loss=0.02226   time=0.96s\n",
      "Epoch 2   loss=0.02015   val_loss=0.01856   sm_loss=0.02006   sm_val_loss=0.01857   time=0.89s\n",
      "Epoch 3   loss=0.01852   val_loss=0.01786   sm_loss=0.01844   sm_val_loss=0.01786   time=0.95s\n",
      "Epoch 5   loss=0.01738   val_loss=0.01766   sm_loss=0.01740   sm_val_loss=0.01767   time=0.92s\n",
      "Epoch 7   loss=0.01715   val_loss=0.01763   sm_loss=0.01718   sm_val_loss=0.01762   time=0.87s\n",
      "Epoch 9   loss=0.01704   val_loss=0.01755   sm_loss=0.01707   sm_val_loss=0.01756   time=1.03s\n",
      "Epoch 11   loss=0.01686   val_loss=0.01747   sm_loss=0.01689   sm_val_loss=0.01748   time=0.90s\n",
      "Epoch 13   loss=0.01645   val_loss=0.01741   sm_loss=0.01648   sm_val_loss=0.01739   time=1.13s\n",
      "Epoch 14   loss=0.01604   val_loss=0.01722   sm_loss=0.01608   sm_val_loss=0.01721   time=0.96s\n",
      "Epoch 15   loss=0.01572   val_loss=0.01712   sm_loss=0.01576   sm_val_loss=0.01710   time=0.88s\n",
      "Epoch 16   loss=0.01525   val_loss=0.01700   sm_loss=0.01530   sm_val_loss=0.01701   time=0.85s\n",
      "Epoch 17   loss=0.01483   val_loss=0.01691   sm_loss=0.01488   sm_val_loss=0.01691   time=0.86s\n",
      "Epoch 18   loss=0.01431   val_loss=0.01689   sm_loss=0.01435   sm_val_loss=0.01687   time=0.85s\n",
      "Fold 7 log loss: 0.01689321778591399\n",
      "Seed 3\n",
      "Fold 1 log loss: 0.017097290536426012\n",
      "Fold 2 log loss: 0.01669065060705801\n",
      "Fold 3 log loss: 0.017621920580601212\n",
      "Fold 4 log loss: 0.01720126300809085\n",
      "Fold 5 log loss: 0.016907210848371268\n",
      "Fold 6 log loss: 0.01789692345686472\n",
      "Fold 7 log loss: 0.01689321778591399\n",
      "Std of log loss: 0.00039863178260969654\n",
      "Total log loss: 0.017185985747059783\n",
      "Fold 1\n",
      "Epoch 1   loss=0.41298   val_loss=0.02293   sm_loss=0.41295   sm_val_loss=0.02289   time=0.93s\n",
      "Epoch 2   loss=0.02005   val_loss=0.01972   sm_loss=0.02000   sm_val_loss=0.01965   time=1.01s\n",
      "Epoch 3   loss=0.01806   val_loss=0.01824   sm_loss=0.01802   sm_val_loss=0.01823   time=0.84s\n",
      "Epoch 5   loss=0.01740   val_loss=0.01805   sm_loss=0.01743   sm_val_loss=0.01801   time=0.83s\n",
      "Epoch 7   loss=0.01731   val_loss=0.01757   sm_loss=0.01734   sm_val_loss=0.01757   time=1.03s\n",
      "Epoch 10   loss=0.01706   val_loss=0.01748   sm_loss=0.01708   sm_val_loss=0.01747   time=1.00s\n",
      "Epoch 13   loss=0.01646   val_loss=0.01721   sm_loss=0.01649   sm_val_loss=0.01720   time=0.88s\n",
      "Epoch 15   loss=0.01584   val_loss=0.01710   sm_loss=0.01588   sm_val_loss=0.01709   time=0.87s\n",
      "Epoch 17   loss=0.01494   val_loss=0.01709   sm_loss=0.01498   sm_val_loss=0.01707   time=0.88s\n",
      "Epoch 18   loss=0.01447   val_loss=0.01705   sm_loss=0.01452   sm_val_loss=0.01703   time=0.96s\n",
      "Epoch 19   loss=0.01413   val_loss=0.01702   sm_loss=0.01418   sm_val_loss=0.01699   time=1.10s\n",
      "Epoch 20   loss=0.01391   val_loss=0.01701   sm_loss=0.01396   sm_val_loss=0.01699   time=1.14s\n",
      "Fold 1 log loss: 0.017070266338537487\n",
      "Fold 2\n",
      "Epoch 1   loss=0.41430   val_loss=0.02186   sm_loss=0.41426   sm_val_loss=0.02185   time=1.00s\n",
      "Epoch 2   loss=0.02004   val_loss=0.01851   sm_loss=0.02001   sm_val_loss=0.01841   time=1.05s\n",
      "Epoch 3   loss=0.01836   val_loss=0.01792   sm_loss=0.01828   sm_val_loss=0.01793   time=0.87s\n",
      "Epoch 4   loss=0.01748   val_loss=0.01761   sm_loss=0.01749   sm_val_loss=0.01760   time=0.85s\n",
      "Epoch 5   loss=0.01736   val_loss=0.01765   sm_loss=0.01739   sm_val_loss=0.01760   time=0.90s\n",
      "Epoch 7   loss=0.01732   val_loss=0.01752   sm_loss=0.01734   sm_val_loss=0.01748   time=0.94s\n",
      "Epoch 11   loss=0.01695   val_loss=0.01730   sm_loss=0.01698   sm_val_loss=0.01730   time=0.95s\n",
      "Epoch 12   loss=0.01670   val_loss=0.01726   sm_loss=0.01674   sm_val_loss=0.01726   time=0.94s\n",
      "Epoch 14   loss=0.01617   val_loss=0.01711   sm_loss=0.01621   sm_val_loss=0.01708   time=0.84s\n",
      "Epoch 15   loss=0.01577   val_loss=0.01705   sm_loss=0.01581   sm_val_loss=0.01703   time=0.83s\n",
      "Epoch 16   loss=0.01534   val_loss=0.01690   sm_loss=0.01538   sm_val_loss=0.01688   time=0.87s\n",
      "Epoch 17   loss=0.01487   val_loss=0.01685   sm_loss=0.01492   sm_val_loss=0.01683   time=1.07s\n",
      "Epoch 18   loss=0.01432   val_loss=0.01676   sm_loss=0.01437   sm_val_loss=0.01674   time=1.04s\n",
      "Fold 2 log loss: 0.016719604706716778\n",
      "Fold 3\n",
      "Epoch 1   loss=0.41321   val_loss=0.02308   sm_loss=0.41317   sm_val_loss=0.02307   time=0.88s\n",
      "Epoch 3   loss=0.01802   val_loss=0.02317   sm_loss=0.01799   sm_val_loss=0.02271   time=0.85s\n",
      "Epoch 4   loss=0.01783   val_loss=0.01865   sm_loss=0.01783   sm_val_loss=0.01862   time=0.86s\n",
      "Epoch 6   loss=0.01717   val_loss=0.01839   sm_loss=0.01720   sm_val_loss=0.01838   time=0.86s\n",
      "Epoch 9   loss=0.01707   val_loss=0.01835   sm_loss=0.01710   sm_val_loss=0.01833   time=0.90s\n",
      "Epoch 12   loss=0.01660   val_loss=0.01826   sm_loss=0.01663   sm_val_loss=0.01824   time=1.00s\n",
      "Epoch 13   loss=0.01640   val_loss=0.01800   sm_loss=0.01644   sm_val_loss=0.01799   time=0.87s\n",
      "Epoch 15   loss=0.01576   val_loss=0.01794   sm_loss=0.01580   sm_val_loss=0.01792   time=0.88s\n",
      "Epoch 16   loss=0.01532   val_loss=0.01780   sm_loss=0.01536   sm_val_loss=0.01779   time=0.88s\n",
      "Epoch 17   loss=0.01484   val_loss=0.01766   sm_loss=0.01489   sm_val_loss=0.01764   time=0.87s\n",
      "Epoch 18   loss=0.01434   val_loss=0.01759   sm_loss=0.01439   sm_val_loss=0.01758   time=1.02s\n",
      "Epoch 19   loss=0.01396   val_loss=0.01760   sm_loss=0.01401   sm_val_loss=0.01758   time=0.85s\n",
      "Fold 3 log loss: 0.017573562455305523\n",
      "Fold 4\n",
      "Epoch 1   loss=0.41570   val_loss=0.02240   sm_loss=0.41565   sm_val_loss=0.02237   time=1.05s\n",
      "Epoch 3   loss=0.01822   val_loss=0.01790   sm_loss=0.01815   sm_val_loss=0.01792   time=0.84s\n",
      "Epoch 8   loss=0.01720   val_loss=0.01776   sm_loss=0.01723   sm_val_loss=0.01775   time=0.91s\n",
      "Epoch 12   loss=0.01669   val_loss=0.01755   sm_loss=0.01673   sm_val_loss=0.01754   time=0.84s\n",
      "Epoch 14   loss=0.01612   val_loss=0.01738   sm_loss=0.01615   sm_val_loss=0.01738   time=1.08s\n",
      "Epoch 15   loss=0.01580   val_loss=0.01739   sm_loss=0.01584   sm_val_loss=0.01737   time=0.91s\n",
      "Epoch 17   loss=0.01481   val_loss=0.01728   sm_loss=0.01486   sm_val_loss=0.01727   time=0.96s\n",
      "Epoch 19   loss=0.01393   val_loss=0.01727   sm_loss=0.01398   sm_val_loss=0.01725   time=1.04s\n",
      "Fold 4 log loss: 0.01729763795710474\n",
      "Fold 5\n",
      "Epoch 1   loss=0.41317   val_loss=0.02229   sm_loss=0.41313   sm_val_loss=0.02227   time=1.05s\n",
      "Epoch 2   loss=0.02005   val_loss=0.01890   sm_loss=0.02000   sm_val_loss=0.01885   time=1.10s\n",
      "Epoch 3   loss=0.01828   val_loss=0.01772   sm_loss=0.01825   sm_val_loss=0.01773   time=1.09s\n",
      "Epoch 5   loss=0.01738   val_loss=0.01773   sm_loss=0.01740   sm_val_loss=0.01772   time=0.88s\n",
      "Epoch 6   loss=0.01741   val_loss=0.01768   sm_loss=0.01743   sm_val_loss=0.01766   time=0.95s\n",
      "Epoch 8   loss=0.01736   val_loss=0.01752   sm_loss=0.01739   sm_val_loss=0.01750   time=0.90s\n",
      "Epoch 9   loss=0.01722   val_loss=0.01750   sm_loss=0.01725   sm_val_loss=0.01749   time=0.89s\n",
      "Epoch 11   loss=0.01695   val_loss=0.01737   sm_loss=0.01698   sm_val_loss=0.01737   time=0.91s\n",
      "Epoch 12   loss=0.01680   val_loss=0.01722   sm_loss=0.01683   sm_val_loss=0.01721   time=0.88s\n",
      "Epoch 13   loss=0.01648   val_loss=0.01720   sm_loss=0.01652   sm_val_loss=0.01720   time=0.88s\n",
      "Epoch 14   loss=0.01619   val_loss=0.01705   sm_loss=0.01623   sm_val_loss=0.01704   time=1.08s\n",
      "Epoch 15   loss=0.01587   val_loss=0.01690   sm_loss=0.01591   sm_val_loss=0.01688   time=0.96s\n",
      "Epoch 16   loss=0.01545   val_loss=0.01688   sm_loss=0.01550   sm_val_loss=0.01687   time=0.85s\n",
      "Epoch 18   loss=0.01449   val_loss=0.01685   sm_loss=0.01454   sm_val_loss=0.01683   time=0.83s\n",
      "Fold 5 log loss: 0.01685871912714504\n",
      "Fold 6\n",
      "Epoch 1   loss=0.41321   val_loss=0.02384   sm_loss=0.41317   sm_val_loss=0.02383   time=0.87s\n",
      "Epoch 2   loss=0.01980   val_loss=0.02036   sm_loss=0.01977   sm_val_loss=0.01996   time=0.84s\n",
      "Epoch 3   loss=0.01800   val_loss=0.01941   sm_loss=0.01798   sm_val_loss=0.01920   time=0.85s\n",
      "Epoch 4   loss=0.01780   val_loss=0.01889   sm_loss=0.01780   sm_val_loss=0.01878   time=0.94s\n",
      "Epoch 6   loss=0.01709   val_loss=0.01849   sm_loss=0.01712   sm_val_loss=0.01843   time=0.99s\n",
      "Epoch 10   loss=0.01681   val_loss=0.01834   sm_loss=0.01684   sm_val_loss=0.01832   time=0.88s\n",
      "Epoch 11   loss=0.01669   val_loss=0.01819   sm_loss=0.01672   sm_val_loss=0.01816   time=0.87s\n",
      "Epoch 13   loss=0.01627   val_loss=0.01793   sm_loss=0.01631   sm_val_loss=0.01790   time=0.83s\n",
      "Epoch 16   loss=0.01522   val_loss=0.01787   sm_loss=0.01527   sm_val_loss=0.01785   time=1.07s\n",
      "Epoch 17   loss=0.01471   val_loss=0.01782   sm_loss=0.01475   sm_val_loss=0.01779   time=0.90s\n",
      "Epoch 18   loss=0.01422   val_loss=0.01776   sm_loss=0.01427   sm_val_loss=0.01773   time=0.85s\n",
      "Fold 6 log loss: 0.01795266905728358\n",
      "Fold 7\n",
      "Epoch 1   loss=0.41494   val_loss=0.02243   sm_loss=0.41490   sm_val_loss=0.02242   time=0.86s\n",
      "Epoch 2   loss=0.02005   val_loss=0.01871   sm_loss=0.01999   sm_val_loss=0.01872   time=0.87s\n",
      "Epoch 3   loss=0.01817   val_loss=0.01793   sm_loss=0.01812   sm_val_loss=0.01793   time=0.85s\n",
      "Epoch 4   loss=0.01735   val_loss=0.01780   sm_loss=0.01737   sm_val_loss=0.01782   time=0.88s\n",
      "Epoch 5   loss=0.01735   val_loss=0.01749   sm_loss=0.01737   sm_val_loss=0.01750   time=0.86s\n",
      "Epoch 11   loss=0.01686   val_loss=0.01750   sm_loss=0.01689   sm_val_loss=0.01749   time=0.84s\n",
      "Epoch 12   loss=0.01674   val_loss=0.01733   sm_loss=0.01677   sm_val_loss=0.01734   time=0.84s\n",
      "Epoch 14   loss=0.01610   val_loss=0.01726   sm_loss=0.01614   sm_val_loss=0.01726   time=0.84s\n",
      "Epoch 15   loss=0.01581   val_loss=0.01708   sm_loss=0.01585   sm_val_loss=0.01707   time=0.83s\n",
      "Epoch 17   loss=0.01486   val_loss=0.01697   sm_loss=0.01490   sm_val_loss=0.01696   time=1.04s\n",
      "Epoch 18   loss=0.01438   val_loss=0.01694   sm_loss=0.01443   sm_val_loss=0.01693   time=1.17s\n",
      "Epoch 19   loss=0.01398   val_loss=0.01691   sm_loss=0.01403   sm_val_loss=0.01690   time=1.13s\n",
      "Epoch 20   loss=0.01376   val_loss=0.01691   sm_loss=0.01380   sm_val_loss=0.01690   time=1.00s\n",
      "Fold 7 log loss: 0.016923997734915153\n",
      "Seed 4\n",
      "Fold 1 log loss: 0.017070266338537487\n",
      "Fold 2 log loss: 0.016719604706716778\n",
      "Fold 3 log loss: 0.017573562455305523\n",
      "Fold 4 log loss: 0.01729763795710474\n",
      "Fold 5 log loss: 0.01685871912714504\n",
      "Fold 6 log loss: 0.01795266905728358\n",
      "Fold 7 log loss: 0.016923997734915153\n",
      "Std of log loss: 0.0004063515966719434\n",
      "Total log loss: 0.01719846144433199\n",
      "Total log loss in targets: 0.016956087358588518\n"
     ]
    }
   ],
   "source": [
    "seeds = [0,1,2,3,4]\n",
    "target_oof = np.zeros([len(fn_train),fn_targets.shape[1]])\n",
    "target_pred = np.zeros([len(fn_test),fn_targets.shape[1]])\n",
    "\n",
    "for seed_ in seeds:\n",
    "    oof, oof_targets, pytorch_pred = modelling_torch(fn_train, fn_targets, fn_test, seed_, fn_train.shape[1]-1, fn_targets.shape[1], 20)\n",
    "    target_oof += oof / len(seeds)\n",
    "    target_pred += pytorch_pred / len(seeds)\n",
    "\n",
    "print(\"Total log loss in targets: {}\".format(mean_log_loss(oof_targets, target_oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:27:27.376113Z",
     "iopub.status.busy": "2020-11-12T03:27:27.375226Z",
     "iopub.status.idle": "2020-11-12T03:27:28.759920Z",
     "shell.execute_reply": "2020-11-12T03:27:28.759411Z"
    },
    "papermill": {
     "duration": 1.780711,
     "end_time": "2020-11-12T03:27:28.760030",
     "exception": false,
     "start_time": "2020-11-12T03:27:26.979319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AUC : 0.628494447804063\n"
     ]
    }
   ],
   "source": [
    "aucs = []\n",
    "for task_id in range(targets.shape[1]-1):\n",
    "    aucs.append(roc_auc_score(y_true=targets.iloc[:, task_id+1].values,\n",
    "                              y_score=target_oof[:, task_id]))\n",
    "print(f\"Overall AUC : {np.mean(aucs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:27:29.150617Z",
     "iopub.status.busy": "2020-11-12T03:27:29.149664Z",
     "iopub.status.idle": "2020-11-12T03:27:35.058627Z",
     "shell.execute_reply": "2020-11-12T03:27:35.059366Z"
    },
    "papermill": {
     "duration": 6.112863,
     "end_time": "2020-11-12T03:27:35.059523",
     "exception": false,
     "start_time": "2020-11-12T03:27:28.946660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF log loss:  0.015627454663068033\n"
     ]
    }
   ],
   "source": [
    "t = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "train_checkscore = t.copy()\n",
    "train_checkscore.loc[train_checkscore.index.isin(cons_train_index),target_feats] = target_oof\n",
    "train_checkscore.loc[train_checkscore.index.isin(noncons_train_index),target_feats] = 0\n",
    "t.drop(\"sig_id\", axis=1, inplace=True)\n",
    "print('OOF log loss: ', log_loss(np.ravel(t), np.ravel(np.array(train_checkscore.iloc[:,1:]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:27:35.439309Z",
     "iopub.status.busy": "2020-11-12T03:27:35.438362Z",
     "iopub.status.idle": "2020-11-12T03:27:37.860814Z",
     "shell.execute_reply": "2020-11-12T03:27:37.859727Z"
    },
    "papermill": {
     "duration": 2.61329,
     "end_time": "2020-11-12T03:27:37.860948",
     "exception": false,
     "start_time": "2020-11-12T03:27:35.247658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.loc[cons_test_index,target_feats] = target_pred\n",
    "sub.loc[noncons_test_index,target_feats] = 0\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.187386,
     "end_time": "2020-11-12T03:27:38.235061",
     "exception": false,
     "start_time": "2020-11-12T03:27:38.047675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 808.842851,
   "end_time": "2020-11-12T03:27:38.934407",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-12T03:14:10.091556",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
