{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011576,
     "end_time": "2020-10-05T08:20:37.294293",
     "exception": false,
     "start_time": "2020-10-05T08:20:37.282717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- change fold to 5\n",
    "- modify best_val_loss mistake\n",
    "- introduce weight decay\n",
    "- bcewithlogitloss instead of bceloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-05T08:20:37.325239Z",
     "iopub.status.busy": "2020-10-05T08:20:37.324382Z",
     "iopub.status.idle": "2020-10-05T08:20:44.786301Z",
     "shell.execute_reply": "2020-10-05T08:20:44.784694Z"
    },
    "papermill": {
     "duration": 7.481408,
     "end_time": "2020-10-05T08:20:44.786456",
     "exception": false,
     "start_time": "2020-10-05T08:20:37.305048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from category_encoders import CountEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "sys.path.append('../input/multilabelstraifier/')\n",
    "from ml_stratifiers import MultilabelStratifiedKFold\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T08:20:44.818665Z",
     "iopub.status.busy": "2020-10-05T08:20:44.817612Z",
     "iopub.status.idle": "2020-10-05T08:20:50.492406Z",
     "shell.execute_reply": "2020-10-05T08:20:50.491237Z"
    },
    "papermill": {
     "duration": 5.694223,
     "end_time": "2020-10-05T08:20:50.492552",
     "exception": false,
     "start_time": "2020-10-05T08:20:44.798329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/lish-moa/'\n",
    "train = pd.read_csv(DATA_DIR + 'train_features.csv')\n",
    "targets = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "#non_targets = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "test = pd.read_csv(DATA_DIR + 'test_features.csv')\n",
    "sub = pd.read_csv(DATA_DIR + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T08:20:50.522179Z",
     "iopub.status.busy": "2020-10-05T08:20:50.520298Z",
     "iopub.status.idle": "2020-10-05T08:20:50.522923Z",
     "shell.execute_reply": "2020-10-05T08:20:50.523436Z"
    },
    "papermill": {
     "duration": 0.02017,
     "end_time": "2020-10-05T08:20:50.523574",
     "exception": false,
     "start_time": "2020-10-05T08:20:50.503404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_feats = [ i for i in targets.columns if i != \"sig_id\"]\n",
    "g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "c_feats = [i for i in train.columns if \"c-\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T08:20:50.554424Z",
     "iopub.status.busy": "2020-10-05T08:20:50.550518Z",
     "iopub.status.idle": "2020-10-05T08:20:50.658689Z",
     "shell.execute_reply": "2020-10-05T08:20:50.658115Z"
    },
    "papermill": {
     "duration": 0.124781,
     "end_time": "2020-10-05T08:20:50.658806",
     "exception": false,
     "start_time": "2020-10-05T08:20:50.534025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "noncons_train_index = train[train.cp_type==\"ctl_vehicle\"].index\n",
    "cons_train_index = train[train.cp_type!=\"ctl_vehicle\"].index\n",
    "noncons_test_index = test[test.cp_type==\"ctl_vehicle\"].index\n",
    "cons_test_index = test[test.cp_type!=\"ctl_vehicle\"].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011206,
     "end_time": "2020-10-05T08:20:50.681583",
     "exception": false,
     "start_time": "2020-10-05T08:20:50.670377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T08:20:50.716105Z",
     "iopub.status.busy": "2020-10-05T08:20:50.715281Z",
     "iopub.status.idle": "2020-10-05T08:20:52.958430Z",
     "shell.execute_reply": "2020-10-05T08:20:52.957888Z"
    },
    "papermill": {
     "duration": 2.26544,
     "end_time": "2020-10-05T08:20:52.958559",
     "exception": false,
     "start_time": "2020-10-05T08:20:50.693119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# normalization by ctl group\n",
    "train_ctl = train[train.index.isin(noncons_train_index)].copy().reset_index(drop=True)\n",
    "test_ctl = test[test.index.isin(noncons_test_index)].copy().reset_index(drop=True)\n",
    "ctl_df = pd.concat([train_ctl, test_ctl])\n",
    "\n",
    "ctl_group_data = ctl_df.groupby([\"cp_dose\", \"cp_time\"]).agg({\"mean\"}).reset_index()\n",
    "mean_g_feats = [\"mean-\" + i for i in g_feats]\n",
    "mean_c_feats = [\"mean-\" + i for i in c_feats]\n",
    "columns = [\"cp_dose\", \"cp_time\"] + mean_g_feats + mean_c_feats\n",
    "ctl_group_data.columns = columns\n",
    "\n",
    "train = train[train.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "targets = targets[targets.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "#non_targets = non_targets[non_targets.index.isin(cons_train_index)].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011013,
     "end_time": "2020-10-05T08:20:52.982490",
     "exception": false,
     "start_time": "2020-10-05T08:20:52.971477",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T08:20:53.017843Z",
     "iopub.status.busy": "2020-10-05T08:20:53.016467Z",
     "iopub.status.idle": "2020-10-05T08:20:58.819398Z",
     "shell.execute_reply": "2020-10-05T08:20:58.821037Z"
    },
    "papermill": {
     "duration": 5.827701,
     "end_time": "2020-10-05T08:20:58.821216",
     "exception": false,
     "start_time": "2020-10-05T08:20:52.993515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 874) (3982, 874)\n"
     ]
    }
   ],
   "source": [
    "def fe(df, remove_features):\n",
    "    df = pd.merge(df, ctl_group_data, on=[\"cp_time\", \"cp_dose\"], how=\"left\")\n",
    "    for i in range(len(g_feats)):\n",
    "        df[\"diff-g-\"+str(i)] = df[\"g-\"+str(i)] - df[\"mean-g-\"+str(i)]\n",
    "    for i in range(len(c_feats)):\n",
    "        df[\"diff-c-\"+str(i)] = df[\"c-\"+str(i)] - df[\"mean-c-\"+str(i)]\n",
    "    \n",
    "    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "        \n",
    "    df.drop(remove_features, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "remove_features = [\"cp_type\" , \"sig_id\"] + mean_g_feats + mean_c_feats + g_feats + c_feats \n",
    "\n",
    "train = fe(train, remove_features)\n",
    "test = fe(test, remove_features)\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011626,
     "end_time": "2020-10-05T08:20:58.845273",
     "exception": false,
     "start_time": "2020-10-05T08:20:58.833647",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T08:20:58.915746Z",
     "iopub.status.busy": "2020-10-05T08:20:58.888695Z",
     "iopub.status.idle": "2020-10-05T08:20:59.277366Z",
     "shell.execute_reply": "2020-10-05T08:20:59.278094Z"
    },
    "papermill": {
     "duration": 0.421089,
     "end_time": "2020-10-05T08:20:59.278281",
     "exception": false,
     "start_time": "2020-10-05T08:20:58.857192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "batch_size = 128\n",
    "train_epochs = 40\n",
    "n_folds=5\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "\n",
    "def mean_log_loss(y_true, y_pred):\n",
    "    metrics = []\n",
    "    for i, target in enumerate(target_feats):\n",
    "        metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float), labels=[0,1]))\n",
    "    return np.mean(metrics)\n",
    "\n",
    "def seed_everything(seed=1234): \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "class MoaModel(nn.Module):\n",
    "    def __init__(self, num_columns):\n",
    "        super(MoaModel, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_columns)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_columns, 2048))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(2048)\n",
    "        self.dropout2 = nn.Dropout(0.6)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(2048, 1048))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(1048)\n",
    "        self.dropout3 = nn.Dropout(0.6)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(1048, 206))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "def modelling_torch(tr, target, te, sample_seed, init_num):\n",
    "    seed_everything(seed=sample_seed) \n",
    "    X_train = tr.copy()\n",
    "    y_train = target.copy()\n",
    "    X_test = te.copy()\n",
    "    test_len = X_test.shape[0]\n",
    "\n",
    "    mskf=MultilabelStratifiedKFold(n_splits = n_folds, shuffle=True, random_state=2)\n",
    "    models = []\n",
    "    \n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    X_test = torch.utils.data.TensorDataset(X_test) \n",
    "    test_loader = torch.utils.data.DataLoader(X_test, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    oof = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    oof_targets = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    pred_value = np.zeros([test_len, y_train.shape[1]])\n",
    "    scores = []\n",
    "    for fold, (train_index, valid_index) in enumerate(mskf.split(X_train, y_train)):\n",
    "        print(\"Fold \"+str(fold+1))\n",
    "        X_train2 = torch.tensor(X_train[train_index,:], dtype=torch.float32)\n",
    "        y_train2 = torch.tensor(y_train[train_index], dtype=torch.float32)\n",
    "\n",
    "        X_valid2 = torch.tensor(X_train[valid_index,:], dtype=torch.float32)\n",
    "        y_valid2 = torch.tensor(y_train[valid_index], dtype=torch.float32)\n",
    "            \n",
    "        clf = MoaModel(num_columns=init_num)\n",
    "        loss_fn = torch.nn.BCEWithLogitsLoss() \n",
    "        optimizer = optim.Adam(clf.parameters(), lr = 0.001, weight_decay=1e-5) \n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, eps=1e-4, verbose=True)\n",
    "        \n",
    "        train = torch.utils.data.TensorDataset(X_train2, y_train2)\n",
    "        valid = torch.utils.data.TensorDataset(X_valid2, y_valid2)\n",
    "        \n",
    "        clf.to(device)\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True) \n",
    "        valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        best_val_loss = np.inf\n",
    "        for epoch in range(train_epochs):\n",
    "            start_time = time.time()\n",
    "            clf.train()\n",
    "            avg_loss = 0.\n",
    "            for x_batch, y_batch in tqdm(train_loader, disable=True):\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch) \n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                avg_loss += loss.item() / len(train_loader)        \n",
    "            \n",
    "            clf.eval()\n",
    "            avg_val_loss = 0.\n",
    "            for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch).detach()\n",
    "                avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "        \n",
    "            elapsed_time = time.time() - start_time \n",
    "            scheduler.step(avg_val_loss)\n",
    "            #print('Epoch-{0} lr: {1}'.format(epoch, optimizer.param_groups[0]['lr']))\n",
    "                    \n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                print('Best model: Epoch {} \\t loss={:.6f} \\t val_loss={:.6f} \\t time={:.2f}s'.format(\n",
    "                    epoch + 1, avg_loss, avg_val_loss, elapsed_time))\n",
    "                torch.save(clf.state_dict(), 'best-model-parameters.pt')\n",
    "     \n",
    "        pred_model = MoaModel(num_columns=init_num)\n",
    "        pred_model.load_state_dict(torch.load('best-model-parameters.pt'))\n",
    "        pred_model.eval()\n",
    "        \n",
    "        # validation check ----------------\n",
    "        oof_epoch = np.zeros([X_valid2.size(0), y_train.shape[1]])\n",
    "        target_epoch = np.zeros([X_valid2.size(0), y_train.shape[1]])\n",
    "        for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "                y_pred = pred_model(x_batch).sigmoid().detach()\n",
    "                oof_epoch[i * batch_size:(i+1) * batch_size,:] = y_pred.cpu().numpy()\n",
    "                target_epoch[i * batch_size:(i+1) * batch_size,:] = y_batch.cpu().numpy()\n",
    "        #print(\"Fold {} log loss: {}\".format(fold+1, mean_log_loss(target_epoch, oof_epoch)))\n",
    "        scores.append(mean_log_loss(target_epoch, oof_epoch))\n",
    "        oof[valid_index,:] = oof_epoch\n",
    "        oof_targets[valid_index,:] = target_epoch\n",
    "        #-----------------------------------\n",
    "        \n",
    "        # test predcition --------------\n",
    "        test_preds = np.zeros([test_len, y_train.shape[1]])\n",
    "        for i, (x_batch,) in enumerate(test_loader): \n",
    "            y_pred = pred_model(x_batch).sigmoid().detach()\n",
    "            test_preds[i * batch_size:(i+1) * batch_size, :] = y_pred.cpu().numpy()\n",
    "        pred_value += test_preds / n_folds\n",
    "        # ------------------------------\n",
    "        \n",
    "    for i, ele in enumerate(scores):\n",
    "        print(\"Fold {} log loss: {}\".format(i+1, scores[i]))\n",
    "    print(\"Std of log loss: {}\".format(np.std(scores)))\n",
    "    print(\"Total log loss: {}\".format(mean_log_loss(oof_targets, oof)))\n",
    "    \n",
    "    return oof, oof_targets, pred_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T08:20:59.313306Z",
     "iopub.status.busy": "2020-10-05T08:20:59.311192Z",
     "iopub.status.idle": "2020-10-05T08:43:37.997016Z",
     "shell.execute_reply": "2020-10-05T08:43:37.996422Z"
    },
    "papermill": {
     "duration": 1358.706248,
     "end_time": "2020-10-05T08:43:37.997143",
     "exception": false,
     "start_time": "2020-10-05T08:20:59.290895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.415437 \t val_loss=0.079371 \t time=1.53s\n",
      "Best model: Epoch 2 \t loss=0.048834 \t val_loss=0.028417 \t time=0.91s\n",
      "Best model: Epoch 3 \t loss=0.027082 \t val_loss=0.022981 \t time=0.79s\n",
      "Best model: Epoch 4 \t loss=0.023576 \t val_loss=0.021647 \t time=0.80s\n",
      "Best model: Epoch 5 \t loss=0.021531 \t val_loss=0.020388 \t time=0.78s\n",
      "Best model: Epoch 6 \t loss=0.020788 \t val_loss=0.019412 \t time=0.78s\n",
      "Best model: Epoch 7 \t loss=0.019910 \t val_loss=0.018859 \t time=0.81s\n",
      "Best model: Epoch 8 \t loss=0.019516 \t val_loss=0.018564 \t time=0.82s\n",
      "Best model: Epoch 9 \t loss=0.019460 \t val_loss=0.018366 \t time=0.84s\n",
      "Best model: Epoch 11 \t loss=0.018790 \t val_loss=0.017921 \t time=0.96s\n",
      "Best model: Epoch 12 \t loss=0.018150 \t val_loss=0.017586 \t time=0.83s\n",
      "Best model: Epoch 13 \t loss=0.017815 \t val_loss=0.017411 \t time=0.86s\n",
      "Best model: Epoch 15 \t loss=0.017509 \t val_loss=0.017212 \t time=0.79s\n",
      "Best model: Epoch 16 \t loss=0.017328 \t val_loss=0.017035 \t time=0.79s\n",
      "Best model: Epoch 17 \t loss=0.017050 \t val_loss=0.016931 \t time=0.81s\n",
      "Best model: Epoch 18 \t loss=0.016917 \t val_loss=0.016782 \t time=0.82s\n",
      "Best model: Epoch 20 \t loss=0.016667 \t val_loss=0.016762 \t time=0.81s\n",
      "Best model: Epoch 21 \t loss=0.016515 \t val_loss=0.016668 \t time=0.81s\n",
      "Best model: Epoch 22 \t loss=0.016370 \t val_loss=0.016573 \t time=1.00s\n",
      "Best model: Epoch 23 \t loss=0.016288 \t val_loss=0.016572 \t time=0.82s\n",
      "Best model: Epoch 24 \t loss=0.016284 \t val_loss=0.016522 \t time=0.80s\n",
      "Best model: Epoch 25 \t loss=0.016168 \t val_loss=0.016491 \t time=0.84s\n",
      "Best model: Epoch 28 \t loss=0.015950 \t val_loss=0.016436 \t time=0.78s\n",
      "Best model: Epoch 31 \t loss=0.015879 \t val_loss=0.016383 \t time=0.78s\n",
      "Best model: Epoch 35 \t loss=0.015752 \t val_loss=0.016361 \t time=0.94s\n",
      "Best model: Epoch 36 \t loss=0.015692 \t val_loss=0.016348 \t time=0.93s\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.411181 \t val_loss=0.075397 \t time=0.79s\n",
      "Best model: Epoch 2 \t loss=0.049558 \t val_loss=0.029299 \t time=0.81s\n",
      "Best model: Epoch 3 \t loss=0.027598 \t val_loss=0.023163 \t time=0.82s\n",
      "Best model: Epoch 4 \t loss=0.023047 \t val_loss=0.021043 \t time=1.23s\n",
      "Best model: Epoch 5 \t loss=0.021538 \t val_loss=0.019897 \t time=1.16s\n",
      "Best model: Epoch 6 \t loss=0.020781 \t val_loss=0.019249 \t time=1.12s\n",
      "Best model: Epoch 7 \t loss=0.020069 \t val_loss=0.018945 \t time=0.86s\n",
      "Best model: Epoch 8 \t loss=0.019489 \t val_loss=0.018627 \t time=0.79s\n",
      "Best model: Epoch 9 \t loss=0.019424 \t val_loss=0.018436 \t time=0.84s\n",
      "Best model: Epoch 10 \t loss=0.018802 \t val_loss=0.018290 \t time=0.82s\n",
      "Best model: Epoch 11 \t loss=0.018590 \t val_loss=0.017708 \t time=0.83s\n",
      "Best model: Epoch 12 \t loss=0.018498 \t val_loss=0.017601 \t time=0.90s\n",
      "Best model: Epoch 13 \t loss=0.017940 \t val_loss=0.017397 \t time=0.87s\n",
      "Best model: Epoch 14 \t loss=0.017732 \t val_loss=0.017320 \t time=0.80s\n",
      "Best model: Epoch 15 \t loss=0.017458 \t val_loss=0.017106 \t time=0.81s\n",
      "Best model: Epoch 16 \t loss=0.017409 \t val_loss=0.017013 \t time=0.81s\n",
      "Best model: Epoch 17 \t loss=0.017071 \t val_loss=0.016914 \t time=1.08s\n",
      "Best model: Epoch 18 \t loss=0.016922 \t val_loss=0.016848 \t time=0.83s\n",
      "Best model: Epoch 19 \t loss=0.016701 \t val_loss=0.016720 \t time=0.80s\n",
      "Best model: Epoch 21 \t loss=0.016546 \t val_loss=0.016713 \t time=0.78s\n",
      "Best model: Epoch 22 \t loss=0.016444 \t val_loss=0.016566 \t time=0.79s\n",
      "Best model: Epoch 23 \t loss=0.016396 \t val_loss=0.016546 \t time=0.80s\n",
      "Best model: Epoch 24 \t loss=0.016313 \t val_loss=0.016470 \t time=0.80s\n",
      "Best model: Epoch 26 \t loss=0.016201 \t val_loss=0.016422 \t time=0.80s\n",
      "Best model: Epoch 28 \t loss=0.015954 \t val_loss=0.016399 \t time=0.81s\n",
      "Best model: Epoch 29 \t loss=0.015935 \t val_loss=0.016322 \t time=0.80s\n",
      "Best model: Epoch 30 \t loss=0.015867 \t val_loss=0.016320 \t time=1.03s\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 34 \t loss=0.015267 \t val_loss=0.016217 \t time=0.78s\n",
      "Best model: Epoch 35 \t loss=0.015027 \t val_loss=0.016150 \t time=0.80s\n",
      "Best model: Epoch 36 \t loss=0.014955 \t val_loss=0.016069 \t time=0.80s\n",
      "Best model: Epoch 37 \t loss=0.014841 \t val_loss=0.016033 \t time=0.80s\n",
      "Best model: Epoch 39 \t loss=0.014582 \t val_loss=0.016009 \t time=0.81s\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.416004 \t val_loss=0.082151 \t time=0.81s\n",
      "Best model: Epoch 2 \t loss=0.049496 \t val_loss=0.029278 \t time=0.82s\n",
      "Best model: Epoch 3 \t loss=0.027054 \t val_loss=0.022395 \t time=0.80s\n",
      "Best model: Epoch 4 \t loss=0.023408 \t val_loss=0.020991 \t time=0.80s\n",
      "Best model: Epoch 5 \t loss=0.021773 \t val_loss=0.020363 \t time=0.81s\n",
      "Best model: Epoch 6 \t loss=0.020828 \t val_loss=0.019585 \t time=0.79s\n",
      "Best model: Epoch 7 \t loss=0.020006 \t val_loss=0.018859 \t time=0.79s\n",
      "Best model: Epoch 8 \t loss=0.019543 \t val_loss=0.018434 \t time=0.83s\n",
      "Best model: Epoch 9 \t loss=0.019138 \t val_loss=0.018288 \t time=0.79s\n",
      "Best model: Epoch 10 \t loss=0.018848 \t val_loss=0.018076 \t time=0.85s\n",
      "Best model: Epoch 11 \t loss=0.018562 \t val_loss=0.017862 \t time=0.81s\n",
      "Best model: Epoch 12 \t loss=0.018304 \t val_loss=0.017570 \t time=0.88s\n",
      "Best model: Epoch 14 \t loss=0.017841 \t val_loss=0.017379 \t time=0.79s\n",
      "Best model: Epoch 15 \t loss=0.017658 \t val_loss=0.017065 \t time=0.82s\n",
      "Best model: Epoch 17 \t loss=0.017267 \t val_loss=0.016882 \t time=0.79s\n",
      "Best model: Epoch 18 \t loss=0.016996 \t val_loss=0.016799 \t time=0.79s\n",
      "Best model: Epoch 19 \t loss=0.016902 \t val_loss=0.016712 \t time=0.80s\n",
      "Best model: Epoch 21 \t loss=0.016588 \t val_loss=0.016565 \t time=0.80s\n",
      "Best model: Epoch 23 \t loss=0.016488 \t val_loss=0.016517 \t time=0.80s\n",
      "Best model: Epoch 25 \t loss=0.016257 \t val_loss=0.016410 \t time=0.91s\n",
      "Best model: Epoch 26 \t loss=0.016133 \t val_loss=0.016361 \t time=0.89s\n",
      "Best model: Epoch 29 \t loss=0.016028 \t val_loss=0.016359 \t time=0.91s\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 31 \t loss=0.015431 \t val_loss=0.016174 \t time=1.15s\n",
      "Best model: Epoch 32 \t loss=0.015256 \t val_loss=0.016116 \t time=0.90s\n",
      "Best model: Epoch 33 \t loss=0.015083 \t val_loss=0.016037 \t time=0.99s\n",
      "Best model: Epoch 34 \t loss=0.014991 \t val_loss=0.015999 \t time=0.83s\n",
      "Best model: Epoch 35 \t loss=0.014834 \t val_loss=0.015984 \t time=0.82s\n",
      "Best model: Epoch 36 \t loss=0.014790 \t val_loss=0.015962 \t time=0.86s\n",
      "Best model: Epoch 37 \t loss=0.014702 \t val_loss=0.015959 \t time=1.10s\n",
      "Best model: Epoch 38 \t loss=0.014607 \t val_loss=0.015935 \t time=0.80s\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.412582 \t val_loss=0.082573 \t time=0.81s\n",
      "Best model: Epoch 2 \t loss=0.049854 \t val_loss=0.032467 \t time=0.79s\n",
      "Best model: Epoch 3 \t loss=0.027480 \t val_loss=0.023359 \t time=0.79s\n",
      "Best model: Epoch 4 \t loss=0.023706 \t val_loss=0.020830 \t time=0.78s\n",
      "Best model: Epoch 5 \t loss=0.021578 \t val_loss=0.019679 \t time=0.79s\n",
      "Best model: Epoch 6 \t loss=0.020775 \t val_loss=0.019280 \t time=0.80s\n",
      "Best model: Epoch 7 \t loss=0.020349 \t val_loss=0.018949 \t time=0.99s\n",
      "Best model: Epoch 8 \t loss=0.019625 \t val_loss=0.018301 \t time=0.84s\n",
      "Best model: Epoch 9 \t loss=0.019299 \t val_loss=0.018272 \t time=0.80s\n",
      "Best model: Epoch 10 \t loss=0.018838 \t val_loss=0.017897 \t time=0.80s\n",
      "Best model: Epoch 11 \t loss=0.018531 \t val_loss=0.017499 \t time=0.79s\n",
      "Best model: Epoch 12 \t loss=0.018138 \t val_loss=0.017363 \t time=0.80s\n",
      "Best model: Epoch 13 \t loss=0.018109 \t val_loss=0.017326 \t time=0.80s\n",
      "Best model: Epoch 14 \t loss=0.017679 \t val_loss=0.017116 \t time=0.88s\n",
      "Best model: Epoch 15 \t loss=0.017556 \t val_loss=0.016996 \t time=0.82s\n",
      "Best model: Epoch 16 \t loss=0.017363 \t val_loss=0.016901 \t time=0.80s\n",
      "Best model: Epoch 18 \t loss=0.017110 \t val_loss=0.016736 \t time=0.80s\n",
      "Best model: Epoch 19 \t loss=0.016853 \t val_loss=0.016592 \t time=0.95s\n",
      "Best model: Epoch 20 \t loss=0.016644 \t val_loss=0.016574 \t time=0.94s\n",
      "Best model: Epoch 21 \t loss=0.016658 \t val_loss=0.016494 \t time=0.80s\n",
      "Best model: Epoch 23 \t loss=0.016505 \t val_loss=0.016429 \t time=0.81s\n",
      "Best model: Epoch 26 \t loss=0.016151 \t val_loss=0.016304 \t time=0.99s\n",
      "Best model: Epoch 28 \t loss=0.016053 \t val_loss=0.016263 \t time=0.79s\n",
      "Best model: Epoch 29 \t loss=0.016037 \t val_loss=0.016257 \t time=0.80s\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 34 \t loss=0.015383 \t val_loss=0.016117 \t time=0.81s\n",
      "Best model: Epoch 35 \t loss=0.015138 \t val_loss=0.016082 \t time=0.83s\n",
      "Best model: Epoch 36 \t loss=0.014974 \t val_loss=0.016031 \t time=0.82s\n",
      "Best model: Epoch 37 \t loss=0.014817 \t val_loss=0.015973 \t time=0.82s\n",
      "Best model: Epoch 38 \t loss=0.014761 \t val_loss=0.015953 \t time=0.80s\n",
      "Best model: Epoch 40 \t loss=0.014560 \t val_loss=0.015904 \t time=0.79s\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.414328 \t val_loss=0.087448 \t time=0.81s\n",
      "Best model: Epoch 2 \t loss=0.049512 \t val_loss=0.027864 \t time=0.95s\n",
      "Best model: Epoch 3 \t loss=0.027758 \t val_loss=0.022568 \t time=0.88s\n",
      "Best model: Epoch 4 \t loss=0.023222 \t val_loss=0.020926 \t time=0.82s\n",
      "Best model: Epoch 5 \t loss=0.021542 \t val_loss=0.019992 \t time=0.81s\n",
      "Best model: Epoch 6 \t loss=0.020834 \t val_loss=0.019734 \t time=0.81s\n",
      "Best model: Epoch 7 \t loss=0.020109 \t val_loss=0.018927 \t time=0.82s\n",
      "Best model: Epoch 8 \t loss=0.019564 \t val_loss=0.018723 \t time=0.81s\n",
      "Best model: Epoch 9 \t loss=0.019089 \t val_loss=0.018242 \t time=0.80s\n",
      "Best model: Epoch 10 \t loss=0.018894 \t val_loss=0.018092 \t time=0.85s\n",
      "Best model: Epoch 11 \t loss=0.018657 \t val_loss=0.017851 \t time=0.80s\n",
      "Best model: Epoch 12 \t loss=0.018342 \t val_loss=0.017641 \t time=1.17s\n",
      "Best model: Epoch 13 \t loss=0.018009 \t val_loss=0.017451 \t time=0.86s\n",
      "Best model: Epoch 14 \t loss=0.017792 \t val_loss=0.017356 \t time=0.95s\n",
      "Best model: Epoch 15 \t loss=0.017566 \t val_loss=0.017250 \t time=1.02s\n",
      "Best model: Epoch 16 \t loss=0.017320 \t val_loss=0.017161 \t time=0.84s\n",
      "Best model: Epoch 17 \t loss=0.017189 \t val_loss=0.017085 \t time=0.93s\n",
      "Best model: Epoch 18 \t loss=0.016939 \t val_loss=0.016884 \t time=1.21s\n",
      "Best model: Epoch 19 \t loss=0.016780 \t val_loss=0.016788 \t time=0.90s\n",
      "Best model: Epoch 21 \t loss=0.016577 \t val_loss=0.016727 \t time=0.83s\n",
      "Best model: Epoch 22 \t loss=0.016441 \t val_loss=0.016649 \t time=0.80s\n",
      "Best model: Epoch 23 \t loss=0.016291 \t val_loss=0.016597 \t time=0.83s\n",
      "Best model: Epoch 24 \t loss=0.016287 \t val_loss=0.016543 \t time=0.80s\n",
      "Best model: Epoch 28 \t loss=0.016031 \t val_loss=0.016475 \t time=0.82s\n",
      "Best model: Epoch 30 \t loss=0.015817 \t val_loss=0.016463 \t time=0.80s\n",
      "Best model: Epoch 32 \t loss=0.015895 \t val_loss=0.016427 \t time=0.79s\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 37 \t loss=0.015294 \t val_loss=0.016305 \t time=0.80s\n",
      "Best model: Epoch 38 \t loss=0.015050 \t val_loss=0.016241 \t time=0.80s\n",
      "Best model: Epoch 39 \t loss=0.014874 \t val_loss=0.016208 \t time=0.96s\n",
      "Best model: Epoch 40 \t loss=0.014732 \t val_loss=0.016165 \t time=0.87s\n",
      "Fold 1 log loss: 0.016439344860759344\n",
      "Fold 2 log loss: 0.016069898197301345\n",
      "Fold 3 log loss: 0.015931879180978485\n",
      "Fold 4 log loss: 0.01595691889305114\n",
      "Fold 5 log loss: 0.016160054063084902\n",
      "Std of log loss: 0.00018315531450448238\n",
      "Total log loss: 0.016111618733121873\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.411165 \t val_loss=0.081468 \t time=0.82s\n",
      "Best model: Epoch 2 \t loss=0.048499 \t val_loss=0.029076 \t time=0.81s\n",
      "Best model: Epoch 3 \t loss=0.027552 \t val_loss=0.023483 \t time=0.82s\n",
      "Best model: Epoch 4 \t loss=0.023516 \t val_loss=0.021191 \t time=0.81s\n",
      "Best model: Epoch 5 \t loss=0.021550 \t val_loss=0.020015 \t time=0.80s\n",
      "Best model: Epoch 6 \t loss=0.020523 \t val_loss=0.019441 \t time=1.02s\n",
      "Best model: Epoch 7 \t loss=0.019938 \t val_loss=0.018948 \t time=0.85s\n",
      "Best model: Epoch 8 \t loss=0.019424 \t val_loss=0.018626 \t time=0.84s\n",
      "Best model: Epoch 9 \t loss=0.019151 \t val_loss=0.018373 \t time=0.96s\n",
      "Best model: Epoch 10 \t loss=0.019021 \t val_loss=0.018116 \t time=0.82s\n",
      "Best model: Epoch 11 \t loss=0.018437 \t val_loss=0.017981 \t time=0.79s\n",
      "Best model: Epoch 12 \t loss=0.018173 \t val_loss=0.017505 \t time=0.81s\n",
      "Best model: Epoch 13 \t loss=0.017827 \t val_loss=0.017392 \t time=0.81s\n",
      "Best model: Epoch 14 \t loss=0.017632 \t val_loss=0.017217 \t time=0.87s\n",
      "Best model: Epoch 16 \t loss=0.017361 \t val_loss=0.017152 \t time=0.81s\n",
      "Best model: Epoch 17 \t loss=0.017101 \t val_loss=0.017014 \t time=0.79s\n",
      "Best model: Epoch 18 \t loss=0.016934 \t val_loss=0.016929 \t time=0.99s\n",
      "Best model: Epoch 20 \t loss=0.016648 \t val_loss=0.016773 \t time=0.82s\n",
      "Best model: Epoch 21 \t loss=0.016494 \t val_loss=0.016688 \t time=0.83s\n",
      "Best model: Epoch 22 \t loss=0.016404 \t val_loss=0.016643 \t time=0.79s\n",
      "Best model: Epoch 23 \t loss=0.016312 \t val_loss=0.016604 \t time=0.80s\n",
      "Best model: Epoch 24 \t loss=0.016270 \t val_loss=0.016509 \t time=0.80s\n",
      "Best model: Epoch 26 \t loss=0.016067 \t val_loss=0.016471 \t time=0.81s\n",
      "Best model: Epoch 27 \t loss=0.015967 \t val_loss=0.016448 \t time=0.83s\n",
      "Best model: Epoch 28 \t loss=0.015853 \t val_loss=0.016423 \t time=0.81s\n",
      "Best model: Epoch 30 \t loss=0.015834 \t val_loss=0.016371 \t time=0.79s\n",
      "Best model: Epoch 32 \t loss=0.015770 \t val_loss=0.016330 \t time=0.86s\n",
      "Best model: Epoch 35 \t loss=0.015657 \t val_loss=0.016322 \t time=0.89s\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 40 \t loss=0.015154 \t val_loss=0.016233 \t time=0.82s\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.414839 \t val_loss=0.082913 \t time=1.04s\n",
      "Best model: Epoch 2 \t loss=0.048966 \t val_loss=0.030619 \t time=0.89s\n",
      "Best model: Epoch 3 \t loss=0.027523 \t val_loss=0.023401 \t time=0.83s\n",
      "Best model: Epoch 4 \t loss=0.023278 \t val_loss=0.020883 \t time=0.83s\n",
      "Best model: Epoch 5 \t loss=0.021695 \t val_loss=0.020164 \t time=0.87s\n",
      "Best model: Epoch 6 \t loss=0.020612 \t val_loss=0.019331 \t time=0.88s\n",
      "Best model: Epoch 7 \t loss=0.020001 \t val_loss=0.019014 \t time=0.85s\n",
      "Best model: Epoch 8 \t loss=0.019603 \t val_loss=0.018689 \t time=0.84s\n",
      "Best model: Epoch 9 \t loss=0.019243 \t val_loss=0.018593 \t time=0.90s\n",
      "Best model: Epoch 10 \t loss=0.018908 \t val_loss=0.017970 \t time=0.82s\n",
      "Best model: Epoch 11 \t loss=0.018451 \t val_loss=0.017893 \t time=0.83s\n",
      "Best model: Epoch 12 \t loss=0.018354 \t val_loss=0.017556 \t time=1.04s\n",
      "Best model: Epoch 13 \t loss=0.018035 \t val_loss=0.017396 \t time=0.81s\n",
      "Best model: Epoch 14 \t loss=0.017716 \t val_loss=0.017394 \t time=0.81s\n",
      "Best model: Epoch 15 \t loss=0.017709 \t val_loss=0.017190 \t time=0.81s\n",
      "Best model: Epoch 16 \t loss=0.017369 \t val_loss=0.016950 \t time=0.85s\n",
      "Best model: Epoch 17 \t loss=0.017183 \t val_loss=0.016857 \t time=0.80s\n",
      "Best model: Epoch 19 \t loss=0.016794 \t val_loss=0.016745 \t time=0.81s\n",
      "Best model: Epoch 20 \t loss=0.016661 \t val_loss=0.016701 \t time=0.81s\n",
      "Best model: Epoch 21 \t loss=0.016624 \t val_loss=0.016594 \t time=0.80s\n",
      "Best model: Epoch 22 \t loss=0.016417 \t val_loss=0.016593 \t time=0.82s\n",
      "Best model: Epoch 23 \t loss=0.016431 \t val_loss=0.016507 \t time=0.81s\n",
      "Best model: Epoch 24 \t loss=0.016259 \t val_loss=0.016467 \t time=0.81s\n",
      "Best model: Epoch 26 \t loss=0.016173 \t val_loss=0.016430 \t time=0.81s\n",
      "Best model: Epoch 29 \t loss=0.016043 \t val_loss=0.016337 \t time=0.79s\n",
      "Best model: Epoch 32 \t loss=0.015825 \t val_loss=0.016298 \t time=0.78s\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 37 \t loss=0.015357 \t val_loss=0.016169 \t time=0.80s\n",
      "Best model: Epoch 38 \t loss=0.015058 \t val_loss=0.016055 \t time=1.20s\n",
      "Best model: Epoch 40 \t loss=0.014748 \t val_loss=0.016040 \t time=0.80s\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.412181 \t val_loss=0.081163 \t time=0.80s\n",
      "Best model: Epoch 2 \t loss=0.048276 \t val_loss=0.028251 \t time=0.86s\n",
      "Best model: Epoch 3 \t loss=0.027172 \t val_loss=0.022473 \t time=0.81s\n",
      "Best model: Epoch 4 \t loss=0.023020 \t val_loss=0.021053 \t time=0.80s\n",
      "Best model: Epoch 5 \t loss=0.021982 \t val_loss=0.019934 \t time=0.81s\n",
      "Best model: Epoch 6 \t loss=0.020642 \t val_loss=0.019375 \t time=0.80s\n",
      "Best model: Epoch 7 \t loss=0.020054 \t val_loss=0.018857 \t time=0.87s\n",
      "Best model: Epoch 8 \t loss=0.019410 \t val_loss=0.018568 \t time=1.05s\n",
      "Best model: Epoch 9 \t loss=0.019118 \t val_loss=0.018364 \t time=0.80s\n",
      "Best model: Epoch 10 \t loss=0.018779 \t val_loss=0.017997 \t time=0.81s\n",
      "Best model: Epoch 11 \t loss=0.018381 \t val_loss=0.017725 \t time=0.79s\n",
      "Best model: Epoch 13 \t loss=0.018048 \t val_loss=0.017396 \t time=0.79s\n",
      "Best model: Epoch 14 \t loss=0.017764 \t val_loss=0.017311 \t time=0.84s\n",
      "Best model: Epoch 15 \t loss=0.017607 \t val_loss=0.017121 \t time=0.81s\n",
      "Best model: Epoch 16 \t loss=0.017318 \t val_loss=0.016946 \t time=1.19s\n",
      "Best model: Epoch 17 \t loss=0.017196 \t val_loss=0.016941 \t time=0.86s\n",
      "Best model: Epoch 18 \t loss=0.017094 \t val_loss=0.016921 \t time=0.81s\n",
      "Best model: Epoch 19 \t loss=0.016928 \t val_loss=0.016636 \t time=0.89s\n",
      "Best model: Epoch 21 \t loss=0.016646 \t val_loss=0.016561 \t time=0.82s\n",
      "Best model: Epoch 22 \t loss=0.016552 \t val_loss=0.016484 \t time=0.80s\n",
      "Best model: Epoch 25 \t loss=0.016303 \t val_loss=0.016437 \t time=0.84s\n",
      "Best model: Epoch 27 \t loss=0.016043 \t val_loss=0.016359 \t time=0.79s\n",
      "Best model: Epoch 29 \t loss=0.015944 \t val_loss=0.016276 \t time=0.80s\n",
      "Best model: Epoch 33 \t loss=0.015854 \t val_loss=0.016268 \t time=0.79s\n",
      "Best model: Epoch 35 \t loss=0.015867 \t val_loss=0.016262 \t time=0.79s\n",
      "Best model: Epoch 39 \t loss=0.015839 \t val_loss=0.016234 \t time=0.81s\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.416443 \t val_loss=0.075991 \t time=0.82s\n",
      "Best model: Epoch 2 \t loss=0.049054 \t val_loss=0.029717 \t time=1.02s\n",
      "Best model: Epoch 3 \t loss=0.027239 \t val_loss=0.022827 \t time=0.80s\n",
      "Best model: Epoch 4 \t loss=0.023241 \t val_loss=0.020984 \t time=0.81s\n",
      "Best model: Epoch 5 \t loss=0.021879 \t val_loss=0.019942 \t time=0.81s\n",
      "Best model: Epoch 6 \t loss=0.020764 \t val_loss=0.019426 \t time=0.79s\n",
      "Best model: Epoch 7 \t loss=0.020141 \t val_loss=0.018750 \t time=0.80s\n",
      "Best model: Epoch 8 \t loss=0.019796 \t val_loss=0.018656 \t time=0.82s\n",
      "Best model: Epoch 9 \t loss=0.019354 \t val_loss=0.018034 \t time=0.80s\n",
      "Best model: Epoch 10 \t loss=0.018816 \t val_loss=0.017829 \t time=0.86s\n",
      "Best model: Epoch 11 \t loss=0.018510 \t val_loss=0.017534 \t time=0.81s\n",
      "Best model: Epoch 12 \t loss=0.018206 \t val_loss=0.017370 \t time=0.81s\n",
      "Best model: Epoch 13 \t loss=0.017951 \t val_loss=0.017191 \t time=0.82s\n",
      "Best model: Epoch 14 \t loss=0.017844 \t val_loss=0.017172 \t time=0.82s\n",
      "Best model: Epoch 15 \t loss=0.017643 \t val_loss=0.017059 \t time=1.00s\n",
      "Best model: Epoch 16 \t loss=0.017342 \t val_loss=0.016873 \t time=0.82s\n",
      "Best model: Epoch 17 \t loss=0.017152 \t val_loss=0.016699 \t time=0.88s\n",
      "Best model: Epoch 19 \t loss=0.016935 \t val_loss=0.016552 \t time=0.80s\n",
      "Best model: Epoch 20 \t loss=0.016826 \t val_loss=0.016534 \t time=0.84s\n",
      "Best model: Epoch 21 \t loss=0.016652 \t val_loss=0.016486 \t time=0.83s\n",
      "Best model: Epoch 22 \t loss=0.016470 \t val_loss=0.016438 \t time=0.83s\n",
      "Best model: Epoch 23 \t loss=0.016358 \t val_loss=0.016372 \t time=0.89s\n",
      "Best model: Epoch 25 \t loss=0.016274 \t val_loss=0.016271 \t time=0.98s\n",
      "Best model: Epoch 26 \t loss=0.016110 \t val_loss=0.016242 \t time=0.84s\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 31 \t loss=0.015488 \t val_loss=0.016112 \t time=0.85s\n",
      "Best model: Epoch 32 \t loss=0.015233 \t val_loss=0.016011 \t time=0.79s\n",
      "Best model: Epoch 33 \t loss=0.015095 \t val_loss=0.015987 \t time=0.81s\n",
      "Best model: Epoch 34 \t loss=0.014997 \t val_loss=0.015982 \t time=0.81s\n",
      "Best model: Epoch 35 \t loss=0.014958 \t val_loss=0.015935 \t time=0.81s\n",
      "Best model: Epoch 37 \t loss=0.014716 \t val_loss=0.015928 \t time=0.79s\n",
      "Best model: Epoch 38 \t loss=0.014635 \t val_loss=0.015916 \t time=0.85s\n",
      "Best model: Epoch 39 \t loss=0.014526 \t val_loss=0.015891 \t time=0.80s\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.414031 \t val_loss=0.083291 \t time=1.04s\n",
      "Best model: Epoch 2 \t loss=0.048357 \t val_loss=0.028096 \t time=1.00s\n",
      "Best model: Epoch 3 \t loss=0.027095 \t val_loss=0.022531 \t time=0.81s\n",
      "Best model: Epoch 4 \t loss=0.023375 \t val_loss=0.021066 \t time=0.84s\n",
      "Best model: Epoch 5 \t loss=0.021455 \t val_loss=0.020305 \t time=0.83s\n",
      "Best model: Epoch 6 \t loss=0.020656 \t val_loss=0.019620 \t time=0.83s\n",
      "Best model: Epoch 7 \t loss=0.019954 \t val_loss=0.018903 \t time=0.84s\n",
      "Best model: Epoch 8 \t loss=0.019670 \t val_loss=0.018748 \t time=1.02s\n",
      "Best model: Epoch 9 \t loss=0.019112 \t val_loss=0.018323 \t time=0.95s\n",
      "Best model: Epoch 10 \t loss=0.018824 \t val_loss=0.018157 \t time=0.81s\n",
      "Best model: Epoch 11 \t loss=0.018649 \t val_loss=0.017917 \t time=0.83s\n",
      "Best model: Epoch 12 \t loss=0.018306 \t val_loss=0.017688 \t time=0.84s\n",
      "Best model: Epoch 13 \t loss=0.018012 \t val_loss=0.017462 \t time=0.81s\n",
      "Best model: Epoch 15 \t loss=0.017562 \t val_loss=0.017280 \t time=0.82s\n",
      "Best model: Epoch 16 \t loss=0.017310 \t val_loss=0.017067 \t time=0.80s\n",
      "Best model: Epoch 17 \t loss=0.017083 \t val_loss=0.017041 \t time=0.79s\n",
      "Best model: Epoch 18 \t loss=0.016943 \t val_loss=0.016910 \t time=0.95s\n",
      "Best model: Epoch 19 \t loss=0.016881 \t val_loss=0.016841 \t time=0.80s\n",
      "Best model: Epoch 20 \t loss=0.016772 \t val_loss=0.016795 \t time=0.84s\n",
      "Best model: Epoch 21 \t loss=0.016639 \t val_loss=0.016759 \t time=1.03s\n",
      "Best model: Epoch 22 \t loss=0.016572 \t val_loss=0.016720 \t time=0.88s\n",
      "Best model: Epoch 23 \t loss=0.016450 \t val_loss=0.016642 \t time=0.81s\n",
      "Best model: Epoch 25 \t loss=0.016222 \t val_loss=0.016579 \t time=0.80s\n",
      "Best model: Epoch 26 \t loss=0.016140 \t val_loss=0.016551 \t time=0.83s\n",
      "Best model: Epoch 28 \t loss=0.016082 \t val_loss=0.016542 \t time=0.80s\n",
      "Best model: Epoch 29 \t loss=0.016001 \t val_loss=0.016436 \t time=0.81s\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 34 \t loss=0.015343 \t val_loss=0.016297 \t time=1.02s\n",
      "Best model: Epoch 35 \t loss=0.015131 \t val_loss=0.016275 \t time=0.82s\n",
      "Best model: Epoch 36 \t loss=0.014968 \t val_loss=0.016190 \t time=0.82s\n",
      "Best model: Epoch 37 \t loss=0.014826 \t val_loss=0.016153 \t time=0.82s\n",
      "Best model: Epoch 38 \t loss=0.014744 \t val_loss=0.016134 \t time=0.79s\n",
      "Fold 1 log loss: 0.016332759399693298\n",
      "Fold 2 log loss: 0.01609908757102784\n",
      "Fold 3 log loss: 0.016237153893716445\n",
      "Fold 4 log loss: 0.015948551065013965\n",
      "Fold 5 log loss: 0.01613424937593768\n",
      "Std of log loss: 0.00012993689346384776\n",
      "Total log loss: 0.016150363331224337\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.415103 \t val_loss=0.078454 \t time=1.07s\n",
      "Best model: Epoch 2 \t loss=0.048882 \t val_loss=0.028530 \t time=0.80s\n",
      "Best model: Epoch 3 \t loss=0.027167 \t val_loss=0.022708 \t time=0.81s\n",
      "Best model: Epoch 4 \t loss=0.023178 \t val_loss=0.020739 \t time=0.83s\n",
      "Best model: Epoch 5 \t loss=0.022052 \t val_loss=0.020309 \t time=0.83s\n",
      "Best model: Epoch 6 \t loss=0.020813 \t val_loss=0.019484 \t time=0.79s\n",
      "Best model: Epoch 7 \t loss=0.019967 \t val_loss=0.019138 \t time=0.81s\n",
      "Best model: Epoch 8 \t loss=0.019629 \t val_loss=0.018755 \t time=0.99s\n",
      "Best model: Epoch 10 \t loss=0.018943 \t val_loss=0.018203 \t time=0.82s\n",
      "Best model: Epoch 11 \t loss=0.018782 \t val_loss=0.018027 \t time=0.87s\n",
      "Best model: Epoch 12 \t loss=0.018337 \t val_loss=0.018023 \t time=0.82s\n",
      "Best model: Epoch 13 \t loss=0.018044 \t val_loss=0.017679 \t time=1.05s\n",
      "Best model: Epoch 14 \t loss=0.017678 \t val_loss=0.017300 \t time=0.82s\n",
      "Best model: Epoch 15 \t loss=0.017810 \t val_loss=0.017278 \t time=0.81s\n",
      "Best model: Epoch 16 \t loss=0.017376 \t val_loss=0.017145 \t time=0.83s\n",
      "Best model: Epoch 17 \t loss=0.017134 \t val_loss=0.016967 \t time=0.82s\n",
      "Best model: Epoch 18 \t loss=0.016931 \t val_loss=0.016957 \t time=0.83s\n",
      "Best model: Epoch 19 \t loss=0.016823 \t val_loss=0.016939 \t time=0.81s\n",
      "Best model: Epoch 20 \t loss=0.016777 \t val_loss=0.016781 \t time=1.23s\n",
      "Best model: Epoch 22 \t loss=0.016570 \t val_loss=0.016737 \t time=0.79s\n",
      "Best model: Epoch 23 \t loss=0.016320 \t val_loss=0.016563 \t time=0.85s\n",
      "Best model: Epoch 25 \t loss=0.016211 \t val_loss=0.016451 \t time=1.05s\n",
      "Best model: Epoch 28 \t loss=0.016181 \t val_loss=0.016446 \t time=0.85s\n",
      "Best model: Epoch 29 \t loss=0.016011 \t val_loss=0.016434 \t time=0.82s\n",
      "Best model: Epoch 31 \t loss=0.015892 \t val_loss=0.016390 \t time=0.80s\n",
      "Best model: Epoch 32 \t loss=0.015857 \t val_loss=0.016353 \t time=0.80s\n",
      "Best model: Epoch 35 \t loss=0.015807 \t val_loss=0.016337 \t time=0.80s\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 40 \t loss=0.015218 \t val_loss=0.016193 \t time=0.85s\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.411125 \t val_loss=0.080946 \t time=0.96s\n",
      "Best model: Epoch 2 \t loss=0.049252 \t val_loss=0.029123 \t time=0.89s\n",
      "Best model: Epoch 3 \t loss=0.027272 \t val_loss=0.022640 \t time=0.80s\n",
      "Best model: Epoch 4 \t loss=0.023754 \t val_loss=0.020983 \t time=0.83s\n",
      "Best model: Epoch 5 \t loss=0.021629 \t val_loss=0.020024 \t time=0.80s\n",
      "Best model: Epoch 6 \t loss=0.020870 \t val_loss=0.019466 \t time=0.81s\n",
      "Best model: Epoch 7 \t loss=0.020013 \t val_loss=0.019053 \t time=1.03s\n",
      "Best model: Epoch 8 \t loss=0.019603 \t val_loss=0.018721 \t time=0.82s\n",
      "Best model: Epoch 9 \t loss=0.019262 \t val_loss=0.018255 \t time=0.81s\n",
      "Best model: Epoch 10 \t loss=0.018888 \t val_loss=0.018138 \t time=0.85s\n",
      "Best model: Epoch 11 \t loss=0.018502 \t val_loss=0.017763 \t time=0.82s\n",
      "Best model: Epoch 12 \t loss=0.018282 \t val_loss=0.017649 \t time=0.80s\n",
      "Best model: Epoch 13 \t loss=0.018011 \t val_loss=0.017280 \t time=0.81s\n",
      "Best model: Epoch 15 \t loss=0.017480 \t val_loss=0.017093 \t time=0.79s\n",
      "Best model: Epoch 17 \t loss=0.017278 \t val_loss=0.016998 \t time=0.81s\n",
      "Best model: Epoch 18 \t loss=0.016966 \t val_loss=0.016817 \t time=0.81s\n",
      "Best model: Epoch 19 \t loss=0.016838 \t val_loss=0.016787 \t time=0.80s\n",
      "Best model: Epoch 20 \t loss=0.016567 \t val_loss=0.016723 \t time=1.07s\n",
      "Best model: Epoch 21 \t loss=0.016621 \t val_loss=0.016637 \t time=0.81s\n",
      "Best model: Epoch 22 \t loss=0.016378 \t val_loss=0.016629 \t time=0.82s\n",
      "Best model: Epoch 23 \t loss=0.016323 \t val_loss=0.016543 \t time=0.84s\n",
      "Best model: Epoch 24 \t loss=0.016269 \t val_loss=0.016481 \t time=0.82s\n",
      "Best model: Epoch 25 \t loss=0.016177 \t val_loss=0.016357 \t time=0.83s\n",
      "Best model: Epoch 29 \t loss=0.015870 \t val_loss=0.016330 \t time=0.81s\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 34 \t loss=0.015270 \t val_loss=0.016183 \t time=0.81s\n",
      "Best model: Epoch 35 \t loss=0.015026 \t val_loss=0.016122 \t time=0.83s\n",
      "Best model: Epoch 36 \t loss=0.014929 \t val_loss=0.016120 \t time=0.79s\n",
      "Best model: Epoch 37 \t loss=0.014773 \t val_loss=0.016066 \t time=0.92s\n",
      "Best model: Epoch 38 \t loss=0.014764 \t val_loss=0.016022 \t time=0.96s\n",
      "Best model: Epoch 39 \t loss=0.014629 \t val_loss=0.016001 \t time=0.81s\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.410881 \t val_loss=0.078164 \t time=0.81s\n",
      "Best model: Epoch 2 \t loss=0.048339 \t val_loss=0.027988 \t time=1.41s\n",
      "Best model: Epoch 3 \t loss=0.028067 \t val_loss=0.023013 \t time=0.90s\n",
      "Best model: Epoch 4 \t loss=0.023308 \t val_loss=0.020967 \t time=0.85s\n",
      "Best model: Epoch 5 \t loss=0.021841 \t val_loss=0.020025 \t time=1.10s\n",
      "Best model: Epoch 6 \t loss=0.020596 \t val_loss=0.019354 \t time=0.89s\n",
      "Best model: Epoch 7 \t loss=0.020042 \t val_loss=0.019126 \t time=0.81s\n",
      "Best model: Epoch 8 \t loss=0.019594 \t val_loss=0.018706 \t time=0.83s\n",
      "Best model: Epoch 9 \t loss=0.019185 \t val_loss=0.018294 \t time=0.84s\n",
      "Best model: Epoch 10 \t loss=0.018751 \t val_loss=0.017943 \t time=0.89s\n",
      "Best model: Epoch 11 \t loss=0.018480 \t val_loss=0.017743 \t time=0.81s\n",
      "Best model: Epoch 13 \t loss=0.017983 \t val_loss=0.017229 \t time=0.86s\n",
      "Best model: Epoch 14 \t loss=0.017671 \t val_loss=0.017192 \t time=0.83s\n",
      "Best model: Epoch 16 \t loss=0.017357 \t val_loss=0.016882 \t time=0.83s\n",
      "Best model: Epoch 18 \t loss=0.016995 \t val_loss=0.016820 \t time=0.80s\n",
      "Best model: Epoch 19 \t loss=0.016803 \t val_loss=0.016729 \t time=0.81s\n",
      "Best model: Epoch 20 \t loss=0.016752 \t val_loss=0.016671 \t time=0.82s\n",
      "Best model: Epoch 21 \t loss=0.016629 \t val_loss=0.016536 \t time=0.81s\n",
      "Best model: Epoch 23 \t loss=0.016418 \t val_loss=0.016431 \t time=0.80s\n",
      "Best model: Epoch 26 \t loss=0.016180 \t val_loss=0.016363 \t time=0.86s\n",
      "Best model: Epoch 27 \t loss=0.016096 \t val_loss=0.016336 \t time=0.90s\n",
      "Best model: Epoch 28 \t loss=0.016054 \t val_loss=0.016336 \t time=0.93s\n",
      "Best model: Epoch 29 \t loss=0.015945 \t val_loss=0.016236 \t time=0.97s\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 34 \t loss=0.015382 \t val_loss=0.016072 \t time=0.81s\n",
      "Best model: Epoch 36 \t loss=0.015004 \t val_loss=0.016025 \t time=0.80s\n",
      "Best model: Epoch 37 \t loss=0.014904 \t val_loss=0.016003 \t time=0.99s\n",
      "Best model: Epoch 38 \t loss=0.014754 \t val_loss=0.015991 \t time=0.85s\n",
      "Best model: Epoch 39 \t loss=0.014706 \t val_loss=0.015990 \t time=0.81s\n",
      "Best model: Epoch 40 \t loss=0.014597 \t val_loss=0.015961 \t time=0.80s\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.413921 \t val_loss=0.078584 \t time=0.81s\n",
      "Best model: Epoch 2 \t loss=0.049590 \t val_loss=0.027939 \t time=0.81s\n",
      "Best model: Epoch 3 \t loss=0.028037 \t val_loss=0.023023 \t time=0.82s\n",
      "Best model: Epoch 4 \t loss=0.023912 \t val_loss=0.020823 \t time=0.81s\n",
      "Best model: Epoch 5 \t loss=0.022026 \t val_loss=0.020183 \t time=0.81s\n",
      "Best model: Epoch 6 \t loss=0.020938 \t val_loss=0.019573 \t time=0.81s\n",
      "Best model: Epoch 7 \t loss=0.020150 \t val_loss=0.018848 \t time=1.13s\n",
      "Best model: Epoch 8 \t loss=0.019905 \t val_loss=0.018694 \t time=0.86s\n",
      "Best model: Epoch 9 \t loss=0.019514 \t val_loss=0.018515 \t time=0.86s\n",
      "Best model: Epoch 10 \t loss=0.019184 \t val_loss=0.017942 \t time=0.83s\n",
      "Best model: Epoch 11 \t loss=0.018871 \t val_loss=0.017680 \t time=0.81s\n",
      "Best model: Epoch 12 \t loss=0.018398 \t val_loss=0.017418 \t time=0.82s\n",
      "Best model: Epoch 13 \t loss=0.018180 \t val_loss=0.017276 \t time=0.83s\n",
      "Best model: Epoch 14 \t loss=0.017908 \t val_loss=0.017234 \t time=0.82s\n",
      "Best model: Epoch 15 \t loss=0.017723 \t val_loss=0.017127 \t time=0.81s\n",
      "Best model: Epoch 16 \t loss=0.017569 \t val_loss=0.016933 \t time=0.84s\n",
      "Best model: Epoch 17 \t loss=0.017411 \t val_loss=0.016831 \t time=0.81s\n",
      "Best model: Epoch 18 \t loss=0.017183 \t val_loss=0.016752 \t time=0.83s\n",
      "Best model: Epoch 19 \t loss=0.016963 \t val_loss=0.016649 \t time=1.03s\n",
      "Best model: Epoch 20 \t loss=0.016784 \t val_loss=0.016574 \t time=0.94s\n",
      "Best model: Epoch 21 \t loss=0.016666 \t val_loss=0.016517 \t time=0.85s\n",
      "Best model: Epoch 22 \t loss=0.016534 \t val_loss=0.016446 \t time=0.92s\n",
      "Best model: Epoch 24 \t loss=0.016423 \t val_loss=0.016375 \t time=0.83s\n",
      "Best model: Epoch 26 \t loss=0.016237 \t val_loss=0.016293 \t time=0.97s\n",
      "Best model: Epoch 28 \t loss=0.016201 \t val_loss=0.016258 \t time=0.81s\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 33 \t loss=0.015386 \t val_loss=0.016089 \t time=0.84s\n",
      "Best model: Epoch 34 \t loss=0.015241 \t val_loss=0.016012 \t time=0.82s\n",
      "Best model: Epoch 35 \t loss=0.015091 \t val_loss=0.015977 \t time=0.91s\n",
      "Best model: Epoch 36 \t loss=0.014943 \t val_loss=0.015974 \t time=0.82s\n",
      "Best model: Epoch 37 \t loss=0.014885 \t val_loss=0.015935 \t time=0.83s\n",
      "Best model: Epoch 38 \t loss=0.014755 \t val_loss=0.015909 \t time=0.85s\n",
      "Best model: Epoch 39 \t loss=0.014629 \t val_loss=0.015894 \t time=0.86s\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.414792 \t val_loss=0.083727 \t time=0.91s\n",
      "Best model: Epoch 2 \t loss=0.047688 \t val_loss=0.027360 \t time=0.83s\n",
      "Best model: Epoch 3 \t loss=0.027642 \t val_loss=0.022775 \t time=0.83s\n",
      "Best model: Epoch 4 \t loss=0.023623 \t val_loss=0.021450 \t time=0.83s\n",
      "Best model: Epoch 5 \t loss=0.021679 \t val_loss=0.020042 \t time=0.82s\n",
      "Best model: Epoch 6 \t loss=0.021014 \t val_loss=0.019405 \t time=0.84s\n",
      "Best model: Epoch 7 \t loss=0.020099 \t val_loss=0.019183 \t time=0.84s\n",
      "Best model: Epoch 8 \t loss=0.019632 \t val_loss=0.018762 \t time=0.82s\n",
      "Best model: Epoch 9 \t loss=0.019270 \t val_loss=0.018678 \t time=0.81s\n",
      "Best model: Epoch 10 \t loss=0.018930 \t val_loss=0.018132 \t time=0.80s\n",
      "Best model: Epoch 11 \t loss=0.018660 \t val_loss=0.017865 \t time=0.90s\n",
      "Best model: Epoch 12 \t loss=0.018457 \t val_loss=0.017803 \t time=0.87s\n",
      "Best model: Epoch 13 \t loss=0.017994 \t val_loss=0.017560 \t time=1.04s\n",
      "Best model: Epoch 14 \t loss=0.017804 \t val_loss=0.017368 \t time=0.91s\n",
      "Best model: Epoch 15 \t loss=0.017598 \t val_loss=0.017192 \t time=0.86s\n",
      "Best model: Epoch 16 \t loss=0.017274 \t val_loss=0.017156 \t time=0.80s\n",
      "Best model: Epoch 17 \t loss=0.017080 \t val_loss=0.017037 \t time=0.79s\n",
      "Best model: Epoch 18 \t loss=0.017015 \t val_loss=0.016905 \t time=0.80s\n",
      "Best model: Epoch 20 \t loss=0.016735 \t val_loss=0.016757 \t time=0.83s\n",
      "Best model: Epoch 21 \t loss=0.016576 \t val_loss=0.016713 \t time=0.81s\n",
      "Best model: Epoch 22 \t loss=0.016502 \t val_loss=0.016699 \t time=0.82s\n",
      "Best model: Epoch 23 \t loss=0.016313 \t val_loss=0.016587 \t time=0.81s\n",
      "Best model: Epoch 25 \t loss=0.016234 \t val_loss=0.016559 \t time=1.11s\n",
      "Best model: Epoch 26 \t loss=0.016118 \t val_loss=0.016542 \t time=0.82s\n",
      "Best model: Epoch 27 \t loss=0.016008 \t val_loss=0.016520 \t time=0.86s\n",
      "Best model: Epoch 28 \t loss=0.015997 \t val_loss=0.016471 \t time=0.82s\n",
      "Best model: Epoch 32 \t loss=0.015844 \t val_loss=0.016408 \t time=0.79s\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 37 \t loss=0.015224 \t val_loss=0.016262 \t time=0.79s\n",
      "Best model: Epoch 38 \t loss=0.014954 \t val_loss=0.016219 \t time=1.10s\n",
      "Best model: Epoch 39 \t loss=0.014851 \t val_loss=0.016200 \t time=0.86s\n",
      "Best model: Epoch 40 \t loss=0.014746 \t val_loss=0.016149 \t time=0.85s\n",
      "Fold 1 log loss: 0.01629125287524122\n",
      "Fold 2 log loss: 0.016059581357763468\n",
      "Fold 3 log loss: 0.01595703732081844\n",
      "Fold 4 log loss: 0.01594896520044832\n",
      "Fold 5 log loss: 0.01615187251299456\n",
      "Std of log loss: 0.00012844074530335962\n",
      "Total log loss: 0.016081739667825178\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.412792 \t val_loss=0.082595 \t time=0.90s\n",
      "Best model: Epoch 2 \t loss=0.048813 \t val_loss=0.028440 \t time=0.85s\n",
      "Best model: Epoch 3 \t loss=0.027135 \t val_loss=0.023149 \t time=0.80s\n",
      "Best model: Epoch 4 \t loss=0.023493 \t val_loss=0.021958 \t time=1.83s\n",
      "Best model: Epoch 5 \t loss=0.021869 \t val_loss=0.020033 \t time=0.85s\n",
      "Best model: Epoch 7 \t loss=0.020036 \t val_loss=0.019180 \t time=0.80s\n",
      "Best model: Epoch 8 \t loss=0.019601 \t val_loss=0.018664 \t time=0.82s\n",
      "Best model: Epoch 10 \t loss=0.019023 \t val_loss=0.018453 \t time=0.79s\n",
      "Best model: Epoch 11 \t loss=0.018667 \t val_loss=0.018021 \t time=0.88s\n",
      "Best model: Epoch 12 \t loss=0.018255 \t val_loss=0.017783 \t time=0.89s\n",
      "Best model: Epoch 13 \t loss=0.017963 \t val_loss=0.017465 \t time=0.84s\n",
      "Best model: Epoch 14 \t loss=0.017654 \t val_loss=0.017301 \t time=0.82s\n",
      "Best model: Epoch 15 \t loss=0.017460 \t val_loss=0.017252 \t time=0.87s\n",
      "Best model: Epoch 16 \t loss=0.017330 \t val_loss=0.017104 \t time=0.98s\n",
      "Best model: Epoch 18 \t loss=0.017054 \t val_loss=0.017009 \t time=0.84s\n",
      "Best model: Epoch 19 \t loss=0.016843 \t val_loss=0.016863 \t time=0.80s\n",
      "Best model: Epoch 21 \t loss=0.016601 \t val_loss=0.016685 \t time=0.83s\n",
      "Best model: Epoch 22 \t loss=0.016438 \t val_loss=0.016573 \t time=0.82s\n",
      "Best model: Epoch 24 \t loss=0.016310 \t val_loss=0.016516 \t time=0.82s\n",
      "Best model: Epoch 27 \t loss=0.016064 \t val_loss=0.016467 \t time=0.81s\n",
      "Best model: Epoch 30 \t loss=0.015951 \t val_loss=0.016424 \t time=0.82s\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 35 \t loss=0.015218 \t val_loss=0.016186 \t time=0.89s\n",
      "Best model: Epoch 36 \t loss=0.015030 \t val_loss=0.016149 \t time=0.82s\n",
      "Best model: Epoch 37 \t loss=0.014876 \t val_loss=0.016117 \t time=0.85s\n",
      "Best model: Epoch 38 \t loss=0.014750 \t val_loss=0.016097 \t time=0.95s\n",
      "Best model: Epoch 39 \t loss=0.014612 \t val_loss=0.016069 \t time=0.85s\n",
      "Best model: Epoch 40 \t loss=0.014547 \t val_loss=0.016058 \t time=0.82s\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.413905 \t val_loss=0.087526 \t time=0.80s\n",
      "Best model: Epoch 2 \t loss=0.048860 \t val_loss=0.029594 \t time=0.79s\n",
      "Best model: Epoch 3 \t loss=0.027386 \t val_loss=0.022730 \t time=0.79s\n",
      "Best model: Epoch 4 \t loss=0.023100 \t val_loss=0.021027 \t time=0.80s\n",
      "Best model: Epoch 5 \t loss=0.021649 \t val_loss=0.020201 \t time=0.81s\n",
      "Best model: Epoch 6 \t loss=0.020720 \t val_loss=0.019744 \t time=0.82s\n",
      "Best model: Epoch 7 \t loss=0.019991 \t val_loss=0.018991 \t time=0.80s\n",
      "Best model: Epoch 8 \t loss=0.019706 \t val_loss=0.018870 \t time=0.83s\n",
      "Best model: Epoch 9 \t loss=0.019237 \t val_loss=0.018651 \t time=0.84s\n",
      "Best model: Epoch 10 \t loss=0.018955 \t val_loss=0.018132 \t time=0.85s\n",
      "Best model: Epoch 11 \t loss=0.018632 \t val_loss=0.017741 \t time=0.95s\n",
      "Best model: Epoch 12 \t loss=0.018281 \t val_loss=0.017583 \t time=0.82s\n",
      "Best model: Epoch 14 \t loss=0.017918 \t val_loss=0.017201 \t time=0.83s\n",
      "Best model: Epoch 16 \t loss=0.017430 \t val_loss=0.017047 \t time=0.89s\n",
      "Best model: Epoch 17 \t loss=0.017165 \t val_loss=0.016921 \t time=0.83s\n",
      "Best model: Epoch 18 \t loss=0.017016 \t val_loss=0.016836 \t time=0.81s\n",
      "Best model: Epoch 19 \t loss=0.016850 \t val_loss=0.016698 \t time=0.83s\n",
      "Best model: Epoch 20 \t loss=0.016675 \t val_loss=0.016693 \t time=0.83s\n",
      "Best model: Epoch 21 \t loss=0.016700 \t val_loss=0.016598 \t time=0.84s\n",
      "Best model: Epoch 23 \t loss=0.016484 \t val_loss=0.016556 \t time=1.01s\n",
      "Best model: Epoch 24 \t loss=0.016327 \t val_loss=0.016479 \t time=0.82s\n",
      "Best model: Epoch 25 \t loss=0.016189 \t val_loss=0.016469 \t time=0.81s\n",
      "Best model: Epoch 26 \t loss=0.016068 \t val_loss=0.016433 \t time=0.80s\n",
      "Best model: Epoch 27 \t loss=0.016071 \t val_loss=0.016411 \t time=0.95s\n",
      "Best model: Epoch 31 \t loss=0.015815 \t val_loss=0.016343 \t time=0.95s\n",
      "Best model: Epoch 35 \t loss=0.015774 \t val_loss=0.016314 \t time=1.04s\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 40 \t loss=0.015216 \t val_loss=0.016133 \t time=0.80s\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.414497 \t val_loss=0.089107 \t time=0.80s\n",
      "Best model: Epoch 2 \t loss=0.049025 \t val_loss=0.029636 \t time=0.80s\n",
      "Best model: Epoch 3 \t loss=0.027484 \t val_loss=0.022651 \t time=0.80s\n",
      "Best model: Epoch 4 \t loss=0.023504 \t val_loss=0.020819 \t time=0.81s\n",
      "Best model: Epoch 5 \t loss=0.021685 \t val_loss=0.020451 \t time=1.00s\n",
      "Best model: Epoch 6 \t loss=0.020608 \t val_loss=0.019521 \t time=0.80s\n",
      "Best model: Epoch 7 \t loss=0.020132 \t val_loss=0.019020 \t time=0.83s\n",
      "Best model: Epoch 8 \t loss=0.019510 \t val_loss=0.018647 \t time=0.81s\n",
      "Best model: Epoch 9 \t loss=0.019554 \t val_loss=0.018364 \t time=0.80s\n",
      "Best model: Epoch 10 \t loss=0.018908 \t val_loss=0.018065 \t time=0.81s\n",
      "Best model: Epoch 11 \t loss=0.018569 \t val_loss=0.017733 \t time=0.85s\n",
      "Best model: Epoch 12 \t loss=0.018295 \t val_loss=0.017617 \t time=0.80s\n",
      "Best model: Epoch 13 \t loss=0.018046 \t val_loss=0.017390 \t time=0.81s\n",
      "Best model: Epoch 14 \t loss=0.017752 \t val_loss=0.017201 \t time=0.83s\n",
      "Best model: Epoch 16 \t loss=0.017379 \t val_loss=0.017046 \t time=0.80s\n",
      "Best model: Epoch 17 \t loss=0.017101 \t val_loss=0.016858 \t time=0.99s\n",
      "Best model: Epoch 18 \t loss=0.016962 \t val_loss=0.016746 \t time=0.92s\n",
      "Best model: Epoch 19 \t loss=0.016787 \t val_loss=0.016705 \t time=0.97s\n",
      "Best model: Epoch 20 \t loss=0.016635 \t val_loss=0.016560 \t time=0.86s\n",
      "Best model: Epoch 21 \t loss=0.016633 \t val_loss=0.016548 \t time=0.86s\n",
      "Best model: Epoch 23 \t loss=0.016349 \t val_loss=0.016481 \t time=0.97s\n",
      "Best model: Epoch 25 \t loss=0.016144 \t val_loss=0.016364 \t time=0.80s\n",
      "Best model: Epoch 26 \t loss=0.016084 \t val_loss=0.016344 \t time=0.79s\n",
      "Best model: Epoch 27 \t loss=0.016025 \t val_loss=0.016312 \t time=0.80s\n",
      "Best model: Epoch 28 \t loss=0.015935 \t val_loss=0.016278 \t time=0.83s\n",
      "Best model: Epoch 32 \t loss=0.015862 \t val_loss=0.016198 \t time=0.80s\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 37 \t loss=0.015237 \t val_loss=0.016077 \t time=0.81s\n",
      "Best model: Epoch 38 \t loss=0.015030 \t val_loss=0.015993 \t time=0.80s\n",
      "Best model: Epoch 40 \t loss=0.014758 \t val_loss=0.015957 \t time=0.79s\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.412648 \t val_loss=0.082871 \t time=0.82s\n",
      "Best model: Epoch 2 \t loss=0.048901 \t val_loss=0.029730 \t time=0.81s\n",
      "Best model: Epoch 3 \t loss=0.027776 \t val_loss=0.022759 \t time=0.80s\n",
      "Best model: Epoch 4 \t loss=0.023115 \t val_loss=0.020891 \t time=0.81s\n",
      "Best model: Epoch 5 \t loss=0.021800 \t val_loss=0.020010 \t time=0.80s\n",
      "Best model: Epoch 6 \t loss=0.020806 \t val_loss=0.019292 \t time=0.81s\n",
      "Best model: Epoch 7 \t loss=0.020124 \t val_loss=0.018759 \t time=0.82s\n",
      "Best model: Epoch 8 \t loss=0.019602 \t val_loss=0.018267 \t time=0.81s\n",
      "Best model: Epoch 9 \t loss=0.019230 \t val_loss=0.018180 \t time=0.80s\n",
      "Best model: Epoch 10 \t loss=0.019136 \t val_loss=0.017798 \t time=0.83s\n",
      "Best model: Epoch 11 \t loss=0.018694 \t val_loss=0.017533 \t time=1.22s\n",
      "Best model: Epoch 12 \t loss=0.018229 \t val_loss=0.017406 \t time=1.23s\n",
      "Best model: Epoch 13 \t loss=0.018057 \t val_loss=0.017295 \t time=0.81s\n",
      "Best model: Epoch 14 \t loss=0.017803 \t val_loss=0.017093 \t time=0.88s\n",
      "Best model: Epoch 15 \t loss=0.017648 \t val_loss=0.017012 \t time=1.03s\n",
      "Best model: Epoch 16 \t loss=0.017506 \t val_loss=0.016857 \t time=1.12s\n",
      "Best model: Epoch 17 \t loss=0.017167 \t val_loss=0.016642 \t time=0.84s\n",
      "Best model: Epoch 18 \t loss=0.016987 \t val_loss=0.016593 \t time=0.86s\n",
      "Best model: Epoch 21 \t loss=0.016703 \t val_loss=0.016500 \t time=0.85s\n",
      "Best model: Epoch 22 \t loss=0.016519 \t val_loss=0.016400 \t time=0.80s\n",
      "Best model: Epoch 23 \t loss=0.016410 \t val_loss=0.016320 \t time=0.79s\n",
      "Best model: Epoch 24 \t loss=0.016416 \t val_loss=0.016304 \t time=1.06s\n",
      "Best model: Epoch 25 \t loss=0.016264 \t val_loss=0.016272 \t time=0.82s\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 30 \t loss=0.015455 \t val_loss=0.016131 \t time=0.81s\n",
      "Best model: Epoch 31 \t loss=0.015280 \t val_loss=0.016015 \t time=0.81s\n",
      "Best model: Epoch 32 \t loss=0.015095 \t val_loss=0.016004 \t time=0.82s\n",
      "Best model: Epoch 33 \t loss=0.015029 \t val_loss=0.015961 \t time=0.80s\n",
      "Best model: Epoch 34 \t loss=0.014935 \t val_loss=0.015921 \t time=0.82s\n",
      "Best model: Epoch 35 \t loss=0.014835 \t val_loss=0.015897 \t time=0.82s\n",
      "Best model: Epoch 36 \t loss=0.014703 \t val_loss=0.015891 \t time=0.98s\n",
      "Best model: Epoch 38 \t loss=0.014540 \t val_loss=0.015890 \t time=0.85s\n",
      "Best model: Epoch 39 \t loss=0.014498 \t val_loss=0.015884 \t time=0.86s\n",
      "Best model: Epoch 40 \t loss=0.014405 \t val_loss=0.015880 \t time=0.84s\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.408293 \t val_loss=0.075686 \t time=0.81s\n",
      "Best model: Epoch 2 \t loss=0.048959 \t val_loss=0.029908 \t time=0.80s\n",
      "Best model: Epoch 3 \t loss=0.027408 \t val_loss=0.022504 \t time=0.81s\n",
      "Best model: Epoch 4 \t loss=0.023540 \t val_loss=0.020968 \t time=0.94s\n",
      "Best model: Epoch 5 \t loss=0.021814 \t val_loss=0.020080 \t time=0.82s\n",
      "Best model: Epoch 6 \t loss=0.020731 \t val_loss=0.019348 \t time=1.03s\n",
      "Best model: Epoch 7 \t loss=0.020061 \t val_loss=0.019110 \t time=0.85s\n",
      "Best model: Epoch 8 \t loss=0.019634 \t val_loss=0.018735 \t time=1.00s\n",
      "Best model: Epoch 9 \t loss=0.019336 \t val_loss=0.018564 \t time=0.83s\n",
      "Best model: Epoch 10 \t loss=0.019025 \t val_loss=0.018219 \t time=0.80s\n",
      "Best model: Epoch 11 \t loss=0.018725 \t val_loss=0.018126 \t time=0.80s\n",
      "Best model: Epoch 12 \t loss=0.018447 \t val_loss=0.017727 \t time=0.84s\n",
      "Best model: Epoch 13 \t loss=0.018105 \t val_loss=0.017550 \t time=0.82s\n",
      "Best model: Epoch 14 \t loss=0.017739 \t val_loss=0.017355 \t time=0.87s\n",
      "Best model: Epoch 15 \t loss=0.017508 \t val_loss=0.017192 \t time=0.84s\n",
      "Best model: Epoch 16 \t loss=0.017322 \t val_loss=0.017145 \t time=0.82s\n",
      "Best model: Epoch 17 \t loss=0.017118 \t val_loss=0.017063 \t time=0.80s\n",
      "Best model: Epoch 18 \t loss=0.017047 \t val_loss=0.016921 \t time=1.06s\n",
      "Best model: Epoch 20 \t loss=0.016726 \t val_loss=0.016807 \t time=0.82s\n",
      "Best model: Epoch 21 \t loss=0.016584 \t val_loss=0.016761 \t time=0.82s\n",
      "Best model: Epoch 22 \t loss=0.016417 \t val_loss=0.016661 \t time=0.82s\n",
      "Best model: Epoch 23 \t loss=0.016325 \t val_loss=0.016609 \t time=0.81s\n",
      "Best model: Epoch 25 \t loss=0.016272 \t val_loss=0.016560 \t time=0.81s\n",
      "Best model: Epoch 26 \t loss=0.016211 \t val_loss=0.016559 \t time=0.81s\n",
      "Best model: Epoch 27 \t loss=0.016015 \t val_loss=0.016528 \t time=0.81s\n",
      "Best model: Epoch 30 \t loss=0.015816 \t val_loss=0.016497 \t time=0.80s\n",
      "Best model: Epoch 31 \t loss=0.015824 \t val_loss=0.016489 \t time=1.02s\n",
      "Best model: Epoch 33 \t loss=0.015823 \t val_loss=0.016478 \t time=0.82s\n",
      "Best model: Epoch 34 \t loss=0.015832 \t val_loss=0.016469 \t time=0.82s\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 39 \t loss=0.015135 \t val_loss=0.016311 \t time=0.96s\n",
      "Best model: Epoch 40 \t loss=0.015011 \t val_loss=0.016264 \t time=0.86s\n",
      "Fold 1 log loss: 0.016161733817599288\n",
      "Fold 2 log loss: 0.016190608820456365\n",
      "Fold 3 log loss: 0.01596006592365271\n",
      "Fold 4 log loss: 0.015934083255345642\n",
      "Fold 5 log loss: 0.01626997845238435\n",
      "Std of log loss: 0.00013264188989881668\n",
      "Total log loss: 0.016103282481117257\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.415190 \t val_loss=0.075878 \t time=0.81s\n",
      "Best model: Epoch 2 \t loss=0.048968 \t val_loss=0.028708 \t time=0.80s\n",
      "Best model: Epoch 3 \t loss=0.027666 \t val_loss=0.023420 \t time=0.82s\n",
      "Best model: Epoch 4 \t loss=0.023325 \t val_loss=0.021716 \t time=0.80s\n",
      "Best model: Epoch 5 \t loss=0.021754 \t val_loss=0.020249 \t time=0.80s\n",
      "Best model: Epoch 6 \t loss=0.020637 \t val_loss=0.019509 \t time=0.81s\n",
      "Best model: Epoch 7 \t loss=0.020007 \t val_loss=0.018955 \t time=0.84s\n",
      "Best model: Epoch 8 \t loss=0.019609 \t val_loss=0.018733 \t time=0.83s\n",
      "Best model: Epoch 9 \t loss=0.019495 \t val_loss=0.018650 \t time=1.00s\n",
      "Best model: Epoch 10 \t loss=0.018850 \t val_loss=0.018140 \t time=0.83s\n",
      "Best model: Epoch 11 \t loss=0.018573 \t val_loss=0.017965 \t time=0.80s\n",
      "Best model: Epoch 12 \t loss=0.018231 \t val_loss=0.017774 \t time=0.82s\n",
      "Best model: Epoch 13 \t loss=0.018062 \t val_loss=0.017412 \t time=0.83s\n",
      "Best model: Epoch 14 \t loss=0.017814 \t val_loss=0.017371 \t time=0.89s\n",
      "Best model: Epoch 15 \t loss=0.017597 \t val_loss=0.017284 \t time=0.84s\n",
      "Best model: Epoch 16 \t loss=0.017350 \t val_loss=0.017077 \t time=0.80s\n",
      "Best model: Epoch 17 \t loss=0.017168 \t val_loss=0.016974 \t time=0.85s\n",
      "Best model: Epoch 18 \t loss=0.017045 \t val_loss=0.016953 \t time=0.80s\n",
      "Best model: Epoch 19 \t loss=0.016796 \t val_loss=0.016741 \t time=0.80s\n",
      "Best model: Epoch 21 \t loss=0.016578 \t val_loss=0.016634 \t time=0.81s\n",
      "Best model: Epoch 23 \t loss=0.016394 \t val_loss=0.016596 \t time=0.80s\n",
      "Best model: Epoch 25 \t loss=0.016272 \t val_loss=0.016486 \t time=0.80s\n",
      "Best model: Epoch 26 \t loss=0.016062 \t val_loss=0.016433 \t time=0.84s\n",
      "Best model: Epoch 27 \t loss=0.016002 \t val_loss=0.016421 \t time=0.94s\n",
      "Best model: Epoch 30 \t loss=0.015955 \t val_loss=0.016351 \t time=0.80s\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 35 \t loss=0.015270 \t val_loss=0.016218 \t time=0.83s\n",
      "Best model: Epoch 36 \t loss=0.015039 \t val_loss=0.016162 \t time=0.80s\n",
      "Best model: Epoch 38 \t loss=0.014701 \t val_loss=0.016107 \t time=0.80s\n",
      "Best model: Epoch 40 \t loss=0.014522 \t val_loss=0.016090 \t time=0.80s\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.411806 \t val_loss=0.077570 \t time=0.80s\n",
      "Best model: Epoch 2 \t loss=0.048996 \t val_loss=0.029039 \t time=0.80s\n",
      "Best model: Epoch 3 \t loss=0.027963 \t val_loss=0.022961 \t time=0.80s\n",
      "Best model: Epoch 4 \t loss=0.023393 \t val_loss=0.020927 \t time=0.98s\n",
      "Best model: Epoch 5 \t loss=0.021911 \t val_loss=0.020274 \t time=0.83s\n",
      "Best model: Epoch 6 \t loss=0.020659 \t val_loss=0.019253 \t time=0.79s\n",
      "Best model: Epoch 8 \t loss=0.019616 \t val_loss=0.018616 \t time=0.80s\n",
      "Best model: Epoch 9 \t loss=0.019399 \t val_loss=0.018507 \t time=0.81s\n",
      "Best model: Epoch 10 \t loss=0.018853 \t val_loss=0.017988 \t time=0.79s\n",
      "Best model: Epoch 11 \t loss=0.018752 \t val_loss=0.017657 \t time=0.81s\n",
      "Best model: Epoch 12 \t loss=0.018283 \t val_loss=0.017531 \t time=0.79s\n",
      "Best model: Epoch 13 \t loss=0.017853 \t val_loss=0.017503 \t time=0.80s\n",
      "Best model: Epoch 14 \t loss=0.017711 \t val_loss=0.017240 \t time=1.24s\n",
      "Best model: Epoch 15 \t loss=0.017649 \t val_loss=0.017226 \t time=0.90s\n",
      "Best model: Epoch 16 \t loss=0.017412 \t val_loss=0.017076 \t time=1.03s\n",
      "Best model: Epoch 18 \t loss=0.017035 \t val_loss=0.016848 \t time=1.18s\n",
      "Best model: Epoch 19 \t loss=0.016944 \t val_loss=0.016813 \t time=1.11s\n",
      "Best model: Epoch 20 \t loss=0.016807 \t val_loss=0.016643 \t time=0.86s\n",
      "Best model: Epoch 21 \t loss=0.016554 \t val_loss=0.016604 \t time=0.87s\n",
      "Best model: Epoch 23 \t loss=0.016491 \t val_loss=0.016548 \t time=0.81s\n",
      "Best model: Epoch 24 \t loss=0.016383 \t val_loss=0.016494 \t time=0.91s\n",
      "Best model: Epoch 25 \t loss=0.016262 \t val_loss=0.016463 \t time=0.99s\n",
      "Best model: Epoch 26 \t loss=0.016127 \t val_loss=0.016441 \t time=0.84s\n",
      "Best model: Epoch 27 \t loss=0.016134 \t val_loss=0.016420 \t time=1.00s\n",
      "Best model: Epoch 28 \t loss=0.016064 \t val_loss=0.016391 \t time=0.85s\n",
      "Best model: Epoch 30 \t loss=0.015958 \t val_loss=0.016367 \t time=0.82s\n",
      "Best model: Epoch 31 \t loss=0.015887 \t val_loss=0.016292 \t time=0.81s\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 36 \t loss=0.015299 \t val_loss=0.016218 \t time=0.79s\n",
      "Best model: Epoch 37 \t loss=0.015090 \t val_loss=0.016112 \t time=0.82s\n",
      "Best model: Epoch 38 \t loss=0.014899 \t val_loss=0.016082 \t time=0.85s\n",
      "Best model: Epoch 39 \t loss=0.014808 \t val_loss=0.016052 \t time=0.83s\n",
      "Best model: Epoch 40 \t loss=0.014700 \t val_loss=0.016050 \t time=1.06s\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.414838 \t val_loss=0.086086 \t time=0.82s\n",
      "Best model: Epoch 2 \t loss=0.048760 \t val_loss=0.028643 \t time=0.83s\n",
      "Best model: Epoch 3 \t loss=0.027593 \t val_loss=0.023142 \t time=0.82s\n",
      "Best model: Epoch 4 \t loss=0.023603 \t val_loss=0.020953 \t time=0.82s\n",
      "Best model: Epoch 5 \t loss=0.021415 \t val_loss=0.020069 \t time=0.83s\n",
      "Best model: Epoch 6 \t loss=0.020747 \t val_loss=0.019530 \t time=0.83s\n",
      "Best model: Epoch 7 \t loss=0.020151 \t val_loss=0.019003 \t time=0.83s\n",
      "Best model: Epoch 8 \t loss=0.019659 \t val_loss=0.018652 \t time=0.84s\n",
      "Best model: Epoch 9 \t loss=0.019232 \t val_loss=0.018501 \t time=0.85s\n",
      "Best model: Epoch 10 \t loss=0.019078 \t val_loss=0.018079 \t time=0.99s\n",
      "Best model: Epoch 11 \t loss=0.018696 \t val_loss=0.017804 \t time=0.94s\n",
      "Best model: Epoch 12 \t loss=0.018246 \t val_loss=0.017767 \t time=0.81s\n",
      "Best model: Epoch 14 \t loss=0.018021 \t val_loss=0.017361 \t time=0.84s\n",
      "Best model: Epoch 15 \t loss=0.017662 \t val_loss=0.017188 \t time=0.80s\n",
      "Best model: Epoch 16 \t loss=0.017457 \t val_loss=0.016962 \t time=0.82s\n",
      "Best model: Epoch 17 \t loss=0.017104 \t val_loss=0.016843 \t time=0.80s\n",
      "Best model: Epoch 19 \t loss=0.016897 \t val_loss=0.016744 \t time=0.83s\n",
      "Best model: Epoch 20 \t loss=0.016844 \t val_loss=0.016663 \t time=0.81s\n",
      "Best model: Epoch 21 \t loss=0.016659 \t val_loss=0.016614 \t time=0.86s\n",
      "Best model: Epoch 22 \t loss=0.016589 \t val_loss=0.016534 \t time=1.04s\n",
      "Best model: Epoch 24 \t loss=0.016343 \t val_loss=0.016450 \t time=0.81s\n",
      "Best model: Epoch 26 \t loss=0.016220 \t val_loss=0.016353 \t time=0.80s\n",
      "Best model: Epoch 27 \t loss=0.016072 \t val_loss=0.016336 \t time=0.80s\n",
      "Best model: Epoch 28 \t loss=0.015994 \t val_loss=0.016318 \t time=0.82s\n",
      "Best model: Epoch 29 \t loss=0.015958 \t val_loss=0.016299 \t time=0.80s\n",
      "Best model: Epoch 30 \t loss=0.015945 \t val_loss=0.016295 \t time=0.81s\n",
      "Best model: Epoch 31 \t loss=0.015907 \t val_loss=0.016284 \t time=0.84s\n",
      "Best model: Epoch 32 \t loss=0.015876 \t val_loss=0.016275 \t time=0.82s\n",
      "Best model: Epoch 33 \t loss=0.015866 \t val_loss=0.016270 \t time=0.84s\n",
      "Best model: Epoch 34 \t loss=0.015835 \t val_loss=0.016269 \t time=0.90s\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 38 \t loss=0.015262 \t val_loss=0.016093 \t time=0.87s\n",
      "Best model: Epoch 39 \t loss=0.015045 \t val_loss=0.016056 \t time=0.81s\n",
      "Best model: Epoch 40 \t loss=0.014932 \t val_loss=0.016021 \t time=0.83s\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.414301 \t val_loss=0.076600 \t time=0.83s\n",
      "Best model: Epoch 2 \t loss=0.049539 \t val_loss=0.027660 \t time=0.85s\n",
      "Best model: Epoch 3 \t loss=0.027215 \t val_loss=0.022305 \t time=1.10s\n",
      "Best model: Epoch 4 \t loss=0.023437 \t val_loss=0.020806 \t time=0.97s\n",
      "Best model: Epoch 5 \t loss=0.021815 \t val_loss=0.020028 \t time=0.86s\n",
      "Best model: Epoch 6 \t loss=0.020711 \t val_loss=0.019552 \t time=0.96s\n",
      "Best model: Epoch 7 \t loss=0.020167 \t val_loss=0.018675 \t time=0.90s\n",
      "Best model: Epoch 9 \t loss=0.019685 \t val_loss=0.018175 \t time=0.81s\n",
      "Best model: Epoch 11 \t loss=0.018615 \t val_loss=0.017645 \t time=0.82s\n",
      "Best model: Epoch 12 \t loss=0.018347 \t val_loss=0.017403 \t time=0.82s\n",
      "Best model: Epoch 13 \t loss=0.017904 \t val_loss=0.017331 \t time=0.84s\n",
      "Best model: Epoch 14 \t loss=0.017843 \t val_loss=0.017103 \t time=0.80s\n",
      "Best model: Epoch 15 \t loss=0.017710 \t val_loss=0.017055 \t time=0.92s\n",
      "Best model: Epoch 16 \t loss=0.017450 \t val_loss=0.016854 \t time=0.96s\n",
      "Best model: Epoch 17 \t loss=0.017277 \t val_loss=0.016828 \t time=0.86s\n",
      "Best model: Epoch 18 \t loss=0.017100 \t val_loss=0.016668 \t time=0.87s\n",
      "Best model: Epoch 19 \t loss=0.017030 \t val_loss=0.016637 \t time=0.85s\n",
      "Best model: Epoch 20 \t loss=0.016914 \t val_loss=0.016610 \t time=0.81s\n",
      "Best model: Epoch 21 \t loss=0.016803 \t val_loss=0.016542 \t time=0.81s\n",
      "Best model: Epoch 22 \t loss=0.016725 \t val_loss=0.016456 \t time=0.83s\n",
      "Best model: Epoch 24 \t loss=0.016457 \t val_loss=0.016388 \t time=0.80s\n",
      "Best model: Epoch 25 \t loss=0.016359 \t val_loss=0.016344 \t time=0.82s\n",
      "Best model: Epoch 27 \t loss=0.016313 \t val_loss=0.016311 \t time=0.80s\n",
      "Best model: Epoch 28 \t loss=0.016202 \t val_loss=0.016224 \t time=1.01s\n",
      "Best model: Epoch 31 \t loss=0.016062 \t val_loss=0.016200 \t time=0.81s\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 35 \t loss=0.015858 \t val_loss=0.016200 \t time=0.79s\n",
      "Best model: Epoch 36 \t loss=0.015367 \t val_loss=0.016061 \t time=0.81s\n",
      "Best model: Epoch 37 \t loss=0.015174 \t val_loss=0.015995 \t time=0.80s\n",
      "Best model: Epoch 38 \t loss=0.014993 \t val_loss=0.015975 \t time=0.96s\n",
      "Best model: Epoch 39 \t loss=0.014852 \t val_loss=0.015965 \t time=0.82s\n",
      "Best model: Epoch 40 \t loss=0.014749 \t val_loss=0.015950 \t time=0.87s\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.414623 \t val_loss=0.076521 \t time=0.85s\n",
      "Best model: Epoch 2 \t loss=0.049414 \t val_loss=0.028304 \t time=0.80s\n",
      "Best model: Epoch 3 \t loss=0.027708 \t val_loss=0.023459 \t time=0.96s\n",
      "Best model: Epoch 4 \t loss=0.023312 \t val_loss=0.021206 \t time=0.80s\n",
      "Best model: Epoch 5 \t loss=0.021804 \t val_loss=0.020208 \t time=0.80s\n",
      "Best model: Epoch 6 \t loss=0.020887 \t val_loss=0.019449 \t time=0.81s\n",
      "Best model: Epoch 7 \t loss=0.020100 \t val_loss=0.019198 \t time=0.80s\n",
      "Best model: Epoch 8 \t loss=0.019604 \t val_loss=0.018717 \t time=0.84s\n",
      "Best model: Epoch 9 \t loss=0.019084 \t val_loss=0.018359 \t time=0.80s\n",
      "Best model: Epoch 10 \t loss=0.018930 \t val_loss=0.018195 \t time=0.95s\n",
      "Best model: Epoch 11 \t loss=0.018489 \t val_loss=0.017842 \t time=0.90s\n",
      "Best model: Epoch 12 \t loss=0.018212 \t val_loss=0.017676 \t time=0.80s\n",
      "Best model: Epoch 13 \t loss=0.017941 \t val_loss=0.017437 \t time=0.84s\n",
      "Best model: Epoch 15 \t loss=0.017636 \t val_loss=0.017241 \t time=0.80s\n",
      "Best model: Epoch 16 \t loss=0.017402 \t val_loss=0.017114 \t time=0.80s\n",
      "Best model: Epoch 17 \t loss=0.017208 \t val_loss=0.017059 \t time=0.80s\n",
      "Best model: Epoch 18 \t loss=0.017000 \t val_loss=0.016887 \t time=0.80s\n",
      "Best model: Epoch 19 \t loss=0.016922 \t val_loss=0.016885 \t time=1.18s\n",
      "Best model: Epoch 20 \t loss=0.016696 \t val_loss=0.016818 \t time=1.12s\n",
      "Best model: Epoch 21 \t loss=0.016656 \t val_loss=0.016756 \t time=0.82s\n",
      "Best model: Epoch 22 \t loss=0.016507 \t val_loss=0.016694 \t time=1.07s\n",
      "Best model: Epoch 24 \t loss=0.016282 \t val_loss=0.016558 \t time=0.84s\n",
      "Best model: Epoch 25 \t loss=0.016186 \t val_loss=0.016538 \t time=0.87s\n",
      "Best model: Epoch 27 \t loss=0.016083 \t val_loss=0.016478 \t time=0.80s\n",
      "Best model: Epoch 28 \t loss=0.015943 \t val_loss=0.016460 \t time=0.83s\n",
      "Best model: Epoch 29 \t loss=0.015905 \t val_loss=0.016454 \t time=0.99s\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 34 \t loss=0.015278 \t val_loss=0.016311 \t time=0.89s\n",
      "Best model: Epoch 35 \t loss=0.015134 \t val_loss=0.016209 \t time=0.92s\n",
      "Best model: Epoch 36 \t loss=0.014921 \t val_loss=0.016174 \t time=0.85s\n",
      "Best model: Epoch 38 \t loss=0.014698 \t val_loss=0.016143 \t time=0.83s\n",
      "Best model: Epoch 39 \t loss=0.014562 \t val_loss=0.016133 \t time=0.93s\n",
      "Best model: Epoch 40 \t loss=0.014483 \t val_loss=0.016110 \t time=0.83s\n",
      "Fold 1 log loss: 0.016193153397194404\n",
      "Fold 2 log loss: 0.01611095568182438\n",
      "Fold 3 log loss: 0.016017308366712616\n",
      "Fold 4 log loss: 0.01600707188135671\n",
      "Fold 5 log loss: 0.016121775812368344\n",
      "Std of log loss: 6.964280085846069e-05\n",
      "Total log loss: 0.01609005063015854\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.415826 \t val_loss=0.075436 \t time=1.03s\n",
      "Best model: Epoch 2 \t loss=0.049783 \t val_loss=0.029040 \t time=0.83s\n",
      "Best model: Epoch 3 \t loss=0.027200 \t val_loss=0.023126 \t time=0.82s\n",
      "Best model: Epoch 4 \t loss=0.023732 \t val_loss=0.022115 \t time=0.80s\n",
      "Best model: Epoch 5 \t loss=0.021531 \t val_loss=0.020224 \t time=0.81s\n",
      "Best model: Epoch 6 \t loss=0.020618 \t val_loss=0.019628 \t time=0.81s\n",
      "Best model: Epoch 7 \t loss=0.020206 \t val_loss=0.019069 \t time=0.81s\n",
      "Best model: Epoch 8 \t loss=0.019390 \t val_loss=0.018809 \t time=0.86s\n",
      "Best model: Epoch 9 \t loss=0.019062 \t val_loss=0.018511 \t time=0.82s\n",
      "Best model: Epoch 10 \t loss=0.019057 \t val_loss=0.018120 \t time=0.82s\n",
      "Best model: Epoch 11 \t loss=0.018681 \t val_loss=0.018110 \t time=0.82s\n",
      "Best model: Epoch 12 \t loss=0.018267 \t val_loss=0.017998 \t time=0.81s\n",
      "Best model: Epoch 13 \t loss=0.018036 \t val_loss=0.017553 \t time=0.82s\n",
      "Best model: Epoch 15 \t loss=0.017488 \t val_loss=0.017239 \t time=0.81s\n",
      "Best model: Epoch 16 \t loss=0.017394 \t val_loss=0.017054 \t time=0.82s\n",
      "Best model: Epoch 17 \t loss=0.017111 \t val_loss=0.016986 \t time=0.81s\n",
      "Best model: Epoch 18 \t loss=0.016913 \t val_loss=0.016880 \t time=0.98s\n",
      "Best model: Epoch 19 \t loss=0.016842 \t val_loss=0.016802 \t time=0.85s\n",
      "Best model: Epoch 20 \t loss=0.016724 \t val_loss=0.016755 \t time=0.87s\n",
      "Best model: Epoch 21 \t loss=0.016639 \t val_loss=0.016709 \t time=0.81s\n",
      "Best model: Epoch 23 \t loss=0.016344 \t val_loss=0.016601 \t time=0.80s\n",
      "Best model: Epoch 24 \t loss=0.016298 \t val_loss=0.016464 \t time=0.81s\n",
      "Best model: Epoch 27 \t loss=0.016042 \t val_loss=0.016433 \t time=0.86s\n",
      "Best model: Epoch 30 \t loss=0.015941 \t val_loss=0.016428 \t time=0.87s\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 35 \t loss=0.015292 \t val_loss=0.016271 \t time=0.83s\n",
      "Best model: Epoch 36 \t loss=0.015070 \t val_loss=0.016189 \t time=0.80s\n",
      "Best model: Epoch 37 \t loss=0.014901 \t val_loss=0.016118 \t time=0.80s\n",
      "Best model: Epoch 40 \t loss=0.014640 \t val_loss=0.016087 \t time=1.10s\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.414907 \t val_loss=0.079768 \t time=0.80s\n",
      "Best model: Epoch 2 \t loss=0.048839 \t val_loss=0.027705 \t time=1.09s\n",
      "Best model: Epoch 3 \t loss=0.027893 \t val_loss=0.023237 \t time=0.82s\n",
      "Best model: Epoch 4 \t loss=0.023507 \t val_loss=0.020869 \t time=0.85s\n",
      "Best model: Epoch 5 \t loss=0.021773 \t val_loss=0.019954 \t time=0.81s\n",
      "Best model: Epoch 6 \t loss=0.020749 \t val_loss=0.019558 \t time=0.83s\n",
      "Best model: Epoch 7 \t loss=0.020156 \t val_loss=0.018908 \t time=0.87s\n",
      "Best model: Epoch 8 \t loss=0.019570 \t val_loss=0.018562 \t time=1.10s\n",
      "Best model: Epoch 10 \t loss=0.018955 \t val_loss=0.018046 \t time=0.82s\n",
      "Best model: Epoch 11 \t loss=0.018528 \t val_loss=0.017864 \t time=1.04s\n",
      "Best model: Epoch 12 \t loss=0.018255 \t val_loss=0.017508 \t time=0.86s\n",
      "Best model: Epoch 13 \t loss=0.017888 \t val_loss=0.017359 \t time=0.84s\n",
      "Best model: Epoch 14 \t loss=0.017771 \t val_loss=0.017226 \t time=0.82s\n",
      "Best model: Epoch 16 \t loss=0.017334 \t val_loss=0.017120 \t time=0.79s\n",
      "Best model: Epoch 17 \t loss=0.017294 \t val_loss=0.016875 \t time=0.84s\n",
      "Best model: Epoch 18 \t loss=0.017028 \t val_loss=0.016805 \t time=0.81s\n",
      "Best model: Epoch 19 \t loss=0.016893 \t val_loss=0.016769 \t time=0.86s\n",
      "Best model: Epoch 20 \t loss=0.016677 \t val_loss=0.016656 \t time=1.04s\n",
      "Best model: Epoch 22 \t loss=0.016461 \t val_loss=0.016620 \t time=0.80s\n",
      "Best model: Epoch 23 \t loss=0.016359 \t val_loss=0.016568 \t time=0.79s\n",
      "Best model: Epoch 24 \t loss=0.016290 \t val_loss=0.016471 \t time=0.81s\n",
      "Best model: Epoch 25 \t loss=0.016235 \t val_loss=0.016438 \t time=0.85s\n",
      "Best model: Epoch 26 \t loss=0.016152 \t val_loss=0.016429 \t time=0.81s\n",
      "Best model: Epoch 27 \t loss=0.015967 \t val_loss=0.016393 \t time=0.83s\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 32 \t loss=0.015365 \t val_loss=0.016225 \t time=0.88s\n",
      "Best model: Epoch 33 \t loss=0.015099 \t val_loss=0.016147 \t time=1.06s\n",
      "Best model: Epoch 34 \t loss=0.014965 \t val_loss=0.016130 \t time=0.86s\n",
      "Best model: Epoch 35 \t loss=0.014854 \t val_loss=0.016091 \t time=0.87s\n",
      "Best model: Epoch 36 \t loss=0.014718 \t val_loss=0.016090 \t time=0.87s\n",
      "Best model: Epoch 38 \t loss=0.014465 \t val_loss=0.016063 \t time=0.83s\n",
      "Best model: Epoch 40 \t loss=0.014336 \t val_loss=0.016020 \t time=0.81s\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.413049 \t val_loss=0.077277 \t time=0.85s\n",
      "Best model: Epoch 2 \t loss=0.049180 \t val_loss=0.028293 \t time=0.96s\n",
      "Best model: Epoch 3 \t loss=0.027467 \t val_loss=0.022882 \t time=1.15s\n",
      "Best model: Epoch 4 \t loss=0.023398 \t val_loss=0.020662 \t time=0.81s\n",
      "Best model: Epoch 6 \t loss=0.020922 \t val_loss=0.019689 \t time=0.80s\n",
      "Best model: Epoch 7 \t loss=0.020140 \t val_loss=0.019186 \t time=0.80s\n",
      "Best model: Epoch 8 \t loss=0.019586 \t val_loss=0.018557 \t time=0.80s\n",
      "Best model: Epoch 9 \t loss=0.019152 \t val_loss=0.018485 \t time=0.83s\n",
      "Best model: Epoch 10 \t loss=0.018809 \t val_loss=0.017898 \t time=0.80s\n",
      "Best model: Epoch 11 \t loss=0.018561 \t val_loss=0.017772 \t time=0.80s\n",
      "Best model: Epoch 12 \t loss=0.018349 \t val_loss=0.017648 \t time=0.82s\n",
      "Best model: Epoch 13 \t loss=0.017996 \t val_loss=0.017564 \t time=0.81s\n",
      "Best model: Epoch 14 \t loss=0.017831 \t val_loss=0.017287 \t time=1.10s\n",
      "Best model: Epoch 15 \t loss=0.017567 \t val_loss=0.017142 \t time=0.89s\n",
      "Best model: Epoch 17 \t loss=0.017329 \t val_loss=0.016923 \t time=0.79s\n",
      "Best model: Epoch 19 \t loss=0.017037 \t val_loss=0.016815 \t time=0.80s\n",
      "Best model: Epoch 20 \t loss=0.016821 \t val_loss=0.016712 \t time=0.81s\n",
      "Best model: Epoch 21 \t loss=0.016623 \t val_loss=0.016596 \t time=1.16s\n",
      "Best model: Epoch 23 \t loss=0.016485 \t val_loss=0.016495 \t time=1.07s\n",
      "Best model: Epoch 26 \t loss=0.016130 \t val_loss=0.016334 \t time=1.01s\n",
      "Best model: Epoch 27 \t loss=0.016109 \t val_loss=0.016324 \t time=0.91s\n",
      "Best model: Epoch 29 \t loss=0.016003 \t val_loss=0.016313 \t time=0.85s\n",
      "Best model: Epoch 31 \t loss=0.015923 \t val_loss=0.016304 \t time=0.82s\n",
      "Best model: Epoch 34 \t loss=0.015907 \t val_loss=0.016279 \t time=0.84s\n",
      "Best model: Epoch 36 \t loss=0.015893 \t val_loss=0.016249 \t time=0.80s\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.412393 \t val_loss=0.074504 \t time=0.80s\n",
      "Best model: Epoch 2 \t loss=0.049456 \t val_loss=0.028429 \t time=0.80s\n",
      "Best model: Epoch 3 \t loss=0.026859 \t val_loss=0.022331 \t time=0.81s\n",
      "Best model: Epoch 4 \t loss=0.023162 \t val_loss=0.021110 \t time=0.81s\n",
      "Best model: Epoch 5 \t loss=0.021920 \t val_loss=0.020495 \t time=0.82s\n",
      "Best model: Epoch 6 \t loss=0.021258 \t val_loss=0.019205 \t time=0.83s\n",
      "Best model: Epoch 7 \t loss=0.020143 \t val_loss=0.019022 \t time=1.03s\n",
      "Best model: Epoch 8 \t loss=0.019636 \t val_loss=0.018537 \t time=0.92s\n",
      "Best model: Epoch 9 \t loss=0.019229 \t val_loss=0.018076 \t time=0.80s\n",
      "Best model: Epoch 10 \t loss=0.019079 \t val_loss=0.017828 \t time=0.82s\n",
      "Best model: Epoch 11 \t loss=0.018636 \t val_loss=0.017489 \t time=0.84s\n",
      "Best model: Epoch 12 \t loss=0.018577 \t val_loss=0.017362 \t time=0.83s\n",
      "Best model: Epoch 13 \t loss=0.018156 \t val_loss=0.017326 \t time=0.82s\n",
      "Best model: Epoch 14 \t loss=0.018115 \t val_loss=0.017233 \t time=0.80s\n",
      "Best model: Epoch 15 \t loss=0.017660 \t val_loss=0.016975 \t time=0.83s\n",
      "Best model: Epoch 16 \t loss=0.017503 \t val_loss=0.016881 \t time=0.82s\n",
      "Best model: Epoch 17 \t loss=0.017290 \t val_loss=0.016757 \t time=0.81s\n",
      "Best model: Epoch 18 \t loss=0.017069 \t val_loss=0.016739 \t time=0.84s\n",
      "Best model: Epoch 19 \t loss=0.016876 \t val_loss=0.016652 \t time=0.82s\n",
      "Best model: Epoch 21 \t loss=0.016692 \t val_loss=0.016546 \t time=0.82s\n",
      "Best model: Epoch 22 \t loss=0.016619 \t val_loss=0.016534 \t time=0.81s\n",
      "Best model: Epoch 23 \t loss=0.016499 \t val_loss=0.016386 \t time=0.80s\n",
      "Best model: Epoch 24 \t loss=0.016368 \t val_loss=0.016383 \t time=0.81s\n",
      "Best model: Epoch 25 \t loss=0.016302 \t val_loss=0.016334 \t time=0.80s\n",
      "Best model: Epoch 26 \t loss=0.016181 \t val_loss=0.016334 \t time=0.80s\n",
      "Best model: Epoch 27 \t loss=0.016183 \t val_loss=0.016252 \t time=0.83s\n",
      "Best model: Epoch 28 \t loss=0.016066 \t val_loss=0.016240 \t time=0.83s\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 33 \t loss=0.015405 \t val_loss=0.015999 \t time=1.03s\n",
      "Best model: Epoch 34 \t loss=0.015106 \t val_loss=0.015974 \t time=0.97s\n",
      "Best model: Epoch 35 \t loss=0.015009 \t val_loss=0.015931 \t time=0.78s\n",
      "Best model: Epoch 36 \t loss=0.014911 \t val_loss=0.015887 \t time=0.78s\n",
      "Best model: Epoch 38 \t loss=0.014676 \t val_loss=0.015870 \t time=0.80s\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.412295 \t val_loss=0.073530 \t time=0.79s\n",
      "Best model: Epoch 2 \t loss=0.048063 \t val_loss=0.030229 \t time=0.79s\n",
      "Best model: Epoch 3 \t loss=0.027686 \t val_loss=0.023382 \t time=1.00s\n",
      "Best model: Epoch 4 \t loss=0.023404 \t val_loss=0.021045 \t time=1.16s\n",
      "Best model: Epoch 5 \t loss=0.021881 \t val_loss=0.020405 \t time=0.79s\n",
      "Best model: Epoch 6 \t loss=0.020888 \t val_loss=0.019448 \t time=0.80s\n",
      "Best model: Epoch 7 \t loss=0.020014 \t val_loss=0.018995 \t time=1.01s\n",
      "Best model: Epoch 8 \t loss=0.019511 \t val_loss=0.018848 \t time=0.82s\n",
      "Best model: Epoch 9 \t loss=0.019191 \t val_loss=0.018265 \t time=0.79s\n",
      "Best model: Epoch 10 \t loss=0.018728 \t val_loss=0.017945 \t time=0.82s\n",
      "Best model: Epoch 11 \t loss=0.018486 \t val_loss=0.017824 \t time=0.82s\n",
      "Best model: Epoch 12 \t loss=0.018128 \t val_loss=0.017587 \t time=0.84s\n",
      "Best model: Epoch 13 \t loss=0.017856 \t val_loss=0.017525 \t time=0.80s\n",
      "Best model: Epoch 14 \t loss=0.017637 \t val_loss=0.017242 \t time=0.78s\n",
      "Best model: Epoch 15 \t loss=0.017382 \t val_loss=0.017098 \t time=1.05s\n",
      "Best model: Epoch 17 \t loss=0.017160 \t val_loss=0.017070 \t time=0.79s\n",
      "Best model: Epoch 18 \t loss=0.016971 \t val_loss=0.016891 \t time=0.85s\n",
      "Best model: Epoch 19 \t loss=0.016845 \t val_loss=0.016717 \t time=0.78s\n",
      "Best model: Epoch 21 \t loss=0.016546 \t val_loss=0.016679 \t time=0.77s\n",
      "Best model: Epoch 22 \t loss=0.016400 \t val_loss=0.016620 \t time=0.77s\n",
      "Best model: Epoch 23 \t loss=0.016255 \t val_loss=0.016569 \t time=0.76s\n",
      "Best model: Epoch 25 \t loss=0.016164 \t val_loss=0.016550 \t time=0.80s\n",
      "Best model: Epoch 28 \t loss=0.015939 \t val_loss=0.016531 \t time=0.93s\n",
      "Best model: Epoch 30 \t loss=0.015863 \t val_loss=0.016440 \t time=0.77s\n",
      "Best model: Epoch 32 \t loss=0.015857 \t val_loss=0.016428 \t time=0.79s\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 37 \t loss=0.015215 \t val_loss=0.016292 \t time=0.87s\n",
      "Best model: Epoch 38 \t loss=0.015013 \t val_loss=0.016209 \t time=0.77s\n",
      "Best model: Epoch 39 \t loss=0.014848 \t val_loss=0.016159 \t time=0.79s\n",
      "Best model: Epoch 40 \t loss=0.014773 \t val_loss=0.016149 \t time=0.78s\n",
      "Fold 1 log loss: 0.01618260452035551\n",
      "Fold 2 log loss: 0.016078161616862374\n",
      "Fold 3 log loss: 0.016252955045551125\n",
      "Fold 4 log loss: 0.01593216355923179\n",
      "Fold 5 log loss: 0.016158384081531255\n",
      "Std of log loss: 0.00010963488681493135\n",
      "Total log loss: 0.016120853999890983\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.412083 \t val_loss=0.081015 \t time=0.80s\n",
      "Best model: Epoch 2 \t loss=0.048523 \t val_loss=0.028050 \t time=0.81s\n",
      "Best model: Epoch 3 \t loss=0.026901 \t val_loss=0.022562 \t time=0.82s\n",
      "Best model: Epoch 4 \t loss=0.023177 \t val_loss=0.021699 \t time=0.82s\n",
      "Best model: Epoch 5 \t loss=0.021711 \t val_loss=0.020405 \t time=0.80s\n",
      "Best model: Epoch 6 \t loss=0.020689 \t val_loss=0.019523 \t time=0.83s\n",
      "Best model: Epoch 7 \t loss=0.020087 \t val_loss=0.019048 \t time=0.80s\n",
      "Best model: Epoch 8 \t loss=0.019951 \t val_loss=0.018816 \t time=1.12s\n",
      "Best model: Epoch 9 \t loss=0.019188 \t val_loss=0.018365 \t time=0.80s\n",
      "Best model: Epoch 10 \t loss=0.018771 \t val_loss=0.018001 \t time=0.81s\n",
      "Best model: Epoch 11 \t loss=0.018506 \t val_loss=0.017946 \t time=0.79s\n",
      "Best model: Epoch 12 \t loss=0.018214 \t val_loss=0.017540 \t time=0.81s\n",
      "Best model: Epoch 13 \t loss=0.017902 \t val_loss=0.017348 \t time=0.79s\n",
      "Best model: Epoch 14 \t loss=0.017664 \t val_loss=0.017208 \t time=0.82s\n",
      "Best model: Epoch 16 \t loss=0.017395 \t val_loss=0.017133 \t time=0.82s\n",
      "Best model: Epoch 18 \t loss=0.016983 \t val_loss=0.016944 \t time=0.82s\n",
      "Best model: Epoch 19 \t loss=0.016806 \t val_loss=0.016823 \t time=1.05s\n",
      "Best model: Epoch 20 \t loss=0.016652 \t val_loss=0.016661 \t time=0.95s\n",
      "Best model: Epoch 21 \t loss=0.016557 \t val_loss=0.016641 \t time=1.02s\n",
      "Best model: Epoch 22 \t loss=0.016390 \t val_loss=0.016623 \t time=0.79s\n",
      "Best model: Epoch 24 \t loss=0.016271 \t val_loss=0.016505 \t time=0.80s\n",
      "Best model: Epoch 27 \t loss=0.016037 \t val_loss=0.016484 \t time=1.27s\n",
      "Best model: Epoch 29 \t loss=0.015938 \t val_loss=0.016420 \t time=0.80s\n",
      "Best model: Epoch 30 \t loss=0.015904 \t val_loss=0.016343 \t time=1.00s\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 35 \t loss=0.015277 \t val_loss=0.016194 \t time=0.84s\n",
      "Best model: Epoch 36 \t loss=0.015002 \t val_loss=0.016145 \t time=0.84s\n",
      "Best model: Epoch 38 \t loss=0.014780 \t val_loss=0.016141 \t time=0.84s\n",
      "Best model: Epoch 39 \t loss=0.014660 \t val_loss=0.016100 \t time=0.84s\n",
      "Best model: Epoch 40 \t loss=0.014580 \t val_loss=0.016044 \t time=0.83s\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.411345 \t val_loss=0.080446 \t time=0.79s\n",
      "Best model: Epoch 2 \t loss=0.048536 \t val_loss=0.027533 \t time=1.01s\n",
      "Best model: Epoch 3 \t loss=0.027453 \t val_loss=0.022794 \t time=0.81s\n",
      "Best model: Epoch 4 \t loss=0.023272 \t val_loss=0.021387 \t time=0.82s\n",
      "Best model: Epoch 5 \t loss=0.021758 \t val_loss=0.020049 \t time=0.83s\n",
      "Best model: Epoch 6 \t loss=0.020881 \t val_loss=0.019480 \t time=0.84s\n",
      "Best model: Epoch 7 \t loss=0.020003 \t val_loss=0.018972 \t time=0.81s\n",
      "Best model: Epoch 8 \t loss=0.019613 \t val_loss=0.018893 \t time=0.87s\n",
      "Best model: Epoch 9 \t loss=0.019266 \t val_loss=0.018216 \t time=0.82s\n",
      "Best model: Epoch 10 \t loss=0.018872 \t val_loss=0.017956 \t time=1.02s\n",
      "Best model: Epoch 11 \t loss=0.018601 \t val_loss=0.017700 \t time=0.82s\n",
      "Best model: Epoch 12 \t loss=0.018308 \t val_loss=0.017541 \t time=0.83s\n",
      "Best model: Epoch 13 \t loss=0.017927 \t val_loss=0.017343 \t time=0.85s\n",
      "Best model: Epoch 14 \t loss=0.017687 \t val_loss=0.017284 \t time=1.08s\n",
      "Best model: Epoch 15 \t loss=0.017480 \t val_loss=0.017117 \t time=0.83s\n",
      "Best model: Epoch 16 \t loss=0.017331 \t val_loss=0.017069 \t time=0.84s\n",
      "Best model: Epoch 17 \t loss=0.017191 \t val_loss=0.016877 \t time=0.82s\n",
      "Best model: Epoch 18 \t loss=0.016895 \t val_loss=0.016766 \t time=1.00s\n",
      "Best model: Epoch 19 \t loss=0.016828 \t val_loss=0.016722 \t time=0.91s\n",
      "Best model: Epoch 22 \t loss=0.016517 \t val_loss=0.016629 \t time=0.81s\n",
      "Best model: Epoch 23 \t loss=0.016343 \t val_loss=0.016565 \t time=0.83s\n",
      "Best model: Epoch 24 \t loss=0.016231 \t val_loss=0.016491 \t time=0.82s\n",
      "Best model: Epoch 25 \t loss=0.016179 \t val_loss=0.016422 \t time=0.84s\n",
      "Best model: Epoch 27 \t loss=0.016037 \t val_loss=0.016421 \t time=0.85s\n",
      "Best model: Epoch 28 \t loss=0.016053 \t val_loss=0.016373 \t time=0.82s\n",
      "Best model: Epoch 32 \t loss=0.015940 \t val_loss=0.016369 \t time=0.86s\n",
      "Best model: Epoch 33 \t loss=0.015839 \t val_loss=0.016298 \t time=0.80s\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 38 \t loss=0.015250 \t val_loss=0.016160 \t time=0.82s\n",
      "Best model: Epoch 39 \t loss=0.015083 \t val_loss=0.016084 \t time=1.05s\n",
      "Best model: Epoch 40 \t loss=0.014900 \t val_loss=0.016050 \t time=0.83s\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.410801 \t val_loss=0.079377 \t time=0.83s\n",
      "Best model: Epoch 2 \t loss=0.050438 \t val_loss=0.031013 \t time=1.05s\n",
      "Best model: Epoch 3 \t loss=0.026919 \t val_loss=0.022699 \t time=0.82s\n",
      "Best model: Epoch 4 \t loss=0.023532 \t val_loss=0.020730 \t time=0.82s\n",
      "Best model: Epoch 5 \t loss=0.021540 \t val_loss=0.019951 \t time=0.84s\n",
      "Best model: Epoch 6 \t loss=0.020678 \t val_loss=0.019527 \t time=0.83s\n",
      "Best model: Epoch 7 \t loss=0.020106 \t val_loss=0.019044 \t time=0.82s\n",
      "Best model: Epoch 8 \t loss=0.019653 \t val_loss=0.018490 \t time=1.58s\n",
      "Best model: Epoch 9 \t loss=0.019201 \t val_loss=0.018316 \t time=0.88s\n",
      "Best model: Epoch 10 \t loss=0.018987 \t val_loss=0.018038 \t time=1.01s\n",
      "Best model: Epoch 12 \t loss=0.018568 \t val_loss=0.017700 \t time=1.03s\n",
      "Best model: Epoch 13 \t loss=0.018178 \t val_loss=0.017398 \t time=0.81s\n",
      "Best model: Epoch 15 \t loss=0.017463 \t val_loss=0.017096 \t time=0.81s\n",
      "Best model: Epoch 16 \t loss=0.017451 \t val_loss=0.016965 \t time=0.80s\n",
      "Best model: Epoch 17 \t loss=0.017286 \t val_loss=0.016892 \t time=0.83s\n",
      "Best model: Epoch 19 \t loss=0.016957 \t val_loss=0.016777 \t time=0.85s\n",
      "Best model: Epoch 20 \t loss=0.016805 \t val_loss=0.016671 \t time=1.05s\n",
      "Best model: Epoch 21 \t loss=0.016634 \t val_loss=0.016596 \t time=0.90s\n",
      "Best model: Epoch 22 \t loss=0.016478 \t val_loss=0.016460 \t time=0.83s\n",
      "Best model: Epoch 25 \t loss=0.016246 \t val_loss=0.016404 \t time=0.78s\n",
      "Best model: Epoch 27 \t loss=0.016212 \t val_loss=0.016401 \t time=0.78s\n",
      "Best model: Epoch 28 \t loss=0.016120 \t val_loss=0.016324 \t time=0.82s\n",
      "Best model: Epoch 29 \t loss=0.016049 \t val_loss=0.016297 \t time=0.80s\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 34 \t loss=0.015434 \t val_loss=0.016143 \t time=0.81s\n",
      "Best model: Epoch 35 \t loss=0.015276 \t val_loss=0.016077 \t time=0.79s\n",
      "Best model: Epoch 36 \t loss=0.015106 \t val_loss=0.016014 \t time=1.01s\n",
      "Best model: Epoch 38 \t loss=0.014793 \t val_loss=0.015983 \t time=0.80s\n",
      "Best model: Epoch 39 \t loss=0.014727 \t val_loss=0.015938 \t time=0.80s\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.414512 \t val_loss=0.073665 \t time=0.82s\n",
      "Best model: Epoch 2 \t loss=0.048039 \t val_loss=0.029679 \t time=1.01s\n",
      "Best model: Epoch 3 \t loss=0.028178 \t val_loss=0.022916 \t time=1.00s\n",
      "Best model: Epoch 4 \t loss=0.023153 \t val_loss=0.021274 \t time=0.79s\n",
      "Best model: Epoch 5 \t loss=0.021574 \t val_loss=0.019742 \t time=0.79s\n",
      "Best model: Epoch 6 \t loss=0.020577 \t val_loss=0.019042 \t time=0.79s\n",
      "Best model: Epoch 7 \t loss=0.019956 \t val_loss=0.018745 \t time=0.82s\n",
      "Best model: Epoch 8 \t loss=0.019704 \t val_loss=0.018457 \t time=0.83s\n",
      "Best model: Epoch 9 \t loss=0.019347 \t val_loss=0.018131 \t time=0.81s\n",
      "Best model: Epoch 10 \t loss=0.018802 \t val_loss=0.017733 \t time=0.81s\n",
      "Best model: Epoch 12 \t loss=0.018345 \t val_loss=0.017351 \t time=0.81s\n",
      "Best model: Epoch 13 \t loss=0.017941 \t val_loss=0.017193 \t time=0.84s\n",
      "Best model: Epoch 14 \t loss=0.017840 \t val_loss=0.017053 \t time=0.85s\n",
      "Best model: Epoch 15 \t loss=0.017603 \t val_loss=0.016826 \t time=1.03s\n",
      "Best model: Epoch 18 \t loss=0.017008 \t val_loss=0.016670 \t time=0.82s\n",
      "Best model: Epoch 19 \t loss=0.016845 \t val_loss=0.016547 \t time=0.82s\n",
      "Best model: Epoch 20 \t loss=0.016666 \t val_loss=0.016488 \t time=0.83s\n",
      "Best model: Epoch 22 \t loss=0.016466 \t val_loss=0.016450 \t time=0.83s\n",
      "Best model: Epoch 23 \t loss=0.016328 \t val_loss=0.016333 \t time=0.79s\n",
      "Best model: Epoch 24 \t loss=0.016221 \t val_loss=0.016233 \t time=0.83s\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 29 \t loss=0.015541 \t val_loss=0.016081 \t time=0.99s\n",
      "Best model: Epoch 30 \t loss=0.015313 \t val_loss=0.016026 \t time=0.80s\n",
      "Best model: Epoch 31 \t loss=0.015222 \t val_loss=0.015967 \t time=0.80s\n",
      "Best model: Epoch 33 \t loss=0.014906 \t val_loss=0.015956 \t time=0.94s\n",
      "Best model: Epoch 34 \t loss=0.014854 \t val_loss=0.015948 \t time=1.04s\n",
      "Best model: Epoch 35 \t loss=0.014716 \t val_loss=0.015902 \t time=0.84s\n",
      "Best model: Epoch 37 \t loss=0.014590 \t val_loss=0.015880 \t time=0.79s\n",
      "Best model: Epoch 38 \t loss=0.014511 \t val_loss=0.015855 \t time=0.97s\n",
      "Best model: Epoch 40 \t loss=0.014387 \t val_loss=0.015852 \t time=0.86s\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.414446 \t val_loss=0.080894 \t time=0.81s\n",
      "Best model: Epoch 2 \t loss=0.048403 \t val_loss=0.028187 \t time=0.84s\n",
      "Best model: Epoch 3 \t loss=0.027424 \t val_loss=0.022856 \t time=0.84s\n",
      "Best model: Epoch 4 \t loss=0.023245 \t val_loss=0.021121 \t time=0.81s\n",
      "Best model: Epoch 5 \t loss=0.021648 \t val_loss=0.019905 \t time=0.81s\n",
      "Best model: Epoch 6 \t loss=0.020553 \t val_loss=0.019474 \t time=0.79s\n",
      "Best model: Epoch 7 \t loss=0.019987 \t val_loss=0.018995 \t time=0.80s\n",
      "Best model: Epoch 8 \t loss=0.019416 \t val_loss=0.018652 \t time=0.87s\n",
      "Best model: Epoch 9 \t loss=0.019197 \t val_loss=0.018448 \t time=0.94s\n",
      "Best model: Epoch 10 \t loss=0.018943 \t val_loss=0.018145 \t time=0.85s\n",
      "Best model: Epoch 11 \t loss=0.018550 \t val_loss=0.017854 \t time=0.80s\n",
      "Best model: Epoch 12 \t loss=0.018449 \t val_loss=0.017697 \t time=0.80s\n",
      "Best model: Epoch 13 \t loss=0.017955 \t val_loss=0.017538 \t time=0.82s\n",
      "Best model: Epoch 14 \t loss=0.017690 \t val_loss=0.017399 \t time=0.81s\n",
      "Best model: Epoch 15 \t loss=0.017430 \t val_loss=0.017165 \t time=0.80s\n",
      "Best model: Epoch 16 \t loss=0.017358 \t val_loss=0.017113 \t time=0.84s\n",
      "Best model: Epoch 18 \t loss=0.016990 \t val_loss=0.017063 \t time=0.80s\n",
      "Best model: Epoch 20 \t loss=0.016758 \t val_loss=0.016771 \t time=0.82s\n",
      "Best model: Epoch 21 \t loss=0.016574 \t val_loss=0.016750 \t time=1.25s\n",
      "Best model: Epoch 22 \t loss=0.016503 \t val_loss=0.016682 \t time=0.83s\n",
      "Best model: Epoch 23 \t loss=0.016421 \t val_loss=0.016639 \t time=0.81s\n",
      "Best model: Epoch 24 \t loss=0.016287 \t val_loss=0.016520 \t time=0.82s\n",
      "Best model: Epoch 27 \t loss=0.016048 \t val_loss=0.016459 \t time=0.79s\n",
      "Best model: Epoch 31 \t loss=0.015870 \t val_loss=0.016400 \t time=0.96s\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 36 \t loss=0.015337 \t val_loss=0.016288 \t time=0.85s\n",
      "Best model: Epoch 37 \t loss=0.015082 \t val_loss=0.016188 \t time=0.86s\n",
      "Best model: Epoch 38 \t loss=0.014929 \t val_loss=0.016173 \t time=0.86s\n",
      "Best model: Epoch 39 \t loss=0.014745 \t val_loss=0.016154 \t time=0.81s\n",
      "Fold 1 log loss: 0.016142894486710125\n",
      "Fold 2 log loss: 0.016109272593466513\n",
      "Fold 3 log loss: 0.015936000588408408\n",
      "Fold 4 log loss: 0.015908437997192534\n",
      "Fold 5 log loss: 0.01615436316122924\n",
      "Std of log loss: 0.00010589596231781527\n",
      "Total log loss: 0.01605018632744693\n",
      "Total log loss: 0.015985908580343818\n"
     ]
    }
   ],
   "source": [
    "seeds = [0,1,2,3,4,5,6] \n",
    "nn_train = train.copy().to_numpy()\n",
    "nn_targets = targets.drop(\"sig_id\", axis=1).copy().to_numpy()\n",
    "nn_test = test.copy().to_numpy()\n",
    "\n",
    "oof_final = np.zeros([len(train),nn_targets.shape[1]])\n",
    "pred_final = np.zeros([len(test),nn_targets.shape[1]])\n",
    "\n",
    "for seed_ in seeds:\n",
    "    oof, oof_targets, pytorch_pred = modelling_torch(nn_train, nn_targets, nn_test, sample_seed = seed_, init_num = nn_train.shape[1])\n",
    "    oof_final += oof / len(seeds)\n",
    "    pred_final += pytorch_pred / len(seeds)\n",
    "print(\"Total log loss: {}\".format(mean_log_loss(oof_targets, oof_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T08:43:39.003920Z",
     "iopub.status.busy": "2020-10-05T08:43:39.002994Z",
     "iopub.status.idle": "2020-10-05T08:43:39.005518Z",
     "shell.execute_reply": "2020-10-05T08:43:39.006161Z"
    },
    "papermill": {
     "duration": 0.590357,
     "end_time": "2020-10-05T08:43:39.006339",
     "exception": false,
     "start_time": "2020-10-05T08:43:38.415982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#local = targets.drop(\"sig_id\", axis=1).copy()\n",
    "#local[target_feats] = oof_final\n",
    "#local.loc[noncons_train_index,target_feats] = 0\n",
    "#print(\"Local log loss: {}\".format(mean_log_loss(oof_targets, oof_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T08:43:39.903474Z",
     "iopub.status.busy": "2020-10-05T08:43:39.902645Z",
     "iopub.status.idle": "2020-10-05T08:43:42.450995Z",
     "shell.execute_reply": "2020-10-05T08:43:42.449876Z"
    },
    "papermill": {
     "duration": 2.972447,
     "end_time": "2020-10-05T08:43:42.451123",
     "exception": false,
     "start_time": "2020-10-05T08:43:39.478676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub[target_feats] = pred_final\n",
    "sub.loc[noncons_test_index,target_feats] = 0\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.420831,
     "end_time": "2020-10-05T08:43:43.287386",
     "exception": false,
     "start_time": "2020-10-05T08:43:42.866555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 1391.269214,
   "end_time": "2020-10-05T08:43:44.224392",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-05T08:20:32.955178",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
