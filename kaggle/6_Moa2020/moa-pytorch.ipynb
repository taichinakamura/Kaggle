{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015571,
     "end_time": "2020-10-08T09:23:33.978440",
     "exception": false,
     "start_time": "2020-10-08T09:23:33.962869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- set early stopping not to overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-08T09:23:34.017120Z",
     "iopub.status.busy": "2020-10-08T09:23:34.016204Z",
     "iopub.status.idle": "2020-10-08T09:23:41.639172Z",
     "shell.execute_reply": "2020-10-08T09:23:41.637850Z"
    },
    "papermill": {
     "duration": 7.646191,
     "end_time": "2020-10-08T09:23:41.639324",
     "exception": false,
     "start_time": "2020-10-08T09:23:33.993133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "sys.path.append('../input/multilabelstraifier/')\n",
    "sys.path.append('../input/lookahead/')\n",
    "from ml_stratifiers import MultilabelStratifiedKFold\n",
    "from lookahead import Lookahead\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T09:23:41.686005Z",
     "iopub.status.busy": "2020-10-08T09:23:41.684887Z",
     "iopub.status.idle": "2020-10-08T09:23:47.595395Z",
     "shell.execute_reply": "2020-10-08T09:23:47.594098Z"
    },
    "papermill": {
     "duration": 5.938798,
     "end_time": "2020-10-08T09:23:47.595529",
     "exception": false,
     "start_time": "2020-10-08T09:23:41.656731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/lish-moa/'\n",
    "train = pd.read_csv(DATA_DIR + 'train_features.csv')\n",
    "targets = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "non_targets = pd.read_csv(DATA_DIR + 'train_targets_nonscored.csv')\n",
    "test = pd.read_csv(DATA_DIR + 'test_features.csv')\n",
    "sub = pd.read_csv(DATA_DIR + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T09:23:47.637484Z",
     "iopub.status.busy": "2020-10-08T09:23:47.635347Z",
     "iopub.status.idle": "2020-10-08T09:23:47.638255Z",
     "shell.execute_reply": "2020-10-08T09:23:47.638775Z"
    },
    "papermill": {
     "duration": 0.028098,
     "end_time": "2020-10-08T09:23:47.638910",
     "exception": false,
     "start_time": "2020-10-08T09:23:47.610812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_feats = [ i for i in targets.columns if i != \"sig_id\"]\n",
    "g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "c_feats = [i for i in train.columns if \"c-\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T09:23:47.681841Z",
     "iopub.status.busy": "2020-10-08T09:23:47.680767Z",
     "iopub.status.idle": "2020-10-08T09:23:47.782749Z",
     "shell.execute_reply": "2020-10-08T09:23:47.782159Z"
    },
    "papermill": {
     "duration": 0.126264,
     "end_time": "2020-10-08T09:23:47.782871",
     "exception": false,
     "start_time": "2020-10-08T09:23:47.656607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "noncons_train_index = train[train.cp_type==\"ctl_vehicle\"].index\n",
    "cons_train_index = train[train.cp_type!=\"ctl_vehicle\"].index\n",
    "noncons_test_index = test[test.cp_type==\"ctl_vehicle\"].index\n",
    "cons_test_index = test[test.cp_type!=\"ctl_vehicle\"].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015003,
     "end_time": "2020-10-08T09:23:47.813068",
     "exception": false,
     "start_time": "2020-10-08T09:23:47.798065",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T09:23:47.859933Z",
     "iopub.status.busy": "2020-10-08T09:23:47.854359Z",
     "iopub.status.idle": "2020-10-08T09:23:48.180912Z",
     "shell.execute_reply": "2020-10-08T09:23:48.180346Z"
    },
    "papermill": {
     "duration": 0.352459,
     "end_time": "2020-10-08T09:23:48.181056",
     "exception": false,
     "start_time": "2020-10-08T09:23:47.828597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train[train.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "targets = targets[targets.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "non_targets = non_targets[non_targets.index.isin(cons_train_index)].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T09:23:48.248950Z",
     "iopub.status.busy": "2020-10-08T09:23:48.247989Z",
     "iopub.status.idle": "2020-10-08T09:23:48.261516Z",
     "shell.execute_reply": "2020-10-08T09:23:48.260961Z"
    },
    "papermill": {
     "duration": 0.064917,
     "end_time": "2020-10-08T09:23:48.261655",
     "exception": false,
     "start_time": "2020-10-08T09:23:48.196738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "non_target_feats = [i for i in non_targets.columns if i != \"sig_id\"]\n",
    "nontarget_dists = pd.DataFrame(np.sum(non_targets[non_target_feats])).reset_index(drop=False)\n",
    "nontarget_dists.columns = [\"target\", \"number\"]\n",
    "nontarget_dists = nontarget_dists.sort_values(\"number\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T09:23:48.298810Z",
     "iopub.status.busy": "2020-10-08T09:23:48.297120Z",
     "iopub.status.idle": "2020-10-08T09:23:48.299495Z",
     "shell.execute_reply": "2020-10-08T09:23:48.300014Z"
    },
    "papermill": {
     "duration": 0.022706,
     "end_time": "2020-10-08T09:23:48.300165",
     "exception": false,
     "start_time": "2020-10-08T09:23:48.277459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#target_dists = pd.DataFrame(np.sum(targets[target_feats])).reset_index(drop=False)\n",
    "#target_dists.columns = [\"target\", \"number\"]\n",
    "#target_dists = target_dists.sort_values(\"number\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T09:23:48.339267Z",
     "iopub.status.busy": "2020-10-08T09:23:48.338584Z",
     "iopub.status.idle": "2020-10-08T09:23:48.396592Z",
     "shell.execute_reply": "2020-10-08T09:23:48.396051Z"
    },
    "papermill": {
     "duration": 0.080934,
     "end_time": "2020-10-08T09:23:48.396709",
     "exception": false,
     "start_time": "2020-10-08T09:23:48.315775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first drop 71\n",
      "shape after 1st drop: (21948, 332)\n",
      "second drop 125\n",
      "shape after 2nd drop: (21948, 207)\n"
     ]
    }
   ],
   "source": [
    "drop_list1 = list(nontarget_dists[nontarget_dists.number==0][\"target\"].values)\n",
    "print(\"first drop\", len(drop_list1))\n",
    "non_targets.drop(drop_list1, axis=1, inplace=True)\n",
    "print(\"shape after 1st drop:\", non_targets.shape)\n",
    "drop_list2 = list(nontarget_dists[(nontarget_dists.number>0) & (nontarget_dists.number<=6)][\"target\"].values)[:-1]\n",
    "print(\"second drop\", len(drop_list2))\n",
    "non_targets.drop(drop_list2, axis=1, inplace=True)\n",
    "print(\"shape after 2nd drop:\", non_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015515,
     "end_time": "2020-10-08T09:23:48.428505",
     "exception": false,
     "start_time": "2020-10-08T09:23:48.412990",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T09:23:48.469594Z",
     "iopub.status.busy": "2020-10-08T09:23:48.468367Z",
     "iopub.status.idle": "2020-10-08T09:23:48.607349Z",
     "shell.execute_reply": "2020-10-08T09:23:48.607869Z"
    },
    "papermill": {
     "duration": 0.163477,
     "end_time": "2020-10-08T09:23:48.608009",
     "exception": false,
     "start_time": "2020-10-08T09:23:48.444532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 874) (3982, 874)\n"
     ]
    }
   ],
   "source": [
    "def fe(df):\n",
    "    tmp = df.copy()\n",
    "    tmp.loc[:, 'cp_type'] = tmp.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    tmp.loc[:, 'cp_dose'] = tmp.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "        \n",
    "    tmp.drop([\"cp_type\", \"sig_id\"], axis=1, inplace=True)\n",
    "    return tmp\n",
    "\n",
    "f_train = fe(train)\n",
    "f_test = fe(test)\n",
    "\n",
    "print(f_train.shape, f_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016159,
     "end_time": "2020-10-08T09:23:48.640813",
     "exception": false,
     "start_time": "2020-10-08T09:23:48.624654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T09:23:48.687022Z",
     "iopub.status.busy": "2020-10-08T09:23:48.686097Z",
     "iopub.status.idle": "2020-10-08T09:23:49.035956Z",
     "shell.execute_reply": "2020-10-08T09:23:49.036911Z"
    },
    "papermill": {
     "duration": 0.38012,
     "end_time": "2020-10-08T09:23:49.037051",
     "exception": false,
     "start_time": "2020-10-08T09:23:48.656931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "def mean_log_loss(y_true, y_pred):\n",
    "    metrics = []\n",
    "    for i, target in enumerate(target_feats):\n",
    "        metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float), labels=[0,1]))\n",
    "    return np.mean(metrics)\n",
    "\n",
    "def seed_everything(seed=1234): \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "class MoaModel(nn.Module):\n",
    "    def __init__(self, num_columns):\n",
    "        super(MoaModel, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_columns)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_columns, 2048))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(2048)\n",
    "        self.dropout2 = nn.Dropout(0.6)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(2048,1048))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(1048)\n",
    "        self.dropout3 = nn.Dropout(0.6)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(1048, 206))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016809,
     "end_time": "2020-10-08T09:23:49.071076",
     "exception": false,
     "start_time": "2020-10-08T09:23:49.054267",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# train by non-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T09:23:49.128961Z",
     "iopub.status.busy": "2020-10-08T09:23:49.113389Z",
     "iopub.status.idle": "2020-10-08T09:23:49.147468Z",
     "shell.execute_reply": "2020-10-08T09:23:49.146943Z"
    },
    "papermill": {
     "duration": 0.059388,
     "end_time": "2020-10-08T09:23:49.147558",
     "exception": false,
     "start_time": "2020-10-08T09:23:49.088170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_epochs = 30\n",
    "n_folds=5\n",
    "\n",
    "def first_learning(tr, target, sample_seed, init_num):\n",
    "    seed_everything(seed=sample_seed) \n",
    "    X_train = tr.copy()\n",
    "    y_train = target.copy()\n",
    "\n",
    "    mskf=MultilabelStratifiedKFold(n_splits = n_folds, shuffle=True, random_state=2)\n",
    "    files = []\n",
    "        \n",
    "    oof = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    oof_targets = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    scores = []\n",
    "    for fold, (train_index, valid_index) in enumerate(mskf.split(X_train, y_train)):\n",
    "        print(\"Fold \"+str(fold+1))\n",
    "        X_train2 = torch.tensor(X_train[train_index,:], dtype=torch.float32)\n",
    "        y_train2 = torch.tensor(y_train[train_index], dtype=torch.float32)\n",
    "\n",
    "        X_valid2 = torch.tensor(X_train[valid_index,:], dtype=torch.float32)\n",
    "        y_valid2 = torch.tensor(y_train[valid_index], dtype=torch.float32)\n",
    "            \n",
    "        clf = MoaModel(init_num)\n",
    "        loss_fn = torch.nn.BCEWithLogitsLoss() \n",
    "        optimizer = optim.Adam(clf.parameters(), lr = 0.001, weight_decay=1e-5) \n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, eps=1e-4, verbose=True)\n",
    "        \n",
    "        train = torch.utils.data.TensorDataset(X_train2, y_train2)\n",
    "        valid = torch.utils.data.TensorDataset(X_valid2, y_valid2)\n",
    "        \n",
    "        clf.to(device)\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True) \n",
    "        valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        best_val_loss = np.inf\n",
    "        stop_counts = 0\n",
    "        for epoch in range(train_epochs):\n",
    "            start_time = time.time()\n",
    "            clf.train()\n",
    "            avg_loss = 0.\n",
    "            for x_batch, y_batch in tqdm(train_loader, disable=True):\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch) \n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                avg_loss += loss.item() / len(train_loader)        \n",
    "            \n",
    "            clf.eval()\n",
    "            avg_val_loss = 0.\n",
    "            for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch).detach()\n",
    "                avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "        \n",
    "            elapsed_time = time.time() - start_time \n",
    "            scheduler.step(avg_val_loss)\n",
    "                    \n",
    "            if avg_val_loss < best_val_loss:\n",
    "                stop_counts = 0\n",
    "                best_val_loss = avg_val_loss\n",
    "                print('Best model: Epoch {} \\t loss={:.6f} \\t val_loss={:.6f} \\t time={:.2f}s'.format(\n",
    "                    epoch + 1, avg_loss, avg_val_loss, elapsed_time))\n",
    "                torch.save(clf.state_dict(), 'parameters'+str(fold+1)+'.pt')\n",
    "            else:\n",
    "                stop_counts += 1\n",
    "         \n",
    "        files.append('parameters'+str(fold+1)+'.pt')\n",
    "        pred_model = MoaModel(init_num)\n",
    "        pred_model.load_state_dict(torch.load('parameters'+str(fold+1)+'.pt'))\n",
    "        pred_model.eval()\n",
    "        \n",
    "        # validation check ----------------\n",
    "        oof_epoch = np.zeros([X_valid2.size(0), y_train.shape[1]])\n",
    "        target_epoch = np.zeros([X_valid2.size(0), y_train.shape[1]])\n",
    "        for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "                y_pred = pred_model(x_batch).sigmoid().detach()\n",
    "                oof_epoch[i * batch_size:(i+1) * batch_size,:] = y_pred.cpu().numpy()\n",
    "                target_epoch[i * batch_size:(i+1) * batch_size,:] = y_batch.cpu().numpy()\n",
    "        print(\"Fold {} log loss: {}\".format(fold+1, mean_log_loss(target_epoch, oof_epoch)))\n",
    "        scores.append(mean_log_loss(target_epoch, oof_epoch))\n",
    "        oof[valid_index,:] = oof_epoch\n",
    "        oof_targets[valid_index,:] = target_epoch\n",
    "        #-----------------------------------\n",
    "        \n",
    "    print(\"Seed {}\".format(seed_))\n",
    "    for i, ele in enumerate(scores):\n",
    "        print(\"Fold {} log loss: {}\".format(i+1, scores[i]))\n",
    "    print(\"Std of log loss: {}\".format(np.std(scores)))\n",
    "    print(\"Total log loss: {}\".format(mean_log_loss(oof_targets, oof)))\n",
    "    \n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T09:23:49.190595Z",
     "iopub.status.busy": "2020-10-08T09:23:49.189363Z",
     "iopub.status.idle": "2020-10-08T09:26:29.110461Z",
     "shell.execute_reply": "2020-10-08T09:26:29.109481Z"
    },
    "papermill": {
     "duration": 159.945899,
     "end_time": "2020-10-08T09:26:29.110597",
     "exception": false,
     "start_time": "2020-10-08T09:23:49.164698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.411553 \t val_loss=0.066848 \t time=1.82s\n",
      "Best model: Epoch 2 \t loss=0.039160 \t val_loss=0.019184 \t time=0.83s\n",
      "Best model: Epoch 3 \t loss=0.015622 \t val_loss=0.011588 \t time=1.41s\n",
      "Best model: Epoch 4 \t loss=0.010761 \t val_loss=0.008867 \t time=0.79s\n",
      "Best model: Epoch 5 \t loss=0.009001 \t val_loss=0.008143 \t time=0.96s\n",
      "Best model: Epoch 6 \t loss=0.008491 \t val_loss=0.007786 \t time=0.83s\n",
      "Best model: Epoch 7 \t loss=0.007914 \t val_loss=0.007451 \t time=0.93s\n",
      "Best model: Epoch 8 \t loss=0.007738 \t val_loss=0.007360 \t time=0.90s\n",
      "Best model: Epoch 11 \t loss=0.007491 \t val_loss=0.007235 \t time=0.84s\n",
      "Best model: Epoch 13 \t loss=0.007401 \t val_loss=0.007163 \t time=0.81s\n",
      "Best model: Epoch 14 \t loss=0.007295 \t val_loss=0.007146 \t time=0.94s\n",
      "Best model: Epoch 15 \t loss=0.007134 \t val_loss=0.007122 \t time=1.13s\n",
      "Best model: Epoch 16 \t loss=0.006997 \t val_loss=0.007050 \t time=0.87s\n",
      "Best model: Epoch 17 \t loss=0.006939 \t val_loss=0.007000 \t time=0.96s\n",
      "Best model: Epoch 18 \t loss=0.006859 \t val_loss=0.006903 \t time=0.78s\n",
      "Best model: Epoch 20 \t loss=0.006720 \t val_loss=0.006794 \t time=0.79s\n",
      "Best model: Epoch 21 \t loss=0.006661 \t val_loss=0.006793 \t time=0.76s\n",
      "Best model: Epoch 23 \t loss=0.006517 \t val_loss=0.006788 \t time=0.80s\n",
      "Best model: Epoch 24 \t loss=0.006500 \t val_loss=0.006786 \t time=0.77s\n",
      "Best model: Epoch 25 \t loss=0.006401 \t val_loss=0.006711 \t time=0.76s\n",
      "Best model: Epoch 26 \t loss=0.006371 \t val_loss=0.006711 \t time=0.78s\n",
      "Best model: Epoch 27 \t loss=0.006365 \t val_loss=0.006701 \t time=1.13s\n",
      "Best model: Epoch 28 \t loss=0.006367 \t val_loss=0.006699 \t time=1.21s\n",
      "Best model: Epoch 29 \t loss=0.006283 \t val_loss=0.006635 \t time=0.95s\n",
      "Fold 1 log loss: 0.006678689469777681\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.410972 \t val_loss=0.067712 \t time=0.98s\n",
      "Best model: Epoch 2 \t loss=0.038686 \t val_loss=0.017746 \t time=0.82s\n",
      "Best model: Epoch 3 \t loss=0.015685 \t val_loss=0.011750 \t time=0.83s\n",
      "Best model: Epoch 4 \t loss=0.010567 \t val_loss=0.009027 \t time=0.84s\n",
      "Best model: Epoch 5 \t loss=0.009072 \t val_loss=0.008609 \t time=0.83s\n",
      "Best model: Epoch 6 \t loss=0.008209 \t val_loss=0.007769 \t time=0.99s\n",
      "Best model: Epoch 7 \t loss=0.007921 \t val_loss=0.007658 \t time=0.88s\n",
      "Best model: Epoch 8 \t loss=0.007684 \t val_loss=0.007510 \t time=0.86s\n",
      "Best model: Epoch 9 \t loss=0.007607 \t val_loss=0.007494 \t time=0.84s\n",
      "Best model: Epoch 10 \t loss=0.007528 \t val_loss=0.007388 \t time=0.83s\n",
      "Best model: Epoch 12 \t loss=0.007341 \t val_loss=0.007299 \t time=0.86s\n",
      "Best model: Epoch 13 \t loss=0.007267 \t val_loss=0.007283 \t time=0.98s\n",
      "Best model: Epoch 14 \t loss=0.007156 \t val_loss=0.007218 \t time=0.85s\n",
      "Best model: Epoch 16 \t loss=0.007121 \t val_loss=0.007155 \t time=0.84s\n",
      "Best model: Epoch 18 \t loss=0.006910 \t val_loss=0.007061 \t time=1.09s\n",
      "Best model: Epoch 19 \t loss=0.006831 \t val_loss=0.006957 \t time=0.95s\n",
      "Best model: Epoch 21 \t loss=0.006707 \t val_loss=0.006956 \t time=0.82s\n",
      "Best model: Epoch 22 \t loss=0.006633 \t val_loss=0.006894 \t time=0.87s\n",
      "Best model: Epoch 23 \t loss=0.006509 \t val_loss=0.006830 \t time=0.89s\n",
      "Best model: Epoch 26 \t loss=0.006424 \t val_loss=0.006780 \t time=0.89s\n",
      "Best model: Epoch 27 \t loss=0.006377 \t val_loss=0.006761 \t time=0.93s\n",
      "Best model: Epoch 28 \t loss=0.006315 \t val_loss=0.006731 \t time=0.84s\n",
      "Best model: Epoch 30 \t loss=0.006222 \t val_loss=0.006711 \t time=1.08s\n",
      "Fold 2 log loss: 0.0066745046777815\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.412186 \t val_loss=0.072231 \t time=0.99s\n",
      "Best model: Epoch 2 \t loss=0.039084 \t val_loss=0.016662 \t time=0.86s\n",
      "Best model: Epoch 3 \t loss=0.015207 \t val_loss=0.010575 \t time=0.93s\n",
      "Best model: Epoch 4 \t loss=0.011059 \t val_loss=0.009576 \t time=0.83s\n",
      "Best model: Epoch 5 \t loss=0.009172 \t val_loss=0.008474 \t time=1.18s\n",
      "Best model: Epoch 6 \t loss=0.008386 \t val_loss=0.008286 \t time=0.85s\n",
      "Best model: Epoch 7 \t loss=0.007953 \t val_loss=0.007499 \t time=0.88s\n",
      "Best model: Epoch 10 \t loss=0.007564 \t val_loss=0.007213 \t time=0.94s\n",
      "Best model: Epoch 11 \t loss=0.007466 \t val_loss=0.007205 \t time=0.85s\n",
      "Best model: Epoch 12 \t loss=0.007255 \t val_loss=0.007130 \t time=0.84s\n",
      "Best model: Epoch 14 \t loss=0.007160 \t val_loss=0.007095 \t time=0.93s\n",
      "Best model: Epoch 15 \t loss=0.007188 \t val_loss=0.007025 \t time=0.90s\n",
      "Best model: Epoch 17 \t loss=0.007051 \t val_loss=0.007019 \t time=0.81s\n",
      "Best model: Epoch 18 \t loss=0.006891 \t val_loss=0.006903 \t time=1.06s\n",
      "Best model: Epoch 19 \t loss=0.006852 \t val_loss=0.006886 \t time=1.16s\n",
      "Best model: Epoch 20 \t loss=0.006716 \t val_loss=0.006808 \t time=1.12s\n",
      "Best model: Epoch 24 \t loss=0.006544 \t val_loss=0.006745 \t time=0.81s\n",
      "Best model: Epoch 25 \t loss=0.006472 \t val_loss=0.006731 \t time=0.87s\n",
      "Best model: Epoch 26 \t loss=0.006409 \t val_loss=0.006671 \t time=0.84s\n",
      "Best model: Epoch 27 \t loss=0.006345 \t val_loss=0.006624 \t time=0.78s\n",
      "Best model: Epoch 28 \t loss=0.006291 \t val_loss=0.006615 \t time=0.79s\n",
      "Best model: Epoch 29 \t loss=0.006267 \t val_loss=0.006595 \t time=0.81s\n",
      "Fold 3 log loss: 0.006669147460645871\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.409223 \t val_loss=0.069829 \t time=0.90s\n",
      "Best model: Epoch 2 \t loss=0.039736 \t val_loss=0.018641 \t time=0.79s\n",
      "Best model: Epoch 3 \t loss=0.015312 \t val_loss=0.011061 \t time=0.78s\n",
      "Best model: Epoch 4 \t loss=0.010763 \t val_loss=0.009095 \t time=1.05s\n",
      "Best model: Epoch 5 \t loss=0.009210 \t val_loss=0.008176 \t time=1.13s\n",
      "Best model: Epoch 6 \t loss=0.008187 \t val_loss=0.007671 \t time=0.97s\n",
      "Best model: Epoch 7 \t loss=0.007884 \t val_loss=0.007610 \t time=0.83s\n",
      "Best model: Epoch 8 \t loss=0.007806 \t val_loss=0.007510 \t time=0.79s\n",
      "Best model: Epoch 9 \t loss=0.007670 \t val_loss=0.007484 \t time=0.75s\n",
      "Best model: Epoch 11 \t loss=0.007558 \t val_loss=0.007338 \t time=1.04s\n",
      "Best model: Epoch 12 \t loss=0.007370 \t val_loss=0.007250 \t time=0.92s\n",
      "Best model: Epoch 13 \t loss=0.007314 \t val_loss=0.007181 \t time=0.77s\n",
      "Best model: Epoch 14 \t loss=0.007148 \t val_loss=0.007134 \t time=0.82s\n",
      "Best model: Epoch 16 \t loss=0.007115 \t val_loss=0.007126 \t time=0.75s\n",
      "Best model: Epoch 17 \t loss=0.007053 \t val_loss=0.007055 \t time=0.99s\n",
      "Best model: Epoch 18 \t loss=0.007030 \t val_loss=0.007006 \t time=0.78s\n",
      "Best model: Epoch 19 \t loss=0.006898 \t val_loss=0.006884 \t time=0.84s\n",
      "Best model: Epoch 20 \t loss=0.006780 \t val_loss=0.006874 \t time=1.12s\n",
      "Best model: Epoch 22 \t loss=0.006650 \t val_loss=0.006789 \t time=0.82s\n",
      "Best model: Epoch 23 \t loss=0.006565 \t val_loss=0.006772 \t time=0.77s\n",
      "Best model: Epoch 24 \t loss=0.006515 \t val_loss=0.006718 \t time=1.04s\n",
      "Best model: Epoch 27 \t loss=0.006369 \t val_loss=0.006672 \t time=0.88s\n",
      "Best model: Epoch 30 \t loss=0.006261 \t val_loss=0.006652 \t time=0.80s\n",
      "Fold 4 log loss: 0.006594386193740523\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.412756 \t val_loss=0.067032 \t time=1.25s\n",
      "Best model: Epoch 2 \t loss=0.038178 \t val_loss=0.016806 \t time=0.93s\n",
      "Best model: Epoch 3 \t loss=0.015632 \t val_loss=0.011622 \t time=0.81s\n",
      "Best model: Epoch 4 \t loss=0.010557 \t val_loss=0.009338 \t time=1.51s\n",
      "Best model: Epoch 5 \t loss=0.009246 \t val_loss=0.008268 \t time=0.93s\n",
      "Best model: Epoch 6 \t loss=0.008389 \t val_loss=0.007762 \t time=0.90s\n",
      "Best model: Epoch 7 \t loss=0.007946 \t val_loss=0.007598 \t time=0.82s\n",
      "Best model: Epoch 8 \t loss=0.007813 \t val_loss=0.007387 \t time=0.90s\n",
      "Best model: Epoch 9 \t loss=0.007647 \t val_loss=0.007378 \t time=0.80s\n",
      "Best model: Epoch 10 \t loss=0.007533 \t val_loss=0.007366 \t time=0.80s\n",
      "Best model: Epoch 11 \t loss=0.007493 \t val_loss=0.007241 \t time=0.78s\n",
      "Best model: Epoch 14 \t loss=0.007210 \t val_loss=0.007142 \t time=0.78s\n",
      "Best model: Epoch 15 \t loss=0.007177 \t val_loss=0.007103 \t time=1.03s\n",
      "Best model: Epoch 16 \t loss=0.007079 \t val_loss=0.007066 \t time=0.87s\n",
      "Best model: Epoch 17 \t loss=0.007024 \t val_loss=0.007049 \t time=0.82s\n",
      "Best model: Epoch 18 \t loss=0.006997 \t val_loss=0.007007 \t time=0.79s\n",
      "Best model: Epoch 19 \t loss=0.006861 \t val_loss=0.006942 \t time=0.77s\n",
      "Best model: Epoch 20 \t loss=0.006783 \t val_loss=0.006893 \t time=0.88s\n",
      "Best model: Epoch 22 \t loss=0.006655 \t val_loss=0.006853 \t time=0.95s\n",
      "Best model: Epoch 23 \t loss=0.006611 \t val_loss=0.006811 \t time=0.93s\n",
      "Best model: Epoch 26 \t loss=0.006490 \t val_loss=0.006791 \t time=0.77s\n",
      "Best model: Epoch 28 \t loss=0.006330 \t val_loss=0.006764 \t time=0.89s\n",
      "Best model: Epoch 29 \t loss=0.006278 \t val_loss=0.006734 \t time=0.83s\n",
      "Fold 5 log loss: 0.006698666118837581\n",
      "Seed 0\n",
      "Fold 1 log loss: 0.006678689469777681\n",
      "Fold 2 log loss: 0.0066745046777815\n",
      "Fold 3 log loss: 0.006669147460645871\n",
      "Fold 4 log loss: 0.006594386193740523\n",
      "Fold 5 log loss: 0.006698666118837581\n",
      "Std of log loss: 3.576647523250315e-05\n",
      "Total log loss: 0.0066630816374423025\n"
     ]
    }
   ],
   "source": [
    "fn_train = f_train.copy().to_numpy()\n",
    "fn_test = f_test.copy().to_numpy()\n",
    "\n",
    "ss = preprocessing.StandardScaler()\n",
    "fn_train= ss.fit_transform(fn_train)\n",
    "fn_test = ss.transform(fn_test)\n",
    "\n",
    "fn_nontargets = non_targets.drop(\"sig_id\", axis=1).copy().to_numpy()\n",
    "nontarget_oof = np.zeros([len(fn_train),fn_nontargets.shape[1]])\n",
    "nontarget_pred = np.zeros([len(fn_test),fn_nontargets.shape[1]])\n",
    "\n",
    "seeds = [0]\n",
    "for seed_ in seeds:\n",
    "    files = first_learning(fn_train, fn_nontargets, seed_, fn_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.060214,
     "end_time": "2020-10-08T09:26:29.231823",
     "exception": false,
     "start_time": "2020-10-08T09:26:29.171609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# train by targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T09:26:29.380926Z",
     "iopub.status.busy": "2020-10-08T09:26:29.375557Z",
     "iopub.status.idle": "2020-10-08T09:26:29.396072Z",
     "shell.execute_reply": "2020-10-08T09:26:29.395543Z"
    },
    "papermill": {
     "duration": 0.104311,
     "end_time": "2020-10-08T09:26:29.396167",
     "exception": false,
     "start_time": "2020-10-08T09:26:29.291856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_epochs = 30\n",
    "n_folds=5\n",
    "EARLY_STOPPING_STEPS = 3\n",
    "\n",
    "def modelling_torch(tr, target, te, sample_seed, init_num, files):\n",
    "    seed_everything(seed=sample_seed) \n",
    "    X_train = tr.copy()\n",
    "    y_train = target.copy()\n",
    "    X_test = te.copy()\n",
    "    test_len = X_test.shape[0]\n",
    "\n",
    "    mskf=MultilabelStratifiedKFold(n_splits = n_folds, shuffle=True, random_state=2)\n",
    "    models = []\n",
    "    \n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    X_test = torch.utils.data.TensorDataset(X_test) \n",
    "    test_loader = torch.utils.data.DataLoader(X_test, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    oof = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    oof_targets = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    pred_value = np.zeros([test_len, y_train.shape[1]])\n",
    "    scores = []\n",
    "    for fold, (train_index, valid_index) in enumerate(mskf.split(X_train, y_train)):\n",
    "        print(\"Fold \"+str(fold+1))\n",
    "        X_train2 = torch.tensor(X_train[train_index,:], dtype=torch.float32)\n",
    "        y_train2 = torch.tensor(y_train[train_index], dtype=torch.float32)\n",
    "\n",
    "        X_valid2 = torch.tensor(X_train[valid_index,:], dtype=torch.float32)\n",
    "        y_valid2 = torch.tensor(y_train[valid_index], dtype=torch.float32)\n",
    "            \n",
    "        clf = MoaModel(init_num)\n",
    "        clf.load_state_dict(torch.load(files[fold]))\n",
    "        loss_fn = torch.nn.BCEWithLogitsLoss() \n",
    "        optimizer = optim.Adam(clf.parameters(), lr = 0.001) \n",
    "        #lookahead = Lookahead(optimizer, k=10, alpha=0.6) #lookahead\n",
    "        #scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=1, eps=1e-4, verbose=True)\n",
    "        \n",
    "        train = torch.utils.data.TensorDataset(X_train2, y_train2)\n",
    "        valid = torch.utils.data.TensorDataset(X_valid2, y_valid2)\n",
    "        \n",
    "        clf.to(device)\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True) \n",
    "        valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        best_val_loss = np.inf\n",
    "        stop_counts = 0\n",
    "        for epoch in range(train_epochs):\n",
    "            start_time = time.time()\n",
    "            clf.train()\n",
    "            avg_loss = 0.\n",
    "            for x_batch, y_batch in tqdm(train_loader, disable=True):\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch) \n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                avg_loss += loss.item() / len(train_loader)        \n",
    "            \n",
    "            clf.eval()\n",
    "            avg_val_loss = 0.\n",
    "            for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch).detach()\n",
    "                avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "        \n",
    "            elapsed_time = time.time() - start_time \n",
    "            #scheduler.step(avg_val_loss)\n",
    "                    \n",
    "            if avg_val_loss < best_val_loss:\n",
    "                stop_counts = 0\n",
    "                best_val_loss = avg_val_loss\n",
    "                print('Best model: Epoch {} \\t loss={:.6f} \\t val_loss={:.6f} \\t time={:.2f}s'.format(\n",
    "                    epoch + 1, avg_loss, avg_val_loss, elapsed_time))\n",
    "                torch.save(clf.state_dict(), 'best-model-parameters.pt')\n",
    "            else:\n",
    "                stop_counts += 1\n",
    "        \n",
    "            if stop_counts >= EARLY_STOPPING_STEPS: \n",
    "                break\n",
    "         \n",
    "        pred_model = MoaModel(init_num)\n",
    "        pred_model.load_state_dict(torch.load('best-model-parameters.pt'))\n",
    "        pred_model.eval()\n",
    "        \n",
    "        # validation check ----------------\n",
    "        oof_epoch = np.zeros([X_valid2.size(0), y_train.shape[1]])\n",
    "        target_epoch = np.zeros([X_valid2.size(0), y_train.shape[1]])\n",
    "        for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "                y_pred = pred_model(x_batch).sigmoid().detach()\n",
    "                oof_epoch[i * batch_size:(i+1) * batch_size,:] = y_pred.cpu().numpy()\n",
    "                target_epoch[i * batch_size:(i+1) * batch_size,:] = y_batch.cpu().numpy()\n",
    "        print(\"Fold {} log loss: {}\".format(fold+1, mean_log_loss(target_epoch, oof_epoch)))\n",
    "        scores.append(mean_log_loss(target_epoch, oof_epoch))\n",
    "        oof[valid_index,:] = oof_epoch\n",
    "        oof_targets[valid_index,:] = target_epoch\n",
    "        #-----------------------------------\n",
    "        \n",
    "        # test predcition --------------\n",
    "        test_preds = np.zeros([test_len, y_train.shape[1]])\n",
    "        for i, (x_batch,) in enumerate(test_loader): \n",
    "            y_pred = pred_model(x_batch).sigmoid().detach()\n",
    "            test_preds[i * batch_size:(i+1) * batch_size, :] = y_pred.cpu().numpy()\n",
    "        pred_value += test_preds / n_folds\n",
    "        # ------------------------------\n",
    "        \n",
    "    print(\"Seed {}\".format(seed_))\n",
    "    for i, ele in enumerate(scores):\n",
    "        print(\"Fold {} log loss: {}\".format(i+1, scores[i]))\n",
    "    print(\"Std of log loss: {}\".format(np.std(scores)))\n",
    "    print(\"Total log loss: {}\".format(mean_log_loss(oof_targets, oof)))\n",
    "    \n",
    "    return oof, oof_targets, pred_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T09:26:29.533296Z",
     "iopub.status.busy": "2020-10-08T09:26:29.531900Z",
     "iopub.status.idle": "2020-10-08T09:39:34.903866Z",
     "shell.execute_reply": "2020-10-08T09:39:34.903203Z"
    },
    "papermill": {
     "duration": 785.447985,
     "end_time": "2020-10-08T09:39:34.904015",
     "exception": false,
     "start_time": "2020-10-08T09:26:29.456030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.020106 \t val_loss=0.018009 \t time=1.28s\n",
      "Best model: Epoch 2 \t loss=0.018181 \t val_loss=0.017518 \t time=1.32s\n",
      "Best model: Epoch 3 \t loss=0.017560 \t val_loss=0.017024 \t time=1.54s\n",
      "Best model: Epoch 4 \t loss=0.017084 \t val_loss=0.016856 \t time=1.31s\n",
      "Best model: Epoch 5 \t loss=0.016775 \t val_loss=0.016645 \t time=1.27s\n",
      "Best model: Epoch 6 \t loss=0.016546 \t val_loss=0.016532 \t time=1.32s\n",
      "Best model: Epoch 8 \t loss=0.016032 \t val_loss=0.016409 \t time=1.31s\n",
      "Best model: Epoch 9 \t loss=0.015850 \t val_loss=0.016344 \t time=1.40s\n",
      "Best model: Epoch 11 \t loss=0.015460 \t val_loss=0.016283 \t time=1.50s\n",
      "Best model: Epoch 13 \t loss=0.015115 \t val_loss=0.016230 \t time=1.31s\n",
      "Fold 1 log loss: 0.016260669693034798\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.020136 \t val_loss=0.017996 \t time=1.76s\n",
      "Best model: Epoch 2 \t loss=0.018119 \t val_loss=0.017399 \t time=1.51s\n",
      "Best model: Epoch 3 \t loss=0.017516 \t val_loss=0.017030 \t time=1.38s\n",
      "Best model: Epoch 4 \t loss=0.017132 \t val_loss=0.016830 \t time=1.31s\n",
      "Best model: Epoch 5 \t loss=0.016816 \t val_loss=0.016734 \t time=1.35s\n",
      "Best model: Epoch 6 \t loss=0.016600 \t val_loss=0.016554 \t time=1.38s\n",
      "Best model: Epoch 7 \t loss=0.016420 \t val_loss=0.016484 \t time=1.50s\n",
      "Best model: Epoch 9 \t loss=0.015924 \t val_loss=0.016393 \t time=1.26s\n",
      "Best model: Epoch 10 \t loss=0.015823 \t val_loss=0.016293 \t time=1.38s\n",
      "Best model: Epoch 11 \t loss=0.015676 \t val_loss=0.016247 \t time=1.30s\n",
      "Best model: Epoch 12 \t loss=0.015462 \t val_loss=0.016206 \t time=1.36s\n",
      "Best model: Epoch 15 \t loss=0.015001 \t val_loss=0.016161 \t time=1.49s\n",
      "Best model: Epoch 17 \t loss=0.014655 \t val_loss=0.016145 \t time=1.56s\n",
      "Best model: Epoch 19 \t loss=0.014413 \t val_loss=0.016140 \t time=1.46s\n",
      "Fold 2 log loss: 0.01616025921219231\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.020096 \t val_loss=0.018069 \t time=1.42s\n",
      "Best model: Epoch 2 \t loss=0.018201 \t val_loss=0.017251 \t time=1.33s\n",
      "Best model: Epoch 3 \t loss=0.017587 \t val_loss=0.016887 \t time=1.29s\n",
      "Best model: Epoch 4 \t loss=0.017245 \t val_loss=0.016749 \t time=1.27s\n",
      "Best model: Epoch 5 \t loss=0.016861 \t val_loss=0.016560 \t time=1.35s\n",
      "Best model: Epoch 6 \t loss=0.016612 \t val_loss=0.016501 \t time=1.53s\n",
      "Best model: Epoch 7 \t loss=0.016330 \t val_loss=0.016263 \t time=1.35s\n",
      "Best model: Epoch 8 \t loss=0.016145 \t val_loss=0.016219 \t time=1.36s\n",
      "Best model: Epoch 9 \t loss=0.015983 \t val_loss=0.016103 \t time=1.28s\n",
      "Best model: Epoch 11 \t loss=0.015582 \t val_loss=0.016052 \t time=1.29s\n",
      "Best model: Epoch 13 \t loss=0.015317 \t val_loss=0.016033 \t time=1.27s\n",
      "Best model: Epoch 15 \t loss=0.014921 \t val_loss=0.015962 \t time=1.43s\n",
      "Fold 3 log loss: 0.015962228226561553\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.020175 \t val_loss=0.017838 \t time=1.66s\n",
      "Best model: Epoch 2 \t loss=0.018160 \t val_loss=0.017151 \t time=1.46s\n",
      "Best model: Epoch 3 \t loss=0.017586 \t val_loss=0.016891 \t time=1.36s\n",
      "Best model: Epoch 4 \t loss=0.017253 \t val_loss=0.016783 \t time=1.40s\n",
      "Best model: Epoch 5 \t loss=0.016891 \t val_loss=0.016535 \t time=1.29s\n",
      "Best model: Epoch 6 \t loss=0.016629 \t val_loss=0.016395 \t time=1.23s\n",
      "Best model: Epoch 7 \t loss=0.016390 \t val_loss=0.016332 \t time=1.29s\n",
      "Best model: Epoch 8 \t loss=0.016117 \t val_loss=0.016193 \t time=1.47s\n",
      "Best model: Epoch 9 \t loss=0.015953 \t val_loss=0.016183 \t time=1.48s\n",
      "Best model: Epoch 10 \t loss=0.015777 \t val_loss=0.016137 \t time=1.38s\n",
      "Best model: Epoch 11 \t loss=0.015642 \t val_loss=0.016120 \t time=1.27s\n",
      "Best model: Epoch 12 \t loss=0.015490 \t val_loss=0.016108 \t time=1.57s\n",
      "Best model: Epoch 13 \t loss=0.015245 \t val_loss=0.016004 \t time=1.29s\n",
      "Best model: Epoch 15 \t loss=0.014942 \t val_loss=0.015965 \t time=1.27s\n",
      "Best model: Epoch 16 \t loss=0.014729 \t val_loss=0.015914 \t time=1.86s\n",
      "Fold 4 log loss: 0.01593464054742102\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.020115 \t val_loss=0.017950 \t time=1.41s\n",
      "Best model: Epoch 2 \t loss=0.018139 \t val_loss=0.017407 \t time=1.64s\n",
      "Best model: Epoch 3 \t loss=0.017607 \t val_loss=0.017114 \t time=1.36s\n",
      "Best model: Epoch 4 \t loss=0.017189 \t val_loss=0.016887 \t time=1.24s\n",
      "Best model: Epoch 5 \t loss=0.016873 \t val_loss=0.016737 \t time=1.32s\n",
      "Best model: Epoch 6 \t loss=0.016604 \t val_loss=0.016609 \t time=1.29s\n",
      "Best model: Epoch 7 \t loss=0.016414 \t val_loss=0.016516 \t time=1.26s\n",
      "Best model: Epoch 8 \t loss=0.016139 \t val_loss=0.016413 \t time=1.33s\n",
      "Best model: Epoch 9 \t loss=0.015955 \t val_loss=0.016388 \t time=1.31s\n",
      "Best model: Epoch 10 \t loss=0.015803 \t val_loss=0.016318 \t time=1.72s\n",
      "Best model: Epoch 12 \t loss=0.015436 \t val_loss=0.016206 \t time=1.50s\n",
      "Best model: Epoch 13 \t loss=0.015283 \t val_loss=0.016110 \t time=1.32s\n",
      "Fold 5 log loss: 0.016111140983922217\n",
      "Seed 0\n",
      "Fold 1 log loss: 0.016260669693034798\n",
      "Fold 2 log loss: 0.01616025921219231\n",
      "Fold 3 log loss: 0.015962228226561553\n",
      "Fold 4 log loss: 0.01593464054742102\n",
      "Fold 5 log loss: 0.016111140983922217\n",
      "Std of log loss: 0.00012238048196570148\n",
      "Total log loss: 0.01608578318438823\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.020083 \t val_loss=0.018061 \t time=1.38s\n",
      "Best model: Epoch 2 \t loss=0.018150 \t val_loss=0.017505 \t time=1.42s\n",
      "Best model: Epoch 3 \t loss=0.017554 \t val_loss=0.017135 \t time=1.35s\n",
      "Best model: Epoch 4 \t loss=0.017106 \t val_loss=0.016890 \t time=1.51s\n",
      "Best model: Epoch 5 \t loss=0.016805 \t val_loss=0.016737 \t time=1.32s\n",
      "Best model: Epoch 6 \t loss=0.016504 \t val_loss=0.016586 \t time=1.33s\n",
      "Best model: Epoch 7 \t loss=0.016314 \t val_loss=0.016501 \t time=1.26s\n",
      "Best model: Epoch 8 \t loss=0.016015 \t val_loss=0.016447 \t time=1.32s\n",
      "Best model: Epoch 9 \t loss=0.015835 \t val_loss=0.016369 \t time=1.43s\n",
      "Best model: Epoch 11 \t loss=0.015483 \t val_loss=0.016296 \t time=1.30s\n",
      "Best model: Epoch 13 \t loss=0.015137 \t val_loss=0.016245 \t time=1.49s\n",
      "Fold 1 log loss: 0.016270403276513325\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.020051 \t val_loss=0.017909 \t time=1.74s\n",
      "Best model: Epoch 2 \t loss=0.018106 \t val_loss=0.017298 \t time=1.25s\n",
      "Best model: Epoch 3 \t loss=0.017442 \t val_loss=0.017105 \t time=1.42s\n",
      "Best model: Epoch 4 \t loss=0.017151 \t val_loss=0.016776 \t time=1.25s\n",
      "Best model: Epoch 5 \t loss=0.016810 \t val_loss=0.016694 \t time=1.41s\n",
      "Best model: Epoch 6 \t loss=0.016538 \t val_loss=0.016560 \t time=1.43s\n",
      "Best model: Epoch 7 \t loss=0.016362 \t val_loss=0.016428 \t time=1.51s\n",
      "Best model: Epoch 8 \t loss=0.016159 \t val_loss=0.016409 \t time=1.29s\n",
      "Best model: Epoch 9 \t loss=0.015941 \t val_loss=0.016355 \t time=1.70s\n",
      "Best model: Epoch 10 \t loss=0.015775 \t val_loss=0.016267 \t time=1.40s\n",
      "Best model: Epoch 11 \t loss=0.015572 \t val_loss=0.016196 \t time=1.26s\n",
      "Best model: Epoch 13 \t loss=0.015222 \t val_loss=0.016127 \t time=1.49s\n",
      "Fold 2 log loss: 0.01614507294916547\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.020221 \t val_loss=0.017911 \t time=1.67s\n",
      "Best model: Epoch 2 \t loss=0.018199 \t val_loss=0.017293 \t time=1.82s\n",
      "Best model: Epoch 3 \t loss=0.017616 \t val_loss=0.016962 \t time=1.39s\n",
      "Best model: Epoch 4 \t loss=0.017220 \t val_loss=0.016713 \t time=1.37s\n",
      "Best model: Epoch 5 \t loss=0.016916 \t val_loss=0.016507 \t time=2.01s\n",
      "Best model: Epoch 6 \t loss=0.016593 \t val_loss=0.016431 \t time=1.41s\n",
      "Best model: Epoch 7 \t loss=0.016361 \t val_loss=0.016316 \t time=1.48s\n",
      "Best model: Epoch 8 \t loss=0.016198 \t val_loss=0.016209 \t time=1.34s\n",
      "Best model: Epoch 10 \t loss=0.015766 \t val_loss=0.016176 \t time=1.32s\n",
      "Best model: Epoch 11 \t loss=0.015588 \t val_loss=0.016088 \t time=1.33s\n",
      "Best model: Epoch 12 \t loss=0.015500 \t val_loss=0.016051 \t time=1.69s\n",
      "Best model: Epoch 13 \t loss=0.015292 \t val_loss=0.015999 \t time=1.28s\n",
      "Best model: Epoch 14 \t loss=0.015102 \t val_loss=0.015980 \t time=1.34s\n",
      "Best model: Epoch 16 \t loss=0.014788 \t val_loss=0.015979 \t time=1.26s\n",
      "Best model: Epoch 18 \t loss=0.014509 \t val_loss=0.015916 \t time=1.27s\n",
      "Best model: Epoch 19 \t loss=0.014435 \t val_loss=0.015897 \t time=1.28s\n",
      "Fold 3 log loss: 0.015896641109341813\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.020197 \t val_loss=0.017761 \t time=1.44s\n",
      "Best model: Epoch 2 \t loss=0.018158 \t val_loss=0.017306 \t time=1.29s\n",
      "Best model: Epoch 3 \t loss=0.017534 \t val_loss=0.016859 \t time=1.48s\n",
      "Best model: Epoch 4 \t loss=0.017237 \t val_loss=0.016730 \t time=1.35s\n",
      "Best model: Epoch 5 \t loss=0.016817 \t val_loss=0.016579 \t time=1.33s\n",
      "Best model: Epoch 6 \t loss=0.016583 \t val_loss=0.016367 \t time=1.27s\n",
      "Best model: Epoch 7 \t loss=0.016313 \t val_loss=0.016293 \t time=1.42s\n",
      "Best model: Epoch 8 \t loss=0.016161 \t val_loss=0.016247 \t time=1.34s\n",
      "Best model: Epoch 9 \t loss=0.015959 \t val_loss=0.016137 \t time=1.37s\n",
      "Best model: Epoch 11 \t loss=0.015621 \t val_loss=0.016085 \t time=1.48s\n",
      "Best model: Epoch 12 \t loss=0.015401 \t val_loss=0.016085 \t time=1.24s\n",
      "Best model: Epoch 14 \t loss=0.015063 \t val_loss=0.016023 \t time=1.29s\n",
      "Best model: Epoch 15 \t loss=0.014977 \t val_loss=0.015984 \t time=1.27s\n",
      "Fold 4 log loss: 0.016004387646468925\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.020227 \t val_loss=0.018020 \t time=1.42s\n",
      "Best model: Epoch 2 \t loss=0.018157 \t val_loss=0.017390 \t time=1.74s\n",
      "Best model: Epoch 3 \t loss=0.017574 \t val_loss=0.017043 \t time=1.30s\n",
      "Best model: Epoch 4 \t loss=0.017149 \t val_loss=0.016885 \t time=1.38s\n",
      "Best model: Epoch 5 \t loss=0.016880 \t val_loss=0.016728 \t time=1.52s\n",
      "Best model: Epoch 6 \t loss=0.016552 \t val_loss=0.016610 \t time=1.68s\n",
      "Best model: Epoch 8 \t loss=0.016105 \t val_loss=0.016505 \t time=1.42s\n",
      "Best model: Epoch 9 \t loss=0.015977 \t val_loss=0.016368 \t time=1.41s\n",
      "Best model: Epoch 10 \t loss=0.015722 \t val_loss=0.016344 \t time=1.46s\n",
      "Best model: Epoch 11 \t loss=0.015503 \t val_loss=0.016332 \t time=1.48s\n",
      "Best model: Epoch 13 \t loss=0.015250 \t val_loss=0.016226 \t time=1.53s\n",
      "Fold 5 log loss: 0.016228136512462507\n",
      "Seed 1\n",
      "Fold 1 log loss: 0.016270403276513325\n",
      "Fold 2 log loss: 0.01614507294916547\n",
      "Fold 3 log loss: 0.015896641109341813\n",
      "Fold 4 log loss: 0.016004387646468925\n",
      "Fold 5 log loss: 0.016228136512462507\n",
      "Std of log loss: 0.00013970383042710723\n",
      "Total log loss: 0.016108921220566237\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.020112 \t val_loss=0.017971 \t time=1.70s\n",
      "Best model: Epoch 2 \t loss=0.018154 \t val_loss=0.017344 \t time=1.51s\n",
      "Best model: Epoch 3 \t loss=0.017561 \t val_loss=0.017074 \t time=1.28s\n",
      "Best model: Epoch 4 \t loss=0.017055 \t val_loss=0.016886 \t time=1.27s\n",
      "Best model: Epoch 5 \t loss=0.016830 \t val_loss=0.016648 \t time=1.35s\n",
      "Best model: Epoch 6 \t loss=0.016557 \t val_loss=0.016518 \t time=1.53s\n",
      "Best model: Epoch 8 \t loss=0.016034 \t val_loss=0.016433 \t time=1.66s\n",
      "Best model: Epoch 9 \t loss=0.015903 \t val_loss=0.016430 \t time=1.63s\n",
      "Best model: Epoch 10 \t loss=0.015689 \t val_loss=0.016368 \t time=1.27s\n",
      "Best model: Epoch 11 \t loss=0.015468 \t val_loss=0.016323 \t time=1.27s\n",
      "Best model: Epoch 12 \t loss=0.015327 \t val_loss=0.016288 \t time=1.34s\n",
      "Best model: Epoch 13 \t loss=0.015153 \t val_loss=0.016275 \t time=1.35s\n",
      "Best model: Epoch 15 \t loss=0.014787 \t val_loss=0.016194 \t time=1.30s\n",
      "Best model: Epoch 16 \t loss=0.014634 \t val_loss=0.016171 \t time=1.53s\n",
      "Fold 1 log loss: 0.01619772103557217\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.020013 \t val_loss=0.017885 \t time=1.47s\n",
      "Best model: Epoch 2 \t loss=0.018065 \t val_loss=0.017271 \t time=1.93s\n",
      "Best model: Epoch 3 \t loss=0.017514 \t val_loss=0.017105 \t time=1.36s\n",
      "Best model: Epoch 4 \t loss=0.017121 \t val_loss=0.016820 \t time=1.33s\n",
      "Best model: Epoch 5 \t loss=0.016862 \t val_loss=0.016638 \t time=1.40s\n",
      "Best model: Epoch 6 \t loss=0.016635 \t val_loss=0.016547 \t time=1.27s\n",
      "Best model: Epoch 7 \t loss=0.016326 \t val_loss=0.016517 \t time=1.29s\n",
      "Best model: Epoch 8 \t loss=0.016132 \t val_loss=0.016373 \t time=1.33s\n",
      "Best model: Epoch 9 \t loss=0.015965 \t val_loss=0.016331 \t time=1.36s\n",
      "Best model: Epoch 10 \t loss=0.015762 \t val_loss=0.016315 \t time=1.54s\n",
      "Best model: Epoch 11 \t loss=0.015571 \t val_loss=0.016236 \t time=1.32s\n",
      "Best model: Epoch 12 \t loss=0.015386 \t val_loss=0.016185 \t time=1.37s\n",
      "Best model: Epoch 14 \t loss=0.015140 \t val_loss=0.016144 \t time=1.25s\n",
      "Best model: Epoch 16 \t loss=0.014776 \t val_loss=0.016125 \t time=1.26s\n",
      "Best model: Epoch 17 \t loss=0.014655 \t val_loss=0.016073 \t time=1.55s\n",
      "Best model: Epoch 18 \t loss=0.014451 \t val_loss=0.016063 \t time=1.31s\n",
      "Fold 2 log loss: 0.016080735732821833\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.020242 \t val_loss=0.017848 \t time=1.45s\n",
      "Best model: Epoch 2 \t loss=0.018166 \t val_loss=0.017269 \t time=1.51s\n",
      "Best model: Epoch 3 \t loss=0.017570 \t val_loss=0.016949 \t time=1.60s\n",
      "Best model: Epoch 4 \t loss=0.017183 \t val_loss=0.016730 \t time=1.51s\n",
      "Best model: Epoch 5 \t loss=0.016838 \t val_loss=0.016467 \t time=1.39s\n",
      "Best model: Epoch 6 \t loss=0.016620 \t val_loss=0.016262 \t time=1.49s\n",
      "Best model: Epoch 8 \t loss=0.016202 \t val_loss=0.016237 \t time=1.31s\n",
      "Best model: Epoch 9 \t loss=0.016030 \t val_loss=0.016187 \t time=1.47s\n",
      "Best model: Epoch 10 \t loss=0.015805 \t val_loss=0.016058 \t time=1.24s\n",
      "Best model: Epoch 12 \t loss=0.015460 \t val_loss=0.016025 \t time=1.33s\n",
      "Best model: Epoch 13 \t loss=0.015200 \t val_loss=0.015966 \t time=1.33s\n",
      "Best model: Epoch 15 \t loss=0.014961 \t val_loss=0.015965 \t time=1.33s\n",
      "Fold 3 log loss: 0.01596405924335904\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.020133 \t val_loss=0.017661 \t time=1.37s\n",
      "Best model: Epoch 2 \t loss=0.018121 \t val_loss=0.017277 \t time=1.50s\n",
      "Best model: Epoch 3 \t loss=0.017538 \t val_loss=0.016918 \t time=1.27s\n",
      "Best model: Epoch 4 \t loss=0.017190 \t val_loss=0.016681 \t time=1.65s\n",
      "Best model: Epoch 5 \t loss=0.016796 \t val_loss=0.016488 \t time=1.30s\n",
      "Best model: Epoch 6 \t loss=0.016512 \t val_loss=0.016409 \t time=1.27s\n",
      "Best model: Epoch 7 \t loss=0.016331 \t val_loss=0.016204 \t time=1.58s\n",
      "Best model: Epoch 8 \t loss=0.016149 \t val_loss=0.016191 \t time=1.36s\n",
      "Best model: Epoch 9 \t loss=0.015924 \t val_loss=0.016161 \t time=1.44s\n",
      "Best model: Epoch 10 \t loss=0.015757 \t val_loss=0.016064 \t time=1.33s\n",
      "Best model: Epoch 11 \t loss=0.015570 \t val_loss=0.016047 \t time=1.48s\n",
      "Fold 4 log loss: 0.016063927852762352\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.020141 \t val_loss=0.017937 \t time=1.31s\n",
      "Best model: Epoch 2 \t loss=0.018109 \t val_loss=0.017477 \t time=1.35s\n",
      "Best model: Epoch 3 \t loss=0.017581 \t val_loss=0.017110 \t time=1.53s\n",
      "Best model: Epoch 4 \t loss=0.017232 \t val_loss=0.016970 \t time=1.41s\n",
      "Best model: Epoch 5 \t loss=0.016918 \t val_loss=0.016787 \t time=1.38s\n",
      "Best model: Epoch 6 \t loss=0.016600 \t val_loss=0.016628 \t time=1.35s\n",
      "Best model: Epoch 7 \t loss=0.016345 \t val_loss=0.016517 \t time=1.62s\n",
      "Best model: Epoch 8 \t loss=0.016152 \t val_loss=0.016436 \t time=1.35s\n",
      "Best model: Epoch 10 \t loss=0.015766 \t val_loss=0.016307 \t time=1.52s\n",
      "Best model: Epoch 11 \t loss=0.015633 \t val_loss=0.016270 \t time=1.29s\n",
      "Best model: Epoch 13 \t loss=0.015281 \t val_loss=0.016209 \t time=1.31s\n",
      "Best model: Epoch 14 \t loss=0.015080 \t val_loss=0.016196 \t time=1.27s\n",
      "Best model: Epoch 15 \t loss=0.014995 \t val_loss=0.016124 \t time=1.41s\n",
      "Fold 5 log loss: 0.01612389911382417\n",
      "Seed 2\n",
      "Fold 1 log loss: 0.01619772103557217\n",
      "Fold 2 log loss: 0.016080735732821833\n",
      "Fold 3 log loss: 0.01596405924335904\n",
      "Fold 4 log loss: 0.016063927852762352\n",
      "Fold 5 log loss: 0.01612389911382417\n",
      "Std of log loss: 7.655370587230906e-05\n",
      "Total log loss: 0.016086067115002007\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.020083 \t val_loss=0.017976 \t time=1.34s\n",
      "Best model: Epoch 2 \t loss=0.018142 \t val_loss=0.017269 \t time=1.27s\n",
      "Best model: Epoch 3 \t loss=0.017512 \t val_loss=0.017030 \t time=1.72s\n",
      "Best model: Epoch 4 \t loss=0.017158 \t val_loss=0.016861 \t time=1.33s\n",
      "Best model: Epoch 5 \t loss=0.016766 \t val_loss=0.016722 \t time=1.34s\n",
      "Best model: Epoch 6 \t loss=0.016570 \t val_loss=0.016632 \t time=1.44s\n",
      "Best model: Epoch 7 \t loss=0.016327 \t val_loss=0.016545 \t time=1.49s\n",
      "Best model: Epoch 8 \t loss=0.016135 \t val_loss=0.016429 \t time=1.41s\n",
      "Best model: Epoch 9 \t loss=0.015958 \t val_loss=0.016389 \t time=1.31s\n",
      "Best model: Epoch 10 \t loss=0.015781 \t val_loss=0.016387 \t time=1.67s\n",
      "Best model: Epoch 11 \t loss=0.015526 \t val_loss=0.016341 \t time=1.50s\n",
      "Best model: Epoch 12 \t loss=0.015368 \t val_loss=0.016295 \t time=1.27s\n",
      "Fold 1 log loss: 0.016319679493670906\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.020106 \t val_loss=0.017874 \t time=1.62s\n",
      "Best model: Epoch 2 \t loss=0.018048 \t val_loss=0.017344 \t time=1.58s\n",
      "Best model: Epoch 3 \t loss=0.017502 \t val_loss=0.017071 \t time=1.58s\n",
      "Best model: Epoch 4 \t loss=0.017147 \t val_loss=0.016782 \t time=1.60s\n",
      "Best model: Epoch 5 \t loss=0.016874 \t val_loss=0.016546 \t time=1.65s\n",
      "Best model: Epoch 7 \t loss=0.016350 \t val_loss=0.016414 \t time=1.85s\n",
      "Best model: Epoch 8 \t loss=0.016189 \t val_loss=0.016334 \t time=1.62s\n",
      "Best model: Epoch 9 \t loss=0.015932 \t val_loss=0.016276 \t time=1.81s\n",
      "Best model: Epoch 11 \t loss=0.015638 \t val_loss=0.016274 \t time=1.60s\n",
      "Best model: Epoch 12 \t loss=0.015470 \t val_loss=0.016166 \t time=1.53s\n",
      "Best model: Epoch 14 \t loss=0.015106 \t val_loss=0.016100 \t time=1.41s\n",
      "Best model: Epoch 16 \t loss=0.014869 \t val_loss=0.016078 \t time=1.47s\n",
      "Best model: Epoch 19 \t loss=0.014392 \t val_loss=0.016066 \t time=2.04s\n",
      "Best model: Epoch 20 \t loss=0.014282 \t val_loss=0.016043 \t time=1.90s\n",
      "Fold 2 log loss: 0.01606249608663534\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.020163 \t val_loss=0.017803 \t time=1.89s\n",
      "Best model: Epoch 2 \t loss=0.018162 \t val_loss=0.017135 \t time=1.78s\n",
      "Best model: Epoch 3 \t loss=0.017597 \t val_loss=0.016947 \t time=1.48s\n",
      "Best model: Epoch 4 \t loss=0.017220 \t val_loss=0.016721 \t time=1.46s\n",
      "Best model: Epoch 5 \t loss=0.016799 \t val_loss=0.016436 \t time=1.60s\n",
      "Best model: Epoch 6 \t loss=0.016612 \t val_loss=0.016414 \t time=1.42s\n",
      "Best model: Epoch 7 \t loss=0.016357 \t val_loss=0.016343 \t time=1.72s\n",
      "Best model: Epoch 8 \t loss=0.016099 \t val_loss=0.016214 \t time=1.57s\n",
      "Best model: Epoch 9 \t loss=0.015945 \t val_loss=0.016164 \t time=1.46s\n",
      "Best model: Epoch 10 \t loss=0.015814 \t val_loss=0.016106 \t time=1.49s\n",
      "Best model: Epoch 11 \t loss=0.015546 \t val_loss=0.016103 \t time=1.51s\n",
      "Best model: Epoch 12 \t loss=0.015406 \t val_loss=0.015990 \t time=1.44s\n",
      "Fold 3 log loss: 0.015987726737304895\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.020182 \t val_loss=0.017699 \t time=1.55s\n",
      "Best model: Epoch 2 \t loss=0.018056 \t val_loss=0.017178 \t time=1.50s\n",
      "Best model: Epoch 3 \t loss=0.017522 \t val_loss=0.016894 \t time=1.66s\n",
      "Best model: Epoch 4 \t loss=0.017143 \t val_loss=0.016669 \t time=1.84s\n",
      "Best model: Epoch 5 \t loss=0.016879 \t val_loss=0.016498 \t time=1.63s\n",
      "Best model: Epoch 6 \t loss=0.016547 \t val_loss=0.016391 \t time=1.72s\n",
      "Best model: Epoch 7 \t loss=0.016421 \t val_loss=0.016282 \t time=1.54s\n",
      "Best model: Epoch 8 \t loss=0.016136 \t val_loss=0.016263 \t time=1.58s\n",
      "Best model: Epoch 9 \t loss=0.015904 \t val_loss=0.016187 \t time=1.53s\n",
      "Best model: Epoch 10 \t loss=0.015754 \t val_loss=0.016093 \t time=1.80s\n",
      "Best model: Epoch 11 \t loss=0.015559 \t val_loss=0.016090 \t time=1.96s\n",
      "Best model: Epoch 12 \t loss=0.015447 \t val_loss=0.016071 \t time=1.72s\n",
      "Best model: Epoch 13 \t loss=0.015260 \t val_loss=0.016030 \t time=1.79s\n",
      "Best model: Epoch 14 \t loss=0.015043 \t val_loss=0.015982 \t time=1.45s\n",
      "Fold 4 log loss: 0.01600129639516147\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.020177 \t val_loss=0.017975 \t time=1.46s\n",
      "Best model: Epoch 2 \t loss=0.018115 \t val_loss=0.017412 \t time=1.45s\n",
      "Best model: Epoch 3 \t loss=0.017563 \t val_loss=0.017100 \t time=1.87s\n",
      "Best model: Epoch 4 \t loss=0.017128 \t val_loss=0.016941 \t time=1.74s\n",
      "Best model: Epoch 5 \t loss=0.016820 \t val_loss=0.016750 \t time=1.49s\n",
      "Best model: Epoch 6 \t loss=0.016543 \t val_loss=0.016650 \t time=1.43s\n",
      "Best model: Epoch 7 \t loss=0.016353 \t val_loss=0.016499 \t time=1.56s\n",
      "Best model: Epoch 8 \t loss=0.016113 \t val_loss=0.016451 \t time=1.49s\n",
      "Best model: Epoch 9 \t loss=0.015966 \t val_loss=0.016415 \t time=1.65s\n",
      "Best model: Epoch 10 \t loss=0.015736 \t val_loss=0.016320 \t time=1.95s\n",
      "Best model: Epoch 12 \t loss=0.015404 \t val_loss=0.016280 \t time=1.63s\n",
      "Best model: Epoch 13 \t loss=0.015176 \t val_loss=0.016211 \t time=1.72s\n",
      "Best model: Epoch 15 \t loss=0.014918 \t val_loss=0.016189 \t time=1.47s\n",
      "Best model: Epoch 16 \t loss=0.014672 \t val_loss=0.016168 \t time=1.83s\n",
      "Fold 5 log loss: 0.016170618416244564\n",
      "Seed 3\n",
      "Fold 1 log loss: 0.016319679493670906\n",
      "Fold 2 log loss: 0.01606249608663534\n",
      "Fold 3 log loss: 0.015987726737304895\n",
      "Fold 4 log loss: 0.01600129639516147\n",
      "Fold 5 log loss: 0.016170618416244564\n",
      "Std of log loss: 0.00012381481077685085\n",
      "Total log loss: 0.016108362679145363\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.020185 \t val_loss=0.018080 \t time=1.54s\n",
      "Best model: Epoch 2 \t loss=0.018161 \t val_loss=0.017412 \t time=1.58s\n",
      "Best model: Epoch 3 \t loss=0.017548 \t val_loss=0.017150 \t time=1.45s\n",
      "Best model: Epoch 4 \t loss=0.017109 \t val_loss=0.016992 \t time=1.62s\n",
      "Best model: Epoch 5 \t loss=0.016756 \t val_loss=0.016667 \t time=1.67s\n",
      "Best model: Epoch 6 \t loss=0.016528 \t val_loss=0.016635 \t time=1.73s\n",
      "Best model: Epoch 7 \t loss=0.016320 \t val_loss=0.016546 \t time=1.47s\n",
      "Best model: Epoch 8 \t loss=0.016058 \t val_loss=0.016501 \t time=1.80s\n",
      "Best model: Epoch 9 \t loss=0.015819 \t val_loss=0.016383 \t time=1.57s\n",
      "Best model: Epoch 11 \t loss=0.015482 \t val_loss=0.016367 \t time=1.46s\n",
      "Best model: Epoch 12 \t loss=0.015279 \t val_loss=0.016263 \t time=1.45s\n",
      "Best model: Epoch 14 \t loss=0.015041 \t val_loss=0.016234 \t time=1.37s\n",
      "Best model: Epoch 15 \t loss=0.014778 \t val_loss=0.016201 \t time=1.73s\n",
      "Best model: Epoch 17 \t loss=0.014487 \t val_loss=0.016171 \t time=1.52s\n",
      "Fold 1 log loss: 0.016199400665800244\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.020061 \t val_loss=0.017877 \t time=1.48s\n",
      "Best model: Epoch 2 \t loss=0.018136 \t val_loss=0.017299 \t time=1.54s\n",
      "Best model: Epoch 3 \t loss=0.017500 \t val_loss=0.017032 \t time=1.52s\n",
      "Best model: Epoch 4 \t loss=0.017106 \t val_loss=0.016812 \t time=1.77s\n",
      "Best model: Epoch 5 \t loss=0.016859 \t val_loss=0.016628 \t time=1.54s\n",
      "Best model: Epoch 6 \t loss=0.016585 \t val_loss=0.016573 \t time=1.45s\n",
      "Best model: Epoch 7 \t loss=0.016376 \t val_loss=0.016405 \t time=1.51s\n",
      "Best model: Epoch 8 \t loss=0.016138 \t val_loss=0.016339 \t time=1.52s\n",
      "Best model: Epoch 9 \t loss=0.015917 \t val_loss=0.016308 \t time=1.47s\n",
      "Best model: Epoch 10 \t loss=0.015742 \t val_loss=0.016269 \t time=1.53s\n",
      "Best model: Epoch 12 \t loss=0.015398 \t val_loss=0.016171 \t time=1.50s\n",
      "Fold 2 log loss: 0.01618887648233716\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.020198 \t val_loss=0.017845 \t time=2.06s\n",
      "Best model: Epoch 2 \t loss=0.018197 \t val_loss=0.017218 \t time=2.04s\n",
      "Best model: Epoch 3 \t loss=0.017579 \t val_loss=0.016866 \t time=1.52s\n",
      "Best model: Epoch 4 \t loss=0.017164 \t val_loss=0.016665 \t time=1.59s\n",
      "Best model: Epoch 5 \t loss=0.016879 \t val_loss=0.016473 \t time=1.57s\n",
      "Best model: Epoch 6 \t loss=0.016577 \t val_loss=0.016421 \t time=1.76s\n",
      "Best model: Epoch 7 \t loss=0.016372 \t val_loss=0.016298 \t time=1.59s\n",
      "Best model: Epoch 8 \t loss=0.016142 \t val_loss=0.016226 \t time=1.45s\n",
      "Best model: Epoch 9 \t loss=0.016022 \t val_loss=0.016162 \t time=1.50s\n",
      "Best model: Epoch 10 \t loss=0.015810 \t val_loss=0.016058 \t time=1.71s\n",
      "Best model: Epoch 11 \t loss=0.015557 \t val_loss=0.016042 \t time=1.49s\n",
      "Fold 3 log loss: 0.016044501975416316\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.020140 \t val_loss=0.017861 \t time=1.47s\n",
      "Best model: Epoch 2 \t loss=0.018148 \t val_loss=0.017396 \t time=1.52s\n",
      "Best model: Epoch 3 \t loss=0.017564 \t val_loss=0.016835 \t time=1.91s\n",
      "Best model: Epoch 4 \t loss=0.017186 \t val_loss=0.016818 \t time=1.60s\n",
      "Best model: Epoch 5 \t loss=0.016908 \t val_loss=0.016518 \t time=1.46s\n",
      "Best model: Epoch 6 \t loss=0.016551 \t val_loss=0.016381 \t time=1.68s\n",
      "Best model: Epoch 7 \t loss=0.016290 \t val_loss=0.016303 \t time=1.51s\n",
      "Best model: Epoch 9 \t loss=0.015943 \t val_loss=0.016232 \t time=1.70s\n",
      "Best model: Epoch 10 \t loss=0.015750 \t val_loss=0.016060 \t time=1.66s\n",
      "Best model: Epoch 12 \t loss=0.015421 \t val_loss=0.016043 \t time=1.48s\n",
      "Fold 4 log loss: 0.016061116148931565\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.020167 \t val_loss=0.018034 \t time=1.66s\n",
      "Best model: Epoch 2 \t loss=0.018168 \t val_loss=0.017452 \t time=1.68s\n",
      "Best model: Epoch 3 \t loss=0.017556 \t val_loss=0.017190 \t time=1.94s\n",
      "Best model: Epoch 4 \t loss=0.017182 \t val_loss=0.016886 \t time=1.75s\n",
      "Best model: Epoch 5 \t loss=0.016887 \t val_loss=0.016745 \t time=1.96s\n",
      "Best model: Epoch 6 \t loss=0.016595 \t val_loss=0.016625 \t time=1.75s\n",
      "Best model: Epoch 7 \t loss=0.016394 \t val_loss=0.016579 \t time=1.54s\n",
      "Best model: Epoch 8 \t loss=0.016171 \t val_loss=0.016496 \t time=1.52s\n",
      "Best model: Epoch 9 \t loss=0.015945 \t val_loss=0.016408 \t time=1.89s\n",
      "Best model: Epoch 10 \t loss=0.015780 \t val_loss=0.016321 \t time=1.49s\n",
      "Best model: Epoch 11 \t loss=0.015595 \t val_loss=0.016271 \t time=1.67s\n",
      "Best model: Epoch 13 \t loss=0.015243 \t val_loss=0.016255 \t time=1.46s\n",
      "Best model: Epoch 15 \t loss=0.014961 \t val_loss=0.016207 \t time=1.45s\n",
      "Best model: Epoch 16 \t loss=0.014804 \t val_loss=0.016197 \t time=1.44s\n",
      "Best model: Epoch 17 \t loss=0.014676 \t val_loss=0.016155 \t time=1.52s\n",
      "Fold 5 log loss: 0.01615646109429388\n",
      "Seed 4\n",
      "Fold 1 log loss: 0.016199400665800244\n",
      "Fold 2 log loss: 0.01618887648233716\n",
      "Fold 3 log loss: 0.016044501975416316\n",
      "Fold 4 log loss: 0.016061116148931565\n",
      "Fold 5 log loss: 0.01615646109429388\n",
      "Std of log loss: 6.486594459871675e-05\n",
      "Total log loss: 0.016130067391679603\n",
      "Total log loss in targets: 0.01585596689111838\n"
     ]
    }
   ],
   "source": [
    "fn_targets = targets.drop(\"sig_id\", axis=1).copy().to_numpy()\n",
    "target_oof = np.zeros([len(fn_train),fn_targets.shape[1]])\n",
    "target_pred = np.zeros([len(fn_test),fn_targets.shape[1]])\n",
    "\n",
    "seeds = [0,1,2,3,4] \n",
    "for seed_ in seeds:\n",
    "    oof, oof_targets, pytorch_pred = modelling_torch(fn_train, fn_targets, fn_test, seed_, fn_train.shape[1], files)\n",
    "    target_oof += oof / len(seeds)\n",
    "    target_pred += pytorch_pred / len(seeds)\n",
    "print(\"Total log loss in targets: {}\".format(mean_log_loss(oof_targets, target_oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T09:39:35.349581Z",
     "iopub.status.busy": "2020-10-08T09:39:35.348436Z",
     "iopub.status.idle": "2020-10-08T09:39:38.429222Z",
     "shell.execute_reply": "2020-10-08T09:39:38.428348Z"
    },
    "papermill": {
     "duration": 3.307477,
     "end_time": "2020-10-08T09:39:38.429358",
     "exception": false,
     "start_time": "2020-10-08T09:39:35.121881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub[target_feats] = target_pred\n",
    "sub.loc[noncons_test_index,target_feats] = 0\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.217182,
     "end_time": "2020-10-08T09:39:38.864516",
     "exception": false,
     "start_time": "2020-10-08T09:39:38.647334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 969.741339,
   "end_time": "2020-10-08T09:39:39.591826",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-08T09:23:29.850487",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
