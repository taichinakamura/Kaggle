{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01383,
     "end_time": "2020-10-16T04:15:39.314762",
     "exception": false,
     "start_time": "2020-10-16T04:15:39.300932",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- remove outlier patient\n",
    "- implement transfer learning correctly in cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-16T04:15:39.348102Z",
     "iopub.status.busy": "2020-10-16T04:15:39.347305Z",
     "iopub.status.idle": "2020-10-16T04:15:47.618982Z",
     "shell.execute_reply": "2020-10-16T04:15:47.617843Z"
    },
    "papermill": {
     "duration": 8.291814,
     "end_time": "2020-10-16T04:15:47.619165",
     "exception": false,
     "start_time": "2020-10-16T04:15:39.327351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss, mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "sys.path.append('../input/multilabelstraifier/')\n",
    "sys.path.append('../input/lookahead/')\n",
    "from ml_stratifiers import MultilabelStratifiedKFold\n",
    "from lookahead import Lookahead\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-16T04:15:47.664436Z",
     "iopub.status.busy": "2020-10-16T04:15:47.663490Z",
     "iopub.status.idle": "2020-10-16T04:15:54.951258Z",
     "shell.execute_reply": "2020-10-16T04:15:54.950715Z"
    },
    "papermill": {
     "duration": 7.313817,
     "end_time": "2020-10-16T04:15:54.951388",
     "exception": false,
     "start_time": "2020-10-16T04:15:47.637571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/lish-moa/'\n",
    "train = pd.read_csv(DATA_DIR + 'train_features.csv')\n",
    "targets = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "non_targets = pd.read_csv(DATA_DIR + 'train_targets_nonscored.csv')\n",
    "test = pd.read_csv(DATA_DIR + 'test_features.csv')\n",
    "sub = pd.read_csv(DATA_DIR + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-16T04:15:54.993537Z",
     "iopub.status.busy": "2020-10-16T04:15:54.992806Z",
     "iopub.status.idle": "2020-10-16T04:15:54.997040Z",
     "shell.execute_reply": "2020-10-16T04:15:54.996215Z"
    },
    "papermill": {
     "duration": 0.029119,
     "end_time": "2020-10-16T04:15:54.997197",
     "exception": false,
     "start_time": "2020-10-16T04:15:54.968078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_feats = [ i for i in targets.columns if i != \"sig_id\"]\n",
    "g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "c_feats = [i for i in train.columns if \"c-\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-16T04:15:55.032228Z",
     "iopub.status.busy": "2020-10-16T04:15:55.031208Z",
     "iopub.status.idle": "2020-10-16T04:15:55.033368Z",
     "shell.execute_reply": "2020-10-16T04:15:55.034127Z"
    },
    "papermill": {
     "duration": 0.021034,
     "end_time": "2020-10-16T04:15:55.034336",
     "exception": false,
     "start_time": "2020-10-16T04:15:55.013302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to remove outlier paienr\n",
    "original_remove_index = [16674] # remove_index = [15361]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-16T04:15:55.096471Z",
     "iopub.status.busy": "2020-10-16T04:15:55.081628Z",
     "iopub.status.idle": "2020-10-16T04:15:55.124345Z",
     "shell.execute_reply": "2020-10-16T04:15:55.123745Z"
    },
    "papermill": {
     "duration": 0.0701,
     "end_time": "2020-10-16T04:15:55.124533",
     "exception": false,
     "start_time": "2020-10-16T04:15:55.054433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16674</th>\n",
       "      <td>id_b31edc707</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>1.902</td>\n",
       "      <td>3.796</td>\n",
       "      <td>3.323</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.016</td>\n",
       "      <td>-2.356</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-9.28</td>\n",
       "      <td>-9.719</td>\n",
       "      <td>-6.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id cp_type  cp_time cp_dose    g-0    g-1    g-2   g-3  \\\n",
       "16674  id_b31edc707  trt_cp       72      D2  1.902  3.796  3.323  10.0   \n",
       "\n",
       "         g-4    g-5  ...  c-90  c-91  c-92  c-93  c-94  c-95  c-96  c-97  \\\n",
       "16674  2.016 -2.356  ... -10.0 -10.0 -10.0 -10.0 -10.0 -10.0 -10.0 -9.28   \n",
       "\n",
       "        c-98   c-99  \n",
       "16674 -9.719 -6.003  \n",
       "\n",
       "[1 rows x 876 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[original_remove_index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-16T04:15:55.189005Z",
     "iopub.status.busy": "2020-10-16T04:15:55.163827Z",
     "iopub.status.idle": "2020-10-16T04:15:55.334777Z",
     "shell.execute_reply": "2020-10-16T04:15:55.335236Z"
    },
    "papermill": {
     "duration": 0.194343,
     "end_time": "2020-10-16T04:15:55.335421",
     "exception": false,
     "start_time": "2020-10-16T04:15:55.141078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "noncons_train_index = train[train.cp_type==\"ctl_vehicle\"].index\n",
    "noncons_train_index = list(noncons_train_index) + original_remove_index\n",
    "cons_train_index = train[~train.index.isin(noncons_train_index)].index\n",
    "noncons_test_index = test[test.cp_type==\"ctl_vehicle\"].index\n",
    "cons_test_index = test[test.cp_type!=\"ctl_vehicle\"].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013445,
     "end_time": "2020-10-16T04:15:55.362640",
     "exception": false,
     "start_time": "2020-10-16T04:15:55.349195",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-16T04:15:55.400275Z",
     "iopub.status.busy": "2020-10-16T04:15:55.399633Z",
     "iopub.status.idle": "2020-10-16T04:15:55.922792Z",
     "shell.execute_reply": "2020-10-16T04:15:55.922184Z"
    },
    "papermill": {
     "duration": 0.546732,
     "end_time": "2020-10-16T04:15:55.922945",
     "exception": false,
     "start_time": "2020-10-16T04:15:55.376213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train[train.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "targets = targets[targets.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "non_targets = non_targets[non_targets.index.isin(cons_train_index)].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-16T04:15:55.998779Z",
     "iopub.status.busy": "2020-10-16T04:15:55.997706Z",
     "iopub.status.idle": "2020-10-16T04:15:56.069548Z",
     "shell.execute_reply": "2020-10-16T04:15:56.069033Z"
    },
    "papermill": {
     "duration": 0.132747,
     "end_time": "2020-10-16T04:15:56.069665",
     "exception": false,
     "start_time": "2020-10-16T04:15:55.936918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first drop 71\n",
      "shape after 1st drop: (21947, 332)\n",
      "331\n"
     ]
    }
   ],
   "source": [
    "non_target_feats = [i for i in non_targets.columns if i != \"sig_id\"]\n",
    "nontarget_dists = pd.DataFrame(np.sum(non_targets[non_target_feats])).reset_index(drop=False)\n",
    "nontarget_dists.columns = [\"target\", \"number\"]\n",
    "nontarget_dists = nontarget_dists.sort_values(\"number\", ascending=False).reset_index(drop=True)\n",
    "drop_list1 = list(nontarget_dists[nontarget_dists.number==0][\"target\"].values)\n",
    "print(\"first drop\", len(drop_list1))\n",
    "non_targets.drop(drop_list1, axis=1, inplace=True)\n",
    "print(\"shape after 1st drop:\", non_targets.shape)\n",
    "non_target_feats = [i for i in non_targets.columns if i != \"sig_id\"]\n",
    "print(len(non_target_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-16T04:15:56.104735Z",
     "iopub.status.busy": "2020-10-16T04:15:56.104051Z",
     "iopub.status.idle": "2020-10-16T04:15:56.161963Z",
     "shell.execute_reply": "2020-10-16T04:15:56.161302Z"
    },
    "papermill": {
     "duration": 0.078158,
     "end_time": "2020-10-16T04:15:56.162080",
     "exception": false,
     "start_time": "2020-10-16T04:15:56.083922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_targets = pd.concat([targets, non_targets], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013703,
     "end_time": "2020-10-16T04:15:56.190043",
     "exception": false,
     "start_time": "2020-10-16T04:15:56.176340",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-16T04:15:56.222514Z",
     "iopub.status.busy": "2020-10-16T04:15:56.221869Z",
     "iopub.status.idle": "2020-10-16T04:15:56.224574Z",
     "shell.execute_reply": "2020-10-16T04:15:56.223981Z"
    },
    "papermill": {
     "duration": 0.020539,
     "end_time": "2020-10-16T04:15:56.224680",
     "exception": false,
     "start_time": "2020-10-16T04:15:56.204141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#num = 10\n",
    "#pca_c_cols = [\"pca-c\"+str(i+1) for i in range(num)]\n",
    "#pca = PCA(n_components=num)\n",
    "#tmp_train = pca.fit_transform(train[c_feats])\n",
    "#tmp_test = pca.transform(test[c_feats])\n",
    "#tmp_train = pd.DataFrame(tmp_train, columns=pca_c_cols)\n",
    "#tmp_test = pd.DataFrame(tmp_test, columns=pca_c_cols)\n",
    "\n",
    "#train = pd.concat([train, tmp_train],axis=1)\n",
    "#test = pd.concat([test, tmp_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-16T04:15:56.260656Z",
     "iopub.status.busy": "2020-10-16T04:15:56.259964Z",
     "iopub.status.idle": "2020-10-16T04:15:56.518804Z",
     "shell.execute_reply": "2020-10-16T04:15:56.519247Z"
    },
    "papermill": {
     "duration": 0.280326,
     "end_time": "2020-10-16T04:15:56.519415",
     "exception": false,
     "start_time": "2020-10-16T04:15:56.239089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21947, 872) (3982, 872)\n"
     ]
    }
   ],
   "source": [
    "def fe(df):\n",
    "    tmp = df.copy()\n",
    "    #tmp['g_sum'] = tmp[g_feats].sum(axis = 1)\n",
    "    #tmp['g_mean'] = tmp[g_feats].mean(axis = 1)\n",
    "    #tmp['g_std'] = tmp[g_feats].std(axis = 1)\n",
    "    #tmp['g_kurt'] = tmp[g_feats].kurtosis(axis = 1)\n",
    "    #tmp['g_skew'] = tmp[g_feats].skew(axis = 1)\n",
    "    #tmp['c_sum'] = tmp[c_feats].sum(axis = 1)\n",
    "    #tmp['c_mean'] = tmp[c_feats].mean(axis = 1)\n",
    "    #tmp['c_std'] = tmp[c_feats].std(axis = 1)\n",
    "    #tmp['c_kurt'] = tmp[c_feats].kurtosis(axis = 1)\n",
    "    #tmp['c_skew'] = tmp[c_feats].skew(axis = 1)\n",
    "    #tmp['gc_sum'] = tmp[c_feats + g_feats].sum(axis = 1)\n",
    "    #tmp['gc_mean'] = tmp[c_feats + g_feats].mean(axis = 1)\n",
    "    #tmp['gc_std'] = tmp[c_feats + g_feats].std(axis = 1)\n",
    "    #tmp['gc_kurt'] = tmp[c_feats + g_feats].kurtosis(axis = 1)\n",
    "    #tmp['gc_skew'] = tmp[c_feats + g_feats].skew(axis = 1)\n",
    "    #tmp.loc[:, 'cp_type'] = tmp.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    #tmp.loc[:, 'cp_dose'] = tmp.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "        \n",
    "    tmp.drop([\"cp_type\", \"sig_id\", \"cp_time\", \"cp_dose\"], axis=1, inplace=True)\n",
    "    return tmp\n",
    "\n",
    "f_train = fe(train)\n",
    "f_test = fe(test)\n",
    "\n",
    "print(f_train.shape, f_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-16T04:15:56.555209Z",
     "iopub.status.busy": "2020-10-16T04:15:56.554609Z",
     "iopub.status.idle": "2020-10-16T04:15:58.075475Z",
     "shell.execute_reply": "2020-10-16T04:15:58.074798Z"
    },
    "papermill": {
     "duration": 1.541483,
     "end_time": "2020-10-16T04:15:58.075592",
     "exception": false,
     "start_time": "2020-10-16T04:15:56.534109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fn_train = f_train.copy().to_numpy()\n",
    "fn_test = f_test.copy().to_numpy()\n",
    "\n",
    "ss = preprocessing.RobustScaler()\n",
    "fn_train= ss.fit_transform(fn_train)\n",
    "fn_test = ss.transform(fn_test)\n",
    "\n",
    "#fn_nontargets = non_targets.drop(\"sig_id\", axis=1).copy().to_numpy()\n",
    "fn_targets = targets.drop(\"sig_id\", axis=1).copy().to_numpy()\n",
    "fn_all_targets = all_targets.drop(\"sig_id\", axis=1).copy().to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014812,
     "end_time": "2020-10-16T04:15:58.105630",
     "exception": false,
     "start_time": "2020-10-16T04:15:58.090818",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-16T04:15:58.152837Z",
     "iopub.status.busy": "2020-10-16T04:15:58.144776Z",
     "iopub.status.idle": "2020-10-16T04:15:58.156452Z",
     "shell.execute_reply": "2020-10-16T04:15:58.156923Z"
    },
    "papermill": {
     "duration": 0.036372,
     "end_time": "2020-10-16T04:15:58.157092",
     "exception": false,
     "start_time": "2020-10-16T04:15:58.120720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "def mean_log_loss(y_true, y_pred):\n",
    "    metrics = []\n",
    "    for i, target in enumerate(target_feats):\n",
    "        metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float), labels=[0,1]))\n",
    "    return np.mean(metrics)\n",
    "\n",
    "def seed_everything(seed=1234): \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "class MoaModel(nn.Module):\n",
    "    def __init__(self, num_columns, last_num):\n",
    "        super(MoaModel, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_columns)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_columns, 2048))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(2048)\n",
    "        self.dropout2 = nn.Dropout(0.6)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(2048,1048))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(1048)\n",
    "        self.dropout3 = nn.Dropout(0.6)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(1048, last_num))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014899,
     "end_time": "2020-10-16T04:15:58.187530",
     "exception": false,
     "start_time": "2020-10-16T04:15:58.172631",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-16T04:15:58.260306Z",
     "iopub.status.busy": "2020-10-16T04:15:58.227422Z",
     "iopub.status.idle": "2020-10-16T04:15:58.263663Z",
     "shell.execute_reply": "2020-10-16T04:15:58.262991Z"
    },
    "papermill": {
     "duration": 0.060622,
     "end_time": "2020-10-16T04:15:58.263784",
     "exception": false,
     "start_time": "2020-10-16T04:15:58.203162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_folds=5\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "\n",
    "def modelling_torch(tr, target, te, sample_seed, init_num, last_num, files):\n",
    "    seed_everything(seed=sample_seed) \n",
    "    X_train = tr.copy()\n",
    "    y_train = target.copy()\n",
    "    X_test = te.copy()\n",
    "    test_len = X_test.shape[0]\n",
    "    \n",
    "    if files == []:\n",
    "        train_epochs = 30\n",
    "        mskf=MultilabelStratifiedKFold(n_splits = n_folds, shuffle=True, random_state=224)\n",
    "        ans = []\n",
    "    else:\n",
    "        train_epochs = 10\n",
    "        mskf=MultilabelStratifiedKFold(n_splits = n_folds, shuffle=True, random_state=2)\n",
    "\n",
    "    models = []\n",
    "    \n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    X_test = torch.utils.data.TensorDataset(X_test) \n",
    "    test_loader = torch.utils.data.DataLoader(X_test, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    oof = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    oof_targets = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    pred_value = np.zeros([test_len, y_train.shape[1]])\n",
    "    scores = []\n",
    "    for fold, (train_index, valid_index) in enumerate(mskf.split(X_train, y_train)):\n",
    "        print(\"Fold \"+str(fold+1))\n",
    "        X_train2 = torch.tensor(X_train[train_index,:], dtype=torch.float32)\n",
    "        y_train2 = torch.tensor(y_train[train_index], dtype=torch.float32)\n",
    "\n",
    "        X_valid2 = torch.tensor(X_train[valid_index,:], dtype=torch.float32)\n",
    "        y_valid2 = torch.tensor(y_train[valid_index], dtype=torch.float32)\n",
    "            \n",
    "        clf = MoaModel(init_num, len(non_target_feats)+len(target_feats))\n",
    "        loss_fn = torch.nn.BCEWithLogitsLoss() \n",
    "        if files != []:\n",
    "            clf.load_state_dict(torch.load(files[fold]))\n",
    "            for param in clf.parameters():\n",
    "                param.requires_grad = False\n",
    "            # reinitialze\n",
    "            clf.dense3 = nn.utils.weight_norm(nn.Linear(1048, len(target_feats)))\n",
    "            for param in clf.dense3.parameters():\n",
    "                param.requires_grad = True\n",
    "            optimizer = optim.Adam(clf.parameters(), lr = 0.001, weight_decay=1e-5) \n",
    "            #lookahead = Lookahead(optimizer, k=10, alpha=0.6) #lookahead\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, eps=1e-4, verbose=True)\n",
    "        else:\n",
    "            optimizer = optim.Adam(clf.parameters(), lr = 0.001, weight_decay=1e-5) \n",
    "            #lookahead = Lookahead(optimizer, k=10, alpha=0.6) #lookahead\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, eps=1e-4, verbose=True)\n",
    "        \n",
    "        train = torch.utils.data.TensorDataset(X_train2, y_train2)\n",
    "        valid = torch.utils.data.TensorDataset(X_valid2, y_valid2)\n",
    "        \n",
    "        clf.to(device)\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True) \n",
    "        valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        best_val_loss = np.inf\n",
    "        stop_counts = 0\n",
    "        for epoch in range(train_epochs):\n",
    "            start_time = time.time()\n",
    "            clf.train()\n",
    "            avg_loss = 0.\n",
    "            for x_batch, y_batch in tqdm(train_loader, disable=True):\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch) \n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                avg_loss += loss.item() / len(train_loader)        \n",
    "            \n",
    "            clf.eval()\n",
    "            avg_val_loss = 0.\n",
    "            for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch).detach()\n",
    "                avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "        \n",
    "            elapsed_time = time.time() - start_time \n",
    "            scheduler.step(avg_val_loss)\n",
    "                    \n",
    "            if avg_val_loss < best_val_loss:\n",
    "                stop_counts = 0\n",
    "                best_val_loss = avg_val_loss\n",
    "                print('Best model: Epoch {} \\t loss={:.6f} \\t val_loss={:.6f} \\t time={:.2f}s'.format(\n",
    "                    epoch + 1, avg_loss, avg_val_loss, elapsed_time))\n",
    "                if files == []:\n",
    "                    torch.save(clf.state_dict(), 'parameters'+str(fold+1)+'.pt')\n",
    "                else:    \n",
    "                    torch.save(clf.state_dict(), 'best-model-parameters.pt')\n",
    "            else:\n",
    "                stop_counts += 1\n",
    "        \n",
    "            #if stop_counts >= EARLY_STOPPING_STEPS: \n",
    "            #    break\n",
    "            \n",
    "        if files == []:\n",
    "            pred_model = MoaModel(init_num, len(non_target_feats)+len(target_feats))\n",
    "            ans.append('parameters'+str(fold+1)+'.pt')\n",
    "            pred_model.load_state_dict(torch.load('parameters'+str(fold+1)+'.pt'))\n",
    "        else:\n",
    "            pred_model = MoaModel(init_num, len(target_feats))\n",
    "            pred_model.load_state_dict(torch.load('best-model-parameters.pt'))         \n",
    "        pred_model.eval()\n",
    "        \n",
    "        # validation check ----------------\n",
    "        oof_epoch = np.zeros([X_valid2.size(0), y_train.shape[1]])\n",
    "        target_epoch = np.zeros([X_valid2.size(0), y_train.shape[1]])\n",
    "        for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "                y_pred = pred_model(x_batch).sigmoid().detach()\n",
    "                oof_epoch[i * batch_size:(i+1) * batch_size,:] = y_pred.cpu().numpy()\n",
    "                target_epoch[i * batch_size:(i+1) * batch_size,:] = y_batch.cpu().numpy()\n",
    "        print(\"Fold {} log loss: {}\".format(fold+1, mean_log_loss(target_epoch, oof_epoch)))\n",
    "        scores.append(mean_log_loss(target_epoch, oof_epoch))\n",
    "        oof[valid_index,:] = oof_epoch\n",
    "        oof_targets[valid_index,:] = target_epoch\n",
    "        #-----------------------------------\n",
    "        \n",
    "        if files != []:\n",
    "            # test predcition --------------\n",
    "            test_preds = np.zeros([test_len, y_train.shape[1]])\n",
    "            for i, (x_batch,) in enumerate(test_loader): \n",
    "                y_pred = pred_model(x_batch).sigmoid().detach()\n",
    "                test_preds[i * batch_size:(i+1) * batch_size, :] = y_pred.cpu().numpy()\n",
    "            pred_value += test_preds / n_folds\n",
    "            # ------------------------------\n",
    "        \n",
    "    print(\"Seed {}\".format(seed_))\n",
    "    for i, ele in enumerate(scores):\n",
    "        print(\"Fold {} log loss: {}\".format(i+1, scores[i]))\n",
    "    print(\"Std of log loss: {}\".format(np.std(scores)))\n",
    "    print(\"Total log loss: {}\".format(mean_log_loss(oof_targets, oof)))\n",
    "    \n",
    "    if files != []:\n",
    "        return oof, oof_targets, pred_value\n",
    "    else:\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-16T04:15:58.304764Z",
     "iopub.status.busy": "2020-10-16T04:15:58.304046Z",
     "iopub.status.idle": "2020-10-16T05:00:45.617888Z",
     "shell.execute_reply": "2020-10-16T05:00:45.617257Z"
    },
    "papermill": {
     "duration": 2687.338131,
     "end_time": "2020-10-16T05:00:45.618017",
     "exception": false,
     "start_time": "2020-10-16T04:15:58.279886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer learning\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.407421 \t val_loss=0.072216 \t time=14.80s\n",
      "Best model: Epoch 2 \t loss=0.041442 \t val_loss=0.021327 \t time=13.62s\n",
      "Best model: Epoch 3 \t loss=0.019567 \t val_loss=0.014547 \t time=13.69s\n",
      "Best model: Epoch 4 \t loss=0.014629 \t val_loss=0.013003 \t time=14.14s\n",
      "Best model: Epoch 5 \t loss=0.013476 \t val_loss=0.011736 \t time=14.46s\n",
      "Best model: Epoch 6 \t loss=0.012093 \t val_loss=0.011416 \t time=14.30s\n",
      "Best model: Epoch 7 \t loss=0.011860 \t val_loss=0.011277 \t time=14.00s\n",
      "Best model: Epoch 8 \t loss=0.011667 \t val_loss=0.010979 \t time=14.44s\n",
      "Best model: Epoch 9 \t loss=0.011429 \t val_loss=0.010823 \t time=14.21s\n",
      "Best model: Epoch 10 \t loss=0.011027 \t val_loss=0.010665 \t time=14.62s\n",
      "Best model: Epoch 11 \t loss=0.010848 \t val_loss=0.010472 \t time=14.10s\n",
      "Best model: Epoch 13 \t loss=0.010671 \t val_loss=0.010385 \t time=14.46s\n",
      "Best model: Epoch 14 \t loss=0.010467 \t val_loss=0.010042 \t time=14.45s\n",
      "Best model: Epoch 15 \t loss=0.010432 \t val_loss=0.009991 \t time=14.35s\n",
      "Best model: Epoch 16 \t loss=0.010182 \t val_loss=0.009975 \t time=13.93s\n",
      "Best model: Epoch 17 \t loss=0.010096 \t val_loss=0.009908 \t time=14.19s\n",
      "Best model: Epoch 18 \t loss=0.010038 \t val_loss=0.009768 \t time=14.72s\n",
      "Best model: Epoch 20 \t loss=0.009895 \t val_loss=0.009657 \t time=14.04s\n",
      "Best model: Epoch 21 \t loss=0.009768 \t val_loss=0.009601 \t time=14.12s\n",
      "Best model: Epoch 23 \t loss=0.009660 \t val_loss=0.009539 \t time=14.06s\n",
      "Best model: Epoch 25 \t loss=0.009573 \t val_loss=0.009526 \t time=13.96s\n",
      "Best model: Epoch 26 \t loss=0.009501 \t val_loss=0.009517 \t time=14.68s\n",
      "Best model: Epoch 27 \t loss=0.009474 \t val_loss=0.009463 \t time=14.21s\n",
      "Best model: Epoch 29 \t loss=0.009411 \t val_loss=0.009458 \t time=15.18s\n",
      "Best model: Epoch 30 \t loss=0.009393 \t val_loss=0.009442 \t time=14.96s\n",
      "Fold 1 log loss: 0.016614442042683406\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.407476 \t val_loss=0.069134 \t time=13.90s\n",
      "Best model: Epoch 2 \t loss=0.041146 \t val_loss=0.022410 \t time=13.87s\n",
      "Best model: Epoch 3 \t loss=0.019945 \t val_loss=0.014825 \t time=14.28s\n",
      "Best model: Epoch 4 \t loss=0.014543 \t val_loss=0.012647 \t time=14.28s\n",
      "Best model: Epoch 5 \t loss=0.013074 \t val_loss=0.012487 \t time=14.46s\n",
      "Best model: Epoch 6 \t loss=0.012272 \t val_loss=0.011459 \t time=14.06s\n",
      "Best model: Epoch 7 \t loss=0.011797 \t val_loss=0.011171 \t time=14.15s\n",
      "Best model: Epoch 8 \t loss=0.011519 \t val_loss=0.011021 \t time=14.21s\n",
      "Best model: Epoch 10 \t loss=0.011320 \t val_loss=0.010758 \t time=13.93s\n",
      "Best model: Epoch 11 \t loss=0.011073 \t val_loss=0.010585 \t time=13.86s\n",
      "Best model: Epoch 12 \t loss=0.010885 \t val_loss=0.010377 \t time=16.23s\n",
      "Best model: Epoch 13 \t loss=0.010708 \t val_loss=0.010213 \t time=14.52s\n",
      "Best model: Epoch 14 \t loss=0.010429 \t val_loss=0.010165 \t time=14.26s\n",
      "Best model: Epoch 15 \t loss=0.010310 \t val_loss=0.010009 \t time=13.85s\n",
      "Best model: Epoch 17 \t loss=0.010070 \t val_loss=0.009864 \t time=14.42s\n",
      "Best model: Epoch 20 \t loss=0.009778 \t val_loss=0.009707 \t time=14.25s\n",
      "Best model: Epoch 22 \t loss=0.009702 \t val_loss=0.009635 \t time=13.87s\n",
      "Best model: Epoch 23 \t loss=0.009581 \t val_loss=0.009586 \t time=14.19s\n",
      "Best model: Epoch 25 \t loss=0.009529 \t val_loss=0.009551 \t time=14.38s\n",
      "Best model: Epoch 26 \t loss=0.009494 \t val_loss=0.009526 \t time=14.15s\n",
      "Best model: Epoch 27 \t loss=0.009444 \t val_loss=0.009517 \t time=14.33s\n",
      "Best model: Epoch 28 \t loss=0.009429 \t val_loss=0.009467 \t time=13.71s\n",
      "Fold 2 log loss: 0.01664421227120735\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.405390 \t val_loss=0.072219 \t time=13.78s\n",
      "Best model: Epoch 2 \t loss=0.041384 \t val_loss=0.020841 \t time=13.78s\n",
      "Best model: Epoch 3 \t loss=0.019376 \t val_loss=0.014541 \t time=13.70s\n",
      "Best model: Epoch 4 \t loss=0.015286 \t val_loss=0.013606 \t time=14.55s\n",
      "Best model: Epoch 5 \t loss=0.013218 \t val_loss=0.011919 \t time=13.75s\n",
      "Best model: Epoch 6 \t loss=0.012825 \t val_loss=0.011617 \t time=14.00s\n",
      "Best model: Epoch 7 \t loss=0.011729 \t val_loss=0.011075 \t time=13.78s\n",
      "Best model: Epoch 8 \t loss=0.011497 \t val_loss=0.011037 \t time=14.46s\n",
      "Best model: Epoch 9 \t loss=0.011274 \t val_loss=0.010782 \t time=13.66s\n",
      "Best model: Epoch 10 \t loss=0.011103 \t val_loss=0.010618 \t time=13.65s\n",
      "Best model: Epoch 11 \t loss=0.010913 \t val_loss=0.010499 \t time=13.97s\n",
      "Best model: Epoch 12 \t loss=0.010863 \t val_loss=0.010448 \t time=13.85s\n",
      "Best model: Epoch 13 \t loss=0.010700 \t val_loss=0.010355 \t time=14.27s\n",
      "Best model: Epoch 14 \t loss=0.010575 \t val_loss=0.010197 \t time=13.74s\n",
      "Best model: Epoch 15 \t loss=0.010386 \t val_loss=0.010185 \t time=13.94s\n",
      "Best model: Epoch 16 \t loss=0.010258 \t val_loss=0.010026 \t time=13.96s\n",
      "Best model: Epoch 17 \t loss=0.010233 \t val_loss=0.009943 \t time=14.44s\n",
      "Best model: Epoch 18 \t loss=0.010063 \t val_loss=0.009869 \t time=13.76s\n",
      "Best model: Epoch 19 \t loss=0.009990 \t val_loss=0.009812 \t time=13.83s\n",
      "Best model: Epoch 20 \t loss=0.009870 \t val_loss=0.009760 \t time=14.01s\n",
      "Best model: Epoch 21 \t loss=0.009818 \t val_loss=0.009728 \t time=14.57s\n",
      "Best model: Epoch 22 \t loss=0.009741 \t val_loss=0.009687 \t time=14.05s\n",
      "Best model: Epoch 23 \t loss=0.009708 \t val_loss=0.009649 \t time=13.72s\n",
      "Best model: Epoch 25 \t loss=0.009592 \t val_loss=0.009557 \t time=17.92s\n",
      "Best model: Epoch 27 \t loss=0.009500 \t val_loss=0.009546 \t time=13.84s\n",
      "Best model: Epoch 28 \t loss=0.009470 \t val_loss=0.009543 \t time=13.84s\n",
      "Best model: Epoch 29 \t loss=0.009498 \t val_loss=0.009530 \t time=14.64s\n",
      "Fold 3 log loss: 0.01668101351096892\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.411051 \t val_loss=0.072892 \t time=13.85s\n",
      "Best model: Epoch 2 \t loss=0.042156 \t val_loss=0.020978 \t time=13.59s\n",
      "Best model: Epoch 3 \t loss=0.019105 \t val_loss=0.015084 \t time=14.41s\n",
      "Best model: Epoch 4 \t loss=0.014688 \t val_loss=0.012539 \t time=13.75s\n",
      "Best model: Epoch 5 \t loss=0.012993 \t val_loss=0.011792 \t time=13.88s\n",
      "Best model: Epoch 6 \t loss=0.012239 \t val_loss=0.011385 \t time=13.50s\n",
      "Best model: Epoch 7 \t loss=0.012041 \t val_loss=0.011137 \t time=15.10s\n",
      "Best model: Epoch 9 \t loss=0.011388 \t val_loss=0.010665 \t time=13.55s\n",
      "Best model: Epoch 10 \t loss=0.011068 \t val_loss=0.010511 \t time=14.04s\n",
      "Best model: Epoch 11 \t loss=0.011231 \t val_loss=0.010400 \t time=13.80s\n",
      "Best model: Epoch 12 \t loss=0.010756 \t val_loss=0.010284 \t time=14.72s\n",
      "Best model: Epoch 13 \t loss=0.010556 \t val_loss=0.010152 \t time=13.63s\n",
      "Best model: Epoch 14 \t loss=0.010444 \t val_loss=0.010062 \t time=13.97s\n",
      "Best model: Epoch 16 \t loss=0.010299 \t val_loss=0.009814 \t time=14.27s\n",
      "Best model: Epoch 17 \t loss=0.010137 \t val_loss=0.009767 \t time=13.97s\n",
      "Best model: Epoch 19 \t loss=0.010041 \t val_loss=0.009596 \t time=14.16s\n",
      "Best model: Epoch 22 \t loss=0.009746 \t val_loss=0.009511 \t time=13.66s\n",
      "Best model: Epoch 23 \t loss=0.009710 \t val_loss=0.009471 \t time=13.56s\n",
      "Best model: Epoch 24 \t loss=0.009643 \t val_loss=0.009414 \t time=13.90s\n",
      "Best model: Epoch 25 \t loss=0.009552 \t val_loss=0.009393 \t time=14.28s\n",
      "Best model: Epoch 26 \t loss=0.009538 \t val_loss=0.009389 \t time=14.01s\n",
      "Best model: Epoch 28 \t loss=0.009474 \t val_loss=0.009364 \t time=14.02s\n",
      "Best model: Epoch 29 \t loss=0.009458 \t val_loss=0.009319 \t time=14.27s\n",
      "Fold 4 log loss: 0.01630059292226289\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.410869 \t val_loss=0.067734 \t time=13.53s\n",
      "Best model: Epoch 2 \t loss=0.041416 \t val_loss=0.019992 \t time=13.75s\n",
      "Best model: Epoch 3 \t loss=0.019463 \t val_loss=0.014353 \t time=14.61s\n",
      "Best model: Epoch 4 \t loss=0.014815 \t val_loss=0.012622 \t time=13.80s\n",
      "Best model: Epoch 5 \t loss=0.012994 \t val_loss=0.012267 \t time=13.96s\n",
      "Best model: Epoch 6 \t loss=0.012187 \t val_loss=0.011465 \t time=13.69s\n",
      "Best model: Epoch 7 \t loss=0.011921 \t val_loss=0.011136 \t time=14.30s\n",
      "Best model: Epoch 8 \t loss=0.011463 \t val_loss=0.011049 \t time=16.52s\n",
      "Best model: Epoch 9 \t loss=0.011318 \t val_loss=0.010868 \t time=14.17s\n",
      "Best model: Epoch 10 \t loss=0.011166 \t val_loss=0.010821 \t time=13.70s\n",
      "Best model: Epoch 11 \t loss=0.010899 \t val_loss=0.010514 \t time=14.03s\n",
      "Best model: Epoch 12 \t loss=0.010701 \t val_loss=0.010417 \t time=14.46s\n",
      "Best model: Epoch 13 \t loss=0.010512 \t val_loss=0.010327 \t time=13.73s\n",
      "Best model: Epoch 14 \t loss=0.010395 \t val_loss=0.010130 \t time=13.93s\n",
      "Best model: Epoch 16 \t loss=0.010229 \t val_loss=0.009926 \t time=14.72s\n",
      "Best model: Epoch 18 \t loss=0.009949 \t val_loss=0.009740 \t time=14.03s\n",
      "Best model: Epoch 19 \t loss=0.009954 \t val_loss=0.009732 \t time=13.79s\n",
      "Best model: Epoch 21 \t loss=0.009721 \t val_loss=0.009581 \t time=14.29s\n",
      "Best model: Epoch 24 \t loss=0.009576 \t val_loss=0.009486 \t time=14.47s\n",
      "Best model: Epoch 26 \t loss=0.009443 \t val_loss=0.009448 \t time=13.90s\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Fold 5 log loss: 0.016614479581408638\n",
      "Seed 0\n",
      "Fold 1 log loss: 0.016614442042683406\n",
      "Fold 2 log loss: 0.01664421227120735\n",
      "Fold 3 log loss: 0.01668101351096892\n",
      "Fold 4 log loss: 0.01630059292226289\n",
      "Fold 5 log loss: 0.016614479581408638\n",
      "Std of log loss: 0.00013737588473054053\n",
      "Total log loss: 0.016570939085392856\n",
      "Final prediction\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.044951 \t val_loss=0.019156 \t time=4.96s\n",
      "Best model: Epoch 2 \t loss=0.018788 \t val_loss=0.017344 \t time=5.00s\n",
      "Best model: Epoch 3 \t loss=0.017624 \t val_loss=0.016657 \t time=5.12s\n",
      "Best model: Epoch 4 \t loss=0.017125 \t val_loss=0.016274 \t time=5.15s\n",
      "Best model: Epoch 5 \t loss=0.016814 \t val_loss=0.015974 \t time=5.18s\n",
      "Best model: Epoch 6 \t loss=0.016613 \t val_loss=0.015847 \t time=5.28s\n",
      "Best model: Epoch 7 \t loss=0.016466 \t val_loss=0.015813 \t time=5.11s\n",
      "Best model: Epoch 8 \t loss=0.016458 \t val_loss=0.015719 \t time=5.09s\n",
      "Best model: Epoch 9 \t loss=0.016352 \t val_loss=0.015622 \t time=4.94s\n",
      "Best model: Epoch 10 \t loss=0.016287 \t val_loss=0.015542 \t time=5.24s\n",
      "Fold 1 log loss: 0.01555278682846665\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.044606 \t val_loss=0.019109 \t time=4.99s\n",
      "Best model: Epoch 2 \t loss=0.018696 \t val_loss=0.017358 \t time=5.00s\n",
      "Best model: Epoch 3 \t loss=0.017554 \t val_loss=0.016668 \t time=4.92s\n",
      "Best model: Epoch 4 \t loss=0.017101 \t val_loss=0.016347 \t time=4.99s\n",
      "Best model: Epoch 5 \t loss=0.016735 \t val_loss=0.016160 \t time=5.25s\n",
      "Best model: Epoch 6 \t loss=0.016673 \t val_loss=0.015935 \t time=4.96s\n",
      "Best model: Epoch 7 \t loss=0.016492 \t val_loss=0.015863 \t time=5.44s\n",
      "Best model: Epoch 8 \t loss=0.016367 \t val_loss=0.015772 \t time=5.20s\n",
      "Best model: Epoch 10 \t loss=0.016276 \t val_loss=0.015718 \t time=4.89s\n",
      "Fold 2 log loss: 0.01582977296174664\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.045749 \t val_loss=0.019108 \t time=5.20s\n",
      "Best model: Epoch 2 \t loss=0.018890 \t val_loss=0.017145 \t time=4.98s\n",
      "Best model: Epoch 3 \t loss=0.017694 \t val_loss=0.016518 \t time=4.90s\n",
      "Best model: Epoch 4 \t loss=0.017219 \t val_loss=0.016124 \t time=4.97s\n",
      "Best model: Epoch 5 \t loss=0.016899 \t val_loss=0.015905 \t time=4.93s\n",
      "Best model: Epoch 6 \t loss=0.016745 \t val_loss=0.015762 \t time=4.92s\n",
      "Best model: Epoch 7 \t loss=0.016585 \t val_loss=0.015639 \t time=5.14s\n",
      "Best model: Epoch 8 \t loss=0.016563 \t val_loss=0.015609 \t time=5.74s\n",
      "Best model: Epoch 9 \t loss=0.016411 \t val_loss=0.015606 \t time=5.30s\n",
      "Best model: Epoch 10 \t loss=0.016392 \t val_loss=0.015452 \t time=4.94s\n",
      "Fold 3 log loss: 0.015553331913663032\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.045266 \t val_loss=0.019086 \t time=4.86s\n",
      "Best model: Epoch 2 \t loss=0.018812 \t val_loss=0.017271 \t time=4.87s\n",
      "Best model: Epoch 3 \t loss=0.017659 \t val_loss=0.016511 \t time=5.31s\n",
      "Best model: Epoch 4 \t loss=0.017177 \t val_loss=0.016179 \t time=5.01s\n",
      "Best model: Epoch 5 \t loss=0.016896 \t val_loss=0.015963 \t time=4.92s\n",
      "Best model: Epoch 6 \t loss=0.016632 \t val_loss=0.015769 \t time=4.94s\n",
      "Best model: Epoch 7 \t loss=0.016537 \t val_loss=0.015685 \t time=4.95s\n",
      "Best model: Epoch 8 \t loss=0.016484 \t val_loss=0.015611 \t time=4.89s\n",
      "Best model: Epoch 9 \t loss=0.016365 \t val_loss=0.015487 \t time=5.41s\n",
      "Best model: Epoch 10 \t loss=0.016303 \t val_loss=0.015450 \t time=5.37s\n",
      "Fold 4 log loss: 0.015484060316643239\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.046356 \t val_loss=0.019316 \t time=5.04s\n",
      "Best model: Epoch 2 \t loss=0.018841 \t val_loss=0.017461 \t time=4.92s\n",
      "Best model: Epoch 3 \t loss=0.017691 \t val_loss=0.016759 \t time=4.95s\n",
      "Best model: Epoch 4 \t loss=0.017095 \t val_loss=0.016427 \t time=4.87s\n",
      "Best model: Epoch 5 \t loss=0.016803 \t val_loss=0.016219 \t time=5.29s\n",
      "Best model: Epoch 6 \t loss=0.016652 \t val_loss=0.016089 \t time=4.84s\n",
      "Best model: Epoch 7 \t loss=0.016517 \t val_loss=0.015976 \t time=4.94s\n",
      "Best model: Epoch 8 \t loss=0.016441 \t val_loss=0.015927 \t time=4.86s\n",
      "Best model: Epoch 9 \t loss=0.016365 \t val_loss=0.015822 \t time=4.92s\n",
      "Best model: Epoch 10 \t loss=0.016301 \t val_loss=0.015760 \t time=4.92s\n",
      "Fold 5 log loss: 0.01574557091691592\n",
      "Seed 10\n",
      "Fold 1 log loss: 0.01555278682846665\n",
      "Fold 2 log loss: 0.01582977296174664\n",
      "Fold 3 log loss: 0.015553331913663032\n",
      "Fold 4 log loss: 0.015484060316643239\n",
      "Fold 5 log loss: 0.01574557091691592\n",
      "Std of log loss: 0.00013141989291090472\n",
      "Total log loss: 0.01563311867299781\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.045334 \t val_loss=0.019271 \t time=5.60s\n",
      "Best model: Epoch 2 \t loss=0.018859 \t val_loss=0.017369 \t time=5.02s\n",
      "Best model: Epoch 3 \t loss=0.017654 \t val_loss=0.016595 \t time=5.83s\n",
      "Best model: Epoch 4 \t loss=0.017125 \t val_loss=0.016310 \t time=6.31s\n",
      "Best model: Epoch 5 \t loss=0.016853 \t val_loss=0.016063 \t time=5.05s\n",
      "Best model: Epoch 6 \t loss=0.016622 \t val_loss=0.015837 \t time=5.27s\n",
      "Best model: Epoch 7 \t loss=0.016473 \t val_loss=0.015737 \t time=5.17s\n",
      "Best model: Epoch 8 \t loss=0.016412 \t val_loss=0.015729 \t time=4.95s\n",
      "Best model: Epoch 9 \t loss=0.016345 \t val_loss=0.015647 \t time=5.03s\n",
      "Best model: Epoch 10 \t loss=0.016296 \t val_loss=0.015584 \t time=4.94s\n",
      "Fold 1 log loss: 0.015595942562710728\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.045609 \t val_loss=0.019171 \t time=5.52s\n",
      "Best model: Epoch 2 \t loss=0.018707 \t val_loss=0.017366 \t time=5.32s\n",
      "Best model: Epoch 3 \t loss=0.017599 \t val_loss=0.016702 \t time=4.99s\n",
      "Best model: Epoch 4 \t loss=0.017118 \t val_loss=0.016344 \t time=5.00s\n",
      "Best model: Epoch 5 \t loss=0.016818 \t val_loss=0.016148 \t time=5.11s\n",
      "Best model: Epoch 6 \t loss=0.016614 \t val_loss=0.016038 \t time=5.01s\n",
      "Best model: Epoch 7 \t loss=0.016354 \t val_loss=0.015930 \t time=4.99s\n",
      "Best model: Epoch 8 \t loss=0.016338 \t val_loss=0.015807 \t time=4.92s\n",
      "Best model: Epoch 10 \t loss=0.016220 \t val_loss=0.015702 \t time=4.94s\n",
      "Fold 2 log loss: 0.015816665728117688\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.045528 \t val_loss=0.019103 \t time=4.97s\n",
      "Best model: Epoch 2 \t loss=0.018829 \t val_loss=0.017202 \t time=5.22s\n",
      "Best model: Epoch 3 \t loss=0.017741 \t val_loss=0.016485 \t time=5.32s\n",
      "Best model: Epoch 4 \t loss=0.017220 \t val_loss=0.016117 \t time=4.88s\n",
      "Best model: Epoch 5 \t loss=0.016954 \t val_loss=0.015984 \t time=5.35s\n",
      "Best model: Epoch 6 \t loss=0.016820 \t val_loss=0.015816 \t time=4.92s\n",
      "Best model: Epoch 7 \t loss=0.016591 \t val_loss=0.015715 \t time=4.96s\n",
      "Best model: Epoch 8 \t loss=0.016502 \t val_loss=0.015583 \t time=5.04s\n",
      "Best model: Epoch 9 \t loss=0.016429 \t val_loss=0.015473 \t time=4.96s\n",
      "Fold 3 log loss: 0.015573709299576821\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.045442 \t val_loss=0.019164 \t time=5.01s\n",
      "Best model: Epoch 2 \t loss=0.018833 \t val_loss=0.017302 \t time=4.91s\n",
      "Best model: Epoch 3 \t loss=0.017689 \t val_loss=0.016603 \t time=5.15s\n",
      "Best model: Epoch 4 \t loss=0.017093 \t val_loss=0.016129 \t time=5.30s\n",
      "Best model: Epoch 5 \t loss=0.016901 \t val_loss=0.015853 \t time=5.13s\n",
      "Best model: Epoch 6 \t loss=0.016663 \t val_loss=0.015750 \t time=5.03s\n",
      "Best model: Epoch 7 \t loss=0.016500 \t val_loss=0.015650 \t time=5.32s\n",
      "Best model: Epoch 9 \t loss=0.016390 \t val_loss=0.015519 \t time=4.97s\n",
      "Best model: Epoch 10 \t loss=0.016319 \t val_loss=0.015514 \t time=5.04s\n",
      "Fold 4 log loss: 0.015549415065733615\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.045851 \t val_loss=0.019293 \t time=4.89s\n",
      "Best model: Epoch 2 \t loss=0.018845 \t val_loss=0.017410 \t time=4.97s\n",
      "Best model: Epoch 3 \t loss=0.017602 \t val_loss=0.016766 \t time=5.18s\n",
      "Best model: Epoch 4 \t loss=0.017126 \t val_loss=0.016409 \t time=5.15s\n",
      "Best model: Epoch 5 \t loss=0.016842 \t val_loss=0.016244 \t time=5.18s\n",
      "Best model: Epoch 6 \t loss=0.016584 \t val_loss=0.016070 \t time=5.19s\n",
      "Best model: Epoch 7 \t loss=0.016539 \t val_loss=0.015965 \t time=4.95s\n",
      "Best model: Epoch 8 \t loss=0.016450 \t val_loss=0.015920 \t time=4.95s\n",
      "Best model: Epoch 9 \t loss=0.016412 \t val_loss=0.015912 \t time=5.17s\n",
      "Best model: Epoch 10 \t loss=0.016319 \t val_loss=0.015793 \t time=4.96s\n",
      "Fold 5 log loss: 0.01577801102585244\n",
      "Seed 40\n",
      "Fold 1 log loss: 0.015595942562710728\n",
      "Fold 2 log loss: 0.015816665728117688\n",
      "Fold 3 log loss: 0.015573709299576821\n",
      "Fold 4 log loss: 0.015549415065733615\n",
      "Fold 5 log loss: 0.01577801102585244\n",
      "Std of log loss: 0.00011154500685261299\n",
      "Total log loss: 0.01566276100136756\n",
      "Total log loss in targets: 0.015616611339466511\n"
     ]
    }
   ],
   "source": [
    "print(\"Transfer learning\")\n",
    "for seed_ in [0]:\n",
    "    files = modelling_torch(fn_train, fn_all_targets, fn_test, seed_, fn_train.shape[1], fn_all_targets.shape[1],[])\n",
    "\n",
    "target_oof = np.zeros([len(fn_train),fn_targets.shape[1]])\n",
    "target_pred = np.zeros([len(fn_test),fn_targets.shape[1]])\n",
    "\n",
    "seeds = [10,40]\n",
    "\n",
    "print(\"Final prediction\")\n",
    "for seed_ in seeds:\n",
    "    oof, oof_targets, pytorch_pred = modelling_torch(fn_train, fn_targets, fn_test, seed_, fn_train.shape[1], fn_targets.shape[1], files)\n",
    "    target_oof += oof / len(seeds)\n",
    "    target_pred += pytorch_pred / len(seeds)\n",
    "print(\"Total log loss in targets: {}\".format(mean_log_loss(oof_targets, target_oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-16T05:00:45.796357Z",
     "iopub.status.busy": "2020-10-16T05:00:45.795685Z",
     "iopub.status.idle": "2020-10-16T05:00:52.200867Z",
     "shell.execute_reply": "2020-10-16T05:00:52.201361Z"
    },
    "papermill": {
     "duration": 6.499542,
     "end_time": "2020-10-16T05:00:52.201536",
     "exception": false,
     "start_time": "2020-10-16T05:00:45.701994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF log loss:  0.014392884939624309\n"
     ]
    }
   ],
   "source": [
    "t = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "train_checkscore = t.copy()\n",
    "train_checkscore.loc[train_checkscore.index.isin(cons_train_index),target_feats] = target_oof\n",
    "train_checkscore.loc[train_checkscore.index.isin(noncons_train_index),target_feats] = 0\n",
    "\n",
    "train_checkscore.drop(original_remove_index, inplace=True)\n",
    "t.drop(original_remove_index, inplace=True)\n",
    "t.drop(\"sig_id\", axis=1, inplace=True)\n",
    "\n",
    "print('OOF log loss: ', log_loss(np.ravel(t), np.ravel(np.array(train_checkscore.iloc[:,1:]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-16T05:00:52.376439Z",
     "iopub.status.busy": "2020-10-16T05:00:52.375629Z",
     "iopub.status.idle": "2020-10-16T05:00:54.303723Z",
     "shell.execute_reply": "2020-10-16T05:00:54.303073Z"
    },
    "papermill": {
     "duration": 2.018127,
     "end_time": "2020-10-16T05:00:54.303868",
     "exception": false,
     "start_time": "2020-10-16T05:00:52.285741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub[target_feats] = target_pred\n",
    "sub.loc[noncons_test_index,target_feats] = 0\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.085835,
     "end_time": "2020-10-16T05:00:54.473970",
     "exception": false,
     "start_time": "2020-10-16T05:00:54.388135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 2719.790075,
   "end_time": "2020-10-16T05:00:54.666815",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-16T04:15:34.876740",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
