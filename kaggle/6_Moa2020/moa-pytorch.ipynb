{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016848,
     "end_time": "2020-10-17T03:13:59.393030",
     "exception": false,
     "start_time": "2020-10-17T03:13:59.376182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- cancel transfer leanring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-17T03:13:59.434020Z",
     "iopub.status.busy": "2020-10-17T03:13:59.433141Z",
     "iopub.status.idle": "2020-10-17T03:14:06.588359Z",
     "shell.execute_reply": "2020-10-17T03:14:06.586769Z"
    },
    "papermill": {
     "duration": 7.180136,
     "end_time": "2020-10-17T03:14:06.588488",
     "exception": false,
     "start_time": "2020-10-17T03:13:59.408352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss, mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "sys.path.append('../input/multilabelstraifier/')\n",
    "sys.path.append('../input/lookahead/')\n",
    "from ml_stratifiers import MultilabelStratifiedKFold\n",
    "from lookahead import Lookahead\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-17T03:14:06.630442Z",
     "iopub.status.busy": "2020-10-17T03:14:06.629142Z",
     "iopub.status.idle": "2020-10-17T03:14:13.319373Z",
     "shell.execute_reply": "2020-10-17T03:14:13.318154Z"
    },
    "papermill": {
     "duration": 6.71458,
     "end_time": "2020-10-17T03:14:13.319527",
     "exception": false,
     "start_time": "2020-10-17T03:14:06.604947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/lish-moa/'\n",
    "train = pd.read_csv(DATA_DIR + 'train_features.csv')\n",
    "targets = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "non_targets = pd.read_csv(DATA_DIR + 'train_targets_nonscored.csv')\n",
    "test = pd.read_csv(DATA_DIR + 'test_features.csv')\n",
    "sub = pd.read_csv(DATA_DIR + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-17T03:14:13.361422Z",
     "iopub.status.busy": "2020-10-17T03:14:13.359528Z",
     "iopub.status.idle": "2020-10-17T03:14:13.362121Z",
     "shell.execute_reply": "2020-10-17T03:14:13.362662Z"
    },
    "papermill": {
     "duration": 0.027018,
     "end_time": "2020-10-17T03:14:13.362781",
     "exception": false,
     "start_time": "2020-10-17T03:14:13.335763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_feats = [ i for i in targets.columns if i != \"sig_id\"]\n",
    "g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "c_feats = [i for i in train.columns if \"c-\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-17T03:14:13.405203Z",
     "iopub.status.busy": "2020-10-17T03:14:13.404425Z",
     "iopub.status.idle": "2020-10-17T03:14:13.504521Z",
     "shell.execute_reply": "2020-10-17T03:14:13.503859Z"
    },
    "papermill": {
     "duration": 0.125759,
     "end_time": "2020-10-17T03:14:13.504628",
     "exception": false,
     "start_time": "2020-10-17T03:14:13.378869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "noncons_train_index = train[train.cp_type==\"ctl_vehicle\"].index\n",
    "noncons_train_index = list(noncons_train_index) #+ original_remove_index\n",
    "cons_train_index = train[~train.index.isin(noncons_train_index)].index\n",
    "noncons_test_index = test[test.cp_type==\"ctl_vehicle\"].index\n",
    "cons_test_index = test[test.cp_type!=\"ctl_vehicle\"].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015371,
     "end_time": "2020-10-17T03:14:13.536777",
     "exception": false,
     "start_time": "2020-10-17T03:14:13.521406",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-17T03:14:13.582784Z",
     "iopub.status.busy": "2020-10-17T03:14:13.578547Z",
     "iopub.status.idle": "2020-10-17T03:14:13.896985Z",
     "shell.execute_reply": "2020-10-17T03:14:13.896405Z"
    },
    "papermill": {
     "duration": 0.34447,
     "end_time": "2020-10-17T03:14:13.897113",
     "exception": false,
     "start_time": "2020-10-17T03:14:13.552643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train[train.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "targets = targets[targets.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "non_targets = non_targets[non_targets.index.isin(cons_train_index)].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-17T03:14:13.965363Z",
     "iopub.status.busy": "2020-10-17T03:14:13.964400Z",
     "iopub.status.idle": "2020-10-17T03:14:14.014391Z",
     "shell.execute_reply": "2020-10-17T03:14:14.015103Z"
    },
    "papermill": {
     "duration": 0.101878,
     "end_time": "2020-10-17T03:14:14.015299",
     "exception": false,
     "start_time": "2020-10-17T03:14:13.913421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first drop 71\n",
      "shape after 1st drop: (21948, 332)\n",
      "331\n"
     ]
    }
   ],
   "source": [
    "non_target_feats = [i for i in non_targets.columns if i != \"sig_id\"]\n",
    "nontarget_dists = pd.DataFrame(np.sum(non_targets[non_target_feats])).reset_index(drop=False)\n",
    "nontarget_dists.columns = [\"target\", \"number\"]\n",
    "nontarget_dists = nontarget_dists.sort_values(\"number\", ascending=False).reset_index(drop=True)\n",
    "drop_list1 = list(nontarget_dists[nontarget_dists.number==0][\"target\"].values)\n",
    "print(\"first drop\", len(drop_list1))\n",
    "non_targets.drop(drop_list1, axis=1, inplace=True)\n",
    "print(\"shape after 1st drop:\", non_targets.shape)\n",
    "non_target_feats = [i for i in non_targets.columns if i != \"sig_id\"]\n",
    "print(len(non_target_feats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016346,
     "end_time": "2020-10-17T03:14:14.049545",
     "exception": false,
     "start_time": "2020-10-17T03:14:14.033199",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-17T03:14:14.085532Z",
     "iopub.status.busy": "2020-10-17T03:14:14.084613Z",
     "iopub.status.idle": "2020-10-17T03:14:23.263087Z",
     "shell.execute_reply": "2020-10-17T03:14:23.262533Z"
    },
    "papermill": {
     "duration": 9.197468,
     "end_time": "2020-10-17T03:14:23.263203",
     "exception": false,
     "start_time": "2020-10-17T03:14:14.065735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rank gauss\n",
    "for i in c_feats + g_feats:\n",
    "    ss = preprocessing.QuantileTransformer(n_quantiles=100, random_state=0, output_distribution=\"normal\") #確かに正規分布っぽくなっている。\n",
    "    \n",
    "    vec_len = len(train[i].values)\n",
    "    vec_len_test = len(test[i].values)\n",
    "    raw_vec = train[i].values.reshape(vec_len, 1)\n",
    "    ss.fit(raw_vec)\n",
    "\n",
    "    train[i] = ss.transform(raw_vec).reshape(1, vec_len)[0]\n",
    "    test[i] = ss.transform(test[i].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-17T03:14:23.318316Z",
     "iopub.status.busy": "2020-10-17T03:14:23.317154Z",
     "iopub.status.idle": "2020-10-17T03:14:25.366380Z",
     "shell.execute_reply": "2020-10-17T03:14:25.365810Z"
    },
    "papermill": {
     "duration": 2.086342,
     "end_time": "2020-10-17T03:14:25.366488",
     "exception": false,
     "start_time": "2020-10-17T03:14:23.280146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num = 10\n",
    "pca_c_cols = [\"pca-c\"+str(i+1) for i in range(num)]\n",
    "pca = PCA(n_components=num,random_state=42)\n",
    "c_train = pca.fit_transform(train[c_feats])\n",
    "c_test = pca.transform(test[c_feats])\n",
    "c_train = pd.DataFrame(c_train, columns=pca_c_cols)\n",
    "c_test = pd.DataFrame(c_test, columns=pca_c_cols)\n",
    "\n",
    "num = 40\n",
    "pca_g_cols = [\"pca-g\"+str(i+1) for i in range(num)]\n",
    "pca = PCA(n_components=num, random_state=42)\n",
    "g_train = pca.fit_transform(train[g_feats])\n",
    "g_test = pca.transform(test[g_feats])\n",
    "g_train = pd.DataFrame(g_train, columns=pca_g_cols)\n",
    "g_test = pd.DataFrame(g_test, columns=pca_g_cols)\n",
    "\n",
    "train = pd.concat([train, c_train],axis=1)\n",
    "test = pd.concat([test, c_test],axis=1)\n",
    "train = pd.concat([train, g_train],axis=1)\n",
    "test = pd.concat([test, g_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-17T03:14:25.457422Z",
     "iopub.status.busy": "2020-10-17T03:14:25.455958Z",
     "iopub.status.idle": "2020-10-17T03:14:25.917599Z",
     "shell.execute_reply": "2020-10-17T03:14:25.918139Z"
    },
    "papermill": {
     "duration": 0.534989,
     "end_time": "2020-10-17T03:14:25.918299",
     "exception": false,
     "start_time": "2020-10-17T03:14:25.383310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.iloc[:,4:].copy().values\n",
    "select = VarianceThreshold(threshold=0.5)\n",
    "X_new = select.fit_transform(X)\n",
    "drop_feats = list(np.array(train.iloc[:,4:].columns)[select.get_support()==False])\n",
    "len(drop_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-17T03:14:25.965866Z",
     "iopub.status.busy": "2020-10-17T03:14:25.964660Z",
     "iopub.status.idle": "2020-10-17T03:14:26.438898Z",
     "shell.execute_reply": "2020-10-17T03:14:26.438373Z"
    },
    "papermill": {
     "duration": 0.499853,
     "end_time": "2020-10-17T03:14:26.439010",
     "exception": false,
     "start_time": "2020-10-17T03:14:25.939157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 927) (3982, 927)\n"
     ]
    }
   ],
   "source": [
    "def fe(df):\n",
    "    tmp = df.copy()\n",
    "    #tmp['g_sum'] = tmp[g_feats].sum(axis = 1)\n",
    "    #tmp['g_mean'] = tmp[g_feats].mean(axis = 1)\n",
    "    #tmp['g_std'] = tmp[g_feats].std(axis = 1)\n",
    "    #tmp['g_kurt'] = tmp[g_feats].kurtosis(axis = 1)\n",
    "    #tmp['g_skew'] = tmp[g_feats].skew(axis = 1)\n",
    "    #tmp['c_sum'] = tmp[c_feats].sum(axis = 1)\n",
    "    #tmp['c_mean'] = tmp[c_feats].mean(axis = 1)\n",
    "    #tmp['c_std'] = tmp[c_feats].std(axis = 1)\n",
    "    #tmp['c_kurt'] = tmp[c_feats].kurtosis(axis = 1)\n",
    "    #tmp['c_skew'] = tmp[c_feats].skew(axis = 1)\n",
    "    #tmp['gc_sum'] = tmp[c_feats + g_feats].sum(axis = 1)\n",
    "    #tmp['gc_mean'] = tmp[c_feats + g_feats].mean(axis = 1)\n",
    "    #tmp['gc_std'] = tmp[c_feats + g_feats].std(axis = 1)\n",
    "    #tmp['gc_kurt'] = tmp[c_feats + g_feats].kurtosis(axis = 1)\n",
    "    #tmp['gc_skew'] = tmp[c_feats + g_feats].skew(axis = 1)\n",
    "    #tmp.loc[:, 'cp_type'] = tmp.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    #tmp.loc[:, 'cp_dose'] = tmp.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "    tmp = pd.get_dummies(tmp, columns=['cp_time','cp_dose'])\n",
    "        \n",
    "    tmp.drop([\"cp_type\", \"sig_id\"], axis=1, inplace=True)\n",
    "    return tmp\n",
    "\n",
    "train = fe(train).to_numpy()\n",
    "test = fe(test).to_numpy()\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-17T03:14:26.501128Z",
     "iopub.status.busy": "2020-10-17T03:14:26.499566Z",
     "iopub.status.idle": "2020-10-17T03:14:26.550427Z",
     "shell.execute_reply": "2020-10-17T03:14:26.549880Z"
    },
    "papermill": {
     "duration": 0.093825,
     "end_time": "2020-10-17T03:14:26.550547",
     "exception": false,
     "start_time": "2020-10-17T03:14:26.456722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fn_train = train.copy().to_numpy()\n",
    "#fn_test = test.copy().to_numpy()\n",
    "\n",
    "#ss = preprocessing.RobustScaler()\n",
    "#fn_train= ss.fit_transform(fn_train)\n",
    "#fn_test = ss.transform(fn_test)\n",
    "\n",
    "fn_non_targets = non_targets.drop(\"sig_id\", axis=1).copy().to_numpy()\n",
    "fn_targets = targets.drop(\"sig_id\", axis=1).copy().to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01795,
     "end_time": "2020-10-17T03:14:26.586672",
     "exception": false,
     "start_time": "2020-10-17T03:14:26.568722",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-17T03:14:27.026585Z",
     "iopub.status.busy": "2020-10-17T03:14:27.024892Z",
     "iopub.status.idle": "2020-10-17T03:14:27.038314Z",
     "shell.execute_reply": "2020-10-17T03:14:27.037561Z"
    },
    "papermill": {
     "duration": 0.433542,
     "end_time": "2020-10-17T03:14:27.038443",
     "exception": false,
     "start_time": "2020-10-17T03:14:26.604901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "def mean_log_loss(y_true, y_pred):\n",
    "    metrics = []\n",
    "    for i, target in enumerate(target_feats):\n",
    "        metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float), labels=[0,1]))\n",
    "    return np.mean(metrics)\n",
    "\n",
    "def seed_everything(seed=42): \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "class MoaModel(nn.Module):\n",
    "    def __init__(self, num_columns, last_num):\n",
    "        super(MoaModel, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_columns)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_columns, 1024))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(1024)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(1024,1024))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(1024)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(1024, last_num))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.034011,
     "end_time": "2020-10-17T03:14:27.104270",
     "exception": false,
     "start_time": "2020-10-17T03:14:27.070259",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-17T03:14:27.168214Z",
     "iopub.status.busy": "2020-10-17T03:14:27.167220Z",
     "iopub.status.idle": "2020-10-17T03:14:27.225734Z",
     "shell.execute_reply": "2020-10-17T03:14:27.225037Z"
    },
    "papermill": {
     "duration": 0.096159,
     "end_time": "2020-10-17T03:14:27.225875",
     "exception": false,
     "start_time": "2020-10-17T03:14:27.129716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_folds=5\n",
    "EARLY_STOPPING_STEPS = 25\n",
    "train_epochs = 25\n",
    "\n",
    "def modelling_torch(tr, target, te, sample_seed, init_num, last_num):\n",
    "    seed_everything(seed=sample_seed) \n",
    "    X_train = tr.copy()\n",
    "    y_train = target.copy()\n",
    "    X_test = te.copy()\n",
    "    test_len = X_test.shape[0]\n",
    "    \n",
    "    mskf=MultilabelStratifiedKFold(n_splits = n_folds, shuffle=True, random_state=224)\n",
    "\n",
    "    models = []\n",
    "    \n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    X_test = torch.utils.data.TensorDataset(X_test) \n",
    "    test_loader = torch.utils.data.DataLoader(X_test, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    oof = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    oof_targets = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    pred_value = np.zeros([test_len, y_train.shape[1]])\n",
    "    scores = []\n",
    "    for fold, (train_index, valid_index) in enumerate(mskf.split(X_train, y_train)):\n",
    "        print(\"Fold \"+str(fold+1))\n",
    "        X_train2 = torch.tensor(X_train[train_index,:], dtype=torch.float32)\n",
    "        y_train2 = torch.tensor(y_train[train_index], dtype=torch.float32)\n",
    "\n",
    "        X_valid2 = torch.tensor(X_train[valid_index,:], dtype=torch.float32)\n",
    "        y_valid2 = torch.tensor(y_train[valid_index], dtype=torch.float32)\n",
    "        \n",
    "        train = torch.utils.data.TensorDataset(X_train2, y_train2)\n",
    "        valid = torch.utils.data.TensorDataset(X_valid2, y_valid2)\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True) \n",
    "        valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "            \n",
    "        clf = MoaModel(init_num, last_num)\n",
    "        loss_fn = torch.nn.BCEWithLogitsLoss() \n",
    "\n",
    "        optimizer = optim.Adam(clf.parameters(), lr = 0.001, weight_decay=1e-5) \n",
    "        #lookahead = Lookahead(optimizer, k=10, alpha=0.6) #lookahead\n",
    "        #scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, eps=1e-4, verbose=True)\n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e1, \n",
    "                                              max_lr=1e-2, epochs=25, steps_per_epoch=len(train_loader))\n",
    "        \n",
    "        clf.to(device)\n",
    "        \n",
    "        best_val_loss = np.inf\n",
    "        stop_counts = 0\n",
    "        for epoch in range(train_epochs):\n",
    "            start_time = time.time()\n",
    "            clf.train()\n",
    "            avg_loss = 0.\n",
    "            for x_batch, y_batch in tqdm(train_loader, disable=True):\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch) \n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                avg_loss += loss.item() / len(train_loader)        \n",
    "            \n",
    "            clf.eval()\n",
    "            avg_val_loss = 0.\n",
    "            for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch).detach()\n",
    "                avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "        \n",
    "            elapsed_time = time.time() - start_time \n",
    "            scheduler.step(avg_val_loss)\n",
    "                    \n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                print('Best model: Epoch {} \\t loss={:.6f} \\t val_loss={:.6f} \\t time={:.2f}s'.format(\n",
    "                    epoch + 1, avg_loss, avg_val_loss, elapsed_time))\n",
    "                torch.save(clf.state_dict(), 'best-model-parameters.pt')\n",
    "            else:\n",
    "                stop_counts += 1\n",
    "        \n",
    "            #if stop_counts >= EARLY_STOPPING_STEPS: \n",
    "            #    break\n",
    "        pred_model = MoaModel(init_num, last_num)\n",
    "        pred_model.load_state_dict(torch.load('best-model-parameters.pt'))         \n",
    "        pred_model.eval()\n",
    "        \n",
    "        # validation check ----------------\n",
    "        oof_epoch = np.zeros([X_valid2.size(0), y_train.shape[1]])\n",
    "        target_epoch = np.zeros([X_valid2.size(0), y_train.shape[1]])\n",
    "        for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "                y_pred = pred_model(x_batch).sigmoid().detach()\n",
    "                oof_epoch[i * batch_size:(i+1) * batch_size,:] = y_pred.cpu().numpy()\n",
    "                target_epoch[i * batch_size:(i+1) * batch_size,:] = y_batch.cpu().numpy()\n",
    "        print(\"Fold {} log loss: {}\".format(fold+1, mean_log_loss(target_epoch, oof_epoch)))\n",
    "        scores.append(mean_log_loss(target_epoch, oof_epoch))\n",
    "        oof[valid_index,:] = oof_epoch\n",
    "        oof_targets[valid_index,:] = target_epoch\n",
    "        #-----------------------------------\n",
    "        \n",
    "        # test predcition --------------\n",
    "        test_preds = np.zeros([test_len, y_train.shape[1]])\n",
    "        for i, (x_batch,) in enumerate(test_loader): \n",
    "            y_pred = pred_model(x_batch).sigmoid().detach()\n",
    "            test_preds[i * batch_size:(i+1) * batch_size, :] = y_pred.cpu().numpy()\n",
    "        pred_value += test_preds / n_folds\n",
    "        # ------------------------------\n",
    "        \n",
    "    print(\"Seed {}\".format(seed_))\n",
    "    for i, ele in enumerate(scores):\n",
    "        print(\"Fold {} log loss: {}\".format(i+1, scores[i]))\n",
    "    print(\"Std of log loss: {}\".format(np.std(scores)))\n",
    "    print(\"Total log loss: {}\".format(mean_log_loss(oof_targets, oof)))\n",
    "    \n",
    "    return oof, oof_targets, pred_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-17T03:14:27.292506Z",
     "iopub.status.busy": "2020-10-17T03:14:27.291572Z",
     "iopub.status.idle": "2020-10-17T03:22:50.023311Z",
     "shell.execute_reply": "2020-10-17T03:22:50.022081Z"
    },
    "papermill": {
     "duration": 502.770035,
     "end_time": "2020-10-17T03:22:50.023458",
     "exception": false,
     "start_time": "2020-10-17T03:14:27.253423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.410298 \t val_loss=0.080772 \t time=1.76s\n",
      "Best model: Epoch 2 \t loss=0.045649 \t val_loss=0.027791 \t time=0.85s\n",
      "Best model: Epoch 3 \t loss=0.026340 \t val_loss=0.022323 \t time=0.89s\n",
      "Best model: Epoch 4 \t loss=0.022533 \t val_loss=0.020522 \t time=0.97s\n",
      "Best model: Epoch 5 \t loss=0.020916 \t val_loss=0.019512 \t time=1.47s\n",
      "Best model: Epoch 6 \t loss=0.020083 \t val_loss=0.018881 \t time=1.06s\n",
      "Best model: Epoch 7 \t loss=0.019489 \t val_loss=0.018548 \t time=0.86s\n",
      "Best model: Epoch 8 \t loss=0.018890 \t val_loss=0.018123 \t time=0.82s\n",
      "Best model: Epoch 9 \t loss=0.018482 \t val_loss=0.017825 \t time=0.88s\n",
      "Best model: Epoch 10 \t loss=0.017990 \t val_loss=0.017534 \t time=0.81s\n",
      "Best model: Epoch 11 \t loss=0.017523 \t val_loss=0.017194 \t time=0.80s\n",
      "Best model: Epoch 12 \t loss=0.017161 \t val_loss=0.017091 \t time=0.80s\n",
      "Best model: Epoch 13 \t loss=0.016895 \t val_loss=0.016929 \t time=0.82s\n",
      "Best model: Epoch 14 \t loss=0.016614 \t val_loss=0.016768 \t time=0.79s\n",
      "Best model: Epoch 15 \t loss=0.016292 \t val_loss=0.016699 \t time=1.04s\n",
      "Best model: Epoch 16 \t loss=0.015927 \t val_loss=0.016669 \t time=0.82s\n",
      "Best model: Epoch 17 \t loss=0.015766 \t val_loss=0.016537 \t time=0.81s\n",
      "Best model: Epoch 18 \t loss=0.015473 \t val_loss=0.016499 \t time=0.80s\n",
      "Best model: Epoch 19 \t loss=0.015260 \t val_loss=0.016462 \t time=0.85s\n",
      "Best model: Epoch 20 \t loss=0.014936 \t val_loss=0.016383 \t time=0.80s\n",
      "Best model: Epoch 21 \t loss=0.014748 \t val_loss=0.016299 \t time=0.83s\n",
      "Fold 1 log loss: 0.016308156634613682\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.412353 \t val_loss=0.076791 \t time=1.08s\n",
      "Best model: Epoch 2 \t loss=0.046601 \t val_loss=0.027338 \t time=0.82s\n",
      "Best model: Epoch 3 \t loss=0.026250 \t val_loss=0.022171 \t time=0.82s\n",
      "Best model: Epoch 4 \t loss=0.022396 \t val_loss=0.020495 \t time=0.85s\n",
      "Best model: Epoch 5 \t loss=0.021266 \t val_loss=0.019795 \t time=0.84s\n",
      "Best model: Epoch 6 \t loss=0.020019 \t val_loss=0.019064 \t time=0.85s\n",
      "Best model: Epoch 7 \t loss=0.019336 \t val_loss=0.018647 \t time=0.84s\n",
      "Best model: Epoch 8 \t loss=0.018857 \t val_loss=0.018412 \t time=0.82s\n",
      "Best model: Epoch 9 \t loss=0.018377 \t val_loss=0.017858 \t time=0.82s\n",
      "Best model: Epoch 10 \t loss=0.017955 \t val_loss=0.017655 \t time=0.82s\n",
      "Best model: Epoch 11 \t loss=0.017601 \t val_loss=0.017372 \t time=0.81s\n",
      "Best model: Epoch 12 \t loss=0.017340 \t val_loss=0.017197 \t time=0.85s\n",
      "Best model: Epoch 13 \t loss=0.016990 \t val_loss=0.017024 \t time=0.99s\n",
      "Best model: Epoch 14 \t loss=0.016761 \t val_loss=0.016884 \t time=0.89s\n",
      "Best model: Epoch 15 \t loss=0.016468 \t val_loss=0.016717 \t time=1.06s\n",
      "Best model: Epoch 17 \t loss=0.015914 \t val_loss=0.016538 \t time=0.79s\n",
      "Best model: Epoch 19 \t loss=0.015397 \t val_loss=0.016455 \t time=0.80s\n",
      "Best model: Epoch 20 \t loss=0.015047 \t val_loss=0.016354 \t time=0.81s\n",
      "Best model: Epoch 23 \t loss=0.014580 \t val_loss=0.016284 \t time=0.79s\n",
      "Fold 2 log loss: 0.016264682888657987\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.415237 \t val_loss=0.082686 \t time=0.82s\n",
      "Best model: Epoch 2 \t loss=0.046781 \t val_loss=0.028371 \t time=0.80s\n",
      "Best model: Epoch 3 \t loss=0.026286 \t val_loss=0.022133 \t time=0.81s\n",
      "Best model: Epoch 4 \t loss=0.022457 \t val_loss=0.020459 \t time=0.79s\n",
      "Best model: Epoch 5 \t loss=0.020937 \t val_loss=0.019433 \t time=0.79s\n",
      "Best model: Epoch 6 \t loss=0.020033 \t val_loss=0.018813 \t time=0.79s\n",
      "Best model: Epoch 8 \t loss=0.018928 \t val_loss=0.018074 \t time=0.82s\n",
      "Best model: Epoch 9 \t loss=0.018517 \t val_loss=0.017725 \t time=0.83s\n",
      "Best model: Epoch 11 \t loss=0.017881 \t val_loss=0.017279 \t time=0.81s\n",
      "Best model: Epoch 12 \t loss=0.017321 \t val_loss=0.017043 \t time=1.11s\n",
      "Best model: Epoch 13 \t loss=0.017052 \t val_loss=0.016822 \t time=1.09s\n",
      "Best model: Epoch 14 \t loss=0.016702 \t val_loss=0.016620 \t time=1.18s\n",
      "Best model: Epoch 15 \t loss=0.016449 \t val_loss=0.016561 \t time=0.91s\n",
      "Best model: Epoch 16 \t loss=0.016163 \t val_loss=0.016456 \t time=0.87s\n",
      "Best model: Epoch 17 \t loss=0.015866 \t val_loss=0.016322 \t time=0.85s\n",
      "Best model: Epoch 18 \t loss=0.015562 \t val_loss=0.016190 \t time=0.86s\n",
      "Best model: Epoch 20 \t loss=0.015061 \t val_loss=0.016179 \t time=0.82s\n",
      "Best model: Epoch 21 \t loss=0.014875 \t val_loss=0.016153 \t time=0.90s\n",
      "Best model: Epoch 23 \t loss=0.014475 \t val_loss=0.016109 \t time=1.26s\n",
      "Fold 3 log loss: 0.016241931914069724\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.410151 \t val_loss=0.077184 \t time=0.80s\n",
      "Best model: Epoch 2 \t loss=0.046506 \t val_loss=0.027823 \t time=0.82s\n",
      "Best model: Epoch 3 \t loss=0.026374 \t val_loss=0.022342 \t time=0.81s\n",
      "Best model: Epoch 4 \t loss=0.022527 \t val_loss=0.020624 \t time=0.79s\n",
      "Best model: Epoch 5 \t loss=0.021031 \t val_loss=0.019755 \t time=0.80s\n",
      "Best model: Epoch 6 \t loss=0.020114 \t val_loss=0.019162 \t time=0.82s\n",
      "Best model: Epoch 7 \t loss=0.019410 \t val_loss=0.018668 \t time=0.80s\n",
      "Best model: Epoch 8 \t loss=0.018781 \t val_loss=0.018410 \t time=1.00s\n",
      "Best model: Epoch 9 \t loss=0.018435 \t val_loss=0.018019 \t time=0.83s\n",
      "Best model: Epoch 10 \t loss=0.018148 \t val_loss=0.017663 \t time=0.79s\n",
      "Best model: Epoch 11 \t loss=0.017771 \t val_loss=0.017522 \t time=0.79s\n",
      "Best model: Epoch 12 \t loss=0.017437 \t val_loss=0.017166 \t time=0.78s\n",
      "Best model: Epoch 13 \t loss=0.017099 \t val_loss=0.017105 \t time=0.80s\n",
      "Best model: Epoch 14 \t loss=0.016721 \t val_loss=0.016755 \t time=0.79s\n",
      "Best model: Epoch 15 \t loss=0.016411 \t val_loss=0.016590 \t time=0.86s\n",
      "Best model: Epoch 17 \t loss=0.015736 \t val_loss=0.016389 \t time=0.80s\n",
      "Best model: Epoch 19 \t loss=0.015304 \t val_loss=0.016283 \t time=0.78s\n",
      "Best model: Epoch 21 \t loss=0.014855 \t val_loss=0.016228 \t time=1.03s\n",
      "Best model: Epoch 22 \t loss=0.014638 \t val_loss=0.016219 \t time=0.86s\n",
      "Best model: Epoch 25 \t loss=0.014069 \t val_loss=0.016180 \t time=0.78s\n",
      "Fold 4 log loss: 0.01621930791184349\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.416540 \t val_loss=0.078957 \t time=0.79s\n",
      "Best model: Epoch 2 \t loss=0.046997 \t val_loss=0.027746 \t time=0.80s\n",
      "Best model: Epoch 3 \t loss=0.026057 \t val_loss=0.022268 \t time=0.80s\n",
      "Best model: Epoch 4 \t loss=0.022434 \t val_loss=0.020731 \t time=0.81s\n",
      "Best model: Epoch 5 \t loss=0.020983 \t val_loss=0.019547 \t time=0.82s\n",
      "Best model: Epoch 6 \t loss=0.020010 \t val_loss=0.018948 \t time=0.80s\n",
      "Best model: Epoch 7 \t loss=0.019543 \t val_loss=0.018600 \t time=1.52s\n",
      "Best model: Epoch 8 \t loss=0.018825 \t val_loss=0.018223 \t time=0.79s\n",
      "Best model: Epoch 9 \t loss=0.018384 \t val_loss=0.017915 \t time=0.78s\n",
      "Best model: Epoch 10 \t loss=0.017946 \t val_loss=0.017725 \t time=0.81s\n",
      "Best model: Epoch 11 \t loss=0.017715 \t val_loss=0.017429 \t time=0.78s\n",
      "Best model: Epoch 12 \t loss=0.017349 \t val_loss=0.017297 \t time=0.83s\n",
      "Best model: Epoch 13 \t loss=0.016984 \t val_loss=0.016987 \t time=0.81s\n",
      "Best model: Epoch 14 \t loss=0.016670 \t val_loss=0.016872 \t time=0.82s\n",
      "Best model: Epoch 15 \t loss=0.016413 \t val_loss=0.016693 \t time=0.81s\n",
      "Best model: Epoch 16 \t loss=0.016055 \t val_loss=0.016637 \t time=0.81s\n",
      "Best model: Epoch 17 \t loss=0.015766 \t val_loss=0.016481 \t time=0.81s\n",
      "Best model: Epoch 18 \t loss=0.015431 \t val_loss=0.016424 \t time=0.80s\n",
      "Best model: Epoch 20 \t loss=0.015049 \t val_loss=0.016332 \t time=0.92s\n",
      "Best model: Epoch 21 \t loss=0.014789 \t val_loss=0.016279 \t time=0.83s\n",
      "Fold 5 log loss: 0.01636123622382052\n",
      "Seed 0\n",
      "Fold 1 log loss: 0.016308156634613682\n",
      "Fold 2 log loss: 0.016264682888657987\n",
      "Fold 3 log loss: 0.016241931914069724\n",
      "Fold 4 log loss: 0.01621930791184349\n",
      "Fold 5 log loss: 0.01636123622382052\n",
      "Std of log loss: 5.050753209807144e-05\n",
      "Total log loss: 0.016279065461576956\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.413565 \t val_loss=0.079203 \t time=0.98s\n",
      "Best model: Epoch 2 \t loss=0.047043 \t val_loss=0.027529 \t time=1.26s\n",
      "Best model: Epoch 3 \t loss=0.026043 \t val_loss=0.022633 \t time=0.80s\n",
      "Best model: Epoch 4 \t loss=0.022640 \t val_loss=0.020618 \t time=0.82s\n",
      "Best model: Epoch 5 \t loss=0.020906 \t val_loss=0.019549 \t time=0.84s\n",
      "Best model: Epoch 6 \t loss=0.020205 \t val_loss=0.018893 \t time=0.83s\n",
      "Best model: Epoch 7 \t loss=0.019505 \t val_loss=0.018458 \t time=0.87s\n",
      "Best model: Epoch 8 \t loss=0.018887 \t val_loss=0.018235 \t time=0.80s\n",
      "Best model: Epoch 9 \t loss=0.018466 \t val_loss=0.017804 \t time=0.82s\n",
      "Best model: Epoch 10 \t loss=0.017993 \t val_loss=0.017756 \t time=0.83s\n",
      "Best model: Epoch 11 \t loss=0.017731 \t val_loss=0.017373 \t time=0.78s\n",
      "Best model: Epoch 13 \t loss=0.017093 \t val_loss=0.017068 \t time=0.84s\n",
      "Best model: Epoch 14 \t loss=0.016708 \t val_loss=0.016987 \t time=1.52s\n",
      "Best model: Epoch 15 \t loss=0.016450 \t val_loss=0.016753 \t time=0.84s\n",
      "Best model: Epoch 16 \t loss=0.016177 \t val_loss=0.016675 \t time=0.79s\n",
      "Best model: Epoch 17 \t loss=0.016139 \t val_loss=0.016626 \t time=0.82s\n",
      "Best model: Epoch 18 \t loss=0.015712 \t val_loss=0.016524 \t time=0.81s\n",
      "Best model: Epoch 19 \t loss=0.015451 \t val_loss=0.016462 \t time=0.81s\n",
      "Best model: Epoch 21 \t loss=0.015001 \t val_loss=0.016456 \t time=0.79s\n",
      "Best model: Epoch 22 \t loss=0.014784 \t val_loss=0.016437 \t time=0.79s\n",
      "Best model: Epoch 23 \t loss=0.014574 \t val_loss=0.016412 \t time=0.80s\n",
      "Best model: Epoch 24 \t loss=0.014332 \t val_loss=0.016390 \t time=0.79s\n",
      "Best model: Epoch 25 \t loss=0.014205 \t val_loss=0.016339 \t time=0.80s\n",
      "Fold 1 log loss: 0.01633832523140075\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.411380 \t val_loss=0.078054 \t time=0.81s\n",
      "Best model: Epoch 2 \t loss=0.046458 \t val_loss=0.027754 \t time=0.81s\n",
      "Best model: Epoch 3 \t loss=0.026364 \t val_loss=0.022365 \t time=0.81s\n",
      "Best model: Epoch 4 \t loss=0.022551 \t val_loss=0.020385 \t time=0.84s\n",
      "Best model: Epoch 5 \t loss=0.021018 \t val_loss=0.019676 \t time=0.82s\n",
      "Best model: Epoch 6 \t loss=0.020010 \t val_loss=0.018921 \t time=0.82s\n",
      "Best model: Epoch 7 \t loss=0.019245 \t val_loss=0.018520 \t time=0.81s\n",
      "Best model: Epoch 8 \t loss=0.018883 \t val_loss=0.018336 \t time=0.82s\n",
      "Best model: Epoch 9 \t loss=0.018625 \t val_loss=0.018085 \t time=0.80s\n",
      "Best model: Epoch 10 \t loss=0.018086 \t val_loss=0.017729 \t time=0.82s\n",
      "Best model: Epoch 11 \t loss=0.017611 \t val_loss=0.017464 \t time=0.81s\n",
      "Best model: Epoch 12 \t loss=0.017331 \t val_loss=0.017240 \t time=1.06s\n",
      "Best model: Epoch 13 \t loss=0.016950 \t val_loss=0.017046 \t time=0.89s\n",
      "Best model: Epoch 14 \t loss=0.016606 \t val_loss=0.016882 \t time=0.87s\n",
      "Best model: Epoch 15 \t loss=0.016336 \t val_loss=0.016791 \t time=0.85s\n",
      "Best model: Epoch 16 \t loss=0.016034 \t val_loss=0.016660 \t time=0.83s\n",
      "Best model: Epoch 17 \t loss=0.015695 \t val_loss=0.016562 \t time=0.80s\n",
      "Best model: Epoch 18 \t loss=0.015570 \t val_loss=0.016512 \t time=0.82s\n",
      "Best model: Epoch 19 \t loss=0.015325 \t val_loss=0.016469 \t time=0.81s\n",
      "Best model: Epoch 20 \t loss=0.015017 \t val_loss=0.016448 \t time=0.85s\n",
      "Best model: Epoch 21 \t loss=0.014787 \t val_loss=0.016412 \t time=0.81s\n",
      "Best model: Epoch 22 \t loss=0.014602 \t val_loss=0.016399 \t time=0.82s\n",
      "Best model: Epoch 23 \t loss=0.014453 \t val_loss=0.016372 \t time=0.98s\n",
      "Best model: Epoch 24 \t loss=0.014186 \t val_loss=0.016329 \t time=1.17s\n",
      "Best model: Epoch 25 \t loss=0.014028 \t val_loss=0.016313 \t time=0.93s\n",
      "Fold 2 log loss: 0.01629256070000529\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.414592 \t val_loss=0.073585 \t time=0.80s\n",
      "Best model: Epoch 2 \t loss=0.046609 \t val_loss=0.026290 \t time=0.82s\n",
      "Best model: Epoch 3 \t loss=0.025868 \t val_loss=0.021966 \t time=0.79s\n",
      "Best model: Epoch 4 \t loss=0.022540 \t val_loss=0.020608 \t time=0.80s\n",
      "Best model: Epoch 5 \t loss=0.020991 \t val_loss=0.019712 \t time=0.82s\n",
      "Best model: Epoch 6 \t loss=0.020063 \t val_loss=0.018747 \t time=0.80s\n",
      "Best model: Epoch 7 \t loss=0.019208 \t val_loss=0.018330 \t time=0.79s\n",
      "Best model: Epoch 8 \t loss=0.018813 \t val_loss=0.017992 \t time=0.80s\n",
      "Best model: Epoch 9 \t loss=0.018357 \t val_loss=0.017607 \t time=0.80s\n",
      "Best model: Epoch 10 \t loss=0.017883 \t val_loss=0.017330 \t time=1.05s\n",
      "Best model: Epoch 12 \t loss=0.017517 \t val_loss=0.017041 \t time=0.80s\n",
      "Best model: Epoch 13 \t loss=0.017023 \t val_loss=0.016743 \t time=0.86s\n",
      "Best model: Epoch 14 \t loss=0.016620 \t val_loss=0.016693 \t time=0.85s\n",
      "Best model: Epoch 15 \t loss=0.016435 \t val_loss=0.016501 \t time=0.83s\n",
      "Best model: Epoch 16 \t loss=0.016179 \t val_loss=0.016398 \t time=0.86s\n",
      "Best model: Epoch 17 \t loss=0.015869 \t val_loss=0.016377 \t time=1.00s\n",
      "Best model: Epoch 18 \t loss=0.015634 \t val_loss=0.016230 \t time=0.86s\n",
      "Best model: Epoch 19 \t loss=0.015331 \t val_loss=0.016227 \t time=0.81s\n",
      "Best model: Epoch 20 \t loss=0.015204 \t val_loss=0.016213 \t time=0.83s\n",
      "Best model: Epoch 22 \t loss=0.014690 \t val_loss=0.016135 \t time=1.10s\n",
      "Best model: Epoch 23 \t loss=0.014516 \t val_loss=0.016103 \t time=0.79s\n",
      "Fold 3 log loss: 0.016243214613729896\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.413880 \t val_loss=0.078257 \t time=0.83s\n",
      "Best model: Epoch 2 \t loss=0.046372 \t val_loss=0.026810 \t time=0.85s\n",
      "Best model: Epoch 3 \t loss=0.026184 \t val_loss=0.022476 \t time=0.82s\n",
      "Best model: Epoch 4 \t loss=0.022488 \t val_loss=0.020394 \t time=0.92s\n",
      "Best model: Epoch 5 \t loss=0.020864 \t val_loss=0.019649 \t time=1.02s\n",
      "Best model: Epoch 6 \t loss=0.019967 \t val_loss=0.018999 \t time=0.78s\n",
      "Best model: Epoch 7 \t loss=0.019291 \t val_loss=0.018621 \t time=1.06s\n",
      "Best model: Epoch 8 \t loss=0.018783 \t val_loss=0.018166 \t time=0.82s\n",
      "Best model: Epoch 9 \t loss=0.018374 \t val_loss=0.017978 \t time=0.81s\n",
      "Best model: Epoch 10 \t loss=0.018022 \t val_loss=0.017547 \t time=0.80s\n",
      "Best model: Epoch 11 \t loss=0.017685 \t val_loss=0.017366 \t time=0.81s\n",
      "Best model: Epoch 12 \t loss=0.017296 \t val_loss=0.017087 \t time=0.80s\n",
      "Best model: Epoch 13 \t loss=0.016948 \t val_loss=0.016877 \t time=0.81s\n",
      "Best model: Epoch 14 \t loss=0.016618 \t val_loss=0.016707 \t time=0.84s\n",
      "Best model: Epoch 15 \t loss=0.016282 \t val_loss=0.016599 \t time=0.80s\n",
      "Best model: Epoch 16 \t loss=0.016083 \t val_loss=0.016554 \t time=0.81s\n",
      "Best model: Epoch 17 \t loss=0.015756 \t val_loss=0.016383 \t time=0.79s\n",
      "Best model: Epoch 19 \t loss=0.015173 \t val_loss=0.016344 \t time=0.79s\n",
      "Best model: Epoch 20 \t loss=0.015004 \t val_loss=0.016292 \t time=1.07s\n",
      "Best model: Epoch 22 \t loss=0.014551 \t val_loss=0.016210 \t time=0.81s\n",
      "Fold 4 log loss: 0.016248327694534097\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.415158 \t val_loss=0.079629 \t time=0.81s\n",
      "Best model: Epoch 2 \t loss=0.045922 \t val_loss=0.028119 \t time=0.80s\n",
      "Best model: Epoch 3 \t loss=0.026283 \t val_loss=0.022327 \t time=0.79s\n",
      "Best model: Epoch 4 \t loss=0.022708 \t val_loss=0.020788 \t time=0.81s\n",
      "Best model: Epoch 5 \t loss=0.021035 \t val_loss=0.019580 \t time=0.81s\n",
      "Best model: Epoch 6 \t loss=0.019973 \t val_loss=0.018991 \t time=1.04s\n",
      "Best model: Epoch 7 \t loss=0.019231 \t val_loss=0.018430 \t time=0.79s\n",
      "Best model: Epoch 8 \t loss=0.018718 \t val_loss=0.018113 \t time=0.81s\n",
      "Best model: Epoch 9 \t loss=0.018379 \t val_loss=0.017772 \t time=0.80s\n",
      "Best model: Epoch 10 \t loss=0.018013 \t val_loss=0.017609 \t time=0.81s\n",
      "Best model: Epoch 11 \t loss=0.017519 \t val_loss=0.017382 \t time=0.84s\n",
      "Best model: Epoch 12 \t loss=0.017244 \t val_loss=0.017176 \t time=0.81s\n",
      "Best model: Epoch 13 \t loss=0.016863 \t val_loss=0.016973 \t time=0.80s\n",
      "Best model: Epoch 14 \t loss=0.016540 \t val_loss=0.016916 \t time=0.86s\n",
      "Best model: Epoch 15 \t loss=0.016264 \t val_loss=0.016671 \t time=1.16s\n",
      "Best model: Epoch 16 \t loss=0.016045 \t val_loss=0.016513 \t time=0.83s\n",
      "Best model: Epoch 18 \t loss=0.015472 \t val_loss=0.016422 \t time=0.99s\n",
      "Best model: Epoch 19 \t loss=0.015265 \t val_loss=0.016372 \t time=0.87s\n",
      "Best model: Epoch 20 \t loss=0.015016 \t val_loss=0.016362 \t time=0.82s\n",
      "Best model: Epoch 21 \t loss=0.014722 \t val_loss=0.016263 \t time=0.81s\n",
      "Fold 5 log loss: 0.016344392129819914\n",
      "Seed 1\n",
      "Fold 1 log loss: 0.01633832523140075\n",
      "Fold 2 log loss: 0.01629256070000529\n",
      "Fold 3 log loss: 0.016243214613729896\n",
      "Fold 4 log loss: 0.016248327694534097\n",
      "Fold 5 log loss: 0.016344392129819914\n",
      "Std of log loss: 4.2823492165236374e-05\n",
      "Total log loss: 0.016293366395423142\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.412421 \t val_loss=0.075672 \t time=1.06s\n",
      "Best model: Epoch 2 \t loss=0.046559 \t val_loss=0.027359 \t time=0.85s\n",
      "Best model: Epoch 3 \t loss=0.026254 \t val_loss=0.022091 \t time=0.85s\n",
      "Best model: Epoch 4 \t loss=0.022403 \t val_loss=0.020438 \t time=0.89s\n",
      "Best model: Epoch 5 \t loss=0.020960 \t val_loss=0.019436 \t time=0.83s\n",
      "Best model: Epoch 6 \t loss=0.020180 \t val_loss=0.018875 \t time=0.82s\n",
      "Best model: Epoch 7 \t loss=0.019421 \t val_loss=0.018416 \t time=0.82s\n",
      "Best model: Epoch 8 \t loss=0.019014 \t val_loss=0.018146 \t time=0.84s\n",
      "Best model: Epoch 9 \t loss=0.018448 \t val_loss=0.017801 \t time=0.82s\n",
      "Best model: Epoch 10 \t loss=0.017919 \t val_loss=0.017477 \t time=0.82s\n",
      "Best model: Epoch 11 \t loss=0.017628 \t val_loss=0.017320 \t time=0.82s\n",
      "Best model: Epoch 12 \t loss=0.017229 \t val_loss=0.017103 \t time=0.95s\n",
      "Best model: Epoch 13 \t loss=0.017015 \t val_loss=0.016942 \t time=0.88s\n",
      "Best model: Epoch 14 \t loss=0.016652 \t val_loss=0.016829 \t time=0.85s\n",
      "Best model: Epoch 15 \t loss=0.016375 \t val_loss=0.016712 \t time=0.82s\n",
      "Best model: Epoch 16 \t loss=0.016157 \t val_loss=0.016684 \t time=0.81s\n",
      "Best model: Epoch 17 \t loss=0.015916 \t val_loss=0.016619 \t time=0.82s\n",
      "Best model: Epoch 18 \t loss=0.015680 \t val_loss=0.016538 \t time=0.83s\n",
      "Best model: Epoch 19 \t loss=0.015336 \t val_loss=0.016463 \t time=0.83s\n",
      "Best model: Epoch 20 \t loss=0.015111 \t val_loss=0.016376 \t time=1.07s\n",
      "Best model: Epoch 22 \t loss=0.014637 \t val_loss=0.016331 \t time=0.82s\n",
      "Fold 1 log loss: 0.016342763474368766\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.415497 \t val_loss=0.083157 \t time=0.83s\n",
      "Best model: Epoch 2 \t loss=0.046161 \t val_loss=0.026911 \t time=0.80s\n",
      "Best model: Epoch 3 \t loss=0.026386 \t val_loss=0.022292 \t time=0.85s\n",
      "Best model: Epoch 4 \t loss=0.022387 \t val_loss=0.021119 \t time=0.82s\n",
      "Best model: Epoch 5 \t loss=0.021003 \t val_loss=0.019557 \t time=0.81s\n",
      "Best model: Epoch 6 \t loss=0.020045 \t val_loss=0.019066 \t time=0.87s\n",
      "Best model: Epoch 7 \t loss=0.019303 \t val_loss=0.018550 \t time=0.81s\n",
      "Best model: Epoch 8 \t loss=0.019025 \t val_loss=0.018183 \t time=0.83s\n",
      "Best model: Epoch 9 \t loss=0.018380 \t val_loss=0.018004 \t time=0.84s\n",
      "Best model: Epoch 10 \t loss=0.017915 \t val_loss=0.017689 \t time=1.03s\n",
      "Best model: Epoch 11 \t loss=0.017694 \t val_loss=0.017483 \t time=0.87s\n",
      "Best model: Epoch 12 \t loss=0.017298 \t val_loss=0.017204 \t time=0.83s\n",
      "Best model: Epoch 13 \t loss=0.016973 \t val_loss=0.017033 \t time=0.82s\n",
      "Best model: Epoch 14 \t loss=0.016574 \t val_loss=0.016969 \t time=0.82s\n",
      "Best model: Epoch 15 \t loss=0.016352 \t val_loss=0.016816 \t time=0.81s\n",
      "Best model: Epoch 16 \t loss=0.016128 \t val_loss=0.016658 \t time=0.83s\n",
      "Best model: Epoch 18 \t loss=0.015602 \t val_loss=0.016503 \t time=0.82s\n",
      "Best model: Epoch 19 \t loss=0.015389 \t val_loss=0.016419 \t time=0.81s\n",
      "Best model: Epoch 21 \t loss=0.014997 \t val_loss=0.016381 \t time=0.79s\n",
      "Best model: Epoch 22 \t loss=0.014781 \t val_loss=0.016358 \t time=0.85s\n",
      "Best model: Epoch 23 \t loss=0.014645 \t val_loss=0.016251 \t time=1.05s\n",
      "Fold 2 log loss: 0.016243370433113836\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.410537 \t val_loss=0.076244 \t time=0.82s\n",
      "Best model: Epoch 2 \t loss=0.046304 \t val_loss=0.028359 \t time=1.05s\n",
      "Best model: Epoch 3 \t loss=0.026317 \t val_loss=0.021789 \t time=0.89s\n",
      "Best model: Epoch 4 \t loss=0.022621 \t val_loss=0.020799 \t time=0.83s\n",
      "Best model: Epoch 5 \t loss=0.020945 \t val_loss=0.019318 \t time=0.82s\n",
      "Best model: Epoch 6 \t loss=0.019935 \t val_loss=0.018750 \t time=0.84s\n",
      "Best model: Epoch 7 \t loss=0.019541 \t val_loss=0.018312 \t time=0.83s\n",
      "Best model: Epoch 8 \t loss=0.018876 \t val_loss=0.018067 \t time=1.65s\n",
      "Best model: Epoch 9 \t loss=0.018478 \t val_loss=0.017739 \t time=0.83s\n",
      "Best model: Epoch 10 \t loss=0.017912 \t val_loss=0.017400 \t time=0.85s\n",
      "Best model: Epoch 11 \t loss=0.017734 \t val_loss=0.017321 \t time=0.93s\n",
      "Best model: Epoch 12 \t loss=0.017341 \t val_loss=0.017055 \t time=1.03s\n",
      "Best model: Epoch 13 \t loss=0.017014 \t val_loss=0.016929 \t time=0.94s\n",
      "Best model: Epoch 14 \t loss=0.016640 \t val_loss=0.016631 \t time=0.86s\n",
      "Best model: Epoch 16 \t loss=0.016136 \t val_loss=0.016473 \t time=0.80s\n",
      "Best model: Epoch 17 \t loss=0.015760 \t val_loss=0.016347 \t time=0.84s\n",
      "Best model: Epoch 18 \t loss=0.015550 \t val_loss=0.016300 \t time=0.86s\n",
      "Best model: Epoch 19 \t loss=0.015258 \t val_loss=0.016206 \t time=1.00s\n",
      "Best model: Epoch 20 \t loss=0.014980 \t val_loss=0.016101 \t time=0.90s\n",
      "Best model: Epoch 23 \t loss=0.014381 \t val_loss=0.016081 \t time=0.83s\n",
      "Best model: Epoch 24 \t loss=0.014200 \t val_loss=0.016074 \t time=0.82s\n",
      "Fold 3 log loss: 0.01621580413011131\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.413738 \t val_loss=0.081208 \t time=0.82s\n",
      "Best model: Epoch 2 \t loss=0.045727 \t val_loss=0.027513 \t time=0.81s\n",
      "Best model: Epoch 3 \t loss=0.026517 \t val_loss=0.022306 \t time=0.80s\n",
      "Best model: Epoch 4 \t loss=0.022678 \t val_loss=0.020750 \t time=0.80s\n",
      "Best model: Epoch 5 \t loss=0.020915 \t val_loss=0.019800 \t time=1.07s\n",
      "Best model: Epoch 6 \t loss=0.020048 \t val_loss=0.019078 \t time=0.81s\n",
      "Best model: Epoch 7 \t loss=0.019381 \t val_loss=0.018759 \t time=0.86s\n",
      "Best model: Epoch 8 \t loss=0.018983 \t val_loss=0.018384 \t time=0.82s\n",
      "Best model: Epoch 9 \t loss=0.018373 \t val_loss=0.017894 \t time=0.83s\n",
      "Best model: Epoch 10 \t loss=0.017917 \t val_loss=0.017664 \t time=1.17s\n",
      "Best model: Epoch 11 \t loss=0.017782 \t val_loss=0.017566 \t time=0.86s\n",
      "Best model: Epoch 12 \t loss=0.017359 \t val_loss=0.017021 \t time=0.85s\n",
      "Best model: Epoch 13 \t loss=0.016937 \t val_loss=0.017013 \t time=0.82s\n",
      "Best model: Epoch 14 \t loss=0.016771 \t val_loss=0.016857 \t time=0.80s\n",
      "Best model: Epoch 15 \t loss=0.016348 \t val_loss=0.016639 \t time=0.80s\n",
      "Best model: Epoch 16 \t loss=0.016010 \t val_loss=0.016532 \t time=0.84s\n",
      "Best model: Epoch 17 \t loss=0.015906 \t val_loss=0.016493 \t time=1.06s\n",
      "Best model: Epoch 18 \t loss=0.015558 \t val_loss=0.016424 \t time=0.81s\n",
      "Best model: Epoch 19 \t loss=0.015280 \t val_loss=0.016352 \t time=0.81s\n",
      "Best model: Epoch 20 \t loss=0.015064 \t val_loss=0.016328 \t time=0.87s\n",
      "Best model: Epoch 21 \t loss=0.014891 \t val_loss=0.016218 \t time=0.83s\n",
      "Best model: Epoch 22 \t loss=0.014653 \t val_loss=0.016168 \t time=0.82s\n",
      "Fold 4 log loss: 0.016201492605622675\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.409658 \t val_loss=0.088582 \t time=0.83s\n",
      "Best model: Epoch 2 \t loss=0.046494 \t val_loss=0.027947 \t time=0.87s\n",
      "Best model: Epoch 3 \t loss=0.026323 \t val_loss=0.022574 \t time=1.05s\n",
      "Best model: Epoch 4 \t loss=0.022593 \t val_loss=0.020523 \t time=0.86s\n",
      "Best model: Epoch 5 \t loss=0.021122 \t val_loss=0.019786 \t time=0.87s\n",
      "Best model: Epoch 6 \t loss=0.020152 \t val_loss=0.019013 \t time=0.86s\n",
      "Best model: Epoch 7 \t loss=0.019275 \t val_loss=0.018660 \t time=0.89s\n",
      "Best model: Epoch 8 \t loss=0.019069 \t val_loss=0.018220 \t time=0.83s\n",
      "Best model: Epoch 9 \t loss=0.018532 \t val_loss=0.017981 \t time=0.84s\n",
      "Best model: Epoch 10 \t loss=0.018069 \t val_loss=0.017715 \t time=0.83s\n",
      "Best model: Epoch 11 \t loss=0.017658 \t val_loss=0.017398 \t time=0.81s\n",
      "Best model: Epoch 12 \t loss=0.017359 \t val_loss=0.017269 \t time=0.83s\n",
      "Best model: Epoch 13 \t loss=0.017210 \t val_loss=0.017032 \t time=0.82s\n",
      "Best model: Epoch 14 \t loss=0.016691 \t val_loss=0.016898 \t time=0.82s\n",
      "Best model: Epoch 15 \t loss=0.016377 \t val_loss=0.016804 \t time=1.07s\n",
      "Best model: Epoch 16 \t loss=0.016096 \t val_loss=0.016681 \t time=0.81s\n",
      "Best model: Epoch 17 \t loss=0.015781 \t val_loss=0.016605 \t time=0.83s\n",
      "Best model: Epoch 18 \t loss=0.015586 \t val_loss=0.016435 \t time=0.82s\n",
      "Best model: Epoch 19 \t loss=0.015379 \t val_loss=0.016414 \t time=1.07s\n",
      "Best model: Epoch 21 \t loss=0.015011 \t val_loss=0.016363 \t time=0.84s\n",
      "Best model: Epoch 22 \t loss=0.014761 \t val_loss=0.016347 \t time=0.86s\n",
      "Best model: Epoch 23 \t loss=0.014545 \t val_loss=0.016314 \t time=0.88s\n",
      "Fold 5 log loss: 0.01639998301613369\n",
      "Seed 2\n",
      "Fold 1 log loss: 0.016342763474368766\n",
      "Fold 2 log loss: 0.016243370433113836\n",
      "Fold 3 log loss: 0.01621580413011131\n",
      "Fold 4 log loss: 0.016201492605622675\n",
      "Fold 5 log loss: 0.01639998301613369\n",
      "Std of log loss: 7.740683834687317e-05\n",
      "Total log loss: 0.01628068738791619\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.414390 \t val_loss=0.077225 \t time=0.84s\n",
      "Best model: Epoch 2 \t loss=0.045842 \t val_loss=0.027358 \t time=0.83s\n",
      "Best model: Epoch 3 \t loss=0.026609 \t val_loss=0.022118 \t time=0.84s\n",
      "Best model: Epoch 4 \t loss=0.022557 \t val_loss=0.020275 \t time=0.83s\n",
      "Best model: Epoch 5 \t loss=0.021114 \t val_loss=0.019530 \t time=0.83s\n",
      "Best model: Epoch 6 \t loss=0.020046 \t val_loss=0.018797 \t time=0.85s\n",
      "Best model: Epoch 7 \t loss=0.019450 \t val_loss=0.018493 \t time=0.84s\n",
      "Best model: Epoch 8 \t loss=0.018850 \t val_loss=0.018052 \t time=1.04s\n",
      "Best model: Epoch 9 \t loss=0.018448 \t val_loss=0.017794 \t time=0.87s\n",
      "Best model: Epoch 10 \t loss=0.018008 \t val_loss=0.017618 \t time=0.84s\n",
      "Best model: Epoch 11 \t loss=0.017706 \t val_loss=0.017260 \t time=0.85s\n",
      "Best model: Epoch 12 \t loss=0.017224 \t val_loss=0.017159 \t time=0.85s\n",
      "Best model: Epoch 13 \t loss=0.016908 \t val_loss=0.017059 \t time=0.81s\n",
      "Best model: Epoch 14 \t loss=0.016668 \t val_loss=0.016841 \t time=0.82s\n",
      "Best model: Epoch 15 \t loss=0.016307 \t val_loss=0.016737 \t time=0.80s\n",
      "Best model: Epoch 16 \t loss=0.016113 \t val_loss=0.016726 \t time=0.81s\n",
      "Best model: Epoch 17 \t loss=0.015922 \t val_loss=0.016628 \t time=0.83s\n",
      "Best model: Epoch 18 \t loss=0.015632 \t val_loss=0.016576 \t time=0.84s\n",
      "Best model: Epoch 19 \t loss=0.015311 \t val_loss=0.016420 \t time=0.86s\n",
      "Best model: Epoch 20 \t loss=0.015043 \t val_loss=0.016412 \t time=0.89s\n",
      "Best model: Epoch 21 \t loss=0.014833 \t val_loss=0.016396 \t time=1.00s\n",
      "Best model: Epoch 22 \t loss=0.014569 \t val_loss=0.016374 \t time=0.84s\n",
      "Best model: Epoch 23 \t loss=0.014330 \t val_loss=0.016343 \t time=0.98s\n",
      "Fold 1 log loss: 0.016354565369217547\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.415422 \t val_loss=0.080292 \t time=0.85s\n",
      "Best model: Epoch 2 \t loss=0.046713 \t val_loss=0.026978 \t time=0.86s\n",
      "Best model: Epoch 3 \t loss=0.026015 \t val_loss=0.022280 \t time=0.83s\n",
      "Best model: Epoch 4 \t loss=0.022459 \t val_loss=0.020420 \t time=0.91s\n",
      "Best model: Epoch 5 \t loss=0.020889 \t val_loss=0.019613 \t time=0.92s\n",
      "Best model: Epoch 6 \t loss=0.019897 \t val_loss=0.018952 \t time=0.95s\n",
      "Best model: Epoch 7 \t loss=0.019324 \t val_loss=0.018668 \t time=0.85s\n",
      "Best model: Epoch 8 \t loss=0.018977 \t val_loss=0.018366 \t time=0.84s\n",
      "Best model: Epoch 9 \t loss=0.018453 \t val_loss=0.017946 \t time=0.82s\n",
      "Best model: Epoch 10 \t loss=0.018039 \t val_loss=0.017729 \t time=0.81s\n",
      "Best model: Epoch 11 \t loss=0.017651 \t val_loss=0.017399 \t time=0.84s\n",
      "Best model: Epoch 12 \t loss=0.017433 \t val_loss=0.017218 \t time=0.80s\n",
      "Best model: Epoch 13 \t loss=0.017048 \t val_loss=0.017108 \t time=0.80s\n",
      "Best model: Epoch 14 \t loss=0.016729 \t val_loss=0.016937 \t time=0.82s\n",
      "Best model: Epoch 15 \t loss=0.016445 \t val_loss=0.016820 \t time=0.85s\n",
      "Best model: Epoch 16 \t loss=0.016114 \t val_loss=0.016711 \t time=0.88s\n",
      "Best model: Epoch 17 \t loss=0.015866 \t val_loss=0.016518 \t time=0.86s\n",
      "Best model: Epoch 19 \t loss=0.015345 \t val_loss=0.016477 \t time=0.88s\n",
      "Best model: Epoch 20 \t loss=0.015221 \t val_loss=0.016466 \t time=0.85s\n",
      "Best model: Epoch 21 \t loss=0.014979 \t val_loss=0.016414 \t time=0.82s\n",
      "Best model: Epoch 22 \t loss=0.014725 \t val_loss=0.016408 \t time=0.83s\n",
      "Best model: Epoch 23 \t loss=0.014566 \t val_loss=0.016351 \t time=0.80s\n",
      "Best model: Epoch 24 \t loss=0.014401 \t val_loss=0.016326 \t time=0.82s\n",
      "Fold 2 log loss: 0.016305088534103885\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.413657 \t val_loss=0.077485 \t time=0.83s\n",
      "Best model: Epoch 2 \t loss=0.046528 \t val_loss=0.027094 \t time=1.14s\n",
      "Best model: Epoch 3 \t loss=0.026074 \t val_loss=0.022311 \t time=1.22s\n",
      "Best model: Epoch 4 \t loss=0.023184 \t val_loss=0.020890 \t time=0.90s\n",
      "Best model: Epoch 5 \t loss=0.021100 \t val_loss=0.019426 \t time=1.63s\n",
      "Best model: Epoch 6 \t loss=0.020014 \t val_loss=0.018785 \t time=0.87s\n",
      "Best model: Epoch 7 \t loss=0.019392 \t val_loss=0.018456 \t time=0.83s\n",
      "Best model: Epoch 8 \t loss=0.018783 \t val_loss=0.017911 \t time=0.86s\n",
      "Best model: Epoch 9 \t loss=0.018402 \t val_loss=0.017686 \t time=0.94s\n",
      "Best model: Epoch 10 \t loss=0.018115 \t val_loss=0.017382 \t time=0.93s\n",
      "Best model: Epoch 11 \t loss=0.017700 \t val_loss=0.017187 \t time=0.84s\n",
      "Best model: Epoch 12 \t loss=0.017306 \t val_loss=0.016976 \t time=0.84s\n",
      "Best model: Epoch 13 \t loss=0.017044 \t val_loss=0.016878 \t time=0.81s\n",
      "Best model: Epoch 14 \t loss=0.016772 \t val_loss=0.016643 \t time=1.05s\n",
      "Best model: Epoch 15 \t loss=0.016423 \t val_loss=0.016578 \t time=0.85s\n",
      "Best model: Epoch 16 \t loss=0.016075 \t val_loss=0.016386 \t time=0.81s\n",
      "Best model: Epoch 17 \t loss=0.015792 \t val_loss=0.016311 \t time=0.82s\n",
      "Best model: Epoch 18 \t loss=0.015532 \t val_loss=0.016191 \t time=0.83s\n",
      "Best model: Epoch 19 \t loss=0.015375 \t val_loss=0.016184 \t time=0.81s\n",
      "Best model: Epoch 20 \t loss=0.015070 \t val_loss=0.016100 \t time=0.79s\n",
      "Fold 3 log loss: 0.01623708681914511\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.415948 \t val_loss=0.077778 \t time=0.81s\n",
      "Best model: Epoch 2 \t loss=0.046644 \t val_loss=0.026705 \t time=0.82s\n",
      "Best model: Epoch 3 \t loss=0.025892 \t val_loss=0.022203 \t time=0.82s\n",
      "Best model: Epoch 4 \t loss=0.022580 \t val_loss=0.020849 \t time=0.82s\n",
      "Best model: Epoch 5 \t loss=0.021026 \t val_loss=0.019698 \t time=0.82s\n",
      "Best model: Epoch 6 \t loss=0.020148 \t val_loss=0.019693 \t time=0.83s\n",
      "Best model: Epoch 7 \t loss=0.019439 \t val_loss=0.018733 \t time=0.80s\n",
      "Best model: Epoch 8 \t loss=0.018965 \t val_loss=0.018416 \t time=0.80s\n",
      "Best model: Epoch 9 \t loss=0.018434 \t val_loss=0.017886 \t time=0.82s\n",
      "Best model: Epoch 10 \t loss=0.018092 \t val_loss=0.017544 \t time=0.82s\n",
      "Best model: Epoch 12 \t loss=0.017265 \t val_loss=0.017137 \t time=0.83s\n",
      "Best model: Epoch 13 \t loss=0.016956 \t val_loss=0.016953 \t time=1.01s\n",
      "Best model: Epoch 14 \t loss=0.016625 \t val_loss=0.016877 \t time=0.98s\n",
      "Best model: Epoch 15 \t loss=0.016394 \t val_loss=0.016594 \t time=1.00s\n",
      "Best model: Epoch 16 \t loss=0.016108 \t val_loss=0.016547 \t time=0.81s\n",
      "Best model: Epoch 17 \t loss=0.015788 \t val_loss=0.016435 \t time=0.84s\n",
      "Best model: Epoch 18 \t loss=0.015498 \t val_loss=0.016390 \t time=0.88s\n",
      "Best model: Epoch 19 \t loss=0.015180 \t val_loss=0.016286 \t time=0.80s\n",
      "Best model: Epoch 21 \t loss=0.014848 \t val_loss=0.016197 \t time=0.80s\n",
      "Best model: Epoch 22 \t loss=0.014631 \t val_loss=0.016166 \t time=0.81s\n",
      "Best model: Epoch 23 \t loss=0.014399 \t val_loss=0.016154 \t time=0.82s\n",
      "Fold 4 log loss: 0.01618151296213908\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.411778 \t val_loss=0.075132 \t time=0.84s\n",
      "Best model: Epoch 2 \t loss=0.046545 \t val_loss=0.027733 \t time=0.80s\n",
      "Best model: Epoch 3 \t loss=0.025973 \t val_loss=0.022376 \t time=0.81s\n",
      "Best model: Epoch 4 \t loss=0.022501 \t val_loss=0.020454 \t time=0.84s\n",
      "Best model: Epoch 5 \t loss=0.021024 \t val_loss=0.019700 \t time=0.82s\n",
      "Best model: Epoch 6 \t loss=0.020139 \t val_loss=0.019324 \t time=0.82s\n",
      "Best model: Epoch 7 \t loss=0.019428 \t val_loss=0.018564 \t time=0.81s\n",
      "Best model: Epoch 8 \t loss=0.018815 \t val_loss=0.018204 \t time=0.85s\n",
      "Best model: Epoch 9 \t loss=0.018461 \t val_loss=0.017954 \t time=0.84s\n",
      "Best model: Epoch 10 \t loss=0.017949 \t val_loss=0.017617 \t time=1.01s\n",
      "Best model: Epoch 11 \t loss=0.017580 \t val_loss=0.017306 \t time=0.92s\n",
      "Best model: Epoch 13 \t loss=0.016989 \t val_loss=0.017033 \t time=0.83s\n",
      "Best model: Epoch 14 \t loss=0.016584 \t val_loss=0.016835 \t time=0.81s\n",
      "Best model: Epoch 15 \t loss=0.016287 \t val_loss=0.016740 \t time=1.29s\n",
      "Best model: Epoch 16 \t loss=0.015974 \t val_loss=0.016627 \t time=0.94s\n",
      "Best model: Epoch 17 \t loss=0.015673 \t val_loss=0.016556 \t time=1.00s\n",
      "Best model: Epoch 18 \t loss=0.015469 \t val_loss=0.016395 \t time=0.83s\n",
      "Best model: Epoch 19 \t loss=0.015191 \t val_loss=0.016373 \t time=0.88s\n",
      "Best model: Epoch 22 \t loss=0.014605 \t val_loss=0.016297 \t time=1.38s\n",
      "Best model: Epoch 23 \t loss=0.014378 \t val_loss=0.016237 \t time=1.16s\n",
      "Fold 5 log loss: 0.016315882768899587\n",
      "Seed 3\n",
      "Fold 1 log loss: 0.016354565369217547\n",
      "Fold 2 log loss: 0.016305088534103885\n",
      "Fold 3 log loss: 0.01623708681914511\n",
      "Fold 4 log loss: 0.01618151296213908\n",
      "Fold 5 log loss: 0.016315882768899587\n",
      "Std of log loss: 6.166257116944717e-05\n",
      "Total log loss: 0.01627882799596932\n",
      "Total log loss in targets: 0.01599115000763674\n"
     ]
    }
   ],
   "source": [
    "seeds = [0,1,2,3]\n",
    "target_oof = np.zeros([len(train),fn_targets.shape[1]])\n",
    "target_pred = np.zeros([len(test),fn_targets.shape[1]])\n",
    "\n",
    "nontarget_oof = np.zeros([len(train),fn_non_targets.shape[1]])\n",
    "nontarget_pred = np.zeros([len(test),fn_non_targets.shape[1]])\n",
    "\n",
    "for seed_ in seeds:\n",
    "    oof, oof_targets, pytorch_pred = modelling_torch(train, fn_targets, test, seed_, train.shape[1], fn_targets.shape[1])\n",
    "    target_oof += oof / len(seeds)\n",
    "    target_pred += pytorch_pred / len(seeds)\n",
    "print(\"Total log loss in targets: {}\".format(mean_log_loss(oof_targets, target_oof)))\n",
    "\n",
    "#for seed_ in seeds:\n",
    "#    oof, oof_targets, pytorch_pred = modelling_torch(train, fn_non_targets, test, seed_, train.shape[1], fn_non_targets.shape[1])\n",
    "#    nontarget_oof += oof / len(seeds)\n",
    "#    nontarget_pred += pytorch_pred / len(seeds)\n",
    "#print(\"Total log loss in Non targets: {}\".format(mean_log_loss(oof_targets, nontarget_oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-17T03:22:50.415890Z",
     "iopub.status.busy": "2020-10-17T03:22:50.414903Z",
     "iopub.status.idle": "2020-10-17T03:22:56.502895Z",
     "shell.execute_reply": "2020-10-17T03:22:56.503670Z"
    },
    "papermill": {
     "duration": 6.288254,
     "end_time": "2020-10-17T03:22:56.503836",
     "exception": false,
     "start_time": "2020-10-17T03:22:50.215582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF log loss:  0.014738127167532242\n"
     ]
    }
   ],
   "source": [
    "t = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "train_checkscore = t.copy()\n",
    "train_checkscore.loc[train_checkscore.index.isin(cons_train_index),target_feats] = target_oof\n",
    "train_checkscore.loc[train_checkscore.index.isin(noncons_train_index),target_feats] = 0\n",
    "\n",
    "t.drop(\"sig_id\", axis=1, inplace=True)\n",
    "\n",
    "print('OOF log loss: ', log_loss(np.ravel(t), np.ravel(np.array(train_checkscore.iloc[:,1:]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-17T03:22:56.911689Z",
     "iopub.status.busy": "2020-10-17T03:22:56.910810Z",
     "iopub.status.idle": "2020-10-17T03:22:59.484287Z",
     "shell.execute_reply": "2020-10-17T03:22:59.483663Z"
    },
    "papermill": {
     "duration": 2.777853,
     "end_time": "2020-10-17T03:22:59.484427",
     "exception": false,
     "start_time": "2020-10-17T03:22:56.706574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub[target_feats] = target_pred\n",
    "sub.loc[noncons_test_index,target_feats] = 0\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.197432,
     "end_time": "2020-10-17T03:22:59.871756",
     "exception": false,
     "start_time": "2020-10-17T03:22:59.674324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 545.919081,
   "end_time": "2020-10-17T03:23:01.193302",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-17T03:13:55.274221",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
