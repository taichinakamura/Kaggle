{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020648,
     "end_time": "2020-11-11T00:42:40.987953",
     "exception": false,
     "start_time": "2020-11-11T00:42:40.967305",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- add ctl diff information\n",
    "- change threshold to 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-11T00:42:41.037112Z",
     "iopub.status.busy": "2020-11-11T00:42:41.036370Z",
     "iopub.status.idle": "2020-11-11T00:42:51.272945Z",
     "shell.execute_reply": "2020-11-11T00:42:51.273873Z"
    },
    "papermill": {
     "duration": 10.266081,
     "end_time": "2020-11-11T00:42:51.274107",
     "exception": false,
     "start_time": "2020-11-11T00:42:41.008026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from umap import UMAP\n",
    "from scipy import stats\n",
    "import networkx as nx\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss,roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "sys.path.append('../input/multilabelstraifier/')\n",
    "from ml_stratifiers import MultilabelStratifiedKFold\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "from torch.nn.modules.loss import _WeightedLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T00:42:51.339463Z",
     "iopub.status.busy": "2020-11-11T00:42:51.338518Z",
     "iopub.status.idle": "2020-11-11T00:42:58.117835Z",
     "shell.execute_reply": "2020-11-11T00:42:58.115117Z"
    },
    "papermill": {
     "duration": 6.814603,
     "end_time": "2020-11-11T00:42:58.117991",
     "exception": false,
     "start_time": "2020-11-11T00:42:51.303388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/lish-moa/'\n",
    "train = pd.read_csv(DATA_DIR + 'train_features.csv')\n",
    "targets = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "non_targets = pd.read_csv(DATA_DIR + 'train_targets_nonscored.csv')\n",
    "test = pd.read_csv(DATA_DIR + 'test_features.csv')\n",
    "sub = pd.read_csv(DATA_DIR + 'sample_submission.csv')\n",
    "drug = pd.read_csv(DATA_DIR + 'train_drug.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T00:42:58.163753Z",
     "iopub.status.busy": "2020-11-11T00:42:58.163128Z",
     "iopub.status.idle": "2020-11-11T00:42:58.167228Z",
     "shell.execute_reply": "2020-11-11T00:42:58.166694Z"
    },
    "papermill": {
     "duration": 0.029085,
     "end_time": "2020-11-11T00:42:58.167315",
     "exception": false,
     "start_time": "2020-11-11T00:42:58.138230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_feats = [ i for i in targets.columns if i != \"sig_id\"]\n",
    "g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "c_feats = [i for i in train.columns if \"c-\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T00:42:58.216095Z",
     "iopub.status.busy": "2020-11-11T00:42:58.215324Z",
     "iopub.status.idle": "2020-11-11T00:42:58.311452Z",
     "shell.execute_reply": "2020-11-11T00:42:58.310913Z"
    },
    "papermill": {
     "duration": 0.12397,
     "end_time": "2020-11-11T00:42:58.311556",
     "exception": false,
     "start_time": "2020-11-11T00:42:58.187586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "noncons_train_index = train[train.cp_type==\"ctl_vehicle\"].index\n",
    "cons_train_index = train[train.cp_type!=\"ctl_vehicle\"].index\n",
    "noncons_test_index = test[test.cp_type==\"ctl_vehicle\"].index\n",
    "cons_test_index = test[test.cp_type!=\"ctl_vehicle\"].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019554,
     "end_time": "2020-11-11T00:42:58.351257",
     "exception": false,
     "start_time": "2020-11-11T00:42:58.331703",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T00:42:58.401272Z",
     "iopub.status.busy": "2020-11-11T00:42:58.400357Z",
     "iopub.status.idle": "2020-11-11T00:43:00.246188Z",
     "shell.execute_reply": "2020-11-11T00:43:00.245583Z"
    },
    "papermill": {
     "duration": 1.875362,
     "end_time": "2020-11-11T00:43:00.246295",
     "exception": false,
     "start_time": "2020-11-11T00:42:58.370933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# normalization by ctl group\n",
    "train_ctl = train[train.index.isin(noncons_train_index)].copy().reset_index(drop=True)\n",
    "test_ctl = test[test.index.isin(noncons_test_index)].copy().reset_index(drop=True)\n",
    "ctl_df = pd.concat([train_ctl, test_ctl])\n",
    "\n",
    "ctl_group_data = ctl_df.groupby([\"cp_dose\", \"cp_time\"]).agg({\"mean\"}).reset_index()\n",
    "mean_g_feats = [\"mean-\" + i for i in g_feats]\n",
    "mean_c_feats = [\"mean-\" + i for i in c_feats]\n",
    "columns = [\"cp_dose\", \"cp_time\"] + mean_g_feats + mean_c_feats\n",
    "ctl_group_data.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T00:43:00.299857Z",
     "iopub.status.busy": "2020-11-11T00:43:00.298804Z",
     "iopub.status.idle": "2020-11-11T00:43:00.535872Z",
     "shell.execute_reply": "2020-11-11T00:43:00.535296Z"
    },
    "papermill": {
     "duration": 0.26922,
     "end_time": "2020-11-11T00:43:00.535981",
     "exception": false,
     "start_time": "2020-11-11T00:43:00.266761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train[train.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "test = test[test.index.isin(cons_test_index)].copy().reset_index(drop=True)\n",
    "targets = targets[targets.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "#non_targets = non_targets[non_targets.index.isin(cons_train_index)].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T00:43:00.598099Z",
     "iopub.status.busy": "2020-11-11T00:43:00.596406Z",
     "iopub.status.idle": "2020-11-11T00:43:01.548975Z",
     "shell.execute_reply": "2020-11-11T00:43:01.548143Z"
    },
    "papermill": {
     "duration": 0.992761,
     "end_time": "2020-11-11T00:43:01.549092",
     "exception": false,
     "start_time": "2020-11-11T00:43:00.556331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, ctl_group_data, on=[\"cp_time\", \"cp_dose\"], how=\"left\")\n",
    "test = pd.merge(test, ctl_group_data, on=[\"cp_time\", \"cp_dose\"], how=\"left\")\n",
    "\n",
    "for i in range(len(g_feats)):\n",
    "    train[\"mean-g-\"+str(i)] = train[\"g-\"+str(i)] - train[\"mean-g-\"+str(i)]\n",
    "    test[\"mean-g-\"+str(i)] = test[\"g-\"+str(i)] - test[\"mean-g-\"+str(i)]\n",
    "    \n",
    "for i in range(len(c_feats)):\n",
    "    train[\"mean-c-\"+str(i)] = train[\"c-\"+str(i)] - train[\"mean-c-\"+str(i)]\n",
    "    test[\"mean-c-\"+str(i)] = test[\"c-\"+str(i)] - test[\"mean-c-\"+str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T00:43:01.612158Z",
     "iopub.status.busy": "2020-11-11T00:43:01.605933Z",
     "iopub.status.idle": "2020-11-11T00:43:02.079146Z",
     "shell.execute_reply": "2020-11-11T00:43:02.079637Z"
    },
    "papermill": {
     "duration": 0.510133,
     "end_time": "2020-11-11T00:43:02.079804",
     "exception": false,
     "start_time": "2020-11-11T00:43:01.569671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 6, ..., 3, 4, 0]], dtype=int8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/c/lish-moa/discussion/195195\n",
    "NB_SPLITS = 7\n",
    "seed = 34\n",
    "\n",
    "folds = []\n",
    "    \n",
    "# LOAD FILES\n",
    "train_score = targets.merge(drug, on='sig_id', how='left') \n",
    "\n",
    "# LOCATE DRUGS\n",
    "vc = train_score.drug_id.value_counts()\n",
    "vc1 = vc.loc[vc <= 18].index.sort_values()\n",
    "vc2 = vc.loc[vc > 18].index.sort_values()\n",
    "    \n",
    "# STRATIFY DRUGS 18X OR LESS\n",
    "dct1 = {}; dct2 = {}\n",
    "skf = MultilabelStratifiedKFold(n_splits = NB_SPLITS, shuffle = True, random_state = seed)\n",
    "tmp = train_score.groupby('drug_id')[target_feats].mean().loc[vc1]\n",
    "for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_feats])):\n",
    "    dd = {k:fold for k in tmp.index[idxV].values}\n",
    "    dct1.update(dd)\n",
    "\n",
    "# STRATIFY DRUGS MORE THAN 18X\n",
    "skf = MultilabelStratifiedKFold(n_splits = NB_SPLITS, shuffle = True, random_state = seed)\n",
    "tmp = train_score.loc[train_score.drug_id.isin(vc2)].reset_index(drop = True)\n",
    "for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_feats])):\n",
    "    dd = {k:fold for k in tmp.sig_id[idxV].values}\n",
    "    dct2.update(dd)\n",
    "\n",
    "# ASSIGN FOLDS\n",
    "train_score['fold'] = train_score.drug_id.map(dct1)\n",
    "train_score.loc[train_score.fold.isna(),'fold'] = train_score.loc[train_score.fold.isna(),'sig_id'].map(dct2)\n",
    "train_score.fold = train_score.fold.astype('int8')\n",
    "folds.append(train_score.fold.values)\n",
    "    \n",
    "np.array(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020673,
     "end_time": "2020-11-11T00:43:02.121547",
     "exception": false,
     "start_time": "2020-11-11T00:43:02.100874",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T00:43:02.262645Z",
     "iopub.status.busy": "2020-11-11T00:43:02.261169Z",
     "iopub.status.idle": "2020-11-11T00:43:03.101586Z",
     "shell.execute_reply": "2020-11-11T00:43:03.102127Z"
    },
    "papermill": {
     "duration": 0.959773,
     "end_time": "2020-11-11T00:43:03.102267",
     "exception": false,
     "start_time": "2020-11-11T00:43:02.142494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "X = train.iloc[:,4:].copy().values\n",
    "select = VarianceThreshold(threshold=0.7)\n",
    "X_new = select.fit_transform(X)\n",
    "drop_feats = list(np.array(train.iloc[:,4:].columns)[select.get_support()==False])\n",
    "print(len(drop_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T00:43:03.150461Z",
     "iopub.status.busy": "2020-11-11T00:43:03.148683Z",
     "iopub.status.idle": "2020-11-11T00:43:03.151175Z",
     "shell.execute_reply": "2020-11-11T00:43:03.151653Z"
    },
    "papermill": {
     "duration": 0.028088,
     "end_time": "2020-11-11T00:43:03.151766",
     "exception": false,
     "start_time": "2020-11-11T00:43:03.123678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#correlations = train[c_feats].corr().abs()\n",
    "#correlations = (correlations.where(np.triu(np.ones(correlations.shape), k=1).astype(np.bool)).stack().sort_values(ascending=False))\n",
    "#pairs_df = (1-correlations).reset_index()\n",
    "#G = nx.from_pandas_edgelist(pairs_df[:20], source='level_0', target='level_1', edge_attr=0)\n",
    "#c_group = list(nx.algorithms.community.modularity_max.greedy_modularity_communities(G))\n",
    "\n",
    "#drop_c_feats = []\n",
    "#for i in range(len(c_group)):\n",
    "#    for j in list(c_group[i])[1:]:\n",
    "#        drop_c_feats.append(j)\n",
    "#en(drop_c_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T00:43:03.204172Z",
     "iopub.status.busy": "2020-11-11T00:43:03.202749Z",
     "iopub.status.idle": "2020-11-11T00:43:03.544347Z",
     "shell.execute_reply": "2020-11-11T00:43:03.543822Z"
    },
    "papermill": {
     "duration": 0.371148,
     "end_time": "2020-11-11T00:43:03.544462",
     "exception": false,
     "start_time": "2020-11-11T00:43:03.173314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.drop(drop_feats, axis=1, inplace=True)\n",
    "test.drop(drop_feats, axis=1, inplace=True)\n",
    "\n",
    "#train.drop(drop_c_feats, axis=1, inplace=True)\n",
    "#test.drop(drop_c_feats, axis=1, inplace=True)\n",
    "\n",
    "g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "c_feats = [i for i in train.columns if \"c-\" in i]\n",
    "mean_g_feats = [i for i in train.columns if \"mean-g-\" in i]\n",
    "mean_c_feats = [i for i in train.columns if \"mean-c-\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T00:43:03.596913Z",
     "iopub.status.busy": "2020-11-11T00:43:03.596167Z",
     "iopub.status.idle": "2020-11-11T00:43:32.173463Z",
     "shell.execute_reply": "2020-11-11T00:43:32.172144Z"
    },
    "papermill": {
     "duration": 28.607234,
     "end_time": "2020-11-11T00:43:32.173596",
     "exception": false,
     "start_time": "2020-11-11T00:43:03.566362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rank gauss\n",
    "for i in c_feats + g_feats + mean_g_feats + mean_c_feats:\n",
    "    ss = preprocessing.QuantileTransformer(n_quantiles=1000, random_state=0, output_distribution=\"normal\")\n",
    "    ss.fit(train[i].values.reshape(-1,1))\n",
    "    train[i] = ss.transform(train[i].values.reshape(-1,1))\n",
    "    test[i] = ss.transform(test[i].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T00:43:32.247492Z",
     "iopub.status.busy": "2020-11-11T00:43:32.246497Z",
     "iopub.status.idle": "2020-11-11T00:43:35.908773Z",
     "shell.execute_reply": "2020-11-11T00:43:35.908100Z"
    },
    "papermill": {
     "duration": 3.713155,
     "end_time": "2020-11-11T00:43:35.908908",
     "exception": false,
     "start_time": "2020-11-11T00:43:32.195753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_num = 10\n",
    "pca_c_cols = [\"pca-c\"+str(i+1) for i in range(c_num)]\n",
    "pca = PCA(n_components=c_num,random_state=42)\n",
    "c_train = pca.fit_transform(train[c_feats])\n",
    "c_test = pca.transform(test[c_feats])\n",
    "c_train = pd.DataFrame(c_train, columns=pca_c_cols)\n",
    "c_test = pd.DataFrame(c_test, columns=pca_c_cols)\n",
    "\n",
    "g_num = 60\n",
    "pca_g_cols = [\"pca-g\"+str(i+1) for i in range(g_num)]\n",
    "pca = PCA(n_components=g_num, random_state=42)\n",
    "g_train = pca.fit_transform(train[g_feats])\n",
    "g_test = pca.transform(test[g_feats])\n",
    "g_train = pd.DataFrame(g_train, columns=pca_g_cols)\n",
    "g_test = pd.DataFrame(g_test, columns=pca_g_cols)\n",
    "\n",
    "train = pd.concat([train, c_train],axis=1)\n",
    "test = pd.concat([test, c_test],axis=1)\n",
    "train = pd.concat([train, g_train],axis=1)\n",
    "test = pd.concat([test, g_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T00:43:35.959287Z",
     "iopub.status.busy": "2020-11-11T00:43:35.958411Z",
     "iopub.status.idle": "2020-11-11T00:43:35.961581Z",
     "shell.execute_reply": "2020-11-11T00:43:35.961070Z"
    },
    "papermill": {
     "duration": 0.029851,
     "end_time": "2020-11-11T00:43:35.961707",
     "exception": false,
     "start_time": "2020-11-11T00:43:35.931856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#uc_num = 1\n",
    "#um = UMAP(n_neighbors=20, n_components=uc_num, random_state=42)\n",
    "#um_c_cols = [\"um-c\"+str(i+1) for i in range(uc_num)]\n",
    "#uc_train = um.fit_transform(train[c_feats])\n",
    "#uc_test = um.transform(test[c_feats])\n",
    "#uc_train = pd.DataFrame(uc_train, columns=um_c_cols)\n",
    "#uc_test = pd.DataFrame(uc_test, columns=um_c_cols)\n",
    "\n",
    "#ug_num = 5\n",
    "#um = UMAP(n_neighbors=20, n_components=ug_num, random_state=42)\n",
    "#um_g_cols = [\"um-g\"+str(i+1) for i in range(ug_num)]\n",
    "#ug_train = um.fit_transform(train[g_feats])\n",
    "#ug_test = um.transform(test[g_feats])\n",
    "#ug_train = pd.DataFrame(ug_train, columns=um_g_cols)\n",
    "#ug_test = pd.DataFrame(ug_test, columns=um_g_cols)\n",
    "\n",
    "#train = pd.concat([train, uc_train],axis=1)\n",
    "#test = pd.concat([test, uc_test],axis=1)\n",
    "#train = pd.concat([train, ug_train],axis=1)\n",
    "#test = pd.concat([test, ug_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T00:43:36.015932Z",
     "iopub.status.busy": "2020-11-11T00:43:36.014663Z",
     "iopub.status.idle": "2020-11-11T00:43:39.615127Z",
     "shell.execute_reply": "2020-11-11T00:43:39.615579Z"
    },
    "papermill": {
     "duration": 3.631846,
     "end_time": "2020-11-11T00:43:39.615738",
     "exception": false,
     "start_time": "2020-11-11T00:43:35.983892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 1761) (3624, 1761)\n"
     ]
    }
   ],
   "source": [
    "def fe(df):\n",
    "    tmp = df.copy()\n",
    "    tmp['g_kurt'] = tmp[g_feats].kurtosis(axis = 1)\n",
    "    tmp['g_skew'] = tmp[g_feats].skew(axis = 1)\n",
    "    tmp['c_kurt'] = tmp[c_feats].kurtosis(axis = 1)\n",
    "    tmp['c_skew'] = tmp[c_feats].skew(axis = 1)\n",
    "    tmp = pd.get_dummies(tmp, columns=['cp_time','cp_dose'])\n",
    "    tmp.drop([\"cp_type\", \"sig_id\"], axis=1, inplace=True) \n",
    "    return tmp\n",
    "\n",
    "train = fe(train)\n",
    "test = fe(test)\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T00:43:39.668822Z",
     "iopub.status.busy": "2020-11-11T00:43:39.667857Z",
     "iopub.status.idle": "2020-11-11T00:43:39.670966Z",
     "shell.execute_reply": "2020-11-11T00:43:39.670448Z"
    },
    "papermill": {
     "duration": 0.032019,
     "end_time": "2020-11-11T00:43:39.671070",
     "exception": false,
     "start_time": "2020-11-11T00:43:39.639051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[\"fold\"] = np.array(folds).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T00:43:39.725623Z",
     "iopub.status.busy": "2020-11-11T00:43:39.724312Z",
     "iopub.status.idle": "2020-11-11T00:43:40.017641Z",
     "shell.execute_reply": "2020-11-11T00:43:40.017074Z"
    },
    "papermill": {
     "duration": 0.32406,
     "end_time": "2020-11-11T00:43:40.017752",
     "exception": false,
     "start_time": "2020-11-11T00:43:39.693692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fn_train = train.copy().to_numpy()\n",
    "fn_test = test.copy().to_numpy()\n",
    "\n",
    "fn_targets = targets.drop(\"sig_id\", axis=1).copy().to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022938,
     "end_time": "2020-11-11T00:43:40.064018",
     "exception": false,
     "start_time": "2020-11-11T00:43:40.041080",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T00:43:40.483842Z",
     "iopub.status.busy": "2020-11-11T00:43:40.483057Z",
     "iopub.status.idle": "2020-11-11T00:43:40.486689Z",
     "shell.execute_reply": "2020-11-11T00:43:40.485663Z"
    },
    "papermill": {
     "duration": 0.399644,
     "end_time": "2020-11-11T00:43:40.486811",
     "exception": false,
     "start_time": "2020-11-11T00:43:40.087167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T00:43:40.546306Z",
     "iopub.status.busy": "2020-11-11T00:43:40.544457Z",
     "iopub.status.idle": "2020-11-11T00:43:40.546990Z",
     "shell.execute_reply": "2020-11-11T00:43:40.547427Z"
    },
    "papermill": {
     "duration": 0.037104,
     "end_time": "2020-11-11T00:43:40.547565",
     "exception": false,
     "start_time": "2020-11-11T00:43:40.510461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SmoothCrossEntropyLoss(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets, n_classes, smoothing=0.0):\n",
    "        assert 0 <= smoothing <= 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1 - smoothing) + torch.ones_like(targets).to(device) * smoothing / n_classes\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothCrossEntropyLoss()._smooth(targets, inputs.shape[1], self.smoothing)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            inputs = inputs * self.weight.unsqueeze(0)\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T00:43:40.611736Z",
     "iopub.status.busy": "2020-11-11T00:43:40.611020Z",
     "iopub.status.idle": "2020-11-11T00:43:40.614576Z",
     "shell.execute_reply": "2020-11-11T00:43:40.615070Z"
    },
    "papermill": {
     "duration": 0.042793,
     "end_time": "2020-11-11T00:43:40.615191",
     "exception": false,
     "start_time": "2020-11-11T00:43:40.572398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "def seed_everything(seed=42): \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "class MoaModel(nn.Module):\n",
    "    def __init__(self, num_columns, last_num):\n",
    "        super(MoaModel, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_columns)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_columns, 1024))\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(1024)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(1024, 1024))\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(1024)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(1024, last_num))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu1(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.relu2(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023811,
     "end_time": "2020-11-11T00:43:40.662789",
     "exception": false,
     "start_time": "2020-11-11T00:43:40.638978",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T00:43:40.729577Z",
     "iopub.status.busy": "2020-11-11T00:43:40.728471Z",
     "iopub.status.idle": "2020-11-11T00:43:40.797223Z",
     "shell.execute_reply": "2020-11-11T00:43:40.798427Z"
    },
    "papermill": {
     "duration": 0.112248,
     "end_time": "2020-11-11T00:43:40.798645",
     "exception": false,
     "start_time": "2020-11-11T00:43:40.686397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_folds=7\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "smoothing = 0.001\n",
    "p_min = smoothing\n",
    "p_max = 1 - smoothing\n",
    "\n",
    "def mean_log_loss(y_true, y_pred):\n",
    "    metrics = []\n",
    "    for i, target in enumerate(target_feats):\n",
    "        metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float), labels=[0,1]))\n",
    "    return np.mean(metrics)\n",
    "\n",
    "def modelling_torch(tr, target, te, sample_seed, init_num, last_num, train_epochs):\n",
    "    seed_everything(seed=sample_seed) \n",
    "    X_train = tr.copy()\n",
    "    y_train = target.copy()\n",
    "    X_test = te.copy()\n",
    "    test_len = X_test.shape[0]\n",
    "    \n",
    "    mskf=MultilabelStratifiedKFold(n_splits = n_folds, shuffle=True, random_state=224)\n",
    "    metric = lambda inputs, targets : F.binary_cross_entropy((torch.clamp(torch.sigmoid(inputs), p_min, p_max)), targets)\n",
    "\n",
    "    models = []\n",
    "    \n",
    "    X_test2 = torch.tensor(X_test, dtype=torch.float32)\n",
    "    test = torch.utils.data.TensorDataset(X_test2) \n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    oof = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    oof_targets = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    pred_value = np.zeros([test_len, y_train.shape[1]])\n",
    "    scores = []\n",
    "    for fold in range(n_folds):\n",
    "        valid_index = X_train[:,-1] == fold\n",
    "        train_index = X_train[:,-1] != fold\n",
    "        print(\"Fold \"+str(fold+1))\n",
    "        X_train2 = torch.tensor(X_train[train_index,:], dtype=torch.float32)\n",
    "        X_valid2 = torch.tensor(X_train[valid_index,:], dtype=torch.float32)\n",
    "        X_train2 = X_train2[:,:-1]\n",
    "        X_valid2 = X_valid2[:,:-1]\n",
    "        \n",
    "        y_train2 = torch.tensor(y_train[train_index], dtype=torch.float32)\n",
    "        y_valid2 = torch.tensor(y_train[valid_index], dtype=torch.float32)\n",
    "        \n",
    "        train = torch.utils.data.TensorDataset(X_train2, y_train2)\n",
    "        valid = torch.utils.data.TensorDataset(X_valid2, y_valid2)\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True) \n",
    "        valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "            \n",
    "        clf = MoaModel(init_num, last_num)\n",
    "        loss_fn = SmoothCrossEntropyLoss(smoothing=smoothing)\n",
    "\n",
    "        optimizer = optim.Adam(clf.parameters(), lr = 0.001, weight_decay=1e-5) \n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=train_epochs, steps_per_epoch=len(train_loader))\n",
    "        \n",
    "        clf.to(device)\n",
    "        \n",
    "        best_val_loss = np.inf\n",
    "        stop_counts = 0\n",
    "        for epoch in range(train_epochs):\n",
    "            start_time = time.time()\n",
    "            clf.train()\n",
    "            avg_loss = 0.\n",
    "            sm_avg_loss = 0.\n",
    "            for x_batch, y_batch in tqdm(train_loader, disable=True):\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch) \n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                avg_loss += loss.item() / len(train_loader)  \n",
    "                sm_avg_loss += metric(y_pred, y_batch) / len(train_loader) \n",
    "                \n",
    "            clf.eval()\n",
    "            avg_val_loss = 0.\n",
    "            sm_avg_val_loss = 0.\n",
    "            for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch).detach()\n",
    "                avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "                sm_avg_val_loss += metric(y_pred, y_batch) / len(valid_loader)\n",
    "        \n",
    "            elapsed_time = time.time() - start_time \n",
    "            #scheduler.step() #avg_val_loss # maybe mistake\n",
    "                    \n",
    "            if sm_avg_val_loss < best_val_loss:\n",
    "                best_val_loss = sm_avg_val_loss\n",
    "                print('Epoch {}   loss={:.5f}   val_loss={:.5f}   sm_loss={:.5f}   sm_val_loss={:.5f}   time={:.2f}s'.format(\n",
    "                    epoch + 1, avg_loss, avg_val_loss, sm_avg_loss, sm_avg_val_loss, elapsed_time))\n",
    "                torch.save(clf.state_dict(), 'best-model-parameters.pt')\n",
    "            else:\n",
    "                stop_counts += 1\n",
    "        \n",
    "        pred_model = MoaModel(init_num, last_num)\n",
    "        pred_model.load_state_dict(torch.load('best-model-parameters.pt'))         \n",
    "        pred_model.eval()\n",
    "        \n",
    "        # validation check ----------------\n",
    "        oof_epoch = np.zeros([X_valid2.size(0), y_train.shape[1]])\n",
    "        target_epoch = np.zeros([X_valid2.size(0), y_train.shape[1]])\n",
    "        for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "                y_pred = pred_model(x_batch).detach()\n",
    "                oof_epoch[i * batch_size:(i+1) * batch_size,:] = torch.clamp(torch.sigmoid(y_pred.cpu()), p_min, p_max)\n",
    "                target_epoch[i * batch_size:(i+1) * batch_size,:] = y_batch.cpu().numpy()\n",
    "        print(\"Fold {} log loss: {}\".format(fold+1, mean_log_loss(target_epoch, oof_epoch)))\n",
    "        scores.append(mean_log_loss(target_epoch, oof_epoch))\n",
    "        oof[valid_index,:] = oof_epoch\n",
    "        oof_targets[valid_index,:] = target_epoch\n",
    "        #-----------------------------------\n",
    "        \n",
    "        # test predcition --------------\n",
    "        test_preds = np.zeros([test_len, y_train.shape[1]])\n",
    "        for i, (x_batch,) in enumerate(test_loader): \n",
    "            y_pred = pred_model(x_batch).detach()\n",
    "            test_preds[i * batch_size:(i+1) * batch_size, :] = torch.clamp(torch.sigmoid(y_pred.cpu()), p_min, p_max)\n",
    "        pred_value += test_preds / n_folds\n",
    "        # ------------------------------\n",
    "        \n",
    "    print(\"Seed {}\".format(seed_))\n",
    "    for i, ele in enumerate(scores):\n",
    "        print(\"Fold {} log loss: {}\".format(i+1, scores[i]))\n",
    "    print(\"Std of log loss: {}\".format(np.std(scores)))\n",
    "    print(\"Total log loss: {}\".format(mean_log_loss(oof_targets, oof)))\n",
    "    \n",
    "    return oof, oof_targets, pred_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T00:43:40.889357Z",
     "iopub.status.busy": "2020-11-11T00:43:40.887682Z",
     "iopub.status.idle": "2020-11-11T00:56:19.295357Z",
     "shell.execute_reply": "2020-11-11T00:56:19.294833Z"
    },
    "papermill": {
     "duration": 758.457792,
     "end_time": "2020-11-11T00:56:19.295479",
     "exception": false,
     "start_time": "2020-11-11T00:43:40.837687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1   loss=0.41238   val_loss=0.02259   sm_loss=0.41236   sm_val_loss=0.02256   time=1.54s\n",
      "Epoch 2   loss=0.02008   val_loss=0.02354   sm_loss=0.02004   sm_val_loss=0.02234   time=0.97s\n",
      "Epoch 3   loss=0.01822   val_loss=0.01781   sm_loss=0.01819   sm_val_loss=0.01784   time=0.98s\n",
      "Epoch 11   loss=0.01693   val_loss=0.01752   sm_loss=0.01706   sm_val_loss=0.01752   time=0.87s\n",
      "Epoch 13   loss=0.01648   val_loss=0.01733   sm_loss=0.01663   sm_val_loss=0.01735   time=0.91s\n",
      "Epoch 14   loss=0.01618   val_loss=0.01728   sm_loss=0.01634   sm_val_loss=0.01730   time=0.89s\n",
      "Epoch 15   loss=0.01584   val_loss=0.01725   sm_loss=0.01601   sm_val_loss=0.01728   time=0.88s\n",
      "Epoch 16   loss=0.01545   val_loss=0.01717   sm_loss=0.01564   sm_val_loss=0.01719   time=0.86s\n",
      "Epoch 17   loss=0.01501   val_loss=0.01700   sm_loss=0.01521   sm_val_loss=0.01703   time=1.11s\n",
      "Fold 1 log loss: 0.017101726328441796\n",
      "Fold 2\n",
      "Epoch 1   loss=0.41411   val_loss=0.02237   sm_loss=0.41407   sm_val_loss=0.02236   time=0.85s\n",
      "Epoch 2   loss=0.02020   val_loss=0.01846   sm_loss=0.02016   sm_val_loss=0.01849   time=0.86s\n",
      "Epoch 3   loss=0.01817   val_loss=0.01789   sm_loss=0.01820   sm_val_loss=0.01793   time=0.97s\n",
      "Epoch 4   loss=0.01758   val_loss=0.01774   sm_loss=0.01767   sm_val_loss=0.01780   time=0.87s\n",
      "Epoch 5   loss=0.01741   val_loss=0.01765   sm_loss=0.01753   sm_val_loss=0.01768   time=0.88s\n",
      "Epoch 8   loss=0.01729   val_loss=0.01753   sm_loss=0.01742   sm_val_loss=0.01754   time=0.89s\n",
      "Epoch 9   loss=0.01719   val_loss=0.01749   sm_loss=0.01732   sm_val_loss=0.01746   time=0.86s\n",
      "Epoch 11   loss=0.01696   val_loss=0.01730   sm_loss=0.01709   sm_val_loss=0.01734   time=1.01s\n",
      "Epoch 12   loss=0.01675   val_loss=0.01728   sm_loss=0.01690   sm_val_loss=0.01731   time=0.87s\n",
      "Epoch 14   loss=0.01620   val_loss=0.01698   sm_loss=0.01636   sm_val_loss=0.01696   time=0.94s\n",
      "Epoch 15   loss=0.01590   val_loss=0.01686   sm_loss=0.01608   sm_val_loss=0.01688   time=1.35s\n",
      "Epoch 16   loss=0.01548   val_loss=0.01683   sm_loss=0.01568   sm_val_loss=0.01685   time=0.87s\n",
      "Epoch 18   loss=0.01451   val_loss=0.01682   sm_loss=0.01473   sm_val_loss=0.01678   time=0.91s\n",
      "Epoch 20   loss=0.01389   val_loss=0.01679   sm_loss=0.01412   sm_val_loss=0.01677   time=0.87s\n",
      "Fold 2 log loss: 0.016750877294862878\n",
      "Fold 3\n",
      "Epoch 1   loss=0.41359   val_loss=0.02333   sm_loss=0.41355   sm_val_loss=0.02332   time=0.87s\n",
      "Epoch 2   loss=0.02010   val_loss=0.01935   sm_loss=0.02005   sm_val_loss=0.01937   time=0.86s\n",
      "Epoch 3   loss=0.01791   val_loss=0.01864   sm_loss=0.01797   sm_val_loss=0.01867   time=0.87s\n",
      "Epoch 4   loss=0.01752   val_loss=0.01859   sm_loss=0.01760   sm_val_loss=0.01860   time=0.90s\n",
      "Epoch 8   loss=0.01717   val_loss=0.01840   sm_loss=0.01729   sm_val_loss=0.01840   time=0.96s\n",
      "Epoch 11   loss=0.01683   val_loss=0.01803   sm_loss=0.01696   sm_val_loss=0.01803   time=0.86s\n",
      "Epoch 14   loss=0.01615   val_loss=0.01795   sm_loss=0.01631   sm_val_loss=0.01796   time=0.87s\n",
      "Epoch 15   loss=0.01575   val_loss=0.01779   sm_loss=0.01592   sm_val_loss=0.01781   time=0.97s\n",
      "Epoch 17   loss=0.01489   val_loss=0.01773   sm_loss=0.01509   sm_val_loss=0.01774   time=0.86s\n",
      "Epoch 18   loss=0.01440   val_loss=0.01766   sm_loss=0.01462   sm_val_loss=0.01767   time=0.87s\n",
      "Fold 3 log loss: 0.01766950572467899\n",
      "Fold 4\n",
      "Epoch 1   loss=0.41299   val_loss=0.02227   sm_loss=0.41294   sm_val_loss=0.02225   time=1.33s\n",
      "Epoch 2   loss=0.02031   val_loss=0.02029   sm_loss=0.02025   sm_val_loss=0.02031   time=1.21s\n",
      "Epoch 3   loss=0.01809   val_loss=0.01785   sm_loss=0.01812   sm_val_loss=0.01789   time=1.01s\n",
      "Epoch 9   loss=0.01715   val_loss=0.01768   sm_loss=0.01727   sm_val_loss=0.01771   time=0.90s\n",
      "Epoch 11   loss=0.01695   val_loss=0.01760   sm_loss=0.01708   sm_val_loss=0.01763   time=1.02s\n",
      "Epoch 14   loss=0.01629   val_loss=0.01738   sm_loss=0.01645   sm_val_loss=0.01743   time=0.88s\n",
      "Epoch 15   loss=0.01591   val_loss=0.01728   sm_loss=0.01609   sm_val_loss=0.01733   time=0.86s\n",
      "Epoch 16   loss=0.01548   val_loss=0.01718   sm_loss=0.01566   sm_val_loss=0.01724   time=0.91s\n",
      "Epoch 18   loss=0.01453   val_loss=0.01713   sm_loss=0.01474   sm_val_loss=0.01717   time=0.85s\n",
      "Epoch 19   loss=0.01412   val_loss=0.01710   sm_loss=0.01434   sm_val_loss=0.01715   time=1.04s\n",
      "Fold 4 log loss: 0.017197101188504076\n",
      "Fold 5\n",
      "Epoch 1   loss=0.41246   val_loss=0.02212   sm_loss=0.41242   sm_val_loss=0.02210   time=1.02s\n",
      "Epoch 3   loss=0.01815   val_loss=0.01795   sm_loss=0.01819   sm_val_loss=0.01800   time=0.87s\n",
      "Epoch 4   loss=0.01763   val_loss=0.01770   sm_loss=0.01773   sm_val_loss=0.01775   time=0.88s\n",
      "Epoch 5   loss=0.01742   val_loss=0.01752   sm_loss=0.01754   sm_val_loss=0.01753   time=1.03s\n",
      "Epoch 10   loss=0.01722   val_loss=0.01746   sm_loss=0.01734   sm_val_loss=0.01749   time=1.01s\n",
      "Epoch 11   loss=0.01706   val_loss=0.01727   sm_loss=0.01718   sm_val_loss=0.01729   time=0.87s\n",
      "Epoch 12   loss=0.01684   val_loss=0.01703   sm_loss=0.01698   sm_val_loss=0.01707   time=0.89s\n",
      "Epoch 15   loss=0.01601   val_loss=0.01689   sm_loss=0.01619   sm_val_loss=0.01691   time=1.38s\n",
      "Epoch 16   loss=0.01563   val_loss=0.01681   sm_loss=0.01581   sm_val_loss=0.01683   time=0.94s\n",
      "Epoch 18   loss=0.01473   val_loss=0.01681   sm_loss=0.01494   sm_val_loss=0.01682   time=0.86s\n",
      "Epoch 20   loss=0.01416   val_loss=0.01679   sm_loss=0.01438   sm_val_loss=0.01681   time=1.08s\n",
      "Fold 5 log loss: 0.01682594723394819\n",
      "Fold 6\n",
      "Epoch 1   loss=0.41241   val_loss=0.02354   sm_loss=0.41238   sm_val_loss=0.02352   time=0.89s\n",
      "Epoch 2   loss=0.01994   val_loss=0.01963   sm_loss=0.01991   sm_val_loss=0.01950   time=0.86s\n",
      "Epoch 3   loss=0.01807   val_loss=0.01941   sm_loss=0.01811   sm_val_loss=0.01924   time=0.87s\n",
      "Epoch 4   loss=0.01732   val_loss=0.01905   sm_loss=0.01744   sm_val_loss=0.01891   time=0.87s\n",
      "Epoch 5   loss=0.01727   val_loss=0.01894   sm_loss=0.01739   sm_val_loss=0.01889   time=0.86s\n",
      "Epoch 6   loss=0.01720   val_loss=0.01891   sm_loss=0.01732   sm_val_loss=0.01888   time=0.89s\n",
      "Epoch 8   loss=0.01711   val_loss=0.01878   sm_loss=0.01723   sm_val_loss=0.01882   time=0.88s\n",
      "Epoch 9   loss=0.01709   val_loss=0.01836   sm_loss=0.01721   sm_val_loss=0.01838   time=0.86s\n",
      "Epoch 12   loss=0.01661   val_loss=0.01807   sm_loss=0.01675   sm_val_loss=0.01813   time=0.91s\n",
      "Epoch 13   loss=0.01641   val_loss=0.01795   sm_loss=0.01656   sm_val_loss=0.01796   time=0.94s\n",
      "Epoch 14   loss=0.01615   val_loss=0.01781   sm_loss=0.01631   sm_val_loss=0.01788   time=0.87s\n",
      "Epoch 16   loss=0.01533   val_loss=0.01773   sm_loss=0.01552   sm_val_loss=0.01778   time=0.93s\n",
      "Epoch 19   loss=0.01407   val_loss=0.01773   sm_loss=0.01429   sm_val_loss=0.01777   time=1.09s\n",
      "Fold 6 log loss: 0.01794999410405827\n",
      "Fold 7\n",
      "Epoch 1   loss=0.41293   val_loss=0.02232   sm_loss=0.41291   sm_val_loss=0.02231   time=0.87s\n",
      "Epoch 2   loss=0.02024   val_loss=0.01946   sm_loss=0.02017   sm_val_loss=0.01947   time=0.96s\n",
      "Epoch 3   loss=0.01807   val_loss=0.01785   sm_loss=0.01811   sm_val_loss=0.01792   time=0.97s\n",
      "Epoch 4   loss=0.01756   val_loss=0.01782   sm_loss=0.01767   sm_val_loss=0.01789   time=1.12s\n",
      "Epoch 5   loss=0.01740   val_loss=0.01755   sm_loss=0.01752   sm_val_loss=0.01764   time=1.05s\n",
      "Epoch 9   loss=0.01726   val_loss=0.01754   sm_loss=0.01738   sm_val_loss=0.01762   time=0.85s\n",
      "Epoch 11   loss=0.01695   val_loss=0.01744   sm_loss=0.01708   sm_val_loss=0.01751   time=0.90s\n",
      "Epoch 12   loss=0.01678   val_loss=0.01726   sm_loss=0.01691   sm_val_loss=0.01733   time=0.86s\n",
      "Epoch 14   loss=0.01626   val_loss=0.01705   sm_loss=0.01642   sm_val_loss=0.01713   time=0.87s\n",
      "Epoch 15   loss=0.01589   val_loss=0.01697   sm_loss=0.01606   sm_val_loss=0.01703   time=1.03s\n",
      "Epoch 17   loss=0.01502   val_loss=0.01691   sm_loss=0.01521   sm_val_loss=0.01699   time=1.03s\n",
      "Epoch 19   loss=0.01415   val_loss=0.01684   sm_loss=0.01436   sm_val_loss=0.01691   time=0.85s\n",
      "Fold 7 log loss: 0.01694004410093994\n",
      "Seed 0\n",
      "Fold 1 log loss: 0.017101726328441796\n",
      "Fold 2 log loss: 0.016750877294862878\n",
      "Fold 3 log loss: 0.01766950572467899\n",
      "Fold 4 log loss: 0.017197101188504076\n",
      "Fold 5 log loss: 0.01682594723394819\n",
      "Fold 6 log loss: 0.01794999410405827\n",
      "Fold 7 log loss: 0.01694004410093994\n",
      "Std of log loss: 0.0004143186626488605\n",
      "Total log loss: 0.017204242717156776\n",
      "Fold 1\n",
      "Epoch 1   loss=0.41198   val_loss=0.02237   sm_loss=0.41196   sm_val_loss=0.02231   time=0.87s\n",
      "Epoch 2   loss=0.02016   val_loss=0.02005   sm_loss=0.02014   sm_val_loss=0.01990   time=0.98s\n",
      "Epoch 3   loss=0.01805   val_loss=0.01807   sm_loss=0.01811   sm_val_loss=0.01808   time=0.87s\n",
      "Epoch 5   loss=0.01735   val_loss=0.01796   sm_loss=0.01747   sm_val_loss=0.01800   time=0.89s\n",
      "Epoch 9   loss=0.01724   val_loss=0.01766   sm_loss=0.01736   sm_val_loss=0.01769   time=0.86s\n",
      "Epoch 11   loss=0.01697   val_loss=0.01752   sm_loss=0.01710   sm_val_loss=0.01756   time=1.05s\n",
      "Epoch 12   loss=0.01683   val_loss=0.01751   sm_loss=0.01697   sm_val_loss=0.01755   time=0.89s\n",
      "Epoch 13   loss=0.01646   val_loss=0.01741   sm_loss=0.01661   sm_val_loss=0.01744   time=1.01s\n",
      "Epoch 14   loss=0.01624   val_loss=0.01725   sm_loss=0.01640   sm_val_loss=0.01728   time=1.16s\n",
      "Epoch 15   loss=0.01598   val_loss=0.01724   sm_loss=0.01615   sm_val_loss=0.01726   time=0.90s\n",
      "Epoch 16   loss=0.01555   val_loss=0.01709   sm_loss=0.01573   sm_val_loss=0.01711   time=0.87s\n",
      "Epoch 17   loss=0.01506   val_loss=0.01707   sm_loss=0.01526   sm_val_loss=0.01708   time=0.88s\n",
      "Epoch 18   loss=0.01462   val_loss=0.01706   sm_loss=0.01482   sm_val_loss=0.01706   time=0.99s\n",
      "Epoch 19   loss=0.01422   val_loss=0.01700   sm_loss=0.01443   sm_val_loss=0.01700   time=0.86s\n",
      "Fold 1 log loss: 0.017078901515481408\n",
      "Fold 2\n",
      "Epoch 1   loss=0.41305   val_loss=0.02331   sm_loss=0.41298   sm_val_loss=0.02330   time=0.90s\n",
      "Epoch 2   loss=0.02014   val_loss=0.01866   sm_loss=0.02010   sm_val_loss=0.01870   time=0.86s\n",
      "Epoch 3   loss=0.01829   val_loss=0.01780   sm_loss=0.01828   sm_val_loss=0.01782   time=0.87s\n",
      "Epoch 5   loss=0.01740   val_loss=0.01753   sm_loss=0.01752   sm_val_loss=0.01755   time=1.08s\n",
      "Epoch 9   loss=0.01721   val_loss=0.01746   sm_loss=0.01733   sm_val_loss=0.01746   time=1.01s\n",
      "Epoch 11   loss=0.01700   val_loss=0.01734   sm_loss=0.01714   sm_val_loss=0.01735   time=1.15s\n",
      "Epoch 12   loss=0.01683   val_loss=0.01722   sm_loss=0.01697   sm_val_loss=0.01727   time=0.87s\n",
      "Epoch 13   loss=0.01654   val_loss=0.01727   sm_loss=0.01669   sm_val_loss=0.01724   time=0.86s\n",
      "Epoch 14   loss=0.01625   val_loss=0.01696   sm_loss=0.01642   sm_val_loss=0.01701   time=1.26s\n",
      "Epoch 16   loss=0.01550   val_loss=0.01691   sm_loss=0.01569   sm_val_loss=0.01691   time=0.89s\n",
      "Epoch 17   loss=0.01502   val_loss=0.01682   sm_loss=0.01522   sm_val_loss=0.01683   time=1.13s\n",
      "Epoch 20   loss=0.01383   val_loss=0.01683   sm_loss=0.01405   sm_val_loss=0.01683   time=0.95s\n",
      "Fold 2 log loss: 0.016807503539042774\n",
      "Fold 3\n",
      "Epoch 1   loss=0.41403   val_loss=0.02297   sm_loss=0.41398   sm_val_loss=0.02294   time=1.07s\n",
      "Epoch 2   loss=0.02011   val_loss=0.01965   sm_loss=0.02008   sm_val_loss=0.01960   time=0.92s\n",
      "Epoch 3   loss=0.01795   val_loss=0.01869   sm_loss=0.01800   sm_val_loss=0.01873   time=1.31s\n",
      "Epoch 4   loss=0.01753   val_loss=0.01859   sm_loss=0.01761   sm_val_loss=0.01857   time=0.95s\n",
      "Epoch 7   loss=0.01724   val_loss=0.01843   sm_loss=0.01736   sm_val_loss=0.01841   time=0.89s\n",
      "Epoch 8   loss=0.01716   val_loss=0.01816   sm_loss=0.01728   sm_val_loss=0.01816   time=0.89s\n",
      "Epoch 11   loss=0.01683   val_loss=0.01803   sm_loss=0.01696   sm_val_loss=0.01805   time=1.20s\n",
      "Epoch 14   loss=0.01617   val_loss=0.01794   sm_loss=0.01633   sm_val_loss=0.01796   time=0.86s\n",
      "Epoch 15   loss=0.01584   val_loss=0.01780   sm_loss=0.01601   sm_val_loss=0.01785   time=0.87s\n",
      "Epoch 16   loss=0.01545   val_loss=0.01768   sm_loss=0.01563   sm_val_loss=0.01768   time=0.86s\n",
      "Epoch 18   loss=0.01446   val_loss=0.01756   sm_loss=0.01466   sm_val_loss=0.01761   time=0.87s\n",
      "Epoch 19   loss=0.01408   val_loss=0.01757   sm_loss=0.01430   sm_val_loss=0.01760   time=1.06s\n",
      "Epoch 20   loss=0.01387   val_loss=0.01757   sm_loss=0.01408   sm_val_loss=0.01759   time=1.00s\n",
      "Fold 3 log loss: 0.01758660805670084\n",
      "Fold 4\n",
      "Epoch 1   loss=0.41330   val_loss=0.02199   sm_loss=0.41326   sm_val_loss=0.02198   time=1.02s\n",
      "Epoch 2   loss=0.02021   val_loss=0.02070   sm_loss=0.02015   sm_val_loss=0.02071   time=1.09s\n",
      "Epoch 3   loss=0.01808   val_loss=0.01802   sm_loss=0.01810   sm_val_loss=0.01805   time=1.03s\n",
      "Epoch 4   loss=0.01751   val_loss=0.01796   sm_loss=0.01762   sm_val_loss=0.01799   time=0.87s\n",
      "Epoch 9   loss=0.01713   val_loss=0.01790   sm_loss=0.01726   sm_val_loss=0.01795   time=0.86s\n",
      "Epoch 10   loss=0.01710   val_loss=0.01776   sm_loss=0.01723   sm_val_loss=0.01779   time=0.97s\n",
      "Epoch 12   loss=0.01677   val_loss=0.01752   sm_loss=0.01690   sm_val_loss=0.01760   time=1.10s\n",
      "Epoch 14   loss=0.01619   val_loss=0.01727   sm_loss=0.01636   sm_val_loss=0.01731   time=1.31s\n",
      "Epoch 16   loss=0.01548   val_loss=0.01725   sm_loss=0.01567   sm_val_loss=0.01729   time=0.90s\n",
      "Epoch 17   loss=0.01499   val_loss=0.01714   sm_loss=0.01519   sm_val_loss=0.01720   time=0.91s\n",
      "Epoch 18   loss=0.01452   val_loss=0.01714   sm_loss=0.01474   sm_val_loss=0.01720   time=0.87s\n",
      "Fold 4 log loss: 0.017241207219019186\n",
      "Fold 5\n",
      "Epoch 1   loss=0.41272   val_loss=0.02237   sm_loss=0.41268   sm_val_loss=0.02235   time=1.10s\n",
      "Epoch 2   loss=0.02031   val_loss=0.02082   sm_loss=0.02026   sm_val_loss=0.02073   time=1.01s\n",
      "Epoch 3   loss=0.01845   val_loss=0.01779   sm_loss=0.01845   sm_val_loss=0.01782   time=0.86s\n",
      "Epoch 4   loss=0.01768   val_loss=0.01776   sm_loss=0.01779   sm_val_loss=0.01780   time=0.86s\n",
      "Epoch 5   loss=0.01760   val_loss=0.01781   sm_loss=0.01771   sm_val_loss=0.01778   time=0.87s\n",
      "Epoch 6   loss=0.01750   val_loss=0.01765   sm_loss=0.01762   sm_val_loss=0.01766   time=0.88s\n",
      "Epoch 7   loss=0.01739   val_loss=0.01739   sm_loss=0.01751   sm_val_loss=0.01743   time=0.90s\n",
      "Epoch 10   loss=0.01715   val_loss=0.01737   sm_loss=0.01727   sm_val_loss=0.01738   time=1.19s\n",
      "Epoch 11   loss=0.01704   val_loss=0.01714   sm_loss=0.01717   sm_val_loss=0.01719   time=0.91s\n",
      "Epoch 14   loss=0.01634   val_loss=0.01714   sm_loss=0.01650   sm_val_loss=0.01711   time=0.93s\n",
      "Epoch 16   loss=0.01562   val_loss=0.01706   sm_loss=0.01581   sm_val_loss=0.01707   time=0.96s\n",
      "Epoch 17   loss=0.01514   val_loss=0.01694   sm_loss=0.01534   sm_val_loss=0.01694   time=1.02s\n",
      "Epoch 18   loss=0.01469   val_loss=0.01693   sm_loss=0.01489   sm_val_loss=0.01693   time=0.89s\n",
      "Fold 5 log loss: 0.016956884382465127\n",
      "Fold 6\n",
      "Epoch 1   loss=0.41212   val_loss=0.02365   sm_loss=0.41206   sm_val_loss=0.02364   time=0.90s\n",
      "Epoch 2   loss=0.02001   val_loss=0.02008   sm_loss=0.01998   sm_val_loss=0.01983   time=1.05s\n",
      "Epoch 3   loss=0.01777   val_loss=0.01983   sm_loss=0.01786   sm_val_loss=0.01945   time=1.22s\n",
      "Epoch 4   loss=0.01736   val_loss=0.01947   sm_loss=0.01748   sm_val_loss=0.01941   time=0.88s\n",
      "Epoch 5   loss=0.01726   val_loss=0.01900   sm_loss=0.01738   sm_val_loss=0.01890   time=0.86s\n",
      "Epoch 8   loss=0.01713   val_loss=0.01855   sm_loss=0.01725   sm_val_loss=0.01854   time=0.87s\n",
      "Epoch 9   loss=0.01704   val_loss=0.01849   sm_loss=0.01716   sm_val_loss=0.01847   time=0.98s\n",
      "Epoch 10   loss=0.01701   val_loss=0.01825   sm_loss=0.01713   sm_val_loss=0.01823   time=0.87s\n",
      "Epoch 14   loss=0.01614   val_loss=0.01815   sm_loss=0.01630   sm_val_loss=0.01819   time=1.23s\n",
      "Epoch 15   loss=0.01579   val_loss=0.01788   sm_loss=0.01596   sm_val_loss=0.01790   time=0.89s\n",
      "Epoch 16   loss=0.01545   val_loss=0.01762   sm_loss=0.01563   sm_val_loss=0.01766   time=0.91s\n",
      "Fold 6 log loss: 0.01790505060078061\n",
      "Fold 7\n",
      "Epoch 1   loss=0.41376   val_loss=0.02253   sm_loss=0.41371   sm_val_loss=0.02253   time=0.86s\n",
      "Epoch 2   loss=0.02019   val_loss=0.01951   sm_loss=0.02013   sm_val_loss=0.01953   time=0.86s\n",
      "Epoch 3   loss=0.01819   val_loss=0.01791   sm_loss=0.01819   sm_val_loss=0.01798   time=0.96s\n",
      "Epoch 6   loss=0.01731   val_loss=0.01782   sm_loss=0.01743   sm_val_loss=0.01787   time=0.98s\n",
      "Epoch 9   loss=0.01722   val_loss=0.01769   sm_loss=0.01735   sm_val_loss=0.01774   time=0.86s\n",
      "Epoch 11   loss=0.01689   val_loss=0.01749   sm_loss=0.01703   sm_val_loss=0.01754   time=0.88s\n",
      "Epoch 12   loss=0.01674   val_loss=0.01745   sm_loss=0.01688   sm_val_loss=0.01751   time=0.86s\n",
      "Epoch 13   loss=0.01649   val_loss=0.01739   sm_loss=0.01663   sm_val_loss=0.01745   time=1.06s\n",
      "Epoch 14   loss=0.01627   val_loss=0.01715   sm_loss=0.01643   sm_val_loss=0.01724   time=0.91s\n",
      "Epoch 15   loss=0.01589   val_loss=0.01705   sm_loss=0.01607   sm_val_loss=0.01711   time=1.64s\n",
      "Epoch 16   loss=0.01547   val_loss=0.01698   sm_loss=0.01566   sm_val_loss=0.01706   time=0.85s\n",
      "Epoch 17   loss=0.01499   val_loss=0.01691   sm_loss=0.01518   sm_val_loss=0.01699   time=0.87s\n",
      "Epoch 18   loss=0.01452   val_loss=0.01690   sm_loss=0.01473   sm_val_loss=0.01698   time=0.89s\n",
      "Epoch 20   loss=0.01391   val_loss=0.01689   sm_loss=0.01413   sm_val_loss=0.01696   time=0.91s\n",
      "Fold 7 log loss: 0.016987254071742956\n",
      "Seed 1\n",
      "Fold 1 log loss: 0.017078901515481408\n",
      "Fold 2 log loss: 0.016807503539042774\n",
      "Fold 3 log loss: 0.01758660805670084\n",
      "Fold 4 log loss: 0.017241207219019186\n",
      "Fold 5 log loss: 0.016956884382465127\n",
      "Fold 6 log loss: 0.01790505060078061\n",
      "Fold 7 log loss: 0.016987254071742956\n",
      "Std of log loss: 0.0003620437742547417\n",
      "Total log loss: 0.01722248547246913\n",
      "Fold 1\n",
      "Epoch 1   loss=0.41208   val_loss=0.02215   sm_loss=0.41201   sm_val_loss=0.02211   time=0.88s\n",
      "Epoch 2   loss=0.02005   val_loss=0.01851   sm_loss=0.02001   sm_val_loss=0.01855   time=0.98s\n",
      "Epoch 4   loss=0.01758   val_loss=0.01831   sm_loss=0.01767   sm_val_loss=0.01827   time=0.87s\n",
      "Epoch 5   loss=0.01745   val_loss=0.01809   sm_loss=0.01757   sm_val_loss=0.01812   time=1.33s\n",
      "Epoch 6   loss=0.01739   val_loss=0.01798   sm_loss=0.01750   sm_val_loss=0.01795   time=0.86s\n",
      "Epoch 9   loss=0.01719   val_loss=0.01767   sm_loss=0.01732   sm_val_loss=0.01770   time=1.11s\n",
      "Epoch 11   loss=0.01695   val_loss=0.01760   sm_loss=0.01708   sm_val_loss=0.01763   time=0.91s\n",
      "Epoch 12   loss=0.01684   val_loss=0.01758   sm_loss=0.01698   sm_val_loss=0.01758   time=1.00s\n",
      "Epoch 13   loss=0.01647   val_loss=0.01737   sm_loss=0.01662   sm_val_loss=0.01739   time=1.07s\n",
      "Epoch 15   loss=0.01587   val_loss=0.01717   sm_loss=0.01605   sm_val_loss=0.01721   time=0.94s\n",
      "Epoch 17   loss=0.01504   val_loss=0.01710   sm_loss=0.01524   sm_val_loss=0.01712   time=0.98s\n",
      "Epoch 18   loss=0.01454   val_loss=0.01710   sm_loss=0.01475   sm_val_loss=0.01711   time=0.94s\n",
      "Epoch 19   loss=0.01415   val_loss=0.01709   sm_loss=0.01437   sm_val_loss=0.01710   time=0.95s\n",
      "Fold 1 log loss: 0.01717610434450897\n",
      "Fold 2\n",
      "Epoch 1   loss=0.41349   val_loss=0.02237   sm_loss=0.41343   sm_val_loss=0.02234   time=0.89s\n",
      "Epoch 2   loss=0.02041   val_loss=0.01857   sm_loss=0.02033   sm_val_loss=0.01858   time=1.32s\n",
      "Epoch 3   loss=0.01815   val_loss=0.01774   sm_loss=0.01822   sm_val_loss=0.01778   time=0.95s\n",
      "Epoch 5   loss=0.01744   val_loss=0.01774   sm_loss=0.01756   sm_val_loss=0.01771   time=0.86s\n",
      "Epoch 8   loss=0.01732   val_loss=0.01760   sm_loss=0.01745   sm_val_loss=0.01761   time=0.86s\n",
      "Epoch 9   loss=0.01720   val_loss=0.01740   sm_loss=0.01732   sm_val_loss=0.01743   time=0.87s\n",
      "Epoch 12   loss=0.01674   val_loss=0.01736   sm_loss=0.01689   sm_val_loss=0.01736   time=0.85s\n",
      "Epoch 13   loss=0.01656   val_loss=0.01709   sm_loss=0.01672   sm_val_loss=0.01712   time=0.88s\n",
      "Epoch 14   loss=0.01626   val_loss=0.01697   sm_loss=0.01643   sm_val_loss=0.01699   time=1.21s\n",
      "Epoch 16   loss=0.01550   val_loss=0.01684   sm_loss=0.01569   sm_val_loss=0.01688   time=1.09s\n",
      "Epoch 17   loss=0.01501   val_loss=0.01681   sm_loss=0.01521   sm_val_loss=0.01685   time=0.96s\n",
      "Epoch 18   loss=0.01453   val_loss=0.01677   sm_loss=0.01474   sm_val_loss=0.01679   time=0.87s\n",
      "Epoch 19   loss=0.01412   val_loss=0.01673   sm_loss=0.01434   sm_val_loss=0.01676   time=0.88s\n",
      "Epoch 20   loss=0.01391   val_loss=0.01672   sm_loss=0.01414   sm_val_loss=0.01675   time=0.86s\n",
      "Fold 2 log loss: 0.016722774068367686\n",
      "Fold 3\n",
      "Epoch 1   loss=0.41339   val_loss=0.02301   sm_loss=0.41336   sm_val_loss=0.02300   time=0.88s\n",
      "Epoch 2   loss=0.02012   val_loss=0.01940   sm_loss=0.02006   sm_val_loss=0.01932   time=0.86s\n",
      "Epoch 3   loss=0.01803   val_loss=0.01887   sm_loss=0.01806   sm_val_loss=0.01883   time=0.86s\n",
      "Epoch 4   loss=0.01738   val_loss=0.01873   sm_loss=0.01748   sm_val_loss=0.01866   time=1.09s\n",
      "Epoch 5   loss=0.01725   val_loss=0.01848   sm_loss=0.01737   sm_val_loss=0.01852   time=0.87s\n",
      "Epoch 6   loss=0.01719   val_loss=0.01844   sm_loss=0.01731   sm_val_loss=0.01841   time=0.86s\n",
      "Epoch 8   loss=0.01714   val_loss=0.01829   sm_loss=0.01726   sm_val_loss=0.01827   time=0.91s\n",
      "Epoch 13   loss=0.01645   val_loss=0.01806   sm_loss=0.01660   sm_val_loss=0.01805   time=1.16s\n",
      "Epoch 14   loss=0.01611   val_loss=0.01801   sm_loss=0.01627   sm_val_loss=0.01802   time=1.02s\n",
      "Epoch 15   loss=0.01578   val_loss=0.01775   sm_loss=0.01596   sm_val_loss=0.01779   time=1.18s\n",
      "Epoch 17   loss=0.01496   val_loss=0.01779   sm_loss=0.01516   sm_val_loss=0.01778   time=0.93s\n",
      "Epoch 19   loss=0.01411   val_loss=0.01777   sm_loss=0.01433   sm_val_loss=0.01776   time=0.88s\n",
      "Epoch 20   loss=0.01387   val_loss=0.01773   sm_loss=0.01409   sm_val_loss=0.01773   time=0.88s\n",
      "Fold 3 log loss: 0.017728729973789627\n",
      "Fold 4\n",
      "Epoch 1   loss=0.41272   val_loss=0.02209   sm_loss=0.41267   sm_val_loss=0.02206   time=1.23s\n",
      "Epoch 2   loss=0.02006   val_loss=0.01863   sm_loss=0.02003   sm_val_loss=0.01862   time=1.08s\n",
      "Epoch 3   loss=0.01805   val_loss=0.01790   sm_loss=0.01811   sm_val_loss=0.01793   time=0.93s\n",
      "Epoch 5   loss=0.01731   val_loss=0.01786   sm_loss=0.01744   sm_val_loss=0.01792   time=1.02s\n",
      "Epoch 7   loss=0.01728   val_loss=0.01785   sm_loss=0.01740   sm_val_loss=0.01790   time=0.88s\n",
      "Epoch 8   loss=0.01715   val_loss=0.01774   sm_loss=0.01727   sm_val_loss=0.01778   time=0.89s\n",
      "Epoch 12   loss=0.01667   val_loss=0.01752   sm_loss=0.01682   sm_val_loss=0.01758   time=0.86s\n",
      "Epoch 14   loss=0.01613   val_loss=0.01744   sm_loss=0.01630   sm_val_loss=0.01749   time=0.88s\n",
      "Epoch 15   loss=0.01578   val_loss=0.01733   sm_loss=0.01596   sm_val_loss=0.01739   time=1.13s\n",
      "Epoch 16   loss=0.01537   val_loss=0.01725   sm_loss=0.01556   sm_val_loss=0.01729   time=1.04s\n",
      "Fold 4 log loss: 0.017331577997648756\n",
      "Fold 5\n",
      "Epoch 1   loss=0.41221   val_loss=0.02222   sm_loss=0.41215   sm_val_loss=0.02221   time=0.94s\n",
      "Epoch 3   loss=0.01850   val_loss=0.01755   sm_loss=0.01850   sm_val_loss=0.01757   time=0.89s\n",
      "Epoch 8   loss=0.01737   val_loss=0.01749   sm_loss=0.01750   sm_val_loss=0.01749   time=0.87s\n",
      "Epoch 10   loss=0.01714   val_loss=0.01733   sm_loss=0.01727   sm_val_loss=0.01737   time=0.87s\n",
      "Epoch 11   loss=0.01700   val_loss=0.01712   sm_loss=0.01714   sm_val_loss=0.01717   time=0.90s\n",
      "Epoch 14   loss=0.01622   val_loss=0.01702   sm_loss=0.01638   sm_val_loss=0.01704   time=0.88s\n",
      "Epoch 16   loss=0.01555   val_loss=0.01701   sm_loss=0.01574   sm_val_loss=0.01703   time=0.87s\n",
      "Epoch 17   loss=0.01506   val_loss=0.01689   sm_loss=0.01526   sm_val_loss=0.01691   time=1.11s\n",
      "Epoch 18   loss=0.01455   val_loss=0.01684   sm_loss=0.01476   sm_val_loss=0.01686   time=0.88s\n",
      "Epoch 19   loss=0.01417   val_loss=0.01683   sm_loss=0.01439   sm_val_loss=0.01684   time=0.91s\n",
      "Fold 5 log loss: 0.016861287600582076\n",
      "Fold 6\n",
      "Epoch 1   loss=0.41236   val_loss=0.02326   sm_loss=0.41231   sm_val_loss=0.02323   time=0.90s\n",
      "Epoch 2   loss=0.01982   val_loss=0.02050   sm_loss=0.01981   sm_val_loss=0.02048   time=0.86s\n",
      "Epoch 3   loss=0.01804   val_loss=0.01984   sm_loss=0.01809   sm_val_loss=0.01983   time=0.87s\n",
      "Epoch 4   loss=0.01744   val_loss=0.01899   sm_loss=0.01755   sm_val_loss=0.01903   time=0.90s\n",
      "Epoch 5   loss=0.01721   val_loss=0.01878   sm_loss=0.01734   sm_val_loss=0.01880   time=0.88s\n",
      "Epoch 6   loss=0.01721   val_loss=0.01867   sm_loss=0.01733   sm_val_loss=0.01865   time=0.87s\n",
      "Epoch 8   loss=0.01711   val_loss=0.01858   sm_loss=0.01723   sm_val_loss=0.01858   time=0.89s\n",
      "Epoch 10   loss=0.01695   val_loss=0.01845   sm_loss=0.01708   sm_val_loss=0.01844   time=0.87s\n",
      "Epoch 12   loss=0.01662   val_loss=0.01834   sm_loss=0.01676   sm_val_loss=0.01835   time=0.89s\n",
      "Epoch 13   loss=0.01640   val_loss=0.01816   sm_loss=0.01654   sm_val_loss=0.01815   time=0.87s\n",
      "Epoch 14   loss=0.01615   val_loss=0.01804   sm_loss=0.01631   sm_val_loss=0.01802   time=1.19s\n",
      "Epoch 15   loss=0.01572   val_loss=0.01783   sm_loss=0.01589   sm_val_loss=0.01784   time=0.99s\n",
      "Epoch 16   loss=0.01536   val_loss=0.01778   sm_loss=0.01555   sm_val_loss=0.01783   time=0.93s\n",
      "Epoch 18   loss=0.01441   val_loss=0.01775   sm_loss=0.01462   sm_val_loss=0.01777   time=1.17s\n",
      "Fold 6 log loss: 0.017984507383999607\n",
      "Fold 7\n",
      "Epoch 1   loss=0.41304   val_loss=0.02262   sm_loss=0.41301   sm_val_loss=0.02261   time=0.93s\n",
      "Epoch 3   loss=0.01818   val_loss=0.01803   sm_loss=0.01820   sm_val_loss=0.01809   time=1.08s\n",
      "Epoch 4   loss=0.01756   val_loss=0.01795   sm_loss=0.01765   sm_val_loss=0.01798   time=0.93s\n",
      "Epoch 5   loss=0.01737   val_loss=0.01785   sm_loss=0.01750   sm_val_loss=0.01792   time=1.04s\n",
      "Epoch 6   loss=0.01732   val_loss=0.01777   sm_loss=0.01745   sm_val_loss=0.01782   time=0.92s\n",
      "Epoch 7   loss=0.01730   val_loss=0.01763   sm_loss=0.01741   sm_val_loss=0.01770   time=1.24s\n",
      "Epoch 10   loss=0.01717   val_loss=0.01731   sm_loss=0.01730   sm_val_loss=0.01737   time=0.89s\n",
      "Epoch 12   loss=0.01672   val_loss=0.01727   sm_loss=0.01686   sm_val_loss=0.01734   time=0.87s\n",
      "Epoch 14   loss=0.01620   val_loss=0.01715   sm_loss=0.01636   sm_val_loss=0.01723   time=1.04s\n",
      "Epoch 15   loss=0.01591   val_loss=0.01706   sm_loss=0.01608   sm_val_loss=0.01714   time=0.87s\n",
      "Epoch 16   loss=0.01550   val_loss=0.01695   sm_loss=0.01568   sm_val_loss=0.01702   time=0.87s\n",
      "Epoch 18   loss=0.01452   val_loss=0.01689   sm_loss=0.01473   sm_val_loss=0.01695   time=0.89s\n",
      "Epoch 19   loss=0.01412   val_loss=0.01687   sm_loss=0.01433   sm_val_loss=0.01694   time=0.88s\n",
      "Epoch 20   loss=0.01391   val_loss=0.01686   sm_loss=0.01413   sm_val_loss=0.01693   time=0.87s\n",
      "Fold 7 log loss: 0.016947083889813846\n",
      "Seed 2\n",
      "Fold 1 log loss: 0.01717610434450897\n",
      "Fold 2 log loss: 0.016722774068367686\n",
      "Fold 3 log loss: 0.017728729973789627\n",
      "Fold 4 log loss: 0.017331577997648756\n",
      "Fold 5 log loss: 0.016861287600582076\n",
      "Fold 6 log loss: 0.017984507383999607\n",
      "Fold 7 log loss: 0.016947083889813846\n",
      "Std of log loss: 0.0004312144139329653\n",
      "Total log loss: 0.01724944250792907\n",
      "Fold 1\n",
      "Epoch 1   loss=0.41218   val_loss=0.02252   sm_loss=0.41215   sm_val_loss=0.02246   time=1.03s\n",
      "Epoch 2   loss=0.02053   val_loss=0.02083   sm_loss=0.02043   sm_val_loss=0.02074   time=1.00s\n",
      "Epoch 3   loss=0.01840   val_loss=0.01876   sm_loss=0.01843   sm_val_loss=0.01876   time=0.87s\n",
      "Epoch 4   loss=0.01772   val_loss=0.01830   sm_loss=0.01781   sm_val_loss=0.01830   time=1.08s\n",
      "Epoch 5   loss=0.01742   val_loss=0.01789   sm_loss=0.01754   sm_val_loss=0.01791   time=1.06s\n",
      "Epoch 6   loss=0.01738   val_loss=0.01783   sm_loss=0.01750   sm_val_loss=0.01784   time=0.91s\n",
      "Epoch 9   loss=0.01733   val_loss=0.01776   sm_loss=0.01745   sm_val_loss=0.01778   time=0.88s\n",
      "Epoch 10   loss=0.01718   val_loss=0.01776   sm_loss=0.01730   sm_val_loss=0.01778   time=0.88s\n",
      "Epoch 11   loss=0.01701   val_loss=0.01767   sm_loss=0.01714   sm_val_loss=0.01770   time=0.99s\n",
      "Epoch 12   loss=0.01671   val_loss=0.01744   sm_loss=0.01685   sm_val_loss=0.01748   time=0.87s\n",
      "Epoch 13   loss=0.01643   val_loss=0.01735   sm_loss=0.01658   sm_val_loss=0.01737   time=0.89s\n",
      "Epoch 14   loss=0.01622   val_loss=0.01719   sm_loss=0.01638   sm_val_loss=0.01721   time=0.87s\n",
      "Epoch 16   loss=0.01550   val_loss=0.01710   sm_loss=0.01569   sm_val_loss=0.01713   time=0.93s\n",
      "Epoch 17   loss=0.01502   val_loss=0.01707   sm_loss=0.01522   sm_val_loss=0.01712   time=1.12s\n",
      "Epoch 18   loss=0.01450   val_loss=0.01707   sm_loss=0.01471   sm_val_loss=0.01709   time=1.02s\n",
      "Epoch 19   loss=0.01404   val_loss=0.01705   sm_loss=0.01426   sm_val_loss=0.01709   time=0.87s\n",
      "Fold 1 log loss: 0.017160302764169726\n",
      "Fold 2\n",
      "Epoch 1   loss=0.41345   val_loss=0.02244   sm_loss=0.41337   sm_val_loss=0.02240   time=0.93s\n",
      "Epoch 2   loss=0.02023   val_loss=0.01867   sm_loss=0.02020   sm_val_loss=0.01868   time=0.88s\n",
      "Epoch 3   loss=0.01818   val_loss=0.01775   sm_loss=0.01822   sm_val_loss=0.01780   time=0.96s\n",
      "Epoch 5   loss=0.01741   val_loss=0.01745   sm_loss=0.01754   sm_val_loss=0.01747   time=0.92s\n",
      "Epoch 11   loss=0.01697   val_loss=0.01736   sm_loss=0.01710   sm_val_loss=0.01741   time=1.15s\n",
      "Epoch 13   loss=0.01661   val_loss=0.01724   sm_loss=0.01676   sm_val_loss=0.01727   time=0.89s\n",
      "Epoch 14   loss=0.01625   val_loss=0.01708   sm_loss=0.01641   sm_val_loss=0.01710   time=0.87s\n",
      "Epoch 15   loss=0.01595   val_loss=0.01701   sm_loss=0.01613   sm_val_loss=0.01701   time=0.90s\n",
      "Epoch 16   loss=0.01553   val_loss=0.01677   sm_loss=0.01572   sm_val_loss=0.01679   time=0.94s\n",
      "Epoch 17   loss=0.01506   val_loss=0.01678   sm_loss=0.01526   sm_val_loss=0.01678   time=1.49s\n",
      "Epoch 18   loss=0.01453   val_loss=0.01670   sm_loss=0.01475   sm_val_loss=0.01672   time=0.89s\n",
      "Epoch 20   loss=0.01389   val_loss=0.01670   sm_loss=0.01412   sm_val_loss=0.01672   time=0.90s\n",
      "Fold 2 log loss: 0.016691637473596362\n",
      "Fold 3\n",
      "Epoch 1   loss=0.41281   val_loss=0.02345   sm_loss=0.41277   sm_val_loss=0.02341   time=0.90s\n",
      "Epoch 2   loss=0.02004   val_loss=0.02039   sm_loss=0.01999   sm_val_loss=0.02040   time=0.89s\n",
      "Epoch 3   loss=0.01811   val_loss=0.01926   sm_loss=0.01812   sm_val_loss=0.01924   time=0.91s\n",
      "Epoch 4   loss=0.01754   val_loss=0.01871   sm_loss=0.01764   sm_val_loss=0.01875   time=0.90s\n",
      "Epoch 5   loss=0.01728   val_loss=0.01868   sm_loss=0.01741   sm_val_loss=0.01867   time=0.95s\n",
      "Epoch 6   loss=0.01728   val_loss=0.01846   sm_loss=0.01740   sm_val_loss=0.01848   time=1.14s\n",
      "Epoch 9   loss=0.01709   val_loss=0.01838   sm_loss=0.01721   sm_val_loss=0.01838   time=0.89s\n",
      "Epoch 12   loss=0.01666   val_loss=0.01810   sm_loss=0.01679   sm_val_loss=0.01811   time=0.88s\n",
      "Epoch 14   loss=0.01617   val_loss=0.01789   sm_loss=0.01633   sm_val_loss=0.01791   time=0.92s\n",
      "Epoch 15   loss=0.01583   val_loss=0.01774   sm_loss=0.01600   sm_val_loss=0.01776   time=0.89s\n",
      "Epoch 16   loss=0.01540   val_loss=0.01773   sm_loss=0.01559   sm_val_loss=0.01772   time=0.90s\n",
      "Epoch 17   loss=0.01497   val_loss=0.01768   sm_loss=0.01517   sm_val_loss=0.01769   time=1.14s\n",
      "Epoch 18   loss=0.01450   val_loss=0.01760   sm_loss=0.01471   sm_val_loss=0.01760   time=1.01s\n",
      "Fold 3 log loss: 0.01759730812340729\n",
      "Fold 4\n",
      "Epoch 1   loss=0.41440   val_loss=0.02198   sm_loss=0.41437   sm_val_loss=0.02196   time=0.93s\n",
      "Epoch 2   loss=0.02037   val_loss=0.01861   sm_loss=0.02033   sm_val_loss=0.01866   time=0.87s\n",
      "Epoch 3   loss=0.01801   val_loss=0.01812   sm_loss=0.01807   sm_val_loss=0.01819   time=0.95s\n",
      "Epoch 5   loss=0.01737   val_loss=0.01800   sm_loss=0.01749   sm_val_loss=0.01802   time=0.90s\n",
      "Epoch 6   loss=0.01728   val_loss=0.01794   sm_loss=0.01741   sm_val_loss=0.01796   time=0.88s\n",
      "Epoch 9   loss=0.01722   val_loss=0.01775   sm_loss=0.01735   sm_val_loss=0.01779   time=0.92s\n",
      "Epoch 12   loss=0.01673   val_loss=0.01763   sm_loss=0.01688   sm_val_loss=0.01767   time=0.89s\n",
      "Epoch 13   loss=0.01656   val_loss=0.01758   sm_loss=0.01672   sm_val_loss=0.01760   time=0.87s\n",
      "Epoch 14   loss=0.01622   val_loss=0.01749   sm_loss=0.01638   sm_val_loss=0.01753   time=0.88s\n",
      "Epoch 16   loss=0.01546   val_loss=0.01736   sm_loss=0.01565   sm_val_loss=0.01738   time=0.90s\n",
      "Epoch 17   loss=0.01501   val_loss=0.01731   sm_loss=0.01521   sm_val_loss=0.01736   time=0.89s\n",
      "Epoch 18   loss=0.01445   val_loss=0.01722   sm_loss=0.01467   sm_val_loss=0.01726   time=1.05s\n",
      "Fold 4 log loss: 0.017313576551293397\n",
      "Fold 5\n",
      "Epoch 1   loss=0.41253   val_loss=0.02220   sm_loss=0.41247   sm_val_loss=0.02220   time=0.90s\n",
      "Epoch 2   loss=0.02012   val_loss=0.01834   sm_loss=0.02010   sm_val_loss=0.01837   time=0.88s\n",
      "Epoch 4   loss=0.01767   val_loss=0.01762   sm_loss=0.01778   sm_val_loss=0.01760   time=0.87s\n",
      "Epoch 6   loss=0.01739   val_loss=0.01747   sm_loss=0.01750   sm_val_loss=0.01747   time=0.86s\n",
      "Epoch 10   loss=0.01713   val_loss=0.01736   sm_loss=0.01726   sm_val_loss=0.01737   time=1.06s\n",
      "Epoch 12   loss=0.01685   val_loss=0.01725   sm_loss=0.01699   sm_val_loss=0.01726   time=0.87s\n",
      "Epoch 13   loss=0.01653   val_loss=0.01691   sm_loss=0.01668   sm_val_loss=0.01695   time=1.31s\n",
      "Epoch 16   loss=0.01556   val_loss=0.01683   sm_loss=0.01575   sm_val_loss=0.01686   time=0.91s\n",
      "Fold 5 log loss: 0.016901566340300878\n",
      "Fold 6\n",
      "Epoch 1   loss=0.41117   val_loss=0.02383   sm_loss=0.41114   sm_val_loss=0.02382   time=0.91s\n",
      "Epoch 2   loss=0.01994   val_loss=0.02032   sm_loss=0.01990   sm_val_loss=0.01976   time=0.96s\n",
      "Epoch 3   loss=0.01789   val_loss=0.01893   sm_loss=0.01796   sm_val_loss=0.01884   time=1.09s\n",
      "Epoch 5   loss=0.01720   val_loss=0.01879   sm_loss=0.01732   sm_val_loss=0.01876   time=0.86s\n",
      "Epoch 7   loss=0.01714   val_loss=0.01862   sm_loss=0.01726   sm_val_loss=0.01864   time=0.86s\n",
      "Epoch 8   loss=0.01712   val_loss=0.01844   sm_loss=0.01724   sm_val_loss=0.01845   time=1.15s\n",
      "Epoch 10   loss=0.01697   val_loss=0.01834   sm_loss=0.01710   sm_val_loss=0.01837   time=0.88s\n",
      "Epoch 13   loss=0.01641   val_loss=0.01812   sm_loss=0.01656   sm_val_loss=0.01817   time=0.94s\n",
      "Epoch 14   loss=0.01614   val_loss=0.01805   sm_loss=0.01630   sm_val_loss=0.01804   time=0.87s\n",
      "Epoch 16   loss=0.01535   val_loss=0.01792   sm_loss=0.01554   sm_val_loss=0.01794   time=0.88s\n",
      "Epoch 17   loss=0.01495   val_loss=0.01785   sm_loss=0.01515   sm_val_loss=0.01789   time=0.87s\n",
      "Epoch 18   loss=0.01450   val_loss=0.01780   sm_loss=0.01471   sm_val_loss=0.01783   time=0.86s\n",
      "Epoch 19   loss=0.01410   val_loss=0.01774   sm_loss=0.01431   sm_val_loss=0.01777   time=1.23s\n",
      "Fold 6 log loss: 0.017975213419522185\n",
      "Fold 7\n",
      "Epoch 1   loss=0.41192   val_loss=0.02249   sm_loss=0.41189   sm_val_loss=0.02249   time=0.86s\n",
      "Epoch 2   loss=0.02019   val_loss=0.01962   sm_loss=0.02014   sm_val_loss=0.01964   time=0.86s\n",
      "Epoch 3   loss=0.01801   val_loss=0.01787   sm_loss=0.01806   sm_val_loss=0.01793   time=0.86s\n",
      "Epoch 5   loss=0.01741   val_loss=0.01774   sm_loss=0.01752   sm_val_loss=0.01780   time=0.86s\n",
      "Epoch 9   loss=0.01721   val_loss=0.01754   sm_loss=0.01733   sm_val_loss=0.01762   time=1.09s\n",
      "Epoch 11   loss=0.01691   val_loss=0.01733   sm_loss=0.01703   sm_val_loss=0.01739   time=0.90s\n",
      "Epoch 12   loss=0.01670   val_loss=0.01730   sm_loss=0.01684   sm_val_loss=0.01737   time=0.87s\n",
      "Epoch 13   loss=0.01651   val_loss=0.01718   sm_loss=0.01666   sm_val_loss=0.01725   time=0.88s\n",
      "Epoch 14   loss=0.01621   val_loss=0.01713   sm_loss=0.01637   sm_val_loss=0.01720   time=0.86s\n",
      "Epoch 15   loss=0.01585   val_loss=0.01708   sm_loss=0.01602   sm_val_loss=0.01716   time=0.87s\n",
      "Epoch 16   loss=0.01549   val_loss=0.01699   sm_loss=0.01567   sm_val_loss=0.01707   time=0.96s\n",
      "Epoch 17   loss=0.01498   val_loss=0.01699   sm_loss=0.01517   sm_val_loss=0.01706   time=0.87s\n",
      "Epoch 18   loss=0.01451   val_loss=0.01692   sm_loss=0.01472   sm_val_loss=0.01699   time=0.87s\n",
      "Fold 7 log loss: 0.017008364593913507\n",
      "Seed 3\n",
      "Fold 1 log loss: 0.017160302764169726\n",
      "Fold 2 log loss: 0.016691637473596362\n",
      "Fold 3 log loss: 0.01759730812340729\n",
      "Fold 4 log loss: 0.017313576551293397\n",
      "Fold 5 log loss: 0.016901566340300878\n",
      "Fold 6 log loss: 0.017975213419522185\n",
      "Fold 7 log loss: 0.017008364593913507\n",
      "Std of log loss: 0.0004050961477560605\n",
      "Total log loss: 0.01723438304827868\n",
      "Fold 1\n",
      "Epoch 1   loss=0.41328   val_loss=0.02227   sm_loss=0.41324   sm_val_loss=0.02224   time=1.08s\n",
      "Epoch 2   loss=0.02021   val_loss=0.01926   sm_loss=0.02017   sm_val_loss=0.01925   time=1.12s\n",
      "Epoch 3   loss=0.01808   val_loss=0.01882   sm_loss=0.01811   sm_val_loss=0.01878   time=1.00s\n",
      "Epoch 4   loss=0.01747   val_loss=0.01800   sm_loss=0.01758   sm_val_loss=0.01798   time=0.88s\n",
      "Epoch 6   loss=0.01735   val_loss=0.01771   sm_loss=0.01747   sm_val_loss=0.01775   time=0.86s\n",
      "Epoch 9   loss=0.01719   val_loss=0.01757   sm_loss=0.01731   sm_val_loss=0.01760   time=1.26s\n",
      "Epoch 12   loss=0.01676   val_loss=0.01737   sm_loss=0.01690   sm_val_loss=0.01740   time=0.87s\n",
      "Epoch 14   loss=0.01628   val_loss=0.01739   sm_loss=0.01644   sm_val_loss=0.01740   time=0.87s\n",
      "Epoch 15   loss=0.01594   val_loss=0.01720   sm_loss=0.01611   sm_val_loss=0.01724   time=0.95s\n",
      "Epoch 16   loss=0.01557   val_loss=0.01717   sm_loss=0.01575   sm_val_loss=0.01721   time=0.88s\n",
      "Epoch 17   loss=0.01501   val_loss=0.01705   sm_loss=0.01520   sm_val_loss=0.01708   time=0.97s\n",
      "Fold 1 log loss: 0.01714869371628876\n",
      "Fold 2\n",
      "Epoch 1   loss=0.41338   val_loss=0.02214   sm_loss=0.41334   sm_val_loss=0.02211   time=0.85s\n",
      "Epoch 2   loss=0.02040   val_loss=0.01856   sm_loss=0.02032   sm_val_loss=0.01855   time=0.87s\n",
      "Epoch 3   loss=0.01807   val_loss=0.01772   sm_loss=0.01813   sm_val_loss=0.01773   time=0.86s\n",
      "Epoch 5   loss=0.01738   val_loss=0.01764   sm_loss=0.01750   sm_val_loss=0.01766   time=0.86s\n",
      "Epoch 7   loss=0.01742   val_loss=0.01761   sm_loss=0.01753   sm_val_loss=0.01757   time=0.89s\n",
      "Epoch 8   loss=0.01726   val_loss=0.01739   sm_loss=0.01738   sm_val_loss=0.01739   time=0.91s\n",
      "Epoch 10   loss=0.01712   val_loss=0.01737   sm_loss=0.01725   sm_val_loss=0.01738   time=0.87s\n",
      "Epoch 11   loss=0.01696   val_loss=0.01727   sm_loss=0.01709   sm_val_loss=0.01730   time=0.88s\n",
      "Epoch 12   loss=0.01678   val_loss=0.01726   sm_loss=0.01692   sm_val_loss=0.01729   time=0.87s\n",
      "Epoch 13   loss=0.01653   val_loss=0.01715   sm_loss=0.01668   sm_val_loss=0.01719   time=0.87s\n",
      "Epoch 14   loss=0.01626   val_loss=0.01714   sm_loss=0.01642   sm_val_loss=0.01717   time=1.04s\n",
      "Epoch 15   loss=0.01592   val_loss=0.01696   sm_loss=0.01610   sm_val_loss=0.01699   time=0.89s\n",
      "Epoch 17   loss=0.01504   val_loss=0.01675   sm_loss=0.01525   sm_val_loss=0.01678   time=0.87s\n",
      "Epoch 18   loss=0.01447   val_loss=0.01670   sm_loss=0.01469   sm_val_loss=0.01672   time=1.02s\n",
      "Fold 2 log loss: 0.016703900452791846\n",
      "Fold 3\n",
      "Epoch 1   loss=0.41358   val_loss=0.02339   sm_loss=0.41355   sm_val_loss=0.02333   time=0.91s\n",
      "Epoch 2   loss=0.02020   val_loss=0.01969   sm_loss=0.02013   sm_val_loss=0.01969   time=0.96s\n",
      "Epoch 3   loss=0.01826   val_loss=0.01888   sm_loss=0.01823   sm_val_loss=0.01882   time=0.92s\n",
      "Epoch 4   loss=0.01747   val_loss=0.01869   sm_loss=0.01758   sm_val_loss=0.01866   time=0.99s\n",
      "Epoch 8   loss=0.01719   val_loss=0.01834   sm_loss=0.01731   sm_val_loss=0.01837   time=0.88s\n",
      "Epoch 10   loss=0.01698   val_loss=0.01822   sm_loss=0.01711   sm_val_loss=0.01824   time=0.99s\n",
      "Epoch 11   loss=0.01688   val_loss=0.01802   sm_loss=0.01701   sm_val_loss=0.01803   time=0.86s\n",
      "Epoch 14   loss=0.01620   val_loss=0.01794   sm_loss=0.01636   sm_val_loss=0.01795   time=0.87s\n",
      "Epoch 16   loss=0.01543   val_loss=0.01774   sm_loss=0.01562   sm_val_loss=0.01776   time=0.86s\n",
      "Epoch 17   loss=0.01500   val_loss=0.01763   sm_loss=0.01520   sm_val_loss=0.01766   time=0.86s\n",
      "Epoch 18   loss=0.01453   val_loss=0.01763   sm_loss=0.01474   sm_val_loss=0.01764   time=0.87s\n",
      "Fold 3 log loss: 0.01763864274025113\n",
      "Fold 4\n",
      "Epoch 1   loss=0.41302   val_loss=0.02195   sm_loss=0.41296   sm_val_loss=0.02194   time=1.12s\n",
      "Epoch 2   loss=0.02027   val_loss=0.01923   sm_loss=0.02020   sm_val_loss=0.01925   time=0.89s\n",
      "Epoch 3   loss=0.01808   val_loss=0.01804   sm_loss=0.01811   sm_val_loss=0.01810   time=0.87s\n",
      "Epoch 6   loss=0.01727   val_loss=0.01803   sm_loss=0.01740   sm_val_loss=0.01807   time=0.87s\n",
      "Epoch 8   loss=0.01729   val_loss=0.01774   sm_loss=0.01741   sm_val_loss=0.01779   time=0.93s\n",
      "Epoch 11   loss=0.01693   val_loss=0.01763   sm_loss=0.01707   sm_val_loss=0.01767   time=1.07s\n",
      "Epoch 12   loss=0.01667   val_loss=0.01761   sm_loss=0.01681   sm_val_loss=0.01766   time=1.03s\n",
      "Epoch 14   loss=0.01615   val_loss=0.01747   sm_loss=0.01632   sm_val_loss=0.01750   time=0.87s\n",
      "Epoch 15   loss=0.01584   val_loss=0.01735   sm_loss=0.01602   sm_val_loss=0.01739   time=0.86s\n",
      "Epoch 16   loss=0.01539   val_loss=0.01733   sm_loss=0.01558   sm_val_loss=0.01737   time=0.87s\n",
      "Epoch 17   loss=0.01489   val_loss=0.01732   sm_loss=0.01510   sm_val_loss=0.01736   time=0.86s\n",
      "Epoch 20   loss=0.01374   val_loss=0.01732   sm_loss=0.01396   sm_val_loss=0.01735   time=0.85s\n",
      "Fold 4 log loss: 0.017396148367218825\n",
      "Fold 5\n",
      "Epoch 1   loss=0.41246   val_loss=0.02194   sm_loss=0.41243   sm_val_loss=0.02194   time=1.02s\n",
      "Epoch 2   loss=0.02021   val_loss=0.01867   sm_loss=0.02015   sm_val_loss=0.01868   time=0.86s\n",
      "Epoch 3   loss=0.01801   val_loss=0.01816   sm_loss=0.01806   sm_val_loss=0.01821   time=0.99s\n",
      "Epoch 4   loss=0.01764   val_loss=0.01773   sm_loss=0.01775   sm_val_loss=0.01774   time=0.88s\n",
      "Epoch 7   loss=0.01742   val_loss=0.01762   sm_loss=0.01754   sm_val_loss=0.01767   time=0.87s\n",
      "Epoch 9   loss=0.01729   val_loss=0.01750   sm_loss=0.01741   sm_val_loss=0.01753   time=0.87s\n",
      "Epoch 11   loss=0.01694   val_loss=0.01745   sm_loss=0.01708   sm_val_loss=0.01747   time=0.88s\n",
      "Epoch 12   loss=0.01681   val_loss=0.01732   sm_loss=0.01695   sm_val_loss=0.01736   time=1.10s\n",
      "Epoch 13   loss=0.01655   val_loss=0.01718   sm_loss=0.01670   sm_val_loss=0.01720   time=0.87s\n",
      "Epoch 14   loss=0.01632   val_loss=0.01707   sm_loss=0.01649   sm_val_loss=0.01710   time=0.88s\n",
      "Epoch 15   loss=0.01591   val_loss=0.01697   sm_loss=0.01608   sm_val_loss=0.01700   time=0.92s\n",
      "Epoch 16   loss=0.01556   val_loss=0.01683   sm_loss=0.01575   sm_val_loss=0.01688   time=0.92s\n",
      "Fold 5 log loss: 0.016893398116592153\n",
      "Fold 6\n",
      "Epoch 1   loss=0.41236   val_loss=0.02347   sm_loss=0.41231   sm_val_loss=0.02347   time=0.99s\n",
      "Epoch 2   loss=0.02004   val_loss=0.02112   sm_loss=0.02000   sm_val_loss=0.02104   time=1.03s\n",
      "Epoch 3   loss=0.01782   val_loss=0.01907   sm_loss=0.01791   sm_val_loss=0.01904   time=0.90s\n",
      "Epoch 5   loss=0.01719   val_loss=0.01904   sm_loss=0.01731   sm_val_loss=0.01899   time=0.87s\n",
      "Epoch 6   loss=0.01719   val_loss=0.01865   sm_loss=0.01731   sm_val_loss=0.01860   time=0.90s\n",
      "Epoch 11   loss=0.01682   val_loss=0.01850   sm_loss=0.01695   sm_val_loss=0.01848   time=0.87s\n",
      "Epoch 12   loss=0.01664   val_loss=0.01834   sm_loss=0.01678   sm_val_loss=0.01834   time=0.94s\n",
      "Epoch 13   loss=0.01640   val_loss=0.01812   sm_loss=0.01654   sm_val_loss=0.01814   time=1.08s\n",
      "Epoch 14   loss=0.01608   val_loss=0.01796   sm_loss=0.01624   sm_val_loss=0.01799   time=0.88s\n",
      "Epoch 15   loss=0.01575   val_loss=0.01788   sm_loss=0.01592   sm_val_loss=0.01787   time=0.89s\n",
      "Epoch 18   loss=0.01439   val_loss=0.01778   sm_loss=0.01460   sm_val_loss=0.01780   time=1.08s\n",
      "Fold 6 log loss: 0.018031253849570505\n",
      "Fold 7\n",
      "Epoch 1   loss=0.41379   val_loss=0.02275   sm_loss=0.41373   sm_val_loss=0.02274   time=0.88s\n",
      "Epoch 2   loss=0.02076   val_loss=0.01929   sm_loss=0.02065   sm_val_loss=0.01931   time=1.01s\n",
      "Epoch 3   loss=0.01833   val_loss=0.01791   sm_loss=0.01836   sm_val_loss=0.01798   time=1.03s\n",
      "Epoch 4   loss=0.01760   val_loss=0.01778   sm_loss=0.01770   sm_val_loss=0.01784   time=0.96s\n",
      "Epoch 8   loss=0.01732   val_loss=0.01756   sm_loss=0.01744   sm_val_loss=0.01762   time=0.92s\n",
      "Epoch 10   loss=0.01710   val_loss=0.01742   sm_loss=0.01722   sm_val_loss=0.01748   time=1.30s\n",
      "Epoch 13   loss=0.01653   val_loss=0.01739   sm_loss=0.01668   sm_val_loss=0.01744   time=1.10s\n",
      "Epoch 14   loss=0.01628   val_loss=0.01715   sm_loss=0.01644   sm_val_loss=0.01721   time=0.94s\n",
      "Epoch 15   loss=0.01588   val_loss=0.01701   sm_loss=0.01605   sm_val_loss=0.01707   time=0.87s\n",
      "Epoch 16   loss=0.01553   val_loss=0.01698   sm_loss=0.01572   sm_val_loss=0.01704   time=0.86s\n",
      "Epoch 17   loss=0.01504   val_loss=0.01693   sm_loss=0.01524   sm_val_loss=0.01700   time=0.86s\n",
      "Epoch 18   loss=0.01453   val_loss=0.01689   sm_loss=0.01474   sm_val_loss=0.01694   time=0.99s\n",
      "Fold 7 log loss: 0.016961231384717803\n",
      "Seed 4\n",
      "Fold 1 log loss: 0.01714869371628876\n",
      "Fold 2 log loss: 0.016703900452791846\n",
      "Fold 3 log loss: 0.01763864274025113\n",
      "Fold 4 log loss: 0.017396148367218825\n",
      "Fold 5 log loss: 0.016893398116592153\n",
      "Fold 6 log loss: 0.018031253849570505\n",
      "Fold 7 log loss: 0.016961231384717803\n",
      "Std of log loss: 0.0004312312356594289\n",
      "Total log loss: 0.017252195059441398\n",
      "Total log loss in targets: 0.01701909093841111\n"
     ]
    }
   ],
   "source": [
    "seeds = [0,1,2,3,4] \n",
    "target_oof = np.zeros([len(fn_train),fn_targets.shape[1]])\n",
    "target_pred = np.zeros([len(fn_test),fn_targets.shape[1]])\n",
    "\n",
    "for seed_ in seeds:\n",
    "    oof, oof_targets, pytorch_pred = modelling_torch(fn_train, fn_targets, fn_test, seed_, fn_train.shape[1]-1, fn_targets.shape[1], 20)\n",
    "    target_oof += oof / len(seeds)\n",
    "    target_pred += pytorch_pred / len(seeds)\n",
    "\n",
    "print(\"Total log loss in targets: {}\".format(mean_log_loss(oof_targets, target_oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T00:56:19.683161Z",
     "iopub.status.busy": "2020-11-11T00:56:19.682227Z",
     "iopub.status.idle": "2020-11-11T00:56:21.013437Z",
     "shell.execute_reply": "2020-11-11T00:56:21.012932Z"
    },
    "papermill": {
     "duration": 1.527658,
     "end_time": "2020-11-11T00:56:21.013551",
     "exception": false,
     "start_time": "2020-11-11T00:56:19.485893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AUC : 0.6450927472884791\n"
     ]
    }
   ],
   "source": [
    "aucs = []\n",
    "for task_id in range(targets.shape[1]-1):\n",
    "    aucs.append(roc_auc_score(y_true=targets.iloc[:, task_id+1].values,\n",
    "                              y_score=target_oof[:, task_id]))\n",
    "print(f\"Overall AUC : {np.mean(aucs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T00:56:21.414426Z",
     "iopub.status.busy": "2020-11-11T00:56:21.413252Z",
     "iopub.status.idle": "2020-11-11T00:56:27.113493Z",
     "shell.execute_reply": "2020-11-11T00:56:27.112958Z"
    },
    "papermill": {
     "duration": 5.906802,
     "end_time": "2020-11-11T00:56:27.113595",
     "exception": false,
     "start_time": "2020-11-11T00:56:21.206793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF log loss:  0.01568552145444902\n"
     ]
    }
   ],
   "source": [
    "t = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "train_checkscore = t.copy()\n",
    "train_checkscore.loc[train_checkscore.index.isin(cons_train_index),target_feats] = target_oof\n",
    "train_checkscore.loc[train_checkscore.index.isin(noncons_train_index),target_feats] = 0\n",
    "t.drop(\"sig_id\", axis=1, inplace=True)\n",
    "print('OOF log loss: ', log_loss(np.ravel(t), np.ravel(np.array(train_checkscore.iloc[:,1:]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T00:56:27.504158Z",
     "iopub.status.busy": "2020-11-11T00:56:27.502960Z",
     "iopub.status.idle": "2020-11-11T00:56:29.894158Z",
     "shell.execute_reply": "2020-11-11T00:56:29.894737Z"
    },
    "papermill": {
     "duration": 2.589582,
     "end_time": "2020-11-11T00:56:29.894888",
     "exception": false,
     "start_time": "2020-11-11T00:56:27.305306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.loc[cons_test_index,target_feats] = target_pred\n",
    "sub.loc[noncons_test_index,target_feats] = 0\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.19232,
     "end_time": "2020-11-11T00:56:30.279446",
     "exception": false,
     "start_time": "2020-11-11T00:56:30.087126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 833.995325,
   "end_time": "2020-11-11T00:56:30.980189",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-11T00:42:36.984864",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
