{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020119,
     "end_time": "2020-11-09T12:08:42.027634",
     "exception": false,
     "start_time": "2020-11-09T12:08:42.007515",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- include ctl group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-09T12:08:42.076472Z",
     "iopub.status.busy": "2020-11-09T12:08:42.075752Z",
     "iopub.status.idle": "2020-11-09T12:08:51.553699Z",
     "shell.execute_reply": "2020-11-09T12:08:51.554724Z"
    },
    "papermill": {
     "duration": 9.508155,
     "end_time": "2020-11-09T12:08:51.554940",
     "exception": false,
     "start_time": "2020-11-09T12:08:42.046785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from umap import UMAP\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss,roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "sys.path.append('../input/multilabelstraifier/')\n",
    "from ml_stratifiers import MultilabelStratifiedKFold\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "from torch.nn.modules.loss import _WeightedLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T12:08:51.623497Z",
     "iopub.status.busy": "2020-11-09T12:08:51.622660Z",
     "iopub.status.idle": "2020-11-09T12:08:58.050917Z",
     "shell.execute_reply": "2020-11-09T12:08:58.052138Z"
    },
    "papermill": {
     "duration": 6.469114,
     "end_time": "2020-11-09T12:08:58.052373",
     "exception": false,
     "start_time": "2020-11-09T12:08:51.583259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/lish-moa/'\n",
    "train = pd.read_csv(DATA_DIR + 'train_features.csv')\n",
    "targets = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "non_targets = pd.read_csv(DATA_DIR + 'train_targets_nonscored.csv')\n",
    "test = pd.read_csv(DATA_DIR + 'test_features.csv')\n",
    "sub = pd.read_csv(DATA_DIR + 'sample_submission.csv')\n",
    "drug = pd.read_csv(DATA_DIR + 'train_drug.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T12:08:58.127245Z",
     "iopub.status.busy": "2020-11-09T12:08:58.126385Z",
     "iopub.status.idle": "2020-11-09T12:08:58.130343Z",
     "shell.execute_reply": "2020-11-09T12:08:58.131172Z"
    },
    "papermill": {
     "duration": 0.04453,
     "end_time": "2020-11-09T12:08:58.131349",
     "exception": false,
     "start_time": "2020-11-09T12:08:58.086819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_feats = [ i for i in targets.columns if i != \"sig_id\"]\n",
    "g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "c_feats = [i for i in train.columns if \"c-\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T12:08:58.202420Z",
     "iopub.status.busy": "2020-11-09T12:08:58.201729Z",
     "iopub.status.idle": "2020-11-09T12:08:58.333009Z",
     "shell.execute_reply": "2020-11-09T12:08:58.333875Z"
    },
    "papermill": {
     "duration": 0.172649,
     "end_time": "2020-11-09T12:08:58.334054",
     "exception": false,
     "start_time": "2020-11-09T12:08:58.161405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "noncons_train_index = train[train.cp_type==\"ctl_vehicle\"].index\n",
    "cons_train_index = train[train.cp_type!=\"ctl_vehicle\"].index\n",
    "noncons_test_index = test[test.cp_type==\"ctl_vehicle\"].index\n",
    "cons_test_index = test[test.cp_type!=\"ctl_vehicle\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T12:08:58.536076Z",
     "iopub.status.busy": "2020-11-09T12:08:58.535302Z",
     "iopub.status.idle": "2020-11-09T12:08:59.021633Z",
     "shell.execute_reply": "2020-11-09T12:08:59.022311Z"
    },
    "papermill": {
     "duration": 0.658649,
     "end_time": "2020-11-09T12:08:59.022509",
     "exception": false,
     "start_time": "2020-11-09T12:08:58.363860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.at[train['cp_type'].str.contains('ctl_vehicle'),train.filter(regex='-.*').columns] = 0.0\n",
    "test.at[train['cp_type'].str.contains('ctl_vehicle'),test.filter(regex='-.*').columns] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028471,
     "end_time": "2020-11-09T12:08:59.085954",
     "exception": false,
     "start_time": "2020-11-09T12:08:59.057483",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T12:08:59.133862Z",
     "iopub.status.busy": "2020-11-09T12:08:59.131874Z",
     "iopub.status.idle": "2020-11-09T12:08:59.134555Z",
     "shell.execute_reply": "2020-11-09T12:08:59.135041Z"
    },
    "papermill": {
     "duration": 0.027481,
     "end_time": "2020-11-09T12:08:59.135191",
     "exception": false,
     "start_time": "2020-11-09T12:08:59.107710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train = train[train.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "#test = test[test.index.isin(cons_test_index)].copy().reset_index(drop=True)\n",
    "#targets = targets[targets.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "#non_targets = non_targets[non_targets.index.isin(cons_train_index)].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T12:08:59.202798Z",
     "iopub.status.busy": "2020-11-09T12:08:59.194094Z",
     "iopub.status.idle": "2020-11-09T12:08:59.790906Z",
     "shell.execute_reply": "2020-11-09T12:08:59.789843Z"
    },
    "papermill": {
     "duration": 0.635536,
     "end_time": "2020-11-09T12:08:59.791021",
     "exception": false,
     "start_time": "2020-11-09T12:08:59.155485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4, 5, ..., 5, 1, 5]], dtype=int8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/c/lish-moa/discussion/195195\n",
    "NB_SPLITS = 7\n",
    "seed = 34\n",
    "\n",
    "folds = []\n",
    "    \n",
    "# LOAD FILES\n",
    "train_score = targets.merge(drug, on='sig_id', how='left') \n",
    "\n",
    "# LOCATE DRUGS\n",
    "vc = train_score.drug_id.value_counts()\n",
    "vc1 = vc.loc[vc <= 19].index.sort_values()\n",
    "vc2 = vc.loc[vc > 19].index.sort_values()\n",
    "    \n",
    "# STRATIFY DRUGS 18X OR LESS\n",
    "dct1 = {}; dct2 = {}\n",
    "skf = MultilabelStratifiedKFold(n_splits = NB_SPLITS, shuffle = True, random_state = seed)\n",
    "tmp = train_score.groupby('drug_id')[target_feats].mean().loc[vc1]\n",
    "for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_feats])):\n",
    "    dd = {k:fold for k in tmp.index[idxV].values}\n",
    "    dct1.update(dd)\n",
    "\n",
    "# STRATIFY DRUGS MORE THAN 18X\n",
    "skf = MultilabelStratifiedKFold(n_splits = NB_SPLITS, shuffle = True, random_state = seed)\n",
    "tmp = train_score.loc[train_score.drug_id.isin(vc2)].reset_index(drop = True)\n",
    "for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_feats])):\n",
    "    dd = {k:fold for k in tmp.sig_id[idxV].values}\n",
    "    dct2.update(dd)\n",
    "\n",
    "# ASSIGN FOLDS\n",
    "train_score['fold'] = train_score.drug_id.map(dct1)\n",
    "train_score.loc[train_score.fold.isna(),'fold'] = train_score.loc[train_score.fold.isna(),'sig_id'].map(dct2)\n",
    "train_score.fold = train_score.fold.astype('int8')\n",
    "folds.append(train_score.fold.values)\n",
    "    \n",
    "np.array(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02763,
     "end_time": "2020-11-09T12:08:59.840031",
     "exception": false,
     "start_time": "2020-11-09T12:08:59.812401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T12:08:59.940571Z",
     "iopub.status.busy": "2020-11-09T12:08:59.939024Z",
     "iopub.status.idle": "2020-11-09T12:09:00.291776Z",
     "shell.execute_reply": "2020-11-09T12:09:00.292282Z"
    },
    "papermill": {
     "duration": 0.431576,
     "end_time": "2020-11-09T12:09:00.292418",
     "exception": false,
     "start_time": "2020-11-09T12:08:59.860842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "X = train.iloc[:,4:].copy().values\n",
    "select = VarianceThreshold(threshold=0.7)\n",
    "X_new = select.fit_transform(X)\n",
    "drop_feats = list(np.array(train.iloc[:,4:].columns)[select.get_support()==False])\n",
    "print(len(drop_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T12:09:00.397694Z",
     "iopub.status.busy": "2020-11-09T12:09:00.390382Z",
     "iopub.status.idle": "2020-11-09T12:09:00.400056Z",
     "shell.execute_reply": "2020-11-09T12:09:00.400547Z"
    },
    "papermill": {
     "duration": 0.086878,
     "end_time": "2020-11-09T12:09:00.400697",
     "exception": false,
     "start_time": "2020-11-09T12:09:00.313819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.drop(drop_feats, axis=1, inplace=True)\n",
    "test.drop(drop_feats, axis=1, inplace=True)\n",
    "\n",
    "g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "c_feats = [i for i in train.columns if \"c-\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T12:09:00.452411Z",
     "iopub.status.busy": "2020-11-09T12:09:00.451712Z",
     "iopub.status.idle": "2020-11-09T12:09:11.279403Z",
     "shell.execute_reply": "2020-11-09T12:09:11.278535Z"
    },
    "papermill": {
     "duration": 10.857183,
     "end_time": "2020-11-09T12:09:11.279536",
     "exception": false,
     "start_time": "2020-11-09T12:09:00.422353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rank gauss\n",
    "for i in c_feats + g_feats:\n",
    "    ss = preprocessing.QuantileTransformer(n_quantiles=1000, random_state=0, output_distribution=\"normal\")\n",
    "    ss.fit(train[i].values.reshape(-1,1))\n",
    "    train[i] = ss.transform(train[i].values.reshape(-1,1))\n",
    "    test[i] = ss.transform(test[i].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T12:09:11.345543Z",
     "iopub.status.busy": "2020-11-09T12:09:11.343744Z",
     "iopub.status.idle": "2020-11-09T12:09:13.616241Z",
     "shell.execute_reply": "2020-11-09T12:09:13.615627Z"
    },
    "papermill": {
     "duration": 2.314724,
     "end_time": "2020-11-09T12:09:13.616368",
     "exception": false,
     "start_time": "2020-11-09T12:09:11.301644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_num = 10\n",
    "pca_c_cols = [\"pca-c\"+str(i+1) for i in range(c_num)]\n",
    "pca = PCA(n_components=c_num,random_state=42)\n",
    "c_train = pca.fit_transform(train[c_feats])\n",
    "c_test = pca.transform(test[c_feats])\n",
    "c_train = pd.DataFrame(c_train, columns=pca_c_cols)\n",
    "c_test = pd.DataFrame(c_test, columns=pca_c_cols)\n",
    "\n",
    "g_num = 60\n",
    "pca_g_cols = [\"pca-g\"+str(i+1) for i in range(g_num)]\n",
    "pca = PCA(n_components=g_num, random_state=42)\n",
    "g_train = pca.fit_transform(train[g_feats])\n",
    "g_test = pca.transform(test[g_feats])\n",
    "g_train = pd.DataFrame(g_train, columns=pca_g_cols)\n",
    "g_test = pd.DataFrame(g_test, columns=pca_g_cols)\n",
    "\n",
    "train = pd.concat([train, c_train],axis=1)\n",
    "test = pd.concat([test, c_test],axis=1)\n",
    "train = pd.concat([train, g_train],axis=1)\n",
    "test = pd.concat([test, g_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T12:09:13.665822Z",
     "iopub.status.busy": "2020-11-09T12:09:13.664982Z",
     "iopub.status.idle": "2020-11-09T12:09:13.669095Z",
     "shell.execute_reply": "2020-11-09T12:09:13.668615Z"
    },
    "papermill": {
     "duration": 0.030429,
     "end_time": "2020-11-09T12:09:13.669206",
     "exception": false,
     "start_time": "2020-11-09T12:09:13.638777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#uc_num = 1\n",
    "#um = UMAP(n_neighbors=20, n_components=uc_num, random_state=42)\n",
    "#um_c_cols = [\"um-c\"+str(i+1) for i in range(uc_num)]\n",
    "#uc_train = um.fit_transform(train[c_feats])\n",
    "#uc_test = um.transform(test[c_feats])\n",
    "#uc_train = pd.DataFrame(uc_train, columns=um_c_cols)\n",
    "#uc_test = pd.DataFrame(uc_test, columns=um_c_cols)\n",
    "\n",
    "#ug_num = 5\n",
    "#um = UMAP(n_neighbors=20, n_components=ug_num, random_state=42)\n",
    "#um_g_cols = [\"um-g\"+str(i+1) for i in range(ug_num)]\n",
    "#ug_train = um.fit_transform(train[g_feats])\n",
    "#ug_test = um.transform(test[g_feats])\n",
    "#ug_train = pd.DataFrame(ug_train, columns=um_g_cols)\n",
    "#ug_test = pd.DataFrame(ug_test, columns=um_g_cols)\n",
    "\n",
    "#train = pd.concat([train, uc_train],axis=1)\n",
    "#test = pd.concat([test, uc_test],axis=1)\n",
    "#train = pd.concat([train, ug_train],axis=1)\n",
    "#test = pd.concat([test, ug_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T12:09:13.725284Z",
     "iopub.status.busy": "2020-11-09T12:09:13.723989Z",
     "iopub.status.idle": "2020-11-09T12:09:15.738466Z",
     "shell.execute_reply": "2020-11-09T12:09:15.739188Z"
    },
    "papermill": {
     "duration": 2.047584,
     "end_time": "2020-11-09T12:09:15.739513",
     "exception": false,
     "start_time": "2020-11-09T12:09:13.691929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23814, 901) (3982, 901)\n"
     ]
    }
   ],
   "source": [
    "def fe(df):\n",
    "    tmp = df.copy()\n",
    "    tmp['g_kurt'] = tmp[g_feats].kurtosis(axis = 1)\n",
    "    tmp['g_skew'] = tmp[g_feats].skew(axis = 1)\n",
    "    tmp['c_kurt'] = tmp[c_feats].kurtosis(axis = 1)\n",
    "    tmp['c_skew'] = tmp[c_feats].skew(axis = 1)\n",
    "    tmp = pd.get_dummies(tmp, columns=['cp_time','cp_dose'])\n",
    "    tmp.drop([\"cp_type\", \"sig_id\"], axis=1, inplace=True) \n",
    "    return tmp\n",
    "\n",
    "train = fe(train)\n",
    "test = fe(test)\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T12:09:15.797336Z",
     "iopub.status.busy": "2020-11-09T12:09:15.796414Z",
     "iopub.status.idle": "2020-11-09T12:09:15.800307Z",
     "shell.execute_reply": "2020-11-09T12:09:15.799638Z"
    },
    "papermill": {
     "duration": 0.034911,
     "end_time": "2020-11-09T12:09:15.800442",
     "exception": false,
     "start_time": "2020-11-09T12:09:15.765531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[\"fold\"] = np.array(folds).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T12:09:15.855606Z",
     "iopub.status.busy": "2020-11-09T12:09:15.854461Z",
     "iopub.status.idle": "2020-11-09T12:09:16.030422Z",
     "shell.execute_reply": "2020-11-09T12:09:16.029806Z"
    },
    "papermill": {
     "duration": 0.203807,
     "end_time": "2020-11-09T12:09:16.030542",
     "exception": false,
     "start_time": "2020-11-09T12:09:15.826735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fn_train = train.copy().to_numpy()\n",
    "fn_test = test.copy().to_numpy()\n",
    "\n",
    "fn_targets = targets.drop(\"sig_id\", axis=1).copy().to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023951,
     "end_time": "2020-11-09T12:09:16.078647",
     "exception": false,
     "start_time": "2020-11-09T12:09:16.054696",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T12:09:16.513004Z",
     "iopub.status.busy": "2020-11-09T12:09:16.512063Z",
     "iopub.status.idle": "2020-11-09T12:09:16.515549Z",
     "shell.execute_reply": "2020-11-09T12:09:16.514511Z"
    },
    "papermill": {
     "duration": 0.413539,
     "end_time": "2020-11-09T12:09:16.515664",
     "exception": false,
     "start_time": "2020-11-09T12:09:16.102125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T12:09:16.573288Z",
     "iopub.status.busy": "2020-11-09T12:09:16.572657Z",
     "iopub.status.idle": "2020-11-09T12:09:16.577019Z",
     "shell.execute_reply": "2020-11-09T12:09:16.576465Z"
    },
    "papermill": {
     "duration": 0.038135,
     "end_time": "2020-11-09T12:09:16.577115",
     "exception": false,
     "start_time": "2020-11-09T12:09:16.538980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SmoothCrossEntropyLoss(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets, n_classes, smoothing=0.0):\n",
    "        assert 0 <= smoothing <= 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1 - smoothing) + torch.ones_like(targets).to(device) * smoothing / n_classes\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothCrossEntropyLoss()._smooth(targets, inputs.shape[1], self.smoothing)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            inputs = inputs * self.weight.unsqueeze(0)\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T12:09:16.636891Z",
     "iopub.status.busy": "2020-11-09T12:09:16.631678Z",
     "iopub.status.idle": "2020-11-09T12:09:16.644190Z",
     "shell.execute_reply": "2020-11-09T12:09:16.644745Z"
    },
    "papermill": {
     "duration": 0.044206,
     "end_time": "2020-11-09T12:09:16.644879",
     "exception": false,
     "start_time": "2020-11-09T12:09:16.600673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "def seed_everything(seed=42): \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "class MoaModel(nn.Module):\n",
    "    def __init__(self, num_columns, last_num):\n",
    "        super(MoaModel, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_columns)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_columns, 1024))\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(1024)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(1024, 1024))\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(1024)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(1024, last_num))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu1(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.relu2(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025344,
     "end_time": "2020-11-09T12:09:16.693869",
     "exception": false,
     "start_time": "2020-11-09T12:09:16.668525",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T12:09:16.768761Z",
     "iopub.status.busy": "2020-11-09T12:09:16.763406Z",
     "iopub.status.idle": "2020-11-09T12:09:16.799841Z",
     "shell.execute_reply": "2020-11-09T12:09:16.799074Z"
    },
    "papermill": {
     "duration": 0.081005,
     "end_time": "2020-11-09T12:09:16.799956",
     "exception": false,
     "start_time": "2020-11-09T12:09:16.718951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_folds=7\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "smoothing = 0.001\n",
    "p_min = smoothing\n",
    "p_max = 1 - smoothing\n",
    "\n",
    "def mean_log_loss(y_true, y_pred):\n",
    "    metrics = []\n",
    "    for i, target in enumerate(target_feats):\n",
    "        metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float), labels=[0,1]))\n",
    "    return np.mean(metrics)\n",
    "\n",
    "def modelling_torch(tr, target, te, sample_seed, init_num, last_num, train_epochs):\n",
    "    seed_everything(seed=sample_seed) \n",
    "    X_train = tr.copy()\n",
    "    y_train = target.copy()\n",
    "    X_test = te.copy()\n",
    "    test_len = X_test.shape[0]\n",
    "    \n",
    "    mskf=MultilabelStratifiedKFold(n_splits = n_folds, shuffle=True, random_state=224)\n",
    "    metric = lambda inputs, targets : F.binary_cross_entropy((torch.clamp(torch.sigmoid(inputs), p_min, p_max)), targets)\n",
    "\n",
    "    models = []\n",
    "    \n",
    "    X_test2 = torch.tensor(X_test, dtype=torch.float32)\n",
    "    test = torch.utils.data.TensorDataset(X_test2) \n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    oof = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    oof_targets = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    pred_value = np.zeros([test_len, y_train.shape[1]])\n",
    "    scores = []\n",
    "    for fold in range(n_folds):\n",
    "        valid_index = X_train[:,-1] == fold\n",
    "        train_index = X_train[:,-1] != fold\n",
    "        print(\"Fold \"+str(fold+1))\n",
    "        X_train2 = torch.tensor(X_train[train_index,:], dtype=torch.float32)\n",
    "        X_valid2 = torch.tensor(X_train[valid_index,:], dtype=torch.float32)\n",
    "        X_train2 = X_train2[:,:-1]\n",
    "        X_valid2 = X_valid2[:,:-1]\n",
    "        \n",
    "        y_train2 = torch.tensor(y_train[train_index], dtype=torch.float32)\n",
    "        y_valid2 = torch.tensor(y_train[valid_index], dtype=torch.float32)\n",
    "        \n",
    "        train = torch.utils.data.TensorDataset(X_train2, y_train2)\n",
    "        valid = torch.utils.data.TensorDataset(X_valid2, y_valid2)\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True) \n",
    "        valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "            \n",
    "        clf = MoaModel(init_num, last_num)\n",
    "        loss_fn = SmoothCrossEntropyLoss(smoothing=smoothing)\n",
    "\n",
    "        optimizer = optim.Adam(clf.parameters(), lr = 0.001, weight_decay=1e-5) \n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=train_epochs, steps_per_epoch=len(train_loader))\n",
    "        \n",
    "        clf.to(device)\n",
    "        \n",
    "        best_val_loss = np.inf\n",
    "        stop_counts = 0\n",
    "        for epoch in range(train_epochs):\n",
    "            start_time = time.time()\n",
    "            clf.train()\n",
    "            avg_loss = 0.\n",
    "            sm_avg_loss = 0.\n",
    "            for x_batch, y_batch in tqdm(train_loader, disable=True):\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch) \n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                avg_loss += loss.item() / len(train_loader)  \n",
    "                sm_avg_loss += metric(y_pred, y_batch) / len(train_loader) \n",
    "                \n",
    "            clf.eval()\n",
    "            avg_val_loss = 0.\n",
    "            sm_avg_val_loss = 0.\n",
    "            for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch).detach()\n",
    "                avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "                sm_avg_val_loss += metric(y_pred, y_batch) / len(valid_loader)\n",
    "        \n",
    "            elapsed_time = time.time() - start_time \n",
    "            #scheduler.step() #avg_val_loss # maybe mistake\n",
    "                    \n",
    "            if sm_avg_val_loss < best_val_loss:\n",
    "                best_val_loss = sm_avg_val_loss\n",
    "                print('Epoch {}   loss={:.5f}   val_loss={:.5f}   sm_loss={:.5f}   sm_val_loss={:.5f}   time={:.2f}s'.format(\n",
    "                    epoch + 1, avg_loss, avg_val_loss, sm_avg_loss, sm_avg_val_loss, elapsed_time))\n",
    "                torch.save(clf.state_dict(), 'best-model-parameters.pt')\n",
    "            else:\n",
    "                stop_counts += 1\n",
    "        \n",
    "        pred_model = MoaModel(init_num, last_num)\n",
    "        pred_model.load_state_dict(torch.load('best-model-parameters.pt'))         \n",
    "        pred_model.eval()\n",
    "        \n",
    "        # validation check ----------------\n",
    "        oof_epoch = np.zeros([X_valid2.size(0), y_train.shape[1]])\n",
    "        target_epoch = np.zeros([X_valid2.size(0), y_train.shape[1]])\n",
    "        for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "                y_pred = pred_model(x_batch).detach()\n",
    "                oof_epoch[i * batch_size:(i+1) * batch_size,:] = torch.clamp(torch.sigmoid(y_pred.cpu()), p_min, p_max)\n",
    "                target_epoch[i * batch_size:(i+1) * batch_size,:] = y_batch.cpu().numpy()\n",
    "        print(\"Fold {} log loss: {}\".format(fold+1, mean_log_loss(target_epoch, oof_epoch)))\n",
    "        scores.append(mean_log_loss(target_epoch, oof_epoch))\n",
    "        oof[valid_index,:] = oof_epoch\n",
    "        oof_targets[valid_index,:] = target_epoch\n",
    "        #-----------------------------------\n",
    "        \n",
    "        # test predcition --------------\n",
    "        test_preds = np.zeros([test_len, y_train.shape[1]])\n",
    "        for i, (x_batch,) in enumerate(test_loader): \n",
    "            y_pred = pred_model(x_batch).detach()\n",
    "            test_preds[i * batch_size:(i+1) * batch_size, :] = torch.clamp(torch.sigmoid(y_pred.cpu()), p_min, p_max)\n",
    "        pred_value += test_preds / n_folds\n",
    "        # ------------------------------\n",
    "        \n",
    "    print(\"Seed {}\".format(seed_))\n",
    "    for i, ele in enumerate(scores):\n",
    "        print(\"Fold {} log loss: {}\".format(i+1, scores[i]))\n",
    "    print(\"Std of log loss: {}\".format(np.std(scores)))\n",
    "    print(\"Total log loss: {}\".format(mean_log_loss(oof_targets, oof)))\n",
    "    \n",
    "    return oof, oof_targets, pred_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T12:09:16.861557Z",
     "iopub.status.busy": "2020-11-09T12:09:16.860832Z",
     "iopub.status.idle": "2020-11-09T12:22:26.764073Z",
     "shell.execute_reply": "2020-11-09T12:22:26.762703Z"
    },
    "papermill": {
     "duration": 789.938321,
     "end_time": "2020-11-09T12:22:26.764297",
     "exception": false,
     "start_time": "2020-11-09T12:09:16.825976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1   loss=0.40043   val_loss=0.02068   sm_loss=0.40038   sm_val_loss=0.02065   time=1.85s\n",
      "Epoch 3   loss=0.01678   val_loss=0.01660   sm_loss=0.01684   sm_val_loss=0.01667   time=0.92s\n",
      "Epoch 9   loss=0.01598   val_loss=0.01634   sm_loss=0.01614   sm_val_loss=0.01638   time=1.21s\n",
      "Epoch 12   loss=0.01563   val_loss=0.01623   sm_loss=0.01580   sm_val_loss=0.01631   time=0.98s\n",
      "Epoch 13   loss=0.01546   val_loss=0.01613   sm_loss=0.01563   sm_val_loss=0.01623   time=1.03s\n",
      "Epoch 14   loss=0.01510   val_loss=0.01594   sm_loss=0.01529   sm_val_loss=0.01601   time=0.96s\n",
      "Epoch 16   loss=0.01448   val_loss=0.01587   sm_loss=0.01470   sm_val_loss=0.01593   time=0.95s\n",
      "Epoch 17   loss=0.01407   val_loss=0.01584   sm_loss=0.01429   sm_val_loss=0.01589   time=0.96s\n",
      "Epoch 18   loss=0.01363   val_loss=0.01583   sm_loss=0.01386   sm_val_loss=0.01587   time=0.96s\n",
      "Epoch 20   loss=0.01309   val_loss=0.01583   sm_loss=0.01333   sm_val_loss=0.01587   time=0.96s\n",
      "Fold 1 log loss: 0.015938049952719503\n",
      "Fold 2\n",
      "Epoch 1   loss=0.40045   val_loss=0.02050   sm_loss=0.40044   sm_val_loss=0.02049   time=0.95s\n",
      "Epoch 2   loss=0.01869   val_loss=0.01745   sm_loss=0.01867   sm_val_loss=0.01732   time=0.94s\n",
      "Epoch 3   loss=0.01669   val_loss=0.01619   sm_loss=0.01677   sm_val_loss=0.01626   time=0.95s\n",
      "Epoch 9   loss=0.01600   val_loss=0.01617   sm_loss=0.01616   sm_val_loss=0.01624   time=1.01s\n",
      "Epoch 10   loss=0.01593   val_loss=0.01611   sm_loss=0.01609   sm_val_loss=0.01620   time=0.96s\n",
      "Epoch 12   loss=0.01556   val_loss=0.01611   sm_loss=0.01574   sm_val_loss=0.01617   time=1.03s\n",
      "Epoch 13   loss=0.01536   val_loss=0.01591   sm_loss=0.01555   sm_val_loss=0.01598   time=0.95s\n",
      "Epoch 15   loss=0.01474   val_loss=0.01587   sm_loss=0.01494   sm_val_loss=0.01592   time=0.95s\n",
      "Epoch 17   loss=0.01399   val_loss=0.01574   sm_loss=0.01423   sm_val_loss=0.01578   time=0.94s\n",
      "Epoch 19   loss=0.01322   val_loss=0.01573   sm_loss=0.01347   sm_val_loss=0.01577   time=1.13s\n",
      "Fold 2 log loss: 0.015836632917097446\n",
      "Fold 3\n",
      "Epoch 1   loss=0.40010   val_loss=0.02097   sm_loss=0.40004   sm_val_loss=0.02095   time=0.93s\n",
      "Epoch 2   loss=0.01929   val_loss=0.01817   sm_loss=0.01912   sm_val_loss=0.01808   time=0.94s\n",
      "Epoch 3   loss=0.01695   val_loss=0.01738   sm_loss=0.01700   sm_val_loss=0.01743   time=0.93s\n",
      "Epoch 4   loss=0.01628   val_loss=0.01694   sm_loss=0.01641   sm_val_loss=0.01699   time=0.94s\n",
      "Epoch 7   loss=0.01618   val_loss=0.01681   sm_loss=0.01633   sm_val_loss=0.01687   time=0.96s\n",
      "Epoch 10   loss=0.01586   val_loss=0.01677   sm_loss=0.01601   sm_val_loss=0.01681   time=0.96s\n",
      "Epoch 12   loss=0.01560   val_loss=0.01671   sm_loss=0.01578   sm_val_loss=0.01677   time=0.94s\n",
      "Epoch 13   loss=0.01535   val_loss=0.01658   sm_loss=0.01552   sm_val_loss=0.01662   time=0.96s\n",
      "Epoch 15   loss=0.01478   val_loss=0.01634   sm_loss=0.01498   sm_val_loss=0.01641   time=0.95s\n",
      "Epoch 16   loss=0.01441   val_loss=0.01625   sm_loss=0.01462   sm_val_loss=0.01632   time=0.93s\n",
      "Epoch 17   loss=0.01398   val_loss=0.01622   sm_loss=0.01420   sm_val_loss=0.01629   time=0.94s\n",
      "Epoch 19   loss=0.01312   val_loss=0.01619   sm_loss=0.01337   sm_val_loss=0.01624   time=0.97s\n",
      "Epoch 20   loss=0.01293   val_loss=0.01616   sm_loss=0.01318   sm_val_loss=0.01621   time=1.29s\n",
      "Fold 3 log loss: 0.0161948895895312\n",
      "Fold 4\n",
      "Epoch 1   loss=0.40108   val_loss=0.02174   sm_loss=0.40101   sm_val_loss=0.02172   time=1.05s\n",
      "Epoch 2   loss=0.01866   val_loss=0.01777   sm_loss=0.01860   sm_val_loss=0.01775   time=0.96s\n",
      "Epoch 3   loss=0.01671   val_loss=0.01724   sm_loss=0.01680   sm_val_loss=0.01718   time=0.99s\n",
      "Epoch 4   loss=0.01614   val_loss=0.01687   sm_loss=0.01628   sm_val_loss=0.01687   time=0.99s\n",
      "Epoch 7   loss=0.01597   val_loss=0.01676   sm_loss=0.01613   sm_val_loss=0.01681   time=0.98s\n",
      "Epoch 10   loss=0.01584   val_loss=0.01670   sm_loss=0.01601   sm_val_loss=0.01677   time=1.01s\n",
      "Epoch 11   loss=0.01566   val_loss=0.01655   sm_loss=0.01583   sm_val_loss=0.01662   time=0.96s\n",
      "Epoch 12   loss=0.01547   val_loss=0.01654   sm_loss=0.01565   sm_val_loss=0.01657   time=0.95s\n",
      "Epoch 13   loss=0.01525   val_loss=0.01652   sm_loss=0.01544   sm_val_loss=0.01657   time=0.96s\n",
      "Epoch 14   loss=0.01498   val_loss=0.01642   sm_loss=0.01518   sm_val_loss=0.01649   time=0.95s\n",
      "Epoch 16   loss=0.01428   val_loss=0.01635   sm_loss=0.01450   sm_val_loss=0.01640   time=0.95s\n",
      "Epoch 17   loss=0.01384   val_loss=0.01623   sm_loss=0.01407   sm_val_loss=0.01628   time=0.94s\n",
      "Fold 4 log loss: 0.01637021491027147\n",
      "Fold 5\n",
      "Epoch 1   loss=0.40208   val_loss=0.02076   sm_loss=0.40204   sm_val_loss=0.02075   time=0.96s\n",
      "Epoch 2   loss=0.01860   val_loss=0.01832   sm_loss=0.01858   sm_val_loss=0.01832   time=0.96s\n",
      "Epoch 3   loss=0.01695   val_loss=0.01678   sm_loss=0.01700   sm_val_loss=0.01684   time=0.93s\n",
      "Epoch 4   loss=0.01611   val_loss=0.01676   sm_loss=0.01624   sm_val_loss=0.01682   time=0.95s\n",
      "Epoch 6   loss=0.01605   val_loss=0.01663   sm_loss=0.01620   sm_val_loss=0.01669   time=0.97s\n",
      "Epoch 9   loss=0.01593   val_loss=0.01662   sm_loss=0.01609   sm_val_loss=0.01666   time=1.04s\n",
      "Epoch 10   loss=0.01588   val_loss=0.01657   sm_loss=0.01603   sm_val_loss=0.01656   time=1.20s\n",
      "Epoch 11   loss=0.01569   val_loss=0.01645   sm_loss=0.01585   sm_val_loss=0.01644   time=1.07s\n",
      "Epoch 12   loss=0.01554   val_loss=0.01639   sm_loss=0.01571   sm_val_loss=0.01640   time=0.96s\n",
      "Epoch 13   loss=0.01532   val_loss=0.01623   sm_loss=0.01550   sm_val_loss=0.01626   time=0.94s\n",
      "Epoch 15   loss=0.01473   val_loss=0.01604   sm_loss=0.01493   sm_val_loss=0.01609   time=0.96s\n",
      "Epoch 16   loss=0.01438   val_loss=0.01599   sm_loss=0.01460   sm_val_loss=0.01603   time=0.94s\n",
      "Epoch 17   loss=0.01393   val_loss=0.01588   sm_loss=0.01416   sm_val_loss=0.01593   time=0.94s\n",
      "Epoch 18   loss=0.01353   val_loss=0.01584   sm_loss=0.01378   sm_val_loss=0.01587   time=0.95s\n",
      "Epoch 19   loss=0.01316   val_loss=0.01582   sm_loss=0.01341   sm_val_loss=0.01585   time=1.18s\n",
      "Epoch 20   loss=0.01299   val_loss=0.01581   sm_loss=0.01324   sm_val_loss=0.01583   time=0.98s\n",
      "Fold 5 log loss: 0.016007014844876707\n",
      "Fold 6\n",
      "Epoch 1   loss=0.40077   val_loss=0.02136   sm_loss=0.40073   sm_val_loss=0.02134   time=0.94s\n",
      "Epoch 2   loss=0.01857   val_loss=0.01912   sm_loss=0.01854   sm_val_loss=0.01894   time=0.96s\n",
      "Epoch 3   loss=0.01669   val_loss=0.01664   sm_loss=0.01675   sm_val_loss=0.01675   time=0.96s\n",
      "Epoch 6   loss=0.01606   val_loss=0.01661   sm_loss=0.01621   sm_val_loss=0.01668   time=0.96s\n",
      "Epoch 9   loss=0.01602   val_loss=0.01634   sm_loss=0.01616   sm_val_loss=0.01645   time=1.18s\n",
      "Epoch 13   loss=0.01534   val_loss=0.01622   sm_loss=0.01552   sm_val_loss=0.01633   time=0.99s\n",
      "Epoch 14   loss=0.01509   val_loss=0.01620   sm_loss=0.01527   sm_val_loss=0.01631   time=1.20s\n",
      "Epoch 15   loss=0.01480   val_loss=0.01617   sm_loss=0.01500   sm_val_loss=0.01629   time=1.15s\n",
      "Epoch 16   loss=0.01442   val_loss=0.01598   sm_loss=0.01463   sm_val_loss=0.01610   time=0.95s\n",
      "Epoch 18   loss=0.01356   val_loss=0.01598   sm_loss=0.01380   sm_val_loss=0.01609   time=1.01s\n",
      "Fold 6 log loss: 0.016135620467993928\n",
      "Fold 7\n",
      "Epoch 1   loss=0.40097   val_loss=0.02065   sm_loss=0.40091   sm_val_loss=0.02064   time=0.96s\n",
      "Epoch 2   loss=0.01856   val_loss=0.01834   sm_loss=0.01853   sm_val_loss=0.01824   time=0.95s\n",
      "Epoch 3   loss=0.01734   val_loss=0.01688   sm_loss=0.01733   sm_val_loss=0.01698   time=0.98s\n",
      "Epoch 4   loss=0.01626   val_loss=0.01676   sm_loss=0.01639   sm_val_loss=0.01687   time=0.93s\n",
      "Epoch 5   loss=0.01617   val_loss=0.01668   sm_loss=0.01632   sm_val_loss=0.01681   time=0.94s\n",
      "Epoch 6   loss=0.01613   val_loss=0.01661   sm_loss=0.01628   sm_val_loss=0.01671   time=0.95s\n",
      "Epoch 7   loss=0.01612   val_loss=0.01641   sm_loss=0.01627   sm_val_loss=0.01651   time=1.09s\n",
      "Epoch 11   loss=0.01574   val_loss=0.01620   sm_loss=0.01590   sm_val_loss=0.01633   time=0.94s\n",
      "Epoch 12   loss=0.01565   val_loss=0.01609   sm_loss=0.01582   sm_val_loss=0.01618   time=0.94s\n",
      "Epoch 13   loss=0.01540   val_loss=0.01601   sm_loss=0.01558   sm_val_loss=0.01611   time=0.94s\n",
      "Epoch 14   loss=0.01512   val_loss=0.01593   sm_loss=0.01531   sm_val_loss=0.01603   time=0.94s\n",
      "Epoch 15   loss=0.01479   val_loss=0.01566   sm_loss=0.01499   sm_val_loss=0.01580   time=0.95s\n",
      "Epoch 16   loss=0.01442   val_loss=0.01565   sm_loss=0.01464   sm_val_loss=0.01577   time=0.95s\n",
      "Epoch 17   loss=0.01400   val_loss=0.01561   sm_loss=0.01423   sm_val_loss=0.01574   time=0.95s\n",
      "Fold 7 log loss: 0.015723567281300994\n",
      "Seed 0\n",
      "Fold 1 log loss: 0.015938049952719503\n",
      "Fold 2 log loss: 0.015836632917097446\n",
      "Fold 3 log loss: 0.0161948895895312\n",
      "Fold 4 log loss: 0.01637021491027147\n",
      "Fold 5 log loss: 0.016007014844876707\n",
      "Fold 6 log loss: 0.016135620467993928\n",
      "Fold 7 log loss: 0.015723567281300994\n",
      "Std of log loss: 0.00020506553529398317\n",
      "Total log loss: 0.016029288444252842\n",
      "Fold 1\n",
      "Epoch 1   loss=0.40029   val_loss=0.02123   sm_loss=0.40026   sm_val_loss=0.02120   time=0.96s\n",
      "Epoch 2   loss=0.01877   val_loss=0.01834   sm_loss=0.01871   sm_val_loss=0.01807   time=0.96s\n",
      "Epoch 3   loss=0.01676   val_loss=0.01668   sm_loss=0.01685   sm_val_loss=0.01674   time=0.94s\n",
      "Epoch 4   loss=0.01615   val_loss=0.01664   sm_loss=0.01629   sm_val_loss=0.01668   time=0.96s\n",
      "Epoch 5   loss=0.01609   val_loss=0.01654   sm_loss=0.01624   sm_val_loss=0.01659   time=0.95s\n",
      "Epoch 9   loss=0.01600   val_loss=0.01639   sm_loss=0.01615   sm_val_loss=0.01646   time=0.94s\n",
      "Epoch 12   loss=0.01554   val_loss=0.01629   sm_loss=0.01571   sm_val_loss=0.01634   time=0.94s\n",
      "Epoch 13   loss=0.01544   val_loss=0.01612   sm_loss=0.01562   sm_val_loss=0.01620   time=0.94s\n",
      "Epoch 15   loss=0.01481   val_loss=0.01597   sm_loss=0.01501   sm_val_loss=0.01602   time=0.94s\n",
      "Epoch 17   loss=0.01402   val_loss=0.01592   sm_loss=0.01424   sm_val_loss=0.01598   time=1.12s\n",
      "Epoch 18   loss=0.01359   val_loss=0.01591   sm_loss=0.01383   sm_val_loss=0.01596   time=0.99s\n",
      "Epoch 19   loss=0.01324   val_loss=0.01586   sm_loss=0.01348   sm_val_loss=0.01591   time=0.96s\n",
      "Epoch 20   loss=0.01301   val_loss=0.01585   sm_loss=0.01326   sm_val_loss=0.01590   time=0.95s\n",
      "Fold 1 log loss: 0.015967638056316822\n",
      "Fold 2\n",
      "Epoch 1   loss=0.40153   val_loss=0.02066   sm_loss=0.40146   sm_val_loss=0.02066   time=0.98s\n",
      "Epoch 2   loss=0.01864   val_loss=0.01754   sm_loss=0.01863   sm_val_loss=0.01758   time=0.98s\n",
      "Epoch 3   loss=0.01672   val_loss=0.01646   sm_loss=0.01679   sm_val_loss=0.01649   time=0.97s\n",
      "Epoch 5   loss=0.01613   val_loss=0.01622   sm_loss=0.01628   sm_val_loss=0.01625   time=0.97s\n",
      "Epoch 10   loss=0.01594   val_loss=0.01604   sm_loss=0.01610   sm_val_loss=0.01610   time=1.01s\n",
      "Epoch 11   loss=0.01577   val_loss=0.01600   sm_loss=0.01594   sm_val_loss=0.01608   time=0.98s\n",
      "Epoch 13   loss=0.01537   val_loss=0.01591   sm_loss=0.01555   sm_val_loss=0.01596   time=1.04s\n",
      "Epoch 17   loss=0.01403   val_loss=0.01579   sm_loss=0.01426   sm_val_loss=0.01586   time=1.00s\n",
      "Epoch 18   loss=0.01357   val_loss=0.01576   sm_loss=0.01381   sm_val_loss=0.01585   time=0.95s\n",
      "Epoch 19   loss=0.01321   val_loss=0.01576   sm_loss=0.01345   sm_val_loss=0.01584   time=0.94s\n",
      "Epoch 20   loss=0.01302   val_loss=0.01574   sm_loss=0.01328   sm_val_loss=0.01582   time=0.94s\n",
      "Fold 2 log loss: 0.015881121752421647\n",
      "Fold 3\n",
      "Epoch 1   loss=0.40070   val_loss=0.02107   sm_loss=0.40066   sm_val_loss=0.02106   time=0.96s\n",
      "Epoch 2   loss=0.01877   val_loss=0.01852   sm_loss=0.01869   sm_val_loss=0.01812   time=0.94s\n",
      "Epoch 3   loss=0.01663   val_loss=0.01675   sm_loss=0.01671   sm_val_loss=0.01682   time=0.94s\n",
      "Epoch 10   loss=0.01586   val_loss=0.01668   sm_loss=0.01602   sm_val_loss=0.01674   time=0.93s\n",
      "Epoch 11   loss=0.01569   val_loss=0.01666   sm_loss=0.01586   sm_val_loss=0.01670   time=0.96s\n",
      "Epoch 12   loss=0.01560   val_loss=0.01646   sm_loss=0.01577   sm_val_loss=0.01655   time=0.99s\n",
      "Epoch 13   loss=0.01538   val_loss=0.01645   sm_loss=0.01556   sm_val_loss=0.01652   time=0.97s\n",
      "Epoch 15   loss=0.01473   val_loss=0.01641   sm_loss=0.01493   sm_val_loss=0.01646   time=0.93s\n",
      "Epoch 16   loss=0.01438   val_loss=0.01633   sm_loss=0.01459   sm_val_loss=0.01637   time=1.02s\n",
      "Epoch 17   loss=0.01396   val_loss=0.01619   sm_loss=0.01419   sm_val_loss=0.01624   time=1.07s\n",
      "Epoch 18   loss=0.01354   val_loss=0.01617   sm_loss=0.01378   sm_val_loss=0.01623   time=0.95s\n",
      "Epoch 19   loss=0.01318   val_loss=0.01616   sm_loss=0.01342   sm_val_loss=0.01620   time=0.94s\n",
      "Fold 3 log loss: 0.016192192060828486\n",
      "Fold 4\n",
      "Epoch 1   loss=0.40108   val_loss=0.02100   sm_loss=0.40103   sm_val_loss=0.02097   time=0.96s\n",
      "Epoch 2   loss=0.01844   val_loss=0.01779   sm_loss=0.01844   sm_val_loss=0.01781   time=0.97s\n",
      "Epoch 3   loss=0.01663   val_loss=0.01753   sm_loss=0.01672   sm_val_loss=0.01745   time=1.07s\n",
      "Epoch 4   loss=0.01608   val_loss=0.01745   sm_loss=0.01623   sm_val_loss=0.01738   time=1.16s\n",
      "Epoch 5   loss=0.01603   val_loss=0.01702   sm_loss=0.01619   sm_val_loss=0.01700   time=0.94s\n",
      "Epoch 6   loss=0.01594   val_loss=0.01679   sm_loss=0.01610   sm_val_loss=0.01684   time=1.27s\n",
      "Epoch 8   loss=0.01594   val_loss=0.01655   sm_loss=0.01610   sm_val_loss=0.01657   time=0.99s\n",
      "Epoch 14   loss=0.01495   val_loss=0.01641   sm_loss=0.01515   sm_val_loss=0.01642   time=0.94s\n",
      "Epoch 17   loss=0.01379   val_loss=0.01635   sm_loss=0.01402   sm_val_loss=0.01640   time=1.18s\n",
      "Epoch 18   loss=0.01340   val_loss=0.01632   sm_loss=0.01365   sm_val_loss=0.01637   time=0.95s\n",
      "Epoch 19   loss=0.01306   val_loss=0.01628   sm_loss=0.01331   sm_val_loss=0.01632   time=0.96s\n",
      "Epoch 20   loss=0.01281   val_loss=0.01629   sm_loss=0.01307   sm_val_loss=0.01631   time=0.96s\n",
      "Fold 4 log loss: 0.01640140447573916\n",
      "Fold 5\n",
      "Epoch 1   loss=0.40194   val_loss=0.02145   sm_loss=0.40187   sm_val_loss=0.02144   time=0.99s\n",
      "Epoch 2   loss=0.01876   val_loss=0.01800   sm_loss=0.01873   sm_val_loss=0.01805   time=1.01s\n",
      "Epoch 3   loss=0.01732   val_loss=0.01712   sm_loss=0.01733   sm_val_loss=0.01714   time=1.31s\n",
      "Epoch 4   loss=0.01633   val_loss=0.01678   sm_loss=0.01647   sm_val_loss=0.01680   time=1.02s\n",
      "Epoch 5   loss=0.01613   val_loss=0.01670   sm_loss=0.01628   sm_val_loss=0.01674   time=1.21s\n",
      "Epoch 7   loss=0.01611   val_loss=0.01668   sm_loss=0.01626   sm_val_loss=0.01670   time=1.02s\n",
      "Epoch 8   loss=0.01601   val_loss=0.01659   sm_loss=0.01616   sm_val_loss=0.01661   time=0.95s\n",
      "Epoch 12   loss=0.01555   val_loss=0.01639   sm_loss=0.01573   sm_val_loss=0.01642   time=1.04s\n",
      "Epoch 13   loss=0.01539   val_loss=0.01630   sm_loss=0.01557   sm_val_loss=0.01635   time=1.21s\n",
      "Epoch 14   loss=0.01510   val_loss=0.01621   sm_loss=0.01530   sm_val_loss=0.01627   time=0.97s\n",
      "Epoch 15   loss=0.01472   val_loss=0.01605   sm_loss=0.01493   sm_val_loss=0.01612   time=1.17s\n",
      "Epoch 16   loss=0.01439   val_loss=0.01599   sm_loss=0.01461   sm_val_loss=0.01603   time=0.98s\n",
      "Epoch 17   loss=0.01401   val_loss=0.01593   sm_loss=0.01424   sm_val_loss=0.01598   time=0.97s\n",
      "Epoch 18   loss=0.01359   val_loss=0.01589   sm_loss=0.01383   sm_val_loss=0.01593   time=0.97s\n",
      "Epoch 19   loss=0.01322   val_loss=0.01589   sm_loss=0.01348   sm_val_loss=0.01593   time=0.95s\n",
      "Fold 5 log loss: 0.016071408242120444\n",
      "Fold 6\n",
      "Epoch 1   loss=0.40020   val_loss=0.02087   sm_loss=0.40015   sm_val_loss=0.02084   time=0.96s\n",
      "Epoch 2   loss=0.01862   val_loss=0.01832   sm_loss=0.01857   sm_val_loss=0.01835   time=0.97s\n",
      "Epoch 3   loss=0.01690   val_loss=0.01708   sm_loss=0.01695   sm_val_loss=0.01718   time=0.95s\n",
      "Epoch 5   loss=0.01613   val_loss=0.01680   sm_loss=0.01628   sm_val_loss=0.01687   time=1.06s\n",
      "Epoch 7   loss=0.01604   val_loss=0.01674   sm_loss=0.01619   sm_val_loss=0.01685   time=0.95s\n",
      "Epoch 8   loss=0.01600   val_loss=0.01672   sm_loss=0.01614   sm_val_loss=0.01681   time=0.94s\n",
      "Epoch 9   loss=0.01595   val_loss=0.01646   sm_loss=0.01611   sm_val_loss=0.01653   time=0.94s\n",
      "Epoch 11   loss=0.01572   val_loss=0.01639   sm_loss=0.01588   sm_val_loss=0.01649   time=0.95s\n",
      "Epoch 12   loss=0.01556   val_loss=0.01633   sm_loss=0.01573   sm_val_loss=0.01646   time=0.96s\n",
      "Epoch 14   loss=0.01508   val_loss=0.01615   sm_loss=0.01527   sm_val_loss=0.01628   time=0.98s\n",
      "Epoch 15   loss=0.01476   val_loss=0.01605   sm_loss=0.01496   sm_val_loss=0.01617   time=1.11s\n",
      "Epoch 16   loss=0.01434   val_loss=0.01602   sm_loss=0.01456   sm_val_loss=0.01615   time=1.05s\n",
      "Epoch 17   loss=0.01388   val_loss=0.01594   sm_loss=0.01411   sm_val_loss=0.01607   time=0.95s\n",
      "Fold 6 log loss: 0.0161156977689977\n",
      "Fold 7\n",
      "Epoch 1   loss=0.40164   val_loss=0.02057   sm_loss=0.40159   sm_val_loss=0.02057   time=1.27s\n",
      "Epoch 2   loss=0.01892   val_loss=0.01767   sm_loss=0.01885   sm_val_loss=0.01761   time=0.95s\n",
      "Epoch 3   loss=0.01728   val_loss=0.01665   sm_loss=0.01726   sm_val_loss=0.01674   time=0.95s\n",
      "Epoch 5   loss=0.01610   val_loss=0.01660   sm_loss=0.01626   sm_val_loss=0.01666   time=1.12s\n",
      "Epoch 8   loss=0.01610   val_loss=0.01645   sm_loss=0.01625   sm_val_loss=0.01655   time=0.97s\n",
      "Epoch 11   loss=0.01577   val_loss=0.01614   sm_loss=0.01593   sm_val_loss=0.01625   time=0.96s\n",
      "Epoch 13   loss=0.01535   val_loss=0.01599   sm_loss=0.01552   sm_val_loss=0.01609   time=0.96s\n",
      "Epoch 15   loss=0.01482   val_loss=0.01584   sm_loss=0.01502   sm_val_loss=0.01597   time=1.42s\n",
      "Epoch 16   loss=0.01444   val_loss=0.01565   sm_loss=0.01465   sm_val_loss=0.01577   time=1.13s\n",
      "Epoch 17   loss=0.01404   val_loss=0.01555   sm_loss=0.01427   sm_val_loss=0.01567   time=0.97s\n",
      "Epoch 18   loss=0.01361   val_loss=0.01551   sm_loss=0.01385   sm_val_loss=0.01564   time=1.23s\n",
      "Epoch 19   loss=0.01326   val_loss=0.01548   sm_loss=0.01350   sm_val_loss=0.01560   time=1.13s\n",
      "Fold 7 log loss: 0.015581392472713736\n",
      "Seed 1\n",
      "Fold 1 log loss: 0.015967638056316822\n",
      "Fold 2 log loss: 0.015881121752421647\n",
      "Fold 3 log loss: 0.016192192060828486\n",
      "Fold 4 log loss: 0.01640140447573916\n",
      "Fold 5 log loss: 0.016071408242120444\n",
      "Fold 6 log loss: 0.0161156977689977\n",
      "Fold 7 log loss: 0.015581392472713736\n",
      "Std of log loss: 0.000239227522631548\n",
      "Total log loss: 0.016030118643633257\n",
      "Fold 1\n",
      "Epoch 1   loss=0.40181   val_loss=0.02102   sm_loss=0.40175   sm_val_loss=0.02096   time=0.98s\n",
      "Epoch 2   loss=0.01862   val_loss=0.01754   sm_loss=0.01859   sm_val_loss=0.01750   time=1.08s\n",
      "Epoch 3   loss=0.01673   val_loss=0.01680   sm_loss=0.01678   sm_val_loss=0.01686   time=1.04s\n",
      "Epoch 4   loss=0.01621   val_loss=0.01669   sm_loss=0.01634   sm_val_loss=0.01670   time=0.96s\n",
      "Epoch 6   loss=0.01616   val_loss=0.01668   sm_loss=0.01631   sm_val_loss=0.01667   time=0.96s\n",
      "Epoch 8   loss=0.01612   val_loss=0.01649   sm_loss=0.01626   sm_val_loss=0.01658   time=1.30s\n",
      "Epoch 10   loss=0.01593   val_loss=0.01634   sm_loss=0.01609   sm_val_loss=0.01640   time=0.95s\n",
      "Epoch 11   loss=0.01581   val_loss=0.01619   sm_loss=0.01597   sm_val_loss=0.01627   time=0.94s\n",
      "Epoch 13   loss=0.01543   val_loss=0.01612   sm_loss=0.01560   sm_val_loss=0.01619   time=1.17s\n",
      "Epoch 15   loss=0.01491   val_loss=0.01598   sm_loss=0.01511   sm_val_loss=0.01605   time=0.95s\n",
      "Epoch 16   loss=0.01451   val_loss=0.01588   sm_loss=0.01472   sm_val_loss=0.01591   time=0.94s\n",
      "Epoch 17   loss=0.01412   val_loss=0.01588   sm_loss=0.01434   sm_val_loss=0.01590   time=0.94s\n",
      "Epoch 18   loss=0.01370   val_loss=0.01583   sm_loss=0.01393   sm_val_loss=0.01586   time=0.95s\n",
      "Epoch 19   loss=0.01332   val_loss=0.01577   sm_loss=0.01356   sm_val_loss=0.01581   time=0.95s\n",
      "Fold 1 log loss: 0.01587623137459665\n",
      "Fold 2\n",
      "Epoch 1   loss=0.40059   val_loss=0.02066   sm_loss=0.40054   sm_val_loss=0.02065   time=1.01s\n",
      "Epoch 2   loss=0.01886   val_loss=0.01708   sm_loss=0.01877   sm_val_loss=0.01714   time=1.14s\n",
      "Epoch 3   loss=0.01687   val_loss=0.01649   sm_loss=0.01692   sm_val_loss=0.01659   time=1.04s\n",
      "Epoch 4   loss=0.01621   val_loss=0.01650   sm_loss=0.01635   sm_val_loss=0.01658   time=0.97s\n",
      "Epoch 6   loss=0.01614   val_loss=0.01606   sm_loss=0.01629   sm_val_loss=0.01615   time=1.01s\n",
      "Epoch 12   loss=0.01561   val_loss=0.01580   sm_loss=0.01578   sm_val_loss=0.01589   time=0.95s\n",
      "Epoch 15   loss=0.01478   val_loss=0.01570   sm_loss=0.01498   sm_val_loss=0.01578   time=1.00s\n",
      "Epoch 17   loss=0.01400   val_loss=0.01561   sm_loss=0.01423   sm_val_loss=0.01569   time=0.99s\n",
      "Fold 2 log loss: 0.015759905620089637\n",
      "Fold 3\n",
      "Epoch 1   loss=0.40028   val_loss=0.02113   sm_loss=0.40021   sm_val_loss=0.02110   time=0.97s\n",
      "Epoch 2   loss=0.01857   val_loss=0.02090   sm_loss=0.01852   sm_val_loss=0.02093   time=1.12s\n",
      "Epoch 3   loss=0.01670   val_loss=0.01988   sm_loss=0.01677   sm_val_loss=0.01906   time=1.03s\n",
      "Epoch 4   loss=0.01631   val_loss=0.01702   sm_loss=0.01642   sm_val_loss=0.01709   time=0.97s\n",
      "Epoch 6   loss=0.01616   val_loss=0.01682   sm_loss=0.01631   sm_val_loss=0.01687   time=1.31s\n",
      "Epoch 7   loss=0.01611   val_loss=0.01677   sm_loss=0.01626   sm_val_loss=0.01682   time=1.04s\n",
      "Epoch 10   loss=0.01586   val_loss=0.01671   sm_loss=0.01602   sm_val_loss=0.01678   time=0.98s\n",
      "Epoch 13   loss=0.01535   val_loss=0.01665   sm_loss=0.01553   sm_val_loss=0.01666   time=1.14s\n",
      "Epoch 14   loss=0.01514   val_loss=0.01631   sm_loss=0.01533   sm_val_loss=0.01639   time=1.00s\n",
      "Epoch 15   loss=0.01481   val_loss=0.01623   sm_loss=0.01501   sm_val_loss=0.01630   time=0.97s\n",
      "Epoch 17   loss=0.01398   val_loss=0.01618   sm_loss=0.01421   sm_val_loss=0.01625   time=0.94s\n",
      "Epoch 18   loss=0.01357   val_loss=0.01620   sm_loss=0.01382   sm_val_loss=0.01624   time=0.95s\n",
      "Epoch 19   loss=0.01322   val_loss=0.01615   sm_loss=0.01346   sm_val_loss=0.01619   time=0.95s\n",
      "Fold 3 log loss: 0.016177047699961682\n",
      "Fold 4\n",
      "Epoch 1   loss=0.40155   val_loss=0.02090   sm_loss=0.40150   sm_val_loss=0.02089   time=0.93s\n",
      "Epoch 2   loss=0.01842   val_loss=0.01905   sm_loss=0.01840   sm_val_loss=0.01853   time=1.19s\n",
      "Epoch 3   loss=0.01667   val_loss=0.01740   sm_loss=0.01674   sm_val_loss=0.01728   time=0.99s\n",
      "Epoch 4   loss=0.01603   val_loss=0.01710   sm_loss=0.01618   sm_val_loss=0.01715   time=0.95s\n",
      "Epoch 5   loss=0.01600   val_loss=0.01681   sm_loss=0.01616   sm_val_loss=0.01685   time=0.98s\n",
      "Epoch 8   loss=0.01593   val_loss=0.01680   sm_loss=0.01609   sm_val_loss=0.01684   time=0.95s\n",
      "Epoch 10   loss=0.01573   val_loss=0.01672   sm_loss=0.01589   sm_val_loss=0.01675   time=0.94s\n",
      "Epoch 11   loss=0.01560   val_loss=0.01655   sm_loss=0.01577   sm_val_loss=0.01659   time=0.96s\n",
      "Epoch 14   loss=0.01496   val_loss=0.01629   sm_loss=0.01515   sm_val_loss=0.01634   time=0.94s\n",
      "Epoch 18   loss=0.01341   val_loss=0.01622   sm_loss=0.01365   sm_val_loss=0.01626   time=0.97s\n",
      "Fold 4 log loss: 0.01635539992041662\n",
      "Fold 5\n",
      "Epoch 1   loss=0.40213   val_loss=0.02094   sm_loss=0.40209   sm_val_loss=0.02090   time=0.96s\n",
      "Epoch 2   loss=0.01882   val_loss=0.01761   sm_loss=0.01871   sm_val_loss=0.01763   time=1.20s\n",
      "Epoch 3   loss=0.01677   val_loss=0.01675   sm_loss=0.01681   sm_val_loss=0.01682   time=0.99s\n",
      "Epoch 5   loss=0.01606   val_loss=0.01667   sm_loss=0.01621   sm_val_loss=0.01669   time=0.96s\n",
      "Epoch 9   loss=0.01593   val_loss=0.01645   sm_loss=0.01609   sm_val_loss=0.01653   time=0.94s\n",
      "Epoch 10   loss=0.01587   val_loss=0.01650   sm_loss=0.01602   sm_val_loss=0.01653   time=0.95s\n",
      "Epoch 11   loss=0.01570   val_loss=0.01639   sm_loss=0.01586   sm_val_loss=0.01644   time=0.95s\n",
      "Epoch 12   loss=0.01553   val_loss=0.01639   sm_loss=0.01571   sm_val_loss=0.01641   time=0.94s\n",
      "Epoch 13   loss=0.01530   val_loss=0.01626   sm_loss=0.01549   sm_val_loss=0.01632   time=1.16s\n",
      "Epoch 14   loss=0.01508   val_loss=0.01606   sm_loss=0.01528   sm_val_loss=0.01612   time=0.99s\n",
      "Epoch 16   loss=0.01440   val_loss=0.01600   sm_loss=0.01462   sm_val_loss=0.01607   time=1.15s\n",
      "Epoch 17   loss=0.01400   val_loss=0.01599   sm_loss=0.01424   sm_val_loss=0.01603   time=0.97s\n",
      "Epoch 18   loss=0.01357   val_loss=0.01587   sm_loss=0.01381   sm_val_loss=0.01592   time=0.96s\n",
      "Epoch 19   loss=0.01324   val_loss=0.01585   sm_loss=0.01349   sm_val_loss=0.01591   time=0.98s\n",
      "Fold 5 log loss: 0.01603911773923737\n",
      "Fold 6\n",
      "Epoch 1   loss=0.40028   val_loss=0.02080   sm_loss=0.40022   sm_val_loss=0.02074   time=1.00s\n",
      "Epoch 2   loss=0.01862   val_loss=0.01794   sm_loss=0.01858   sm_val_loss=0.01798   time=1.31s\n",
      "Epoch 3   loss=0.01671   val_loss=0.01730   sm_loss=0.01677   sm_val_loss=0.01739   time=1.09s\n",
      "Epoch 4   loss=0.01614   val_loss=0.01705   sm_loss=0.01628   sm_val_loss=0.01715   time=1.01s\n",
      "Epoch 5   loss=0.01614   val_loss=0.01668   sm_loss=0.01629   sm_val_loss=0.01679   time=1.05s\n",
      "Epoch 7   loss=0.01612   val_loss=0.01641   sm_loss=0.01626   sm_val_loss=0.01651   time=1.05s\n",
      "Epoch 11   loss=0.01566   val_loss=0.01633   sm_loss=0.01582   sm_val_loss=0.01644   time=0.96s\n",
      "Epoch 12   loss=0.01558   val_loss=0.01624   sm_loss=0.01575   sm_val_loss=0.01636   time=1.18s\n",
      "Epoch 14   loss=0.01509   val_loss=0.01614   sm_loss=0.01528   sm_val_loss=0.01627   time=0.95s\n",
      "Epoch 15   loss=0.01474   val_loss=0.01602   sm_loss=0.01494   sm_val_loss=0.01614   time=0.96s\n",
      "Epoch 16   loss=0.01439   val_loss=0.01600   sm_loss=0.01460   sm_val_loss=0.01612   time=0.96s\n",
      "Epoch 17   loss=0.01393   val_loss=0.01587   sm_loss=0.01416   sm_val_loss=0.01600   time=0.95s\n",
      "Fold 6 log loss: 0.016035877181472258\n",
      "Fold 7\n",
      "Epoch 1   loss=0.40116   val_loss=0.02066   sm_loss=0.40108   sm_val_loss=0.02065   time=1.10s\n",
      "Epoch 2   loss=0.01858   val_loss=0.01920   sm_loss=0.01854   sm_val_loss=0.01890   time=1.12s\n",
      "Epoch 3   loss=0.01702   val_loss=0.01686   sm_loss=0.01705   sm_val_loss=0.01695   time=1.24s\n",
      "Epoch 4   loss=0.01620   val_loss=0.01663   sm_loss=0.01633   sm_val_loss=0.01673   time=1.09s\n",
      "Epoch 6   loss=0.01611   val_loss=0.01643   sm_loss=0.01626   sm_val_loss=0.01655   time=1.00s\n",
      "Epoch 8   loss=0.01602   val_loss=0.01635   sm_loss=0.01617   sm_val_loss=0.01643   time=0.95s\n",
      "Epoch 11   loss=0.01574   val_loss=0.01619   sm_loss=0.01591   sm_val_loss=0.01630   time=0.94s\n",
      "Epoch 13   loss=0.01535   val_loss=0.01605   sm_loss=0.01553   sm_val_loss=0.01614   time=0.97s\n",
      "Epoch 14   loss=0.01513   val_loss=0.01582   sm_loss=0.01532   sm_val_loss=0.01595   time=1.03s\n",
      "Epoch 15   loss=0.01479   val_loss=0.01579   sm_loss=0.01499   sm_val_loss=0.01589   time=1.00s\n",
      "Epoch 16   loss=0.01444   val_loss=0.01569   sm_loss=0.01466   sm_val_loss=0.01581   time=0.98s\n",
      "Epoch 17   loss=0.01398   val_loss=0.01567   sm_loss=0.01421   sm_val_loss=0.01579   time=0.96s\n",
      "Epoch 18   loss=0.01355   val_loss=0.01564   sm_loss=0.01379   sm_val_loss=0.01575   time=0.95s\n",
      "Fold 7 log loss: 0.015733816386007633\n",
      "Seed 2\n",
      "Fold 1 log loss: 0.01587623137459665\n",
      "Fold 2 log loss: 0.015759905620089637\n",
      "Fold 3 log loss: 0.016177047699961682\n",
      "Fold 4 log loss: 0.01635539992041662\n",
      "Fold 5 log loss: 0.01603911773923737\n",
      "Fold 6 log loss: 0.016035877181472258\n",
      "Fold 7 log loss: 0.015733816386007633\n",
      "Std of log loss: 0.0002084696173045757\n",
      "Total log loss: 0.015996926598324888\n",
      "Fold 1\n",
      "Epoch 1   loss=0.40167   val_loss=0.02078   sm_loss=0.40165   sm_val_loss=0.02075   time=0.98s\n",
      "Epoch 2   loss=0.01869   val_loss=0.01763   sm_loss=0.01866   sm_val_loss=0.01766   time=0.96s\n",
      "Epoch 3   loss=0.01672   val_loss=0.01696   sm_loss=0.01681   sm_val_loss=0.01697   time=0.96s\n",
      "Epoch 4   loss=0.01619   val_loss=0.01669   sm_loss=0.01633   sm_val_loss=0.01676   time=0.96s\n",
      "Epoch 6   loss=0.01614   val_loss=0.01646   sm_loss=0.01629   sm_val_loss=0.01653   time=0.94s\n",
      "Epoch 7   loss=0.01609   val_loss=0.01647   sm_loss=0.01624   sm_val_loss=0.01651   time=0.96s\n",
      "Epoch 11   loss=0.01573   val_loss=0.01621   sm_loss=0.01589   sm_val_loss=0.01630   time=1.20s\n",
      "Epoch 13   loss=0.01539   val_loss=0.01615   sm_loss=0.01557   sm_val_loss=0.01621   time=1.21s\n",
      "Epoch 14   loss=0.01518   val_loss=0.01603   sm_loss=0.01537   sm_val_loss=0.01610   time=1.30s\n",
      "Epoch 15   loss=0.01481   val_loss=0.01600   sm_loss=0.01501   sm_val_loss=0.01609   time=0.97s\n",
      "Epoch 16   loss=0.01441   val_loss=0.01587   sm_loss=0.01462   sm_val_loss=0.01594   time=1.02s\n",
      "Epoch 17   loss=0.01403   val_loss=0.01573   sm_loss=0.01426   sm_val_loss=0.01579   time=0.98s\n",
      "Fold 1 log loss: 0.01586267774779687\n",
      "Fold 2\n",
      "Epoch 1   loss=0.40043   val_loss=0.02037   sm_loss=0.40038   sm_val_loss=0.02036   time=0.98s\n",
      "Epoch 2   loss=0.01874   val_loss=0.01707   sm_loss=0.01868   sm_val_loss=0.01711   time=1.01s\n",
      "Epoch 3   loss=0.01686   val_loss=0.01634   sm_loss=0.01688   sm_val_loss=0.01642   time=0.99s\n",
      "Epoch 4   loss=0.01626   val_loss=0.01631   sm_loss=0.01639   sm_val_loss=0.01638   time=0.98s\n",
      "Epoch 5   loss=0.01608   val_loss=0.01622   sm_loss=0.01623   sm_val_loss=0.01629   time=0.97s\n",
      "Epoch 6   loss=0.01615   val_loss=0.01614   sm_loss=0.01630   sm_val_loss=0.01622   time=0.97s\n",
      "Epoch 11   loss=0.01576   val_loss=0.01598   sm_loss=0.01592   sm_val_loss=0.01605   time=0.98s\n",
      "Epoch 15   loss=0.01470   val_loss=0.01597   sm_loss=0.01491   sm_val_loss=0.01605   time=0.95s\n",
      "Epoch 16   loss=0.01435   val_loss=0.01585   sm_loss=0.01457   sm_val_loss=0.01593   time=0.96s\n",
      "Epoch 17   loss=0.01392   val_loss=0.01584   sm_loss=0.01415   sm_val_loss=0.01590   time=0.95s\n",
      "Epoch 18   loss=0.01342   val_loss=0.01580   sm_loss=0.01367   sm_val_loss=0.01586   time=0.95s\n",
      "Epoch 19   loss=0.01304   val_loss=0.01579   sm_loss=0.01329   sm_val_loss=0.01586   time=0.97s\n",
      "Epoch 20   loss=0.01286   val_loss=0.01575   sm_loss=0.01311   sm_val_loss=0.01582   time=0.96s\n",
      "Fold 2 log loss: 0.01590654841234074\n",
      "Fold 3\n",
      "Epoch 1   loss=0.40063   val_loss=0.02106   sm_loss=0.40058   sm_val_loss=0.02104   time=0.97s\n",
      "Epoch 2   loss=0.01861   val_loss=0.02012   sm_loss=0.01856   sm_val_loss=0.01997   time=0.94s\n",
      "Epoch 3   loss=0.01676   val_loss=0.01705   sm_loss=0.01681   sm_val_loss=0.01714   time=0.97s\n",
      "Epoch 6   loss=0.01603   val_loss=0.01704   sm_loss=0.01619   sm_val_loss=0.01706   time=0.94s\n",
      "Epoch 8   loss=0.01597   val_loss=0.01670   sm_loss=0.01612   sm_val_loss=0.01677   time=0.98s\n",
      "Epoch 12   loss=0.01557   val_loss=0.01645   sm_loss=0.01574   sm_val_loss=0.01653   time=0.94s\n",
      "Epoch 14   loss=0.01504   val_loss=0.01636   sm_loss=0.01523   sm_val_loss=0.01642   time=0.96s\n",
      "Epoch 15   loss=0.01476   val_loss=0.01631   sm_loss=0.01496   sm_val_loss=0.01639   time=0.97s\n",
      "Epoch 16   loss=0.01436   val_loss=0.01627   sm_loss=0.01458   sm_val_loss=0.01633   time=0.99s\n",
      "Epoch 17   loss=0.01393   val_loss=0.01617   sm_loss=0.01416   sm_val_loss=0.01624   time=0.94s\n",
      "Epoch 18   loss=0.01347   val_loss=0.01619   sm_loss=0.01371   sm_val_loss=0.01623   time=0.94s\n",
      "Fold 3 log loss: 0.016216556332763605\n",
      "Fold 4\n",
      "Epoch 1   loss=0.40124   val_loss=0.02117   sm_loss=0.40120   sm_val_loss=0.02116   time=0.98s\n",
      "Epoch 2   loss=0.01859   val_loss=0.01857   sm_loss=0.01859   sm_val_loss=0.01827   time=0.98s\n",
      "Epoch 3   loss=0.01673   val_loss=0.01707   sm_loss=0.01682   sm_val_loss=0.01706   time=0.94s\n",
      "Epoch 4   loss=0.01607   val_loss=0.01692   sm_loss=0.01622   sm_val_loss=0.01693   time=0.94s\n",
      "Epoch 8   loss=0.01591   val_loss=0.01680   sm_loss=0.01607   sm_val_loss=0.01685   time=0.98s\n",
      "Epoch 9   loss=0.01589   val_loss=0.01676   sm_loss=0.01605   sm_val_loss=0.01675   time=1.33s\n",
      "Epoch 11   loss=0.01563   val_loss=0.01670   sm_loss=0.01579   sm_val_loss=0.01674   time=1.22s\n",
      "Epoch 12   loss=0.01543   val_loss=0.01662   sm_loss=0.01560   sm_val_loss=0.01666   time=0.98s\n",
      "Epoch 13   loss=0.01525   val_loss=0.01636   sm_loss=0.01543   sm_val_loss=0.01644   time=1.01s\n",
      "Epoch 15   loss=0.01462   val_loss=0.01632   sm_loss=0.01483   sm_val_loss=0.01638   time=0.97s\n",
      "Epoch 18   loss=0.01331   val_loss=0.01630   sm_loss=0.01356   sm_val_loss=0.01636   time=0.95s\n",
      "Epoch 19   loss=0.01294   val_loss=0.01628   sm_loss=0.01320   sm_val_loss=0.01634   time=1.05s\n",
      "Epoch 20   loss=0.01270   val_loss=0.01626   sm_loss=0.01295   sm_val_loss=0.01632   time=1.21s\n",
      "Fold 4 log loss: 0.01640720456182241\n",
      "Fold 5\n",
      "Epoch 1   loss=0.40221   val_loss=0.02096   sm_loss=0.40217   sm_val_loss=0.02095   time=0.95s\n",
      "Epoch 2   loss=0.01859   val_loss=0.01803   sm_loss=0.01858   sm_val_loss=0.01807   time=0.97s\n",
      "Epoch 3   loss=0.01668   val_loss=0.01706   sm_loss=0.01675   sm_val_loss=0.01713   time=1.13s\n",
      "Epoch 4   loss=0.01615   val_loss=0.01681   sm_loss=0.01628   sm_val_loss=0.01687   time=0.96s\n",
      "Epoch 6   loss=0.01602   val_loss=0.01672   sm_loss=0.01618   sm_val_loss=0.01677   time=0.95s\n",
      "Epoch 10   loss=0.01577   val_loss=0.01656   sm_loss=0.01594   sm_val_loss=0.01661   time=0.99s\n",
      "Epoch 11   loss=0.01566   val_loss=0.01638   sm_loss=0.01582   sm_val_loss=0.01644   time=0.96s\n",
      "Epoch 12   loss=0.01545   val_loss=0.01635   sm_loss=0.01563   sm_val_loss=0.01639   time=0.95s\n",
      "Epoch 13   loss=0.01527   val_loss=0.01617   sm_loss=0.01545   sm_val_loss=0.01620   time=0.96s\n",
      "Epoch 14   loss=0.01500   val_loss=0.01615   sm_loss=0.01519   sm_val_loss=0.01617   time=0.96s\n",
      "Epoch 15   loss=0.01470   val_loss=0.01606   sm_loss=0.01491   sm_val_loss=0.01613   time=0.94s\n",
      "Epoch 16   loss=0.01431   val_loss=0.01594   sm_loss=0.01453   sm_val_loss=0.01598   time=0.98s\n",
      "Epoch 17   loss=0.01385   val_loss=0.01588   sm_loss=0.01408   sm_val_loss=0.01594   time=0.96s\n",
      "Epoch 18   loss=0.01340   val_loss=0.01585   sm_loss=0.01365   sm_val_loss=0.01590   time=0.96s\n",
      "Epoch 19   loss=0.01301   val_loss=0.01583   sm_loss=0.01326   sm_val_loss=0.01587   time=1.27s\n",
      "Epoch 20   loss=0.01281   val_loss=0.01582   sm_loss=0.01307   sm_val_loss=0.01586   time=1.24s\n",
      "Fold 5 log loss: 0.016007923983823977\n",
      "Fold 6\n",
      "Epoch 1   loss=0.40021   val_loss=0.02062   sm_loss=0.40016   sm_val_loss=0.02060   time=0.97s\n",
      "Epoch 2   loss=0.01870   val_loss=0.02049   sm_loss=0.01864   sm_val_loss=0.02048   time=0.98s\n",
      "Epoch 3   loss=0.01672   val_loss=0.01930   sm_loss=0.01679   sm_val_loss=0.01939   time=0.96s\n",
      "Epoch 4   loss=0.01621   val_loss=0.01689   sm_loss=0.01633   sm_val_loss=0.01701   time=0.95s\n",
      "Epoch 6   loss=0.01611   val_loss=0.01653   sm_loss=0.01625   sm_val_loss=0.01665   time=0.97s\n",
      "Epoch 8   loss=0.01612   val_loss=0.01652   sm_loss=0.01626   sm_val_loss=0.01662   time=0.96s\n",
      "Epoch 10   loss=0.01590   val_loss=0.01640   sm_loss=0.01605   sm_val_loss=0.01652   time=0.97s\n",
      "Epoch 11   loss=0.01575   val_loss=0.01636   sm_loss=0.01591   sm_val_loss=0.01648   time=0.97s\n",
      "Epoch 12   loss=0.01561   val_loss=0.01622   sm_loss=0.01578   sm_val_loss=0.01634   time=0.98s\n",
      "Epoch 14   loss=0.01507   val_loss=0.01615   sm_loss=0.01526   sm_val_loss=0.01625   time=0.95s\n",
      "Epoch 16   loss=0.01441   val_loss=0.01595   sm_loss=0.01463   sm_val_loss=0.01609   time=0.95s\n",
      "Epoch 17   loss=0.01398   val_loss=0.01589   sm_loss=0.01420   sm_val_loss=0.01603   time=0.94s\n",
      "Epoch 20   loss=0.01291   val_loss=0.01589   sm_loss=0.01315   sm_val_loss=0.01602   time=1.16s\n",
      "Fold 6 log loss: 0.0160610970744921\n",
      "Fold 7\n",
      "Epoch 1   loss=0.40097   val_loss=0.02121   sm_loss=0.40094   sm_val_loss=0.02120   time=1.02s\n",
      "Epoch 2   loss=0.01876   val_loss=0.01742   sm_loss=0.01869   sm_val_loss=0.01746   time=1.00s\n",
      "Epoch 3   loss=0.01678   val_loss=0.01661   sm_loss=0.01684   sm_val_loss=0.01670   time=1.03s\n",
      "Epoch 4   loss=0.01625   val_loss=0.01658   sm_loss=0.01638   sm_val_loss=0.01667   time=0.99s\n",
      "Epoch 5   loss=0.01612   val_loss=0.01657   sm_loss=0.01627   sm_val_loss=0.01667   time=1.27s\n",
      "Epoch 6   loss=0.01608   val_loss=0.01631   sm_loss=0.01623   sm_val_loss=0.01640   time=1.24s\n",
      "Epoch 9   loss=0.01604   val_loss=0.01624   sm_loss=0.01619   sm_val_loss=0.01634   time=1.03s\n",
      "Epoch 12   loss=0.01563   val_loss=0.01615   sm_loss=0.01580   sm_val_loss=0.01624   time=0.95s\n",
      "Epoch 13   loss=0.01539   val_loss=0.01589   sm_loss=0.01557   sm_val_loss=0.01599   time=0.94s\n",
      "Epoch 15   loss=0.01485   val_loss=0.01582   sm_loss=0.01506   sm_val_loss=0.01595   time=0.96s\n",
      "Epoch 16   loss=0.01449   val_loss=0.01572   sm_loss=0.01470   sm_val_loss=0.01586   time=1.04s\n",
      "Epoch 17   loss=0.01401   val_loss=0.01560   sm_loss=0.01423   sm_val_loss=0.01573   time=0.96s\n",
      "Epoch 18   loss=0.01361   val_loss=0.01552   sm_loss=0.01384   sm_val_loss=0.01564   time=0.97s\n",
      "Epoch 19   loss=0.01325   val_loss=0.01550   sm_loss=0.01350   sm_val_loss=0.01563   time=1.18s\n",
      "Fold 7 log loss: 0.015608325546924992\n",
      "Seed 3\n",
      "Fold 1 log loss: 0.01586267774779687\n",
      "Fold 2 log loss: 0.01590654841234074\n",
      "Fold 3 log loss: 0.016216556332763605\n",
      "Fold 4 log loss: 0.01640720456182241\n",
      "Fold 5 log loss: 0.016007923983823977\n",
      "Fold 6 log loss: 0.0160610970744921\n",
      "Fold 7 log loss: 0.015608325546924992\n",
      "Std of log loss: 0.0002380878081520366\n",
      "Total log loss: 0.016009802223022403\n",
      "Fold 1\n",
      "Epoch 1   loss=0.40105   val_loss=0.02082   sm_loss=0.40101   sm_val_loss=0.02080   time=0.94s\n",
      "Epoch 2   loss=0.01867   val_loss=0.01814   sm_loss=0.01863   sm_val_loss=0.01818   time=0.94s\n",
      "Epoch 3   loss=0.01680   val_loss=0.01695   sm_loss=0.01687   sm_val_loss=0.01703   time=0.94s\n",
      "Epoch 4   loss=0.01627   val_loss=0.01677   sm_loss=0.01638   sm_val_loss=0.01681   time=0.94s\n",
      "Epoch 7   loss=0.01617   val_loss=0.01657   sm_loss=0.01632   sm_val_loss=0.01662   time=1.16s\n",
      "Epoch 9   loss=0.01603   val_loss=0.01648   sm_loss=0.01618   sm_val_loss=0.01654   time=0.93s\n",
      "Epoch 10   loss=0.01592   val_loss=0.01636   sm_loss=0.01607   sm_val_loss=0.01641   time=0.93s\n",
      "Epoch 11   loss=0.01575   val_loss=0.01627   sm_loss=0.01591   sm_val_loss=0.01635   time=0.95s\n",
      "Epoch 12   loss=0.01563   val_loss=0.01623   sm_loss=0.01579   sm_val_loss=0.01630   time=0.94s\n",
      "Epoch 13   loss=0.01538   val_loss=0.01615   sm_loss=0.01555   sm_val_loss=0.01623   time=0.97s\n",
      "Epoch 14   loss=0.01512   val_loss=0.01600   sm_loss=0.01531   sm_val_loss=0.01606   time=0.98s\n",
      "Epoch 17   loss=0.01405   val_loss=0.01579   sm_loss=0.01427   sm_val_loss=0.01586   time=0.95s\n",
      "Epoch 18   loss=0.01359   val_loss=0.01574   sm_loss=0.01383   sm_val_loss=0.01578   time=1.20s\n",
      "Fold 1 log loss: 0.01585169080170077\n",
      "Fold 2\n",
      "Epoch 1   loss=0.40128   val_loss=0.02076   sm_loss=0.40125   sm_val_loss=0.02073   time=0.95s\n",
      "Epoch 2   loss=0.01854   val_loss=0.01801   sm_loss=0.01850   sm_val_loss=0.01786   time=1.05s\n",
      "Epoch 3   loss=0.01675   val_loss=0.01632   sm_loss=0.01681   sm_val_loss=0.01640   time=0.95s\n",
      "Epoch 4   loss=0.01611   val_loss=0.01621   sm_loss=0.01626   sm_val_loss=0.01628   time=0.95s\n",
      "Epoch 8   loss=0.01613   val_loss=0.01612   sm_loss=0.01628   sm_val_loss=0.01617   time=1.04s\n",
      "Epoch 12   loss=0.01562   val_loss=0.01594   sm_loss=0.01579   sm_val_loss=0.01603   time=0.97s\n",
      "Epoch 14   loss=0.01510   val_loss=0.01574   sm_loss=0.01530   sm_val_loss=0.01584   time=1.23s\n",
      "Epoch 17   loss=0.01404   val_loss=0.01575   sm_loss=0.01427   sm_val_loss=0.01582   time=1.21s\n",
      "Epoch 18   loss=0.01359   val_loss=0.01566   sm_loss=0.01383   sm_val_loss=0.01574   time=1.19s\n",
      "Fold 2 log loss: 0.015807914684123767\n",
      "Fold 3\n",
      "Epoch 1   loss=0.40050   val_loss=0.02083   sm_loss=0.40045   sm_val_loss=0.02079   time=0.97s\n",
      "Epoch 2   loss=0.01869   val_loss=0.01757   sm_loss=0.01863   sm_val_loss=0.01761   time=0.95s\n",
      "Epoch 4   loss=0.01629   val_loss=0.01680   sm_loss=0.01641   sm_val_loss=0.01687   time=1.17s\n",
      "Epoch 10   loss=0.01587   val_loss=0.01666   sm_loss=0.01603   sm_val_loss=0.01673   time=0.94s\n",
      "Epoch 11   loss=0.01567   val_loss=0.01656   sm_loss=0.01584   sm_val_loss=0.01661   time=1.02s\n",
      "Epoch 13   loss=0.01533   val_loss=0.01640   sm_loss=0.01551   sm_val_loss=0.01645   time=0.92s\n",
      "Epoch 14   loss=0.01505   val_loss=0.01631   sm_loss=0.01524   sm_val_loss=0.01640   time=0.95s\n",
      "Epoch 16   loss=0.01437   val_loss=0.01625   sm_loss=0.01458   sm_val_loss=0.01629   time=0.91s\n",
      "Epoch 17   loss=0.01394   val_loss=0.01607   sm_loss=0.01417   sm_val_loss=0.01613   time=0.93s\n",
      "Fold 3 log loss: 0.01611644901066391\n",
      "Fold 4\n",
      "Epoch 1   loss=0.40104   val_loss=0.02089   sm_loss=0.40100   sm_val_loss=0.02088   time=0.92s\n",
      "Epoch 2   loss=0.01840   val_loss=0.01784   sm_loss=0.01837   sm_val_loss=0.01764   time=0.93s\n",
      "Epoch 4   loss=0.01601   val_loss=0.01720   sm_loss=0.01616   sm_val_loss=0.01717   time=0.92s\n",
      "Epoch 5   loss=0.01603   val_loss=0.01707   sm_loss=0.01618   sm_val_loss=0.01708   time=0.93s\n",
      "Epoch 6   loss=0.01597   val_loss=0.01686   sm_loss=0.01612   sm_val_loss=0.01687   time=0.92s\n",
      "Epoch 9   loss=0.01581   val_loss=0.01681   sm_loss=0.01597   sm_val_loss=0.01684   time=0.96s\n",
      "Epoch 10   loss=0.01578   val_loss=0.01677   sm_loss=0.01594   sm_val_loss=0.01682   time=0.93s\n",
      "Epoch 11   loss=0.01566   val_loss=0.01653   sm_loss=0.01583   sm_val_loss=0.01658   time=0.95s\n",
      "Epoch 13   loss=0.01522   val_loss=0.01640   sm_loss=0.01540   sm_val_loss=0.01646   time=0.92s\n",
      "Epoch 16   loss=0.01428   val_loss=0.01630   sm_loss=0.01450   sm_val_loss=0.01635   time=0.94s\n",
      "Epoch 17   loss=0.01382   val_loss=0.01628   sm_loss=0.01406   sm_val_loss=0.01634   time=0.93s\n",
      "Fold 4 log loss: 0.016425655888374097\n",
      "Fold 5\n",
      "Epoch 1   loss=0.40188   val_loss=0.02064   sm_loss=0.40185   sm_val_loss=0.02062   time=0.94s\n",
      "Epoch 2   loss=0.01870   val_loss=0.01741   sm_loss=0.01865   sm_val_loss=0.01745   time=0.93s\n",
      "Epoch 3   loss=0.01667   val_loss=0.01713   sm_loss=0.01673   sm_val_loss=0.01716   time=0.94s\n",
      "Epoch 4   loss=0.01619   val_loss=0.01683   sm_loss=0.01632   sm_val_loss=0.01688   time=0.93s\n",
      "Epoch 5   loss=0.01610   val_loss=0.01678   sm_loss=0.01625   sm_val_loss=0.01678   time=0.93s\n",
      "Epoch 7   loss=0.01606   val_loss=0.01650   sm_loss=0.01621   sm_val_loss=0.01652   time=0.93s\n",
      "Epoch 10   loss=0.01582   val_loss=0.01646   sm_loss=0.01598   sm_val_loss=0.01648   time=1.00s\n",
      "Epoch 11   loss=0.01562   val_loss=0.01629   sm_loss=0.01579   sm_val_loss=0.01632   time=1.13s\n",
      "Epoch 14   loss=0.01500   val_loss=0.01605   sm_loss=0.01520   sm_val_loss=0.01611   time=0.97s\n",
      "Epoch 15   loss=0.01469   val_loss=0.01594   sm_loss=0.01490   sm_val_loss=0.01601   time=1.03s\n",
      "Epoch 16   loss=0.01430   val_loss=0.01588   sm_loss=0.01452   sm_val_loss=0.01593   time=1.09s\n",
      "Epoch 17   loss=0.01389   val_loss=0.01583   sm_loss=0.01412   sm_val_loss=0.01588   time=0.99s\n",
      "Epoch 18   loss=0.01344   val_loss=0.01585   sm_loss=0.01368   sm_val_loss=0.01587   time=1.16s\n",
      "Fold 5 log loss: 0.016018163952198863\n",
      "Fold 6\n",
      "Epoch 1   loss=0.39992   val_loss=0.02113   sm_loss=0.39988   sm_val_loss=0.02110   time=0.95s\n",
      "Epoch 2   loss=0.01856   val_loss=0.01743   sm_loss=0.01853   sm_val_loss=0.01747   time=1.06s\n",
      "Epoch 3   loss=0.01669   val_loss=0.01680   sm_loss=0.01676   sm_val_loss=0.01689   time=1.17s\n",
      "Epoch 4   loss=0.01619   val_loss=0.01668   sm_loss=0.01631   sm_val_loss=0.01677   time=0.96s\n",
      "Epoch 5   loss=0.01608   val_loss=0.01658   sm_loss=0.01623   sm_val_loss=0.01669   time=0.96s\n",
      "Epoch 8   loss=0.01599   val_loss=0.01643   sm_loss=0.01614   sm_val_loss=0.01654   time=0.98s\n",
      "Epoch 11   loss=0.01565   val_loss=0.01637   sm_loss=0.01581   sm_val_loss=0.01649   time=0.93s\n",
      "Epoch 12   loss=0.01553   val_loss=0.01621   sm_loss=0.01570   sm_val_loss=0.01633   time=0.93s\n",
      "Epoch 13   loss=0.01530   val_loss=0.01621   sm_loss=0.01547   sm_val_loss=0.01632   time=0.94s\n",
      "Epoch 14   loss=0.01509   val_loss=0.01604   sm_loss=0.01528   sm_val_loss=0.01617   time=0.95s\n",
      "Epoch 16   loss=0.01433   val_loss=0.01595   sm_loss=0.01455   sm_val_loss=0.01609   time=0.93s\n",
      "Epoch 17   loss=0.01387   val_loss=0.01594   sm_loss=0.01410   sm_val_loss=0.01608   time=0.93s\n",
      "Epoch 18   loss=0.01343   val_loss=0.01592   sm_loss=0.01367   sm_val_loss=0.01605   time=1.11s\n",
      "Epoch 19   loss=0.01308   val_loss=0.01589   sm_loss=0.01332   sm_val_loss=0.01602   time=0.99s\n",
      "Epoch 20   loss=0.01286   val_loss=0.01587   sm_loss=0.01311   sm_val_loss=0.01600   time=0.92s\n",
      "Fold 6 log loss: 0.016037515709550577\n",
      "Fold 7\n",
      "Epoch 1   loss=0.40169   val_loss=0.02097   sm_loss=0.40161   sm_val_loss=0.02096   time=0.92s\n",
      "Epoch 2   loss=0.01857   val_loss=0.01783   sm_loss=0.01854   sm_val_loss=0.01781   time=0.94s\n",
      "Epoch 3   loss=0.01670   val_loss=0.01654   sm_loss=0.01675   sm_val_loss=0.01663   time=0.97s\n",
      "Epoch 4   loss=0.01616   val_loss=0.01649   sm_loss=0.01628   sm_val_loss=0.01658   time=0.94s\n",
      "Epoch 7   loss=0.01610   val_loss=0.01650   sm_loss=0.01625   sm_val_loss=0.01658   time=0.94s\n",
      "Epoch 9   loss=0.01599   val_loss=0.01637   sm_loss=0.01614   sm_val_loss=0.01646   time=0.96s\n",
      "Epoch 10   loss=0.01590   val_loss=0.01624   sm_loss=0.01605   sm_val_loss=0.01635   time=0.96s\n",
      "Epoch 12   loss=0.01559   val_loss=0.01618   sm_loss=0.01576   sm_val_loss=0.01629   time=1.01s\n",
      "Epoch 13   loss=0.01541   val_loss=0.01600   sm_loss=0.01559   sm_val_loss=0.01612   time=1.18s\n",
      "Epoch 14   loss=0.01510   val_loss=0.01595   sm_loss=0.01529   sm_val_loss=0.01606   time=0.95s\n",
      "Epoch 15   loss=0.01479   val_loss=0.01589   sm_loss=0.01499   sm_val_loss=0.01601   time=0.94s\n",
      "Epoch 16   loss=0.01442   val_loss=0.01571   sm_loss=0.01464   sm_val_loss=0.01583   time=0.93s\n",
      "Epoch 17   loss=0.01404   val_loss=0.01572   sm_loss=0.01427   sm_val_loss=0.01583   time=0.93s\n",
      "Epoch 18   loss=0.01357   val_loss=0.01558   sm_loss=0.01381   sm_val_loss=0.01569   time=1.09s\n",
      "Fold 7 log loss: 0.015675602962379027\n",
      "Seed 4\n",
      "Fold 1 log loss: 0.01585169080170077\n",
      "Fold 2 log loss: 0.015807914684123767\n",
      "Fold 3 log loss: 0.01611644901066391\n",
      "Fold 4 log loss: 0.016425655888374097\n",
      "Fold 5 log loss: 0.016018163952198863\n",
      "Fold 6 log loss: 0.016037515709550577\n",
      "Fold 7 log loss: 0.015675602962379027\n",
      "Std of log loss: 0.00022676768173562624\n",
      "Total log loss: 0.015990360881822836\n",
      "Total log loss in targets: 0.015814200228663096\n"
     ]
    }
   ],
   "source": [
    "seeds = [0,1,2,3,4] \n",
    "target_oof = np.zeros([len(fn_train),fn_targets.shape[1]])\n",
    "target_pred = np.zeros([len(fn_test),fn_targets.shape[1]])\n",
    "\n",
    "for seed_ in seeds:\n",
    "    oof, oof_targets, pytorch_pred = modelling_torch(fn_train, fn_targets, fn_test, seed_, fn_train.shape[1]-1, fn_targets.shape[1], 20)\n",
    "    target_oof += oof / len(seeds)\n",
    "    target_pred += pytorch_pred / len(seeds)\n",
    "\n",
    "print(\"Total log loss in targets: {}\".format(mean_log_loss(oof_targets, target_oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T12:22:27.454208Z",
     "iopub.status.busy": "2020-11-09T12:22:27.453133Z",
     "iopub.status.idle": "2020-11-09T12:22:28.688295Z",
     "shell.execute_reply": "2020-11-09T12:22:28.688909Z"
    },
    "papermill": {
     "duration": 1.530949,
     "end_time": "2020-11-09T12:22:28.689039",
     "exception": false,
     "start_time": "2020-11-09T12:22:27.158090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AUC : 0.6645990992081033\n"
     ]
    }
   ],
   "source": [
    "aucs = []\n",
    "for task_id in range(targets.shape[1]-1):\n",
    "    aucs.append(roc_auc_score(y_true=targets.iloc[:, task_id+1].values,\n",
    "                              y_score=target_oof[:, task_id]))\n",
    "print(f\"Overall AUC : {np.mean(aucs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T12:22:29.155637Z",
     "iopub.status.busy": "2020-11-09T12:22:29.154674Z",
     "iopub.status.idle": "2020-11-09T12:22:34.009240Z",
     "shell.execute_reply": "2020-11-09T12:22:34.009961Z"
    },
    "papermill": {
     "duration": 5.105373,
     "end_time": "2020-11-09T12:22:34.010112",
     "exception": false,
     "start_time": "2020-11-09T12:22:28.904739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF log loss:  0.015730719707971196\n"
     ]
    }
   ],
   "source": [
    "t = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "train_checkscore = t.copy()\n",
    "train_checkscore.loc[:,target_feats] = target_oof\n",
    "#train_checkscore.loc[train_checkscore.index.isin(cons_train_index),target_feats] = target_oof\n",
    "train_checkscore.loc[train_checkscore.index.isin(noncons_train_index),target_feats] = 0\n",
    "t.drop(\"sig_id\", axis=1, inplace=True)\n",
    "print('OOF log loss: ', log_loss(np.ravel(t), np.ravel(np.array(train_checkscore.iloc[:,1:]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T12:22:34.467076Z",
     "iopub.status.busy": "2020-11-09T12:22:34.466171Z",
     "iopub.status.idle": "2020-11-09T12:22:37.093445Z",
     "shell.execute_reply": "2020-11-09T12:22:37.092058Z"
    },
    "papermill": {
     "duration": 2.850393,
     "end_time": "2020-11-09T12:22:37.093604",
     "exception": false,
     "start_time": "2020-11-09T12:22:34.243211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sub.loc[cons_test_index,target_feats] = target_pred\n",
    "sub.loc[:,target_feats] = target_pred\n",
    "sub.loc[noncons_test_index,target_feats] = 0\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.209624,
     "end_time": "2020-11-09T12:22:37.515080",
     "exception": false,
     "start_time": "2020-11-09T12:22:37.305456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 841.098077,
   "end_time": "2020-11-09T12:22:39.090392",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-09T12:08:37.992315",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
