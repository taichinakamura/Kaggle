{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017435,
     "end_time": "2020-10-11T12:20:15.595683",
     "exception": false,
     "start_time": "2020-10-11T12:20:15.578248",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- increase seed to stabilize sum of moa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-11T12:20:15.637161Z",
     "iopub.status.busy": "2020-10-11T12:20:15.636520Z",
     "iopub.status.idle": "2020-10-11T12:20:23.159088Z",
     "shell.execute_reply": "2020-10-11T12:20:23.157719Z"
    },
    "papermill": {
     "duration": 7.546971,
     "end_time": "2020-10-11T12:20:23.159216",
     "exception": false,
     "start_time": "2020-10-11T12:20:15.612245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "sys.path.append('../input/multilabelstraifier/')\n",
    "sys.path.append('../input/lookahead/')\n",
    "from ml_stratifiers import MultilabelStratifiedKFold\n",
    "from lookahead import Lookahead\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T12:20:23.199907Z",
     "iopub.status.busy": "2020-10-11T12:20:23.199211Z",
     "iopub.status.idle": "2020-10-11T12:20:28.951103Z",
     "shell.execute_reply": "2020-10-11T12:20:28.950494Z"
    },
    "papermill": {
     "duration": 5.77516,
     "end_time": "2020-10-11T12:20:28.951226",
     "exception": false,
     "start_time": "2020-10-11T12:20:23.176066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/lish-moa/'\n",
    "train = pd.read_csv(DATA_DIR + 'train_features.csv')\n",
    "targets = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "non_targets = pd.read_csv(DATA_DIR + 'train_targets_nonscored.csv')\n",
    "test = pd.read_csv(DATA_DIR + 'test_features.csv')\n",
    "sub = pd.read_csv(DATA_DIR + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T12:20:28.992975Z",
     "iopub.status.busy": "2020-10-11T12:20:28.992166Z",
     "iopub.status.idle": "2020-10-11T12:20:28.995106Z",
     "shell.execute_reply": "2020-10-11T12:20:28.994625Z"
    },
    "papermill": {
     "duration": 0.026513,
     "end_time": "2020-10-11T12:20:28.995204",
     "exception": false,
     "start_time": "2020-10-11T12:20:28.968691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_feats = [ i for i in targets.columns if i != \"sig_id\"]\n",
    "g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "c_feats = [i for i in train.columns if \"c-\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T12:20:29.036749Z",
     "iopub.status.busy": "2020-10-11T12:20:29.036043Z",
     "iopub.status.idle": "2020-10-11T12:20:29.133457Z",
     "shell.execute_reply": "2020-10-11T12:20:29.132864Z"
    },
    "papermill": {
     "duration": 0.12158,
     "end_time": "2020-10-11T12:20:29.133568",
     "exception": false,
     "start_time": "2020-10-11T12:20:29.011988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "noncons_train_index = train[train.cp_type==\"ctl_vehicle\"].index\n",
    "cons_train_index = train[train.cp_type!=\"ctl_vehicle\"].index\n",
    "noncons_test_index = test[test.cp_type==\"ctl_vehicle\"].index\n",
    "cons_test_index = test[test.cp_type!=\"ctl_vehicle\"].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01672,
     "end_time": "2020-10-11T12:20:29.167340",
     "exception": false,
     "start_time": "2020-10-11T12:20:29.150620",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T12:20:29.215492Z",
     "iopub.status.busy": "2020-10-11T12:20:29.214515Z",
     "iopub.status.idle": "2020-10-11T12:20:29.514031Z",
     "shell.execute_reply": "2020-10-11T12:20:29.513488Z"
    },
    "papermill": {
     "duration": 0.329923,
     "end_time": "2020-10-11T12:20:29.514153",
     "exception": false,
     "start_time": "2020-10-11T12:20:29.184230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train[train.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "targets = targets[targets.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "non_targets = non_targets[non_targets.index.isin(cons_train_index)].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T12:20:29.581490Z",
     "iopub.status.busy": "2020-10-11T12:20:29.580530Z",
     "iopub.status.idle": "2020-10-11T12:20:29.592789Z",
     "shell.execute_reply": "2020-10-11T12:20:29.593246Z"
    },
    "papermill": {
     "duration": 0.06222,
     "end_time": "2020-10-11T12:20:29.593393",
     "exception": false,
     "start_time": "2020-10-11T12:20:29.531173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "non_target_feats = [i for i in non_targets.columns if i != \"sig_id\"]\n",
    "nontarget_dists = pd.DataFrame(np.sum(non_targets[non_target_feats])).reset_index(drop=False)\n",
    "nontarget_dists.columns = [\"target\", \"number\"]\n",
    "nontarget_dists = nontarget_dists.sort_values(\"number\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T12:20:29.633574Z",
     "iopub.status.busy": "2020-10-11T12:20:29.632917Z",
     "iopub.status.idle": "2020-10-11T12:20:29.674581Z",
     "shell.execute_reply": "2020-10-11T12:20:29.673931Z"
    },
    "papermill": {
     "duration": 0.064105,
     "end_time": "2020-10-11T12:20:29.674707",
     "exception": false,
     "start_time": "2020-10-11T12:20:29.610602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first drop 71\n",
      "shape after 1st drop: (21948, 332)\n"
     ]
    }
   ],
   "source": [
    "drop_list1 = list(nontarget_dists[nontarget_dists.number==0][\"target\"].values)\n",
    "print(\"first drop\", len(drop_list1))\n",
    "non_targets.drop(drop_list1, axis=1, inplace=True)\n",
    "print(\"shape after 1st drop:\", non_targets.shape)\n",
    "#drop_list2 = list(nontarget_dists[(nontarget_dists.number>0) & (nontarget_dists.number<=6)][\"target\"].values)[:-1]\n",
    "#print(\"second drop\", len(drop_list2))\n",
    "#non_targets.drop(drop_list2, axis=1, inplace=True)\n",
    "#print(\"shape after 2nd drop:\", non_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T12:20:29.715210Z",
     "iopub.status.busy": "2020-10-11T12:20:29.714365Z",
     "iopub.status.idle": "2020-10-11T12:20:29.717115Z",
     "shell.execute_reply": "2020-10-11T12:20:29.716627Z"
    },
    "papermill": {
     "duration": 0.023861,
     "end_time": "2020-10-11T12:20:29.717213",
     "exception": false,
     "start_time": "2020-10-11T12:20:29.693352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#X = train[g_feats].copy().values\n",
    "#select = VarianceThreshold(threshold=1)\n",
    "#X_new = select.fit_transform(X)\n",
    "#drop_g_feats = list(np.array(g_feats)[select.get_support()==False])\n",
    "#len(drop_g_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022695,
     "end_time": "2020-10-11T12:20:29.766675",
     "exception": false,
     "start_time": "2020-10-11T12:20:29.743980",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T12:20:29.812263Z",
     "iopub.status.busy": "2020-10-11T12:20:29.811498Z",
     "iopub.status.idle": "2020-10-11T12:20:29.814059Z",
     "shell.execute_reply": "2020-10-11T12:20:29.814580Z"
    },
    "papermill": {
     "duration": 0.024242,
     "end_time": "2020-10-11T12:20:29.814692",
     "exception": false,
     "start_time": "2020-10-11T12:20:29.790450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#num = 10\n",
    "#pca_c_cols = [\"pca-c\"+str(i+1) for i in range(num)]\n",
    "#pca = PCA(n_components=num)\n",
    "#tmp_train = pca.fit_transform(train[c_feats])\n",
    "#tmp_test = pca.transform(test[c_feats])\n",
    "#tmp_train = pd.DataFrame(tmp_train, columns=pca_c_cols)\n",
    "#tmp_test = pd.DataFrame(tmp_test, columns=pca_c_cols)\n",
    "\n",
    "#train = pd.concat([train, tmp_train],axis=1)\n",
    "#test = pd.concat([test, tmp_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T12:20:29.858903Z",
     "iopub.status.busy": "2020-10-11T12:20:29.857715Z",
     "iopub.status.idle": "2020-10-11T12:20:29.996914Z",
     "shell.execute_reply": "2020-10-11T12:20:29.997481Z"
    },
    "papermill": {
     "duration": 0.165114,
     "end_time": "2020-10-11T12:20:29.997625",
     "exception": false,
     "start_time": "2020-10-11T12:20:29.832511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 874) (3982, 874)\n"
     ]
    }
   ],
   "source": [
    "def fe(df):\n",
    "    tmp = df.copy()\n",
    "    tmp.loc[:, 'cp_type'] = tmp.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    tmp.loc[:, 'cp_dose'] = tmp.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "        \n",
    "    tmp.drop([\"cp_type\", \"sig_id\"], axis=1, inplace=True)\n",
    "    return tmp\n",
    "\n",
    "f_train = fe(train)\n",
    "f_test = fe(test)\n",
    "\n",
    "print(f_train.shape, f_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018327,
     "end_time": "2020-10-11T12:20:30.034670",
     "exception": false,
     "start_time": "2020-10-11T12:20:30.016343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T12:20:30.432852Z",
     "iopub.status.busy": "2020-10-11T12:20:30.084703Z",
     "iopub.status.idle": "2020-10-11T12:20:30.438138Z",
     "shell.execute_reply": "2020-10-11T12:20:30.438873Z"
    },
    "papermill": {
     "duration": 0.38599,
     "end_time": "2020-10-11T12:20:30.439063",
     "exception": false,
     "start_time": "2020-10-11T12:20:30.053073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "def mean_log_loss(y_true, y_pred):\n",
    "    metrics = []\n",
    "    for i, target in enumerate(target_feats):\n",
    "        metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float), labels=[0,1]))\n",
    "    return np.mean(metrics)\n",
    "\n",
    "def seed_everything(seed=1234): \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "class MoaModel(nn.Module):\n",
    "    def __init__(self, num_columns, last_num):\n",
    "        super(MoaModel, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_columns)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_columns, 2048))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(2048)\n",
    "        self.dropout2 = nn.Dropout(0.6)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(2048,1048))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(1048)\n",
    "        self.dropout3 = nn.Dropout(0.6)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(1048, last_num))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018598,
     "end_time": "2020-10-11T12:20:30.476667",
     "exception": false,
     "start_time": "2020-10-11T12:20:30.458069",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# predict non-targets, targets separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T12:20:30.538365Z",
     "iopub.status.busy": "2020-10-11T12:20:30.522126Z",
     "iopub.status.idle": "2020-10-11T12:20:30.552993Z",
     "shell.execute_reply": "2020-10-11T12:20:30.552506Z"
    },
    "papermill": {
     "duration": 0.057627,
     "end_time": "2020-10-11T12:20:30.553092",
     "exception": false,
     "start_time": "2020-10-11T12:20:30.495465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_epochs = 5\n",
    "n_folds=5\n",
    "\n",
    "def first_learning(tr, target, sample_seed, init_num):\n",
    "    seed_everything(seed=sample_seed) \n",
    "    X_train = tr.copy()\n",
    "    y_train = target.copy()\n",
    "\n",
    "    mskf=MultilabelStratifiedKFold(n_splits = n_folds, shuffle=True, random_state=2)\n",
    "    files = []\n",
    "        \n",
    "    oof = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    oof_targets = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    scores = []\n",
    "    for fold, (train_index, valid_index) in enumerate(mskf.split(X_train, y_train)):\n",
    "        print(\"Fold \"+str(fold+1))\n",
    "        X_train2 = torch.tensor(X_train[train_index,:], dtype=torch.float32)\n",
    "        y_train2 = torch.tensor(y_train[train_index], dtype=torch.float32)\n",
    "\n",
    "        X_valid2 = torch.tensor(X_train[valid_index,:], dtype=torch.float32)\n",
    "        y_valid2 = torch.tensor(y_train[valid_index], dtype=torch.float32)\n",
    "            \n",
    "        clf = MoaModel(init_num)\n",
    "        loss_fn = torch.nn.BCEWithLogitsLoss() \n",
    "        optimizer = optim.Adam(clf.parameters(), lr = 0.001, weight_decay=1e-5) \n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, eps=1e-4, verbose=True)\n",
    "        \n",
    "        train = torch.utils.data.TensorDataset(X_train2, y_train2)\n",
    "        valid = torch.utils.data.TensorDataset(X_valid2, y_valid2)\n",
    "        \n",
    "        clf.to(device)\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True) \n",
    "        valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        best_val_loss = np.inf\n",
    "        stop_counts = 0\n",
    "        for epoch in range(train_epochs):\n",
    "            start_time = time.time()\n",
    "            clf.train()\n",
    "            avg_loss = 0.\n",
    "            for x_batch, y_batch in tqdm(train_loader, disable=True):\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch) \n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                avg_loss += loss.item() / len(train_loader)        \n",
    "            \n",
    "            clf.eval()\n",
    "            avg_val_loss = 0.\n",
    "            for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch).detach()\n",
    "                avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "        \n",
    "            elapsed_time = time.time() - start_time \n",
    "            scheduler.step(avg_val_loss)\n",
    "                    \n",
    "            if avg_val_loss < best_val_loss:\n",
    "                stop_counts = 0\n",
    "                best_val_loss = avg_val_loss\n",
    "                print('Best model: Epoch {} \\t loss={:.6f} \\t val_loss={:.6f} \\t time={:.2f}s'.format(\n",
    "                    epoch + 1, avg_loss, avg_val_loss, elapsed_time))\n",
    "                torch.save(clf.state_dict(), 'parameters'+str(fold+1)+'.pt')\n",
    "            else:\n",
    "                stop_counts += 1\n",
    "         \n",
    "        files.append('parameters'+str(fold+1)+'.pt')\n",
    "        pred_model = MoaModel(init_num)\n",
    "        pred_model.load_state_dict(torch.load('parameters'+str(fold+1)+'.pt'))\n",
    "        pred_model.eval()\n",
    "        \n",
    "        # validation check ----------------\n",
    "        oof_epoch = np.zeros([X_valid2.size(0), y_train.shape[1]])\n",
    "        target_epoch = np.zeros([X_valid2.size(0), y_train.shape[1]])\n",
    "        for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "                y_pred = pred_model(x_batch).sigmoid().detach()\n",
    "                oof_epoch[i * batch_size:(i+1) * batch_size,:] = y_pred.cpu().numpy()\n",
    "                target_epoch[i * batch_size:(i+1) * batch_size,:] = y_batch.cpu().numpy()\n",
    "        print(\"Fold {} log loss: {}\".format(fold+1, mean_log_loss(target_epoch, oof_epoch)))\n",
    "        scores.append(mean_log_loss(target_epoch, oof_epoch))\n",
    "        oof[valid_index,:] = oof_epoch\n",
    "        oof_targets[valid_index,:] = target_epoch\n",
    "        #-----------------------------------\n",
    "        \n",
    "    print(\"Seed {}\".format(seed_))\n",
    "    for i, ele in enumerate(scores):\n",
    "        print(\"Fold {} log loss: {}\".format(i+1, scores[i]))\n",
    "    print(\"Std of log loss: {}\".format(np.std(scores)))\n",
    "    print(\"Total log loss: {}\".format(mean_log_loss(oof_targets, oof)))\n",
    "    \n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T12:20:30.598076Z",
     "iopub.status.busy": "2020-10-11T12:20:30.596851Z",
     "iopub.status.idle": "2020-10-11T12:20:31.202979Z",
     "shell.execute_reply": "2020-10-11T12:20:31.201720Z"
    },
    "papermill": {
     "duration": 0.631333,
     "end_time": "2020-10-11T12:20:31.203117",
     "exception": false,
     "start_time": "2020-10-11T12:20:30.571784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fn_train = f_train.copy().to_numpy()\n",
    "fn_test = f_test.copy().to_numpy()\n",
    "\n",
    "ss = preprocessing.StandardScaler()\n",
    "fn_train= ss.fit_transform(fn_train)\n",
    "fn_test = ss.transform(fn_test)\n",
    "\n",
    "fn_nontargets = non_targets.drop(\"sig_id\", axis=1).copy().to_numpy()\n",
    "fn_targets = targets.drop(\"sig_id\", axis=1).copy().to_numpy()\n",
    "\n",
    "#seeds = [0]\n",
    "#for seed_ in seeds:\n",
    "#    files = first_learning(fn_train, fn_nontargets, seed_, fn_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019054,
     "end_time": "2020-10-11T12:20:31.241540",
     "exception": false,
     "start_time": "2020-10-11T12:20:31.222486",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# train by targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T12:20:31.303430Z",
     "iopub.status.busy": "2020-10-11T12:20:31.293106Z",
     "iopub.status.idle": "2020-10-11T12:20:31.324632Z",
     "shell.execute_reply": "2020-10-11T12:20:31.324133Z"
    },
    "papermill": {
     "duration": 0.063931,
     "end_time": "2020-10-11T12:20:31.324729",
     "exception": false,
     "start_time": "2020-10-11T12:20:31.260798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_epochs = 40\n",
    "n_folds=5\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "\n",
    "def modelling_torch(tr, target, te, sample_seed, init_num, last_num, files):\n",
    "    seed_everything(seed=sample_seed) \n",
    "    X_train = tr.copy()\n",
    "    y_train = target.copy()\n",
    "    X_test = te.copy()\n",
    "    test_len = X_test.shape[0]\n",
    "\n",
    "    mskf=MultilabelStratifiedKFold(n_splits = n_folds, shuffle=True, random_state=2)\n",
    "    models = []\n",
    "    \n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    X_test = torch.utils.data.TensorDataset(X_test) \n",
    "    test_loader = torch.utils.data.DataLoader(X_test, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    oof = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    oof_targets = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    pred_value = np.zeros([test_len, y_train.shape[1]])\n",
    "    scores = []\n",
    "    for fold, (train_index, valid_index) in enumerate(mskf.split(X_train, y_train)):\n",
    "        print(\"Fold \"+str(fold+1))\n",
    "        X_train2 = torch.tensor(X_train[train_index,:], dtype=torch.float32)\n",
    "        y_train2 = torch.tensor(y_train[train_index], dtype=torch.float32)\n",
    "\n",
    "        X_valid2 = torch.tensor(X_train[valid_index,:], dtype=torch.float32)\n",
    "        y_valid2 = torch.tensor(y_train[valid_index], dtype=torch.float32)\n",
    "            \n",
    "        clf = MoaModel(init_num, last_num)\n",
    "        if files != []:\n",
    "            clf.load_state_dict(torch.load(files[fold]))\n",
    "        loss_fn = torch.nn.BCEWithLogitsLoss() \n",
    "        optimizer = optim.Adam(clf.parameters(), lr = 0.001, weight_decay=1e-5) \n",
    "        #lookahead = Lookahead(optimizer, k=10, alpha=0.6) #lookahead\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, eps=1e-4, verbose=True)\n",
    "        \n",
    "        train = torch.utils.data.TensorDataset(X_train2, y_train2)\n",
    "        valid = torch.utils.data.TensorDataset(X_valid2, y_valid2)\n",
    "        \n",
    "        clf.to(device)\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True) \n",
    "        valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        best_val_loss = np.inf\n",
    "        stop_counts = 0\n",
    "        for epoch in range(train_epochs):\n",
    "            start_time = time.time()\n",
    "            clf.train()\n",
    "            avg_loss = 0.\n",
    "            for x_batch, y_batch in tqdm(train_loader, disable=True):\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch) \n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                avg_loss += loss.item() / len(train_loader)        \n",
    "            \n",
    "            clf.eval()\n",
    "            avg_val_loss = 0.\n",
    "            for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch).detach()\n",
    "                avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "        \n",
    "            elapsed_time = time.time() - start_time \n",
    "            scheduler.step(avg_val_loss)\n",
    "                    \n",
    "            if avg_val_loss < best_val_loss:\n",
    "                stop_counts = 0\n",
    "                best_val_loss = avg_val_loss\n",
    "                print('Best model: Epoch {} \\t loss={:.6f} \\t val_loss={:.6f} \\t time={:.2f}s'.format(\n",
    "                    epoch + 1, avg_loss, avg_val_loss, elapsed_time))\n",
    "                torch.save(clf.state_dict(), 'best-model-parameters.pt')\n",
    "            else:\n",
    "                stop_counts += 1\n",
    "        \n",
    "            #if stop_counts >= EARLY_STOPPING_STEPS: \n",
    "            #    break\n",
    "         \n",
    "        pred_model = MoaModel(init_num, last_num)\n",
    "        pred_model.load_state_dict(torch.load('best-model-parameters.pt'))\n",
    "        pred_model.eval()\n",
    "        \n",
    "        # validation check ----------------\n",
    "        oof_epoch = np.zeros([X_valid2.size(0), y_train.shape[1]])\n",
    "        target_epoch = np.zeros([X_valid2.size(0), y_train.shape[1]])\n",
    "        for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "                y_pred = pred_model(x_batch).sigmoid().detach()\n",
    "                oof_epoch[i * batch_size:(i+1) * batch_size,:] = y_pred.cpu().numpy()\n",
    "                target_epoch[i * batch_size:(i+1) * batch_size,:] = y_batch.cpu().numpy()\n",
    "        print(\"Fold {} log loss: {}\".format(fold+1, mean_log_loss(target_epoch, oof_epoch)))\n",
    "        scores.append(mean_log_loss(target_epoch, oof_epoch))\n",
    "        oof[valid_index,:] = oof_epoch\n",
    "        oof_targets[valid_index,:] = target_epoch\n",
    "        #-----------------------------------\n",
    "        \n",
    "        # test predcition --------------\n",
    "        test_preds = np.zeros([test_len, y_train.shape[1]])\n",
    "        for i, (x_batch,) in enumerate(test_loader): \n",
    "            y_pred = pred_model(x_batch).sigmoid().detach()\n",
    "            test_preds[i * batch_size:(i+1) * batch_size, :] = y_pred.cpu().numpy()\n",
    "        pred_value += test_preds / n_folds\n",
    "        # ------------------------------\n",
    "        \n",
    "    print(\"Seed {}\".format(seed_))\n",
    "    for i, ele in enumerate(scores):\n",
    "        print(\"Fold {} log loss: {}\".format(i+1, scores[i]))\n",
    "    print(\"Std of log loss: {}\".format(np.std(scores)))\n",
    "    print(\"Total log loss: {}\".format(mean_log_loss(oof_targets, oof)))\n",
    "    \n",
    "    return oof, oof_targets, pred_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T12:20:31.376100Z",
     "iopub.status.busy": "2020-10-11T12:20:31.374717Z",
     "iopub.status.idle": "2020-10-11T12:44:47.136905Z",
     "shell.execute_reply": "2020-10-11T12:44:47.136406Z"
    },
    "papermill": {
     "duration": 1455.793036,
     "end_time": "2020-10-11T12:44:47.137030",
     "exception": false,
     "start_time": "2020-10-11T12:20:31.343994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.412591 \t val_loss=0.077221 \t time=1.44s\n",
      "Best model: Epoch 2 \t loss=0.048580 \t val_loss=0.028151 \t time=0.74s\n",
      "Best model: Epoch 3 \t loss=0.027003 \t val_loss=0.022851 \t time=0.74s\n",
      "Best model: Epoch 4 \t loss=0.023460 \t val_loss=0.021035 \t time=0.91s\n",
      "Best model: Epoch 5 \t loss=0.021372 \t val_loss=0.019930 \t time=0.77s\n",
      "Best model: Epoch 6 \t loss=0.020710 \t val_loss=0.019312 \t time=0.75s\n",
      "Best model: Epoch 7 \t loss=0.020091 \t val_loss=0.019111 \t time=0.74s\n",
      "Best model: Epoch 8 \t loss=0.019413 \t val_loss=0.018614 \t time=0.75s\n",
      "Best model: Epoch 9 \t loss=0.018994 \t val_loss=0.018114 \t time=0.74s\n",
      "Best model: Epoch 10 \t loss=0.018733 \t val_loss=0.017949 \t time=0.74s\n",
      "Best model: Epoch 11 \t loss=0.018251 \t val_loss=0.017597 \t time=0.75s\n",
      "Best model: Epoch 13 \t loss=0.017651 \t val_loss=0.017239 \t time=0.74s\n",
      "Best model: Epoch 14 \t loss=0.017350 \t val_loss=0.017176 \t time=1.08s\n",
      "Best model: Epoch 15 \t loss=0.017291 \t val_loss=0.017116 \t time=0.76s\n",
      "Best model: Epoch 16 \t loss=0.017107 \t val_loss=0.016993 \t time=0.74s\n",
      "Best model: Epoch 17 \t loss=0.016768 \t val_loss=0.016788 \t time=0.74s\n",
      "Best model: Epoch 18 \t loss=0.016622 \t val_loss=0.016715 \t time=0.95s\n",
      "Best model: Epoch 21 \t loss=0.016251 \t val_loss=0.016576 \t time=0.74s\n",
      "Best model: Epoch 22 \t loss=0.016066 \t val_loss=0.016500 \t time=0.74s\n",
      "Best model: Epoch 24 \t loss=0.015943 \t val_loss=0.016470 \t time=0.74s\n",
      "Best model: Epoch 25 \t loss=0.015734 \t val_loss=0.016424 \t time=0.74s\n",
      "Best model: Epoch 28 \t loss=0.015489 \t val_loss=0.016377 \t time=0.73s\n",
      "Best model: Epoch 31 \t loss=0.015327 \t val_loss=0.016313 \t time=0.75s\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 36 \t loss=0.014506 \t val_loss=0.016155 \t time=0.76s\n",
      "Best model: Epoch 37 \t loss=0.014171 \t val_loss=0.016128 \t time=0.75s\n",
      "Best model: Epoch 38 \t loss=0.014019 \t val_loss=0.016098 \t time=0.74s\n",
      "Best model: Epoch 39 \t loss=0.013838 \t val_loss=0.016042 \t time=0.76s\n",
      "Fold 1 log loss: 0.016144690589180097\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.414173 \t val_loss=0.076114 \t time=0.75s\n",
      "Best model: Epoch 2 \t loss=0.048296 \t val_loss=0.029272 \t time=0.75s\n",
      "Best model: Epoch 3 \t loss=0.027405 \t val_loss=0.022898 \t time=0.96s\n",
      "Best model: Epoch 4 \t loss=0.023185 \t val_loss=0.021045 \t time=0.78s\n",
      "Best model: Epoch 5 \t loss=0.021348 \t val_loss=0.019655 \t time=0.79s\n",
      "Best model: Epoch 6 \t loss=0.020497 \t val_loss=0.019208 \t time=0.79s\n",
      "Best model: Epoch 7 \t loss=0.019868 \t val_loss=0.018997 \t time=0.78s\n",
      "Best model: Epoch 8 \t loss=0.019279 \t val_loss=0.018520 \t time=1.16s\n",
      "Best model: Epoch 9 \t loss=0.018965 \t val_loss=0.017982 \t time=0.99s\n",
      "Best model: Epoch 10 \t loss=0.018675 \t val_loss=0.017759 \t time=0.86s\n",
      "Best model: Epoch 11 \t loss=0.018200 \t val_loss=0.017652 \t time=1.02s\n",
      "Best model: Epoch 12 \t loss=0.017911 \t val_loss=0.017377 \t time=0.76s\n",
      "Best model: Epoch 13 \t loss=0.017592 \t val_loss=0.017221 \t time=0.82s\n",
      "Best model: Epoch 15 \t loss=0.017180 \t val_loss=0.017090 \t time=0.91s\n",
      "Best model: Epoch 16 \t loss=0.017055 \t val_loss=0.016951 \t time=0.81s\n",
      "Best model: Epoch 17 \t loss=0.016813 \t val_loss=0.016760 \t time=0.76s\n",
      "Best model: Epoch 18 \t loss=0.016564 \t val_loss=0.016719 \t time=0.77s\n",
      "Best model: Epoch 19 \t loss=0.016340 \t val_loss=0.016593 \t time=0.77s\n",
      "Best model: Epoch 20 \t loss=0.016182 \t val_loss=0.016538 \t time=0.75s\n",
      "Best model: Epoch 21 \t loss=0.016051 \t val_loss=0.016499 \t time=0.75s\n",
      "Best model: Epoch 22 \t loss=0.016053 \t val_loss=0.016487 \t time=0.78s\n",
      "Best model: Epoch 24 \t loss=0.015813 \t val_loss=0.016389 \t time=0.73s\n",
      "Best model: Epoch 25 \t loss=0.015707 \t val_loss=0.016370 \t time=0.75s\n",
      "Best model: Epoch 26 \t loss=0.015672 \t val_loss=0.016358 \t time=0.77s\n",
      "Best model: Epoch 27 \t loss=0.015543 \t val_loss=0.016294 \t time=0.75s\n",
      "Best model: Epoch 28 \t loss=0.015430 \t val_loss=0.016279 \t time=0.94s\n",
      "Best model: Epoch 29 \t loss=0.015341 \t val_loss=0.016245 \t time=0.75s\n",
      "Best model: Epoch 30 \t loss=0.015306 \t val_loss=0.016228 \t time=0.75s\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 35 \t loss=0.014418 \t val_loss=0.016175 \t time=0.74s\n",
      "Best model: Epoch 36 \t loss=0.014187 \t val_loss=0.016067 \t time=0.74s\n",
      "Best model: Epoch 37 \t loss=0.013917 \t val_loss=0.016034 \t time=0.75s\n",
      "Best model: Epoch 38 \t loss=0.013762 \t val_loss=0.016030 \t time=0.74s\n",
      "Best model: Epoch 39 \t loss=0.013603 \t val_loss=0.015983 \t time=0.75s\n",
      "Fold 2 log loss: 0.016044396281569673\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.413986 \t val_loss=0.076896 \t time=0.74s\n",
      "Best model: Epoch 2 \t loss=0.049192 \t val_loss=0.028994 \t time=0.74s\n",
      "Best model: Epoch 3 \t loss=0.027106 \t val_loss=0.022515 \t time=0.76s\n",
      "Best model: Epoch 4 \t loss=0.023059 \t val_loss=0.020760 \t time=0.74s\n",
      "Best model: Epoch 5 \t loss=0.021690 \t val_loss=0.020538 \t time=0.99s\n",
      "Best model: Epoch 6 \t loss=0.020625 \t val_loss=0.019409 \t time=0.85s\n",
      "Best model: Epoch 7 \t loss=0.019750 \t val_loss=0.018819 \t time=0.75s\n",
      "Best model: Epoch 8 \t loss=0.019329 \t val_loss=0.018315 \t time=0.75s\n",
      "Best model: Epoch 9 \t loss=0.019057 \t val_loss=0.018125 \t time=0.74s\n",
      "Best model: Epoch 10 \t loss=0.018609 \t val_loss=0.017987 \t time=0.75s\n",
      "Best model: Epoch 11 \t loss=0.018311 \t val_loss=0.017812 \t time=0.77s\n",
      "Best model: Epoch 12 \t loss=0.018039 \t val_loss=0.017600 \t time=0.87s\n",
      "Best model: Epoch 13 \t loss=0.017822 \t val_loss=0.017359 \t time=0.82s\n",
      "Best model: Epoch 14 \t loss=0.017500 \t val_loss=0.017197 \t time=0.76s\n",
      "Best model: Epoch 15 \t loss=0.017385 \t val_loss=0.017085 \t time=0.75s\n",
      "Best model: Epoch 16 \t loss=0.017066 \t val_loss=0.016969 \t time=0.79s\n",
      "Best model: Epoch 17 \t loss=0.016860 \t val_loss=0.016758 \t time=0.84s\n",
      "Best model: Epoch 18 \t loss=0.016605 \t val_loss=0.016644 \t time=0.74s\n",
      "Best model: Epoch 19 \t loss=0.016521 \t val_loss=0.016627 \t time=0.74s\n",
      "Best model: Epoch 21 \t loss=0.016267 \t val_loss=0.016498 \t time=0.76s\n",
      "Best model: Epoch 23 \t loss=0.015995 \t val_loss=0.016465 \t time=0.77s\n",
      "Best model: Epoch 24 \t loss=0.015823 \t val_loss=0.016417 \t time=0.76s\n",
      "Best model: Epoch 25 \t loss=0.015703 \t val_loss=0.016356 \t time=0.75s\n",
      "Best model: Epoch 26 \t loss=0.015659 \t val_loss=0.016288 \t time=1.02s\n",
      "Best model: Epoch 30 \t loss=0.015393 \t val_loss=0.016223 \t time=0.78s\n",
      "Best model: Epoch 33 \t loss=0.015215 \t val_loss=0.016222 \t time=0.74s\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 35 \t loss=0.014525 \t val_loss=0.016054 \t time=0.75s\n",
      "Best model: Epoch 36 \t loss=0.014278 \t val_loss=0.015991 \t time=0.75s\n",
      "Best model: Epoch 37 \t loss=0.014126 \t val_loss=0.015968 \t time=0.75s\n",
      "Best model: Epoch 38 \t loss=0.013885 \t val_loss=0.015964 \t time=1.09s\n",
      "Best model: Epoch 39 \t loss=0.013728 \t val_loss=0.015933 \t time=0.97s\n",
      "Fold 3 log loss: 0.015932693904937074\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.414550 \t val_loss=0.077203 \t time=0.78s\n",
      "Best model: Epoch 2 \t loss=0.050157 \t val_loss=0.030820 \t time=0.75s\n",
      "Best model: Epoch 3 \t loss=0.028654 \t val_loss=0.022643 \t time=0.80s\n",
      "Best model: Epoch 4 \t loss=0.022900 \t val_loss=0.020759 \t time=0.76s\n",
      "Best model: Epoch 5 \t loss=0.021488 \t val_loss=0.019617 \t time=0.81s\n",
      "Best model: Epoch 6 \t loss=0.020599 \t val_loss=0.019256 \t time=0.75s\n",
      "Best model: Epoch 7 \t loss=0.020185 \t val_loss=0.018790 \t time=0.75s\n",
      "Best model: Epoch 8 \t loss=0.019538 \t val_loss=0.018186 \t time=0.76s\n",
      "Best model: Epoch 9 \t loss=0.019437 \t val_loss=0.017978 \t time=0.98s\n",
      "Best model: Epoch 10 \t loss=0.018881 \t val_loss=0.017777 \t time=0.75s\n",
      "Best model: Epoch 11 \t loss=0.018440 \t val_loss=0.017634 \t time=0.80s\n",
      "Best model: Epoch 12 \t loss=0.018149 \t val_loss=0.017331 \t time=0.75s\n",
      "Best model: Epoch 13 \t loss=0.017822 \t val_loss=0.017247 \t time=0.75s\n",
      "Best model: Epoch 14 \t loss=0.017593 \t val_loss=0.017178 \t time=0.75s\n",
      "Best model: Epoch 15 \t loss=0.017360 \t val_loss=0.017018 \t time=0.76s\n",
      "Best model: Epoch 16 \t loss=0.017128 \t val_loss=0.016771 \t time=0.75s\n",
      "Best model: Epoch 18 \t loss=0.016888 \t val_loss=0.016649 \t time=0.74s\n",
      "Best model: Epoch 19 \t loss=0.016572 \t val_loss=0.016569 \t time=0.75s\n",
      "Best model: Epoch 20 \t loss=0.016374 \t val_loss=0.016445 \t time=0.75s\n",
      "Best model: Epoch 22 \t loss=0.016243 \t val_loss=0.016368 \t time=0.75s\n",
      "Best model: Epoch 23 \t loss=0.016123 \t val_loss=0.016358 \t time=0.98s\n",
      "Best model: Epoch 25 \t loss=0.015849 \t val_loss=0.016256 \t time=0.75s\n",
      "Best model: Epoch 27 \t loss=0.015719 \t val_loss=0.016254 \t time=0.75s\n",
      "Best model: Epoch 28 \t loss=0.015601 \t val_loss=0.016216 \t time=0.76s\n",
      "Best model: Epoch 29 \t loss=0.015491 \t val_loss=0.016183 \t time=0.75s\n",
      "Best model: Epoch 30 \t loss=0.015505 \t val_loss=0.016177 \t time=0.77s\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 35 \t loss=0.014550 \t val_loss=0.016025 \t time=0.74s\n",
      "Best model: Epoch 36 \t loss=0.014275 \t val_loss=0.015951 \t time=0.75s\n",
      "Best model: Epoch 37 \t loss=0.014051 \t val_loss=0.015898 \t time=0.96s\n",
      "Best model: Epoch 39 \t loss=0.013728 \t val_loss=0.015897 \t time=1.07s\n",
      "Best model: Epoch 40 \t loss=0.013633 \t val_loss=0.015858 \t time=0.75s\n",
      "Fold 4 log loss: 0.01591978898403236\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.412187 \t val_loss=0.088095 \t time=0.75s\n",
      "Best model: Epoch 2 \t loss=0.049344 \t val_loss=0.028300 \t time=0.74s\n",
      "Best model: Epoch 3 \t loss=0.027639 \t val_loss=0.022942 \t time=0.76s\n",
      "Best model: Epoch 4 \t loss=0.023355 \t val_loss=0.020933 \t time=0.86s\n",
      "Best model: Epoch 5 \t loss=0.021415 \t val_loss=0.019995 \t time=0.76s\n",
      "Best model: Epoch 6 \t loss=0.020525 \t val_loss=0.019669 \t time=0.78s\n",
      "Best model: Epoch 7 \t loss=0.019796 \t val_loss=0.018820 \t time=0.98s\n",
      "Best model: Epoch 8 \t loss=0.019289 \t val_loss=0.018472 \t time=0.77s\n",
      "Best model: Epoch 9 \t loss=0.019185 \t val_loss=0.018166 \t time=0.75s\n",
      "Best model: Epoch 11 \t loss=0.018588 \t val_loss=0.017788 \t time=0.74s\n",
      "Best model: Epoch 12 \t loss=0.018107 \t val_loss=0.017631 \t time=0.74s\n",
      "Best model: Epoch 13 \t loss=0.017794 \t val_loss=0.017333 \t time=0.76s\n",
      "Best model: Epoch 14 \t loss=0.017391 \t val_loss=0.017204 \t time=0.75s\n",
      "Best model: Epoch 15 \t loss=0.017268 \t val_loss=0.017087 \t time=0.75s\n",
      "Best model: Epoch 16 \t loss=0.017022 \t val_loss=0.016977 \t time=0.75s\n",
      "Best model: Epoch 17 \t loss=0.016798 \t val_loss=0.016941 \t time=0.75s\n",
      "Best model: Epoch 18 \t loss=0.016580 \t val_loss=0.016778 \t time=0.75s\n",
      "Best model: Epoch 19 \t loss=0.016403 \t val_loss=0.016737 \t time=0.75s\n",
      "Best model: Epoch 21 \t loss=0.016202 \t val_loss=0.016591 \t time=0.95s\n",
      "Best model: Epoch 22 \t loss=0.016031 \t val_loss=0.016581 \t time=0.77s\n",
      "Best model: Epoch 23 \t loss=0.015834 \t val_loss=0.016542 \t time=0.75s\n",
      "Best model: Epoch 24 \t loss=0.015865 \t val_loss=0.016475 \t time=0.75s\n",
      "Best model: Epoch 27 \t loss=0.015609 \t val_loss=0.016414 \t time=0.74s\n",
      "Best model: Epoch 30 \t loss=0.015342 \t val_loss=0.016413 \t time=0.98s\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 32 \t loss=0.014680 \t val_loss=0.016273 \t time=0.77s\n",
      "Best model: Epoch 33 \t loss=0.014344 \t val_loss=0.016219 \t time=0.75s\n",
      "Best model: Epoch 34 \t loss=0.014130 \t val_loss=0.016189 \t time=1.36s\n",
      "Best model: Epoch 35 \t loss=0.014023 \t val_loss=0.016185 \t time=0.81s\n",
      "Best model: Epoch 36 \t loss=0.013851 \t val_loss=0.016143 \t time=0.79s\n",
      "Best model: Epoch 37 \t loss=0.013768 \t val_loss=0.016134 \t time=0.74s\n",
      "Best model: Epoch 40 \t loss=0.013329 \t val_loss=0.016125 \t time=0.74s\n",
      "Fold 5 log loss: 0.016124345038051664\n",
      "Seed 0\n",
      "Fold 1 log loss: 0.016144690589180097\n",
      "Fold 2 log loss: 0.016044396281569673\n",
      "Fold 3 log loss: 0.015932693904937074\n",
      "Fold 4 log loss: 0.01591978898403236\n",
      "Fold 5 log loss: 0.016124345038051664\n",
      "Std of log loss: 9.362313645021518e-05\n",
      "Total log loss: 0.016033178295101806\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.412054 \t val_loss=0.076325 \t time=0.95s\n",
      "Best model: Epoch 2 \t loss=0.048526 \t val_loss=0.028851 \t time=0.75s\n",
      "Best model: Epoch 3 \t loss=0.026873 \t val_loss=0.023145 \t time=0.74s\n",
      "Best model: Epoch 4 \t loss=0.023518 \t val_loss=0.020954 \t time=0.74s\n",
      "Best model: Epoch 5 \t loss=0.021069 \t val_loss=0.019802 \t time=0.77s\n",
      "Best model: Epoch 6 \t loss=0.020366 \t val_loss=0.019167 \t time=0.80s\n",
      "Best model: Epoch 7 \t loss=0.019715 \t val_loss=0.018802 \t time=0.76s\n",
      "Best model: Epoch 8 \t loss=0.019131 \t val_loss=0.018499 \t time=0.76s\n",
      "Best model: Epoch 9 \t loss=0.018863 \t val_loss=0.018232 \t time=0.77s\n",
      "Best model: Epoch 10 \t loss=0.018576 \t val_loss=0.017987 \t time=0.77s\n",
      "Best model: Epoch 11 \t loss=0.018388 \t val_loss=0.017902 \t time=0.76s\n",
      "Best model: Epoch 12 \t loss=0.018011 \t val_loss=0.017349 \t time=0.77s\n",
      "Best model: Epoch 13 \t loss=0.017622 \t val_loss=0.017302 \t time=0.77s\n",
      "Best model: Epoch 14 \t loss=0.017534 \t val_loss=0.017155 \t time=0.97s\n",
      "Best model: Epoch 16 \t loss=0.017059 \t val_loss=0.016986 \t time=0.78s\n",
      "Best model: Epoch 17 \t loss=0.016869 \t val_loss=0.016890 \t time=0.77s\n",
      "Best model: Epoch 18 \t loss=0.016664 \t val_loss=0.016821 \t time=0.78s\n",
      "Best model: Epoch 19 \t loss=0.016417 \t val_loss=0.016683 \t time=0.75s\n",
      "Best model: Epoch 20 \t loss=0.016225 \t val_loss=0.016591 \t time=0.75s\n",
      "Best model: Epoch 22 \t loss=0.015986 \t val_loss=0.016465 \t time=0.73s\n",
      "Best model: Epoch 24 \t loss=0.015784 \t val_loss=0.016374 \t time=0.77s\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 29 \t loss=0.014782 \t val_loss=0.016199 \t time=0.75s\n",
      "Best model: Epoch 30 \t loss=0.014521 \t val_loss=0.016131 \t time=0.82s\n",
      "Best model: Epoch 31 \t loss=0.014358 \t val_loss=0.016063 \t time=0.75s\n",
      "Best model: Epoch 32 \t loss=0.014177 \t val_loss=0.016035 \t time=0.75s\n",
      "Best model: Epoch 34 \t loss=0.013939 \t val_loss=0.016024 \t time=0.75s\n",
      "Best model: Epoch 35 \t loss=0.013725 \t val_loss=0.016020 \t time=0.76s\n",
      "Best model: Epoch 36 \t loss=0.013646 \t val_loss=0.016016 \t time=0.78s\n",
      "Best model: Epoch 40 \t loss=0.013190 \t val_loss=0.015981 \t time=0.75s\n",
      "Fold 1 log loss: 0.016079840868431054\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.414855 \t val_loss=0.075799 \t time=0.74s\n",
      "Best model: Epoch 2 \t loss=0.048749 \t val_loss=0.029421 \t time=0.74s\n",
      "Best model: Epoch 3 \t loss=0.027499 \t val_loss=0.023112 \t time=0.75s\n",
      "Best model: Epoch 4 \t loss=0.023323 \t val_loss=0.020927 \t time=0.76s\n",
      "Best model: Epoch 5 \t loss=0.021469 \t val_loss=0.019786 \t time=0.79s\n",
      "Best model: Epoch 6 \t loss=0.020582 \t val_loss=0.019286 \t time=0.76s\n",
      "Best model: Epoch 7 \t loss=0.020079 \t val_loss=0.018804 \t time=0.76s\n",
      "Best model: Epoch 8 \t loss=0.019293 \t val_loss=0.018348 \t time=1.14s\n",
      "Best model: Epoch 9 \t loss=0.019088 \t val_loss=0.018044 \t time=0.78s\n",
      "Best model: Epoch 10 \t loss=0.018684 \t val_loss=0.018009 \t time=0.80s\n",
      "Best model: Epoch 11 \t loss=0.018275 \t val_loss=0.017549 \t time=1.28s\n",
      "Best model: Epoch 12 \t loss=0.017908 \t val_loss=0.017357 \t time=0.76s\n",
      "Best model: Epoch 13 \t loss=0.017698 \t val_loss=0.017252 \t time=0.76s\n",
      "Best model: Epoch 14 \t loss=0.017397 \t val_loss=0.017156 \t time=0.77s\n",
      "Best model: Epoch 15 \t loss=0.017207 \t val_loss=0.016991 \t time=0.77s\n",
      "Best model: Epoch 16 \t loss=0.016897 \t val_loss=0.016768 \t time=0.78s\n",
      "Best model: Epoch 18 \t loss=0.016568 \t val_loss=0.016672 \t time=0.75s\n",
      "Best model: Epoch 19 \t loss=0.016429 \t val_loss=0.016570 \t time=0.78s\n",
      "Best model: Epoch 20 \t loss=0.016223 \t val_loss=0.016533 \t time=0.76s\n",
      "Best model: Epoch 21 \t loss=0.016095 \t val_loss=0.016416 \t time=0.75s\n",
      "Best model: Epoch 23 \t loss=0.015917 \t val_loss=0.016410 \t time=0.85s\n",
      "Best model: Epoch 24 \t loss=0.015726 \t val_loss=0.016333 \t time=0.97s\n",
      "Best model: Epoch 27 \t loss=0.015412 \t val_loss=0.016291 \t time=0.74s\n",
      "Best model: Epoch 29 \t loss=0.015315 \t val_loss=0.016222 \t time=0.75s\n",
      "Best model: Epoch 32 \t loss=0.015167 \t val_loss=0.016173 \t time=0.74s\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 37 \t loss=0.014376 \t val_loss=0.016120 \t time=0.74s\n",
      "Best model: Epoch 38 \t loss=0.014005 \t val_loss=0.016016 \t time=0.94s\n",
      "Best model: Epoch 40 \t loss=0.013573 \t val_loss=0.016004 \t time=0.75s\n",
      "Fold 2 log loss: 0.016064742658142592\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.415098 \t val_loss=0.080733 \t time=0.74s\n",
      "Best model: Epoch 2 \t loss=0.048767 \t val_loss=0.028509 \t time=0.81s\n",
      "Best model: Epoch 3 \t loss=0.026784 \t val_loss=0.023150 \t time=0.78s\n",
      "Best model: Epoch 4 \t loss=0.023161 \t val_loss=0.021295 \t time=0.75s\n",
      "Best model: Epoch 5 \t loss=0.021450 \t val_loss=0.019731 \t time=0.74s\n",
      "Best model: Epoch 6 \t loss=0.020675 \t val_loss=0.019469 \t time=0.74s\n",
      "Best model: Epoch 7 \t loss=0.020227 \t val_loss=0.019188 \t time=0.74s\n",
      "Best model: Epoch 8 \t loss=0.019444 \t val_loss=0.018675 \t time=0.89s\n",
      "Best model: Epoch 9 \t loss=0.019434 \t val_loss=0.018288 \t time=0.81s\n",
      "Best model: Epoch 10 \t loss=0.018643 \t val_loss=0.018101 \t time=0.74s\n",
      "Best model: Epoch 11 \t loss=0.018215 \t val_loss=0.017674 \t time=0.75s\n",
      "Best model: Epoch 12 \t loss=0.017846 \t val_loss=0.017324 \t time=0.75s\n",
      "Best model: Epoch 15 \t loss=0.017431 \t val_loss=0.017053 \t time=0.74s\n",
      "Best model: Epoch 16 \t loss=0.017095 \t val_loss=0.016751 \t time=0.76s\n",
      "Best model: Epoch 19 \t loss=0.016675 \t val_loss=0.016733 \t time=1.03s\n",
      "Best model: Epoch 21 \t loss=0.016288 \t val_loss=0.016438 \t time=0.74s\n",
      "Best model: Epoch 22 \t loss=0.016149 \t val_loss=0.016371 \t time=0.95s\n",
      "Best model: Epoch 24 \t loss=0.015809 \t val_loss=0.016315 \t time=0.75s\n",
      "Best model: Epoch 25 \t loss=0.015760 \t val_loss=0.016313 \t time=0.74s\n",
      "Best model: Epoch 26 \t loss=0.015703 \t val_loss=0.016287 \t time=0.76s\n",
      "Best model: Epoch 27 \t loss=0.015558 \t val_loss=0.016223 \t time=0.74s\n",
      "Best model: Epoch 29 \t loss=0.015499 \t val_loss=0.016220 \t time=0.75s\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 34 \t loss=0.014648 \t val_loss=0.016064 \t time=0.76s\n",
      "Best model: Epoch 35 \t loss=0.014381 \t val_loss=0.016009 \t time=0.74s\n",
      "Best model: Epoch 36 \t loss=0.014148 \t val_loss=0.015964 \t time=0.98s\n",
      "Best model: Epoch 37 \t loss=0.014036 \t val_loss=0.015958 \t time=0.79s\n",
      "Best model: Epoch 38 \t loss=0.013845 \t val_loss=0.015945 \t time=1.08s\n",
      "Best model: Epoch 39 \t loss=0.013695 \t val_loss=0.015936 \t time=0.91s\n",
      "Best model: Epoch 40 \t loss=0.013596 \t val_loss=0.015928 \t time=0.97s\n",
      "Fold 3 log loss: 0.01592049020117655\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.413201 \t val_loss=0.077351 \t time=0.77s\n",
      "Best model: Epoch 2 \t loss=0.047845 \t val_loss=0.027291 \t time=0.78s\n",
      "Best model: Epoch 3 \t loss=0.027879 \t val_loss=0.022880 \t time=0.79s\n",
      "Best model: Epoch 4 \t loss=0.023083 \t val_loss=0.021099 \t time=0.80s\n",
      "Best model: Epoch 5 \t loss=0.021983 \t val_loss=0.020159 \t time=0.91s\n",
      "Best model: Epoch 6 \t loss=0.020838 \t val_loss=0.019249 \t time=0.83s\n",
      "Best model: Epoch 7 \t loss=0.019902 \t val_loss=0.018613 \t time=0.76s\n",
      "Best model: Epoch 8 \t loss=0.019397 \t val_loss=0.018178 \t time=0.77s\n",
      "Best model: Epoch 9 \t loss=0.018991 \t val_loss=0.017956 \t time=0.77s\n",
      "Best model: Epoch 10 \t loss=0.018744 \t val_loss=0.017936 \t time=0.79s\n",
      "Best model: Epoch 11 \t loss=0.018373 \t val_loss=0.017435 \t time=0.77s\n",
      "Best model: Epoch 12 \t loss=0.017988 \t val_loss=0.017253 \t time=0.75s\n",
      "Best model: Epoch 13 \t loss=0.017706 \t val_loss=0.017092 \t time=0.75s\n",
      "Best model: Epoch 14 \t loss=0.017475 \t val_loss=0.016959 \t time=0.85s\n",
      "Best model: Epoch 15 \t loss=0.017304 \t val_loss=0.016845 \t time=0.94s\n",
      "Best model: Epoch 16 \t loss=0.016985 \t val_loss=0.016721 \t time=0.77s\n",
      "Best model: Epoch 17 \t loss=0.016821 \t val_loss=0.016602 \t time=0.81s\n",
      "Best model: Epoch 18 \t loss=0.016629 \t val_loss=0.016580 \t time=0.85s\n",
      "Best model: Epoch 19 \t loss=0.016474 \t val_loss=0.016482 \t time=0.85s\n",
      "Best model: Epoch 20 \t loss=0.016306 \t val_loss=0.016427 \t time=0.75s\n",
      "Best model: Epoch 21 \t loss=0.016230 \t val_loss=0.016412 \t time=0.77s\n",
      "Best model: Epoch 22 \t loss=0.016012 \t val_loss=0.016284 \t time=0.75s\n",
      "Best model: Epoch 23 \t loss=0.015916 \t val_loss=0.016250 \t time=0.75s\n",
      "Best model: Epoch 26 \t loss=0.015605 \t val_loss=0.016187 \t time=0.74s\n",
      "Best model: Epoch 29 \t loss=0.015414 \t val_loss=0.016160 \t time=0.74s\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 34 \t loss=0.014523 \t val_loss=0.016007 \t time=0.74s\n",
      "Best model: Epoch 35 \t loss=0.014326 \t val_loss=0.015953 \t time=0.75s\n",
      "Best model: Epoch 36 \t loss=0.014128 \t val_loss=0.015927 \t time=0.74s\n",
      "Best model: Epoch 37 \t loss=0.013961 \t val_loss=0.015913 \t time=0.74s\n",
      "Best model: Epoch 38 \t loss=0.013800 \t val_loss=0.015902 \t time=0.75s\n",
      "Best model: Epoch 39 \t loss=0.013707 \t val_loss=0.015887 \t time=0.74s\n",
      "Best model: Epoch 40 \t loss=0.013494 \t val_loss=0.015874 \t time=0.76s\n",
      "Fold 4 log loss: 0.01592111042134359\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.414129 \t val_loss=0.077634 \t time=0.74s\n",
      "Best model: Epoch 2 \t loss=0.048715 \t val_loss=0.028425 \t time=0.75s\n",
      "Best model: Epoch 3 \t loss=0.027408 \t val_loss=0.022374 \t time=0.86s\n",
      "Best model: Epoch 4 \t loss=0.023334 \t val_loss=0.020878 \t time=0.85s\n",
      "Best model: Epoch 5 \t loss=0.021927 \t val_loss=0.020042 \t time=0.79s\n",
      "Best model: Epoch 6 \t loss=0.020496 \t val_loss=0.019306 \t time=0.74s\n",
      "Best model: Epoch 7 \t loss=0.019769 \t val_loss=0.018887 \t time=0.75s\n",
      "Best model: Epoch 8 \t loss=0.019723 \t val_loss=0.018739 \t time=0.75s\n",
      "Best model: Epoch 9 \t loss=0.018921 \t val_loss=0.018396 \t time=0.78s\n",
      "Best model: Epoch 10 \t loss=0.018596 \t val_loss=0.017923 \t time=0.75s\n",
      "Best model: Epoch 11 \t loss=0.018246 \t val_loss=0.017664 \t time=0.96s\n",
      "Best model: Epoch 12 \t loss=0.018002 \t val_loss=0.017398 \t time=1.01s\n",
      "Best model: Epoch 13 \t loss=0.017603 \t val_loss=0.017307 \t time=0.79s\n",
      "Best model: Epoch 15 \t loss=0.017409 \t val_loss=0.017181 \t time=0.75s\n",
      "Best model: Epoch 16 \t loss=0.017084 \t val_loss=0.017008 \t time=0.86s\n",
      "Best model: Epoch 18 \t loss=0.016757 \t val_loss=0.016826 \t time=0.75s\n",
      "Best model: Epoch 19 \t loss=0.016483 \t val_loss=0.016648 \t time=0.76s\n",
      "Best model: Epoch 20 \t loss=0.016282 \t val_loss=0.016632 \t time=0.75s\n",
      "Best model: Epoch 22 \t loss=0.016100 \t val_loss=0.016561 \t time=0.76s\n",
      "Best model: Epoch 23 \t loss=0.015977 \t val_loss=0.016516 \t time=0.75s\n",
      "Best model: Epoch 24 \t loss=0.015867 \t val_loss=0.016485 \t time=0.75s\n",
      "Best model: Epoch 25 \t loss=0.015713 \t val_loss=0.016440 \t time=0.97s\n",
      "Best model: Epoch 28 \t loss=0.015600 \t val_loss=0.016433 \t time=0.75s\n",
      "Best model: Epoch 29 \t loss=0.015441 \t val_loss=0.016363 \t time=0.78s\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 34 \t loss=0.014609 \t val_loss=0.016205 \t time=0.78s\n",
      "Best model: Epoch 35 \t loss=0.014249 \t val_loss=0.016198 \t time=0.76s\n",
      "Best model: Epoch 36 \t loss=0.014074 \t val_loss=0.016103 \t time=0.77s\n",
      "Best model: Epoch 37 \t loss=0.013971 \t val_loss=0.016069 \t time=0.79s\n",
      "Best model: Epoch 38 \t loss=0.013754 \t val_loss=0.016059 \t time=0.74s\n",
      "Fold 5 log loss: 0.016063688369179374\n",
      "Seed 1\n",
      "Fold 1 log loss: 0.016079840868431054\n",
      "Fold 2 log loss: 0.016064742658142592\n",
      "Fold 3 log loss: 0.01592049020117655\n",
      "Fold 4 log loss: 0.01592111042134359\n",
      "Fold 5 log loss: 0.016063688369179374\n",
      "Std of log loss: 7.303465552417108e-05\n",
      "Total log loss: 0.01600996956097101\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.414243 \t val_loss=0.075401 \t time=0.77s\n",
      "Best model: Epoch 2 \t loss=0.049196 \t val_loss=0.028064 \t time=0.74s\n",
      "Best model: Epoch 3 \t loss=0.026940 \t val_loss=0.022525 \t time=1.08s\n",
      "Best model: Epoch 4 \t loss=0.023264 \t val_loss=0.021226 \t time=0.80s\n",
      "Best model: Epoch 5 \t loss=0.021407 \t val_loss=0.019807 \t time=0.75s\n",
      "Best model: Epoch 6 \t loss=0.020540 \t val_loss=0.019256 \t time=0.75s\n",
      "Best model: Epoch 7 \t loss=0.019968 \t val_loss=0.018993 \t time=0.76s\n",
      "Best model: Epoch 8 \t loss=0.019501 \t val_loss=0.018829 \t time=0.77s\n",
      "Best model: Epoch 9 \t loss=0.019202 \t val_loss=0.018372 \t time=0.94s\n",
      "Best model: Epoch 10 \t loss=0.019079 \t val_loss=0.018125 \t time=0.76s\n",
      "Best model: Epoch 11 \t loss=0.018344 \t val_loss=0.017942 \t time=0.77s\n",
      "Best model: Epoch 12 \t loss=0.018138 \t val_loss=0.017556 \t time=0.77s\n",
      "Best model: Epoch 13 \t loss=0.017707 \t val_loss=0.017321 \t time=0.77s\n",
      "Best model: Epoch 14 \t loss=0.017455 \t val_loss=0.017192 \t time=0.78s\n",
      "Best model: Epoch 15 \t loss=0.017177 \t val_loss=0.017051 \t time=0.76s\n",
      "Best model: Epoch 16 \t loss=0.017017 \t val_loss=0.016919 \t time=0.75s\n",
      "Best model: Epoch 18 \t loss=0.016662 \t val_loss=0.016903 \t time=0.75s\n",
      "Best model: Epoch 19 \t loss=0.016553 \t val_loss=0.016804 \t time=0.74s\n",
      "Best model: Epoch 20 \t loss=0.016457 \t val_loss=0.016643 \t time=0.75s\n",
      "Best model: Epoch 21 \t loss=0.016250 \t val_loss=0.016637 \t time=0.77s\n",
      "Best model: Epoch 22 \t loss=0.016172 \t val_loss=0.016621 \t time=0.86s\n",
      "Best model: Epoch 23 \t loss=0.016010 \t val_loss=0.016544 \t time=0.82s\n",
      "Best model: Epoch 25 \t loss=0.015790 \t val_loss=0.016434 \t time=0.74s\n",
      "Best model: Epoch 26 \t loss=0.015725 \t val_loss=0.016409 \t time=0.75s\n",
      "Best model: Epoch 28 \t loss=0.015650 \t val_loss=0.016400 \t time=0.75s\n",
      "Best model: Epoch 29 \t loss=0.015497 \t val_loss=0.016379 \t time=0.75s\n",
      "Best model: Epoch 33 \t loss=0.015218 \t val_loss=0.016377 \t time=0.74s\n",
      "Best model: Epoch 35 \t loss=0.015280 \t val_loss=0.016351 \t time=0.75s\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 40 \t loss=0.014390 \t val_loss=0.016189 \t time=0.76s\n",
      "Fold 1 log loss: 0.016280616069086786\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.412084 \t val_loss=0.076539 \t time=0.90s\n",
      "Best model: Epoch 2 \t loss=0.049085 \t val_loss=0.028798 \t time=0.74s\n",
      "Best model: Epoch 3 \t loss=0.026930 \t val_loss=0.022483 \t time=0.74s\n",
      "Best model: Epoch 4 \t loss=0.023605 \t val_loss=0.021048 \t time=0.75s\n",
      "Best model: Epoch 5 \t loss=0.021499 \t val_loss=0.019946 \t time=0.75s\n",
      "Best model: Epoch 6 \t loss=0.020550 \t val_loss=0.019083 \t time=0.76s\n",
      "Best model: Epoch 7 \t loss=0.019963 \t val_loss=0.018862 \t time=0.94s\n",
      "Best model: Epoch 8 \t loss=0.019379 \t val_loss=0.018356 \t time=0.77s\n",
      "Best model: Epoch 9 \t loss=0.018966 \t val_loss=0.018103 \t time=1.00s\n",
      "Best model: Epoch 10 \t loss=0.018577 \t val_loss=0.017829 \t time=0.84s\n",
      "Best model: Epoch 12 \t loss=0.018119 \t val_loss=0.017426 \t time=0.76s\n",
      "Best model: Epoch 13 \t loss=0.017755 \t val_loss=0.017169 \t time=0.75s\n",
      "Best model: Epoch 15 \t loss=0.017197 \t val_loss=0.016995 \t time=0.75s\n",
      "Best model: Epoch 16 \t loss=0.016993 \t val_loss=0.016966 \t time=0.79s\n",
      "Best model: Epoch 17 \t loss=0.016980 \t val_loss=0.016896 \t time=0.80s\n",
      "Best model: Epoch 18 \t loss=0.016810 \t val_loss=0.016787 \t time=0.77s\n",
      "Best model: Epoch 19 \t loss=0.016601 \t val_loss=0.016749 \t time=0.75s\n",
      "Best model: Epoch 20 \t loss=0.016273 \t val_loss=0.016588 \t time=0.99s\n",
      "Best model: Epoch 21 \t loss=0.016209 \t val_loss=0.016517 \t time=0.81s\n",
      "Best model: Epoch 23 \t loss=0.015865 \t val_loss=0.016396 \t time=0.81s\n",
      "Best model: Epoch 25 \t loss=0.015726 \t val_loss=0.016323 \t time=0.74s\n",
      "Best model: Epoch 29 \t loss=0.015473 \t val_loss=0.016273 \t time=0.74s\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 34 \t loss=0.014607 \t val_loss=0.016130 \t time=0.94s\n",
      "Best model: Epoch 35 \t loss=0.014302 \t val_loss=0.016075 \t time=0.83s\n",
      "Best model: Epoch 36 \t loss=0.014098 \t val_loss=0.016072 \t time=0.77s\n",
      "Best model: Epoch 37 \t loss=0.014008 \t val_loss=0.016029 \t time=0.75s\n",
      "Best model: Epoch 38 \t loss=0.013877 \t val_loss=0.016023 \t time=0.75s\n",
      "Best model: Epoch 40 \t loss=0.013495 \t val_loss=0.016019 \t time=0.78s\n",
      "Fold 2 log loss: 0.0160819916597495\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.411402 \t val_loss=0.077279 \t time=0.76s\n",
      "Best model: Epoch 2 \t loss=0.049547 \t val_loss=0.029069 \t time=0.75s\n",
      "Best model: Epoch 3 \t loss=0.027701 \t val_loss=0.022526 \t time=0.76s\n",
      "Best model: Epoch 4 \t loss=0.022974 \t val_loss=0.020914 \t time=0.95s\n",
      "Best model: Epoch 5 \t loss=0.021929 \t val_loss=0.020299 \t time=0.75s\n",
      "Best model: Epoch 6 \t loss=0.020641 \t val_loss=0.019507 \t time=0.75s\n",
      "Best model: Epoch 7 \t loss=0.020131 \t val_loss=0.019061 \t time=0.75s\n",
      "Best model: Epoch 9 \t loss=0.019336 \t val_loss=0.018609 \t time=0.75s\n",
      "Best model: Epoch 10 \t loss=0.018623 \t val_loss=0.017850 \t time=0.74s\n",
      "Best model: Epoch 12 \t loss=0.018119 \t val_loss=0.017799 \t time=0.74s\n",
      "Best model: Epoch 13 \t loss=0.017806 \t val_loss=0.017264 \t time=0.75s\n",
      "Best model: Epoch 15 \t loss=0.017459 \t val_loss=0.017123 \t time=0.73s\n",
      "Best model: Epoch 16 \t loss=0.017064 \t val_loss=0.016860 \t time=0.75s\n",
      "Best model: Epoch 18 \t loss=0.016741 \t val_loss=0.016715 \t time=0.94s\n",
      "Best model: Epoch 19 \t loss=0.016492 \t val_loss=0.016638 \t time=0.83s\n",
      "Best model: Epoch 20 \t loss=0.016265 \t val_loss=0.016467 \t time=0.75s\n",
      "Best model: Epoch 21 \t loss=0.016243 \t val_loss=0.016437 \t time=0.76s\n",
      "Best model: Epoch 23 \t loss=0.016021 \t val_loss=0.016410 \t time=0.76s\n",
      "Best model: Epoch 24 \t loss=0.015786 \t val_loss=0.016352 \t time=0.80s\n",
      "Best model: Epoch 26 \t loss=0.015692 \t val_loss=0.016319 \t time=0.77s\n",
      "Best model: Epoch 27 \t loss=0.015599 \t val_loss=0.016292 \t time=0.76s\n",
      "Best model: Epoch 29 \t loss=0.015427 \t val_loss=0.016235 \t time=0.76s\n",
      "Best model: Epoch 30 \t loss=0.015397 \t val_loss=0.016205 \t time=0.85s\n",
      "Best model: Epoch 31 \t loss=0.015269 \t val_loss=0.016160 \t time=0.79s\n",
      "Best model: Epoch 33 \t loss=0.015170 \t val_loss=0.016138 \t time=0.77s\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 38 \t loss=0.014412 \t val_loss=0.016074 \t time=0.75s\n",
      "Best model: Epoch 39 \t loss=0.014103 \t val_loss=0.016024 \t time=0.74s\n",
      "Best model: Epoch 40 \t loss=0.013940 \t val_loss=0.015989 \t time=1.17s\n",
      "Fold 3 log loss: 0.01598215567903187\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.414447 \t val_loss=0.083103 \t time=0.75s\n",
      "Best model: Epoch 2 \t loss=0.048190 \t val_loss=0.029241 \t time=0.91s\n",
      "Best model: Epoch 3 \t loss=0.028207 \t val_loss=0.022736 \t time=0.94s\n",
      "Best model: Epoch 4 \t loss=0.023313 \t val_loss=0.020537 \t time=0.76s\n",
      "Best model: Epoch 5 \t loss=0.021788 \t val_loss=0.019921 \t time=0.78s\n",
      "Best model: Epoch 6 \t loss=0.020538 \t val_loss=0.019117 \t time=0.77s\n",
      "Best model: Epoch 7 \t loss=0.020011 \t val_loss=0.018677 \t time=0.78s\n",
      "Best model: Epoch 8 \t loss=0.019755 \t val_loss=0.018538 \t time=0.77s\n",
      "Best model: Epoch 9 \t loss=0.019270 \t val_loss=0.017984 \t time=0.78s\n",
      "Best model: Epoch 10 \t loss=0.018757 \t val_loss=0.017874 \t time=0.75s\n",
      "Best model: Epoch 11 \t loss=0.018413 \t val_loss=0.017491 \t time=0.75s\n",
      "Best model: Epoch 12 \t loss=0.018074 \t val_loss=0.017276 \t time=0.75s\n",
      "Best model: Epoch 13 \t loss=0.017728 \t val_loss=0.017107 \t time=0.75s\n",
      "Best model: Epoch 14 \t loss=0.017529 \t val_loss=0.017003 \t time=0.76s\n",
      "Best model: Epoch 15 \t loss=0.017251 \t val_loss=0.016845 \t time=0.95s\n",
      "Best model: Epoch 16 \t loss=0.017310 \t val_loss=0.016813 \t time=0.75s\n",
      "Best model: Epoch 17 \t loss=0.017063 \t val_loss=0.016771 \t time=0.76s\n",
      "Best model: Epoch 18 \t loss=0.016799 \t val_loss=0.016573 \t time=0.78s\n",
      "Best model: Epoch 19 \t loss=0.016628 \t val_loss=0.016536 \t time=0.75s\n",
      "Best model: Epoch 20 \t loss=0.016486 \t val_loss=0.016442 \t time=0.75s\n",
      "Best model: Epoch 21 \t loss=0.016320 \t val_loss=0.016359 \t time=0.75s\n",
      "Best model: Epoch 22 \t loss=0.016065 \t val_loss=0.016320 \t time=0.76s\n",
      "Best model: Epoch 23 \t loss=0.016071 \t val_loss=0.016278 \t time=0.75s\n",
      "Best model: Epoch 24 \t loss=0.015930 \t val_loss=0.016261 \t time=0.83s\n",
      "Best model: Epoch 26 \t loss=0.015693 \t val_loss=0.016257 \t time=0.74s\n",
      "Best model: Epoch 28 \t loss=0.015580 \t val_loss=0.016195 \t time=0.75s\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 33 \t loss=0.014672 \t val_loss=0.016048 \t time=0.75s\n",
      "Best model: Epoch 34 \t loss=0.014376 \t val_loss=0.015966 \t time=0.75s\n",
      "Best model: Epoch 35 \t loss=0.014214 \t val_loss=0.015932 \t time=0.75s\n",
      "Best model: Epoch 37 \t loss=0.013900 \t val_loss=0.015920 \t time=0.76s\n",
      "Best model: Epoch 40 \t loss=0.013575 \t val_loss=0.015914 \t time=0.76s\n",
      "Fold 4 log loss: 0.015969970162948186\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.413087 \t val_loss=0.073699 \t time=0.76s\n",
      "Best model: Epoch 2 \t loss=0.049084 \t val_loss=0.029309 \t time=0.77s\n",
      "Best model: Epoch 3 \t loss=0.028082 \t val_loss=0.023504 \t time=0.76s\n",
      "Best model: Epoch 4 \t loss=0.023135 \t val_loss=0.020912 \t time=0.76s\n",
      "Best model: Epoch 5 \t loss=0.021648 \t val_loss=0.020058 \t time=0.77s\n",
      "Best model: Epoch 6 \t loss=0.020544 \t val_loss=0.019231 \t time=0.81s\n",
      "Best model: Epoch 7 \t loss=0.019869 \t val_loss=0.018961 \t time=0.80s\n",
      "Best model: Epoch 8 \t loss=0.019517 \t val_loss=0.018423 \t time=0.75s\n",
      "Best model: Epoch 9 \t loss=0.018956 \t val_loss=0.018169 \t time=0.76s\n",
      "Best model: Epoch 10 \t loss=0.018656 \t val_loss=0.017995 \t time=0.75s\n",
      "Best model: Epoch 11 \t loss=0.018387 \t val_loss=0.017671 \t time=0.75s\n",
      "Best model: Epoch 12 \t loss=0.017993 \t val_loss=0.017505 \t time=0.83s\n",
      "Best model: Epoch 13 \t loss=0.017741 \t val_loss=0.017458 \t time=0.87s\n",
      "Best model: Epoch 14 \t loss=0.017536 \t val_loss=0.017309 \t time=0.75s\n",
      "Best model: Epoch 15 \t loss=0.017324 \t val_loss=0.017063 \t time=0.77s\n",
      "Best model: Epoch 16 \t loss=0.017025 \t val_loss=0.017025 \t time=0.75s\n",
      "Best model: Epoch 17 \t loss=0.016810 \t val_loss=0.016959 \t time=0.75s\n",
      "Best model: Epoch 18 \t loss=0.016821 \t val_loss=0.016803 \t time=0.76s\n",
      "Best model: Epoch 19 \t loss=0.016505 \t val_loss=0.016753 \t time=0.83s\n",
      "Best model: Epoch 21 \t loss=0.016231 \t val_loss=0.016673 \t time=0.75s\n",
      "Best model: Epoch 22 \t loss=0.016069 \t val_loss=0.016543 \t time=0.75s\n",
      "Best model: Epoch 23 \t loss=0.015954 \t val_loss=0.016523 \t time=0.75s\n",
      "Best model: Epoch 25 \t loss=0.015810 \t val_loss=0.016492 \t time=0.76s\n",
      "Best model: Epoch 26 \t loss=0.015618 \t val_loss=0.016482 \t time=0.90s\n",
      "Best model: Epoch 27 \t loss=0.015527 \t val_loss=0.016386 \t time=1.17s\n",
      "Best model: Epoch 28 \t loss=0.015535 \t val_loss=0.016386 \t time=0.96s\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 32 \t loss=0.014660 \t val_loss=0.016190 \t time=1.06s\n",
      "Best model: Epoch 34 \t loss=0.014195 \t val_loss=0.016131 \t time=0.78s\n",
      "Best model: Epoch 35 \t loss=0.014032 \t val_loss=0.016129 \t time=0.80s\n",
      "Best model: Epoch 36 \t loss=0.013952 \t val_loss=0.016119 \t time=0.77s\n",
      "Best model: Epoch 38 \t loss=0.013619 \t val_loss=0.016104 \t time=0.82s\n",
      "Fold 5 log loss: 0.016105637577698048\n",
      "Seed 2\n",
      "Fold 1 log loss: 0.016280616069086786\n",
      "Fold 2 log loss: 0.0160819916597495\n",
      "Fold 3 log loss: 0.01598215567903187\n",
      "Fold 4 log loss: 0.015969970162948186\n",
      "Fold 5 log loss: 0.016105637577698048\n",
      "Std of log loss: 0.0001118079949946509\n",
      "Total log loss: 0.01608407334211503\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.413482 \t val_loss=0.085006 \t time=0.74s\n",
      "Best model: Epoch 2 \t loss=0.048716 \t val_loss=0.028552 \t time=0.77s\n",
      "Best model: Epoch 3 \t loss=0.027498 \t val_loss=0.023904 \t time=0.75s\n",
      "Best model: Epoch 4 \t loss=0.023643 \t val_loss=0.022032 \t time=0.74s\n",
      "Best model: Epoch 5 \t loss=0.021593 \t val_loss=0.019921 \t time=0.75s\n",
      "Best model: Epoch 6 \t loss=0.020638 \t val_loss=0.019664 \t time=0.97s\n",
      "Best model: Epoch 7 \t loss=0.019979 \t val_loss=0.019123 \t time=0.74s\n",
      "Best model: Epoch 8 \t loss=0.019318 \t val_loss=0.018529 \t time=0.76s\n",
      "Best model: Epoch 9 \t loss=0.019013 \t val_loss=0.018134 \t time=0.86s\n",
      "Best model: Epoch 11 \t loss=0.018321 \t val_loss=0.017871 \t time=0.74s\n",
      "Best model: Epoch 12 \t loss=0.018269 \t val_loss=0.017847 \t time=0.75s\n",
      "Best model: Epoch 13 \t loss=0.017851 \t val_loss=0.017346 \t time=0.75s\n",
      "Best model: Epoch 14 \t loss=0.017423 \t val_loss=0.017188 \t time=0.75s\n",
      "Best model: Epoch 16 \t loss=0.017074 \t val_loss=0.016996 \t time=0.74s\n",
      "Best model: Epoch 17 \t loss=0.016863 \t val_loss=0.016935 \t time=0.76s\n",
      "Best model: Epoch 18 \t loss=0.016690 \t val_loss=0.016766 \t time=0.81s\n",
      "Best model: Epoch 19 \t loss=0.016395 \t val_loss=0.016740 \t time=0.80s\n",
      "Best model: Epoch 20 \t loss=0.016392 \t val_loss=0.016729 \t time=0.95s\n",
      "Best model: Epoch 21 \t loss=0.016257 \t val_loss=0.016575 \t time=0.75s\n",
      "Best model: Epoch 22 \t loss=0.016079 \t val_loss=0.016537 \t time=0.77s\n",
      "Best model: Epoch 24 \t loss=0.015940 \t val_loss=0.016440 \t time=0.74s\n",
      "Best model: Epoch 26 \t loss=0.015711 \t val_loss=0.016439 \t time=0.75s\n",
      "Best model: Epoch 27 \t loss=0.015655 \t val_loss=0.016355 \t time=0.75s\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 32 \t loss=0.014718 \t val_loss=0.016233 \t time=0.75s\n",
      "Best model: Epoch 33 \t loss=0.014492 \t val_loss=0.016164 \t time=0.95s\n",
      "Best model: Epoch 34 \t loss=0.014242 \t val_loss=0.016162 \t time=0.77s\n",
      "Best model: Epoch 35 \t loss=0.014062 \t val_loss=0.016079 \t time=0.74s\n",
      "Best model: Epoch 38 \t loss=0.013740 \t val_loss=0.016068 \t time=0.75s\n",
      "Fold 1 log loss: 0.01615919115850787\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.410309 \t val_loss=0.088772 \t time=0.75s\n",
      "Best model: Epoch 2 \t loss=0.049774 \t val_loss=0.029268 \t time=0.75s\n",
      "Best model: Epoch 3 \t loss=0.027053 \t val_loss=0.022645 \t time=0.76s\n",
      "Best model: Epoch 4 \t loss=0.023236 \t val_loss=0.021036 \t time=1.04s\n",
      "Best model: Epoch 5 \t loss=0.021846 \t val_loss=0.019918 \t time=0.75s\n",
      "Best model: Epoch 6 \t loss=0.020478 \t val_loss=0.019441 \t time=0.75s\n",
      "Best model: Epoch 7 \t loss=0.020034 \t val_loss=0.019010 \t time=0.76s\n",
      "Best model: Epoch 8 \t loss=0.019641 \t val_loss=0.018800 \t time=0.76s\n",
      "Best model: Epoch 9 \t loss=0.019041 \t val_loss=0.018087 \t time=0.75s\n",
      "Best model: Epoch 10 \t loss=0.018651 \t val_loss=0.017874 \t time=0.74s\n",
      "Best model: Epoch 11 \t loss=0.018348 \t val_loss=0.017594 \t time=1.02s\n",
      "Best model: Epoch 12 \t loss=0.017880 \t val_loss=0.017560 \t time=0.81s\n",
      "Best model: Epoch 13 \t loss=0.017816 \t val_loss=0.017224 \t time=0.75s\n",
      "Best model: Epoch 14 \t loss=0.017406 \t val_loss=0.017038 \t time=0.75s\n",
      "Best model: Epoch 15 \t loss=0.017159 \t val_loss=0.016993 \t time=0.78s\n",
      "Best model: Epoch 16 \t loss=0.017050 \t val_loss=0.016916 \t time=0.75s\n",
      "Best model: Epoch 18 \t loss=0.016693 \t val_loss=0.016737 \t time=1.20s\n",
      "Best model: Epoch 19 \t loss=0.016392 \t val_loss=0.016562 \t time=0.80s\n",
      "Best model: Epoch 21 \t loss=0.016198 \t val_loss=0.016541 \t time=1.07s\n",
      "Best model: Epoch 22 \t loss=0.016053 \t val_loss=0.016421 \t time=0.75s\n",
      "Best model: Epoch 24 \t loss=0.015905 \t val_loss=0.016389 \t time=0.74s\n",
      "Best model: Epoch 25 \t loss=0.015724 \t val_loss=0.016362 \t time=0.76s\n",
      "Best model: Epoch 27 \t loss=0.015611 \t val_loss=0.016351 \t time=0.74s\n",
      "Best model: Epoch 29 \t loss=0.015418 \t val_loss=0.016304 \t time=0.75s\n",
      "Best model: Epoch 30 \t loss=0.015379 \t val_loss=0.016291 \t time=0.89s\n",
      "Best model: Epoch 31 \t loss=0.015286 \t val_loss=0.016288 \t time=0.75s\n",
      "Best model: Epoch 35 \t loss=0.015174 \t val_loss=0.016268 \t time=0.74s\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 40 \t loss=0.014326 \t val_loss=0.016078 \t time=0.74s\n",
      "Fold 2 log loss: 0.016131589753943455\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.416642 \t val_loss=0.077390 \t time=0.96s\n",
      "Best model: Epoch 2 \t loss=0.049910 \t val_loss=0.028385 \t time=0.76s\n",
      "Best model: Epoch 3 \t loss=0.027063 \t val_loss=0.022448 \t time=0.76s\n",
      "Best model: Epoch 4 \t loss=0.023517 \t val_loss=0.021003 \t time=0.76s\n",
      "Best model: Epoch 5 \t loss=0.021520 \t val_loss=0.020122 \t time=0.75s\n",
      "Best model: Epoch 6 \t loss=0.020809 \t val_loss=0.019284 \t time=0.75s\n",
      "Best model: Epoch 7 \t loss=0.019977 \t val_loss=0.018849 \t time=0.75s\n",
      "Best model: Epoch 8 \t loss=0.019361 \t val_loss=0.018720 \t time=0.76s\n",
      "Best model: Epoch 9 \t loss=0.019017 \t val_loss=0.018142 \t time=0.75s\n",
      "Best model: Epoch 10 \t loss=0.018557 \t val_loss=0.017915 \t time=0.75s\n",
      "Best model: Epoch 11 \t loss=0.018590 \t val_loss=0.017653 \t time=0.77s\n",
      "Best model: Epoch 12 \t loss=0.018100 \t val_loss=0.017520 \t time=0.75s\n",
      "Best model: Epoch 13 \t loss=0.017907 \t val_loss=0.017251 \t time=0.75s\n",
      "Best model: Epoch 14 \t loss=0.017499 \t val_loss=0.017095 \t time=0.75s\n",
      "Best model: Epoch 15 \t loss=0.017316 \t val_loss=0.017086 \t time=0.95s\n",
      "Best model: Epoch 16 \t loss=0.017026 \t val_loss=0.016796 \t time=0.75s\n",
      "Best model: Epoch 18 \t loss=0.016643 \t val_loss=0.016680 \t time=0.91s\n",
      "Best model: Epoch 20 \t loss=0.016413 \t val_loss=0.016520 \t time=0.85s\n",
      "Best model: Epoch 21 \t loss=0.016271 \t val_loss=0.016456 \t time=0.75s\n",
      "Best model: Epoch 22 \t loss=0.016094 \t val_loss=0.016416 \t time=0.74s\n",
      "Best model: Epoch 23 \t loss=0.015980 \t val_loss=0.016379 \t time=0.74s\n",
      "Best model: Epoch 25 \t loss=0.015681 \t val_loss=0.016315 \t time=0.74s\n",
      "Best model: Epoch 26 \t loss=0.015640 \t val_loss=0.016247 \t time=0.78s\n",
      "Best model: Epoch 30 \t loss=0.015300 \t val_loss=0.016237 \t time=0.74s\n",
      "Best model: Epoch 31 \t loss=0.015267 \t val_loss=0.016224 \t time=0.74s\n",
      "Best model: Epoch 32 \t loss=0.015209 \t val_loss=0.016183 \t time=0.75s\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 37 \t loss=0.014489 \t val_loss=0.016069 \t time=0.84s\n",
      "Best model: Epoch 38 \t loss=0.014129 \t val_loss=0.015990 \t time=0.75s\n",
      "Best model: Epoch 40 \t loss=0.013782 \t val_loss=0.015978 \t time=0.75s\n",
      "Fold 3 log loss: 0.015970096888850625\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.408462 \t val_loss=0.074284 \t time=0.78s\n",
      "Best model: Epoch 2 \t loss=0.049468 \t val_loss=0.028216 \t time=0.80s\n",
      "Best model: Epoch 3 \t loss=0.027922 \t val_loss=0.022309 \t time=0.93s\n",
      "Best model: Epoch 4 \t loss=0.023475 \t val_loss=0.020758 \t time=0.83s\n",
      "Best model: Epoch 5 \t loss=0.021691 \t val_loss=0.019736 \t time=0.75s\n",
      "Best model: Epoch 6 \t loss=0.020567 \t val_loss=0.019042 \t time=0.78s\n",
      "Best model: Epoch 7 \t loss=0.019984 \t val_loss=0.018598 \t time=0.76s\n",
      "Best model: Epoch 8 \t loss=0.019345 \t val_loss=0.018219 \t time=0.76s\n",
      "Best model: Epoch 9 \t loss=0.019050 \t val_loss=0.017943 \t time=0.82s\n",
      "Best model: Epoch 10 \t loss=0.018741 \t val_loss=0.017613 \t time=0.77s\n",
      "Best model: Epoch 12 \t loss=0.017970 \t val_loss=0.017243 \t time=0.77s\n",
      "Best model: Epoch 13 \t loss=0.017718 \t val_loss=0.017188 \t time=0.75s\n",
      "Best model: Epoch 14 \t loss=0.017529 \t val_loss=0.016956 \t time=1.08s\n",
      "Best model: Epoch 15 \t loss=0.017444 \t val_loss=0.016822 \t time=0.75s\n",
      "Best model: Epoch 16 \t loss=0.017227 \t val_loss=0.016729 \t time=0.75s\n",
      "Best model: Epoch 17 \t loss=0.016915 \t val_loss=0.016672 \t time=0.74s\n",
      "Best model: Epoch 18 \t loss=0.016773 \t val_loss=0.016519 \t time=0.75s\n",
      "Best model: Epoch 21 \t loss=0.016231 \t val_loss=0.016478 \t time=0.75s\n",
      "Best model: Epoch 22 \t loss=0.016146 \t val_loss=0.016421 \t time=0.74s\n",
      "Best model: Epoch 23 \t loss=0.016069 \t val_loss=0.016306 \t time=0.75s\n",
      "Best model: Epoch 24 \t loss=0.015932 \t val_loss=0.016244 \t time=0.75s\n",
      "Best model: Epoch 25 \t loss=0.015780 \t val_loss=0.016208 \t time=0.95s\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 30 \t loss=0.014801 \t val_loss=0.016035 \t time=0.75s\n",
      "Best model: Epoch 31 \t loss=0.014562 \t val_loss=0.015951 \t time=0.88s\n",
      "Best model: Epoch 32 \t loss=0.014330 \t val_loss=0.015949 \t time=0.74s\n",
      "Best model: Epoch 33 \t loss=0.014244 \t val_loss=0.015931 \t time=0.75s\n",
      "Best model: Epoch 34 \t loss=0.014103 \t val_loss=0.015871 \t time=0.74s\n",
      "Fold 4 log loss: 0.01593554139806171\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.412365 \t val_loss=0.078813 \t time=0.75s\n",
      "Best model: Epoch 2 \t loss=0.049562 \t val_loss=0.030582 \t time=0.74s\n",
      "Best model: Epoch 3 \t loss=0.027535 \t val_loss=0.022771 \t time=0.75s\n",
      "Best model: Epoch 4 \t loss=0.023436 \t val_loss=0.020868 \t time=0.76s\n",
      "Best model: Epoch 5 \t loss=0.021557 \t val_loss=0.019981 \t time=0.75s\n",
      "Best model: Epoch 6 \t loss=0.020607 \t val_loss=0.019295 \t time=0.75s\n",
      "Best model: Epoch 7 \t loss=0.020060 \t val_loss=0.019073 \t time=0.77s\n",
      "Best model: Epoch 8 \t loss=0.019507 \t val_loss=0.018563 \t time=0.82s\n",
      "Best model: Epoch 9 \t loss=0.019204 \t val_loss=0.018202 \t time=0.82s\n",
      "Best model: Epoch 10 \t loss=0.018767 \t val_loss=0.017955 \t time=0.85s\n",
      "Best model: Epoch 11 \t loss=0.018517 \t val_loss=0.017727 \t time=0.78s\n",
      "Best model: Epoch 12 \t loss=0.018120 \t val_loss=0.017525 \t time=1.08s\n",
      "Best model: Epoch 13 \t loss=0.017746 \t val_loss=0.017468 \t time=0.82s\n",
      "Best model: Epoch 14 \t loss=0.017485 \t val_loss=0.017203 \t time=0.76s\n",
      "Best model: Epoch 15 \t loss=0.017232 \t val_loss=0.017094 \t time=0.76s\n",
      "Best model: Epoch 16 \t loss=0.017003 \t val_loss=0.017025 \t time=0.76s\n",
      "Best model: Epoch 17 \t loss=0.016785 \t val_loss=0.016926 \t time=0.78s\n",
      "Best model: Epoch 18 \t loss=0.016714 \t val_loss=0.016916 \t time=0.76s\n",
      "Best model: Epoch 19 \t loss=0.016531 \t val_loss=0.016807 \t time=0.76s\n",
      "Best model: Epoch 20 \t loss=0.016316 \t val_loss=0.016705 \t time=0.76s\n",
      "Best model: Epoch 21 \t loss=0.016168 \t val_loss=0.016531 \t time=0.75s\n",
      "Best model: Epoch 22 \t loss=0.016100 \t val_loss=0.016499 \t time=0.78s\n",
      "Best model: Epoch 25 \t loss=0.015851 \t val_loss=0.016459 \t time=0.76s\n",
      "Best model: Epoch 29 \t loss=0.015470 \t val_loss=0.016444 \t time=0.74s\n",
      "Best model: Epoch 31 \t loss=0.015325 \t val_loss=0.016384 \t time=0.74s\n",
      "Best model: Epoch 35 \t loss=0.015085 \t val_loss=0.016368 \t time=0.78s\n",
      "Best model: Epoch 39 \t loss=0.014981 \t val_loss=0.016356 \t time=0.83s\n",
      "Fold 5 log loss: 0.01637002395976194\n",
      "Seed 3\n",
      "Fold 1 log loss: 0.01615919115850787\n",
      "Fold 2 log loss: 0.016131589753943455\n",
      "Fold 3 log loss: 0.015970096888850625\n",
      "Fold 4 log loss: 0.01593554139806171\n",
      "Fold 5 log loss: 0.01637002395976194\n",
      "Std of log loss: 0.0001552114403026376\n",
      "Total log loss: 0.01611327610054892\n",
      "Total log loss in targets: 0.015924724369741437\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.408572 \t val_loss=0.066028 \t time=1.00s\n",
      "Best model: Epoch 2 \t loss=0.036649 \t val_loss=0.016669 \t time=0.75s\n",
      "Best model: Epoch 3 \t loss=0.014277 \t val_loss=0.009975 \t time=0.92s\n",
      "Best model: Epoch 4 \t loss=0.009188 \t val_loss=0.007213 \t time=0.85s\n",
      "Best model: Epoch 5 \t loss=0.007483 \t val_loss=0.006587 \t time=0.75s\n",
      "Best model: Epoch 6 \t loss=0.006642 \t val_loss=0.006208 \t time=0.75s\n",
      "Best model: Epoch 7 \t loss=0.006166 \t val_loss=0.005869 \t time=0.76s\n",
      "Best model: Epoch 8 \t loss=0.005950 \t val_loss=0.005680 \t time=0.77s\n",
      "Best model: Epoch 9 \t loss=0.005778 \t val_loss=0.005536 \t time=0.75s\n",
      "Best model: Epoch 13 \t loss=0.005627 \t val_loss=0.005398 \t time=0.75s\n",
      "Best model: Epoch 16 \t loss=0.005449 \t val_loss=0.005316 \t time=0.74s\n",
      "Best model: Epoch 18 \t loss=0.005404 \t val_loss=0.005250 \t time=0.74s\n",
      "Best model: Epoch 19 \t loss=0.005269 \t val_loss=0.005207 \t time=0.75s\n",
      "Best model: Epoch 21 \t loss=0.005158 \t val_loss=0.005108 \t time=0.74s\n",
      "Best model: Epoch 23 \t loss=0.005009 \t val_loss=0.005059 \t time=0.74s\n",
      "Best model: Epoch 25 \t loss=0.004965 \t val_loss=0.005026 \t time=0.74s\n",
      "Best model: Epoch 26 \t loss=0.004939 \t val_loss=0.005016 \t time=0.76s\n",
      "Best model: Epoch 27 \t loss=0.004905 \t val_loss=0.005013 \t time=0.75s\n",
      "Best model: Epoch 30 \t loss=0.004807 \t val_loss=0.004994 \t time=0.75s\n",
      "Best model: Epoch 31 \t loss=0.004834 \t val_loss=0.004989 \t time=0.76s\n",
      "Best model: Epoch 34 \t loss=0.004842 \t val_loss=0.004988 \t time=0.74s\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 39 \t loss=0.004646 \t val_loss=0.004907 \t time=0.76s\n",
      "Best model: Epoch 40 \t loss=0.004551 \t val_loss=0.004892 \t time=0.75s\n",
      "Fold 1 log loss: 0.004584021661370486\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.411267 \t val_loss=0.066460 \t time=0.81s\n",
      "Best model: Epoch 2 \t loss=0.036862 \t val_loss=0.016818 \t time=1.02s\n",
      "Best model: Epoch 3 \t loss=0.014079 \t val_loss=0.010783 \t time=0.77s\n",
      "Best model: Epoch 4 \t loss=0.009197 \t val_loss=0.007390 \t time=0.74s\n",
      "Best model: Epoch 5 \t loss=0.007404 \t val_loss=0.006697 \t time=0.75s\n",
      "Best model: Epoch 6 \t loss=0.006585 \t val_loss=0.006061 \t time=0.77s\n",
      "Best model: Epoch 7 \t loss=0.006254 \t val_loss=0.005947 \t time=0.76s\n",
      "Best model: Epoch 9 \t loss=0.005951 \t val_loss=0.005639 \t time=0.75s\n",
      "Best model: Epoch 10 \t loss=0.005925 \t val_loss=0.005638 \t time=1.11s\n",
      "Best model: Epoch 12 \t loss=0.005634 \t val_loss=0.005515 \t time=0.97s\n",
      "Best model: Epoch 13 \t loss=0.005519 \t val_loss=0.005479 \t time=0.87s\n",
      "Best model: Epoch 15 \t loss=0.005441 \t val_loss=0.005434 \t time=0.87s\n",
      "Best model: Epoch 16 \t loss=0.005345 \t val_loss=0.005378 \t time=0.87s\n",
      "Best model: Epoch 17 \t loss=0.005309 \t val_loss=0.005340 \t time=0.76s\n",
      "Best model: Epoch 18 \t loss=0.005309 \t val_loss=0.005273 \t time=0.81s\n",
      "Best model: Epoch 20 \t loss=0.005130 \t val_loss=0.005212 \t time=0.75s\n",
      "Best model: Epoch 22 \t loss=0.005074 \t val_loss=0.005205 \t time=0.76s\n",
      "Best model: Epoch 23 \t loss=0.005005 \t val_loss=0.005175 \t time=0.77s\n",
      "Best model: Epoch 24 \t loss=0.005016 \t val_loss=0.005161 \t time=0.76s\n",
      "Best model: Epoch 25 \t loss=0.004986 \t val_loss=0.005136 \t time=0.98s\n",
      "Best model: Epoch 26 \t loss=0.004924 \t val_loss=0.005118 \t time=0.80s\n",
      "Best model: Epoch 27 \t loss=0.004947 \t val_loss=0.005088 \t time=0.80s\n",
      "Best model: Epoch 29 \t loss=0.004840 \t val_loss=0.005085 \t time=0.78s\n",
      "Best model: Epoch 31 \t loss=0.004808 \t val_loss=0.005082 \t time=0.77s\n",
      "Best model: Epoch 33 \t loss=0.004809 \t val_loss=0.005073 \t time=0.74s\n",
      "Best model: Epoch 35 \t loss=0.004797 \t val_loss=0.005071 \t time=0.74s\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 40 \t loss=0.004611 \t val_loss=0.005010 \t time=0.75s\n",
      "Fold 2 log loss: 0.004678826863347746\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.411747 \t val_loss=0.073359 \t time=0.74s\n",
      "Best model: Epoch 2 \t loss=0.038070 \t val_loss=0.019307 \t time=0.75s\n",
      "Best model: Epoch 3 \t loss=0.014028 \t val_loss=0.008955 \t time=0.76s\n",
      "Best model: Epoch 4 \t loss=0.009123 \t val_loss=0.007694 \t time=0.74s\n",
      "Best model: Epoch 5 \t loss=0.007441 \t val_loss=0.006444 \t time=0.75s\n",
      "Best model: Epoch 6 \t loss=0.006680 \t val_loss=0.006128 \t time=0.75s\n",
      "Best model: Epoch 7 \t loss=0.006494 \t val_loss=0.005904 \t time=0.75s\n",
      "Best model: Epoch 8 \t loss=0.006211 \t val_loss=0.005826 \t time=0.88s\n",
      "Best model: Epoch 9 \t loss=0.006021 \t val_loss=0.005686 \t time=0.95s\n",
      "Best model: Epoch 10 \t loss=0.005864 \t val_loss=0.005652 \t time=0.76s\n",
      "Best model: Epoch 11 \t loss=0.005655 \t val_loss=0.005464 \t time=0.77s\n",
      "Best model: Epoch 14 \t loss=0.005724 \t val_loss=0.005388 \t time=0.74s\n",
      "Best model: Epoch 15 \t loss=0.005443 \t val_loss=0.005385 \t time=0.76s\n",
      "Best model: Epoch 16 \t loss=0.005357 \t val_loss=0.005369 \t time=0.74s\n",
      "Best model: Epoch 17 \t loss=0.005347 \t val_loss=0.005276 \t time=0.74s\n",
      "Best model: Epoch 19 \t loss=0.005213 \t val_loss=0.005243 \t time=0.74s\n",
      "Best model: Epoch 20 \t loss=0.005163 \t val_loss=0.005203 \t time=0.79s\n",
      "Best model: Epoch 23 \t loss=0.005060 \t val_loss=0.005140 \t time=0.78s\n",
      "Best model: Epoch 24 \t loss=0.005005 \t val_loss=0.005110 \t time=0.77s\n",
      "Best model: Epoch 25 \t loss=0.004976 \t val_loss=0.005084 \t time=0.77s\n",
      "Best model: Epoch 26 \t loss=0.004935 \t val_loss=0.005071 \t time=0.77s\n",
      "Best model: Epoch 29 \t loss=0.004888 \t val_loss=0.005065 \t time=0.76s\n",
      "Best model: Epoch 30 \t loss=0.004868 \t val_loss=0.005034 \t time=0.78s\n",
      "Best model: Epoch 32 \t loss=0.004832 \t val_loss=0.005026 \t time=0.76s\n",
      "Best model: Epoch 34 \t loss=0.004814 \t val_loss=0.005009 \t time=0.77s\n",
      "Best model: Epoch 37 \t loss=0.004798 \t val_loss=0.005004 \t time=0.76s\n",
      "Fold 3 log loss: 0.004721389854379404\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.408862 \t val_loss=0.061165 \t time=0.74s\n",
      "Best model: Epoch 2 \t loss=0.037493 \t val_loss=0.015900 \t time=0.91s\n",
      "Best model: Epoch 3 \t loss=0.013699 \t val_loss=0.010333 \t time=0.76s\n",
      "Best model: Epoch 4 \t loss=0.008977 \t val_loss=0.007489 \t time=0.77s\n",
      "Best model: Epoch 5 \t loss=0.007812 \t val_loss=0.006917 \t time=1.09s\n",
      "Best model: Epoch 6 \t loss=0.006728 \t val_loss=0.006059 \t time=0.80s\n",
      "Best model: Epoch 7 \t loss=0.006328 \t val_loss=0.005933 \t time=0.84s\n",
      "Best model: Epoch 8 \t loss=0.006117 \t val_loss=0.005664 \t time=0.83s\n",
      "Best model: Epoch 9 \t loss=0.005870 \t val_loss=0.005662 \t time=0.76s\n",
      "Best model: Epoch 12 \t loss=0.005743 \t val_loss=0.005540 \t time=0.75s\n",
      "Best model: Epoch 13 \t loss=0.005533 \t val_loss=0.005422 \t time=0.75s\n",
      "Best model: Epoch 15 \t loss=0.005470 \t val_loss=0.005379 \t time=0.75s\n",
      "Best model: Epoch 16 \t loss=0.005428 \t val_loss=0.005369 \t time=0.76s\n",
      "Best model: Epoch 17 \t loss=0.005447 \t val_loss=0.005336 \t time=0.78s\n",
      "Best model: Epoch 19 \t loss=0.005281 \t val_loss=0.005322 \t time=0.80s\n",
      "Best model: Epoch 20 \t loss=0.005182 \t val_loss=0.005253 \t time=0.75s\n",
      "Best model: Epoch 21 \t loss=0.005145 \t val_loss=0.005230 \t time=0.75s\n",
      "Best model: Epoch 24 \t loss=0.005006 \t val_loss=0.005145 \t time=0.75s\n",
      "Best model: Epoch 27 \t loss=0.004951 \t val_loss=0.005116 \t time=0.78s\n",
      "Best model: Epoch 28 \t loss=0.004942 \t val_loss=0.005093 \t time=0.75s\n",
      "Best model: Epoch 31 \t loss=0.004849 \t val_loss=0.005067 \t time=0.78s\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 36 \t loss=0.004628 \t val_loss=0.005032 \t time=0.76s\n",
      "Best model: Epoch 37 \t loss=0.004523 \t val_loss=0.005008 \t time=0.75s\n",
      "Best model: Epoch 38 \t loss=0.004463 \t val_loss=0.004985 \t time=0.76s\n",
      "Best model: Epoch 39 \t loss=0.004393 \t val_loss=0.004977 \t time=0.89s\n",
      "Best model: Epoch 40 \t loss=0.004338 \t val_loss=0.004965 \t time=0.75s\n",
      "Fold 4 log loss: 0.004635539761769005\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.407591 \t val_loss=0.067954 \t time=0.77s\n",
      "Best model: Epoch 2 \t loss=0.037969 \t val_loss=0.015452 \t time=0.94s\n",
      "Best model: Epoch 3 \t loss=0.013713 \t val_loss=0.009105 \t time=0.75s\n",
      "Best model: Epoch 4 \t loss=0.009382 \t val_loss=0.007125 \t time=0.77s\n",
      "Best model: Epoch 5 \t loss=0.007392 \t val_loss=0.006348 \t time=0.78s\n",
      "Best model: Epoch 6 \t loss=0.006592 \t val_loss=0.005954 \t time=0.74s\n",
      "Best model: Epoch 7 \t loss=0.006143 \t val_loss=0.005783 \t time=0.75s\n",
      "Best model: Epoch 9 \t loss=0.006107 \t val_loss=0.005693 \t time=0.74s\n",
      "Best model: Epoch 11 \t loss=0.005693 \t val_loss=0.005479 \t time=0.79s\n",
      "Best model: Epoch 14 \t loss=0.005518 \t val_loss=0.005426 \t time=0.73s\n",
      "Best model: Epoch 15 \t loss=0.005473 \t val_loss=0.005332 \t time=0.85s\n",
      "Best model: Epoch 18 \t loss=0.005407 \t val_loss=0.005219 \t time=0.74s\n",
      "Best model: Epoch 20 \t loss=0.005219 \t val_loss=0.005183 \t time=0.74s\n",
      "Best model: Epoch 21 \t loss=0.005171 \t val_loss=0.005153 \t time=0.74s\n",
      "Best model: Epoch 22 \t loss=0.005113 \t val_loss=0.005129 \t time=0.75s\n",
      "Best model: Epoch 24 \t loss=0.005021 \t val_loss=0.005075 \t time=0.74s\n",
      "Best model: Epoch 25 \t loss=0.005005 \t val_loss=0.005060 \t time=0.75s\n",
      "Best model: Epoch 26 \t loss=0.004968 \t val_loss=0.005057 \t time=1.06s\n",
      "Best model: Epoch 27 \t loss=0.004938 \t val_loss=0.005033 \t time=0.79s\n",
      "Best model: Epoch 28 \t loss=0.004940 \t val_loss=0.005023 \t time=0.80s\n",
      "Best model: Epoch 29 \t loss=0.004904 \t val_loss=0.005011 \t time=0.90s\n",
      "Best model: Epoch 30 \t loss=0.004899 \t val_loss=0.005006 \t time=1.11s\n",
      "Best model: Epoch 31 \t loss=0.004848 \t val_loss=0.004984 \t time=0.97s\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 36 \t loss=0.004638 \t val_loss=0.004923 \t time=0.93s\n",
      "Best model: Epoch 37 \t loss=0.004516 \t val_loss=0.004892 \t time=0.76s\n",
      "Best model: Epoch 38 \t loss=0.004431 \t val_loss=0.004885 \t time=0.75s\n",
      "Best model: Epoch 39 \t loss=0.004355 \t val_loss=0.004874 \t time=0.76s\n",
      "Best model: Epoch 40 \t loss=0.004328 \t val_loss=0.004857 \t time=0.76s\n",
      "Fold 5 log loss: 0.004565935712085979\n",
      "Seed 0\n",
      "Fold 1 log loss: 0.004584021661370486\n",
      "Fold 2 log loss: 0.004678826863347746\n",
      "Fold 3 log loss: 0.004721389854379404\n",
      "Fold 4 log loss: 0.004635539761769005\n",
      "Fold 5 log loss: 0.004565935712085979\n",
      "Std of log loss: 5.7844622531125794e-05\n",
      "Total log loss: 0.00463714329168659\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.410240 \t val_loss=0.074631 \t time=0.75s\n",
      "Best model: Epoch 2 \t loss=0.037365 \t val_loss=0.017122 \t time=0.75s\n",
      "Best model: Epoch 3 \t loss=0.013988 \t val_loss=0.010081 \t time=0.74s\n",
      "Best model: Epoch 4 \t loss=0.009564 \t val_loss=0.007632 \t time=0.75s\n",
      "Best model: Epoch 5 \t loss=0.007518 \t val_loss=0.006520 \t time=0.75s\n",
      "Best model: Epoch 6 \t loss=0.007194 \t val_loss=0.006075 \t time=0.75s\n",
      "Best model: Epoch 7 \t loss=0.006135 \t val_loss=0.005737 \t time=0.88s\n",
      "Best model: Epoch 8 \t loss=0.005950 \t val_loss=0.005692 \t time=0.81s\n",
      "Best model: Epoch 10 \t loss=0.006127 \t val_loss=0.005583 \t time=0.74s\n",
      "Best model: Epoch 11 \t loss=0.005733 \t val_loss=0.005544 \t time=0.76s\n",
      "Best model: Epoch 12 \t loss=0.005619 \t val_loss=0.005487 \t time=0.76s\n",
      "Best model: Epoch 13 \t loss=0.005608 \t val_loss=0.005410 \t time=0.75s\n",
      "Best model: Epoch 14 \t loss=0.005469 \t val_loss=0.005402 \t time=0.75s\n",
      "Best model: Epoch 16 \t loss=0.005390 \t val_loss=0.005361 \t time=0.75s\n",
      "Best model: Epoch 17 \t loss=0.005324 \t val_loss=0.005302 \t time=0.75s\n",
      "Best model: Epoch 19 \t loss=0.005282 \t val_loss=0.005248 \t time=0.75s\n",
      "Best model: Epoch 20 \t loss=0.005170 \t val_loss=0.005155 \t time=0.77s\n",
      "Best model: Epoch 21 \t loss=0.005121 \t val_loss=0.005126 \t time=0.94s\n",
      "Best model: Epoch 23 \t loss=0.005028 \t val_loss=0.005106 \t time=0.77s\n",
      "Best model: Epoch 24 \t loss=0.004984 \t val_loss=0.005046 \t time=1.01s\n",
      "Best model: Epoch 28 \t loss=0.004918 \t val_loss=0.005040 \t time=0.74s\n",
      "Best model: Epoch 29 \t loss=0.004894 \t val_loss=0.005035 \t time=1.00s\n",
      "Best model: Epoch 31 \t loss=0.004870 \t val_loss=0.005012 \t time=0.80s\n",
      "Best model: Epoch 32 \t loss=0.004857 \t val_loss=0.004999 \t time=0.75s\n",
      "Best model: Epoch 35 \t loss=0.004844 \t val_loss=0.004983 \t time=0.84s\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 40 \t loss=0.004680 \t val_loss=0.004951 \t time=0.75s\n",
      "Fold 1 log loss: 0.004645941348972966\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.407218 \t val_loss=0.068475 \t time=0.76s\n",
      "Best model: Epoch 2 \t loss=0.037979 \t val_loss=0.016140 \t time=0.76s\n",
      "Best model: Epoch 3 \t loss=0.014340 \t val_loss=0.009121 \t time=0.76s\n",
      "Best model: Epoch 4 \t loss=0.009199 \t val_loss=0.007683 \t time=0.94s\n",
      "Best model: Epoch 5 \t loss=0.007449 \t val_loss=0.006462 \t time=0.77s\n",
      "Best model: Epoch 6 \t loss=0.006489 \t val_loss=0.006036 \t time=0.75s\n",
      "Best model: Epoch 7 \t loss=0.006265 \t val_loss=0.005940 \t time=1.11s\n",
      "Best model: Epoch 8 \t loss=0.005995 \t val_loss=0.005706 \t time=0.96s\n",
      "Best model: Epoch 10 \t loss=0.005815 \t val_loss=0.005689 \t time=0.77s\n",
      "Best model: Epoch 11 \t loss=0.005727 \t val_loss=0.005573 \t time=0.75s\n",
      "Best model: Epoch 12 \t loss=0.005735 \t val_loss=0.005532 \t time=0.75s\n",
      "Best model: Epoch 13 \t loss=0.005531 \t val_loss=0.005460 \t time=0.79s\n",
      "Best model: Epoch 14 \t loss=0.005479 \t val_loss=0.005439 \t time=0.80s\n",
      "Best model: Epoch 16 \t loss=0.005399 \t val_loss=0.005365 \t time=0.83s\n",
      "Best model: Epoch 18 \t loss=0.005277 \t val_loss=0.005320 \t time=0.74s\n",
      "Best model: Epoch 19 \t loss=0.005281 \t val_loss=0.005294 \t time=0.99s\n",
      "Best model: Epoch 20 \t loss=0.005240 \t val_loss=0.005259 \t time=0.86s\n",
      "Best model: Epoch 21 \t loss=0.005146 \t val_loss=0.005244 \t time=0.90s\n",
      "Best model: Epoch 23 \t loss=0.005165 \t val_loss=0.005199 \t time=0.75s\n",
      "Best model: Epoch 24 \t loss=0.005073 \t val_loss=0.005183 \t time=0.75s\n",
      "Best model: Epoch 25 \t loss=0.004992 \t val_loss=0.005148 \t time=0.74s\n",
      "Best model: Epoch 27 \t loss=0.004916 \t val_loss=0.005111 \t time=0.76s\n",
      "Best model: Epoch 28 \t loss=0.004868 \t val_loss=0.005103 \t time=0.76s\n",
      "Best model: Epoch 29 \t loss=0.004896 \t val_loss=0.005083 \t time=0.78s\n",
      "Best model: Epoch 31 \t loss=0.004833 \t val_loss=0.005081 \t time=0.74s\n",
      "Best model: Epoch 33 \t loss=0.004804 \t val_loss=0.005080 \t time=0.75s\n",
      "Best model: Epoch 34 \t loss=0.004819 \t val_loss=0.005047 \t time=0.75s\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 39 \t loss=0.004620 \t val_loss=0.005017 \t time=0.75s\n",
      "Best model: Epoch 40 \t loss=0.004498 \t val_loss=0.004987 \t time=0.75s\n",
      "Fold 2 log loss: 0.0046473394293845924\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.410134 \t val_loss=0.068467 \t time=0.88s\n",
      "Best model: Epoch 2 \t loss=0.037470 \t val_loss=0.016618 \t time=0.74s\n",
      "Best model: Epoch 3 \t loss=0.014102 \t val_loss=0.009521 \t time=0.75s\n",
      "Best model: Epoch 4 \t loss=0.009373 \t val_loss=0.008176 \t time=0.74s\n",
      "Best model: Epoch 5 \t loss=0.007759 \t val_loss=0.006610 \t time=0.75s\n",
      "Best model: Epoch 6 \t loss=0.006604 \t val_loss=0.006176 \t time=0.75s\n",
      "Best model: Epoch 7 \t loss=0.006364 \t val_loss=0.005767 \t time=0.74s\n",
      "Best model: Epoch 9 \t loss=0.006072 \t val_loss=0.005663 \t time=0.75s\n",
      "Best model: Epoch 10 \t loss=0.005986 \t val_loss=0.005613 \t time=0.75s\n",
      "Best model: Epoch 11 \t loss=0.005711 \t val_loss=0.005541 \t time=0.75s\n",
      "Best model: Epoch 13 \t loss=0.005634 \t val_loss=0.005531 \t time=0.76s\n",
      "Best model: Epoch 14 \t loss=0.005469 \t val_loss=0.005350 \t time=0.93s\n",
      "Best model: Epoch 15 \t loss=0.005405 \t val_loss=0.005307 \t time=0.84s\n",
      "Best model: Epoch 17 \t loss=0.005340 \t val_loss=0.005297 \t time=0.78s\n",
      "Best model: Epoch 18 \t loss=0.005242 \t val_loss=0.005248 \t time=0.76s\n",
      "Best model: Epoch 19 \t loss=0.005186 \t val_loss=0.005233 \t time=0.75s\n",
      "Best model: Epoch 20 \t loss=0.005136 \t val_loss=0.005189 \t time=0.79s\n",
      "Best model: Epoch 21 \t loss=0.005103 \t val_loss=0.005188 \t time=0.75s\n",
      "Best model: Epoch 22 \t loss=0.005083 \t val_loss=0.005126 \t time=0.75s\n",
      "Best model: Epoch 24 \t loss=0.005017 \t val_loss=0.005100 \t time=0.75s\n",
      "Best model: Epoch 25 \t loss=0.004937 \t val_loss=0.005070 \t time=0.75s\n",
      "Best model: Epoch 27 \t loss=0.004921 \t val_loss=0.005068 \t time=0.93s\n",
      "Best model: Epoch 28 \t loss=0.004949 \t val_loss=0.005048 \t time=0.74s\n",
      "Best model: Epoch 29 \t loss=0.004882 \t val_loss=0.005047 \t time=0.74s\n",
      "Best model: Epoch 30 \t loss=0.004855 \t val_loss=0.005019 \t time=0.74s\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 35 \t loss=0.004591 \t val_loss=0.004963 \t time=0.90s\n",
      "Best model: Epoch 36 \t loss=0.004489 \t val_loss=0.004937 \t time=0.90s\n",
      "Best model: Epoch 37 \t loss=0.004409 \t val_loss=0.004927 \t time=0.77s\n",
      "Best model: Epoch 38 \t loss=0.004331 \t val_loss=0.004912 \t time=0.75s\n",
      "Best model: Epoch 39 \t loss=0.004297 \t val_loss=0.004905 \t time=0.75s\n",
      "Best model: Epoch 40 \t loss=0.004262 \t val_loss=0.004890 \t time=1.37s\n",
      "Fold 3 log loss: 0.004604927845116698\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.408760 \t val_loss=0.067429 \t time=0.81s\n",
      "Best model: Epoch 2 \t loss=0.038467 \t val_loss=0.015794 \t time=0.82s\n",
      "Best model: Epoch 3 \t loss=0.013610 \t val_loss=0.009636 \t time=0.80s\n",
      "Best model: Epoch 4 \t loss=0.009155 \t val_loss=0.007408 \t time=0.77s\n",
      "Best model: Epoch 5 \t loss=0.007525 \t val_loss=0.006654 \t time=0.76s\n",
      "Best model: Epoch 7 \t loss=0.006375 \t val_loss=0.005857 \t time=0.75s\n",
      "Best model: Epoch 8 \t loss=0.005977 \t val_loss=0.005712 \t time=0.83s\n",
      "Best model: Epoch 9 \t loss=0.005919 \t val_loss=0.005666 \t time=0.92s\n",
      "Best model: Epoch 10 \t loss=0.005792 \t val_loss=0.005575 \t time=0.92s\n",
      "Best model: Epoch 12 \t loss=0.005640 \t val_loss=0.005514 \t time=1.05s\n",
      "Best model: Epoch 14 \t loss=0.005596 \t val_loss=0.005431 \t time=0.76s\n",
      "Best model: Epoch 15 \t loss=0.005464 \t val_loss=0.005403 \t time=0.75s\n",
      "Best model: Epoch 16 \t loss=0.005342 \t val_loss=0.005366 \t time=0.75s\n",
      "Best model: Epoch 17 \t loss=0.005290 \t val_loss=0.005346 \t time=0.75s\n",
      "Best model: Epoch 18 \t loss=0.005250 \t val_loss=0.005240 \t time=0.75s\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 23 \t loss=0.004966 \t val_loss=0.005169 \t time=0.75s\n",
      "Best model: Epoch 24 \t loss=0.004842 \t val_loss=0.005133 \t time=0.75s\n",
      "Best model: Epoch 25 \t loss=0.004770 \t val_loss=0.005096 \t time=0.75s\n",
      "Best model: Epoch 27 \t loss=0.004686 \t val_loss=0.005080 \t time=0.75s\n",
      "Best model: Epoch 28 \t loss=0.004656 \t val_loss=0.005061 \t time=0.75s\n",
      "Best model: Epoch 29 \t loss=0.004640 \t val_loss=0.005057 \t time=0.76s\n",
      "Best model: Epoch 30 \t loss=0.004560 \t val_loss=0.005050 \t time=0.74s\n",
      "Best model: Epoch 31 \t loss=0.004542 \t val_loss=0.005039 \t time=0.75s\n",
      "Best model: Epoch 32 \t loss=0.004509 \t val_loss=0.005032 \t time=0.75s\n",
      "Best model: Epoch 34 \t loss=0.004434 \t val_loss=0.005019 \t time=0.75s\n",
      "Best model: Epoch 35 \t loss=0.004396 \t val_loss=0.005012 \t time=0.94s\n",
      "Best model: Epoch 36 \t loss=0.004323 \t val_loss=0.005010 \t time=0.76s\n",
      "Best model: Epoch 37 \t loss=0.004278 \t val_loss=0.005009 \t time=0.77s\n",
      "Best model: Epoch 38 \t loss=0.004268 \t val_loss=0.004991 \t time=0.75s\n",
      "Best model: Epoch 40 \t loss=0.004202 \t val_loss=0.004985 \t time=0.74s\n",
      "Fold 4 log loss: 0.00464935920817104\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.409975 \t val_loss=0.069771 \t time=0.79s\n",
      "Best model: Epoch 2 \t loss=0.038194 \t val_loss=0.016563 \t time=0.74s\n",
      "Best model: Epoch 3 \t loss=0.013839 \t val_loss=0.009287 \t time=0.75s\n",
      "Best model: Epoch 4 \t loss=0.008988 \t val_loss=0.007421 \t time=0.75s\n",
      "Best model: Epoch 5 \t loss=0.007356 \t val_loss=0.006568 \t time=0.93s\n",
      "Best model: Epoch 6 \t loss=0.006892 \t val_loss=0.006004 \t time=0.94s\n",
      "Best model: Epoch 7 \t loss=0.006317 \t val_loss=0.005855 \t time=0.77s\n",
      "Best model: Epoch 8 \t loss=0.006086 \t val_loss=0.005772 \t time=0.76s\n",
      "Best model: Epoch 9 \t loss=0.006306 \t val_loss=0.005615 \t time=1.08s\n",
      "Best model: Epoch 10 \t loss=0.005851 \t val_loss=0.005596 \t time=0.77s\n",
      "Best model: Epoch 11 \t loss=0.005681 \t val_loss=0.005449 \t time=0.76s\n",
      "Best model: Epoch 12 \t loss=0.005682 \t val_loss=0.005418 \t time=0.75s\n",
      "Best model: Epoch 14 \t loss=0.005470 \t val_loss=0.005339 \t time=0.74s\n",
      "Best model: Epoch 15 \t loss=0.005378 \t val_loss=0.005274 \t time=0.75s\n",
      "Best model: Epoch 17 \t loss=0.005277 \t val_loss=0.005193 \t time=0.74s\n",
      "Best model: Epoch 20 \t loss=0.005189 \t val_loss=0.005141 \t time=0.76s\n",
      "Best model: Epoch 22 \t loss=0.005177 \t val_loss=0.005122 \t time=0.77s\n",
      "Best model: Epoch 23 \t loss=0.005094 \t val_loss=0.005065 \t time=0.77s\n",
      "Best model: Epoch 24 \t loss=0.005008 \t val_loss=0.005025 \t time=0.75s\n",
      "Best model: Epoch 28 \t loss=0.004864 \t val_loss=0.005014 \t time=0.78s\n",
      "Best model: Epoch 29 \t loss=0.004876 \t val_loss=0.004988 \t time=0.75s\n",
      "Best model: Epoch 31 \t loss=0.004847 \t val_loss=0.004980 \t time=0.76s\n",
      "Best model: Epoch 32 \t loss=0.004823 \t val_loss=0.004978 \t time=1.03s\n",
      "Best model: Epoch 35 \t loss=0.004792 \t val_loss=0.004978 \t time=0.77s\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 37 \t loss=0.004586 \t val_loss=0.004922 \t time=0.78s\n",
      "Best model: Epoch 38 \t loss=0.004490 \t val_loss=0.004880 \t time=0.78s\n",
      "Best model: Epoch 39 \t loss=0.004431 \t val_loss=0.004863 \t time=0.74s\n",
      "Best model: Epoch 40 \t loss=0.004344 \t val_loss=0.004855 \t time=0.75s\n",
      "Fold 5 log loss: 0.004583211613077572\n",
      "Seed 1\n",
      "Fold 1 log loss: 0.004645941348972966\n",
      "Fold 2 log loss: 0.0046473394293845924\n",
      "Fold 3 log loss: 0.004604927845116698\n",
      "Fold 4 log loss: 0.00464935920817104\n",
      "Fold 5 log loss: 0.004583211613077572\n",
      "Std of log loss: 2.710513424328941e-05\n",
      "Total log loss: 0.004626154022305223\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.410531 \t val_loss=0.072441 \t time=0.93s\n",
      "Best model: Epoch 2 \t loss=0.037545 \t val_loss=0.018593 \t time=0.76s\n",
      "Best model: Epoch 3 \t loss=0.014359 \t val_loss=0.010631 \t time=0.74s\n",
      "Best model: Epoch 4 \t loss=0.009510 \t val_loss=0.007788 \t time=0.75s\n",
      "Best model: Epoch 5 \t loss=0.007294 \t val_loss=0.006424 \t time=0.75s\n",
      "Best model: Epoch 6 \t loss=0.006961 \t val_loss=0.006059 \t time=0.75s\n",
      "Best model: Epoch 7 \t loss=0.006420 \t val_loss=0.005830 \t time=0.76s\n",
      "Best model: Epoch 9 \t loss=0.006182 \t val_loss=0.005585 \t time=0.77s\n",
      "Best model: Epoch 10 \t loss=0.005824 \t val_loss=0.005547 \t time=0.76s\n",
      "Best model: Epoch 11 \t loss=0.005822 \t val_loss=0.005541 \t time=0.98s\n",
      "Best model: Epoch 12 \t loss=0.005900 \t val_loss=0.005492 \t time=0.75s\n",
      "Best model: Epoch 13 \t loss=0.005629 \t val_loss=0.005403 \t time=0.76s\n",
      "Best model: Epoch 14 \t loss=0.005528 \t val_loss=0.005374 \t time=0.76s\n",
      "Best model: Epoch 16 \t loss=0.005401 \t val_loss=0.005309 \t time=0.76s\n",
      "Best model: Epoch 18 \t loss=0.005323 \t val_loss=0.005261 \t time=0.75s\n",
      "Best model: Epoch 19 \t loss=0.005312 \t val_loss=0.005166 \t time=0.77s\n",
      "Best model: Epoch 21 \t loss=0.005199 \t val_loss=0.005153 \t time=0.74s\n",
      "Best model: Epoch 22 \t loss=0.005116 \t val_loss=0.005135 \t time=0.74s\n",
      "Best model: Epoch 23 \t loss=0.005066 \t val_loss=0.005114 \t time=0.75s\n",
      "Best model: Epoch 24 \t loss=0.005009 \t val_loss=0.005062 \t time=0.93s\n",
      "Best model: Epoch 27 \t loss=0.004975 \t val_loss=0.005031 \t time=0.74s\n",
      "Best model: Epoch 28 \t loss=0.004901 \t val_loss=0.005006 \t time=0.75s\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 33 \t loss=0.004613 \t val_loss=0.004925 \t time=0.91s\n",
      "Best model: Epoch 34 \t loss=0.004493 \t val_loss=0.004894 \t time=0.75s\n",
      "Best model: Epoch 35 \t loss=0.004434 \t val_loss=0.004887 \t time=0.75s\n",
      "Best model: Epoch 36 \t loss=0.004365 \t val_loss=0.004865 \t time=0.76s\n",
      "Best model: Epoch 37 \t loss=0.004316 \t val_loss=0.004860 \t time=0.77s\n",
      "Best model: Epoch 38 \t loss=0.004286 \t val_loss=0.004849 \t time=0.94s\n",
      "Best model: Epoch 40 \t loss=0.004195 \t val_loss=0.004834 \t time=1.08s\n",
      "Fold 1 log loss: 0.00452115666100014\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.408895 \t val_loss=0.068768 \t time=0.77s\n",
      "Best model: Epoch 2 \t loss=0.037766 \t val_loss=0.017799 \t time=0.76s\n",
      "Best model: Epoch 3 \t loss=0.013389 \t val_loss=0.010457 \t time=1.11s\n",
      "Best model: Epoch 4 \t loss=0.009244 \t val_loss=0.008402 \t time=0.77s\n",
      "Best model: Epoch 5 \t loss=0.007471 \t val_loss=0.006501 \t time=0.78s\n",
      "Best model: Epoch 6 \t loss=0.006552 \t val_loss=0.006240 \t time=0.78s\n",
      "Best model: Epoch 7 \t loss=0.006222 \t val_loss=0.005894 \t time=1.27s\n",
      "Best model: Epoch 10 \t loss=0.006153 \t val_loss=0.005836 \t time=0.77s\n",
      "Best model: Epoch 11 \t loss=0.005770 \t val_loss=0.005532 \t time=0.78s\n",
      "Best model: Epoch 13 \t loss=0.005592 \t val_loss=0.005494 \t time=0.77s\n",
      "Best model: Epoch 14 \t loss=0.005478 \t val_loss=0.005437 \t time=0.79s\n",
      "Best model: Epoch 15 \t loss=0.005405 \t val_loss=0.005430 \t time=0.79s\n",
      "Best model: Epoch 16 \t loss=0.005354 \t val_loss=0.005395 \t time=0.81s\n",
      "Best model: Epoch 17 \t loss=0.005304 \t val_loss=0.005345 \t time=0.81s\n",
      "Best model: Epoch 18 \t loss=0.005249 \t val_loss=0.005297 \t time=0.84s\n",
      "Best model: Epoch 19 \t loss=0.005244 \t val_loss=0.005264 \t time=0.80s\n",
      "Best model: Epoch 21 \t loss=0.005189 \t val_loss=0.005203 \t time=0.76s\n",
      "Best model: Epoch 24 \t loss=0.005072 \t val_loss=0.005187 \t time=0.77s\n",
      "Best model: Epoch 25 \t loss=0.005016 \t val_loss=0.005170 \t time=0.75s\n",
      "Best model: Epoch 26 \t loss=0.004973 \t val_loss=0.005127 \t time=0.93s\n",
      "Best model: Epoch 29 \t loss=0.004904 \t val_loss=0.005127 \t time=0.74s\n",
      "Best model: Epoch 30 \t loss=0.004862 \t val_loss=0.005125 \t time=0.75s\n",
      "Best model: Epoch 32 \t loss=0.004863 \t val_loss=0.005103 \t time=0.76s\n",
      "Best model: Epoch 33 \t loss=0.004847 \t val_loss=0.005084 \t time=0.79s\n",
      "Best model: Epoch 35 \t loss=0.004841 \t val_loss=0.005083 \t time=0.92s\n",
      "Best model: Epoch 36 \t loss=0.004841 \t val_loss=0.005082 \t time=0.75s\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Fold 2 log loss: 0.004751353804878585\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.409649 \t val_loss=0.074777 \t time=0.75s\n",
      "Best model: Epoch 2 \t loss=0.038346 \t val_loss=0.016165 \t time=0.75s\n",
      "Best model: Epoch 3 \t loss=0.013545 \t val_loss=0.009875 \t time=0.75s\n",
      "Best model: Epoch 4 \t loss=0.009718 \t val_loss=0.007145 \t time=0.96s\n",
      "Best model: Epoch 5 \t loss=0.007804 \t val_loss=0.006742 \t time=0.76s\n",
      "Best model: Epoch 6 \t loss=0.006641 \t val_loss=0.006074 \t time=0.75s\n",
      "Best model: Epoch 7 \t loss=0.006373 \t val_loss=0.005801 \t time=0.77s\n",
      "Best model: Epoch 8 \t loss=0.006021 \t val_loss=0.005749 \t time=0.74s\n",
      "Best model: Epoch 9 \t loss=0.005838 \t val_loss=0.005662 \t time=0.75s\n",
      "Best model: Epoch 10 \t loss=0.005703 \t val_loss=0.005497 \t time=0.78s\n",
      "Best model: Epoch 12 \t loss=0.005684 \t val_loss=0.005463 \t time=0.75s\n",
      "Best model: Epoch 14 \t loss=0.005512 \t val_loss=0.005370 \t time=0.74s\n",
      "Best model: Epoch 16 \t loss=0.005406 \t val_loss=0.005370 \t time=0.74s\n",
      "Best model: Epoch 17 \t loss=0.005375 \t val_loss=0.005295 \t time=0.78s\n",
      "Best model: Epoch 19 \t loss=0.005243 \t val_loss=0.005206 \t time=0.76s\n",
      "Best model: Epoch 22 \t loss=0.005124 \t val_loss=0.005122 \t time=0.76s\n",
      "Best model: Epoch 24 \t loss=0.005039 \t val_loss=0.005100 \t time=0.76s\n",
      "Best model: Epoch 27 \t loss=0.004889 \t val_loss=0.005058 \t time=0.76s\n",
      "Best model: Epoch 28 \t loss=0.004830 \t val_loss=0.005051 \t time=0.77s\n",
      "Best model: Epoch 29 \t loss=0.004824 \t val_loss=0.005026 \t time=0.76s\n",
      "Best model: Epoch 33 \t loss=0.004753 \t val_loss=0.005005 \t time=0.77s\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 38 \t loss=0.004582 \t val_loss=0.004960 \t time=0.76s\n",
      "Best model: Epoch 39 \t loss=0.004485 \t val_loss=0.004934 \t time=0.76s\n",
      "Best model: Epoch 40 \t loss=0.004406 \t val_loss=0.004920 \t time=0.78s\n",
      "Fold 3 log loss: 0.004637686254643723\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.408468 \t val_loss=0.071267 \t time=0.97s\n",
      "Best model: Epoch 2 \t loss=0.037301 \t val_loss=0.016402 \t time=0.75s\n",
      "Best model: Epoch 3 \t loss=0.014577 \t val_loss=0.010089 \t time=0.76s\n",
      "Best model: Epoch 4 \t loss=0.009475 \t val_loss=0.007715 \t time=0.76s\n",
      "Best model: Epoch 5 \t loss=0.008199 \t val_loss=0.007014 \t time=0.75s\n",
      "Best model: Epoch 6 \t loss=0.006612 \t val_loss=0.005984 \t time=0.75s\n",
      "Best model: Epoch 7 \t loss=0.006300 \t val_loss=0.005781 \t time=0.75s\n",
      "Best model: Epoch 8 \t loss=0.006039 \t val_loss=0.005733 \t time=0.75s\n",
      "Best model: Epoch 9 \t loss=0.005769 \t val_loss=0.005581 \t time=0.75s\n",
      "Best model: Epoch 11 \t loss=0.005705 \t val_loss=0.005530 \t time=0.76s\n",
      "Best model: Epoch 12 \t loss=0.005595 \t val_loss=0.005512 \t time=0.75s\n",
      "Best model: Epoch 13 \t loss=0.005575 \t val_loss=0.005505 \t time=0.75s\n",
      "Best model: Epoch 14 \t loss=0.005491 \t val_loss=0.005411 \t time=0.94s\n",
      "Best model: Epoch 15 \t loss=0.005392 \t val_loss=0.005400 \t time=0.81s\n",
      "Best model: Epoch 17 \t loss=0.005333 \t val_loss=0.005342 \t time=0.77s\n",
      "Best model: Epoch 18 \t loss=0.005340 \t val_loss=0.005314 \t time=1.00s\n",
      "Best model: Epoch 19 \t loss=0.005225 \t val_loss=0.005259 \t time=0.78s\n",
      "Best model: Epoch 20 \t loss=0.005167 \t val_loss=0.005238 \t time=0.75s\n",
      "Best model: Epoch 21 \t loss=0.005184 \t val_loss=0.005218 \t time=0.75s\n",
      "Best model: Epoch 23 \t loss=0.005041 \t val_loss=0.005181 \t time=0.77s\n",
      "Best model: Epoch 24 \t loss=0.005026 \t val_loss=0.005153 \t time=0.76s\n",
      "Best model: Epoch 26 \t loss=0.004990 \t val_loss=0.005148 \t time=0.75s\n",
      "Best model: Epoch 29 \t loss=0.004923 \t val_loss=0.005120 \t time=0.78s\n",
      "Best model: Epoch 30 \t loss=0.004884 \t val_loss=0.005105 \t time=0.77s\n",
      "Best model: Epoch 31 \t loss=0.004871 \t val_loss=0.005091 \t time=0.75s\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 36 \t loss=0.004648 \t val_loss=0.005044 \t time=0.75s\n",
      "Best model: Epoch 37 \t loss=0.004527 \t val_loss=0.005019 \t time=0.75s\n",
      "Best model: Epoch 38 \t loss=0.004492 \t val_loss=0.004990 \t time=0.74s\n",
      "Best model: Epoch 39 \t loss=0.004428 \t val_loss=0.004990 \t time=0.75s\n",
      "Best model: Epoch 40 \t loss=0.004371 \t val_loss=0.004977 \t time=0.76s\n",
      "Fold 4 log loss: 0.004644217038272317\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.408006 \t val_loss=0.069958 \t time=0.76s\n",
      "Best model: Epoch 2 \t loss=0.038563 \t val_loss=0.019963 \t time=0.75s\n",
      "Best model: Epoch 3 \t loss=0.014470 \t val_loss=0.009272 \t time=0.77s\n",
      "Best model: Epoch 4 \t loss=0.009151 \t val_loss=0.007178 \t time=0.76s\n",
      "Best model: Epoch 5 \t loss=0.007781 \t val_loss=0.006495 \t time=0.75s\n",
      "Best model: Epoch 6 \t loss=0.006602 \t val_loss=0.006350 \t time=0.75s\n",
      "Best model: Epoch 7 \t loss=0.006180 \t val_loss=0.005783 \t time=0.75s\n",
      "Best model: Epoch 8 \t loss=0.006125 \t val_loss=0.005668 \t time=0.76s\n",
      "Best model: Epoch 9 \t loss=0.006190 \t val_loss=0.005634 \t time=0.77s\n",
      "Best model: Epoch 11 \t loss=0.005828 \t val_loss=0.005493 \t time=0.83s\n",
      "Best model: Epoch 12 \t loss=0.005930 \t val_loss=0.005492 \t time=0.84s\n",
      "Best model: Epoch 13 \t loss=0.005579 \t val_loss=0.005428 \t time=0.95s\n",
      "Best model: Epoch 14 \t loss=0.005568 \t val_loss=0.005379 \t time=0.75s\n",
      "Best model: Epoch 15 \t loss=0.005501 \t val_loss=0.005308 \t time=0.76s\n",
      "Best model: Epoch 18 \t loss=0.005330 \t val_loss=0.005283 \t time=0.98s\n",
      "Best model: Epoch 19 \t loss=0.005236 \t val_loss=0.005197 \t time=0.91s\n",
      "Best model: Epoch 20 \t loss=0.005319 \t val_loss=0.005192 \t time=0.91s\n",
      "Best model: Epoch 21 \t loss=0.005190 \t val_loss=0.005137 \t time=0.77s\n",
      "Best model: Epoch 22 \t loss=0.005133 \t val_loss=0.005107 \t time=1.02s\n",
      "Best model: Epoch 24 \t loss=0.005026 \t val_loss=0.005076 \t time=0.98s\n",
      "Best model: Epoch 27 \t loss=0.004968 \t val_loss=0.005028 \t time=0.75s\n",
      "Best model: Epoch 29 \t loss=0.004911 \t val_loss=0.005008 \t time=0.75s\n",
      "Best model: Epoch 30 \t loss=0.004871 \t val_loss=0.004991 \t time=0.76s\n",
      "Best model: Epoch 34 \t loss=0.004853 \t val_loss=0.004986 \t time=0.76s\n",
      "Best model: Epoch 35 \t loss=0.004845 \t val_loss=0.004983 \t time=0.76s\n",
      "Best model: Epoch 37 \t loss=0.004841 \t val_loss=0.004966 \t time=0.89s\n",
      "Fold 5 log loss: 0.004690238151688292\n",
      "Seed 2\n",
      "Fold 1 log loss: 0.00452115666100014\n",
      "Fold 2 log loss: 0.004751353804878585\n",
      "Fold 3 log loss: 0.004637686254643723\n",
      "Fold 4 log loss: 0.004644217038272317\n",
      "Fold 5 log loss: 0.004690238151688292\n",
      "Std of log loss: 7.572537114869211e-05\n",
      "Total log loss: 0.004648931537112937\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.409825 \t val_loss=0.071706 \t time=0.75s\n",
      "Best model: Epoch 2 \t loss=0.037912 \t val_loss=0.015967 \t time=0.74s\n",
      "Best model: Epoch 3 \t loss=0.014223 \t val_loss=0.010694 \t time=1.11s\n",
      "Best model: Epoch 4 \t loss=0.009154 \t val_loss=0.007143 \t time=0.82s\n",
      "Best model: Epoch 5 \t loss=0.007371 \t val_loss=0.006552 \t time=0.75s\n",
      "Best model: Epoch 6 \t loss=0.006789 \t val_loss=0.006136 \t time=0.75s\n",
      "Best model: Epoch 7 \t loss=0.006314 \t val_loss=0.006071 \t time=0.75s\n",
      "Best model: Epoch 8 \t loss=0.006031 \t val_loss=0.005689 \t time=0.77s\n",
      "Best model: Epoch 9 \t loss=0.005980 \t val_loss=0.005639 \t time=0.76s\n",
      "Best model: Epoch 10 \t loss=0.005742 \t val_loss=0.005545 \t time=0.75s\n",
      "Best model: Epoch 12 \t loss=0.005846 \t val_loss=0.005538 \t time=0.74s\n",
      "Best model: Epoch 13 \t loss=0.005671 \t val_loss=0.005425 \t time=0.75s\n",
      "Best model: Epoch 15 \t loss=0.005491 \t val_loss=0.005344 \t time=0.93s\n",
      "Best model: Epoch 17 \t loss=0.005475 \t val_loss=0.005263 \t time=0.91s\n",
      "Best model: Epoch 18 \t loss=0.005302 \t val_loss=0.005238 \t time=0.75s\n",
      "Best model: Epoch 20 \t loss=0.005205 \t val_loss=0.005198 \t time=0.74s\n",
      "Best model: Epoch 21 \t loss=0.005139 \t val_loss=0.005134 \t time=0.75s\n",
      "Best model: Epoch 22 \t loss=0.005128 \t val_loss=0.005123 \t time=0.84s\n",
      "Best model: Epoch 23 \t loss=0.005096 \t val_loss=0.005119 \t time=0.78s\n",
      "Best model: Epoch 24 \t loss=0.005080 \t val_loss=0.005118 \t time=0.75s\n",
      "Best model: Epoch 26 \t loss=0.005022 \t val_loss=0.005101 \t time=0.74s\n",
      "Best model: Epoch 27 \t loss=0.004967 \t val_loss=0.005036 \t time=0.75s\n",
      "Best model: Epoch 28 \t loss=0.004966 \t val_loss=0.005034 \t time=0.77s\n",
      "Best model: Epoch 29 \t loss=0.004911 \t val_loss=0.005007 \t time=0.77s\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 34 \t loss=0.004663 \t val_loss=0.004969 \t time=0.74s\n",
      "Best model: Epoch 35 \t loss=0.004571 \t val_loss=0.004937 \t time=0.75s\n",
      "Best model: Epoch 36 \t loss=0.004512 \t val_loss=0.004911 \t time=0.75s\n",
      "Best model: Epoch 37 \t loss=0.004420 \t val_loss=0.004903 \t time=0.75s\n",
      "Best model: Epoch 38 \t loss=0.004376 \t val_loss=0.004894 \t time=0.75s\n",
      "Best model: Epoch 39 \t loss=0.004339 \t val_loss=0.004883 \t time=0.75s\n",
      "Best model: Epoch 40 \t loss=0.004332 \t val_loss=0.004863 \t time=0.75s\n",
      "Fold 1 log loss: 0.004564225065176827\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.410174 \t val_loss=0.070790 \t time=1.18s\n",
      "Best model: Epoch 2 \t loss=0.036825 \t val_loss=0.018156 \t time=0.75s\n",
      "Best model: Epoch 3 \t loss=0.014035 \t val_loss=0.009074 \t time=0.78s\n",
      "Best model: Epoch 4 \t loss=0.009185 \t val_loss=0.007191 \t time=0.95s\n",
      "Best model: Epoch 5 \t loss=0.007628 \t val_loss=0.006844 \t time=0.75s\n",
      "Best model: Epoch 6 \t loss=0.006858 \t val_loss=0.006243 \t time=0.78s\n",
      "Best model: Epoch 7 \t loss=0.006185 \t val_loss=0.005873 \t time=0.77s\n",
      "Best model: Epoch 9 \t loss=0.006014 \t val_loss=0.005720 \t time=0.83s\n",
      "Best model: Epoch 10 \t loss=0.005827 \t val_loss=0.005595 \t time=1.07s\n",
      "Best model: Epoch 12 \t loss=0.005684 \t val_loss=0.005584 \t time=0.75s\n",
      "Best model: Epoch 13 \t loss=0.005540 \t val_loss=0.005492 \t time=0.99s\n",
      "Best model: Epoch 14 \t loss=0.005546 \t val_loss=0.005426 \t time=0.76s\n",
      "Best model: Epoch 16 \t loss=0.005474 \t val_loss=0.005401 \t time=0.77s\n",
      "Best model: Epoch 17 \t loss=0.005459 \t val_loss=0.005381 \t time=0.75s\n",
      "Best model: Epoch 18 \t loss=0.005301 \t val_loss=0.005352 \t time=0.75s\n",
      "Best model: Epoch 19 \t loss=0.005221 \t val_loss=0.005289 \t time=0.76s\n",
      "Best model: Epoch 20 \t loss=0.005154 \t val_loss=0.005232 \t time=0.76s\n",
      "Best model: Epoch 21 \t loss=0.005116 \t val_loss=0.005200 \t time=0.78s\n",
      "Best model: Epoch 22 \t loss=0.005065 \t val_loss=0.005199 \t time=0.76s\n",
      "Best model: Epoch 24 \t loss=0.005049 \t val_loss=0.005169 \t time=0.75s\n",
      "Best model: Epoch 25 \t loss=0.004984 \t val_loss=0.005131 \t time=0.75s\n",
      "Best model: Epoch 27 \t loss=0.004908 \t val_loss=0.005100 \t time=0.90s\n",
      "Best model: Epoch 28 \t loss=0.004881 \t val_loss=0.005081 \t time=0.75s\n",
      "Best model: Epoch 29 \t loss=0.004852 \t val_loss=0.005079 \t time=0.75s\n",
      "Best model: Epoch 31 \t loss=0.004829 \t val_loss=0.005063 \t time=0.75s\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 36 \t loss=0.004576 \t val_loss=0.004987 \t time=0.95s\n",
      "Best model: Epoch 37 \t loss=0.004448 \t val_loss=0.004960 \t time=0.75s\n",
      "Best model: Epoch 38 \t loss=0.004378 \t val_loss=0.004952 \t time=0.75s\n",
      "Best model: Epoch 39 \t loss=0.004316 \t val_loss=0.004938 \t time=0.76s\n",
      "Best model: Epoch 40 \t loss=0.004279 \t val_loss=0.004938 \t time=0.95s\n",
      "Fold 2 log loss: 0.004605266994251012\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.409435 \t val_loss=0.066888 \t time=0.77s\n",
      "Best model: Epoch 2 \t loss=0.037070 \t val_loss=0.014385 \t time=0.78s\n",
      "Best model: Epoch 3 \t loss=0.013888 \t val_loss=0.008990 \t time=0.79s\n",
      "Best model: Epoch 4 \t loss=0.009180 \t val_loss=0.007163 \t time=0.76s\n",
      "Best model: Epoch 5 \t loss=0.007530 \t val_loss=0.006723 \t time=0.76s\n",
      "Best model: Epoch 6 \t loss=0.007129 \t val_loss=0.006615 \t time=1.10s\n",
      "Best model: Epoch 7 \t loss=0.006248 \t val_loss=0.005750 \t time=0.78s\n",
      "Best model: Epoch 8 \t loss=0.006148 \t val_loss=0.005650 \t time=0.80s\n",
      "Best model: Epoch 9 \t loss=0.005817 \t val_loss=0.005647 \t time=0.79s\n",
      "Best model: Epoch 10 \t loss=0.005914 \t val_loss=0.005599 \t time=1.01s\n",
      "Best model: Epoch 13 \t loss=0.005712 \t val_loss=0.005557 \t time=0.78s\n",
      "Best model: Epoch 14 \t loss=0.005570 \t val_loss=0.005432 \t time=0.81s\n",
      "Best model: Epoch 15 \t loss=0.005469 \t val_loss=0.005366 \t time=0.79s\n",
      "Best model: Epoch 16 \t loss=0.005394 \t val_loss=0.005310 \t time=0.75s\n",
      "Best model: Epoch 17 \t loss=0.005316 \t val_loss=0.005300 \t time=0.75s\n",
      "Best model: Epoch 18 \t loss=0.005317 \t val_loss=0.005250 \t time=0.75s\n",
      "Best model: Epoch 21 \t loss=0.005210 \t val_loss=0.005171 \t time=0.75s\n",
      "Best model: Epoch 22 \t loss=0.005141 \t val_loss=0.005167 \t time=0.76s\n",
      "Best model: Epoch 23 \t loss=0.005171 \t val_loss=0.005149 \t time=0.93s\n",
      "Best model: Epoch 24 \t loss=0.005056 \t val_loss=0.005120 \t time=0.78s\n",
      "Best model: Epoch 26 \t loss=0.004966 \t val_loss=0.005098 \t time=0.75s\n",
      "Best model: Epoch 27 \t loss=0.004959 \t val_loss=0.005077 \t time=0.75s\n",
      "Best model: Epoch 28 \t loss=0.004913 \t val_loss=0.005076 \t time=0.77s\n",
      "Best model: Epoch 31 \t loss=0.004872 \t val_loss=0.005050 \t time=0.75s\n",
      "Best model: Epoch 32 \t loss=0.004867 \t val_loss=0.005004 \t time=0.97s\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 37 \t loss=0.004651 \t val_loss=0.004969 \t time=0.79s\n",
      "Best model: Epoch 38 \t loss=0.004501 \t val_loss=0.004946 \t time=0.76s\n",
      "Best model: Epoch 39 \t loss=0.004432 \t val_loss=0.004928 \t time=0.76s\n",
      "Best model: Epoch 40 \t loss=0.004399 \t val_loss=0.004927 \t time=0.81s\n",
      "Fold 3 log loss: 0.004641951974766587\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.411918 \t val_loss=0.074305 \t time=0.95s\n",
      "Best model: Epoch 2 \t loss=0.038331 \t val_loss=0.017654 \t time=0.75s\n",
      "Best model: Epoch 3 \t loss=0.014428 \t val_loss=0.010051 \t time=0.76s\n",
      "Best model: Epoch 4 \t loss=0.009387 \t val_loss=0.007305 \t time=0.75s\n",
      "Best model: Epoch 5 \t loss=0.007260 \t val_loss=0.006499 \t time=0.77s\n",
      "Best model: Epoch 6 \t loss=0.006906 \t val_loss=0.006213 \t time=0.92s\n",
      "Best model: Epoch 7 \t loss=0.006351 \t val_loss=0.005887 \t time=0.81s\n",
      "Best model: Epoch 9 \t loss=0.005881 \t val_loss=0.005583 \t time=0.75s\n",
      "Best model: Epoch 10 \t loss=0.005747 \t val_loss=0.005558 \t time=0.76s\n",
      "Best model: Epoch 13 \t loss=0.005633 \t val_loss=0.005440 \t time=0.75s\n",
      "Best model: Epoch 14 \t loss=0.005490 \t val_loss=0.005419 \t time=0.75s\n",
      "Best model: Epoch 16 \t loss=0.005528 \t val_loss=0.005390 \t time=0.75s\n",
      "Best model: Epoch 17 \t loss=0.005342 \t val_loss=0.005327 \t time=0.75s\n",
      "Best model: Epoch 19 \t loss=0.005200 \t val_loss=0.005266 \t time=0.75s\n",
      "Best model: Epoch 20 \t loss=0.005148 \t val_loss=0.005238 \t time=0.95s\n",
      "Best model: Epoch 21 \t loss=0.005106 \t val_loss=0.005200 \t time=0.75s\n",
      "Best model: Epoch 22 \t loss=0.005103 \t val_loss=0.005164 \t time=0.75s\n",
      "Best model: Epoch 23 \t loss=0.005020 \t val_loss=0.005113 \t time=0.76s\n",
      "Best model: Epoch 24 \t loss=0.004950 \t val_loss=0.005100 \t time=0.75s\n",
      "Best model: Epoch 28 \t loss=0.004867 \t val_loss=0.005094 \t time=0.76s\n",
      "Best model: Epoch 30 \t loss=0.004802 \t val_loss=0.005073 \t time=0.74s\n",
      "Best model: Epoch 33 \t loss=0.004780 \t val_loss=0.005062 \t time=0.85s\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 38 \t loss=0.004554 \t val_loss=0.005014 \t time=0.78s\n",
      "Best model: Epoch 39 \t loss=0.004442 \t val_loss=0.004983 \t time=0.97s\n",
      "Best model: Epoch 40 \t loss=0.004354 \t val_loss=0.004970 \t time=1.01s\n",
      "Fold 4 log loss: 0.004638930943613447\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.408388 \t val_loss=0.068515 \t time=0.76s\n",
      "Best model: Epoch 2 \t loss=0.037283 \t val_loss=0.019167 \t time=0.75s\n",
      "Best model: Epoch 3 \t loss=0.014212 \t val_loss=0.009136 \t time=0.76s\n",
      "Best model: Epoch 4 \t loss=0.009127 \t val_loss=0.007837 \t time=0.93s\n",
      "Best model: Epoch 5 \t loss=0.007564 \t val_loss=0.006431 \t time=0.77s\n",
      "Best model: Epoch 6 \t loss=0.006627 \t val_loss=0.006146 \t time=0.76s\n",
      "Best model: Epoch 7 \t loss=0.006280 \t val_loss=0.005864 \t time=0.77s\n",
      "Best model: Epoch 8 \t loss=0.005980 \t val_loss=0.005702 \t time=0.76s\n",
      "Best model: Epoch 9 \t loss=0.006008 \t val_loss=0.005646 \t time=0.76s\n",
      "Best model: Epoch 11 \t loss=0.005743 \t val_loss=0.005596 \t time=0.75s\n",
      "Best model: Epoch 12 \t loss=0.005751 \t val_loss=0.005445 \t time=0.75s\n",
      "Best model: Epoch 14 \t loss=0.005464 \t val_loss=0.005351 \t time=0.76s\n",
      "Best model: Epoch 16 \t loss=0.005434 \t val_loss=0.005258 \t time=0.83s\n",
      "Best model: Epoch 19 \t loss=0.005275 \t val_loss=0.005194 \t time=0.88s\n",
      "Best model: Epoch 20 \t loss=0.005190 \t val_loss=0.005131 \t time=0.75s\n",
      "Best model: Epoch 23 \t loss=0.005120 \t val_loss=0.005097 \t time=0.78s\n",
      "Best model: Epoch 24 \t loss=0.005043 \t val_loss=0.005091 \t time=1.03s\n",
      "Best model: Epoch 25 \t loss=0.005050 \t val_loss=0.005012 \t time=0.80s\n",
      "Best model: Epoch 29 \t loss=0.004917 \t val_loss=0.004989 \t time=0.89s\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 34 \t loss=0.004659 \t val_loss=0.004925 \t time=1.04s\n",
      "Best model: Epoch 35 \t loss=0.004564 \t val_loss=0.004897 \t time=0.79s\n",
      "Best model: Epoch 36 \t loss=0.004472 \t val_loss=0.004870 \t time=0.77s\n",
      "Best model: Epoch 37 \t loss=0.004438 \t val_loss=0.004858 \t time=0.77s\n",
      "Best model: Epoch 39 \t loss=0.004366 \t val_loss=0.004850 \t time=0.75s\n",
      "Best model: Epoch 40 \t loss=0.004271 \t val_loss=0.004845 \t time=0.76s\n",
      "Fold 5 log loss: 0.004556664361985448\n",
      "Seed 3\n",
      "Fold 1 log loss: 0.004564225065176827\n",
      "Fold 2 log loss: 0.004605266994251012\n",
      "Fold 3 log loss: 0.004641951974766587\n",
      "Fold 4 log loss: 0.004638930943613447\n",
      "Fold 5 log loss: 0.004556664361985448\n",
      "Std of log loss: 3.5920024523029835e-05\n",
      "Total log loss: 0.004601409386259944\n",
      "Total log loss in Non targets: 0.004593299468012177\n"
     ]
    }
   ],
   "source": [
    "seeds = [0,1,2,3]\n",
    "\n",
    "target_oof = np.zeros([len(fn_train),fn_targets.shape[1]])\n",
    "target_pred = np.zeros([len(fn_test),fn_targets.shape[1]])\n",
    "\n",
    "nontarget_oof = np.zeros([len(fn_train),fn_nontargets.shape[1]])\n",
    "nontarget_pred = np.zeros([len(fn_test),fn_nontargets.shape[1]])\n",
    "\n",
    "for seed_ in seeds:\n",
    "    oof, oof_targets, pytorch_pred = modelling_torch(fn_train, fn_targets, fn_test, seed_, fn_train.shape[1], fn_targets.shape[1],[])\n",
    "    target_oof += oof / len(seeds)\n",
    "    target_pred += pytorch_pred / len(seeds)\n",
    "print(\"Total log loss in targets: {}\".format(mean_log_loss(oof_targets, target_oof)))\n",
    "\n",
    "for seed_ in seeds:\n",
    "    oof, oof_targets, pytorch_pred = modelling_torch(fn_train, fn_nontargets, fn_test, seed_, fn_train.shape[1], fn_nontargets.shape[1],[])\n",
    "    nontarget_oof += oof / len(seeds)\n",
    "    nontarget_pred += pytorch_pred / len(seeds)\n",
    "print(\"Total log loss in Non targets: {}\".format(mean_log_loss(oof_targets, nontarget_oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T12:44:48.017016Z",
     "iopub.status.busy": "2020-10-11T12:44:48.015796Z",
     "iopub.status.idle": "2020-10-11T12:44:48.295065Z",
     "shell.execute_reply": "2020-10-11T12:44:48.294429Z"
    },
    "papermill": {
     "duration": 0.722577,
     "end_time": "2020-10-11T12:44:48.295273",
     "exception": false,
     "start_time": "2020-10-11T12:44:47.572696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_train = f_train.copy()\n",
    "n_test = f_test.copy()\n",
    "\n",
    "n_train[\"target_sum\"] = target_oof.sum(axis=1)\n",
    "n_train[\"nontarget_sum\"] = nontarget_oof.sum(axis=1)\n",
    "n_test[\"target_sum\"] = target_pred.sum(axis=1)\n",
    "n_test.loc[noncons_test_index, \"target_sum\"] = 0\n",
    "n_test[\"nontarget_sum\"] = nontarget_pred.sum(axis=1)\n",
    "n_test.loc[noncons_test_index, \"nontarget_sum\"] = 0\n",
    "\n",
    "n_train = n_train.to_numpy()\n",
    "n_test = n_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T12:44:49.188076Z",
     "iopub.status.busy": "2020-10-11T12:44:49.186587Z",
     "iopub.status.idle": "2020-10-11T12:50:48.929582Z",
     "shell.execute_reply": "2020-10-11T12:50:48.928937Z"
    },
    "papermill": {
     "duration": 360.195794,
     "end_time": "2020-10-11T12:50:48.929693",
     "exception": false,
     "start_time": "2020-10-11T12:44:48.733899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.411042 \t val_loss=0.076603 \t time=0.80s\n",
      "Best model: Epoch 2 \t loss=0.048487 \t val_loss=0.030337 \t time=0.78s\n",
      "Best model: Epoch 3 \t loss=0.027204 \t val_loss=0.023304 \t time=0.75s\n",
      "Best model: Epoch 4 \t loss=0.023114 \t val_loss=0.021551 \t time=0.74s\n",
      "Best model: Epoch 5 \t loss=0.021304 \t val_loss=0.019862 \t time=0.74s\n",
      "Best model: Epoch 6 \t loss=0.020342 \t val_loss=0.019234 \t time=0.94s\n",
      "Best model: Epoch 7 \t loss=0.019731 \t val_loss=0.018788 \t time=0.75s\n",
      "Best model: Epoch 8 \t loss=0.019247 \t val_loss=0.018366 \t time=0.74s\n",
      "Best model: Epoch 9 \t loss=0.018857 \t val_loss=0.018158 \t time=0.74s\n",
      "Best model: Epoch 10 \t loss=0.018510 \t val_loss=0.017875 \t time=0.76s\n",
      "Best model: Epoch 11 \t loss=0.018249 \t val_loss=0.017602 \t time=0.77s\n",
      "Best model: Epoch 12 \t loss=0.017826 \t val_loss=0.017352 \t time=0.74s\n",
      "Best model: Epoch 13 \t loss=0.017645 \t val_loss=0.017275 \t time=0.75s\n",
      "Best model: Epoch 14 \t loss=0.017354 \t val_loss=0.017100 \t time=0.74s\n",
      "Best model: Epoch 17 \t loss=0.016906 \t val_loss=0.016904 \t time=0.76s\n",
      "Best model: Epoch 18 \t loss=0.016551 \t val_loss=0.016775 \t time=0.75s\n",
      "Best model: Epoch 19 \t loss=0.016376 \t val_loss=0.016643 \t time=0.88s\n",
      "Best model: Epoch 20 \t loss=0.016291 \t val_loss=0.016622 \t time=0.80s\n",
      "Best model: Epoch 21 \t loss=0.016003 \t val_loss=0.016484 \t time=0.74s\n",
      "Best model: Epoch 23 \t loss=0.015893 \t val_loss=0.016434 \t time=0.97s\n",
      "Best model: Epoch 25 \t loss=0.015639 \t val_loss=0.016403 \t time=0.74s\n",
      "Best model: Epoch 26 \t loss=0.015482 \t val_loss=0.016387 \t time=0.75s\n",
      "Best model: Epoch 27 \t loss=0.015378 \t val_loss=0.016338 \t time=0.74s\n",
      "Best model: Epoch 28 \t loss=0.015357 \t val_loss=0.016293 \t time=0.75s\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 33 \t loss=0.014561 \t val_loss=0.016189 \t time=0.93s\n",
      "Best model: Epoch 34 \t loss=0.014241 \t val_loss=0.016093 \t time=0.75s\n",
      "Best model: Epoch 36 \t loss=0.013855 \t val_loss=0.016048 \t time=0.74s\n",
      "Best model: Epoch 38 \t loss=0.013601 \t val_loss=0.016011 \t time=0.77s\n",
      "Best model: Epoch 39 \t loss=0.013447 \t val_loss=0.016011 \t time=0.98s\n",
      "Fold 1 log loss: 0.016116600512334878\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.414180 \t val_loss=0.085503 \t time=0.75s\n",
      "Best model: Epoch 2 \t loss=0.048377 \t val_loss=0.027513 \t time=0.75s\n",
      "Best model: Epoch 3 \t loss=0.027276 \t val_loss=0.022646 \t time=1.03s\n",
      "Best model: Epoch 4 \t loss=0.023385 \t val_loss=0.021000 \t time=0.77s\n",
      "Best model: Epoch 5 \t loss=0.021379 \t val_loss=0.019654 \t time=0.77s\n",
      "Best model: Epoch 6 \t loss=0.020391 \t val_loss=0.018879 \t time=0.75s\n",
      "Best model: Epoch 7 \t loss=0.019744 \t val_loss=0.018846 \t time=0.76s\n",
      "Best model: Epoch 8 \t loss=0.019288 \t val_loss=0.018296 \t time=0.78s\n",
      "Best model: Epoch 9 \t loss=0.018808 \t val_loss=0.018029 \t time=0.76s\n",
      "Best model: Epoch 10 \t loss=0.018537 \t val_loss=0.017679 \t time=0.75s\n",
      "Best model: Epoch 11 \t loss=0.018296 \t val_loss=0.017552 \t time=0.78s\n",
      "Best model: Epoch 12 \t loss=0.017883 \t val_loss=0.017366 \t time=0.76s\n",
      "Best model: Epoch 13 \t loss=0.017872 \t val_loss=0.017266 \t time=0.75s\n",
      "Best model: Epoch 14 \t loss=0.017472 \t val_loss=0.017126 \t time=0.75s\n",
      "Best model: Epoch 16 \t loss=0.016939 \t val_loss=0.016855 \t time=0.96s\n",
      "Best model: Epoch 18 \t loss=0.016789 \t val_loss=0.016754 \t time=0.98s\n",
      "Best model: Epoch 19 \t loss=0.016416 \t val_loss=0.016616 \t time=0.82s\n",
      "Best model: Epoch 20 \t loss=0.016298 \t val_loss=0.016594 \t time=0.77s\n",
      "Best model: Epoch 21 \t loss=0.016177 \t val_loss=0.016522 \t time=0.75s\n",
      "Best model: Epoch 22 \t loss=0.016008 \t val_loss=0.016501 \t time=0.74s\n",
      "Best model: Epoch 23 \t loss=0.015910 \t val_loss=0.016481 \t time=0.74s\n",
      "Best model: Epoch 24 \t loss=0.015840 \t val_loss=0.016413 \t time=0.75s\n",
      "Best model: Epoch 25 \t loss=0.015755 \t val_loss=0.016318 \t time=0.75s\n",
      "Best model: Epoch 26 \t loss=0.015580 \t val_loss=0.016304 \t time=0.76s\n",
      "Best model: Epoch 27 \t loss=0.015475 \t val_loss=0.016292 \t time=0.75s\n",
      "Best model: Epoch 30 \t loss=0.015310 \t val_loss=0.016236 \t time=0.86s\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 35 \t loss=0.014486 \t val_loss=0.016119 \t time=0.96s\n",
      "Best model: Epoch 36 \t loss=0.014226 \t val_loss=0.016044 \t time=0.74s\n",
      "Best model: Epoch 37 \t loss=0.013988 \t val_loss=0.016029 \t time=0.74s\n",
      "Best model: Epoch 38 \t loss=0.013853 \t val_loss=0.016005 \t time=0.74s\n",
      "Fold 2 log loss: 0.016068439465779138\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.415185 \t val_loss=0.078267 \t time=0.90s\n",
      "Best model: Epoch 2 \t loss=0.050057 \t val_loss=0.030885 \t time=0.75s\n",
      "Best model: Epoch 3 \t loss=0.027158 \t val_loss=0.023099 \t time=0.78s\n",
      "Best model: Epoch 4 \t loss=0.023547 \t val_loss=0.021408 \t time=0.76s\n",
      "Best model: Epoch 5 \t loss=0.021591 \t val_loss=0.019722 \t time=0.74s\n",
      "Best model: Epoch 6 \t loss=0.020290 \t val_loss=0.019112 \t time=0.75s\n",
      "Best model: Epoch 7 \t loss=0.019739 \t val_loss=0.018604 \t time=0.74s\n",
      "Best model: Epoch 8 \t loss=0.019215 \t val_loss=0.018253 \t time=0.74s\n",
      "Best model: Epoch 9 \t loss=0.018925 \t val_loss=0.018126 \t time=0.79s\n",
      "Best model: Epoch 10 \t loss=0.018632 \t val_loss=0.017914 \t time=0.79s\n",
      "Best model: Epoch 11 \t loss=0.018228 \t val_loss=0.017585 \t time=0.75s\n",
      "Best model: Epoch 12 \t loss=0.018065 \t val_loss=0.017528 \t time=0.77s\n",
      "Best model: Epoch 13 \t loss=0.017672 \t val_loss=0.017353 \t time=0.75s\n",
      "Best model: Epoch 14 \t loss=0.017594 \t val_loss=0.017090 \t time=0.97s\n",
      "Best model: Epoch 15 \t loss=0.017192 \t val_loss=0.016905 \t time=1.05s\n",
      "Best model: Epoch 16 \t loss=0.016972 \t val_loss=0.016879 \t time=0.75s\n",
      "Best model: Epoch 17 \t loss=0.016772 \t val_loss=0.016739 \t time=0.75s\n",
      "Best model: Epoch 18 \t loss=0.016639 \t val_loss=0.016680 \t time=0.74s\n",
      "Best model: Epoch 19 \t loss=0.016426 \t val_loss=0.016573 \t time=0.76s\n",
      "Best model: Epoch 20 \t loss=0.016243 \t val_loss=0.016555 \t time=0.75s\n",
      "Best model: Epoch 21 \t loss=0.016152 \t val_loss=0.016494 \t time=0.77s\n",
      "Best model: Epoch 22 \t loss=0.015987 \t val_loss=0.016392 \t time=0.75s\n",
      "Best model: Epoch 23 \t loss=0.015859 \t val_loss=0.016385 \t time=0.75s\n",
      "Best model: Epoch 24 \t loss=0.015779 \t val_loss=0.016338 \t time=1.08s\n",
      "Best model: Epoch 25 \t loss=0.015669 \t val_loss=0.016309 \t time=0.75s\n",
      "Best model: Epoch 26 \t loss=0.015621 \t val_loss=0.016270 \t time=0.77s\n",
      "Best model: Epoch 29 \t loss=0.015325 \t val_loss=0.016257 \t time=0.74s\n",
      "Best model: Epoch 30 \t loss=0.015263 \t val_loss=0.016239 \t time=1.02s\n",
      "Best model: Epoch 33 \t loss=0.015193 \t val_loss=0.016231 \t time=0.80s\n",
      "Best model: Epoch 36 \t loss=0.015052 \t val_loss=0.016210 \t time=0.75s\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Fold 3 log loss: 0.016207887014995957\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.414611 \t val_loss=0.080516 \t time=0.75s\n",
      "Best model: Epoch 2 \t loss=0.048944 \t val_loss=0.027357 \t time=0.76s\n",
      "Best model: Epoch 3 \t loss=0.027110 \t val_loss=0.022728 \t time=0.74s\n",
      "Best model: Epoch 4 \t loss=0.022980 \t val_loss=0.020653 \t time=0.75s\n",
      "Best model: Epoch 5 \t loss=0.021181 \t val_loss=0.019509 \t time=0.74s\n",
      "Best model: Epoch 6 \t loss=0.020430 \t val_loss=0.018788 \t time=0.74s\n",
      "Best model: Epoch 7 \t loss=0.019564 \t val_loss=0.018374 \t time=0.74s\n",
      "Best model: Epoch 8 \t loss=0.019216 \t val_loss=0.018001 \t time=0.79s\n",
      "Best model: Epoch 9 \t loss=0.018738 \t val_loss=0.017880 \t time=0.76s\n",
      "Best model: Epoch 10 \t loss=0.018510 \t val_loss=0.017491 \t time=0.92s\n",
      "Best model: Epoch 11 \t loss=0.018339 \t val_loss=0.017388 \t time=1.20s\n",
      "Best model: Epoch 12 \t loss=0.017932 \t val_loss=0.017337 \t time=0.73s\n",
      "Best model: Epoch 13 \t loss=0.017714 \t val_loss=0.017075 \t time=0.74s\n",
      "Best model: Epoch 14 \t loss=0.017451 \t val_loss=0.016978 \t time=0.77s\n",
      "Best model: Epoch 15 \t loss=0.017461 \t val_loss=0.016817 \t time=0.75s\n",
      "Best model: Epoch 16 \t loss=0.017027 \t val_loss=0.016735 \t time=0.77s\n",
      "Best model: Epoch 17 \t loss=0.016790 \t val_loss=0.016571 \t time=0.74s\n",
      "Best model: Epoch 18 \t loss=0.016596 \t val_loss=0.016484 \t time=0.74s\n",
      "Best model: Epoch 19 \t loss=0.016447 \t val_loss=0.016435 \t time=0.74s\n",
      "Best model: Epoch 21 \t loss=0.016250 \t val_loss=0.016380 \t time=0.76s\n",
      "Best model: Epoch 22 \t loss=0.016047 \t val_loss=0.016340 \t time=0.76s\n",
      "Best model: Epoch 23 \t loss=0.016010 \t val_loss=0.016228 \t time=0.75s\n",
      "Best model: Epoch 25 \t loss=0.015672 \t val_loss=0.016195 \t time=0.75s\n",
      "Best model: Epoch 27 \t loss=0.015522 \t val_loss=0.016175 \t time=0.75s\n",
      "Best model: Epoch 30 \t loss=0.015337 \t val_loss=0.016140 \t time=0.75s\n",
      "Best model: Epoch 31 \t loss=0.015245 \t val_loss=0.016093 \t time=0.75s\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 36 \t loss=0.014400 \t val_loss=0.015983 \t time=0.74s\n",
      "Best model: Epoch 37 \t loss=0.014114 \t val_loss=0.015966 \t time=0.74s\n",
      "Best model: Epoch 38 \t loss=0.013857 \t val_loss=0.015880 \t time=0.95s\n",
      "Best model: Epoch 40 \t loss=0.013585 \t val_loss=0.015875 \t time=0.77s\n",
      "Fold 4 log loss: 0.015927188205723614\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.417558 \t val_loss=0.082595 \t time=0.76s\n",
      "Best model: Epoch 2 \t loss=0.049268 \t val_loss=0.027986 \t time=0.75s\n",
      "Best model: Epoch 3 \t loss=0.026986 \t val_loss=0.023348 \t time=0.74s\n",
      "Best model: Epoch 4 \t loss=0.023391 \t val_loss=0.021134 \t time=0.76s\n",
      "Best model: Epoch 5 \t loss=0.021474 \t val_loss=0.020150 \t time=0.74s\n",
      "Best model: Epoch 6 \t loss=0.020700 \t val_loss=0.019222 \t time=0.80s\n",
      "Best model: Epoch 7 \t loss=0.019954 \t val_loss=0.018926 \t time=1.00s\n",
      "Best model: Epoch 8 \t loss=0.019176 \t val_loss=0.018385 \t time=0.93s\n",
      "Best model: Epoch 9 \t loss=0.018922 \t val_loss=0.018118 \t time=0.80s\n",
      "Best model: Epoch 10 \t loss=0.018511 \t val_loss=0.017981 \t time=0.75s\n",
      "Best model: Epoch 11 \t loss=0.018602 \t val_loss=0.017659 \t time=1.08s\n",
      "Best model: Epoch 12 \t loss=0.018087 \t val_loss=0.017548 \t time=0.75s\n",
      "Best model: Epoch 13 \t loss=0.017705 \t val_loss=0.017324 \t time=0.77s\n",
      "Best model: Epoch 14 \t loss=0.017452 \t val_loss=0.017219 \t time=0.76s\n",
      "Best model: Epoch 15 \t loss=0.017265 \t val_loss=0.017212 \t time=0.97s\n",
      "Best model: Epoch 16 \t loss=0.017077 \t val_loss=0.016940 \t time=0.75s\n",
      "Best model: Epoch 18 \t loss=0.016593 \t val_loss=0.016826 \t time=0.74s\n",
      "Best model: Epoch 20 \t loss=0.016384 \t val_loss=0.016634 \t time=0.77s\n",
      "Best model: Epoch 21 \t loss=0.016190 \t val_loss=0.016609 \t time=1.35s\n",
      "Best model: Epoch 22 \t loss=0.016120 \t val_loss=0.016557 \t time=0.81s\n",
      "Best model: Epoch 23 \t loss=0.015952 \t val_loss=0.016497 \t time=0.78s\n",
      "Best model: Epoch 27 \t loss=0.015572 \t val_loss=0.016417 \t time=0.79s\n",
      "Best model: Epoch 28 \t loss=0.015566 \t val_loss=0.016376 \t time=0.81s\n",
      "Best model: Epoch 29 \t loss=0.015409 \t val_loss=0.016361 \t time=0.77s\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 34 \t loss=0.014515 \t val_loss=0.016203 \t time=0.87s\n",
      "Best model: Epoch 35 \t loss=0.014199 \t val_loss=0.016147 \t time=0.76s\n",
      "Best model: Epoch 36 \t loss=0.014005 \t val_loss=0.016109 \t time=0.74s\n",
      "Best model: Epoch 37 \t loss=0.013868 \t val_loss=0.016085 \t time=0.75s\n",
      "Best model: Epoch 40 \t loss=0.013464 \t val_loss=0.016078 \t time=0.75s\n",
      "Fold 5 log loss: 0.016075852644351848\n",
      "Seed 10\n",
      "Fold 1 log loss: 0.016116600512334878\n",
      "Fold 2 log loss: 0.016068439465779138\n",
      "Fold 3 log loss: 0.016207887014995957\n",
      "Fold 4 log loss: 0.015927188205723614\n",
      "Fold 5 log loss: 0.016075852644351848\n",
      "Std of log loss: 9.076753321573603e-05\n",
      "Total log loss: 0.016079194210838067\n",
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.417051 \t val_loss=0.079323 \t time=0.75s\n",
      "Best model: Epoch 2 \t loss=0.048966 \t val_loss=0.028361 \t time=0.95s\n",
      "Best model: Epoch 3 \t loss=0.027186 \t val_loss=0.022887 \t time=0.75s\n",
      "Best model: Epoch 4 \t loss=0.023325 \t val_loss=0.021298 \t time=0.74s\n",
      "Best model: Epoch 5 \t loss=0.021438 \t val_loss=0.019744 \t time=0.74s\n",
      "Best model: Epoch 6 \t loss=0.020359 \t val_loss=0.019165 \t time=0.74s\n",
      "Best model: Epoch 7 \t loss=0.019656 \t val_loss=0.018941 \t time=0.75s\n",
      "Best model: Epoch 8 \t loss=0.019169 \t val_loss=0.018579 \t time=0.74s\n",
      "Best model: Epoch 9 \t loss=0.018863 \t val_loss=0.018277 \t time=0.74s\n",
      "Best model: Epoch 10 \t loss=0.018485 \t val_loss=0.017695 \t time=0.75s\n",
      "Best model: Epoch 11 \t loss=0.018194 \t val_loss=0.017640 \t time=0.74s\n",
      "Best model: Epoch 13 \t loss=0.017683 \t val_loss=0.017388 \t time=0.74s\n",
      "Best model: Epoch 14 \t loss=0.017367 \t val_loss=0.017131 \t time=0.99s\n",
      "Best model: Epoch 15 \t loss=0.017108 \t val_loss=0.016990 \t time=0.97s\n",
      "Best model: Epoch 16 \t loss=0.016902 \t val_loss=0.016912 \t time=0.77s\n",
      "Best model: Epoch 18 \t loss=0.016692 \t val_loss=0.016868 \t time=0.74s\n",
      "Best model: Epoch 19 \t loss=0.016383 \t val_loss=0.016679 \t time=0.74s\n",
      "Best model: Epoch 20 \t loss=0.016249 \t val_loss=0.016576 \t time=0.75s\n",
      "Best model: Epoch 21 \t loss=0.016079 \t val_loss=0.016485 \t time=0.75s\n",
      "Best model: Epoch 22 \t loss=0.016003 \t val_loss=0.016449 \t time=0.75s\n",
      "Best model: Epoch 23 \t loss=0.015884 \t val_loss=0.016364 \t time=0.78s\n",
      "Best model: Epoch 25 \t loss=0.015544 \t val_loss=0.016352 \t time=0.74s\n",
      "Best model: Epoch 29 \t loss=0.015347 \t val_loss=0.016344 \t time=0.97s\n",
      "Best model: Epoch 30 \t loss=0.015194 \t val_loss=0.016339 \t time=0.76s\n",
      "Best model: Epoch 32 \t loss=0.015125 \t val_loss=0.016307 \t time=0.74s\n",
      "Best model: Epoch 33 \t loss=0.015079 \t val_loss=0.016284 \t time=0.75s\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 38 \t loss=0.014279 \t val_loss=0.016132 \t time=1.42s\n",
      "Best model: Epoch 39 \t loss=0.014007 \t val_loss=0.016094 \t time=0.88s\n",
      "Best model: Epoch 40 \t loss=0.013807 \t val_loss=0.016045 \t time=0.76s\n",
      "Fold 1 log loss: 0.01613870239044807\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.410332 \t val_loss=0.073364 \t time=0.78s\n",
      "Best model: Epoch 2 \t loss=0.049607 \t val_loss=0.029615 \t time=0.75s\n",
      "Best model: Epoch 3 \t loss=0.027660 \t val_loss=0.022587 \t time=0.77s\n",
      "Best model: Epoch 4 \t loss=0.022936 \t val_loss=0.020799 \t time=0.76s\n",
      "Best model: Epoch 5 \t loss=0.021291 \t val_loss=0.019719 \t time=0.80s\n",
      "Best model: Epoch 6 \t loss=0.020871 \t val_loss=0.019298 \t time=0.77s\n",
      "Best model: Epoch 7 \t loss=0.019983 \t val_loss=0.018678 \t time=0.76s\n",
      "Best model: Epoch 8 \t loss=0.019310 \t val_loss=0.018323 \t time=1.03s\n",
      "Best model: Epoch 9 \t loss=0.018906 \t val_loss=0.018065 \t time=0.76s\n",
      "Best model: Epoch 10 \t loss=0.018543 \t val_loss=0.017762 \t time=0.75s\n",
      "Best model: Epoch 11 \t loss=0.018248 \t val_loss=0.017621 \t time=0.76s\n",
      "Best model: Epoch 12 \t loss=0.017938 \t val_loss=0.017368 \t time=0.94s\n",
      "Best model: Epoch 13 \t loss=0.017660 \t val_loss=0.017269 \t time=0.76s\n",
      "Best model: Epoch 14 \t loss=0.017438 \t val_loss=0.017147 \t time=0.75s\n",
      "Best model: Epoch 16 \t loss=0.016962 \t val_loss=0.016846 \t time=0.74s\n",
      "Best model: Epoch 17 \t loss=0.016648 \t val_loss=0.016734 \t time=0.75s\n",
      "Best model: Epoch 18 \t loss=0.016563 \t val_loss=0.016679 \t time=0.74s\n",
      "Best model: Epoch 19 \t loss=0.016350 \t val_loss=0.016636 \t time=0.75s\n",
      "Best model: Epoch 20 \t loss=0.016227 \t val_loss=0.016519 \t time=0.75s\n",
      "Best model: Epoch 21 \t loss=0.016054 \t val_loss=0.016516 \t time=0.75s\n",
      "Best model: Epoch 22 \t loss=0.015906 \t val_loss=0.016433 \t time=0.76s\n",
      "Best model: Epoch 23 \t loss=0.015818 \t val_loss=0.016343 \t time=0.74s\n",
      "Best model: Epoch 25 \t loss=0.015633 \t val_loss=0.016327 \t time=0.74s\n",
      "Best model: Epoch 27 \t loss=0.015450 \t val_loss=0.016295 \t time=0.80s\n",
      "Best model: Epoch 29 \t loss=0.015328 \t val_loss=0.016283 \t time=0.79s\n",
      "Best model: Epoch 30 \t loss=0.015198 \t val_loss=0.016249 \t time=0.79s\n",
      "Best model: Epoch 31 \t loss=0.015239 \t val_loss=0.016237 \t time=0.79s\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 36 \t loss=0.014271 \t val_loss=0.016141 \t time=0.75s\n",
      "Best model: Epoch 37 \t loss=0.014006 \t val_loss=0.016065 \t time=0.75s\n",
      "Best model: Epoch 38 \t loss=0.013796 \t val_loss=0.016017 \t time=0.79s\n",
      "Best model: Epoch 40 \t loss=0.013474 \t val_loss=0.016016 \t time=0.80s\n",
      "Fold 2 log loss: 0.016073892210555486\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.414719 \t val_loss=0.081923 \t time=0.74s\n",
      "Best model: Epoch 2 \t loss=0.049673 \t val_loss=0.029961 \t time=0.74s\n",
      "Best model: Epoch 3 \t loss=0.026964 \t val_loss=0.022923 \t time=1.00s\n",
      "Best model: Epoch 4 \t loss=0.023271 \t val_loss=0.020805 \t time=0.75s\n",
      "Best model: Epoch 5 \t loss=0.021612 \t val_loss=0.020239 \t time=0.75s\n",
      "Best model: Epoch 6 \t loss=0.020568 \t val_loss=0.019249 \t time=0.74s\n",
      "Best model: Epoch 7 \t loss=0.019815 \t val_loss=0.018888 \t time=0.75s\n",
      "Best model: Epoch 8 \t loss=0.019414 \t val_loss=0.018561 \t time=0.77s\n",
      "Best model: Epoch 9 \t loss=0.018920 \t val_loss=0.018006 \t time=0.83s\n",
      "Best model: Epoch 10 \t loss=0.018604 \t val_loss=0.017764 \t time=0.87s\n",
      "Best model: Epoch 11 \t loss=0.018355 \t val_loss=0.017589 \t time=0.75s\n",
      "Best model: Epoch 12 \t loss=0.018151 \t val_loss=0.017536 \t time=0.74s\n",
      "Best model: Epoch 13 \t loss=0.017756 \t val_loss=0.017260 \t time=0.74s\n",
      "Best model: Epoch 14 \t loss=0.017614 \t val_loss=0.017092 \t time=0.76s\n",
      "Best model: Epoch 15 \t loss=0.017297 \t val_loss=0.016863 \t time=0.76s\n",
      "Best model: Epoch 16 \t loss=0.017331 \t val_loss=0.016783 \t time=0.75s\n",
      "Best model: Epoch 18 \t loss=0.016632 \t val_loss=0.016651 \t time=0.74s\n",
      "Best model: Epoch 19 \t loss=0.016518 \t val_loss=0.016525 \t time=0.74s\n",
      "Best model: Epoch 20 \t loss=0.016291 \t val_loss=0.016468 \t time=0.75s\n",
      "Best model: Epoch 21 \t loss=0.016164 \t val_loss=0.016441 \t time=0.75s\n",
      "Best model: Epoch 23 \t loss=0.015927 \t val_loss=0.016340 \t time=0.90s\n",
      "Best model: Epoch 26 \t loss=0.015608 \t val_loss=0.016272 \t time=0.76s\n",
      "Best model: Epoch 28 \t loss=0.015397 \t val_loss=0.016252 \t time=0.99s\n",
      "Best model: Epoch 29 \t loss=0.015333 \t val_loss=0.016219 \t time=0.79s\n",
      "Best model: Epoch 31 \t loss=0.015273 \t val_loss=0.016175 \t time=0.77s\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 36 \t loss=0.014449 \t val_loss=0.016048 \t time=0.78s\n",
      "Best model: Epoch 37 \t loss=0.014129 \t val_loss=0.015970 \t time=0.76s\n",
      "Best model: Epoch 38 \t loss=0.013926 \t val_loss=0.015959 \t time=0.75s\n",
      "Best model: Epoch 39 \t loss=0.013729 \t val_loss=0.015956 \t time=0.75s\n",
      "Fold 3 log loss: 0.015952558960805188\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.414718 \t val_loss=0.075926 \t time=0.77s\n",
      "Best model: Epoch 2 \t loss=0.049805 \t val_loss=0.028795 \t time=0.79s\n",
      "Best model: Epoch 3 \t loss=0.027463 \t val_loss=0.022582 \t time=0.78s\n",
      "Best model: Epoch 4 \t loss=0.023467 \t val_loss=0.021100 \t time=0.77s\n",
      "Best model: Epoch 5 \t loss=0.021805 \t val_loss=0.019896 \t time=0.88s\n",
      "Best model: Epoch 6 \t loss=0.020586 \t val_loss=0.018852 \t time=0.83s\n",
      "Best model: Epoch 7 \t loss=0.019782 \t val_loss=0.018380 \t time=0.79s\n",
      "Best model: Epoch 8 \t loss=0.019239 \t val_loss=0.018081 \t time=0.77s\n",
      "Best model: Epoch 9 \t loss=0.019007 \t val_loss=0.017919 \t time=0.77s\n",
      "Best model: Epoch 11 \t loss=0.018305 \t val_loss=0.017506 \t time=0.77s\n",
      "Best model: Epoch 12 \t loss=0.017971 \t val_loss=0.017193 \t time=0.76s\n",
      "Best model: Epoch 14 \t loss=0.017611 \t val_loss=0.016940 \t time=0.78s\n",
      "Best model: Epoch 15 \t loss=0.017278 \t val_loss=0.016863 \t time=0.76s\n",
      "Best model: Epoch 16 \t loss=0.017125 \t val_loss=0.016727 \t time=0.77s\n",
      "Best model: Epoch 17 \t loss=0.016897 \t val_loss=0.016586 \t time=0.76s\n",
      "Best model: Epoch 19 \t loss=0.016422 \t val_loss=0.016492 \t time=0.99s\n",
      "Best model: Epoch 20 \t loss=0.016286 \t val_loss=0.016350 \t time=0.76s\n",
      "Best model: Epoch 22 \t loss=0.016003 \t val_loss=0.016296 \t time=0.74s\n",
      "Best model: Epoch 23 \t loss=0.015896 \t val_loss=0.016281 \t time=0.77s\n",
      "Best model: Epoch 24 \t loss=0.015806 \t val_loss=0.016220 \t time=0.75s\n",
      "Best model: Epoch 25 \t loss=0.015607 \t val_loss=0.016186 \t time=0.74s\n",
      "Best model: Epoch 28 \t loss=0.015430 \t val_loss=0.016172 \t time=1.05s\n",
      "Best model: Epoch 29 \t loss=0.015312 \t val_loss=0.016134 \t time=0.75s\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 34 \t loss=0.014434 \t val_loss=0.016009 \t time=0.76s\n",
      "Best model: Epoch 35 \t loss=0.014165 \t val_loss=0.015967 \t time=0.75s\n",
      "Best model: Epoch 37 \t loss=0.013814 \t val_loss=0.015908 \t time=0.74s\n",
      "Best model: Epoch 40 \t loss=0.013397 \t val_loss=0.015898 \t time=0.74s\n",
      "Fold 4 log loss: 0.015948939304961968\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.415697 \t val_loss=0.082228 \t time=0.76s\n",
      "Best model: Epoch 2 \t loss=0.049981 \t val_loss=0.029454 \t time=0.75s\n",
      "Best model: Epoch 3 \t loss=0.027260 \t val_loss=0.023766 \t time=0.93s\n",
      "Best model: Epoch 4 \t loss=0.023032 \t val_loss=0.020659 \t time=0.75s\n",
      "Best model: Epoch 5 \t loss=0.021354 \t val_loss=0.019985 \t time=0.75s\n",
      "Best model: Epoch 6 \t loss=0.020510 \t val_loss=0.019201 \t time=0.74s\n",
      "Best model: Epoch 7 \t loss=0.019813 \t val_loss=0.019188 \t time=0.76s\n",
      "Best model: Epoch 8 \t loss=0.019493 \t val_loss=0.018305 \t time=0.75s\n",
      "Best model: Epoch 9 \t loss=0.018822 \t val_loss=0.018182 \t time=0.77s\n",
      "Best model: Epoch 10 \t loss=0.018489 \t val_loss=0.017831 \t time=0.75s\n",
      "Best model: Epoch 11 \t loss=0.018302 \t val_loss=0.017597 \t time=0.74s\n",
      "Best model: Epoch 12 \t loss=0.017960 \t val_loss=0.017490 \t time=1.06s\n",
      "Best model: Epoch 13 \t loss=0.017594 \t val_loss=0.017391 \t time=0.75s\n",
      "Best model: Epoch 14 \t loss=0.017443 \t val_loss=0.017176 \t time=0.78s\n",
      "Best model: Epoch 15 \t loss=0.017204 \t val_loss=0.017172 \t time=0.97s\n",
      "Best model: Epoch 16 \t loss=0.017048 \t val_loss=0.016947 \t time=0.95s\n",
      "Best model: Epoch 17 \t loss=0.016773 \t val_loss=0.016852 \t time=0.76s\n",
      "Best model: Epoch 18 \t loss=0.016614 \t val_loss=0.016789 \t time=0.77s\n",
      "Best model: Epoch 19 \t loss=0.016482 \t val_loss=0.016689 \t time=0.75s\n",
      "Best model: Epoch 21 \t loss=0.016150 \t val_loss=0.016547 \t time=0.84s\n",
      "Best model: Epoch 22 \t loss=0.015948 \t val_loss=0.016522 \t time=0.76s\n",
      "Best model: Epoch 23 \t loss=0.015857 \t val_loss=0.016506 \t time=0.78s\n",
      "Best model: Epoch 24 \t loss=0.015793 \t val_loss=0.016429 \t time=0.87s\n",
      "Best model: Epoch 25 \t loss=0.015700 \t val_loss=0.016411 \t time=0.93s\n",
      "Best model: Epoch 28 \t loss=0.015423 \t val_loss=0.016383 \t time=0.74s\n",
      "Best model: Epoch 29 \t loss=0.015453 \t val_loss=0.016379 \t time=0.92s\n",
      "Best model: Epoch 33 \t loss=0.015214 \t val_loss=0.016343 \t time=0.77s\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best model: Epoch 38 \t loss=0.014375 \t val_loss=0.016246 \t time=0.74s\n",
      "Best model: Epoch 39 \t loss=0.014056 \t val_loss=0.016164 \t time=0.75s\n",
      "Best model: Epoch 40 \t loss=0.013893 \t val_loss=0.016154 \t time=0.74s\n",
      "Fold 5 log loss: 0.016158120490028943\n",
      "Seed 40\n",
      "Fold 1 log loss: 0.01613870239044807\n",
      "Fold 2 log loss: 0.016073892210555486\n",
      "Fold 3 log loss: 0.015952558960805188\n",
      "Fold 4 log loss: 0.015948939304961968\n",
      "Fold 5 log loss: 0.016158120490028943\n",
      "Std of log loss: 8.914967831394768e-05\n",
      "Total log loss: 0.016054437061401947\n",
      "Total log loss: 0.015973822015281844\n"
     ]
    }
   ],
   "source": [
    "oof_final = np.zeros([len(n_train),fn_targets.shape[1]])\n",
    "pred_final = np.zeros([len(n_test),fn_targets.shape[1]])\n",
    "\n",
    "seeds = [10,40]\n",
    "for seed_ in seeds:\n",
    "    oof, oof_targets, pytorch_pred = modelling_torch(n_train, fn_targets, n_test, seed_, n_train.shape[1], fn_targets.shape[1], [])\n",
    "    oof_final += oof / len(seeds)\n",
    "    pred_final += pytorch_pred / len(seeds)\n",
    "print(\"Total log loss: {}\".format(mean_log_loss(oof_targets, oof_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T12:50:50.098316Z",
     "iopub.status.busy": "2020-10-11T12:50:50.097379Z",
     "iopub.status.idle": "2020-10-11T12:50:55.659848Z",
     "shell.execute_reply": "2020-10-11T12:50:55.659262Z"
    },
    "papermill": {
     "duration": 6.140399,
     "end_time": "2020-10-11T12:50:55.659985",
     "exception": false,
     "start_time": "2020-10-11T12:50:49.519586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF log loss:  0.014722156949332653\n"
     ]
    }
   ],
   "source": [
    "t = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "train_checkscore = t.copy()\n",
    "train_checkscore.loc[train_checkscore.index.isin(cons_train_index),target_feats] = oof_final\n",
    "train_checkscore.loc[train_checkscore.index.isin(noncons_train_index),target_feats] = 0\n",
    "t.drop(\"sig_id\", axis=1, inplace=True)\n",
    "print('OOF log loss: ', log_loss(np.ravel(t), np.ravel(np.array(train_checkscore.iloc[:,1:]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T12:50:56.784229Z",
     "iopub.status.busy": "2020-10-11T12:50:56.783119Z",
     "iopub.status.idle": "2020-10-11T12:50:59.363240Z",
     "shell.execute_reply": "2020-10-11T12:50:59.362489Z"
    },
    "papermill": {
     "duration": 3.139711,
     "end_time": "2020-10-11T12:50:59.363354",
     "exception": false,
     "start_time": "2020-10-11T12:50:56.223643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub[target_feats] = pred_final\n",
    "sub.loc[noncons_test_index,target_feats] = 0\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.550862,
     "end_time": "2020-10-11T12:51:00.467743",
     "exception": false,
     "start_time": "2020-10-11T12:50:59.916881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 1850.497287,
   "end_time": "2020-10-11T12:51:02.092426",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-11T12:20:11.595139",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
