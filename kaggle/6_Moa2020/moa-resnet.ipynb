{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023768,
     "end_time": "2020-11-13T12:09:32.860137",
     "exception": false,
     "start_time": "2020-11-13T12:09:32.836369",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- cpu\n",
    "- incorporate f selection method\n",
    "- change location of dropping features\n",
    "- batch size 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-13T12:09:32.916260Z",
     "iopub.status.busy": "2020-11-13T12:09:32.915220Z",
     "iopub.status.idle": "2020-11-13T12:09:44.732557Z",
     "shell.execute_reply": "2020-11-13T12:09:44.731654Z"
    },
    "papermill": {
     "duration": 11.850925,
     "end_time": "2020-11-13T12:09:44.732723",
     "exception": false,
     "start_time": "2020-11-13T12:09:32.881798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from umap import UMAP\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss,roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "sys.path.append('../input/multilabelstraifier/')\n",
    "from ml_stratifiers import MultilabelStratifiedKFold\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "from torch.nn.modules.loss import _WeightedLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T12:09:44.784606Z",
     "iopub.status.busy": "2020-11-13T12:09:44.783714Z",
     "iopub.status.idle": "2020-11-13T12:09:44.938197Z",
     "shell.execute_reply": "2020-11-13T12:09:44.937382Z"
    },
    "papermill": {
     "duration": 0.182154,
     "end_time": "2020-11-13T12:09:44.938355",
     "exception": false,
     "start_time": "2020-11-13T12:09:44.756201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_file_path = '../input/moapredictors/main_predictors.json'\n",
    "\n",
    "with open(json_file_path, 'r') as j:\n",
    "    predictors = json.loads(j.read())\n",
    "    predictors = predictors['start_predictors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-13T12:09:44.991118Z",
     "iopub.status.busy": "2020-11-13T12:09:44.990099Z",
     "iopub.status.idle": "2020-11-13T12:09:52.500791Z",
     "shell.execute_reply": "2020-11-13T12:09:52.499936Z"
    },
    "papermill": {
     "duration": 7.541697,
     "end_time": "2020-11-13T12:09:52.500927",
     "exception": false,
     "start_time": "2020-11-13T12:09:44.959230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/lish-moa/'\n",
    "train = pd.read_csv(DATA_DIR + 'train_features.csv')\n",
    "targets = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "non_targets = pd.read_csv(DATA_DIR + 'train_targets_nonscored.csv')\n",
    "test = pd.read_csv(DATA_DIR + 'test_features.csv')\n",
    "sub = pd.read_csv(DATA_DIR + 'sample_submission.csv')\n",
    "drug = pd.read_csv(DATA_DIR + 'train_drug.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T12:09:52.551147Z",
     "iopub.status.busy": "2020-11-13T12:09:52.550350Z",
     "iopub.status.idle": "2020-11-13T12:09:52.554015Z",
     "shell.execute_reply": "2020-11-13T12:09:52.553389Z"
    },
    "papermill": {
     "duration": 0.032094,
     "end_time": "2020-11-13T12:09:52.554160",
     "exception": false,
     "start_time": "2020-11-13T12:09:52.522066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_feats = [ i for i in targets.columns if i != \"sig_id\"]\n",
    "g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "c_feats = [i for i in train.columns if \"c-\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T12:09:52.608513Z",
     "iopub.status.busy": "2020-11-13T12:09:52.607597Z",
     "iopub.status.idle": "2020-11-13T12:09:52.756443Z",
     "shell.execute_reply": "2020-11-13T12:09:52.755708Z"
    },
    "papermill": {
     "duration": 0.180972,
     "end_time": "2020-11-13T12:09:52.756587",
     "exception": false,
     "start_time": "2020-11-13T12:09:52.575615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "noncons_train_index = train[train.cp_type==\"ctl_vehicle\"].index\n",
    "cons_train_index = train[train.cp_type!=\"ctl_vehicle\"].index\n",
    "noncons_test_index = test[test.cp_type==\"ctl_vehicle\"].index\n",
    "cons_test_index = test[test.cp_type!=\"ctl_vehicle\"].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021287,
     "end_time": "2020-11-13T12:09:52.799350",
     "exception": false,
     "start_time": "2020-11-13T12:09:52.778063",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T12:09:52.853419Z",
     "iopub.status.busy": "2020-11-13T12:09:52.852587Z",
     "iopub.status.idle": "2020-11-13T12:09:53.164033Z",
     "shell.execute_reply": "2020-11-13T12:09:53.163284Z"
    },
    "papermill": {
     "duration": 0.343694,
     "end_time": "2020-11-13T12:09:53.164172",
     "exception": false,
     "start_time": "2020-11-13T12:09:52.820478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train[train.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "test = test[test.index.isin(cons_test_index)].copy().reset_index(drop=True)\n",
    "targets = targets[targets.index.isin(cons_train_index)].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T12:09:53.230133Z",
     "iopub.status.busy": "2020-11-13T12:09:53.228833Z",
     "iopub.status.idle": "2020-11-13T12:09:54.019748Z",
     "shell.execute_reply": "2020-11-13T12:09:54.020349Z"
    },
    "papermill": {
     "duration": 0.834632,
     "end_time": "2020-11-13T12:09:54.020505",
     "exception": false,
     "start_time": "2020-11-13T12:09:53.185873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 6, 5, ..., 1, 1, 6]], dtype=int8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/c/lish-moa/discussion/195195\n",
    "NB_SPLITS = 7\n",
    "seed = 14\n",
    "\n",
    "folds = []\n",
    "    \n",
    "# LOAD FILES\n",
    "train_score = targets.merge(drug, on='sig_id', how='left') \n",
    "\n",
    "# LOCATE DRUGS\n",
    "vc = train_score.drug_id.value_counts()\n",
    "vc1 = vc.loc[(vc==6)|(vc==12)|(vc==18)].index.sort_values()\n",
    "vc2 = vc.loc[(vc!=6)&(vc!=12)&(vc!=18)].index.sort_values()\n",
    "\n",
    "# STRATIFY DRUGS 1000X OR LESS\n",
    "dct1 = {}; dct2 = {}\n",
    "skf = MultilabelStratifiedKFold(n_splits = NB_SPLITS, shuffle = True, random_state = seed)\n",
    "tmp = train_score.groupby('drug_id')[target_feats].mean().loc[vc1]\n",
    "for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_feats])):\n",
    "    dd = {k:fold for k in tmp.index[idxV].values}\n",
    "    dct1.update(dd)\n",
    "\n",
    "# STRATIFY DRUGS MORE THAN 18X\n",
    "skf = MultilabelStratifiedKFold(n_splits = NB_SPLITS, shuffle = True, random_state = seed)\n",
    "tmp = train_score.loc[train_score.drug_id.isin(vc2)].reset_index(drop = True)\n",
    "for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_feats])):\n",
    "    dd = {k:fold for k in tmp.sig_id[idxV].values}\n",
    "    dct2.update(dd)\n",
    "\n",
    "# ASSIGN FOLDS\n",
    "train_score['fold'] = train_score.drug_id.map(dct1)\n",
    "train_score.loc[train_score.fold.isna(),'fold'] = train_score.loc[train_score.fold.isna(),'sig_id'].map(dct2)\n",
    "train_score.fold = train_score.fold.astype('int8')\n",
    "folds.append(train_score.fold.values)\n",
    "    \n",
    "np.array(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022957,
     "end_time": "2020-11-13T12:09:54.066645",
     "exception": false,
     "start_time": "2020-11-13T12:09:54.043688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature enginnering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T12:09:54.128658Z",
     "iopub.status.busy": "2020-11-13T12:09:54.127872Z",
     "iopub.status.idle": "2020-11-13T12:09:55.152507Z",
     "shell.execute_reply": "2020-11-13T12:09:55.151843Z"
    },
    "papermill": {
     "duration": 1.061041,
     "end_time": "2020-11-13T12:09:55.152635",
     "exception": false,
     "start_time": "2020-11-13T12:09:54.091594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1e-14 1.0 0.1447830667695532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = pd.read_csv('../input/moa-feat-importance-rapids/output_source.csv')\n",
    "importance = importance.set_index(\"Feature\")\n",
    "\n",
    "imp_scaled = importance.copy(deep=True)\n",
    "for c in imp_scaled.columns:\n",
    "    imp_scaled[c] = (1 - preprocessing.MinMaxScaler().fit_transform(imp_scaled[[c]])).round(14)\n",
    "\n",
    "print(imp_scaled.min().min(), imp_scaled.max().max(), imp_scaled.std().mean())\n",
    "\n",
    "imp_scaled[\"MeanImp\"] = imp_scaled[target_feats].mean(axis=1)\n",
    "imp_scaled[\"MaxImp\"]  = imp_scaled[target_feats].max(axis=1)\n",
    "\n",
    "thresh_mean, thresh_max = 0.35, 0.975\n",
    "#fs_both = imp_scaled.loc[(imp_scaled.MeanImp >= thresh_mean) & (imp_scaled.MaxImp >= thresh_max), Targets]\n",
    "fs_any = list(imp_scaled.loc[(imp_scaled.MeanImp >= thresh_mean) | (imp_scaled.MaxImp >= thresh_max), target_feats].index)\n",
    "len(fs_any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T12:09:55.210762Z",
     "iopub.status.busy": "2020-11-13T12:09:55.209876Z",
     "iopub.status.idle": "2020-11-13T12:10:06.906489Z",
     "shell.execute_reply": "2020-11-13T12:10:06.905825Z"
    },
    "papermill": {
     "duration": 11.730018,
     "end_time": "2020-11-13T12:10:06.906632",
     "exception": false,
     "start_time": "2020-11-13T12:09:55.176614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rank gauss\n",
    "for i in c_feats + g_feats:\n",
    "    ss = preprocessing.QuantileTransformer(n_quantiles=500, random_state=0, output_distribution=\"normal\")\n",
    "    ss.fit(train[i].values.reshape(-1,1))\n",
    "    train[i] = ss.transform(train[i].values.reshape(-1,1))\n",
    "    test[i] = ss.transform(test[i].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T12:10:06.976698Z",
     "iopub.status.busy": "2020-11-13T12:10:06.975834Z",
     "iopub.status.idle": "2020-11-13T12:10:08.833316Z",
     "shell.execute_reply": "2020-11-13T12:10:08.833945Z"
    },
    "papermill": {
     "duration": 1.903757,
     "end_time": "2020-11-13T12:10:08.834100",
     "exception": false,
     "start_time": "2020-11-13T12:10:06.930343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_num = 10\n",
    "pca_c_cols = [\"pca-c\"+str(i+1) for i in range(c_num)]\n",
    "pca = PCA(n_components=c_num,random_state=42)\n",
    "c_train = pca.fit_transform(train[c_feats])\n",
    "c_test = pca.transform(test[c_feats])\n",
    "c_train = pd.DataFrame(c_train, columns=pca_c_cols)\n",
    "c_test = pd.DataFrame(c_test, columns=pca_c_cols)\n",
    "\n",
    "g_num = 60\n",
    "pca_g_cols = [\"pca-g\"+str(i+1) for i in range(g_num)]\n",
    "pca = PCA(n_components=g_num, random_state=42)\n",
    "g_train = pca.fit_transform(train[g_feats])\n",
    "g_test = pca.transform(test[g_feats])\n",
    "g_train = pd.DataFrame(g_train, columns=pca_g_cols)\n",
    "g_test = pd.DataFrame(g_test, columns=pca_g_cols)\n",
    "\n",
    "train = pd.concat([train, c_train],axis=1)\n",
    "test = pd.concat([test, c_test],axis=1)\n",
    "train = pd.concat([train, g_train],axis=1)\n",
    "test = pd.concat([test, g_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T12:10:08.899505Z",
     "iopub.status.busy": "2020-11-13T12:10:08.898646Z",
     "iopub.status.idle": "2020-11-13T12:10:09.063039Z",
     "shell.execute_reply": "2020-11-13T12:10:09.063703Z"
    },
    "papermill": {
     "duration": 0.203865,
     "end_time": "2020-11-13T12:10:09.063937",
     "exception": false,
     "start_time": "2020-11-13T12:10:08.860072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#X = train.iloc[:,4:].copy().values\n",
    "#select = VarianceThreshold(threshold=0.6)\n",
    "#X_new = select.fit_transform(X)\n",
    "#drop_feats = list(np.array(train.iloc[:,4:].columns)[select.get_support()==False])\n",
    "#len(drop_feats)\n",
    "\n",
    "drop_feats = [i for i in c_feats+g_feats if i not in fs_any]\n",
    "train.drop(drop_feats, axis=1, inplace=True)\n",
    "test.drop(drop_feats, axis=1, inplace=True)\n",
    "\n",
    "predictors = list(set(predictors) & set(fs_any))\n",
    "\n",
    "g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "c_feats = [i for i in train.columns if \"c-\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T12:10:09.123659Z",
     "iopub.status.busy": "2020-11-13T12:10:09.122261Z",
     "iopub.status.idle": "2020-11-13T12:10:09.605865Z",
     "shell.execute_reply": "2020-11-13T12:10:09.605167Z"
    },
    "papermill": {
     "duration": 0.518031,
     "end_time": "2020-11-13T12:10:09.605997",
     "exception": false,
     "start_time": "2020-11-13T12:10:09.087966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe(df):\n",
    "    tmp = df.copy()\n",
    "    tmp['g_kurt'] = tmp[g_feats].kurtosis(axis = 1)\n",
    "    tmp['g_skew'] = tmp[g_feats].skew(axis = 1)\n",
    "    tmp['c_kurt'] = tmp[c_feats].kurtosis(axis = 1)\n",
    "    tmp['c_skew'] = tmp[c_feats].skew(axis = 1)\n",
    "    tmp = pd.get_dummies(tmp, columns=['cp_time','cp_dose'])\n",
    "    tmp.drop([\"cp_type\", \"sig_id\"], axis=1, inplace=True) \n",
    "    return tmp\n",
    "\n",
    "train = fe(train)\n",
    "test = fe(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T12:10:09.661637Z",
     "iopub.status.busy": "2020-11-13T12:10:09.660688Z",
     "iopub.status.idle": "2020-11-13T12:10:09.665129Z",
     "shell.execute_reply": "2020-11-13T12:10:09.664500Z"
    },
    "papermill": {
     "duration": 0.035208,
     "end_time": "2020-11-13T12:10:09.665308",
     "exception": false,
     "start_time": "2020-11-13T12:10:09.630100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 266) (3624, 266)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T12:10:09.722626Z",
     "iopub.status.busy": "2020-11-13T12:10:09.721526Z",
     "iopub.status.idle": "2020-11-13T12:10:09.725471Z",
     "shell.execute_reply": "2020-11-13T12:10:09.724707Z"
    },
    "papermill": {
     "duration": 0.034861,
     "end_time": "2020-11-13T12:10:09.725605",
     "exception": false,
     "start_time": "2020-11-13T12:10:09.690744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[\"fold\"] = np.array(folds).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T12:10:09.781350Z",
     "iopub.status.busy": "2020-11-13T12:10:09.780561Z",
     "iopub.status.idle": "2020-11-13T12:10:09.830017Z",
     "shell.execute_reply": "2020-11-13T12:10:09.829364Z"
    },
    "papermill": {
     "duration": 0.079877,
     "end_time": "2020-11-13T12:10:09.830152",
     "exception": false,
     "start_time": "2020-11-13T12:10:09.750275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fn_train = train.copy()\n",
    "fn_test = test.copy()\n",
    "\n",
    "fn_targets = targets.drop(\"sig_id\", axis=1).copy().to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030454,
     "end_time": "2020-11-13T12:10:09.890963",
     "exception": false,
     "start_time": "2020-11-13T12:10:09.860509",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T12:10:09.968096Z",
     "iopub.status.busy": "2020-11-13T12:10:09.967264Z",
     "iopub.status.idle": "2020-11-13T12:10:09.970957Z",
     "shell.execute_reply": "2020-11-13T12:10:09.971757Z"
    },
    "papermill": {
     "duration": 0.047963,
     "end_time": "2020-11-13T12:10:09.971927",
     "exception": false,
     "start_time": "2020-11-13T12:10:09.923964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SmoothCrossEntropyLoss(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets, n_classes, smoothing=0.0):\n",
    "        assert 0 <= smoothing <= 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1 - smoothing) + torch.ones_like(targets).to(device) * smoothing / n_classes\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothCrossEntropyLoss()._smooth(targets, inputs.shape[1], self.smoothing)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            inputs = inputs * self.weight.unsqueeze(0)\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T12:10:10.048891Z",
     "iopub.status.busy": "2020-11-13T12:10:10.038565Z",
     "iopub.status.idle": "2020-11-13T12:10:10.068449Z",
     "shell.execute_reply": "2020-11-13T12:10:10.067784Z"
    },
    "papermill": {
     "duration": 0.064572,
     "end_time": "2020-11-13T12:10:10.068578",
     "exception": false,
     "start_time": "2020-11-13T12:10:10.004006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(device)\n",
    "def mean_log_loss(y_true, y_pred):\n",
    "    metrics = []\n",
    "    for i, target in enumerate(target_feats):\n",
    "        metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float), labels=[0,1]))\n",
    "    return np.mean(metrics)\n",
    "\n",
    "def seed_everything(seed=42): \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "class MoaModel(nn.Module):\n",
    "    def __init__(self, num_columns, last_num):\n",
    "        super(MoaModel, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_columns)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dense1 = nn.Linear(num_columns, 512)\n",
    "        self.relu1 = nn.ELU()\n",
    "        self.dense12 = nn.Linear(512, 256)\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(256+len(predictors))\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.dense2 = nn.Linear(256+len(predictors), 512)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.batch_norm22 = nn.BatchNorm1d(512)\n",
    "        self.dense22 = nn.Linear(512, 512)\n",
    "        self.relu22 = nn.ELU()\n",
    "        self.batch_norm23 = nn.BatchNorm1d(512)\n",
    "        self.dense23 = nn.Linear(512, 256)\n",
    "        self.relu23 = nn.ReLU()\n",
    "        self.batch_norm24 = nn.BatchNorm1d(256)\n",
    "        self.dense24 = nn.Linear(256, 256)\n",
    "        self.relu24 = nn.ELU()\n",
    "                \n",
    "        self.batch_norm3 = nn.BatchNorm1d(256)\n",
    "        self.dense3 = nn.Linear(256, 256)\n",
    "        self.relu3 = nn.SELU()\n",
    "        self.batch_norm32 = nn.BatchNorm1d(256)\n",
    "        self.dense32 = nn.Linear(256, last_num)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.batch_norm1(x1)\n",
    "        x1 = self.dropout1(x1)\n",
    "        x1 = self.relu1(self.dense1(x1))\n",
    "        x1 = self.dense12(x1)\n",
    "        \n",
    "        x3 = torch.cat([x1,x2],axis=1)\n",
    "                \n",
    "        x3 = self.batch_norm2(x3)\n",
    "        x3 = self.dropout2(x3)\n",
    "        x3 = self.relu2(self.dense2(x3))\n",
    "        x3 = self.batch_norm22(x3)\n",
    "        x3 = self.relu22(self.dense22(x3))\n",
    "        x3 = self.batch_norm23(x3)\n",
    "        x3 = self.relu23(self.dense23(x3))\n",
    "        x3 = self.batch_norm24(x3)\n",
    "        x3 = self.relu24(self.dense24(x3))\n",
    "        \n",
    "        x4 = (x1 + x3) / 2\n",
    "        \n",
    "        x4 = self.batch_norm3(x4)\n",
    "        x4 = self.relu3(self.dense3(x4))\n",
    "        x4 = self.batch_norm32(x4)\n",
    "        x4 = self.dense32(x4)\n",
    "        \n",
    "        return x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T12:10:10.140114Z",
     "iopub.status.busy": "2020-11-13T12:10:10.129381Z",
     "iopub.status.idle": "2020-11-13T12:10:10.181631Z",
     "shell.execute_reply": "2020-11-13T12:10:10.182369Z"
    },
    "papermill": {
     "duration": 0.08816,
     "end_time": "2020-11-13T12:10:10.182549",
     "exception": false,
     "start_time": "2020-11-13T12:10:10.094389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "n_folds=7\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "smoothing = 0.001\n",
    "p_min = smoothing\n",
    "p_max = 1 - smoothing\n",
    "\n",
    "def torch_tl(tr, target, te, sample_seed, init_num):\n",
    "    seed_everything(seed=sample_seed) \n",
    "    test_len = te.shape[0]\n",
    "    \n",
    "    train_epochs = 20\n",
    "        \n",
    "    metric = lambda inputs, targets : F.binary_cross_entropy((torch.clamp(torch.sigmoid(inputs), p_min, p_max)), targets)\n",
    "    models = []\n",
    "    \n",
    "    X_test = torch.tensor(te.values, dtype=torch.float32)\n",
    "    X_test2 = torch.tensor(te.iloc[:][predictors].values, dtype=torch.float32)\n",
    "    test = torch.utils.data.TensorDataset(X_test, X_test2) \n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    oof = np.zeros([len(tr),target.shape[1]])\n",
    "    oof_targets = np.zeros([len(tr),target.shape[1]])\n",
    "    pred_value = np.zeros([test_len, target.shape[1]])\n",
    "    scores = []\n",
    "    for fold in range(n_folds):\n",
    "        valid_index = tr[\"fold\"] == fold\n",
    "        train_index = tr[\"fold\"] != fold\n",
    "        print(\"Fold \"+str(fold+1))\n",
    "        X_train1 = torch.tensor(tr[train_index].values, dtype=torch.float32)\n",
    "        X_valid1 = torch.tensor(tr[valid_index].values, dtype=torch.float32)\n",
    "        X_train2 = torch.tensor(tr[train_index][predictors].values, dtype=torch.float32)\n",
    "        X_valid2 = torch.tensor(tr[valid_index][predictors].values, dtype=torch.float32)\n",
    "        \n",
    "        y_train2 = torch.tensor(target[train_index], dtype=torch.float32)\n",
    "        y_valid2 = torch.tensor(target[valid_index], dtype=torch.float32)\n",
    "        \n",
    "        X_train1 = X_train1[:,:-1]\n",
    "        X_valid1 = X_valid1[:,:-1]\n",
    "        \n",
    "        train = torch.utils.data.TensorDataset(X_train1, X_train2, y_train2)\n",
    "        valid = torch.utils.data.TensorDataset(X_valid1, X_valid2, y_valid2)\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True) \n",
    "        valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "            \n",
    "        clf = MoaModel(init_num, len(target_feats))\n",
    "\n",
    "        loss_fn = SmoothCrossEntropyLoss(smoothing=smoothing)\n",
    "            \n",
    "        optimizer = optim.Adam(clf.parameters(), lr = 0.01, weight_decay=1e-5) \n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=train_epochs, steps_per_epoch=len(train_loader))                   \n",
    "       \n",
    "        clf.to(device)\n",
    "        best_val_loss = np.inf\n",
    "        stop_counts = 0\n",
    "        \n",
    "        for epoch in range(train_epochs):\n",
    "            start_time = time.time()\n",
    "            clf.train()\n",
    "            avg_loss = 0.\n",
    "            sm_avg_loss = 0.\n",
    "            for x_batch, x_batch2, y_batch in tqdm(train_loader, disable=True):\n",
    "                x_batch = x_batch.to(device)\n",
    "                x_batch2 = x_batch2.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch, x_batch2) \n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                avg_loss += loss.item() / len(train_loader)  \n",
    "                sm_avg_loss += metric(y_pred, y_batch) / len(train_loader)      \n",
    "            \n",
    "            clf.eval()\n",
    "            avg_val_loss = 0.\n",
    "            sm_avg_val_loss = 0.\n",
    "            \n",
    "            for i, (x_batch, x_batch2, y_batch) in enumerate(valid_loader): \n",
    "                x_batch = x_batch.to(device)\n",
    "                x_batch2 = x_batch2.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch, x_batch2).detach()\n",
    "                avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "                sm_avg_val_loss += metric(y_pred, y_batch) / len(valid_loader)\n",
    "                \n",
    "            elapsed_time = time.time() - start_time\n",
    "                    \n",
    "            if sm_avg_val_loss < best_val_loss:\n",
    "                best_val_loss = sm_avg_val_loss\n",
    "                print('Epoch {}  loss={:.5f}  val_loss={:.5f}  sm_loss={:.5f}  sm_val_loss={:.5f}  time={:.2f}s'.format(\n",
    "                    epoch + 1, avg_loss, avg_val_loss, sm_avg_loss, sm_avg_val_loss, elapsed_time))\n",
    "                torch.save(clf.state_dict(), 'best-model-parameters.pt')\n",
    "                \n",
    "        pred_model = MoaModel(init_num, len(target_feats))\n",
    "        pred_model.load_state_dict(torch.load('best-model-parameters.pt'))         \n",
    "        pred_model.eval()\n",
    "        \n",
    "        # validation check ----------------\n",
    "        oof_epoch = np.zeros([X_valid2.size(0), target.shape[1]])\n",
    "        target_epoch = np.zeros([X_valid2.size(0), target.shape[1]])\n",
    "        for i, (x_batch, x_batch2, y_batch) in enumerate(valid_loader): \n",
    "            y_pred = pred_model(x_batch, x_batch2).detach()\n",
    "            oof_epoch[i * batch_size:(i+1) * batch_size,:] = torch.clamp(torch.sigmoid(y_pred.cpu()), p_min, p_max)\n",
    "            target_epoch[i * batch_size:(i+1) * batch_size,:] = y_batch.cpu().numpy()\n",
    "        print(\"Fold {} log loss: {}\".format(fold+1, mean_log_loss(target_epoch, oof_epoch)))\n",
    "        scores.append(mean_log_loss(target_epoch, oof_epoch))\n",
    "        oof[valid_index,:] = oof_epoch\n",
    "        oof_targets[valid_index,:] = target_epoch\n",
    "        #-----------------------------------\n",
    "        \n",
    "\n",
    "        # test predcition --------------\n",
    "        test_preds = np.zeros([test_len, target.shape[1]])\n",
    "        for i, (x_batch,x_batch2,) in enumerate(test_loader): \n",
    "            y_pred = pred_model(x_batch,x_batch2).detach()\n",
    "            test_preds[i * batch_size:(i+1) * batch_size, :] = torch.clamp(torch.sigmoid(y_pred.cpu()), p_min, p_max)\n",
    "        pred_value += test_preds / n_folds\n",
    "        # ------------------------------\n",
    "    \n",
    "    print(\"Seed {}\".format(sample_seed))\n",
    "    for i, ele in enumerate(scores):\n",
    "        print(\"Fold {} log loss: {}\".format(i+1, scores[i]))\n",
    "    print(\"Std of log loss: {}\".format(np.std(scores)))\n",
    "    print(\"Total log loss: {}\".format(mean_log_loss(oof_targets, oof)))\n",
    "    \n",
    "    return oof, oof_targets, pred_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T12:10:10.254466Z",
     "iopub.status.busy": "2020-11-13T12:10:10.253292Z",
     "iopub.status.idle": "2020-11-13T13:03:52.073288Z",
     "shell.execute_reply": "2020-11-13T13:03:52.072607Z"
    },
    "papermill": {
     "duration": 3221.855871,
     "end_time": "2020-11-13T13:03:52.073444",
     "exception": false,
     "start_time": "2020-11-13T12:10:10.217573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1  loss=0.55929  val_loss=0.03072  sm_loss=0.55929  sm_val_loss=0.03072  time=4.54s\n",
      "Epoch 2  loss=0.02074  val_loss=0.01900  sm_loss=0.02071  sm_val_loss=0.01902  time=4.28s\n",
      "Epoch 3  loss=0.01833  val_loss=0.01808  sm_loss=0.01840  sm_val_loss=0.01814  time=4.36s\n",
      "Epoch 4  loss=0.01783  val_loss=0.01784  sm_loss=0.01791  sm_val_loss=0.01790  time=4.31s\n",
      "Epoch 5  loss=0.01763  val_loss=0.01781  sm_loss=0.01772  sm_val_loss=0.01785  time=5.00s\n",
      "Epoch 6  loss=0.01752  val_loss=0.01750  sm_loss=0.01762  sm_val_loss=0.01758  time=4.69s\n",
      "Epoch 9  loss=0.01711  val_loss=0.01733  sm_loss=0.01724  sm_val_loss=0.01741  time=4.38s\n",
      "Epoch 11  loss=0.01683  val_loss=0.01721  sm_loss=0.01697  sm_val_loss=0.01730  time=4.32s\n",
      "Epoch 12  loss=0.01671  val_loss=0.01718  sm_loss=0.01686  sm_val_loss=0.01727  time=4.69s\n",
      "Epoch 13  loss=0.01651  val_loss=0.01713  sm_loss=0.01667  sm_val_loss=0.01719  time=4.42s\n",
      "Epoch 14  loss=0.01636  val_loss=0.01710  sm_loss=0.01653  sm_val_loss=0.01716  time=4.26s\n",
      "Epoch 15  loss=0.01623  val_loss=0.01705  sm_loss=0.01640  sm_val_loss=0.01711  time=4.35s\n",
      "Epoch 16  loss=0.01601  val_loss=0.01693  sm_loss=0.01619  sm_val_loss=0.01699  time=4.25s\n",
      "Epoch 19  loss=0.01564  val_loss=0.01692  sm_loss=0.01583  sm_val_loss=0.01699  time=4.67s\n",
      "Fold 1 log loss: 0.017066132580480026\n",
      "Fold 2\n",
      "Epoch 1  loss=0.55910  val_loss=0.02902  sm_loss=0.55910  sm_val_loss=0.02902  time=4.24s\n",
      "Epoch 2  loss=0.02056  val_loss=0.01907  sm_loss=0.02048  sm_val_loss=0.01908  time=4.30s\n",
      "Epoch 3  loss=0.01832  val_loss=0.01837  sm_loss=0.01839  sm_val_loss=0.01842  time=4.26s\n",
      "Epoch 4  loss=0.01778  val_loss=0.01837  sm_loss=0.01787  sm_val_loss=0.01840  time=4.32s\n",
      "Epoch 5  loss=0.01769  val_loss=0.01829  sm_loss=0.01778  sm_val_loss=0.01834  time=4.51s\n",
      "Epoch 6  loss=0.01750  val_loss=0.01797  sm_loss=0.01760  sm_val_loss=0.01802  time=4.47s\n",
      "Epoch 7  loss=0.01749  val_loss=0.01779  sm_loss=0.01760  sm_val_loss=0.01786  time=4.79s\n",
      "Epoch 9  loss=0.01714  val_loss=0.01766  sm_loss=0.01725  sm_val_loss=0.01773  time=4.35s\n",
      "Epoch 10  loss=0.01707  val_loss=0.01766  sm_loss=0.01719  sm_val_loss=0.01771  time=4.59s\n",
      "Epoch 12  loss=0.01680  val_loss=0.01746  sm_loss=0.01694  sm_val_loss=0.01754  time=4.86s\n",
      "Epoch 14  loss=0.01654  val_loss=0.01733  sm_loss=0.01668  sm_val_loss=0.01740  time=4.87s\n",
      "Epoch 15  loss=0.01638  val_loss=0.01731  sm_loss=0.01653  sm_val_loss=0.01738  time=4.28s\n",
      "Epoch 16  loss=0.01623  val_loss=0.01722  sm_loss=0.01638  sm_val_loss=0.01729  time=4.26s\n",
      "Epoch 17  loss=0.01610  val_loss=0.01721  sm_loss=0.01625  sm_val_loss=0.01728  time=4.74s\n",
      "Epoch 19  loss=0.01594  val_loss=0.01720  sm_loss=0.01609  sm_val_loss=0.01727  time=4.60s\n",
      "Epoch 20  loss=0.01584  val_loss=0.01717  sm_loss=0.01600  sm_val_loss=0.01724  time=4.32s\n",
      "Fold 2 log loss: 0.017162678502918687\n",
      "Fold 3\n",
      "Epoch 1  loss=0.55843  val_loss=0.03499  sm_loss=0.55842  sm_val_loss=0.03498  time=4.74s\n",
      "Epoch 2  loss=0.02052  val_loss=0.01946  sm_loss=0.02047  sm_val_loss=0.01950  time=4.31s\n",
      "Epoch 3  loss=0.01820  val_loss=0.01896  sm_loss=0.01829  sm_val_loss=0.01898  time=4.35s\n",
      "Epoch 4  loss=0.01772  val_loss=0.01861  sm_loss=0.01781  sm_val_loss=0.01864  time=4.60s\n",
      "Epoch 5  loss=0.01750  val_loss=0.01847  sm_loss=0.01761  sm_val_loss=0.01852  time=4.69s\n",
      "Epoch 6  loss=0.01738  val_loss=0.01811  sm_loss=0.01749  sm_val_loss=0.01818  time=4.79s\n",
      "Epoch 7  loss=0.01721  val_loss=0.01812  sm_loss=0.01732  sm_val_loss=0.01817  time=4.35s\n",
      "Epoch 8  loss=0.01705  val_loss=0.01794  sm_loss=0.01718  sm_val_loss=0.01798  time=4.64s\n",
      "Epoch 11  loss=0.01666  val_loss=0.01786  sm_loss=0.01681  sm_val_loss=0.01790  time=4.45s\n",
      "Epoch 12  loss=0.01652  val_loss=0.01780  sm_loss=0.01667  sm_val_loss=0.01784  time=4.40s\n",
      "Epoch 14  loss=0.01620  val_loss=0.01767  sm_loss=0.01636  sm_val_loss=0.01772  time=4.64s\n",
      "Epoch 15  loss=0.01604  val_loss=0.01756  sm_loss=0.01622  sm_val_loss=0.01763  time=4.63s\n",
      "Epoch 16  loss=0.01586  val_loss=0.01755  sm_loss=0.01604  sm_val_loss=0.01761  time=5.42s\n",
      "Epoch 17  loss=0.01576  val_loss=0.01749  sm_loss=0.01594  sm_val_loss=0.01755  time=4.58s\n",
      "Epoch 18  loss=0.01559  val_loss=0.01748  sm_loss=0.01578  sm_val_loss=0.01753  time=5.01s\n",
      "Epoch 19  loss=0.01546  val_loss=0.01748  sm_loss=0.01565  sm_val_loss=0.01753  time=4.74s\n",
      "Epoch 20  loss=0.01543  val_loss=0.01747  sm_loss=0.01562  sm_val_loss=0.01752  time=4.48s\n",
      "Fold 3 log loss: 0.017532982991385407\n",
      "Fold 4\n",
      "Epoch 1  loss=0.55812  val_loss=0.02703  sm_loss=0.55812  sm_val_loss=0.02703  time=4.51s\n",
      "Epoch 2  loss=0.02140  val_loss=0.01988  sm_loss=0.02132  sm_val_loss=0.01992  time=4.83s\n",
      "Epoch 3  loss=0.01889  val_loss=0.01869  sm_loss=0.01895  sm_val_loss=0.01873  time=4.53s\n",
      "Epoch 4  loss=0.01822  val_loss=0.01799  sm_loss=0.01829  sm_val_loss=0.01804  time=4.56s\n",
      "Epoch 6  loss=0.01769  val_loss=0.01775  sm_loss=0.01779  sm_val_loss=0.01780  time=6.19s\n",
      "Epoch 7  loss=0.01750  val_loss=0.01752  sm_loss=0.01761  sm_val_loss=0.01755  time=4.73s\n",
      "Epoch 11  loss=0.01684  val_loss=0.01724  sm_loss=0.01699  sm_val_loss=0.01726  time=4.77s\n",
      "Epoch 12  loss=0.01670  val_loss=0.01725  sm_loss=0.01686  sm_val_loss=0.01723  time=4.61s\n",
      "Epoch 13  loss=0.01648  val_loss=0.01715  sm_loss=0.01664  sm_val_loss=0.01717  time=4.57s\n",
      "Epoch 14  loss=0.01637  val_loss=0.01704  sm_loss=0.01653  sm_val_loss=0.01705  time=4.58s\n",
      "Epoch 15  loss=0.01620  val_loss=0.01697  sm_loss=0.01638  sm_val_loss=0.01699  time=5.00s\n",
      "Epoch 16  loss=0.01606  val_loss=0.01697  sm_loss=0.01624  sm_val_loss=0.01698  time=4.94s\n",
      "Epoch 17  loss=0.01591  val_loss=0.01690  sm_loss=0.01610  sm_val_loss=0.01691  time=4.48s\n",
      "Epoch 18  loss=0.01576  val_loss=0.01686  sm_loss=0.01595  sm_val_loss=0.01688  time=4.72s\n",
      "Epoch 19  loss=0.01568  val_loss=0.01686  sm_loss=0.01587  sm_val_loss=0.01687  time=4.71s\n",
      "Epoch 20  loss=0.01561  val_loss=0.01685  sm_loss=0.01580  sm_val_loss=0.01686  time=4.51s\n",
      "Fold 4 log loss: 0.01702869590049323\n",
      "Fold 5\n",
      "Epoch 1  loss=0.55641  val_loss=0.02984  sm_loss=0.55641  sm_val_loss=0.02983  time=4.49s\n",
      "Epoch 2  loss=0.02055  val_loss=0.01949  sm_loss=0.02051  sm_val_loss=0.01950  time=5.13s\n",
      "Epoch 3  loss=0.01826  val_loss=0.01855  sm_loss=0.01833  sm_val_loss=0.01858  time=4.85s\n",
      "Epoch 4  loss=0.01770  val_loss=0.01823  sm_loss=0.01779  sm_val_loss=0.01827  time=4.52s\n",
      "Epoch 5  loss=0.01758  val_loss=0.01817  sm_loss=0.01767  sm_val_loss=0.01818  time=4.54s\n",
      "Epoch 7  loss=0.01727  val_loss=0.01782  sm_loss=0.01739  sm_val_loss=0.01787  time=4.31s\n",
      "Epoch 11  loss=0.01678  val_loss=0.01776  sm_loss=0.01693  sm_val_loss=0.01780  time=4.33s\n",
      "Epoch 12  loss=0.01671  val_loss=0.01759  sm_loss=0.01686  sm_val_loss=0.01761  time=4.37s\n",
      "Epoch 13  loss=0.01650  val_loss=0.01752  sm_loss=0.01665  sm_val_loss=0.01758  time=4.38s\n",
      "Epoch 14  loss=0.01633  val_loss=0.01747  sm_loss=0.01649  sm_val_loss=0.01749  time=4.34s\n",
      "Epoch 15  loss=0.01617  val_loss=0.01731  sm_loss=0.01634  sm_val_loss=0.01735  time=4.69s\n",
      "Epoch 16  loss=0.01603  val_loss=0.01728  sm_loss=0.01621  sm_val_loss=0.01733  time=4.59s\n",
      "Epoch 17  loss=0.01589  val_loss=0.01721  sm_loss=0.01607  sm_val_loss=0.01726  time=4.89s\n",
      "Fold 5 log loss: 0.01729235419719458\n",
      "Fold 6\n",
      "Epoch 1  loss=0.55840  val_loss=0.03334  sm_loss=0.55840  sm_val_loss=0.03333  time=4.38s\n",
      "Epoch 2  loss=0.02066  val_loss=0.01938  sm_loss=0.02060  sm_val_loss=0.01928  time=4.73s\n",
      "Epoch 3  loss=0.01840  val_loss=0.01864  sm_loss=0.01847  sm_val_loss=0.01868  time=4.70s\n",
      "Epoch 4  loss=0.01786  val_loss=0.01848  sm_loss=0.01794  sm_val_loss=0.01852  time=5.07s\n",
      "Epoch 5  loss=0.01763  val_loss=0.01820  sm_loss=0.01772  sm_val_loss=0.01818  time=4.40s\n",
      "Epoch 6  loss=0.01745  val_loss=0.01772  sm_loss=0.01755  sm_val_loss=0.01778  time=4.39s\n",
      "Epoch 8  loss=0.01720  val_loss=0.01767  sm_loss=0.01731  sm_val_loss=0.01769  time=4.65s\n",
      "Epoch 12  loss=0.01662  val_loss=0.01752  sm_loss=0.01676  sm_val_loss=0.01753  time=4.40s\n",
      "Epoch 13  loss=0.01645  val_loss=0.01749  sm_loss=0.01660  sm_val_loss=0.01748  time=4.42s\n",
      "Epoch 14  loss=0.01636  val_loss=0.01738  sm_loss=0.01652  sm_val_loss=0.01740  time=4.46s\n",
      "Epoch 15  loss=0.01614  val_loss=0.01722  sm_loss=0.01630  sm_val_loss=0.01723  time=4.37s\n",
      "Epoch 16  loss=0.01600  val_loss=0.01716  sm_loss=0.01617  sm_val_loss=0.01717  time=4.49s\n",
      "Epoch 18  loss=0.01571  val_loss=0.01714  sm_loss=0.01589  sm_val_loss=0.01714  time=4.92s\n",
      "Epoch 20  loss=0.01560  val_loss=0.01714  sm_loss=0.01577  sm_val_loss=0.01714  time=4.50s\n",
      "Fold 6 log loss: 0.017270186663232486\n",
      "Fold 7\n",
      "Epoch 1  loss=0.55580  val_loss=0.03372  sm_loss=0.55580  sm_val_loss=0.03371  time=5.29s\n",
      "Epoch 2  loss=0.02080  val_loss=0.01933  sm_loss=0.02073  sm_val_loss=0.01939  time=4.85s\n",
      "Epoch 3  loss=0.01842  val_loss=0.01802  sm_loss=0.01850  sm_val_loss=0.01808  time=4.74s\n",
      "Epoch 5  loss=0.01766  val_loss=0.01788  sm_loss=0.01775  sm_val_loss=0.01793  time=5.04s\n",
      "Epoch 6  loss=0.01743  val_loss=0.01773  sm_loss=0.01753  sm_val_loss=0.01779  time=4.54s\n",
      "Epoch 7  loss=0.01728  val_loss=0.01751  sm_loss=0.01739  sm_val_loss=0.01758  time=4.49s\n",
      "Epoch 8  loss=0.01715  val_loss=0.01746  sm_loss=0.01727  sm_val_loss=0.01751  time=4.55s\n",
      "Epoch 11  loss=0.01684  val_loss=0.01733  sm_loss=0.01698  sm_val_loss=0.01737  time=4.62s\n",
      "Epoch 12  loss=0.01668  val_loss=0.01727  sm_loss=0.01682  sm_val_loss=0.01734  time=4.92s\n",
      "Epoch 13  loss=0.01655  val_loss=0.01724  sm_loss=0.01670  sm_val_loss=0.01729  time=4.63s\n",
      "Epoch 15  loss=0.01627  val_loss=0.01712  sm_loss=0.01642  sm_val_loss=0.01717  time=4.96s\n",
      "Epoch 16  loss=0.01613  val_loss=0.01707  sm_loss=0.01628  sm_val_loss=0.01713  time=4.66s\n",
      "Epoch 17  loss=0.01599  val_loss=0.01696  sm_loss=0.01615  sm_val_loss=0.01702  time=4.59s\n",
      "Fold 7 log loss: 0.017291358755763875\n",
      "Seed 0\n",
      "Fold 1 log loss: 0.017066132580480026\n",
      "Fold 2 log loss: 0.017162678502918687\n",
      "Fold 3 log loss: 0.017532982991385407\n",
      "Fold 4 log loss: 0.01702869590049323\n",
      "Fold 5 log loss: 0.01729235419719458\n",
      "Fold 6 log loss: 0.017270186663232486\n",
      "Fold 7 log loss: 0.017291358755763875\n",
      "Std of log loss: 0.0001571194769557175\n",
      "Total log loss: 0.01723520361131705\n",
      "Fold 1\n",
      "Epoch 1  loss=0.55925  val_loss=0.02976  sm_loss=0.55925  sm_val_loss=0.02975  time=4.53s\n",
      "Epoch 2  loss=0.02055  val_loss=0.01893  sm_loss=0.02050  sm_val_loss=0.01896  time=4.47s\n",
      "Epoch 3  loss=0.01843  val_loss=0.01845  sm_loss=0.01852  sm_val_loss=0.01849  time=4.46s\n",
      "Epoch 4  loss=0.01788  val_loss=0.01780  sm_loss=0.01797  sm_val_loss=0.01785  time=4.52s\n",
      "Epoch 7  loss=0.01735  val_loss=0.01756  sm_loss=0.01746  sm_val_loss=0.01764  time=4.77s\n",
      "Epoch 9  loss=0.01716  val_loss=0.01755  sm_loss=0.01729  sm_val_loss=0.01761  time=4.50s\n",
      "Epoch 10  loss=0.01705  val_loss=0.01727  sm_loss=0.01718  sm_val_loss=0.01736  time=4.40s\n",
      "Epoch 13  loss=0.01658  val_loss=0.01711  sm_loss=0.01673  sm_val_loss=0.01720  time=4.84s\n",
      "Epoch 15  loss=0.01634  val_loss=0.01700  sm_loss=0.01650  sm_val_loss=0.01708  time=4.42s\n",
      "Epoch 16  loss=0.01617  val_loss=0.01699  sm_loss=0.01634  sm_val_loss=0.01707  time=4.53s\n",
      "Epoch 17  loss=0.01604  val_loss=0.01687  sm_loss=0.01621  sm_val_loss=0.01695  time=4.39s\n",
      "Fold 1 log loss: 0.01703531394839128\n",
      "Fold 2\n",
      "Epoch 1  loss=0.55780  val_loss=0.02978  sm_loss=0.55780  sm_val_loss=0.02977  time=4.65s\n",
      "Epoch 2  loss=0.02073  val_loss=0.01894  sm_loss=0.02067  sm_val_loss=0.01898  time=4.43s\n",
      "Epoch 3  loss=0.01836  val_loss=0.01846  sm_loss=0.01843  sm_val_loss=0.01852  time=4.55s\n",
      "Epoch 4  loss=0.01787  val_loss=0.01816  sm_loss=0.01795  sm_val_loss=0.01822  time=4.37s\n",
      "Epoch 5  loss=0.01768  val_loss=0.01811  sm_loss=0.01775  sm_val_loss=0.01818  time=4.53s\n",
      "Epoch 6  loss=0.01748  val_loss=0.01788  sm_loss=0.01757  sm_val_loss=0.01795  time=4.43s\n",
      "Epoch 7  loss=0.01735  val_loss=0.01784  sm_loss=0.01745  sm_val_loss=0.01791  time=4.85s\n",
      "Epoch 8  loss=0.01726  val_loss=0.01772  sm_loss=0.01737  sm_val_loss=0.01779  time=4.56s\n",
      "Epoch 10  loss=0.01705  val_loss=0.01757  sm_loss=0.01717  sm_val_loss=0.01764  time=4.88s\n",
      "Epoch 11  loss=0.01691  val_loss=0.01754  sm_loss=0.01703  sm_val_loss=0.01760  time=4.83s\n",
      "Epoch 12  loss=0.01681  val_loss=0.01739  sm_loss=0.01694  sm_val_loss=0.01746  time=5.30s\n",
      "Epoch 15  loss=0.01636  val_loss=0.01725  sm_loss=0.01650  sm_val_loss=0.01733  time=4.44s\n",
      "Epoch 16  loss=0.01623  val_loss=0.01726  sm_loss=0.01638  sm_val_loss=0.01732  time=4.39s\n",
      "Epoch 17  loss=0.01608  val_loss=0.01720  sm_loss=0.01624  sm_val_loss=0.01727  time=4.51s\n",
      "Epoch 18  loss=0.01595  val_loss=0.01718  sm_loss=0.01611  sm_val_loss=0.01725  time=4.70s\n",
      "Epoch 20  loss=0.01584  val_loss=0.01716  sm_loss=0.01600  sm_val_loss=0.01723  time=4.43s\n",
      "Fold 2 log loss: 0.017152970776227048\n",
      "Fold 3\n",
      "Epoch 1  loss=0.55699  val_loss=0.02841  sm_loss=0.55699  sm_val_loss=0.02841  time=4.97s\n",
      "Epoch 2  loss=0.02044  val_loss=0.01910  sm_loss=0.02039  sm_val_loss=0.01913  time=4.49s\n",
      "Epoch 3  loss=0.01822  val_loss=0.01879  sm_loss=0.01831  sm_val_loss=0.01883  time=4.48s\n",
      "Epoch 4  loss=0.01774  val_loss=0.01870  sm_loss=0.01782  sm_val_loss=0.01875  time=4.93s\n",
      "Epoch 5  loss=0.01747  val_loss=0.01851  sm_loss=0.01757  sm_val_loss=0.01856  time=5.30s\n",
      "Epoch 6  loss=0.01733  val_loss=0.01823  sm_loss=0.01744  sm_val_loss=0.01826  time=5.11s\n",
      "Epoch 8  loss=0.01706  val_loss=0.01817  sm_loss=0.01718  sm_val_loss=0.01823  time=4.91s\n",
      "Epoch 9  loss=0.01699  val_loss=0.01801  sm_loss=0.01713  sm_val_loss=0.01803  time=4.46s\n",
      "Epoch 11  loss=0.01669  val_loss=0.01786  sm_loss=0.01683  sm_val_loss=0.01791  time=4.35s\n",
      "Epoch 12  loss=0.01648  val_loss=0.01773  sm_loss=0.01664  sm_val_loss=0.01777  time=4.42s\n",
      "Epoch 13  loss=0.01636  val_loss=0.01768  sm_loss=0.01652  sm_val_loss=0.01773  time=4.40s\n",
      "Epoch 15  loss=0.01608  val_loss=0.01764  sm_loss=0.01625  sm_val_loss=0.01768  time=6.62s\n",
      "Epoch 16  loss=0.01592  val_loss=0.01749  sm_loss=0.01609  sm_val_loss=0.01754  time=5.24s\n",
      "Epoch 17  loss=0.01577  val_loss=0.01748  sm_loss=0.01595  sm_val_loss=0.01754  time=4.54s\n",
      "Epoch 18  loss=0.01565  val_loss=0.01747  sm_loss=0.01583  sm_val_loss=0.01752  time=4.88s\n",
      "Epoch 19  loss=0.01554  val_loss=0.01746  sm_loss=0.01572  sm_val_loss=0.01751  time=4.44s\n",
      "Epoch 20  loss=0.01552  val_loss=0.01746  sm_loss=0.01570  sm_val_loss=0.01751  time=4.39s\n",
      "Fold 3 log loss: 0.017524176804925642\n",
      "Fold 4\n",
      "Epoch 1  loss=0.55880  val_loss=0.03093  sm_loss=0.55879  sm_val_loss=0.03093  time=4.87s\n",
      "Epoch 2  loss=0.02050  val_loss=0.01946  sm_loss=0.02044  sm_val_loss=0.01950  time=4.52s\n",
      "Epoch 3  loss=0.01821  val_loss=0.01808  sm_loss=0.01830  sm_val_loss=0.01810  time=4.48s\n",
      "Epoch 5  loss=0.01763  val_loss=0.01768  sm_loss=0.01772  sm_val_loss=0.01770  time=4.46s\n",
      "Epoch 7  loss=0.01735  val_loss=0.01761  sm_loss=0.01746  sm_val_loss=0.01761  time=4.57s\n",
      "Epoch 9  loss=0.01709  val_loss=0.01734  sm_loss=0.01722  sm_val_loss=0.01739  time=4.71s\n",
      "Epoch 10  loss=0.01695  val_loss=0.01735  sm_loss=0.01708  sm_val_loss=0.01736  time=4.66s\n",
      "Epoch 11  loss=0.01684  val_loss=0.01726  sm_loss=0.01698  sm_val_loss=0.01729  time=4.51s\n",
      "Epoch 13  loss=0.01661  val_loss=0.01720  sm_loss=0.01675  sm_val_loss=0.01722  time=4.38s\n",
      "Epoch 14  loss=0.01646  val_loss=0.01702  sm_loss=0.01661  sm_val_loss=0.01706  time=4.45s\n",
      "Epoch 15  loss=0.01629  val_loss=0.01701  sm_loss=0.01645  sm_val_loss=0.01705  time=4.46s\n",
      "Epoch 17  loss=0.01602  val_loss=0.01691  sm_loss=0.01618  sm_val_loss=0.01694  time=4.39s\n",
      "Epoch 18  loss=0.01589  val_loss=0.01690  sm_loss=0.01606  sm_val_loss=0.01692  time=4.64s\n",
      "Epoch 19  loss=0.01580  val_loss=0.01690  sm_loss=0.01597  sm_val_loss=0.01692  time=4.49s\n",
      "Epoch 20  loss=0.01574  val_loss=0.01690  sm_loss=0.01591  sm_val_loss=0.01691  time=4.34s\n",
      "Fold 4 log loss: 0.01709266922728043\n",
      "Fold 5\n",
      "Epoch 1  loss=0.55769  val_loss=0.02934  sm_loss=0.55769  sm_val_loss=0.02933  time=4.59s\n",
      "Epoch 2  loss=0.02038  val_loss=0.01883  sm_loss=0.02038  sm_val_loss=0.01886  time=4.98s\n",
      "Epoch 3  loss=0.01803  val_loss=0.01810  sm_loss=0.01812  sm_val_loss=0.01814  time=5.04s\n",
      "Epoch 7  loss=0.01719  val_loss=0.01795  sm_loss=0.01731  sm_val_loss=0.01794  time=4.47s\n",
      "Epoch 8  loss=0.01710  val_loss=0.01789  sm_loss=0.01723  sm_val_loss=0.01791  time=4.55s\n",
      "Epoch 9  loss=0.01708  val_loss=0.01785  sm_loss=0.01721  sm_val_loss=0.01790  time=4.48s\n",
      "Epoch 11  loss=0.01674  val_loss=0.01756  sm_loss=0.01688  sm_val_loss=0.01759  time=4.49s\n",
      "Epoch 14  loss=0.01633  val_loss=0.01735  sm_loss=0.01649  sm_val_loss=0.01737  time=4.52s\n",
      "Epoch 17  loss=0.01587  val_loss=0.01732  sm_loss=0.01604  sm_val_loss=0.01736  time=5.46s\n",
      "Epoch 18  loss=0.01574  val_loss=0.01728  sm_loss=0.01592  sm_val_loss=0.01731  time=5.12s\n",
      "Fold 5 log loss: 0.017329630951444533\n",
      "Fold 6\n",
      "Epoch 1  loss=0.55830  val_loss=0.03555  sm_loss=0.55830  sm_val_loss=0.03554  time=4.61s\n",
      "Epoch 2  loss=0.02074  val_loss=0.01968  sm_loss=0.02070  sm_val_loss=0.01960  time=4.53s\n",
      "Epoch 3  loss=0.01837  val_loss=0.01839  sm_loss=0.01845  sm_val_loss=0.01842  time=4.95s\n",
      "Epoch 4  loss=0.01784  val_loss=0.01817  sm_loss=0.01793  sm_val_loss=0.01820  time=4.48s\n",
      "Epoch 7  loss=0.01735  val_loss=0.01790  sm_loss=0.01746  sm_val_loss=0.01791  time=4.76s\n",
      "Epoch 8  loss=0.01723  val_loss=0.01778  sm_loss=0.01735  sm_val_loss=0.01779  time=4.96s\n",
      "Epoch 9  loss=0.01705  val_loss=0.01770  sm_loss=0.01717  sm_val_loss=0.01775  time=4.68s\n",
      "Epoch 10  loss=0.01694  val_loss=0.01755  sm_loss=0.01707  sm_val_loss=0.01757  time=5.52s\n",
      "Epoch 11  loss=0.01678  val_loss=0.01741  sm_loss=0.01692  sm_val_loss=0.01745  time=4.40s\n",
      "Epoch 12  loss=0.01661  val_loss=0.01732  sm_loss=0.01676  sm_val_loss=0.01735  time=4.31s\n",
      "Epoch 15  loss=0.01623  val_loss=0.01731  sm_loss=0.01639  sm_val_loss=0.01733  time=4.41s\n",
      "Epoch 16  loss=0.01602  val_loss=0.01723  sm_loss=0.01619  sm_val_loss=0.01728  time=4.38s\n",
      "Epoch 17  loss=0.01590  val_loss=0.01719  sm_loss=0.01606  sm_val_loss=0.01723  time=4.79s\n",
      "Epoch 18  loss=0.01576  val_loss=0.01711  sm_loss=0.01593  sm_val_loss=0.01714  time=4.71s\n",
      "Epoch 20  loss=0.01562  val_loss=0.01710  sm_loss=0.01580  sm_val_loss=0.01714  time=4.55s\n",
      "Fold 6 log loss: 0.017267493020381115\n",
      "Fold 7\n",
      "Epoch 1  loss=0.55852  val_loss=0.03228  sm_loss=0.55852  sm_val_loss=0.03227  time=4.51s\n",
      "Epoch 2  loss=0.02084  val_loss=0.01935  sm_loss=0.02074  sm_val_loss=0.01941  time=4.46s\n",
      "Epoch 3  loss=0.01857  val_loss=0.01861  sm_loss=0.01863  sm_val_loss=0.01865  time=4.41s\n",
      "Epoch 4  loss=0.01798  val_loss=0.01778  sm_loss=0.01805  sm_val_loss=0.01782  time=4.71s\n",
      "Epoch 7  loss=0.01732  val_loss=0.01758  sm_loss=0.01743  sm_val_loss=0.01764  time=4.45s\n",
      "Epoch 9  loss=0.01707  val_loss=0.01750  sm_loss=0.01720  sm_val_loss=0.01753  time=4.25s\n",
      "Epoch 10  loss=0.01692  val_loss=0.01744  sm_loss=0.01705  sm_val_loss=0.01750  time=4.34s\n",
      "Epoch 11  loss=0.01677  val_loss=0.01741  sm_loss=0.01691  sm_val_loss=0.01745  time=4.25s\n",
      "Epoch 12  loss=0.01665  val_loss=0.01731  sm_loss=0.01680  sm_val_loss=0.01737  time=4.77s\n",
      "Epoch 13  loss=0.01653  val_loss=0.01722  sm_loss=0.01668  sm_val_loss=0.01729  time=4.51s\n",
      "Epoch 14  loss=0.01633  val_loss=0.01711  sm_loss=0.01649  sm_val_loss=0.01718  time=4.92s\n",
      "Epoch 16  loss=0.01608  val_loss=0.01710  sm_loss=0.01625  sm_val_loss=0.01717  time=4.28s\n",
      "Epoch 17  loss=0.01594  val_loss=0.01699  sm_loss=0.01611  sm_val_loss=0.01706  time=4.36s\n",
      "Epoch 19  loss=0.01570  val_loss=0.01697  sm_loss=0.01588  sm_val_loss=0.01704  time=4.64s\n",
      "Fold 7 log loss: 0.017325712942058993\n",
      "Seed 1\n",
      "Fold 1 log loss: 0.01703531394839128\n",
      "Fold 2 log loss: 0.017152970776227048\n",
      "Fold 3 log loss: 0.017524176804925642\n",
      "Fold 4 log loss: 0.01709266922728043\n",
      "Fold 5 log loss: 0.017329630951444533\n",
      "Fold 6 log loss: 0.017267493020381115\n",
      "Fold 7 log loss: 0.017325712942058993\n",
      "Std of log loss: 0.00015479980665879348\n",
      "Total log loss: 0.017246933240014754\n",
      "Fold 1\n",
      "Epoch 1  loss=0.55981  val_loss=0.03036  sm_loss=0.55980  sm_val_loss=0.03035  time=4.23s\n",
      "Epoch 2  loss=0.02062  val_loss=0.01863  sm_loss=0.02059  sm_val_loss=0.01869  time=4.35s\n",
      "Epoch 3  loss=0.01845  val_loss=0.01857  sm_loss=0.01853  sm_val_loss=0.01863  time=4.28s\n",
      "Epoch 4  loss=0.01789  val_loss=0.01811  sm_loss=0.01798  sm_val_loss=0.01816  time=4.39s\n",
      "Epoch 5  loss=0.01762  val_loss=0.01765  sm_loss=0.01771  sm_val_loss=0.01772  time=4.28s\n",
      "Epoch 6  loss=0.01747  val_loss=0.01764  sm_loss=0.01757  sm_val_loss=0.01770  time=4.96s\n",
      "Epoch 9  loss=0.01717  val_loss=0.01744  sm_loss=0.01730  sm_val_loss=0.01752  time=4.51s\n",
      "Epoch 10  loss=0.01697  val_loss=0.01729  sm_loss=0.01710  sm_val_loss=0.01738  time=4.40s\n",
      "Epoch 13  loss=0.01652  val_loss=0.01707  sm_loss=0.01668  sm_val_loss=0.01714  time=4.79s\n",
      "Epoch 15  loss=0.01624  val_loss=0.01706  sm_loss=0.01641  sm_val_loss=0.01714  time=4.40s\n",
      "Epoch 17  loss=0.01594  val_loss=0.01695  sm_loss=0.01611  sm_val_loss=0.01704  time=4.62s\n",
      "Epoch 18  loss=0.01580  val_loss=0.01694  sm_loss=0.01598  sm_val_loss=0.01702  time=4.47s\n",
      "Epoch 19  loss=0.01571  val_loss=0.01691  sm_loss=0.01589  sm_val_loss=0.01700  time=4.82s\n",
      "Fold 1 log loss: 0.017080542498511802\n",
      "Fold 2\n",
      "Epoch 1  loss=0.55792  val_loss=0.02803  sm_loss=0.55792  sm_val_loss=0.02802  time=4.65s\n",
      "Epoch 2  loss=0.02067  val_loss=0.01957  sm_loss=0.02062  sm_val_loss=0.01959  time=4.45s\n",
      "Epoch 3  loss=0.01845  val_loss=0.01886  sm_loss=0.01854  sm_val_loss=0.01890  time=4.39s\n",
      "Epoch 4  loss=0.01807  val_loss=0.01839  sm_loss=0.01815  sm_val_loss=0.01843  time=4.28s\n",
      "Epoch 5  loss=0.01766  val_loss=0.01791  sm_loss=0.01775  sm_val_loss=0.01796  time=4.35s\n",
      "Epoch 6  loss=0.01755  val_loss=0.01779  sm_loss=0.01764  sm_val_loss=0.01783  time=4.62s\n",
      "Epoch 9  loss=0.01710  val_loss=0.01776  sm_loss=0.01722  sm_val_loss=0.01782  time=4.33s\n",
      "Epoch 10  loss=0.01702  val_loss=0.01749  sm_loss=0.01715  sm_val_loss=0.01757  time=4.35s\n",
      "Epoch 11  loss=0.01687  val_loss=0.01742  sm_loss=0.01701  sm_val_loss=0.01750  time=4.33s\n",
      "Epoch 14  loss=0.01647  val_loss=0.01733  sm_loss=0.01662  sm_val_loss=0.01741  time=4.46s\n",
      "Epoch 15  loss=0.01626  val_loss=0.01725  sm_loss=0.01641  sm_val_loss=0.01732  time=4.76s\n",
      "Epoch 16  loss=0.01617  val_loss=0.01722  sm_loss=0.01633  sm_val_loss=0.01729  time=4.28s\n",
      "Epoch 17  loss=0.01602  val_loss=0.01714  sm_loss=0.01618  sm_val_loss=0.01721  time=4.73s\n",
      "Epoch 18  loss=0.01591  val_loss=0.01713  sm_loss=0.01608  sm_val_loss=0.01719  time=4.49s\n",
      "Fold 2 log loss: 0.01711971625951582\n",
      "Fold 3\n",
      "Epoch 1  loss=0.55891  val_loss=0.04816  sm_loss=0.55891  sm_val_loss=0.04815  time=4.28s\n",
      "Epoch 2  loss=0.02066  val_loss=0.01938  sm_loss=0.02063  sm_val_loss=0.01943  time=4.73s\n",
      "Epoch 3  loss=0.01834  val_loss=0.01894  sm_loss=0.01843  sm_val_loss=0.01897  time=4.30s\n",
      "Epoch 4  loss=0.01781  val_loss=0.01864  sm_loss=0.01790  sm_val_loss=0.01865  time=4.25s\n",
      "Epoch 5  loss=0.01749  val_loss=0.01835  sm_loss=0.01759  sm_val_loss=0.01838  time=5.82s\n",
      "Epoch 7  loss=0.01731  val_loss=0.01817  sm_loss=0.01742  sm_val_loss=0.01822  time=4.41s\n",
      "Epoch 8  loss=0.01718  val_loss=0.01807  sm_loss=0.01730  sm_val_loss=0.01812  time=4.31s\n",
      "Epoch 9  loss=0.01697  val_loss=0.01807  sm_loss=0.01711  sm_val_loss=0.01812  time=4.75s\n",
      "Epoch 10  loss=0.01689  val_loss=0.01795  sm_loss=0.01703  sm_val_loss=0.01800  time=4.26s\n",
      "Epoch 11  loss=0.01670  val_loss=0.01779  sm_loss=0.01684  sm_val_loss=0.01778  time=4.23s\n",
      "Epoch 12  loss=0.01655  val_loss=0.01772  sm_loss=0.01671  sm_val_loss=0.01778  time=4.33s\n",
      "Epoch 13  loss=0.01642  val_loss=0.01759  sm_loss=0.01659  sm_val_loss=0.01766  time=4.31s\n",
      "Epoch 14  loss=0.01624  val_loss=0.01754  sm_loss=0.01641  sm_val_loss=0.01760  time=4.33s\n",
      "Epoch 16  loss=0.01591  val_loss=0.01755  sm_loss=0.01609  sm_val_loss=0.01759  time=4.72s\n",
      "Epoch 17  loss=0.01573  val_loss=0.01747  sm_loss=0.01592  sm_val_loss=0.01752  time=4.57s\n",
      "Epoch 18  loss=0.01559  val_loss=0.01746  sm_loss=0.01579  sm_val_loss=0.01750  time=4.61s\n",
      "Epoch 19  loss=0.01549  val_loss=0.01745  sm_loss=0.01569  sm_val_loss=0.01750  time=4.72s\n",
      "Epoch 20  loss=0.01543  val_loss=0.01745  sm_loss=0.01563  sm_val_loss=0.01749  time=4.62s\n",
      "Fold 3 log loss: 0.017510565684719627\n",
      "Fold 4\n",
      "Epoch 1  loss=0.55869  val_loss=0.02994  sm_loss=0.55868  sm_val_loss=0.02994  time=4.55s\n",
      "Epoch 2  loss=0.02054  val_loss=0.01866  sm_loss=0.02049  sm_val_loss=0.01867  time=4.36s\n",
      "Epoch 3  loss=0.01830  val_loss=0.01828  sm_loss=0.01838  sm_val_loss=0.01832  time=4.76s\n",
      "Epoch 4  loss=0.01783  val_loss=0.01812  sm_loss=0.01792  sm_val_loss=0.01815  time=4.36s\n",
      "Epoch 5  loss=0.01771  val_loss=0.01757  sm_loss=0.01780  sm_val_loss=0.01759  time=4.36s\n",
      "Epoch 8  loss=0.01724  val_loss=0.01742  sm_loss=0.01736  sm_val_loss=0.01745  time=4.44s\n",
      "Epoch 11  loss=0.01687  val_loss=0.01739  sm_loss=0.01701  sm_val_loss=0.01742  time=5.08s\n",
      "Epoch 12  loss=0.01678  val_loss=0.01720  sm_loss=0.01693  sm_val_loss=0.01725  time=4.59s\n",
      "Epoch 13  loss=0.01660  val_loss=0.01719  sm_loss=0.01675  sm_val_loss=0.01724  time=4.42s\n",
      "Epoch 14  loss=0.01648  val_loss=0.01711  sm_loss=0.01664  sm_val_loss=0.01713  time=4.29s\n",
      "Epoch 16  loss=0.01618  val_loss=0.01698  sm_loss=0.01635  sm_val_loss=0.01702  time=4.31s\n",
      "Epoch 17  loss=0.01606  val_loss=0.01689  sm_loss=0.01623  sm_val_loss=0.01692  time=4.56s\n",
      "Epoch 18  loss=0.01591  val_loss=0.01687  sm_loss=0.01608  sm_val_loss=0.01690  time=4.74s\n",
      "Epoch 19  loss=0.01583  val_loss=0.01684  sm_loss=0.01600  sm_val_loss=0.01687  time=4.32s\n",
      "Epoch 20  loss=0.01576  val_loss=0.01684  sm_loss=0.01593  sm_val_loss=0.01687  time=4.26s\n",
      "Fold 4 log loss: 0.01705045556014251\n",
      "Fold 5\n",
      "Epoch 1  loss=0.55918  val_loss=0.02991  sm_loss=0.55918  sm_val_loss=0.02990  time=4.33s\n",
      "Epoch 2  loss=0.02061  val_loss=0.01976  sm_loss=0.02056  sm_val_loss=0.01978  time=4.28s\n",
      "Epoch 3  loss=0.01833  val_loss=0.01851  sm_loss=0.01841  sm_val_loss=0.01853  time=4.37s\n",
      "Epoch 5  loss=0.01763  val_loss=0.01831  sm_loss=0.01772  sm_val_loss=0.01834  time=4.93s\n",
      "Epoch 6  loss=0.01750  val_loss=0.01823  sm_loss=0.01761  sm_val_loss=0.01829  time=4.74s\n",
      "Epoch 7  loss=0.01737  val_loss=0.01805  sm_loss=0.01748  sm_val_loss=0.01810  time=4.32s\n",
      "Epoch 8  loss=0.01723  val_loss=0.01791  sm_loss=0.01734  sm_val_loss=0.01793  time=4.33s\n",
      "Epoch 10  loss=0.01702  val_loss=0.01783  sm_loss=0.01714  sm_val_loss=0.01783  time=4.34s\n",
      "Epoch 11  loss=0.01686  val_loss=0.01778  sm_loss=0.01699  sm_val_loss=0.01781  time=4.39s\n",
      "Epoch 12  loss=0.01671  val_loss=0.01762  sm_loss=0.01685  sm_val_loss=0.01766  time=4.39s\n",
      "Epoch 13  loss=0.01657  val_loss=0.01758  sm_loss=0.01671  sm_val_loss=0.01760  time=4.56s\n",
      "Epoch 14  loss=0.01647  val_loss=0.01753  sm_loss=0.01662  sm_val_loss=0.01757  time=4.30s\n",
      "Epoch 15  loss=0.01628  val_loss=0.01737  sm_loss=0.01644  sm_val_loss=0.01739  time=4.64s\n",
      "Epoch 18  loss=0.01590  val_loss=0.01730  sm_loss=0.01607  sm_val_loss=0.01735  time=4.75s\n",
      "Epoch 19  loss=0.01580  val_loss=0.01729  sm_loss=0.01597  sm_val_loss=0.01733  time=4.50s\n",
      "Epoch 20  loss=0.01579  val_loss=0.01728  sm_loss=0.01596  sm_val_loss=0.01732  time=4.94s\n",
      "Fold 5 log loss: 0.017344825258628394\n",
      "Fold 6\n",
      "Epoch 1  loss=0.55707  val_loss=0.02816  sm_loss=0.55706  sm_val_loss=0.02816  time=4.32s\n",
      "Epoch 2  loss=0.02057  val_loss=0.01941  sm_loss=0.02053  sm_val_loss=0.01934  time=4.32s\n",
      "Epoch 3  loss=0.01835  val_loss=0.01849  sm_loss=0.01842  sm_val_loss=0.01854  time=4.23s\n",
      "Epoch 5  loss=0.01762  val_loss=0.01794  sm_loss=0.01772  sm_val_loss=0.01800  time=4.35s\n",
      "Epoch 6  loss=0.01745  val_loss=0.01798  sm_loss=0.01756  sm_val_loss=0.01797  time=4.27s\n",
      "Epoch 8  loss=0.01710  val_loss=0.01783  sm_loss=0.01722  sm_val_loss=0.01785  time=4.27s\n",
      "Epoch 9  loss=0.01706  val_loss=0.01773  sm_loss=0.01719  sm_val_loss=0.01772  time=4.22s\n",
      "Epoch 10  loss=0.01694  val_loss=0.01760  sm_loss=0.01707  sm_val_loss=0.01762  time=4.30s\n",
      "Epoch 12  loss=0.01663  val_loss=0.01757  sm_loss=0.01678  sm_val_loss=0.01757  time=4.63s\n",
      "Epoch 13  loss=0.01640  val_loss=0.01747  sm_loss=0.01655  sm_val_loss=0.01746  time=4.67s\n",
      "Epoch 14  loss=0.01630  val_loss=0.01726  sm_loss=0.01646  sm_val_loss=0.01725  time=4.75s\n",
      "Epoch 17  loss=0.01582  val_loss=0.01722  sm_loss=0.01599  sm_val_loss=0.01723  time=4.66s\n",
      "Epoch 18  loss=0.01568  val_loss=0.01716  sm_loss=0.01586  sm_val_loss=0.01718  time=4.40s\n",
      "Epoch 19  loss=0.01558  val_loss=0.01716  sm_loss=0.01576  sm_val_loss=0.01717  time=4.35s\n",
      "Fold 6 log loss: 0.017318589130685465\n",
      "Fold 7\n",
      "Epoch 1  loss=0.55726  val_loss=0.02816  sm_loss=0.55725  sm_val_loss=0.02815  time=4.44s\n",
      "Epoch 2  loss=0.02073  val_loss=0.01909  sm_loss=0.02066  sm_val_loss=0.01915  time=4.59s\n",
      "Epoch 3  loss=0.01841  val_loss=0.01840  sm_loss=0.01848  sm_val_loss=0.01843  time=4.29s\n",
      "Epoch 4  loss=0.01780  val_loss=0.01823  sm_loss=0.01788  sm_val_loss=0.01829  time=4.59s\n",
      "Epoch 5  loss=0.01752  val_loss=0.01775  sm_loss=0.01761  sm_val_loss=0.01780  time=4.55s\n",
      "Epoch 8  loss=0.01714  val_loss=0.01747  sm_loss=0.01726  sm_val_loss=0.01753  time=4.26s\n",
      "Epoch 11  loss=0.01674  val_loss=0.01732  sm_loss=0.01687  sm_val_loss=0.01739  time=4.29s\n",
      "Epoch 13  loss=0.01652  val_loss=0.01718  sm_loss=0.01666  sm_val_loss=0.01724  time=4.26s\n",
      "Epoch 15  loss=0.01619  val_loss=0.01704  sm_loss=0.01634  sm_val_loss=0.01709  time=4.27s\n",
      "Epoch 16  loss=0.01604  val_loss=0.01700  sm_loss=0.01620  sm_val_loss=0.01706  time=4.82s\n",
      "Epoch 17  loss=0.01592  val_loss=0.01698  sm_loss=0.01608  sm_val_loss=0.01704  time=4.37s\n",
      "Epoch 18  loss=0.01580  val_loss=0.01694  sm_loss=0.01597  sm_val_loss=0.01700  time=4.60s\n",
      "Epoch 20  loss=0.01565  val_loss=0.01693  sm_loss=0.01582  sm_val_loss=0.01699  time=4.36s\n",
      "Fold 7 log loss: 0.01727081304635949\n",
      "Seed 2\n",
      "Fold 1 log loss: 0.017080542498511802\n",
      "Fold 2 log loss: 0.01711971625951582\n",
      "Fold 3 log loss: 0.017510565684719627\n",
      "Fold 4 log loss: 0.01705045556014251\n",
      "Fold 5 log loss: 0.017344825258628394\n",
      "Fold 6 log loss: 0.017318589130685465\n",
      "Fold 7 log loss: 0.01727081304635949\n",
      "Std of log loss: 0.00015450725049565475\n",
      "Total log loss: 0.017242380033275904\n",
      "Fold 1\n",
      "Epoch 1  loss=0.55938  val_loss=0.02941  sm_loss=0.55938  sm_val_loss=0.02940  time=4.35s\n",
      "Epoch 2  loss=0.02073  val_loss=0.01950  sm_loss=0.02066  sm_val_loss=0.01956  time=4.27s\n",
      "Epoch 3  loss=0.01846  val_loss=0.01820  sm_loss=0.01854  sm_val_loss=0.01824  time=4.65s\n",
      "Epoch 4  loss=0.01795  val_loss=0.01808  sm_loss=0.01803  sm_val_loss=0.01813  time=4.35s\n",
      "Epoch 6  loss=0.01756  val_loss=0.01773  sm_loss=0.01766  sm_val_loss=0.01779  time=4.31s\n",
      "Epoch 7  loss=0.01741  val_loss=0.01749  sm_loss=0.01751  sm_val_loss=0.01756  time=4.33s\n",
      "Epoch 9  loss=0.01715  val_loss=0.01748  sm_loss=0.01727  sm_val_loss=0.01755  time=4.31s\n",
      "Epoch 12  loss=0.01676  val_loss=0.01728  sm_loss=0.01690  sm_val_loss=0.01737  time=4.51s\n",
      "Epoch 13  loss=0.01665  val_loss=0.01715  sm_loss=0.01679  sm_val_loss=0.01722  time=4.28s\n",
      "Epoch 16  loss=0.01619  val_loss=0.01707  sm_loss=0.01634  sm_val_loss=0.01713  time=4.48s\n",
      "Epoch 17  loss=0.01609  val_loss=0.01693  sm_loss=0.01625  sm_val_loss=0.01702  time=4.38s\n",
      "Fold 1 log loss: 0.017102786794990856\n",
      "Fold 2\n",
      "Epoch 1  loss=0.55953  val_loss=0.04059  sm_loss=0.55953  sm_val_loss=0.04058  time=4.36s\n",
      "Epoch 2  loss=0.02100  val_loss=0.02048  sm_loss=0.02093  sm_val_loss=0.02049  time=4.28s\n",
      "Epoch 3  loss=0.01859  val_loss=0.01850  sm_loss=0.01866  sm_val_loss=0.01854  time=4.48s\n",
      "Epoch 4  loss=0.01804  val_loss=0.01799  sm_loss=0.01812  sm_val_loss=0.01804  time=4.82s\n",
      "Epoch 6  loss=0.01759  val_loss=0.01787  sm_loss=0.01768  sm_val_loss=0.01792  time=4.49s\n",
      "Epoch 9  loss=0.01711  val_loss=0.01775  sm_loss=0.01723  sm_val_loss=0.01781  time=4.21s\n",
      "Epoch 10  loss=0.01699  val_loss=0.01756  sm_loss=0.01712  sm_val_loss=0.01762  time=4.21s\n",
      "Epoch 12  loss=0.01672  val_loss=0.01753  sm_loss=0.01686  sm_val_loss=0.01759  time=4.50s\n",
      "Epoch 13  loss=0.01661  val_loss=0.01745  sm_loss=0.01675  sm_val_loss=0.01751  time=4.84s\n",
      "Epoch 14  loss=0.01642  val_loss=0.01741  sm_loss=0.01658  sm_val_loss=0.01748  time=4.27s\n",
      "Epoch 15  loss=0.01630  val_loss=0.01727  sm_loss=0.01647  sm_val_loss=0.01733  time=4.21s\n",
      "Epoch 16  loss=0.01614  val_loss=0.01720  sm_loss=0.01631  sm_val_loss=0.01727  time=4.49s\n",
      "Epoch 17  loss=0.01597  val_loss=0.01716  sm_loss=0.01614  sm_val_loss=0.01722  time=4.26s\n",
      "Epoch 18  loss=0.01583  val_loss=0.01716  sm_loss=0.01601  sm_val_loss=0.01721  time=4.74s\n",
      "Epoch 20  loss=0.01565  val_loss=0.01714  sm_loss=0.01583  sm_val_loss=0.01720  time=6.17s\n",
      "Fold 2 log loss: 0.017123482943968964\n",
      "Fold 3\n",
      "Epoch 1  loss=0.55767  val_loss=0.02980  sm_loss=0.55767  sm_val_loss=0.02979  time=4.63s\n",
      "Epoch 2  loss=0.02075  val_loss=0.01952  sm_loss=0.02070  sm_val_loss=0.01958  time=4.36s\n",
      "Epoch 3  loss=0.01833  val_loss=0.01874  sm_loss=0.01841  sm_val_loss=0.01876  time=4.27s\n",
      "Epoch 4  loss=0.01781  val_loss=0.01849  sm_loss=0.01790  sm_val_loss=0.01854  time=4.38s\n",
      "Epoch 5  loss=0.01747  val_loss=0.01845  sm_loss=0.01757  sm_val_loss=0.01846  time=4.36s\n",
      "Epoch 6  loss=0.01733  val_loss=0.01817  sm_loss=0.01744  sm_val_loss=0.01823  time=4.30s\n",
      "Epoch 7  loss=0.01720  val_loss=0.01809  sm_loss=0.01731  sm_val_loss=0.01818  time=4.76s\n",
      "Epoch 8  loss=0.01703  val_loss=0.01811  sm_loss=0.01716  sm_val_loss=0.01817  time=4.29s\n",
      "Epoch 9  loss=0.01695  val_loss=0.01806  sm_loss=0.01708  sm_val_loss=0.01809  time=4.35s\n",
      "Epoch 10  loss=0.01688  val_loss=0.01799  sm_loss=0.01702  sm_val_loss=0.01805  time=4.68s\n",
      "Epoch 11  loss=0.01668  val_loss=0.01783  sm_loss=0.01682  sm_val_loss=0.01789  time=4.63s\n",
      "Epoch 12  loss=0.01651  val_loss=0.01769  sm_loss=0.01666  sm_val_loss=0.01777  time=4.45s\n",
      "Epoch 14  loss=0.01620  val_loss=0.01763  sm_loss=0.01637  sm_val_loss=0.01769  time=4.74s\n",
      "Epoch 15  loss=0.01604  val_loss=0.01761  sm_loss=0.01622  sm_val_loss=0.01766  time=4.50s\n",
      "Epoch 16  loss=0.01588  val_loss=0.01752  sm_loss=0.01606  sm_val_loss=0.01757  time=4.46s\n",
      "Epoch 17  loss=0.01571  val_loss=0.01752  sm_loss=0.01589  sm_val_loss=0.01756  time=4.37s\n",
      "Epoch 18  loss=0.01559  val_loss=0.01747  sm_loss=0.01578  sm_val_loss=0.01751  time=4.43s\n",
      "Epoch 20  loss=0.01544  val_loss=0.01747  sm_loss=0.01563  sm_val_loss=0.01751  time=4.36s\n",
      "Fold 3 log loss: 0.017516151200683876\n",
      "Fold 4\n",
      "Epoch 1  loss=0.55805  val_loss=0.02586  sm_loss=0.55805  sm_val_loss=0.02586  time=4.67s\n",
      "Epoch 2  loss=0.02086  val_loss=0.01965  sm_loss=0.02080  sm_val_loss=0.01971  time=4.39s\n",
      "Epoch 3  loss=0.01848  val_loss=0.01893  sm_loss=0.01855  sm_val_loss=0.01897  time=4.65s\n",
      "Epoch 4  loss=0.01798  val_loss=0.01789  sm_loss=0.01807  sm_val_loss=0.01790  time=4.63s\n",
      "Epoch 5  loss=0.01756  val_loss=0.01762  sm_loss=0.01766  sm_val_loss=0.01765  time=4.68s\n",
      "Epoch 9  loss=0.01710  val_loss=0.01743  sm_loss=0.01723  sm_val_loss=0.01747  time=4.62s\n",
      "Epoch 11  loss=0.01685  val_loss=0.01726  sm_loss=0.01699  sm_val_loss=0.01730  time=4.32s\n",
      "Epoch 12  loss=0.01662  val_loss=0.01720  sm_loss=0.01676  sm_val_loss=0.01723  time=4.37s\n",
      "Epoch 13  loss=0.01652  val_loss=0.01712  sm_loss=0.01667  sm_val_loss=0.01716  time=4.30s\n",
      "Epoch 14  loss=0.01636  val_loss=0.01712  sm_loss=0.01652  sm_val_loss=0.01712  time=4.35s\n",
      "Epoch 15  loss=0.01621  val_loss=0.01693  sm_loss=0.01637  sm_val_loss=0.01696  time=4.26s\n",
      "Epoch 16  loss=0.01606  val_loss=0.01690  sm_loss=0.01623  sm_val_loss=0.01692  time=4.86s\n",
      "Epoch 17  loss=0.01591  val_loss=0.01686  sm_loss=0.01608  sm_val_loss=0.01688  time=4.66s\n",
      "Epoch 18  loss=0.01579  val_loss=0.01681  sm_loss=0.01596  sm_val_loss=0.01682  time=4.72s\n",
      "Fold 4 log loss: 0.017011894709576928\n",
      "Fold 5\n",
      "Epoch 1  loss=0.55879  val_loss=0.02719  sm_loss=0.55879  sm_val_loss=0.02718  time=4.27s\n",
      "Epoch 2  loss=0.02079  val_loss=0.02020  sm_loss=0.02071  sm_val_loss=0.02017  time=4.25s\n",
      "Epoch 3  loss=0.01842  val_loss=0.01868  sm_loss=0.01850  sm_val_loss=0.01868  time=4.68s\n",
      "Epoch 4  loss=0.01781  val_loss=0.01825  sm_loss=0.01790  sm_val_loss=0.01827  time=4.31s\n",
      "Epoch 5  loss=0.01762  val_loss=0.01813  sm_loss=0.01771  sm_val_loss=0.01817  time=4.27s\n",
      "Epoch 8  loss=0.01715  val_loss=0.01785  sm_loss=0.01727  sm_val_loss=0.01787  time=4.32s\n",
      "Epoch 9  loss=0.01700  val_loss=0.01783  sm_loss=0.01713  sm_val_loss=0.01787  time=4.38s\n",
      "Epoch 10  loss=0.01693  val_loss=0.01775  sm_loss=0.01706  sm_val_loss=0.01776  time=4.72s\n",
      "Epoch 12  loss=0.01666  val_loss=0.01763  sm_loss=0.01680  sm_val_loss=0.01766  time=4.36s\n",
      "Epoch 13  loss=0.01650  val_loss=0.01751  sm_loss=0.01665  sm_val_loss=0.01752  time=4.43s\n",
      "Epoch 14  loss=0.01636  val_loss=0.01739  sm_loss=0.01651  sm_val_loss=0.01743  time=4.33s\n",
      "Epoch 15  loss=0.01621  val_loss=0.01739  sm_loss=0.01637  sm_val_loss=0.01741  time=4.41s\n",
      "Epoch 16  loss=0.01605  val_loss=0.01732  sm_loss=0.01621  sm_val_loss=0.01735  time=4.76s\n",
      "Epoch 17  loss=0.01590  val_loss=0.01725  sm_loss=0.01607  sm_val_loss=0.01728  time=4.70s\n",
      "Epoch 18  loss=0.01577  val_loss=0.01723  sm_loss=0.01594  sm_val_loss=0.01725  time=4.96s\n",
      "Epoch 19  loss=0.01568  val_loss=0.01722  sm_loss=0.01585  sm_val_loss=0.01724  time=4.38s\n",
      "Fold 5 log loss: 0.01727779362314113\n",
      "Fold 6\n",
      "Epoch 1  loss=0.55761  val_loss=0.02847  sm_loss=0.55761  sm_val_loss=0.02847  time=4.29s\n",
      "Epoch 2  loss=0.02041  val_loss=0.02074  sm_loss=0.02036  sm_val_loss=0.02071  time=4.31s\n",
      "Epoch 3  loss=0.01815  val_loss=0.01844  sm_loss=0.01824  sm_val_loss=0.01845  time=4.69s\n",
      "Epoch 5  loss=0.01758  val_loss=0.01814  sm_loss=0.01768  sm_val_loss=0.01814  time=4.83s\n",
      "Epoch 6  loss=0.01743  val_loss=0.01788  sm_loss=0.01753  sm_val_loss=0.01791  time=4.23s\n",
      "Epoch 7  loss=0.01729  val_loss=0.01782  sm_loss=0.01740  sm_val_loss=0.01785  time=4.30s\n",
      "Epoch 10  loss=0.01694  val_loss=0.01764  sm_loss=0.01708  sm_val_loss=0.01768  time=4.32s\n",
      "Epoch 12  loss=0.01667  val_loss=0.01752  sm_loss=0.01682  sm_val_loss=0.01752  time=4.71s\n",
      "Epoch 13  loss=0.01657  val_loss=0.01746  sm_loss=0.01673  sm_val_loss=0.01747  time=4.32s\n",
      "Epoch 14  loss=0.01639  val_loss=0.01734  sm_loss=0.01655  sm_val_loss=0.01736  time=4.36s\n",
      "Epoch 15  loss=0.01624  val_loss=0.01720  sm_loss=0.01641  sm_val_loss=0.01724  time=4.37s\n",
      "Epoch 18  loss=0.01580  val_loss=0.01711  sm_loss=0.01599  sm_val_loss=0.01713  time=4.59s\n",
      "Fold 6 log loss: 0.01726219601357532\n",
      "Fold 7\n",
      "Epoch 1  loss=0.55840  val_loss=0.02918  sm_loss=0.55840  sm_val_loss=0.02917  time=4.31s\n",
      "Epoch 2  loss=0.02089  val_loss=0.01905  sm_loss=0.02085  sm_val_loss=0.01910  time=4.40s\n",
      "Epoch 3  loss=0.01849  val_loss=0.01834  sm_loss=0.01856  sm_val_loss=0.01840  time=4.24s\n",
      "Epoch 4  loss=0.01793  val_loss=0.01774  sm_loss=0.01800  sm_val_loss=0.01778  time=4.22s\n",
      "Epoch 6  loss=0.01756  val_loss=0.01772  sm_loss=0.01765  sm_val_loss=0.01777  time=4.31s\n",
      "Epoch 7  loss=0.01725  val_loss=0.01761  sm_loss=0.01736  sm_val_loss=0.01767  time=4.69s\n",
      "Epoch 8  loss=0.01713  val_loss=0.01754  sm_loss=0.01726  sm_val_loss=0.01758  time=4.42s\n",
      "Epoch 9  loss=0.01703  val_loss=0.01752  sm_loss=0.01716  sm_val_loss=0.01756  time=4.33s\n",
      "Epoch 11  loss=0.01678  val_loss=0.01735  sm_loss=0.01692  sm_val_loss=0.01740  time=4.65s\n",
      "Epoch 12  loss=0.01665  val_loss=0.01726  sm_loss=0.01680  sm_val_loss=0.01733  time=4.42s\n",
      "Epoch 14  loss=0.01630  val_loss=0.01722  sm_loss=0.01647  sm_val_loss=0.01728  time=4.60s\n",
      "Epoch 15  loss=0.01621  val_loss=0.01721  sm_loss=0.01638  sm_val_loss=0.01726  time=4.42s\n",
      "Epoch 16  loss=0.01603  val_loss=0.01711  sm_loss=0.01620  sm_val_loss=0.01717  time=4.52s\n",
      "Epoch 17  loss=0.01590  val_loss=0.01706  sm_loss=0.01608  sm_val_loss=0.01711  time=4.39s\n",
      "Epoch 18  loss=0.01577  val_loss=0.01703  sm_loss=0.01595  sm_val_loss=0.01709  time=4.27s\n",
      "Epoch 19  loss=0.01565  val_loss=0.01703  sm_loss=0.01584  sm_val_loss=0.01709  time=4.21s\n",
      "Epoch 20  loss=0.01563  val_loss=0.01703  sm_loss=0.01581  sm_val_loss=0.01708  time=4.31s\n",
      "Fold 7 log loss: 0.017364043488549166\n",
      "Seed 3\n",
      "Fold 1 log loss: 0.017102786794990856\n",
      "Fold 2 log loss: 0.017123482943968964\n",
      "Fold 3 log loss: 0.017516151200683876\n",
      "Fold 4 log loss: 0.017011894709576928\n",
      "Fold 5 log loss: 0.01727779362314113\n",
      "Fold 6 log loss: 0.01726219601357532\n",
      "Fold 7 log loss: 0.017364043488549166\n",
      "Std of log loss: 0.00015943473237631144\n",
      "Total log loss: 0.017237157604065807\n",
      "Fold 1\n",
      "Epoch 1  loss=0.56136  val_loss=0.03120  sm_loss=0.56136  sm_val_loss=0.03119  time=4.68s\n",
      "Epoch 2  loss=0.02055  val_loss=0.01857  sm_loss=0.02052  sm_val_loss=0.01862  time=4.44s\n",
      "Epoch 3  loss=0.01829  val_loss=0.01804  sm_loss=0.01837  sm_val_loss=0.01809  time=4.59s\n",
      "Epoch 4  loss=0.01775  val_loss=0.01778  sm_loss=0.01783  sm_val_loss=0.01784  time=4.61s\n",
      "Epoch 5  loss=0.01763  val_loss=0.01777  sm_loss=0.01771  sm_val_loss=0.01784  time=4.26s\n",
      "Epoch 7  loss=0.01732  val_loss=0.01763  sm_loss=0.01743  sm_val_loss=0.01768  time=4.30s\n",
      "Epoch 8  loss=0.01720  val_loss=0.01750  sm_loss=0.01732  sm_val_loss=0.01755  time=4.34s\n",
      "Epoch 10  loss=0.01693  val_loss=0.01744  sm_loss=0.01707  sm_val_loss=0.01753  time=4.24s\n",
      "Epoch 11  loss=0.01676  val_loss=0.01732  sm_loss=0.01690  sm_val_loss=0.01740  time=4.32s\n",
      "Epoch 12  loss=0.01664  val_loss=0.01723  sm_loss=0.01679  sm_val_loss=0.01732  time=4.30s\n",
      "Epoch 14  loss=0.01636  val_loss=0.01710  sm_loss=0.01651  sm_val_loss=0.01719  time=4.33s\n",
      "Epoch 15  loss=0.01620  val_loss=0.01699  sm_loss=0.01637  sm_val_loss=0.01708  time=4.31s\n",
      "Epoch 16  loss=0.01607  val_loss=0.01695  sm_loss=0.01624  sm_val_loss=0.01704  time=5.43s\n",
      "Epoch 18  loss=0.01573  val_loss=0.01691  sm_loss=0.01591  sm_val_loss=0.01699  time=4.42s\n",
      "Epoch 19  loss=0.01566  val_loss=0.01691  sm_loss=0.01583  sm_val_loss=0.01699  time=4.41s\n",
      "Epoch 20  loss=0.01560  val_loss=0.01690  sm_loss=0.01577  sm_val_loss=0.01699  time=4.34s\n",
      "Fold 1 log loss: 0.01706632273616957\n",
      "Fold 2\n",
      "Epoch 1  loss=0.55779  val_loss=0.02921  sm_loss=0.55779  sm_val_loss=0.02920  time=4.42s\n",
      "Epoch 2  loss=0.02098  val_loss=0.01956  sm_loss=0.02093  sm_val_loss=0.01960  time=4.36s\n",
      "Epoch 3  loss=0.01850  val_loss=0.01851  sm_loss=0.01857  sm_val_loss=0.01853  time=4.86s\n",
      "Epoch 4  loss=0.01798  val_loss=0.01820  sm_loss=0.01805  sm_val_loss=0.01823  time=4.23s\n",
      "Epoch 6  loss=0.01753  val_loss=0.01798  sm_loss=0.01762  sm_val_loss=0.01804  time=4.67s\n",
      "Epoch 7  loss=0.01743  val_loss=0.01793  sm_loss=0.01754  sm_val_loss=0.01799  time=4.87s\n",
      "Epoch 8  loss=0.01724  val_loss=0.01783  sm_loss=0.01735  sm_val_loss=0.01788  time=4.67s\n",
      "Epoch 10  loss=0.01706  val_loss=0.01752  sm_loss=0.01718  sm_val_loss=0.01760  time=5.02s\n",
      "Epoch 13  loss=0.01654  val_loss=0.01746  sm_loss=0.01669  sm_val_loss=0.01752  time=5.20s\n",
      "Epoch 15  loss=0.01623  val_loss=0.01735  sm_loss=0.01640  sm_val_loss=0.01739  time=5.05s\n",
      "Epoch 16  loss=0.01603  val_loss=0.01722  sm_loss=0.01620  sm_val_loss=0.01728  time=4.51s\n",
      "Epoch 18  loss=0.01578  val_loss=0.01714  sm_loss=0.01597  sm_val_loss=0.01719  time=4.33s\n",
      "Fold 2 log loss: 0.017107314787734543\n",
      "Fold 3\n",
      "Epoch 1  loss=0.55893  val_loss=0.03267  sm_loss=0.55892  sm_val_loss=0.03266  time=4.31s\n",
      "Epoch 2  loss=0.02063  val_loss=0.01966  sm_loss=0.02056  sm_val_loss=0.01971  time=4.70s\n",
      "Epoch 3  loss=0.01839  val_loss=0.01905  sm_loss=0.01846  sm_val_loss=0.01906  time=4.67s\n",
      "Epoch 4  loss=0.01786  val_loss=0.01846  sm_loss=0.01795  sm_val_loss=0.01850  time=4.84s\n",
      "Epoch 5  loss=0.01754  val_loss=0.01842  sm_loss=0.01763  sm_val_loss=0.01846  time=4.54s\n",
      "Epoch 6  loss=0.01735  val_loss=0.01816  sm_loss=0.01745  sm_val_loss=0.01819  time=4.58s\n",
      "Epoch 9  loss=0.01705  val_loss=0.01795  sm_loss=0.01717  sm_val_loss=0.01799  time=4.43s\n",
      "Epoch 11  loss=0.01681  val_loss=0.01784  sm_loss=0.01695  sm_val_loss=0.01785  time=4.72s\n",
      "Epoch 12  loss=0.01664  val_loss=0.01773  sm_loss=0.01678  sm_val_loss=0.01779  time=4.45s\n",
      "Epoch 15  loss=0.01619  val_loss=0.01763  sm_loss=0.01634  sm_val_loss=0.01768  time=4.85s\n",
      "Epoch 16  loss=0.01608  val_loss=0.01756  sm_loss=0.01624  sm_val_loss=0.01761  time=4.76s\n",
      "Epoch 17  loss=0.01589  val_loss=0.01752  sm_loss=0.01605  sm_val_loss=0.01757  time=4.45s\n",
      "Fold 3 log loss: 0.01759128702965622\n",
      "Fold 4\n",
      "Epoch 1  loss=0.55816  val_loss=0.03233  sm_loss=0.55815  sm_val_loss=0.03232  time=4.27s\n",
      "Epoch 2  loss=0.02072  val_loss=0.01868  sm_loss=0.02069  sm_val_loss=0.01873  time=4.20s\n",
      "Epoch 3  loss=0.01830  val_loss=0.01791  sm_loss=0.01837  sm_val_loss=0.01794  time=4.19s\n",
      "Epoch 5  loss=0.01755  val_loss=0.01777  sm_loss=0.01765  sm_val_loss=0.01779  time=4.19s\n",
      "Epoch 6  loss=0.01746  val_loss=0.01771  sm_loss=0.01756  sm_val_loss=0.01773  time=4.63s\n",
      "Epoch 7  loss=0.01731  val_loss=0.01757  sm_loss=0.01743  sm_val_loss=0.01760  time=4.18s\n",
      "Epoch 9  loss=0.01705  val_loss=0.01746  sm_loss=0.01718  sm_val_loss=0.01750  time=4.57s\n",
      "Epoch 10  loss=0.01693  val_loss=0.01746  sm_loss=0.01707  sm_val_loss=0.01748  time=4.31s\n",
      "Epoch 11  loss=0.01681  val_loss=0.01740  sm_loss=0.01696  sm_val_loss=0.01742  time=4.28s\n",
      "Epoch 12  loss=0.01666  val_loss=0.01724  sm_loss=0.01682  sm_val_loss=0.01725  time=4.21s\n",
      "Epoch 14  loss=0.01634  val_loss=0.01700  sm_loss=0.01651  sm_val_loss=0.01702  time=4.41s\n",
      "Epoch 15  loss=0.01622  val_loss=0.01701  sm_loss=0.01640  sm_val_loss=0.01702  time=4.45s\n",
      "Epoch 16  loss=0.01603  val_loss=0.01690  sm_loss=0.01620  sm_val_loss=0.01693  time=4.25s\n",
      "Epoch 17  loss=0.01587  val_loss=0.01684  sm_loss=0.01606  sm_val_loss=0.01688  time=4.19s\n",
      "Epoch 18  loss=0.01572  val_loss=0.01684  sm_loss=0.01591  sm_val_loss=0.01686  time=4.17s\n",
      "Epoch 19  loss=0.01562  val_loss=0.01684  sm_loss=0.01581  sm_val_loss=0.01686  time=4.24s\n",
      "Epoch 20  loss=0.01558  val_loss=0.01682  sm_loss=0.01577  sm_val_loss=0.01685  time=4.16s\n",
      "Fold 4 log loss: 0.017019119589270718\n",
      "Fold 5\n",
      "Epoch 1  loss=0.56081  val_loss=0.03656  sm_loss=0.56080  sm_val_loss=0.03655  time=4.62s\n",
      "Epoch 2  loss=0.02093  val_loss=0.01949  sm_loss=0.02083  sm_val_loss=0.01948  time=4.63s\n",
      "Epoch 3  loss=0.01840  val_loss=0.01847  sm_loss=0.01848  sm_val_loss=0.01850  time=4.49s\n",
      "Epoch 4  loss=0.01779  val_loss=0.01821  sm_loss=0.01788  sm_val_loss=0.01823  time=4.29s\n",
      "Epoch 6  loss=0.01749  val_loss=0.01796  sm_loss=0.01759  sm_val_loss=0.01799  time=4.23s\n",
      "Epoch 10  loss=0.01698  val_loss=0.01779  sm_loss=0.01711  sm_val_loss=0.01781  time=4.17s\n",
      "Epoch 11  loss=0.01685  val_loss=0.01773  sm_loss=0.01698  sm_val_loss=0.01775  time=4.26s\n",
      "Epoch 12  loss=0.01673  val_loss=0.01772  sm_loss=0.01686  sm_val_loss=0.01772  time=4.26s\n",
      "Epoch 13  loss=0.01659  val_loss=0.01762  sm_loss=0.01673  sm_val_loss=0.01764  time=4.17s\n",
      "Epoch 14  loss=0.01645  val_loss=0.01746  sm_loss=0.01659  sm_val_loss=0.01747  time=4.33s\n",
      "Epoch 16  loss=0.01619  val_loss=0.01741  sm_loss=0.01634  sm_val_loss=0.01745  time=5.37s\n",
      "Epoch 17  loss=0.01604  val_loss=0.01729  sm_loss=0.01620  sm_val_loss=0.01731  time=4.52s\n",
      "Fold 5 log loss: 0.017339873992272867\n",
      "Fold 6\n",
      "Epoch 1  loss=0.55897  val_loss=0.03185  sm_loss=0.55897  sm_val_loss=0.03184  time=4.26s\n",
      "Epoch 2  loss=0.02071  val_loss=0.01935  sm_loss=0.02067  sm_val_loss=0.01931  time=4.19s\n",
      "Epoch 3  loss=0.01834  val_loss=0.01880  sm_loss=0.01841  sm_val_loss=0.01881  time=4.57s\n",
      "Epoch 4  loss=0.01787  val_loss=0.01837  sm_loss=0.01795  sm_val_loss=0.01841  time=4.25s\n",
      "Epoch 5  loss=0.01762  val_loss=0.01816  sm_loss=0.01772  sm_val_loss=0.01821  time=4.30s\n",
      "Epoch 7  loss=0.01730  val_loss=0.01800  sm_loss=0.01741  sm_val_loss=0.01800  time=4.17s\n",
      "Epoch 8  loss=0.01710  val_loss=0.01786  sm_loss=0.01721  sm_val_loss=0.01785  time=4.19s\n",
      "Epoch 10  loss=0.01687  val_loss=0.01770  sm_loss=0.01701  sm_val_loss=0.01773  time=4.55s\n",
      "Epoch 11  loss=0.01675  val_loss=0.01756  sm_loss=0.01689  sm_val_loss=0.01758  time=4.73s\n",
      "Epoch 12  loss=0.01658  val_loss=0.01753  sm_loss=0.01674  sm_val_loss=0.01754  time=4.32s\n",
      "Epoch 13  loss=0.01645  val_loss=0.01735  sm_loss=0.01660  sm_val_loss=0.01738  time=4.17s\n",
      "Epoch 15  loss=0.01611  val_loss=0.01725  sm_loss=0.01628  sm_val_loss=0.01728  time=4.36s\n",
      "Epoch 17  loss=0.01581  val_loss=0.01717  sm_loss=0.01598  sm_val_loss=0.01719  time=4.19s\n",
      "Epoch 18  loss=0.01570  val_loss=0.01716  sm_loss=0.01587  sm_val_loss=0.01718  time=4.58s\n",
      "Epoch 19  loss=0.01560  val_loss=0.01715  sm_loss=0.01577  sm_val_loss=0.01718  time=4.26s\n",
      "Fold 6 log loss: 0.017309259209518583\n",
      "Fold 7\n",
      "Epoch 1  loss=0.55759  val_loss=0.03944  sm_loss=0.55759  sm_val_loss=0.03943  time=4.23s\n",
      "Epoch 2  loss=0.02059  val_loss=0.01853  sm_loss=0.02056  sm_val_loss=0.01858  time=4.17s\n",
      "Epoch 3  loss=0.01828  val_loss=0.01796  sm_loss=0.01835  sm_val_loss=0.01802  time=4.51s\n",
      "Epoch 4  loss=0.01770  val_loss=0.01763  sm_loss=0.01779  sm_val_loss=0.01768  time=4.54s\n",
      "Epoch 9  loss=0.01706  val_loss=0.01759  sm_loss=0.01719  sm_val_loss=0.01762  time=4.32s\n",
      "Epoch 10  loss=0.01690  val_loss=0.01732  sm_loss=0.01704  sm_val_loss=0.01739  time=4.34s\n",
      "Epoch 12  loss=0.01663  val_loss=0.01719  sm_loss=0.01678  sm_val_loss=0.01726  time=4.17s\n",
      "Epoch 13  loss=0.01652  val_loss=0.01716  sm_loss=0.01668  sm_val_loss=0.01722  time=4.27s\n",
      "Epoch 15  loss=0.01619  val_loss=0.01709  sm_loss=0.01635  sm_val_loss=0.01714  time=4.34s\n",
      "Epoch 16  loss=0.01602  val_loss=0.01695  sm_loss=0.01620  sm_val_loss=0.01700  time=4.47s\n",
      "Epoch 18  loss=0.01575  val_loss=0.01695  sm_loss=0.01593  sm_val_loss=0.01699  time=4.37s\n",
      "Epoch 19  loss=0.01563  val_loss=0.01693  sm_loss=0.01581  sm_val_loss=0.01697  time=4.26s\n",
      "Fold 7 log loss: 0.01725284598809465\n",
      "Seed 4\n",
      "Fold 1 log loss: 0.01706632273616957\n",
      "Fold 2 log loss: 0.017107314787734543\n",
      "Fold 3 log loss: 0.01759128702965622\n",
      "Fold 4 log loss: 0.017019119589270718\n",
      "Fold 5 log loss: 0.017339873992272867\n",
      "Fold 6 log loss: 0.017309259209518583\n",
      "Fold 7 log loss: 0.01725284598809465\n",
      "Std of log loss: 0.0001831827266833805\n",
      "Total log loss: 0.01724115516375754\n",
      "Total log loss in targets: 0.017171332863942887\n"
     ]
    }
   ],
   "source": [
    "target_oof = np.zeros([len(fn_train),fn_targets.shape[1]])\n",
    "target_pred = np.zeros([len(fn_test),fn_targets.shape[1]])\n",
    "\n",
    "seeds = [0,1,2,3,4] \n",
    "    \n",
    "for seed_ in seeds:\n",
    "    oof, oof_targets, pytorch_pred = torch_tl(fn_train, fn_targets, fn_test, seed_, fn_train.shape[1]-1)\n",
    "    target_oof += oof / len(seeds)\n",
    "    target_pred += pytorch_pred / len(seeds)\n",
    "\n",
    "print(\"Total log loss in targets: {}\".format(mean_log_loss(oof_targets, target_oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T13:03:52.602532Z",
     "iopub.status.busy": "2020-11-13T13:03:52.601676Z",
     "iopub.status.idle": "2020-11-13T13:03:54.017803Z",
     "shell.execute_reply": "2020-11-13T13:03:54.017043Z"
    },
    "papermill": {
     "duration": 1.684667,
     "end_time": "2020-11-13T13:03:54.017944",
     "exception": false,
     "start_time": "2020-11-13T13:03:52.333277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AUC : 0.6512498956385518\n"
     ]
    }
   ],
   "source": [
    "aucs = []\n",
    "for task_id in range(targets.shape[1]-1):\n",
    "    aucs.append(roc_auc_score(y_true=targets.iloc[:, task_id+1].values,\n",
    "                              y_score=target_oof[:, task_id]))\n",
    "print(f\"Overall AUC : {np.mean(aucs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T13:03:54.547416Z",
     "iopub.status.busy": "2020-11-13T13:03:54.546257Z",
     "iopub.status.idle": "2020-11-13T13:04:01.943620Z",
     "shell.execute_reply": "2020-11-13T13:04:01.942995Z"
    },
    "papermill": {
     "duration": 7.666691,
     "end_time": "2020-11-13T13:04:01.943752",
     "exception": false,
     "start_time": "2020-11-13T13:03:54.277061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF log loss:  0.015825834118494173\n"
     ]
    }
   ],
   "source": [
    "t = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "train_checkscore = t.copy()\n",
    "train_checkscore.loc[train_checkscore.index.isin(cons_train_index),target_feats] = target_oof\n",
    "train_checkscore.loc[train_checkscore.index.isin(noncons_train_index),target_feats] = 0\n",
    "t.drop(\"sig_id\", axis=1, inplace=True)\n",
    "print('OOF log loss: ', log_loss(np.ravel(t), np.ravel(np.array(train_checkscore.iloc[:,1:]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T13:04:02.468195Z",
     "iopub.status.busy": "2020-11-13T13:04:02.466908Z",
     "iopub.status.idle": "2020-11-13T13:04:05.411258Z",
     "shell.execute_reply": "2020-11-13T13:04:05.410450Z"
    },
    "papermill": {
     "duration": 3.208944,
     "end_time": "2020-11-13T13:04:05.411386",
     "exception": false,
     "start_time": "2020-11-13T13:04:02.202442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.loc[cons_test_index,target_feats] = target_pred\n",
    "sub.loc[noncons_test_index,target_feats] = 0\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 3278.125824,
   "end_time": "2020-11-13T13:04:05.778051",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-13T12:09:27.652227",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
