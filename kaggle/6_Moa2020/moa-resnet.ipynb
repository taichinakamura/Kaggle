{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019158,
     "end_time": "2020-11-12T14:10:24.775698",
     "exception": false,
     "start_time": "2020-11-12T14:10:24.756540",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- nquantile: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-12T14:10:24.823128Z",
     "iopub.status.busy": "2020-11-12T14:10:24.822343Z",
     "iopub.status.idle": "2020-11-12T14:10:36.395644Z",
     "shell.execute_reply": "2020-11-12T14:10:36.394400Z"
    },
    "papermill": {
     "duration": 11.601092,
     "end_time": "2020-11-12T14:10:36.395806",
     "exception": false,
     "start_time": "2020-11-12T14:10:24.794714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from umap import UMAP\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss,roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "sys.path.append('../input/multilabelstraifier/')\n",
    "from ml_stratifiers import MultilabelStratifiedKFold\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "from torch.nn.modules.loss import _WeightedLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T14:10:36.439692Z",
     "iopub.status.busy": "2020-11-12T14:10:36.438880Z",
     "iopub.status.idle": "2020-11-12T14:10:36.445487Z",
     "shell.execute_reply": "2020-11-12T14:10:36.444917Z"
    },
    "papermill": {
     "duration": 0.029039,
     "end_time": "2020-11-12T14:10:36.445594",
     "exception": false,
     "start_time": "2020-11-12T14:10:36.416555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_file_path = '../input/moapredictors/main_predictors.json'\n",
    "\n",
    "with open(json_file_path, 'r') as j:\n",
    "    predictors = json.loads(j.read())\n",
    "    predictors = predictors['start_predictors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-12T14:10:36.488950Z",
     "iopub.status.busy": "2020-11-12T14:10:36.487900Z",
     "iopub.status.idle": "2020-11-12T14:10:43.294732Z",
     "shell.execute_reply": "2020-11-12T14:10:43.293647Z"
    },
    "papermill": {
     "duration": 6.831367,
     "end_time": "2020-11-12T14:10:43.294884",
     "exception": false,
     "start_time": "2020-11-12T14:10:36.463517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/lish-moa/'\n",
    "train = pd.read_csv(DATA_DIR + 'train_features.csv')\n",
    "targets = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "non_targets = pd.read_csv(DATA_DIR + 'train_targets_nonscored.csv')\n",
    "test = pd.read_csv(DATA_DIR + 'test_features.csv')\n",
    "sub = pd.read_csv(DATA_DIR + 'sample_submission.csv')\n",
    "drug = pd.read_csv(DATA_DIR + 'train_drug.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T14:10:43.338689Z",
     "iopub.status.busy": "2020-11-12T14:10:43.338055Z",
     "iopub.status.idle": "2020-11-12T14:10:43.342476Z",
     "shell.execute_reply": "2020-11-12T14:10:43.341861Z"
    },
    "papermill": {
     "duration": 0.028757,
     "end_time": "2020-11-12T14:10:43.342589",
     "exception": false,
     "start_time": "2020-11-12T14:10:43.313832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_feats = [ i for i in targets.columns if i != \"sig_id\"]\n",
    "g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "c_feats = [i for i in train.columns if \"c-\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T14:10:43.394995Z",
     "iopub.status.busy": "2020-11-12T14:10:43.394333Z",
     "iopub.status.idle": "2020-11-12T14:10:43.491649Z",
     "shell.execute_reply": "2020-11-12T14:10:43.490657Z"
    },
    "papermill": {
     "duration": 0.125865,
     "end_time": "2020-11-12T14:10:43.491798",
     "exception": false,
     "start_time": "2020-11-12T14:10:43.365933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "noncons_train_index = train[train.cp_type==\"ctl_vehicle\"].index\n",
    "cons_train_index = train[train.cp_type!=\"ctl_vehicle\"].index\n",
    "noncons_test_index = test[test.cp_type==\"ctl_vehicle\"].index\n",
    "cons_test_index = test[test.cp_type!=\"ctl_vehicle\"].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019108,
     "end_time": "2020-11-12T14:10:43.529700",
     "exception": false,
     "start_time": "2020-11-12T14:10:43.510592",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T14:10:43.580057Z",
     "iopub.status.busy": "2020-11-12T14:10:43.575898Z",
     "iopub.status.idle": "2020-11-12T14:10:43.832932Z",
     "shell.execute_reply": "2020-11-12T14:10:43.832305Z"
    },
    "papermill": {
     "duration": 0.284888,
     "end_time": "2020-11-12T14:10:43.833040",
     "exception": false,
     "start_time": "2020-11-12T14:10:43.548152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train[train.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "test = test[test.index.isin(cons_test_index)].copy().reset_index(drop=True)\n",
    "targets = targets[targets.index.isin(cons_train_index)].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T14:10:44.062247Z",
     "iopub.status.busy": "2020-11-12T14:10:44.046131Z",
     "iopub.status.idle": "2020-11-12T14:10:44.766272Z",
     "shell.execute_reply": "2020-11-12T14:10:44.765672Z"
    },
    "papermill": {
     "duration": 0.914661,
     "end_time": "2020-11-12T14:10:44.766394",
     "exception": false,
     "start_time": "2020-11-12T14:10:43.851733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 6, 5, ..., 1, 1, 6]], dtype=int8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/c/lish-moa/discussion/195195\n",
    "NB_SPLITS = 7\n",
    "seed = 14\n",
    "\n",
    "folds = []\n",
    "    \n",
    "# LOAD FILES\n",
    "train_score = targets.merge(drug, on='sig_id', how='left') \n",
    "\n",
    "# LOCATE DRUGS\n",
    "vc = train_score.drug_id.value_counts()\n",
    "vc1 = vc.loc[(vc==6)|(vc==12)|(vc==18)].index.sort_values()\n",
    "vc2 = vc.loc[(vc!=6)&(vc!=12)&(vc!=18)].index.sort_values()\n",
    "\n",
    "# STRATIFY DRUGS 1000X OR LESS\n",
    "dct1 = {}; dct2 = {}\n",
    "skf = MultilabelStratifiedKFold(n_splits = NB_SPLITS, shuffle = True, random_state = seed)\n",
    "tmp = train_score.groupby('drug_id')[target_feats].mean().loc[vc1]\n",
    "for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_feats])):\n",
    "    dd = {k:fold for k in tmp.index[idxV].values}\n",
    "    dct1.update(dd)\n",
    "\n",
    "# STRATIFY DRUGS MORE THAN 18X\n",
    "skf = MultilabelStratifiedKFold(n_splits = NB_SPLITS, shuffle = True, random_state = seed)\n",
    "tmp = train_score.loc[train_score.drug_id.isin(vc2)].reset_index(drop = True)\n",
    "for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_feats])):\n",
    "    dd = {k:fold for k in tmp.sig_id[idxV].values}\n",
    "    dct2.update(dd)\n",
    "\n",
    "# ASSIGN FOLDS\n",
    "train_score['fold'] = train_score.drug_id.map(dct1)\n",
    "train_score.loc[train_score.fold.isna(),'fold'] = train_score.loc[train_score.fold.isna(),'sig_id'].map(dct2)\n",
    "train_score.fold = train_score.fold.astype('int8')\n",
    "folds.append(train_score.fold.values)\n",
    "    \n",
    "np.array(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020681,
     "end_time": "2020-11-12T14:10:44.808481",
     "exception": false,
     "start_time": "2020-11-12T14:10:44.787800",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature enginnering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T14:10:44.907525Z",
     "iopub.status.busy": "2020-11-12T14:10:44.906046Z",
     "iopub.status.idle": "2020-11-12T14:10:45.296171Z",
     "shell.execute_reply": "2020-11-12T14:10:45.296709Z"
    },
    "papermill": {
     "duration": 0.467457,
     "end_time": "2020-11-12T14:10:45.296874",
     "exception": false,
     "start_time": "2020-11-12T14:10:44.829417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = train.iloc[:,4:].copy().values\n",
    "select = VarianceThreshold(threshold=0.6)\n",
    "X_new = select.fit_transform(X)\n",
    "drop_feats = list(np.array(train.iloc[:,4:].columns)[select.get_support()==False])\n",
    "len(drop_feats)\n",
    "\n",
    "train.drop(drop_feats, axis=1, inplace=True)\n",
    "test.drop(drop_feats, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T14:10:45.341950Z",
     "iopub.status.busy": "2020-11-12T14:10:45.341258Z",
     "iopub.status.idle": "2020-11-12T14:10:45.345607Z",
     "shell.execute_reply": "2020-11-12T14:10:45.344993Z"
    },
    "papermill": {
     "duration": 0.029175,
     "end_time": "2020-11-12T14:10:45.345718",
     "exception": false,
     "start_time": "2020-11-12T14:10:45.316543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "c_feats = [i for i in train.columns if \"c-\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T14:10:45.402684Z",
     "iopub.status.busy": "2020-11-12T14:10:45.401280Z",
     "iopub.status.idle": "2020-11-12T14:10:54.571494Z",
     "shell.execute_reply": "2020-11-12T14:10:54.570294Z"
    },
    "papermill": {
     "duration": 9.205671,
     "end_time": "2020-11-12T14:10:54.571644",
     "exception": false,
     "start_time": "2020-11-12T14:10:45.365973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rank gauss\n",
    "for i in c_feats + g_feats:\n",
    "    ss = preprocessing.QuantileTransformer(n_quantiles=100, random_state=0, output_distribution=\"normal\")\n",
    "    ss.fit(train[i].values.reshape(-1,1))\n",
    "    train[i] = ss.transform(train[i].values.reshape(-1,1))\n",
    "    test[i] = ss.transform(test[i].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T14:10:54.647259Z",
     "iopub.status.busy": "2020-11-12T14:10:54.645172Z",
     "iopub.status.idle": "2020-11-12T14:10:56.892819Z",
     "shell.execute_reply": "2020-11-12T14:10:56.892216Z"
    },
    "papermill": {
     "duration": 2.296715,
     "end_time": "2020-11-12T14:10:56.892947",
     "exception": false,
     "start_time": "2020-11-12T14:10:54.596232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_num = 10\n",
    "pca_c_cols = [\"pca-c\"+str(i+1) for i in range(c_num)]\n",
    "pca = PCA(n_components=c_num,random_state=42)\n",
    "c_train = pca.fit_transform(train[c_feats])\n",
    "c_test = pca.transform(test[c_feats])\n",
    "c_train = pd.DataFrame(c_train, columns=pca_c_cols)\n",
    "c_test = pd.DataFrame(c_test, columns=pca_c_cols)\n",
    "\n",
    "g_num = 60\n",
    "pca_g_cols = [\"pca-g\"+str(i+1) for i in range(g_num)]\n",
    "pca = PCA(n_components=g_num, random_state=42)\n",
    "g_train = pca.fit_transform(train[g_feats])\n",
    "g_test = pca.transform(test[g_feats])\n",
    "g_train = pd.DataFrame(g_train, columns=pca_g_cols)\n",
    "g_test = pd.DataFrame(g_test, columns=pca_g_cols)\n",
    "\n",
    "train = pd.concat([train, c_train],axis=1)\n",
    "test = pd.concat([test, c_test],axis=1)\n",
    "train = pd.concat([train, g_train],axis=1)\n",
    "test = pd.concat([test, g_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T14:10:56.941817Z",
     "iopub.status.busy": "2020-11-12T14:10:56.940799Z",
     "iopub.status.idle": "2020-11-12T14:10:58.846835Z",
     "shell.execute_reply": "2020-11-12T14:10:58.847439Z"
    },
    "papermill": {
     "duration": 1.934234,
     "end_time": "2020-11-12T14:10:58.847592",
     "exception": false,
     "start_time": "2020-11-12T14:10:56.913358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 933) (3624, 933)\n"
     ]
    }
   ],
   "source": [
    "def fe(df):\n",
    "    tmp = df.copy()\n",
    "    tmp['g_kurt'] = tmp[g_feats].kurtosis(axis = 1)\n",
    "    tmp['g_skew'] = tmp[g_feats].skew(axis = 1)\n",
    "    tmp['c_kurt'] = tmp[c_feats].kurtosis(axis = 1)\n",
    "    tmp['c_skew'] = tmp[c_feats].skew(axis = 1)\n",
    "    tmp = pd.get_dummies(tmp, columns=['cp_time','cp_dose'])\n",
    "    tmp.drop([\"cp_type\", \"sig_id\"], axis=1, inplace=True) \n",
    "    return tmp\n",
    "\n",
    "train = fe(train)\n",
    "test = fe(test)\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T14:10:58.900278Z",
     "iopub.status.busy": "2020-11-12T14:10:58.899213Z",
     "iopub.status.idle": "2020-11-12T14:10:58.902114Z",
     "shell.execute_reply": "2020-11-12T14:10:58.902708Z"
    },
    "papermill": {
     "duration": 0.033142,
     "end_time": "2020-11-12T14:10:58.902850",
     "exception": false,
     "start_time": "2020-11-12T14:10:58.869708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[\"fold\"] = np.array(folds).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T14:10:58.965346Z",
     "iopub.status.busy": "2020-11-12T14:10:58.963044Z",
     "iopub.status.idle": "2020-11-12T14:10:58.968268Z",
     "shell.execute_reply": "2020-11-12T14:10:58.967703Z"
    },
    "papermill": {
     "duration": 0.042089,
     "end_time": "2020-11-12T14:10:58.968366",
     "exception": false,
     "start_time": "2020-11-12T14:10:58.926277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictors_index = []\n",
    "for i in range(len(train.columns)):\n",
    "    if train.columns[i] in predictors:\n",
    "        predictors_index.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T14:10:59.018600Z",
     "iopub.status.busy": "2020-11-12T14:10:59.017341Z",
     "iopub.status.idle": "2020-11-12T14:10:59.120052Z",
     "shell.execute_reply": "2020-11-12T14:10:59.119524Z"
    },
    "papermill": {
     "duration": 0.130945,
     "end_time": "2020-11-12T14:10:59.120200",
     "exception": false,
     "start_time": "2020-11-12T14:10:58.989255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fn_train = train.copy()\n",
    "fn_test = test.copy()\n",
    "\n",
    "fn_targets = targets.drop(\"sig_id\", axis=1).copy().to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020407,
     "end_time": "2020-11-12T14:10:59.160858",
     "exception": false,
     "start_time": "2020-11-12T14:10:59.140451",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T14:10:59.214634Z",
     "iopub.status.busy": "2020-11-12T14:10:59.213782Z",
     "iopub.status.idle": "2020-11-12T14:10:59.216437Z",
     "shell.execute_reply": "2020-11-12T14:10:59.216937Z"
    },
    "papermill": {
     "duration": 0.035225,
     "end_time": "2020-11-12T14:10:59.217060",
     "exception": false,
     "start_time": "2020-11-12T14:10:59.181835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SmoothCrossEntropyLoss(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets, n_classes, smoothing=0.0):\n",
    "        assert 0 <= smoothing <= 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1 - smoothing) + torch.ones_like(targets).to(device) * smoothing / n_classes\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothCrossEntropyLoss()._smooth(targets, inputs.shape[1], self.smoothing)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            inputs = inputs * self.weight.unsqueeze(0)\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T14:10:59.655485Z",
     "iopub.status.busy": "2020-11-12T14:10:59.272401Z",
     "iopub.status.idle": "2020-11-12T14:10:59.661035Z",
     "shell.execute_reply": "2020-11-12T14:10:59.661583Z"
    },
    "papermill": {
     "duration": 0.423033,
     "end_time": "2020-11-12T14:10:59.661717",
     "exception": false,
     "start_time": "2020-11-12T14:10:59.238684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(device)\n",
    "def mean_log_loss(y_true, y_pred):\n",
    "    metrics = []\n",
    "    for i, target in enumerate(target_feats):\n",
    "        metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float), labels=[0,1]))\n",
    "    return np.mean(metrics)\n",
    "\n",
    "def seed_everything(seed=42): \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "class MoaModel(nn.Module):\n",
    "    def __init__(self, num_columns, last_num):\n",
    "        super(MoaModel, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_columns)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dense1 = nn.Linear(num_columns, 512)\n",
    "        self.relu1 = nn.ELU()\n",
    "        self.dense12 = nn.Linear(512, 256)\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(256+len(predictors_index))\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.dense2 = nn.Linear(256+len(predictors_index), 512)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.batch_norm22 = nn.BatchNorm1d(512)\n",
    "        self.dense22 = nn.Linear(512, 512)\n",
    "        self.relu22 = nn.ELU()\n",
    "        self.batch_norm23 = nn.BatchNorm1d(512)\n",
    "        self.dense23 = nn.Linear(512, 256)\n",
    "        self.relu23 = nn.ReLU()\n",
    "        self.batch_norm24 = nn.BatchNorm1d(256)\n",
    "        self.dense24 = nn.Linear(256, 256)\n",
    "        self.relu24 = nn.ELU()\n",
    "                \n",
    "        self.batch_norm3 = nn.BatchNorm1d(256)\n",
    "        self.dense3 = nn.Linear(256, 256)\n",
    "        self.relu3 = nn.SELU()\n",
    "        self.batch_norm32 = nn.BatchNorm1d(256)\n",
    "        self.dense32 = nn.Linear(256, last_num)\n",
    "        self.relu32 = nn.SELU()\n",
    "        self.dense33 = nn.Linear(last_num, last_num)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.batch_norm1(x1)\n",
    "        x1 = self.dropout1(x1)\n",
    "        x1 = self.relu1(self.dense1(x1))\n",
    "        x1 = self.dense12(x1)\n",
    "        \n",
    "        x3 = torch.cat([x1,x2],axis=1)\n",
    "                \n",
    "        x3 = self.batch_norm2(x3)\n",
    "        x3 = self.dropout2(x3)\n",
    "        x3 = self.relu2(self.dense2(x3))\n",
    "        x3 = self.batch_norm22(x3)\n",
    "        x3 = self.relu22(self.dense22(x3))\n",
    "        x3 = self.batch_norm23(x3)\n",
    "        x3 = self.relu23(self.dense23(x3))\n",
    "        x3 = self.batch_norm24(x3)\n",
    "        x3 = self.relu24(self.dense24(x3))\n",
    "        \n",
    "        x4 = (x1 + x3) / 2\n",
    "        \n",
    "        x4 = self.batch_norm3(x4)\n",
    "        x4 = self.relu3(self.dense3(x4))\n",
    "        x4 = self.batch_norm32(x4)\n",
    "        x4 = self.relu32(self.dense32(x4))\n",
    "        x4 = self.dense33(x4)\n",
    "        \n",
    "        return x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T14:10:59.735075Z",
     "iopub.status.busy": "2020-11-12T14:10:59.719421Z",
     "iopub.status.idle": "2020-11-12T14:10:59.758583Z",
     "shell.execute_reply": "2020-11-12T14:10:59.758111Z"
    },
    "papermill": {
     "duration": 0.07526,
     "end_time": "2020-11-12T14:10:59.758680",
     "exception": false,
     "start_time": "2020-11-12T14:10:59.683420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_folds=7\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "smoothing = 0.001\n",
    "p_min = smoothing\n",
    "p_max = 1 - smoothing\n",
    "\n",
    "def torch_tl(tr, target, te, sample_seed, init_num):\n",
    "    seed_everything(seed=sample_seed) \n",
    "    test_len = te.shape[0]\n",
    "    \n",
    "    train_epochs = 20\n",
    "        \n",
    "    metric = lambda inputs, targets : F.binary_cross_entropy((torch.clamp(torch.sigmoid(inputs), p_min, p_max)), targets)\n",
    "    models = []\n",
    "    \n",
    "    X_test = torch.tensor(te.values, dtype=torch.float32)\n",
    "    X_test2 = torch.tensor(te.iloc[:][predictors].values, dtype=torch.float32)\n",
    "    test = torch.utils.data.TensorDataset(X_test, X_test2) \n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    oof = np.zeros([len(tr),target.shape[1]])\n",
    "    oof_targets = np.zeros([len(tr),target.shape[1]])\n",
    "    pred_value = np.zeros([test_len, target.shape[1]])\n",
    "    scores = []\n",
    "    for fold in range(n_folds):\n",
    "        valid_index = tr[\"fold\"] == fold\n",
    "        train_index = tr[\"fold\"] != fold\n",
    "        print(\"Fold \"+str(fold+1))\n",
    "        X_train1 = torch.tensor(tr[train_index].values, dtype=torch.float32)\n",
    "        X_valid1 = torch.tensor(tr[valid_index].values, dtype=torch.float32)\n",
    "        X_train2 = torch.tensor(tr[train_index][predictors].values, dtype=torch.float32)\n",
    "        X_valid2 = torch.tensor(tr[valid_index][predictors].values, dtype=torch.float32)\n",
    "        \n",
    "        y_train2 = torch.tensor(target[train_index], dtype=torch.float32)\n",
    "        y_valid2 = torch.tensor(target[valid_index], dtype=torch.float32)\n",
    "        \n",
    "        X_train1 = X_train1[:,:-1]\n",
    "        X_valid1 = X_valid1[:,:-1]\n",
    "        \n",
    "        train = torch.utils.data.TensorDataset(X_train1, X_train2, y_train2)\n",
    "        valid = torch.utils.data.TensorDataset(X_valid1, X_valid2, y_valid2)\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True) \n",
    "        valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "            \n",
    "        clf = MoaModel(init_num, len(target_feats))\n",
    "\n",
    "        loss_fn = SmoothCrossEntropyLoss(smoothing=smoothing)\n",
    "            \n",
    "        optimizer = optim.Adam(clf.parameters(), lr = 0.01, weight_decay=1e-5) \n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=train_epochs, steps_per_epoch=len(train_loader))            \n",
    "       \n",
    "        clf.to(device)\n",
    "        best_val_loss = np.inf\n",
    "        stop_counts = 0\n",
    "        \n",
    "        for epoch in range(train_epochs):\n",
    "            start_time = time.time()\n",
    "            clf.train()\n",
    "            avg_loss = 0.\n",
    "            sm_avg_loss = 0.\n",
    "            for x_batch, x_batch2, y_batch in tqdm(train_loader, disable=True):\n",
    "                x_batch = x_batch.to(device)\n",
    "                x_batch2 = x_batch2.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch, x_batch2) \n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                avg_loss += loss.item() / len(train_loader)  \n",
    "                sm_avg_loss += metric(y_pred, y_batch) / len(train_loader)      \n",
    "            \n",
    "            clf.eval()\n",
    "            avg_val_loss = 0.\n",
    "            sm_avg_val_loss = 0.\n",
    "            \n",
    "            for i, (x_batch, x_batch2, y_batch) in enumerate(valid_loader): \n",
    "                x_batch = x_batch.to(device)\n",
    "                x_batch2 = x_batch2.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch, x_batch2).detach()\n",
    "                avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "                sm_avg_val_loss += metric(y_pred, y_batch) / len(valid_loader)\n",
    "                \n",
    "            elapsed_time = time.time() - start_time\n",
    "                    \n",
    "            if sm_avg_val_loss < best_val_loss:\n",
    "                best_val_loss = sm_avg_val_loss\n",
    "                print('Epoch {}  loss={:.5f}  val_loss={:.5f}  sm_loss={:.5f}  sm_val_loss={:.5f}  time={:.2f}s'.format(\n",
    "                    epoch + 1, avg_loss, avg_val_loss, sm_avg_loss, sm_avg_val_loss, elapsed_time))\n",
    "                torch.save(clf.state_dict(), 'best-model-parameters.pt')\n",
    "                \n",
    "        pred_model = MoaModel(init_num, len(target_feats))\n",
    "        pred_model.load_state_dict(torch.load('best-model-parameters.pt'))         \n",
    "        pred_model.eval()\n",
    "        \n",
    "        # validation check ----------------\n",
    "        oof_epoch = np.zeros([X_valid2.size(0), target.shape[1]])\n",
    "        target_epoch = np.zeros([X_valid2.size(0), target.shape[1]])\n",
    "        for i, (x_batch, x_batch2, y_batch) in enumerate(valid_loader): \n",
    "            y_pred = pred_model(x_batch, x_batch2).detach()\n",
    "            oof_epoch[i * batch_size:(i+1) * batch_size,:] = torch.clamp(torch.sigmoid(y_pred.cpu()), p_min, p_max)\n",
    "            target_epoch[i * batch_size:(i+1) * batch_size,:] = y_batch.cpu().numpy()\n",
    "        print(\"Fold {} log loss: {}\".format(fold+1, mean_log_loss(target_epoch, oof_epoch)))\n",
    "        scores.append(mean_log_loss(target_epoch, oof_epoch))\n",
    "        oof[valid_index,:] = oof_epoch\n",
    "        oof_targets[valid_index,:] = target_epoch\n",
    "        #-----------------------------------\n",
    "        \n",
    "\n",
    "        # test predcition --------------\n",
    "        test_preds = np.zeros([test_len, target.shape[1]])\n",
    "        for i, (x_batch,x_batch2,) in enumerate(test_loader): \n",
    "            y_pred = pred_model(x_batch,x_batch2).detach()\n",
    "            test_preds[i * batch_size:(i+1) * batch_size, :] = torch.clamp(torch.sigmoid(y_pred.cpu()), p_min, p_max)\n",
    "        pred_value += test_preds / n_folds\n",
    "        # ------------------------------\n",
    "    \n",
    "    print(\"Seed {}\".format(sample_seed))\n",
    "    for i, ele in enumerate(scores):\n",
    "        print(\"Fold {} log loss: {}\".format(i+1, scores[i]))\n",
    "    print(\"Std of log loss: {}\".format(np.std(scores)))\n",
    "    print(\"Total log loss: {}\".format(mean_log_loss(oof_targets, oof)))\n",
    "    \n",
    "    return oof, oof_targets, pred_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T14:10:59.809616Z",
     "iopub.status.busy": "2020-11-12T14:10:59.808768Z",
     "iopub.status.idle": "2020-11-12T14:35:08.550799Z",
     "shell.execute_reply": "2020-11-12T14:35:08.551315Z"
    },
    "papermill": {
     "duration": 1448.771573,
     "end_time": "2020-11-12T14:35:08.551468",
     "exception": false,
     "start_time": "2020-11-12T14:10:59.779895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1  loss=0.28403  val_loss=0.02225  sm_loss=0.28323  sm_val_loss=0.02154  time=2.84s\n",
      "Epoch 2  loss=0.02057  val_loss=0.01930  sm_loss=0.02055  sm_val_loss=0.01934  time=1.94s\n",
      "Epoch 4  loss=0.01890  val_loss=0.01886  sm_loss=0.01896  sm_val_loss=0.01890  time=1.86s\n",
      "Epoch 5  loss=0.01852  val_loss=0.01876  sm_loss=0.01861  sm_val_loss=0.01879  time=1.84s\n",
      "Epoch 6  loss=0.01838  val_loss=0.01797  sm_loss=0.01847  sm_val_loss=0.01806  time=1.84s\n",
      "Epoch 10  loss=0.01752  val_loss=0.01780  sm_loss=0.01767  sm_val_loss=0.01785  time=2.18s\n",
      "Epoch 11  loss=0.01737  val_loss=0.01752  sm_loss=0.01753  sm_val_loss=0.01760  time=1.90s\n",
      "Epoch 12  loss=0.01721  val_loss=0.01739  sm_loss=0.01738  sm_val_loss=0.01747  time=1.88s\n",
      "Epoch 13  loss=0.01698  val_loss=0.01731  sm_loss=0.01716  sm_val_loss=0.01739  time=2.03s\n",
      "Epoch 14  loss=0.01674  val_loss=0.01725  sm_loss=0.01694  sm_val_loss=0.01731  time=2.04s\n",
      "Epoch 15  loss=0.01652  val_loss=0.01718  sm_loss=0.01673  sm_val_loss=0.01724  time=2.23s\n",
      "Epoch 16  loss=0.01629  val_loss=0.01705  sm_loss=0.01651  sm_val_loss=0.01711  time=1.84s\n",
      "Epoch 18  loss=0.01584  val_loss=0.01695  sm_loss=0.01609  sm_val_loss=0.01700  time=1.86s\n",
      "Fold 1 log loss: 0.017015030247899514\n",
      "Fold 2\n",
      "Epoch 1  loss=0.28671  val_loss=0.02095  sm_loss=0.28587  sm_val_loss=0.02087  time=1.85s\n",
      "Epoch 2  loss=0.02075  val_loss=0.01989  sm_loss=0.02072  sm_val_loss=0.01986  time=1.89s\n",
      "Epoch 4  loss=0.01913  val_loss=0.01912  sm_loss=0.01917  sm_val_loss=0.01909  time=2.08s\n",
      "Epoch 7  loss=0.01824  val_loss=0.01886  sm_loss=0.01834  sm_val_loss=0.01886  time=1.86s\n",
      "Epoch 8  loss=0.01794  val_loss=0.01801  sm_loss=0.01807  sm_val_loss=0.01809  time=1.87s\n",
      "Epoch 9  loss=0.01778  val_loss=0.01785  sm_loss=0.01791  sm_val_loss=0.01788  time=1.86s\n",
      "Epoch 12  loss=0.01735  val_loss=0.01776  sm_loss=0.01752  sm_val_loss=0.01780  time=1.85s\n",
      "Epoch 13  loss=0.01714  val_loss=0.01771  sm_loss=0.01731  sm_val_loss=0.01776  time=1.85s\n",
      "Epoch 14  loss=0.01689  val_loss=0.01764  sm_loss=0.01708  sm_val_loss=0.01767  time=1.86s\n",
      "Epoch 16  loss=0.01656  val_loss=0.01746  sm_loss=0.01678  sm_val_loss=0.01747  time=1.84s\n",
      "Epoch 17  loss=0.01633  val_loss=0.01742  sm_loss=0.01656  sm_val_loss=0.01743  time=2.33s\n",
      "Epoch 18  loss=0.01611  val_loss=0.01737  sm_loss=0.01635  sm_val_loss=0.01738  time=2.19s\n",
      "Epoch 19  loss=0.01601  val_loss=0.01734  sm_loss=0.01626  sm_val_loss=0.01736  time=1.99s\n",
      "Epoch 20  loss=0.01590  val_loss=0.01734  sm_loss=0.01616  sm_val_loss=0.01734  time=1.96s\n",
      "Fold 2 log loss: 0.017327726603174547\n",
      "Fold 3\n",
      "Epoch 1  loss=0.27964  val_loss=0.02191  sm_loss=0.27874  sm_val_loss=0.02167  time=2.01s\n",
      "Epoch 5  loss=0.02173  val_loss=0.02135  sm_loss=0.02129  sm_val_loss=0.02088  time=2.51s\n",
      "Epoch 6  loss=0.02080  val_loss=0.02053  sm_loss=0.02068  sm_val_loss=0.02036  time=1.92s\n",
      "Epoch 7  loss=0.01993  val_loss=0.02018  sm_loss=0.01995  sm_val_loss=0.02009  time=1.88s\n",
      "Epoch 8  loss=0.01942  val_loss=0.01958  sm_loss=0.01947  sm_val_loss=0.01953  time=1.92s\n",
      "Epoch 9  loss=0.01901  val_loss=0.01924  sm_loss=0.01910  sm_val_loss=0.01919  time=1.88s\n",
      "Epoch 10  loss=0.01859  val_loss=0.01893  sm_loss=0.01872  sm_val_loss=0.01891  time=1.88s\n",
      "Epoch 12  loss=0.01798  val_loss=0.01859  sm_loss=0.01815  sm_val_loss=0.01853  time=1.87s\n",
      "Epoch 13  loss=0.01761  val_loss=0.01857  sm_loss=0.01780  sm_val_loss=0.01844  time=1.91s\n",
      "Epoch 14  loss=0.01737  val_loss=0.01827  sm_loss=0.01757  sm_val_loss=0.01824  time=1.89s\n",
      "Epoch 16  loss=0.01689  val_loss=0.01807  sm_loss=0.01712  sm_val_loss=0.01800  time=2.16s\n",
      "Epoch 18  loss=0.01640  val_loss=0.01807  sm_loss=0.01666  sm_val_loss=0.01796  time=1.88s\n",
      "Epoch 19  loss=0.01618  val_loss=0.01809  sm_loss=0.01645  sm_val_loss=0.01795  time=1.89s\n",
      "Epoch 20  loss=0.01604  val_loss=0.01807  sm_loss=0.01633  sm_val_loss=0.01792  time=1.89s\n",
      "Fold 3 log loss: 0.01792599685812261\n",
      "Fold 4\n",
      "Epoch 1  loss=0.28513  val_loss=0.02168  sm_loss=0.28460  sm_val_loss=0.02147  time=2.66s\n",
      "Epoch 2  loss=0.02072  val_loss=0.01964  sm_loss=0.02069  sm_val_loss=0.01964  time=1.99s\n",
      "Epoch 3  loss=0.01971  val_loss=0.01921  sm_loss=0.01974  sm_val_loss=0.01922  time=1.96s\n",
      "Epoch 5  loss=0.01870  val_loss=0.01905  sm_loss=0.01878  sm_val_loss=0.01887  time=2.30s\n",
      "Epoch 6  loss=0.01830  val_loss=0.01837  sm_loss=0.01841  sm_val_loss=0.01833  time=1.91s\n",
      "Epoch 7  loss=0.01809  val_loss=0.01807  sm_loss=0.01820  sm_val_loss=0.01799  time=2.51s\n",
      "Epoch 9  loss=0.01770  val_loss=0.01772  sm_loss=0.01784  sm_val_loss=0.01770  time=1.88s\n",
      "Epoch 12  loss=0.01712  val_loss=0.01768  sm_loss=0.01730  sm_val_loss=0.01768  time=2.14s\n",
      "Epoch 13  loss=0.01700  val_loss=0.01739  sm_loss=0.01719  sm_val_loss=0.01738  time=1.90s\n",
      "Epoch 14  loss=0.01674  val_loss=0.01735  sm_loss=0.01695  sm_val_loss=0.01734  time=1.90s\n",
      "Epoch 15  loss=0.01654  val_loss=0.01721  sm_loss=0.01676  sm_val_loss=0.01718  time=1.89s\n",
      "Epoch 16  loss=0.01632  val_loss=0.01728  sm_loss=0.01656  sm_val_loss=0.01717  time=1.91s\n",
      "Epoch 17  loss=0.01612  val_loss=0.01713  sm_loss=0.01637  sm_val_loss=0.01705  time=2.55s\n",
      "Epoch 18  loss=0.01592  val_loss=0.01710  sm_loss=0.01618  sm_val_loss=0.01700  time=1.88s\n",
      "Epoch 19  loss=0.01575  val_loss=0.01708  sm_loss=0.01602  sm_val_loss=0.01699  time=1.88s\n",
      "Fold 4 log loss: 0.01706080843651208\n",
      "Fold 5\n",
      "Epoch 1  loss=0.28123  val_loss=0.02219  sm_loss=0.28025  sm_val_loss=0.02193  time=1.87s\n",
      "Epoch 3  loss=0.01961  val_loss=0.01953  sm_loss=0.01963  sm_val_loss=0.01941  time=1.88s\n",
      "Epoch 4  loss=0.01884  val_loss=0.01951  sm_loss=0.01891  sm_val_loss=0.01923  time=1.87s\n",
      "Epoch 5  loss=0.01852  val_loss=0.01928  sm_loss=0.01862  sm_val_loss=0.01914  time=1.86s\n",
      "Epoch 6  loss=0.01828  val_loss=0.01912  sm_loss=0.01838  sm_val_loss=0.01898  time=1.88s\n",
      "Epoch 7  loss=0.01815  val_loss=0.01840  sm_loss=0.01826  sm_val_loss=0.01836  time=1.89s\n",
      "Epoch 9  loss=0.01770  val_loss=0.01826  sm_loss=0.01784  sm_val_loss=0.01828  time=1.85s\n",
      "Epoch 10  loss=0.01751  val_loss=0.01833  sm_loss=0.01767  sm_val_loss=0.01824  time=1.85s\n",
      "Epoch 11  loss=0.01728  val_loss=0.01816  sm_loss=0.01744  sm_val_loss=0.01812  time=1.88s\n",
      "Epoch 12  loss=0.01710  val_loss=0.01797  sm_loss=0.01727  sm_val_loss=0.01793  time=2.21s\n",
      "Epoch 13  loss=0.01695  val_loss=0.01779  sm_loss=0.01714  sm_val_loss=0.01775  time=2.11s\n",
      "Epoch 14  loss=0.01672  val_loss=0.01760  sm_loss=0.01693  sm_val_loss=0.01759  time=2.42s\n",
      "Epoch 15  loss=0.01652  val_loss=0.01751  sm_loss=0.01673  sm_val_loss=0.01749  time=2.21s\n",
      "Epoch 17  loss=0.01614  val_loss=0.01750  sm_loss=0.01639  sm_val_loss=0.01744  time=1.94s\n",
      "Epoch 18  loss=0.01588  val_loss=0.01752  sm_loss=0.01614  sm_val_loss=0.01742  time=1.99s\n",
      "Fold 5 log loss: 0.017431537113586356\n",
      "Fold 6\n",
      "Epoch 1  loss=0.27772  val_loss=0.02905  sm_loss=0.27677  sm_val_loss=0.02890  time=1.84s\n",
      "Epoch 2  loss=0.02110  val_loss=0.02219  sm_loss=0.02096  sm_val_loss=0.02202  time=1.83s\n",
      "Epoch 3  loss=0.02012  val_loss=0.02025  sm_loss=0.01999  sm_val_loss=0.02002  time=2.11s\n",
      "Epoch 12  loss=0.01943  val_loss=0.01961  sm_loss=0.01921  sm_val_loss=0.01934  time=1.86s\n",
      "Epoch 14  loss=0.01812  val_loss=0.01875  sm_loss=0.01816  sm_val_loss=0.01859  time=1.84s\n",
      "Epoch 15  loss=0.01773  val_loss=0.01838  sm_loss=0.01785  sm_val_loss=0.01834  time=2.14s\n",
      "Epoch 16  loss=0.01744  val_loss=0.01819  sm_loss=0.01756  sm_val_loss=0.01804  time=1.87s\n",
      "Epoch 18  loss=0.01698  val_loss=0.01796  sm_loss=0.01716  sm_val_loss=0.01785  time=1.85s\n",
      "Epoch 19  loss=0.01679  val_loss=0.01788  sm_loss=0.01699  sm_val_loss=0.01782  time=1.88s\n",
      "Fold 6 log loss: 0.017883419189218912\n",
      "Fold 7\n",
      "Epoch 1  loss=0.27894  val_loss=0.02157  sm_loss=0.27818  sm_val_loss=0.02153  time=1.88s\n",
      "Epoch 2  loss=0.02071  val_loss=0.02013  sm_loss=0.02071  sm_val_loss=0.02013  time=1.88s\n",
      "Epoch 3  loss=0.01991  val_loss=0.01933  sm_loss=0.01992  sm_val_loss=0.01936  time=2.59s\n",
      "Epoch 4  loss=0.01899  val_loss=0.01917  sm_loss=0.01906  sm_val_loss=0.01921  time=2.31s\n",
      "Epoch 7  loss=0.01897  val_loss=0.01913  sm_loss=0.01898  sm_val_loss=0.01888  time=2.02s\n",
      "Epoch 9  loss=0.01781  val_loss=0.01814  sm_loss=0.01794  sm_val_loss=0.01818  time=1.87s\n",
      "Epoch 11  loss=0.01766  val_loss=0.01793  sm_loss=0.01779  sm_val_loss=0.01795  time=1.87s\n",
      "Epoch 12  loss=0.01727  val_loss=0.01782  sm_loss=0.01743  sm_val_loss=0.01783  time=1.86s\n",
      "Epoch 13  loss=0.01709  val_loss=0.01764  sm_loss=0.01726  sm_val_loss=0.01765  time=1.86s\n",
      "Epoch 14  loss=0.01696  val_loss=0.01760  sm_loss=0.01715  sm_val_loss=0.01760  time=1.85s\n",
      "Epoch 16  loss=0.01653  val_loss=0.01753  sm_loss=0.01675  sm_val_loss=0.01750  time=2.19s\n",
      "Epoch 17  loss=0.01631  val_loss=0.01753  sm_loss=0.01653  sm_val_loss=0.01750  time=1.96s\n",
      "Epoch 18  loss=0.01610  val_loss=0.01751  sm_loss=0.01633  sm_val_loss=0.01745  time=1.88s\n",
      "Epoch 19  loss=0.01594  val_loss=0.01749  sm_loss=0.01620  sm_val_loss=0.01743  time=2.15s\n",
      "Fold 7 log loss: 0.017547716325584457\n",
      "Seed 0\n",
      "Fold 1 log loss: 0.017015030247899514\n",
      "Fold 2 log loss: 0.017327726603174547\n",
      "Fold 3 log loss: 0.01792599685812261\n",
      "Fold 4 log loss: 0.01706080843651208\n",
      "Fold 5 log loss: 0.017431537113586356\n",
      "Fold 6 log loss: 0.017883419189218912\n",
      "Fold 7 log loss: 0.017547716325584457\n",
      "Std of log loss: 0.0003337405488713575\n",
      "Total log loss: 0.01745638210795466\n",
      "Fold 1\n",
      "Epoch 1  loss=0.28068  val_loss=0.02093  sm_loss=0.27981  sm_val_loss=0.02088  time=1.82s\n",
      "Epoch 2  loss=0.02091  val_loss=0.02015  sm_loss=0.02089  sm_val_loss=0.02012  time=1.81s\n",
      "Epoch 3  loss=0.01977  val_loss=0.01918  sm_loss=0.01980  sm_val_loss=0.01923  time=1.83s\n",
      "Epoch 5  loss=0.01874  val_loss=0.01861  sm_loss=0.01881  sm_val_loss=0.01869  time=1.85s\n",
      "Epoch 6  loss=0.01833  val_loss=0.01821  sm_loss=0.01843  sm_val_loss=0.01827  time=2.08s\n",
      "Epoch 7  loss=0.01817  val_loss=0.01804  sm_loss=0.01827  sm_val_loss=0.01806  time=1.82s\n",
      "Epoch 9  loss=0.01770  val_loss=0.01785  sm_loss=0.01784  sm_val_loss=0.01792  time=1.88s\n",
      "Epoch 10  loss=0.01755  val_loss=0.01769  sm_loss=0.01770  sm_val_loss=0.01774  time=1.82s\n",
      "Epoch 12  loss=0.01720  val_loss=0.01751  sm_loss=0.01737  sm_val_loss=0.01759  time=2.79s\n",
      "Epoch 13  loss=0.01696  val_loss=0.01752  sm_loss=0.01713  sm_val_loss=0.01757  time=1.93s\n",
      "Epoch 14  loss=0.01675  val_loss=0.01735  sm_loss=0.01695  sm_val_loss=0.01738  time=2.69s\n",
      "Epoch 15  loss=0.01655  val_loss=0.01716  sm_loss=0.01675  sm_val_loss=0.01722  time=2.04s\n",
      "Epoch 16  loss=0.01631  val_loss=0.01711  sm_loss=0.01654  sm_val_loss=0.01717  time=2.24s\n",
      "Epoch 17  loss=0.01605  val_loss=0.01708  sm_loss=0.01628  sm_val_loss=0.01712  time=1.83s\n",
      "Epoch 18  loss=0.01586  val_loss=0.01704  sm_loss=0.01611  sm_val_loss=0.01709  time=1.84s\n",
      "Epoch 19  loss=0.01571  val_loss=0.01704  sm_loss=0.01597  sm_val_loss=0.01707  time=1.85s\n",
      "Fold 1 log loss: 0.01708466503304829\n",
      "Fold 2\n",
      "Epoch 1  loss=0.27996  val_loss=0.02117  sm_loss=0.27929  sm_val_loss=0.02104  time=2.04s\n",
      "Epoch 2  loss=0.02109  val_loss=0.01998  sm_loss=0.02105  sm_val_loss=0.01997  time=2.06s\n",
      "Epoch 3  loss=0.01977  val_loss=0.01911  sm_loss=0.01979  sm_val_loss=0.01912  time=1.90s\n",
      "Epoch 4  loss=0.01922  val_loss=0.01906  sm_loss=0.01928  sm_val_loss=0.01906  time=1.86s\n",
      "Epoch 6  loss=0.01835  val_loss=0.01843  sm_loss=0.01845  sm_val_loss=0.01845  time=1.85s\n",
      "Epoch 8  loss=0.01783  val_loss=0.01826  sm_loss=0.01795  sm_val_loss=0.01828  time=1.86s\n",
      "Epoch 9  loss=0.01762  val_loss=0.01819  sm_loss=0.01776  sm_val_loss=0.01824  time=1.98s\n",
      "Epoch 10  loss=0.01750  val_loss=0.01785  sm_loss=0.01764  sm_val_loss=0.01789  time=2.10s\n",
      "Epoch 12  loss=0.01709  val_loss=0.01783  sm_loss=0.01726  sm_val_loss=0.01785  time=1.83s\n",
      "Epoch 13  loss=0.01699  val_loss=0.01752  sm_loss=0.01717  sm_val_loss=0.01756  time=2.11s\n",
      "Epoch 15  loss=0.01653  val_loss=0.01744  sm_loss=0.01674  sm_val_loss=0.01747  time=1.85s\n",
      "Epoch 17  loss=0.01606  val_loss=0.01736  sm_loss=0.01631  sm_val_loss=0.01734  time=1.84s\n",
      "Epoch 18  loss=0.01585  val_loss=0.01736  sm_loss=0.01611  sm_val_loss=0.01732  time=2.06s\n",
      "Epoch 19  loss=0.01568  val_loss=0.01736  sm_loss=0.01595  sm_val_loss=0.01730  time=1.93s\n",
      "Fold 2 log loss: 0.01728287579799802\n",
      "Fold 3\n",
      "Epoch 1  loss=0.28330  val_loss=0.02207  sm_loss=0.28237  sm_val_loss=0.02191  time=2.37s\n",
      "Epoch 2  loss=0.02073  val_loss=0.02051  sm_loss=0.02070  sm_val_loss=0.02049  time=1.97s\n",
      "Epoch 3  loss=0.01963  val_loss=0.02051  sm_loss=0.01966  sm_val_loss=0.02026  time=2.34s\n",
      "Epoch 4  loss=0.01891  val_loss=0.01906  sm_loss=0.01898  sm_val_loss=0.01906  time=1.98s\n",
      "Epoch 6  loss=0.01836  val_loss=0.01892  sm_loss=0.01846  sm_val_loss=0.01889  time=1.88s\n",
      "Epoch 8  loss=0.01787  val_loss=0.01868  sm_loss=0.01799  sm_val_loss=0.01873  time=2.14s\n",
      "Epoch 9  loss=0.01764  val_loss=0.01842  sm_loss=0.01778  sm_val_loss=0.01840  time=1.88s\n",
      "Epoch 10  loss=0.01743  val_loss=0.01840  sm_loss=0.01759  sm_val_loss=0.01837  time=1.90s\n",
      "Epoch 11  loss=0.01731  val_loss=0.01797  sm_loss=0.01748  sm_val_loss=0.01800  time=1.84s\n",
      "Epoch 14  loss=0.01664  val_loss=0.01793  sm_loss=0.01685  sm_val_loss=0.01790  time=2.13s\n",
      "Epoch 15  loss=0.01644  val_loss=0.01797  sm_loss=0.01666  sm_val_loss=0.01789  time=1.91s\n",
      "Epoch 16  loss=0.01614  val_loss=0.01784  sm_loss=0.01638  sm_val_loss=0.01780  time=1.88s\n",
      "Epoch 17  loss=0.01594  val_loss=0.01779  sm_loss=0.01620  sm_val_loss=0.01773  time=1.89s\n",
      "Epoch 18  loss=0.01579  val_loss=0.01776  sm_loss=0.01606  sm_val_loss=0.01767  time=1.87s\n",
      "Fold 3 log loss: 0.0176819872641574\n",
      "Fold 4\n",
      "Epoch 1  loss=0.28274  val_loss=0.02080  sm_loss=0.28202  sm_val_loss=0.02074  time=1.95s\n",
      "Epoch 2  loss=0.02056  val_loss=0.01956  sm_loss=0.02056  sm_val_loss=0.01956  time=1.87s\n",
      "Epoch 3  loss=0.01968  val_loss=0.01894  sm_loss=0.01969  sm_val_loss=0.01896  time=1.87s\n",
      "Epoch 5  loss=0.01884  val_loss=0.01881  sm_loss=0.01890  sm_val_loss=0.01873  time=1.88s\n",
      "Epoch 8  loss=0.01789  val_loss=0.01815  sm_loss=0.01802  sm_val_loss=0.01815  time=1.88s\n",
      "Epoch 10  loss=0.01759  val_loss=0.01807  sm_loss=0.01773  sm_val_loss=0.01806  time=2.59s\n",
      "Epoch 11  loss=0.01741  val_loss=0.01783  sm_loss=0.01756  sm_val_loss=0.01784  time=1.95s\n",
      "Epoch 12  loss=0.01721  val_loss=0.01764  sm_loss=0.01737  sm_val_loss=0.01762  time=2.19s\n",
      "Epoch 13  loss=0.01704  val_loss=0.01751  sm_loss=0.01721  sm_val_loss=0.01744  time=1.93s\n",
      "Epoch 14  loss=0.01683  val_loss=0.01735  sm_loss=0.01703  sm_val_loss=0.01734  time=1.93s\n",
      "Epoch 16  loss=0.01639  val_loss=0.01728  sm_loss=0.01661  sm_val_loss=0.01724  time=2.21s\n",
      "Epoch 17  loss=0.01617  val_loss=0.01728  sm_loss=0.01641  sm_val_loss=0.01724  time=1.89s\n",
      "Epoch 18  loss=0.01600  val_loss=0.01716  sm_loss=0.01625  sm_val_loss=0.01711  time=1.87s\n",
      "Epoch 19  loss=0.01585  val_loss=0.01718  sm_loss=0.01610  sm_val_loss=0.01711  time=1.87s\n",
      "Epoch 20  loss=0.01577  val_loss=0.01718  sm_loss=0.01603  sm_val_loss=0.01710  time=1.88s\n",
      "Fold 4 log loss: 0.017173662542898375\n",
      "Fold 5\n",
      "Epoch 1  loss=0.28220  val_loss=0.02117  sm_loss=0.28154  sm_val_loss=0.02098  time=1.91s\n",
      "Epoch 2  loss=0.02073  val_loss=0.02044  sm_loss=0.02070  sm_val_loss=0.02038  time=1.90s\n",
      "Epoch 3  loss=0.01956  val_loss=0.01997  sm_loss=0.01959  sm_val_loss=0.01997  time=1.87s\n",
      "Epoch 9  loss=0.01889  val_loss=0.01926  sm_loss=0.01886  sm_val_loss=0.01915  time=1.85s\n",
      "Epoch 10  loss=0.01849  val_loss=0.01869  sm_loss=0.01853  sm_val_loss=0.01865  time=1.88s\n",
      "Epoch 11  loss=0.01816  val_loss=0.01873  sm_loss=0.01825  sm_val_loss=0.01853  time=2.11s\n",
      "Epoch 13  loss=0.01749  val_loss=0.01843  sm_loss=0.01764  sm_val_loss=0.01836  time=1.87s\n",
      "Epoch 15  loss=0.01710  val_loss=0.01806  sm_loss=0.01729  sm_val_loss=0.01801  time=1.85s\n",
      "Epoch 16  loss=0.01675  val_loss=0.01799  sm_loss=0.01696  sm_val_loss=0.01793  time=1.87s\n",
      "Epoch 17  loss=0.01655  val_loss=0.01790  sm_loss=0.01677  sm_val_loss=0.01781  time=2.17s\n",
      "Epoch 18  loss=0.01632  val_loss=0.01774  sm_loss=0.01656  sm_val_loss=0.01769  time=1.85s\n",
      "Epoch 19  loss=0.01616  val_loss=0.01771  sm_loss=0.01641  sm_val_loss=0.01762  time=2.28s\n",
      "Epoch 20  loss=0.01609  val_loss=0.01768  sm_loss=0.01636  sm_val_loss=0.01759  time=2.02s\n",
      "Fold 5 log loss: 0.017589403871162014\n",
      "Fold 6\n",
      "Epoch 1  loss=0.28685  val_loss=0.02287  sm_loss=0.28578  sm_val_loss=0.02256  time=2.13s\n",
      "Epoch 5  loss=0.02329  val_loss=0.02325  sm_loss=0.02186  sm_val_loss=0.02206  time=2.05s\n",
      "Epoch 6  loss=0.02112  val_loss=0.02325  sm_loss=0.02102  sm_val_loss=0.02180  time=1.94s\n",
      "Epoch 10  loss=0.01935  val_loss=0.02095  sm_loss=0.01943  sm_val_loss=0.02023  time=1.84s\n",
      "Epoch 11  loss=0.01899  val_loss=0.02038  sm_loss=0.01912  sm_val_loss=0.01991  time=1.89s\n",
      "Epoch 12  loss=0.01896  val_loss=0.02029  sm_loss=0.01908  sm_val_loss=0.01982  time=2.11s\n",
      "Epoch 13  loss=0.01890  val_loss=0.02015  sm_loss=0.01905  sm_val_loss=0.01967  time=1.87s\n",
      "Epoch 16  loss=0.01829  val_loss=0.01954  sm_loss=0.01846  sm_val_loss=0.01907  time=1.90s\n",
      "Epoch 17  loss=0.01803  val_loss=0.01949  sm_loss=0.01821  sm_val_loss=0.01887  time=1.89s\n",
      "Epoch 19  loss=0.01758  val_loss=0.01912  sm_loss=0.01780  sm_val_loss=0.01876  time=1.86s\n",
      "Epoch 20  loss=0.01741  val_loss=0.01912  sm_loss=0.01763  sm_val_loss=0.01859  time=1.84s\n",
      "Fold 6 log loss: 0.018665605731465116\n",
      "Fold 7\n",
      "Epoch 1  loss=0.27861  val_loss=0.02143  sm_loss=0.27796  sm_val_loss=0.02107  time=1.86s\n",
      "Epoch 3  loss=0.01972  val_loss=0.01918  sm_loss=0.01975  sm_val_loss=0.01916  time=2.39s\n",
      "Epoch 4  loss=0.01890  val_loss=0.01916  sm_loss=0.01897  sm_val_loss=0.01915  time=1.83s\n",
      "Epoch 5  loss=0.01849  val_loss=0.01909  sm_loss=0.01859  sm_val_loss=0.01915  time=1.86s\n",
      "Epoch 6  loss=0.01827  val_loss=0.01901  sm_loss=0.01836  sm_val_loss=0.01903  time=1.85s\n",
      "Epoch 7  loss=0.01805  val_loss=0.01875  sm_loss=0.01817  sm_val_loss=0.01869  time=1.85s\n",
      "Epoch 8  loss=0.01796  val_loss=0.01835  sm_loss=0.01808  sm_val_loss=0.01820  time=2.33s\n",
      "Epoch 10  loss=0.01749  val_loss=0.01801  sm_loss=0.01764  sm_val_loss=0.01805  time=2.18s\n",
      "Epoch 11  loss=0.01738  val_loss=0.01774  sm_loss=0.01753  sm_val_loss=0.01780  time=1.89s\n",
      "Epoch 12  loss=0.01722  val_loss=0.01761  sm_loss=0.01739  sm_val_loss=0.01767  time=1.90s\n",
      "Epoch 13  loss=0.01693  val_loss=0.01761  sm_loss=0.01712  sm_val_loss=0.01765  time=1.96s\n",
      "Epoch 14  loss=0.01677  val_loss=0.01747  sm_loss=0.01698  sm_val_loss=0.01747  time=2.16s\n",
      "Epoch 15  loss=0.01654  val_loss=0.01731  sm_loss=0.01675  sm_val_loss=0.01733  time=1.89s\n",
      "Epoch 16  loss=0.01628  val_loss=0.01725  sm_loss=0.01651  sm_val_loss=0.01728  time=1.91s\n",
      "Epoch 17  loss=0.01610  val_loss=0.01716  sm_loss=0.01634  sm_val_loss=0.01719  time=1.88s\n",
      "Epoch 18  loss=0.01589  val_loss=0.01715  sm_loss=0.01614  sm_val_loss=0.01715  time=2.03s\n",
      "Epoch 19  loss=0.01569  val_loss=0.01712  sm_loss=0.01595  sm_val_loss=0.01713  time=2.30s\n",
      "Epoch 20  loss=0.01559  val_loss=0.01713  sm_loss=0.01586  sm_val_loss=0.01713  time=1.90s\n",
      "Fold 7 log loss: 0.01724616697467449\n",
      "Seed 1\n",
      "Fold 1 log loss: 0.01708466503304829\n",
      "Fold 2 log loss: 0.01728287579799802\n",
      "Fold 3 log loss: 0.0176819872641574\n",
      "Fold 4 log loss: 0.017173662542898375\n",
      "Fold 5 log loss: 0.017589403871162014\n",
      "Fold 6 log loss: 0.018665605731465116\n",
      "Fold 7 log loss: 0.01724616697467449\n",
      "Std of log loss: 0.0005047108098689631\n",
      "Total log loss: 0.017531906395436794\n",
      "Fold 1\n",
      "Epoch 1  loss=0.27942  val_loss=0.02766  sm_loss=0.27893  sm_val_loss=0.02749  time=1.83s\n",
      "Epoch 2  loss=0.02104  val_loss=0.02017  sm_loss=0.02093  sm_val_loss=0.02014  time=1.82s\n",
      "Epoch 3  loss=0.01957  val_loss=0.01866  sm_loss=0.01956  sm_val_loss=0.01862  time=1.83s\n",
      "Epoch 5  loss=0.01851  val_loss=0.01839  sm_loss=0.01859  sm_val_loss=0.01840  time=1.84s\n",
      "Epoch 6  loss=0.01824  val_loss=0.01820  sm_loss=0.01835  sm_val_loss=0.01823  time=1.82s\n",
      "Epoch 7  loss=0.01808  val_loss=0.01801  sm_loss=0.01819  sm_val_loss=0.01807  time=1.80s\n",
      "Epoch 10  loss=0.01741  val_loss=0.01755  sm_loss=0.01756  sm_val_loss=0.01763  time=1.89s\n",
      "Epoch 12  loss=0.01709  val_loss=0.01753  sm_loss=0.01726  sm_val_loss=0.01763  time=1.82s\n",
      "Epoch 13  loss=0.01683  val_loss=0.01740  sm_loss=0.01702  sm_val_loss=0.01749  time=1.90s\n",
      "Epoch 15  loss=0.01639  val_loss=0.01718  sm_loss=0.01661  sm_val_loss=0.01727  time=2.04s\n",
      "Epoch 16  loss=0.01614  val_loss=0.01712  sm_loss=0.01637  sm_val_loss=0.01721  time=1.82s\n",
      "Epoch 17  loss=0.01589  val_loss=0.01699  sm_loss=0.01613  sm_val_loss=0.01708  time=2.47s\n",
      "Epoch 20  loss=0.01541  val_loss=0.01701  sm_loss=0.01569  sm_val_loss=0.01708  time=1.91s\n",
      "Fold 1 log loss: 0.017090121481951496\n",
      "Fold 2\n",
      "Epoch 1  loss=0.28980  val_loss=0.02150  sm_loss=0.28895  sm_val_loss=0.02112  time=1.87s\n",
      "Epoch 2  loss=0.02057  val_loss=0.01980  sm_loss=0.02053  sm_val_loss=0.01982  time=1.88s\n",
      "Epoch 3  loss=0.01971  val_loss=0.01950  sm_loss=0.01975  sm_val_loss=0.01950  time=1.84s\n",
      "Epoch 4  loss=0.01908  val_loss=0.01884  sm_loss=0.01916  sm_val_loss=0.01887  time=1.86s\n",
      "Epoch 6  loss=0.01845  val_loss=0.01880  sm_loss=0.01854  sm_val_loss=0.01877  time=1.92s\n",
      "Epoch 7  loss=0.01822  val_loss=0.01857  sm_loss=0.01834  sm_val_loss=0.01858  time=1.90s\n",
      "Epoch 8  loss=0.01800  val_loss=0.01831  sm_loss=0.01813  sm_val_loss=0.01839  time=1.89s\n",
      "Epoch 9  loss=0.01789  val_loss=0.01811  sm_loss=0.01802  sm_val_loss=0.01816  time=2.25s\n",
      "Epoch 10  loss=0.01770  val_loss=0.01796  sm_loss=0.01784  sm_val_loss=0.01802  time=1.90s\n",
      "Epoch 13  loss=0.01714  val_loss=0.01774  sm_loss=0.01731  sm_val_loss=0.01779  time=1.89s\n",
      "Epoch 14  loss=0.01690  val_loss=0.01766  sm_loss=0.01709  sm_val_loss=0.01767  time=1.88s\n",
      "Epoch 16  loss=0.01648  val_loss=0.01744  sm_loss=0.01669  sm_val_loss=0.01748  time=1.93s\n",
      "Epoch 18  loss=0.01611  val_loss=0.01743  sm_loss=0.01634  sm_val_loss=0.01742  time=1.83s\n",
      "Fold 2 log loss: 0.017409111581834315\n",
      "Fold 3\n",
      "Epoch 1  loss=0.28423  val_loss=0.02172  sm_loss=0.28350  sm_val_loss=0.02151  time=1.89s\n",
      "Epoch 2  loss=0.02051  val_loss=0.01985  sm_loss=0.02050  sm_val_loss=0.01984  time=2.10s\n",
      "Epoch 3  loss=0.01962  val_loss=0.01950  sm_loss=0.01965  sm_val_loss=0.01952  time=1.85s\n",
      "Epoch 5  loss=0.01835  val_loss=0.01924  sm_loss=0.01844  sm_val_loss=0.01922  time=2.18s\n",
      "Epoch 6  loss=0.01808  val_loss=0.01896  sm_loss=0.01820  sm_val_loss=0.01896  time=2.32s\n",
      "Epoch 7  loss=0.01788  val_loss=0.01867  sm_loss=0.01800  sm_val_loss=0.01866  time=2.46s\n",
      "Epoch 8  loss=0.01772  val_loss=0.01853  sm_loss=0.01785  sm_val_loss=0.01855  time=2.03s\n",
      "Epoch 10  loss=0.01735  val_loss=0.01832  sm_loss=0.01751  sm_val_loss=0.01836  time=1.92s\n",
      "Epoch 11  loss=0.01719  val_loss=0.01831  sm_loss=0.01736  sm_val_loss=0.01828  time=1.84s\n",
      "Epoch 13  loss=0.01679  val_loss=0.01803  sm_loss=0.01698  sm_val_loss=0.01802  time=1.81s\n",
      "Epoch 15  loss=0.01625  val_loss=0.01781  sm_loss=0.01648  sm_val_loss=0.01775  time=1.84s\n",
      "Epoch 16  loss=0.01597  val_loss=0.01776  sm_loss=0.01622  sm_val_loss=0.01768  time=1.83s\n",
      "Epoch 17  loss=0.01574  val_loss=0.01771  sm_loss=0.01600  sm_val_loss=0.01763  time=1.81s\n",
      "Epoch 19  loss=0.01536  val_loss=0.01773  sm_loss=0.01565  sm_val_loss=0.01763  time=1.84s\n",
      "Epoch 20  loss=0.01522  val_loss=0.01773  sm_loss=0.01552  sm_val_loss=0.01761  time=1.97s\n",
      "Fold 3 log loss: 0.017622207601577716\n",
      "Fold 4\n",
      "Epoch 1  loss=0.28380  val_loss=0.02329  sm_loss=0.28298  sm_val_loss=0.02332  time=1.83s\n",
      "Epoch 2  loss=0.02066  val_loss=0.02137  sm_loss=0.02068  sm_val_loss=0.02141  time=1.84s\n",
      "Epoch 3  loss=0.01990  val_loss=0.01932  sm_loss=0.01994  sm_val_loss=0.01933  time=2.11s\n",
      "Epoch 4  loss=0.01904  val_loss=0.01940  sm_loss=0.01911  sm_val_loss=0.01929  time=1.86s\n",
      "Epoch 5  loss=0.01860  val_loss=0.01843  sm_loss=0.01868  sm_val_loss=0.01827  time=1.86s\n",
      "Epoch 9  loss=0.01769  val_loss=0.01810  sm_loss=0.01783  sm_val_loss=0.01809  time=2.07s\n",
      "Epoch 10  loss=0.01759  val_loss=0.01798  sm_loss=0.01774  sm_val_loss=0.01794  time=1.84s\n",
      "Epoch 11  loss=0.01740  val_loss=0.01783  sm_loss=0.01756  sm_val_loss=0.01778  time=1.84s\n",
      "Epoch 13  loss=0.01696  val_loss=0.01740  sm_loss=0.01715  sm_val_loss=0.01736  time=1.89s\n",
      "Epoch 14  loss=0.01679  val_loss=0.01736  sm_loss=0.01699  sm_val_loss=0.01731  time=2.17s\n",
      "Epoch 15  loss=0.01658  val_loss=0.01729  sm_loss=0.01680  sm_val_loss=0.01725  time=1.89s\n",
      "Epoch 16  loss=0.01631  val_loss=0.01716  sm_loss=0.01654  sm_val_loss=0.01710  time=2.83s\n",
      "Epoch 17  loss=0.01610  val_loss=0.01715  sm_loss=0.01635  sm_val_loss=0.01708  time=2.07s\n",
      "Epoch 18  loss=0.01587  val_loss=0.01709  sm_loss=0.01614  sm_val_loss=0.01700  time=1.90s\n",
      "Fold 4 log loss: 0.017063801060184625\n",
      "Fold 5\n",
      "Epoch 1  loss=0.28152  val_loss=0.02272  sm_loss=0.28054  sm_val_loss=0.02260  time=1.90s\n",
      "Epoch 2  loss=0.02078  val_loss=0.02078  sm_loss=0.02077  sm_val_loss=0.02065  time=1.86s\n",
      "Epoch 3  loss=0.01972  val_loss=0.02041  sm_loss=0.01975  sm_val_loss=0.02017  time=1.80s\n",
      "Epoch 5  loss=0.01894  val_loss=0.01979  sm_loss=0.01897  sm_val_loss=0.01972  time=1.81s\n",
      "Epoch 7  loss=0.01817  val_loss=0.01889  sm_loss=0.01826  sm_val_loss=0.01883  time=1.86s\n",
      "Epoch 8  loss=0.01794  val_loss=0.01895  sm_loss=0.01807  sm_val_loss=0.01881  time=1.83s\n",
      "Epoch 9  loss=0.01773  val_loss=0.01880  sm_loss=0.01786  sm_val_loss=0.01879  time=1.94s\n",
      "Epoch 10  loss=0.01752  val_loss=0.01817  sm_loss=0.01767  sm_val_loss=0.01816  time=2.11s\n",
      "Epoch 12  loss=0.01716  val_loss=0.01800  sm_loss=0.01733  sm_val_loss=0.01797  time=2.20s\n",
      "Epoch 14  loss=0.01685  val_loss=0.01780  sm_loss=0.01704  sm_val_loss=0.01769  time=1.83s\n",
      "Epoch 15  loss=0.01663  val_loss=0.01778  sm_loss=0.01684  sm_val_loss=0.01765  time=1.80s\n",
      "Epoch 16  loss=0.01642  val_loss=0.01769  sm_loss=0.01664  sm_val_loss=0.01760  time=2.07s\n",
      "Epoch 17  loss=0.01621  val_loss=0.01761  sm_loss=0.01644  sm_val_loss=0.01752  time=1.82s\n",
      "Epoch 18  loss=0.01603  val_loss=0.01761  sm_loss=0.01627  sm_val_loss=0.01748  time=1.84s\n",
      "Fold 5 log loss: 0.0174846648633456\n",
      "Fold 6\n",
      "Epoch 1  loss=0.28698  val_loss=0.02259  sm_loss=0.28600  sm_val_loss=0.02217  time=2.06s\n",
      "Epoch 3  loss=0.02011  val_loss=0.02082  sm_loss=0.02009  sm_val_loss=0.02047  time=1.81s\n",
      "Epoch 12  loss=0.01950  val_loss=0.02112  sm_loss=0.01948  sm_val_loss=0.02029  time=2.10s\n",
      "Epoch 13  loss=0.01905  val_loss=0.02078  sm_loss=0.01910  sm_val_loss=0.02019  time=1.83s\n",
      "Epoch 15  loss=0.01899  val_loss=0.01974  sm_loss=0.01907  sm_val_loss=0.01948  time=1.80s\n",
      "Epoch 18  loss=0.01818  val_loss=0.01920  sm_loss=0.01833  sm_val_loss=0.01881  time=1.98s\n",
      "Epoch 19  loss=0.01807  val_loss=0.01889  sm_loss=0.01823  sm_val_loss=0.01870  time=1.82s\n",
      "Fold 6 log loss: 0.0187619050733432\n",
      "Fold 7\n",
      "Epoch 1  loss=0.29170  val_loss=0.02241  sm_loss=0.29064  sm_val_loss=0.02207  time=1.80s\n",
      "Epoch 2  loss=0.02087  val_loss=0.02010  sm_loss=0.02075  sm_val_loss=0.02012  time=1.83s\n",
      "Epoch 3  loss=0.01970  val_loss=0.01983  sm_loss=0.01971  sm_val_loss=0.01976  time=2.46s\n",
      "Epoch 4  loss=0.01924  val_loss=0.01947  sm_loss=0.01929  sm_val_loss=0.01953  time=1.89s\n",
      "Epoch 6  loss=0.01923  val_loss=0.01937  sm_loss=0.01925  sm_val_loss=0.01942  time=1.80s\n",
      "Epoch 7  loss=0.01830  val_loss=0.01839  sm_loss=0.01840  sm_val_loss=0.01846  time=1.87s\n",
      "Epoch 9  loss=0.01790  val_loss=0.01831  sm_loss=0.01804  sm_val_loss=0.01833  time=1.84s\n",
      "Epoch 10  loss=0.01776  val_loss=0.01807  sm_loss=0.01790  sm_val_loss=0.01807  time=1.99s\n",
      "Epoch 11  loss=0.01766  val_loss=0.01803  sm_loss=0.01780  sm_val_loss=0.01804  time=1.81s\n",
      "Epoch 12  loss=0.01735  val_loss=0.01778  sm_loss=0.01751  sm_val_loss=0.01784  time=1.81s\n",
      "Epoch 13  loss=0.01723  val_loss=0.01766  sm_loss=0.01739  sm_val_loss=0.01768  time=1.78s\n",
      "Epoch 14  loss=0.01702  val_loss=0.01743  sm_loss=0.01720  sm_val_loss=0.01748  time=2.01s\n",
      "Epoch 15  loss=0.01682  val_loss=0.01735  sm_loss=0.01701  sm_val_loss=0.01739  time=2.26s\n",
      "Epoch 16  loss=0.01660  val_loss=0.01729  sm_loss=0.01681  sm_val_loss=0.01732  time=2.12s\n",
      "Epoch 18  loss=0.01625  val_loss=0.01727  sm_loss=0.01648  sm_val_loss=0.01729  time=1.84s\n",
      "Epoch 19  loss=0.01611  val_loss=0.01726  sm_loss=0.01635  sm_val_loss=0.01727  time=2.09s\n",
      "Fold 7 log loss: 0.01739409610667826\n",
      "Seed 2\n",
      "Fold 1 log loss: 0.017090121481951496\n",
      "Fold 2 log loss: 0.017409111581834315\n",
      "Fold 3 log loss: 0.017622207601577716\n",
      "Fold 4 log loss: 0.017063801060184625\n",
      "Fold 5 log loss: 0.0174846648633456\n",
      "Fold 6 log loss: 0.0187619050733432\n",
      "Fold 7 log loss: 0.01739409610667826\n",
      "Std of log loss: 0.0005305181881892448\n",
      "Total log loss: 0.017546602143208637\n",
      "Fold 1\n",
      "Epoch 1  loss=0.28214  val_loss=0.02141  sm_loss=0.28126  sm_val_loss=0.02122  time=1.87s\n",
      "Epoch 2  loss=0.02110  val_loss=0.01975  sm_loss=0.02105  sm_val_loss=0.01977  time=1.77s\n",
      "Epoch 4  loss=0.01892  val_loss=0.01864  sm_loss=0.01898  sm_val_loss=0.01863  time=2.00s\n",
      "Epoch 5  loss=0.01864  val_loss=0.01840  sm_loss=0.01872  sm_val_loss=0.01842  time=1.81s\n",
      "Epoch 8  loss=0.01797  val_loss=0.01784  sm_loss=0.01809  sm_val_loss=0.01787  time=1.78s\n",
      "Epoch 10  loss=0.01758  val_loss=0.01777  sm_loss=0.01773  sm_val_loss=0.01780  time=2.07s\n",
      "Epoch 12  loss=0.01722  val_loss=0.01743  sm_loss=0.01738  sm_val_loss=0.01755  time=1.84s\n",
      "Epoch 13  loss=0.01701  val_loss=0.01735  sm_loss=0.01719  sm_val_loss=0.01741  time=1.84s\n",
      "Epoch 14  loss=0.01679  val_loss=0.01728  sm_loss=0.01699  sm_val_loss=0.01732  time=1.84s\n",
      "Epoch 15  loss=0.01658  val_loss=0.01708  sm_loss=0.01679  sm_val_loss=0.01718  time=2.34s\n",
      "Epoch 16  loss=0.01633  val_loss=0.01701  sm_loss=0.01655  sm_val_loss=0.01712  time=1.79s\n",
      "Epoch 17  loss=0.01610  val_loss=0.01695  sm_loss=0.01634  sm_val_loss=0.01705  time=1.80s\n",
      "Epoch 18  loss=0.01590  val_loss=0.01696  sm_loss=0.01616  sm_val_loss=0.01704  time=1.83s\n",
      "Epoch 19  loss=0.01575  val_loss=0.01694  sm_loss=0.01601  sm_val_loss=0.01701  time=1.82s\n",
      "Fold 1 log loss: 0.017025160651738456\n",
      "Fold 2\n",
      "Epoch 1  loss=0.27820  val_loss=0.02101  sm_loss=0.27774  sm_val_loss=0.02090  time=1.98s\n",
      "Epoch 2  loss=0.02065  val_loss=0.02066  sm_loss=0.02063  sm_val_loss=0.02058  time=1.78s\n",
      "Epoch 3  loss=0.01942  val_loss=0.01908  sm_loss=0.01946  sm_val_loss=0.01902  time=1.77s\n",
      "Epoch 4  loss=0.01866  val_loss=0.01841  sm_loss=0.01872  sm_val_loss=0.01844  time=2.19s\n",
      "Epoch 5  loss=0.01841  val_loss=0.01829  sm_loss=0.01850  sm_val_loss=0.01836  time=1.78s\n",
      "Epoch 7  loss=0.01800  val_loss=0.01834  sm_loss=0.01812  sm_val_loss=0.01834  time=2.53s\n",
      "Epoch 10  loss=0.01746  val_loss=0.01817  sm_loss=0.01760  sm_val_loss=0.01811  time=1.80s\n",
      "Epoch 11  loss=0.01729  val_loss=0.01785  sm_loss=0.01745  sm_val_loss=0.01786  time=2.11s\n",
      "Epoch 12  loss=0.01706  val_loss=0.01777  sm_loss=0.01724  sm_val_loss=0.01780  time=2.05s\n",
      "Epoch 13  loss=0.01693  val_loss=0.01764  sm_loss=0.01711  sm_val_loss=0.01763  time=1.80s\n",
      "Epoch 14  loss=0.01670  val_loss=0.01756  sm_loss=0.01690  sm_val_loss=0.01760  time=1.78s\n",
      "Epoch 15  loss=0.01652  val_loss=0.01750  sm_loss=0.01674  sm_val_loss=0.01752  time=1.80s\n",
      "Epoch 16  loss=0.01630  val_loss=0.01744  sm_loss=0.01652  sm_val_loss=0.01744  time=1.83s\n",
      "Epoch 17  loss=0.01603  val_loss=0.01746  sm_loss=0.01628  sm_val_loss=0.01744  time=1.81s\n",
      "Epoch 18  loss=0.01586  val_loss=0.01738  sm_loss=0.01612  sm_val_loss=0.01736  time=2.00s\n",
      "Epoch 20  loss=0.01559  val_loss=0.01739  sm_loss=0.01586  sm_val_loss=0.01735  time=1.78s\n",
      "Fold 2 log loss: 0.017341803624860215\n",
      "Fold 3\n",
      "Epoch 1  loss=0.28042  val_loss=0.02161  sm_loss=0.27977  sm_val_loss=0.02130  time=1.83s\n",
      "Epoch 2  loss=0.02036  val_loss=0.02031  sm_loss=0.02035  sm_val_loss=0.02032  time=1.85s\n",
      "Epoch 3  loss=0.01936  val_loss=0.02032  sm_loss=0.01938  sm_val_loss=0.02011  time=2.07s\n",
      "Epoch 4  loss=0.01869  val_loss=0.01965  sm_loss=0.01876  sm_val_loss=0.01938  time=1.89s\n",
      "Epoch 5  loss=0.01837  val_loss=0.01918  sm_loss=0.01847  sm_val_loss=0.01908  time=1.82s\n",
      "Epoch 6  loss=0.01816  val_loss=0.01886  sm_loss=0.01827  sm_val_loss=0.01882  time=1.83s\n",
      "Epoch 7  loss=0.01801  val_loss=0.01860  sm_loss=0.01812  sm_val_loss=0.01854  time=2.15s\n",
      "Epoch 9  loss=0.01760  val_loss=0.01844  sm_loss=0.01774  sm_val_loss=0.01841  time=1.87s\n",
      "Epoch 10  loss=0.01745  val_loss=0.01831  sm_loss=0.01760  sm_val_loss=0.01827  time=1.84s\n",
      "Epoch 11  loss=0.01724  val_loss=0.01822  sm_loss=0.01740  sm_val_loss=0.01813  time=1.84s\n",
      "Epoch 13  loss=0.01682  val_loss=0.01805  sm_loss=0.01701  sm_val_loss=0.01802  time=1.84s\n",
      "Epoch 15  loss=0.01636  val_loss=0.01783  sm_loss=0.01659  sm_val_loss=0.01782  time=2.04s\n",
      "Epoch 16  loss=0.01609  val_loss=0.01779  sm_loss=0.01634  sm_val_loss=0.01771  time=2.10s\n",
      "Epoch 17  loss=0.01587  val_loss=0.01771  sm_loss=0.01613  sm_val_loss=0.01764  time=1.91s\n",
      "Epoch 18  loss=0.01566  val_loss=0.01775  sm_loss=0.01593  sm_val_loss=0.01763  time=1.89s\n",
      "Epoch 19  loss=0.01548  val_loss=0.01775  sm_loss=0.01577  sm_val_loss=0.01761  time=2.05s\n",
      "Epoch 20  loss=0.01539  val_loss=0.01774  sm_loss=0.01568  sm_val_loss=0.01760  time=1.99s\n",
      "Fold 3 log loss: 0.0176007424480462\n",
      "Fold 4\n",
      "Epoch 1  loss=0.28963  val_loss=0.02097  sm_loss=0.28877  sm_val_loss=0.02091  time=1.83s\n",
      "Epoch 2  loss=0.02040  val_loss=0.02094  sm_loss=0.02040  sm_val_loss=0.02041  time=2.10s\n",
      "Epoch 3  loss=0.01934  val_loss=0.01910  sm_loss=0.01941  sm_val_loss=0.01913  time=1.87s\n",
      "Epoch 4  loss=0.01872  val_loss=0.01862  sm_loss=0.01879  sm_val_loss=0.01863  time=2.02s\n",
      "Epoch 5  loss=0.01842  val_loss=0.01884  sm_loss=0.01852  sm_val_loss=0.01852  time=1.81s\n",
      "Epoch 6  loss=0.01822  val_loss=0.01836  sm_loss=0.01832  sm_val_loss=0.01840  time=1.81s\n",
      "Epoch 9  loss=0.01769  val_loss=0.01783  sm_loss=0.01784  sm_val_loss=0.01783  time=1.79s\n",
      "Epoch 11  loss=0.01724  val_loss=0.01772  sm_loss=0.01741  sm_val_loss=0.01763  time=1.79s\n",
      "Epoch 12  loss=0.01701  val_loss=0.01750  sm_loss=0.01720  sm_val_loss=0.01751  time=1.79s\n",
      "Epoch 13  loss=0.01687  val_loss=0.01733  sm_loss=0.01706  sm_val_loss=0.01727  time=1.97s\n",
      "Epoch 15  loss=0.01643  val_loss=0.01726  sm_loss=0.01665  sm_val_loss=0.01723  time=1.80s\n",
      "Epoch 16  loss=0.01617  val_loss=0.01721  sm_loss=0.01640  sm_val_loss=0.01717  time=2.13s\n",
      "Epoch 17  loss=0.01596  val_loss=0.01713  sm_loss=0.01621  sm_val_loss=0.01707  time=1.80s\n",
      "Epoch 18  loss=0.01578  val_loss=0.01712  sm_loss=0.01604  sm_val_loss=0.01706  time=1.83s\n",
      "Epoch 19  loss=0.01561  val_loss=0.01710  sm_loss=0.01589  sm_val_loss=0.01703  time=2.15s\n",
      "Epoch 20  loss=0.01551  val_loss=0.01709  sm_loss=0.01579  sm_val_loss=0.01702  time=1.83s\n",
      "Fold 4 log loss: 0.017072410404266925\n",
      "Fold 5\n",
      "Epoch 1  loss=0.28476  val_loss=0.02100  sm_loss=0.28393  sm_val_loss=0.02096  time=2.10s\n",
      "Epoch 2  loss=0.02038  val_loss=0.02093  sm_loss=0.02037  sm_val_loss=0.02081  time=1.83s\n",
      "Epoch 3  loss=0.01924  val_loss=0.01923  sm_loss=0.01928  sm_val_loss=0.01923  time=1.80s\n",
      "Epoch 13  loss=0.01846  val_loss=0.01894  sm_loss=0.01855  sm_val_loss=0.01889  time=1.87s\n",
      "Epoch 14  loss=0.01817  val_loss=0.01863  sm_loss=0.01829  sm_val_loss=0.01855  time=1.92s\n",
      "Epoch 15  loss=0.01780  val_loss=0.01837  sm_loss=0.01794  sm_val_loss=0.01831  time=2.17s\n",
      "Epoch 16  loss=0.01770  val_loss=0.01843  sm_loss=0.01785  sm_val_loss=0.01828  time=1.81s\n",
      "Epoch 17  loss=0.01738  val_loss=0.01806  sm_loss=0.01754  sm_val_loss=0.01799  time=1.83s\n",
      "Epoch 18  loss=0.01711  val_loss=0.01806  sm_loss=0.01729  sm_val_loss=0.01797  time=2.06s\n",
      "Epoch 19  loss=0.01696  val_loss=0.01793  sm_loss=0.01715  sm_val_loss=0.01785  time=1.81s\n",
      "Epoch 20  loss=0.01681  val_loss=0.01792  sm_loss=0.01701  sm_val_loss=0.01784  time=1.81s\n",
      "Fold 5 log loss: 0.017826847914389064\n",
      "Fold 6\n",
      "Epoch 1  loss=0.28513  val_loss=0.02193  sm_loss=0.28449  sm_val_loss=0.02168  time=1.82s\n",
      "Epoch 7  loss=0.02334  val_loss=0.03219  sm_loss=0.02140  sm_val_loss=0.02147  time=1.77s\n",
      "Epoch 10  loss=0.02173  val_loss=0.02576  sm_loss=0.02071  sm_val_loss=0.02072  time=1.93s\n",
      "Epoch 14  loss=0.01992  val_loss=0.02152  sm_loss=0.01947  sm_val_loss=0.01984  time=2.57s\n",
      "Epoch 15  loss=0.01967  val_loss=0.02150  sm_loss=0.01927  sm_val_loss=0.01932  time=1.80s\n",
      "Epoch 16  loss=0.01915  val_loss=0.02058  sm_loss=0.01899  sm_val_loss=0.01912  time=1.91s\n",
      "Fold 6 log loss: 0.019195426714240335\n",
      "Fold 7\n",
      "Epoch 1  loss=0.27929  val_loss=0.02174  sm_loss=0.27827  sm_val_loss=0.02157  time=1.80s\n",
      "Epoch 2  loss=0.02091  val_loss=0.02003  sm_loss=0.02086  sm_val_loss=0.02008  time=1.81s\n",
      "Epoch 3  loss=0.01967  val_loss=0.01979  sm_loss=0.01971  sm_val_loss=0.01959  time=1.80s\n",
      "Epoch 4  loss=0.01877  val_loss=0.01926  sm_loss=0.01884  sm_val_loss=0.01927  time=1.84s\n",
      "Epoch 6  loss=0.01841  val_loss=0.01915  sm_loss=0.01850  sm_val_loss=0.01909  time=2.29s\n",
      "Epoch 7  loss=0.01796  val_loss=0.01896  sm_loss=0.01808  sm_val_loss=0.01888  time=1.97s\n",
      "Epoch 8  loss=0.01792  val_loss=0.01861  sm_loss=0.01804  sm_val_loss=0.01855  time=1.80s\n",
      "Epoch 9  loss=0.01764  val_loss=0.01810  sm_loss=0.01779  sm_val_loss=0.01811  time=1.81s\n",
      "Epoch 11  loss=0.01736  val_loss=0.01795  sm_loss=0.01751  sm_val_loss=0.01794  time=1.92s\n",
      "Epoch 12  loss=0.01715  val_loss=0.01787  sm_loss=0.01733  sm_val_loss=0.01787  time=1.83s\n",
      "Epoch 14  loss=0.01675  val_loss=0.01761  sm_loss=0.01695  sm_val_loss=0.01757  time=1.80s\n",
      "Epoch 16  loss=0.01636  val_loss=0.01754  sm_loss=0.01658  sm_val_loss=0.01753  time=2.05s\n",
      "Epoch 17  loss=0.01613  val_loss=0.01755  sm_loss=0.01637  sm_val_loss=0.01747  time=1.88s\n",
      "Epoch 18  loss=0.01594  val_loss=0.01751  sm_loss=0.01619  sm_val_loss=0.01743  time=1.82s\n",
      "Epoch 19  loss=0.01577  val_loss=0.01748  sm_loss=0.01603  sm_val_loss=0.01739  time=1.79s\n",
      "Fold 7 log loss: 0.017507950046570717\n",
      "Seed 3\n",
      "Fold 1 log loss: 0.017025160651738456\n",
      "Fold 2 log loss: 0.017341803624860215\n",
      "Fold 3 log loss: 0.0176007424480462\n",
      "Fold 4 log loss: 0.017072410404266925\n",
      "Fold 5 log loss: 0.017826847914389064\n",
      "Fold 6 log loss: 0.019195426714240335\n",
      "Fold 7 log loss: 0.017507950046570717\n",
      "Std of log loss: 0.0006825564607494794\n",
      "Total log loss: 0.01765231048019267\n",
      "Fold 1\n",
      "Epoch 1  loss=0.28135  val_loss=0.02156  sm_loss=0.28072  sm_val_loss=0.02131  time=2.02s\n",
      "Epoch 2  loss=0.02051  val_loss=0.01956  sm_loss=0.02048  sm_val_loss=0.01957  time=2.18s\n",
      "Epoch 3  loss=0.01940  val_loss=0.01890  sm_loss=0.01945  sm_val_loss=0.01895  time=2.17s\n",
      "Epoch 4  loss=0.01889  val_loss=0.01830  sm_loss=0.01894  sm_val_loss=0.01837  time=1.83s\n",
      "Epoch 6  loss=0.01830  val_loss=0.01822  sm_loss=0.01840  sm_val_loss=0.01827  time=2.13s\n",
      "Epoch 7  loss=0.01801  val_loss=0.01814  sm_loss=0.01813  sm_val_loss=0.01823  time=2.03s\n",
      "Epoch 8  loss=0.01790  val_loss=0.01804  sm_loss=0.01803  sm_val_loss=0.01813  time=1.84s\n",
      "Epoch 9  loss=0.01767  val_loss=0.01777  sm_loss=0.01780  sm_val_loss=0.01786  time=1.76s\n",
      "Epoch 11  loss=0.01739  val_loss=0.01768  sm_loss=0.01754  sm_val_loss=0.01773  time=1.77s\n",
      "Epoch 12  loss=0.01713  val_loss=0.01747  sm_loss=0.01729  sm_val_loss=0.01756  time=1.99s\n",
      "Epoch 13  loss=0.01692  val_loss=0.01739  sm_loss=0.01709  sm_val_loss=0.01748  time=1.75s\n",
      "Epoch 15  loss=0.01651  val_loss=0.01726  sm_loss=0.01672  sm_val_loss=0.01735  time=1.76s\n",
      "Epoch 16  loss=0.01626  val_loss=0.01724  sm_loss=0.01648  sm_val_loss=0.01730  time=1.95s\n",
      "Epoch 18  loss=0.01587  val_loss=0.01713  sm_loss=0.01612  sm_val_loss=0.01721  time=2.51s\n",
      "Epoch 19  loss=0.01570  val_loss=0.01714  sm_loss=0.01596  sm_val_loss=0.01720  time=1.93s\n",
      "Fold 1 log loss: 0.0172178214838474\n",
      "Fold 2\n",
      "Epoch 1  loss=0.28615  val_loss=0.02116  sm_loss=0.28549  sm_val_loss=0.02111  time=1.82s\n",
      "Epoch 2  loss=0.02054  val_loss=0.02058  sm_loss=0.02052  sm_val_loss=0.02047  time=1.90s\n",
      "Epoch 3  loss=0.01948  val_loss=0.01919  sm_loss=0.01954  sm_val_loss=0.01919  time=1.98s\n",
      "Epoch 4  loss=0.01904  val_loss=0.01914  sm_loss=0.01911  sm_val_loss=0.01909  time=1.93s\n",
      "Epoch 6  loss=0.01842  val_loss=0.01910  sm_loss=0.01852  sm_val_loss=0.01905  time=1.94s\n",
      "Epoch 7  loss=0.01823  val_loss=0.01868  sm_loss=0.01833  sm_val_loss=0.01872  time=1.93s\n",
      "Epoch 8  loss=0.01795  val_loss=0.01855  sm_loss=0.01807  sm_val_loss=0.01862  time=2.14s\n",
      "Epoch 9  loss=0.01776  val_loss=0.01853  sm_loss=0.01788  sm_val_loss=0.01858  time=1.88s\n",
      "Epoch 10  loss=0.01754  val_loss=0.01824  sm_loss=0.01768  sm_val_loss=0.01829  time=1.95s\n",
      "Epoch 11  loss=0.01743  val_loss=0.01770  sm_loss=0.01757  sm_val_loss=0.01778  time=1.91s\n",
      "Epoch 13  loss=0.01706  val_loss=0.01766  sm_loss=0.01724  sm_val_loss=0.01771  time=3.07s\n",
      "Epoch 14  loss=0.01681  val_loss=0.01747  sm_loss=0.01700  sm_val_loss=0.01755  time=2.34s\n",
      "Epoch 15  loss=0.01662  val_loss=0.01739  sm_loss=0.01682  sm_val_loss=0.01747  time=2.26s\n",
      "Epoch 16  loss=0.01640  val_loss=0.01742  sm_loss=0.01662  sm_val_loss=0.01744  time=1.95s\n",
      "Epoch 17  loss=0.01618  val_loss=0.01732  sm_loss=0.01641  sm_val_loss=0.01738  time=1.92s\n",
      "Epoch 18  loss=0.01598  val_loss=0.01732  sm_loss=0.01623  sm_val_loss=0.01736  time=2.26s\n",
      "Epoch 19  loss=0.01588  val_loss=0.01729  sm_loss=0.01613  sm_val_loss=0.01732  time=1.94s\n",
      "Epoch 20  loss=0.01574  val_loss=0.01729  sm_loss=0.01600  sm_val_loss=0.01731  time=1.95s\n",
      "Fold 2 log loss: 0.0172936554893337\n",
      "Fold 3\n",
      "Epoch 1  loss=0.28520  val_loss=0.02168  sm_loss=0.28408  sm_val_loss=0.02149  time=1.87s\n",
      "Epoch 2  loss=0.02055  val_loss=0.01989  sm_loss=0.02053  sm_val_loss=0.01985  time=1.90s\n",
      "Epoch 3  loss=0.01941  val_loss=0.01929  sm_loss=0.01945  sm_val_loss=0.01917  time=2.20s\n",
      "Epoch 4  loss=0.01890  val_loss=0.01904  sm_loss=0.01896  sm_val_loss=0.01900  time=1.94s\n",
      "Epoch 6  loss=0.01805  val_loss=0.01873  sm_loss=0.01817  sm_val_loss=0.01872  time=1.90s\n",
      "Epoch 8  loss=0.01778  val_loss=0.01866  sm_loss=0.01792  sm_val_loss=0.01860  time=2.67s\n",
      "Epoch 10  loss=0.01741  val_loss=0.01826  sm_loss=0.01757  sm_val_loss=0.01827  time=1.90s\n",
      "Epoch 11  loss=0.01724  val_loss=0.01805  sm_loss=0.01741  sm_val_loss=0.01807  time=1.91s\n",
      "Epoch 13  loss=0.01685  val_loss=0.01797  sm_loss=0.01704  sm_val_loss=0.01793  time=1.88s\n",
      "Epoch 14  loss=0.01666  val_loss=0.01797  sm_loss=0.01686  sm_val_loss=0.01791  time=2.16s\n",
      "Epoch 15  loss=0.01644  val_loss=0.01784  sm_loss=0.01666  sm_val_loss=0.01785  time=1.82s\n",
      "Epoch 16  loss=0.01622  val_loss=0.01783  sm_loss=0.01645  sm_val_loss=0.01778  time=1.84s\n",
      "Epoch 17  loss=0.01599  val_loss=0.01776  sm_loss=0.01623  sm_val_loss=0.01768  time=1.95s\n",
      "Epoch 18  loss=0.01574  val_loss=0.01776  sm_loss=0.01599  sm_val_loss=0.01766  time=1.90s\n",
      "Epoch 20  loss=0.01548  val_loss=0.01777  sm_loss=0.01576  sm_val_loss=0.01765  time=2.06s\n",
      "Fold 3 log loss: 0.017657713567727665\n",
      "Fold 4\n",
      "Epoch 1  loss=0.29015  val_loss=0.02106  sm_loss=0.28935  sm_val_loss=0.02101  time=2.38s\n",
      "Epoch 2  loss=0.02037  val_loss=0.01945  sm_loss=0.02038  sm_val_loss=0.01948  time=2.00s\n",
      "Epoch 4  loss=0.01896  val_loss=0.01867  sm_loss=0.01901  sm_val_loss=0.01867  time=2.20s\n",
      "Epoch 5  loss=0.01858  val_loss=0.01856  sm_loss=0.01868  sm_val_loss=0.01842  time=2.17s\n",
      "Epoch 8  loss=0.01782  val_loss=0.01800  sm_loss=0.01796  sm_val_loss=0.01802  time=1.90s\n",
      "Epoch 10  loss=0.01756  val_loss=0.01784  sm_loss=0.01771  sm_val_loss=0.01787  time=1.92s\n",
      "Epoch 12  loss=0.01714  val_loss=0.01760  sm_loss=0.01732  sm_val_loss=0.01762  time=1.95s\n",
      "Epoch 13  loss=0.01691  val_loss=0.01730  sm_loss=0.01710  sm_val_loss=0.01731  time=1.89s\n",
      "Epoch 14  loss=0.01672  val_loss=0.01725  sm_loss=0.01693  sm_val_loss=0.01722  time=2.13s\n",
      "Epoch 16  loss=0.01628  val_loss=0.01721  sm_loss=0.01652  sm_val_loss=0.01720  time=1.85s\n",
      "Epoch 17  loss=0.01603  val_loss=0.01712  sm_loss=0.01628  sm_val_loss=0.01708  time=1.88s\n",
      "Epoch 18  loss=0.01583  val_loss=0.01706  sm_loss=0.01610  sm_val_loss=0.01699  time=1.92s\n",
      "Fold 4 log loss: 0.017044175496404697\n",
      "Fold 5\n",
      "Epoch 1  loss=0.28392  val_loss=0.02394  sm_loss=0.28337  sm_val_loss=0.02372  time=1.84s\n",
      "Epoch 2  loss=0.02072  val_loss=0.02044  sm_loss=0.02067  sm_val_loss=0.02034  time=1.84s\n",
      "Epoch 7  loss=0.01983  val_loss=0.02046  sm_loss=0.01987  sm_val_loss=0.02023  time=1.85s\n",
      "Epoch 8  loss=0.01925  val_loss=0.01937  sm_loss=0.01934  sm_val_loss=0.01928  time=1.87s\n",
      "Epoch 9  loss=0.01885  val_loss=0.01902  sm_loss=0.01891  sm_val_loss=0.01894  time=2.31s\n",
      "Epoch 10  loss=0.01834  val_loss=0.01875  sm_loss=0.01846  sm_val_loss=0.01861  time=2.40s\n",
      "Epoch 11  loss=0.01811  val_loss=0.01858  sm_loss=0.01824  sm_val_loss=0.01854  time=1.99s\n",
      "Epoch 12  loss=0.01779  val_loss=0.01858  sm_loss=0.01794  sm_val_loss=0.01848  time=1.88s\n",
      "Epoch 13  loss=0.01770  val_loss=0.01843  sm_loss=0.01786  sm_val_loss=0.01827  time=1.96s\n",
      "Epoch 14  loss=0.01743  val_loss=0.01793  sm_loss=0.01761  sm_val_loss=0.01791  time=2.17s\n",
      "Epoch 15  loss=0.01713  val_loss=0.01780  sm_loss=0.01732  sm_val_loss=0.01778  time=2.10s\n",
      "Epoch 17  loss=0.01658  val_loss=0.01778  sm_loss=0.01681  sm_val_loss=0.01778  time=1.96s\n",
      "Epoch 18  loss=0.01637  val_loss=0.01776  sm_loss=0.01661  sm_val_loss=0.01768  time=1.85s\n",
      "Epoch 19  loss=0.01620  val_loss=0.01770  sm_loss=0.01646  sm_val_loss=0.01764  time=1.98s\n",
      "Fold 5 log loss: 0.01764124187889875\n",
      "Fold 6\n",
      "Epoch 1  loss=0.28033  val_loss=0.02275  sm_loss=0.27947  sm_val_loss=0.02250  time=1.84s\n",
      "Epoch 2  loss=0.02082  val_loss=0.02233  sm_loss=0.02077  sm_val_loss=0.02222  time=1.86s\n",
      "Epoch 7  loss=0.02144  val_loss=0.02342  sm_loss=0.02101  sm_val_loss=0.02150  time=1.88s\n",
      "Epoch 9  loss=0.02007  val_loss=0.02250  sm_loss=0.01985  sm_val_loss=0.02004  time=2.06s\n",
      "Epoch 10  loss=0.01966  val_loss=0.02120  sm_loss=0.01965  sm_val_loss=0.02000  time=2.01s\n",
      "Epoch 12  loss=0.01917  val_loss=0.02032  sm_loss=0.01923  sm_val_loss=0.01947  time=1.89s\n",
      "Epoch 13  loss=0.01871  val_loss=0.01949  sm_loss=0.01882  sm_val_loss=0.01935  time=1.87s\n",
      "Epoch 14  loss=0.01847  val_loss=0.01979  sm_loss=0.01860  sm_val_loss=0.01896  time=1.86s\n",
      "Epoch 15  loss=0.01826  val_loss=0.01988  sm_loss=0.01838  sm_val_loss=0.01881  time=1.83s\n",
      "Epoch 16  loss=0.01815  val_loss=0.01954  sm_loss=0.01827  sm_val_loss=0.01849  time=1.87s\n",
      "Epoch 17  loss=0.01819  val_loss=0.01912  sm_loss=0.01831  sm_val_loss=0.01847  time=2.07s\n",
      "Epoch 18  loss=0.01770  val_loss=0.01913  sm_loss=0.01787  sm_val_loss=0.01834  time=2.01s\n",
      "Epoch 19  loss=0.01758  val_loss=0.01912  sm_loss=0.01775  sm_val_loss=0.01824  time=2.10s\n",
      "Epoch 20  loss=0.01737  val_loss=0.01903  sm_loss=0.01755  sm_val_loss=0.01820  time=1.91s\n",
      "Fold 6 log loss: 0.01826346749957317\n",
      "Fold 7\n",
      "Epoch 1  loss=0.27724  val_loss=0.02643  sm_loss=0.27605  sm_val_loss=0.02626  time=1.97s\n",
      "Epoch 2  loss=0.02237  val_loss=0.02084  sm_loss=0.02174  sm_val_loss=0.02081  time=2.13s\n",
      "Epoch 3  loss=0.01985  val_loss=0.02078  sm_loss=0.01988  sm_val_loss=0.02077  time=1.88s\n",
      "Epoch 4  loss=0.01927  val_loss=0.01957  sm_loss=0.01932  sm_val_loss=0.01955  time=2.00s\n",
      "Epoch 5  loss=0.01871  val_loss=0.01914  sm_loss=0.01878  sm_val_loss=0.01919  time=2.07s\n",
      "Epoch 7  loss=0.01813  val_loss=0.01836  sm_loss=0.01825  sm_val_loss=0.01826  time=2.05s\n",
      "Epoch 9  loss=0.01767  val_loss=0.01793  sm_loss=0.01781  sm_val_loss=0.01794  time=1.84s\n",
      "Epoch 11  loss=0.01736  val_loss=0.01782  sm_loss=0.01752  sm_val_loss=0.01787  time=1.84s\n",
      "Epoch 12  loss=0.01722  val_loss=0.01779  sm_loss=0.01739  sm_val_loss=0.01775  time=1.82s\n",
      "Epoch 14  loss=0.01671  val_loss=0.01748  sm_loss=0.01691  sm_val_loss=0.01749  time=1.82s\n",
      "Epoch 15  loss=0.01659  val_loss=0.01747  sm_loss=0.01680  sm_val_loss=0.01747  time=1.83s\n",
      "Epoch 16  loss=0.01632  val_loss=0.01740  sm_loss=0.01655  sm_val_loss=0.01740  time=1.84s\n",
      "Epoch 17  loss=0.01608  val_loss=0.01729  sm_loss=0.01633  sm_val_loss=0.01730  time=1.83s\n",
      "Epoch 18  loss=0.01582  val_loss=0.01729  sm_loss=0.01607  sm_val_loss=0.01727  time=1.83s\n",
      "Epoch 19  loss=0.01570  val_loss=0.01725  sm_loss=0.01597  sm_val_loss=0.01723  time=2.07s\n",
      "Fold 7 log loss: 0.017351834847576388\n",
      "Seed 4\n",
      "Fold 1 log loss: 0.0172178214838474\n",
      "Fold 2 log loss: 0.0172936554893337\n",
      "Fold 3 log loss: 0.017657713567727665\n",
      "Fold 4 log loss: 0.017044175496404697\n",
      "Fold 5 log loss: 0.01764124187889875\n",
      "Fold 6 log loss: 0.01826346749957317\n",
      "Fold 7 log loss: 0.017351834847576388\n",
      "Std of log loss: 0.00037407176192456203\n",
      "Total log loss: 0.01749586923967173\n",
      "Total log loss in targets: 0.017271281902428874\n"
     ]
    }
   ],
   "source": [
    "target_oof = np.zeros([len(fn_train),fn_targets.shape[1]])\n",
    "target_pred = np.zeros([len(fn_test),fn_targets.shape[1]])\n",
    "\n",
    "seeds = [0,1,2,3,4] \n",
    "    \n",
    "for seed_ in seeds:\n",
    "    oof, oof_targets, pytorch_pred = torch_tl(fn_train, fn_targets, fn_test, seed_, fn_train.shape[1]-1)\n",
    "    target_oof += oof / len(seeds)\n",
    "    target_pred += pytorch_pred / len(seeds)\n",
    "\n",
    "print(\"Total log loss in targets: {}\".format(mean_log_loss(oof_targets, target_oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T14:35:08.991486Z",
     "iopub.status.busy": "2020-11-12T14:35:08.990546Z",
     "iopub.status.idle": "2020-11-12T14:35:10.138095Z",
     "shell.execute_reply": "2020-11-12T14:35:10.139445Z"
    },
    "papermill": {
     "duration": 1.371938,
     "end_time": "2020-11-12T14:35:10.139618",
     "exception": false,
     "start_time": "2020-11-12T14:35:08.767680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AUC : 0.6435926822868844\n"
     ]
    }
   ],
   "source": [
    "aucs = []\n",
    "for task_id in range(targets.shape[1]-1):\n",
    "    aucs.append(roc_auc_score(y_true=targets.iloc[:, task_id+1].values,\n",
    "                              y_score=target_oof[:, task_id]))\n",
    "print(f\"Overall AUC : {np.mean(aucs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T14:35:10.592148Z",
     "iopub.status.busy": "2020-11-12T14:35:10.591269Z",
     "iopub.status.idle": "2020-11-12T14:35:16.599545Z",
     "shell.execute_reply": "2020-11-12T14:35:16.598411Z"
    },
    "papermill": {
     "duration": 6.241173,
     "end_time": "2020-11-12T14:35:16.599671",
     "exception": false,
     "start_time": "2020-11-12T14:35:10.358498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF log loss:  0.01591795142330187\n"
     ]
    }
   ],
   "source": [
    "t = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "train_checkscore = t.copy()\n",
    "train_checkscore.loc[train_checkscore.index.isin(cons_train_index),target_feats] = target_oof\n",
    "train_checkscore.loc[train_checkscore.index.isin(noncons_train_index),target_feats] = 0\n",
    "t.drop(\"sig_id\", axis=1, inplace=True)\n",
    "print('OOF log loss: ', log_loss(np.ravel(t), np.ravel(np.array(train_checkscore.iloc[:,1:]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T14:35:17.060980Z",
     "iopub.status.busy": "2020-11-12T14:35:17.059645Z",
     "iopub.status.idle": "2020-11-12T14:35:19.684351Z",
     "shell.execute_reply": "2020-11-12T14:35:19.683267Z"
    },
    "papermill": {
     "duration": 2.856914,
     "end_time": "2020-11-12T14:35:19.684477",
     "exception": false,
     "start_time": "2020-11-12T14:35:16.827563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.loc[cons_test_index,target_feats] = target_pred\n",
    "sub.loc[noncons_test_index,target_feats] = 0\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 1500.699401,
   "end_time": "2020-11-12T14:35:20.432254",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-12T14:10:19.732853",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
