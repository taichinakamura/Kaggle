{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015171,
     "end_time": "2020-10-12T11:02:51.387300",
     "exception": false,
     "start_time": "2020-10-12T11:02:51.372129",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- first keras model with label smoothing and new feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-12T11:02:51.423511Z",
     "iopub.status.busy": "2020-10-12T11:02:51.422839Z",
     "iopub.status.idle": "2020-10-12T11:02:57.339581Z",
     "shell.execute_reply": "2020-10-12T11:02:57.340765Z"
    },
    "papermill": {
     "duration": 5.939725,
     "end_time": "2020-10-12T11:02:57.341006",
     "exception": false,
     "start_time": "2020-10-12T11:02:51.401281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:68: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.3.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.3.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "sys.path.append('../input/multilabelstraifier/')\n",
    "from ml_stratifiers import MultilabelStratifiedKFold\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tensorflow.keras import layers,regularizers,Sequential,backend,callbacks,optimizers,metrics,losses\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-10-12T11:02:57.385461Z",
     "iopub.status.busy": "2020-10-12T11:02:57.384699Z",
     "iopub.status.idle": "2020-10-12T11:03:02.920435Z",
     "shell.execute_reply": "2020-10-12T11:03:02.919818Z"
    },
    "papermill": {
     "duration": 5.557673,
     "end_time": "2020-10-12T11:03:02.920560",
     "exception": false,
     "start_time": "2020-10-12T11:02:57.362887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/lish-moa/'\n",
    "train = pd.read_csv(DATA_DIR + 'train_features.csv')\n",
    "targets = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "non_targets = pd.read_csv(DATA_DIR + 'train_targets_nonscored.csv')\n",
    "test = pd.read_csv(DATA_DIR + 'test_features.csv')\n",
    "sub = pd.read_csv(DATA_DIR + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T11:03:02.956991Z",
     "iopub.status.busy": "2020-10-12T11:03:02.956306Z",
     "iopub.status.idle": "2020-10-12T11:03:02.960149Z",
     "shell.execute_reply": "2020-10-12T11:03:02.959647Z"
    },
    "papermill": {
     "duration": 0.024248,
     "end_time": "2020-10-12T11:03:02.960258",
     "exception": false,
     "start_time": "2020-10-12T11:03:02.936010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_feats = [ i for i in targets.columns if i != \"sig_id\"]\n",
    "g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "c_feats = [i for i in train.columns if \"c-\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T11:03:02.997577Z",
     "iopub.status.busy": "2020-10-12T11:03:02.996807Z",
     "iopub.status.idle": "2020-10-12T11:03:03.092297Z",
     "shell.execute_reply": "2020-10-12T11:03:03.091742Z"
    },
    "papermill": {
     "duration": 0.117796,
     "end_time": "2020-10-12T11:03:03.092417",
     "exception": false,
     "start_time": "2020-10-12T11:03:02.974621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "noncons_train_index = train[train.cp_type==\"ctl_vehicle\"].index\n",
    "cons_train_index = train[train.cp_type!=\"ctl_vehicle\"].index\n",
    "noncons_test_index = test[test.cp_type==\"ctl_vehicle\"].index\n",
    "cons_test_index = test[test.cp_type!=\"ctl_vehicle\"].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01433,
     "end_time": "2020-10-12T11:03:03.121440",
     "exception": false,
     "start_time": "2020-10-12T11:03:03.107110",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T11:03:03.163745Z",
     "iopub.status.busy": "2020-10-12T11:03:03.162743Z",
     "iopub.status.idle": "2020-10-12T11:03:03.468639Z",
     "shell.execute_reply": "2020-10-12T11:03:03.468045Z"
    },
    "papermill": {
     "duration": 0.332829,
     "end_time": "2020-10-12T11:03:03.468755",
     "exception": false,
     "start_time": "2020-10-12T11:03:03.135926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train[train.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "targets = targets[targets.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "non_targets = non_targets[non_targets.index.isin(cons_train_index)].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T11:03:03.530979Z",
     "iopub.status.busy": "2020-10-12T11:03:03.529892Z",
     "iopub.status.idle": "2020-10-12T11:03:03.543448Z",
     "shell.execute_reply": "2020-10-12T11:03:03.542897Z"
    },
    "papermill": {
     "duration": 0.059787,
     "end_time": "2020-10-12T11:03:03.543567",
     "exception": false,
     "start_time": "2020-10-12T11:03:03.483780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "non_target_feats = [i for i in non_targets.columns if i != \"sig_id\"]\n",
    "nontarget_dists = pd.DataFrame(np.sum(non_targets[non_target_feats])).reset_index(drop=False)\n",
    "nontarget_dists.columns = [\"target\", \"number\"]\n",
    "nontarget_dists = nontarget_dists.sort_values(\"number\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T11:03:03.580112Z",
     "iopub.status.busy": "2020-10-12T11:03:03.579370Z",
     "iopub.status.idle": "2020-10-12T11:03:03.621001Z",
     "shell.execute_reply": "2020-10-12T11:03:03.621753Z"
    },
    "papermill": {
     "duration": 0.063076,
     "end_time": "2020-10-12T11:03:03.621895",
     "exception": false,
     "start_time": "2020-10-12T11:03:03.558819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first drop 71\n",
      "shape after 1st drop: (21948, 332)\n"
     ]
    }
   ],
   "source": [
    "drop_list1 = list(nontarget_dists[nontarget_dists.number==0][\"target\"].values)\n",
    "print(\"first drop\", len(drop_list1))\n",
    "non_targets.drop(drop_list1, axis=1, inplace=True)\n",
    "print(\"shape after 1st drop:\", non_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T11:03:03.669595Z",
     "iopub.status.busy": "2020-10-12T11:03:03.660631Z",
     "iopub.status.idle": "2020-10-12T11:03:08.726768Z",
     "shell.execute_reply": "2020-10-12T11:03:08.727311Z"
    },
    "papermill": {
     "duration": 5.089985,
     "end_time": "2020-10-12T11:03:08.727460",
     "exception": false,
     "start_time": "2020-10-12T11:03:03.637475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 889) (3982, 889)\n"
     ]
    }
   ],
   "source": [
    "def fe(df):\n",
    "    tmp = df.copy()\n",
    "    tmp.loc[:, 'cp_type'] = tmp.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    tmp.loc[:, 'cp_dose'] = tmp.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "    tmp['g_sum'] = tmp[g_feats].sum(axis = 1)\n",
    "    tmp['g_mean'] = tmp[g_feats].mean(axis = 1)\n",
    "    tmp['g_std'] = tmp[g_feats].std(axis = 1)\n",
    "    tmp['g_kurt'] = tmp[g_feats].kurtosis(axis = 1)\n",
    "    tmp['g_skew'] = tmp[g_feats].skew(axis = 1)\n",
    "    tmp['c_sum'] = tmp[c_feats].sum(axis = 1)\n",
    "    tmp['c_mean'] = tmp[c_feats].mean(axis = 1)\n",
    "    tmp['c_std'] = tmp[c_feats].std(axis = 1)\n",
    "    tmp['c_kurt'] = tmp[c_feats].kurtosis(axis = 1)\n",
    "    tmp['c_skew'] = tmp[c_feats].skew(axis = 1)\n",
    "    tmp['gc_sum'] = tmp[c_feats + g_feats].sum(axis = 1)\n",
    "    tmp['gc_mean'] = tmp[c_feats + g_feats].mean(axis = 1)\n",
    "    tmp['gc_std'] = tmp[c_feats + g_feats].std(axis = 1)\n",
    "    tmp['gc_kurt'] = tmp[c_feats + g_feats].kurtosis(axis = 1)\n",
    "    tmp['gc_skew'] = tmp[c_feats + g_feats].skew(axis = 1)\n",
    "        \n",
    "    tmp.drop([\"cp_type\", \"sig_id\"], axis=1, inplace=True)\n",
    "    return tmp\n",
    "\n",
    "f_train = fe(train)\n",
    "f_test = fe(test)\n",
    "\n",
    "print(f_train.shape, f_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T11:03:08.769950Z",
     "iopub.status.busy": "2020-10-12T11:03:08.768786Z",
     "iopub.status.idle": "2020-10-12T11:03:09.904733Z",
     "shell.execute_reply": "2020-10-12T11:03:09.905315Z"
    },
    "papermill": {
     "duration": 1.160892,
     "end_time": "2020-10-12T11:03:09.905457",
     "exception": false,
     "start_time": "2020-10-12T11:03:08.744565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fn_train = f_train.copy().to_numpy()\n",
    "fn_test = f_test.copy().to_numpy()\n",
    "\n",
    "ss = preprocessing.RobustScaler()\n",
    "fn_train= ss.fit_transform(fn_train)\n",
    "fn_test = ss.transform(fn_test)\n",
    "\n",
    "fn_nontargets = non_targets.drop(\"sig_id\", axis=1).copy().to_numpy()\n",
    "fn_targets = targets.drop(\"sig_id\", axis=1).copy().to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016253,
     "end_time": "2020-10-12T11:03:09.937901",
     "exception": false,
     "start_time": "2020-10-12T11:03:09.921648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T11:03:10.002971Z",
     "iopub.status.busy": "2020-10-12T11:03:09.998934Z",
     "iopub.status.idle": "2020-10-12T11:03:10.005109Z",
     "shell.execute_reply": "2020-10-12T11:03:10.005651Z"
    },
    "papermill": {
     "duration": 0.051236,
     "end_time": "2020-10-12T11:03:10.005767",
     "exception": false,
     "start_time": "2020-10-12T11:03:09.954531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prediction Clipping Thresholds\n",
    "p_min = 0.001\n",
    "p_max = 0.999\n",
    "\n",
    "n_folds = 5\n",
    "\n",
    "def mean_log_loss(y_true, y_pred):\n",
    "    metrics = []\n",
    "    for i, target in enumerate(target_feats):\n",
    "        metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float), labels=[0,1]))\n",
    "    return np.mean(metrics)\n",
    "\n",
    "# Evaluation Metric with clipping and no label smoothing\n",
    "def logloss(y_true, y_pred):\n",
    "    y_pred = tf.clip_by_value(y_pred,p_min,p_max)\n",
    "    return -backend.mean(y_true*backend.log(y_pred) + (1-y_true)*backend.log(1-y_pred))\n",
    "\n",
    "def seed_everything(seed=1234): \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "def create_model(shape):\n",
    "    inp = tf.keras.layers.Input(shape = (shape))\n",
    "    x = tf.keras.layers.BatchNormalization()(inp)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tfa.layers.WeightNormalization(tf.keras.layers.Dense(2048, activation = 'relu'))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.6)(x)\n",
    "    x = tfa.layers.WeightNormalization(tf.keras.layers.Dense(1048, activation = 'relu'))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.6)(x)\n",
    "    out = tfa.layers.WeightNormalization(tf.keras.layers.Dense(206, activation = 'sigmoid'))(x)\n",
    "    model = tf.keras.models.Model(inputs = inp, outputs = out)\n",
    "    return model\n",
    "    \n",
    "def modelling_keras(X_train, y_train, X_test, input_features, output_features, sample_seed):\n",
    "    seed_everything(seed=sample_seed) \n",
    "    oof = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    pred_value = np.zeros([X_test.shape[0], y_train.shape[1]])\n",
    "    \n",
    "    scores = []\n",
    "    mskf=MultilabelStratifiedKFold(n_splits = n_folds, shuffle=True, random_state=2)\n",
    "    for i , (train_index, val_index) in enumerate(mskf.split(X_train, y_train)):   \n",
    "        print(\"Fold \"+str(i+1))\n",
    "        X_train2 = X_train[train_index,:]\n",
    "        y_train2 = y_train[train_index,:]\n",
    "    \n",
    "        X_test2 = X_train[val_index,:]\n",
    "        y_test2 = y_train[val_index,:] \n",
    "        \n",
    "        model = create_model(input_features)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "                      loss=losses.BinaryCrossentropy(label_smoothing=0.001), metrics=logloss)\n",
    "        reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_logloss', factor=0.1, patience=3, mode='min', min_lr=1E-5)\n",
    "        #early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_logloss', min_delta=1E-5, \n",
    "        #                                                  patience=10, mode='min',restore_best_weights=True)\n",
    "        save_best = tf.keras.callbacks.ModelCheckpoint('./nn_model.h5', save_best_only=True, monitor=\"val_logloss\", verbose=1)\n",
    "        \n",
    "        model.fit(X_train2, y_train2, validation_data=(X_test2, y_test2),batch_size=128, \n",
    "                epochs=40,callbacks=[reduce_lr, save_best]) \n",
    "\n",
    "        model.load_weights('./nn_model.h5')\n",
    "        valid = np.array(model.predict(X_test2))\n",
    "        oof[val_index,:] = valid\n",
    "        pred_value += model.predict(X_test)/ n_folds\n",
    "        print(\"Fold {} log loss: {}\".format(i+1, mean_log_loss(y_train[val_index,:], valid)))\n",
    "        scores.append(mean_log_loss(y_train[val_index,:], valid))\n",
    "    \n",
    "    print(\"Seed {}\".format(seed_))\n",
    "    for i, ele in enumerate(scores):\n",
    "        print(\"Fold {} log loss: {}\".format(i+1, scores[i]))\n",
    "    print(\"Std of log loss: {}\".format(np.std(scores)))\n",
    "        \n",
    "    print(\"Total log loss: {}\".format(mean_log_loss(y_train, oof)))\n",
    "\n",
    "    return oof, pred_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01594,
     "end_time": "2020-10-12T11:03:10.037598",
     "exception": false,
     "start_time": "2020-10-12T11:03:10.021658",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# non-targets, targets separate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T11:03:10.079972Z",
     "iopub.status.busy": "2020-10-12T11:03:10.078633Z",
     "iopub.status.idle": "2020-10-12T11:16:54.281552Z",
     "shell.execute_reply": "2020-10-12T11:16:54.282023Z"
    },
    "papermill": {
     "duration": 824.228652,
     "end_time": "2020-10-12T11:16:54.282170",
     "exception": false,
     "start_time": "2020-10-12T11:03:10.053518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.4885 - logloss: 0.4879\n",
      "Epoch 00001: val_logloss improved from inf to 0.10674, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.4777 - logloss: 0.4749 - val_loss: 0.1083 - val_logloss: 0.1067\n",
      "Epoch 2/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0561 - logloss: 0.0543\n",
      "Epoch 00002: val_logloss improved from 0.10674 to 0.02940, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0559 - logloss: 0.0540 - val_loss: 0.0317 - val_logloss: 0.0294\n",
      "Epoch 3/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0290 - logloss: 0.0265\n",
      "Epoch 00003: val_logloss improved from 0.02940 to 0.02274, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0290 - logloss: 0.0265 - val_loss: 0.0254 - val_logloss: 0.0227\n",
      "Epoch 4/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0258 - logloss: 0.0231\n",
      "Epoch 00004: val_logloss improved from 0.02274 to 0.02126, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0259 - logloss: 0.0231 - val_loss: 0.0242 - val_logloss: 0.0213\n",
      "Epoch 5/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0242 - logloss: 0.0213\n",
      "Epoch 00005: val_logloss improved from 0.02126 to 0.02008, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0241 - logloss: 0.0212 - val_loss: 0.0231 - val_logloss: 0.0201\n",
      "Epoch 6/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0233 - logloss: 0.0203\n",
      "Epoch 00006: val_logloss improved from 0.02008 to 0.01941, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0233 - logloss: 0.0203 - val_loss: 0.0225 - val_logloss: 0.0194\n",
      "Epoch 7/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0230 - logloss: 0.0199\n",
      "Epoch 00007: val_logloss improved from 0.01941 to 0.01894, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0230 - logloss: 0.0199 - val_loss: 0.0221 - val_logloss: 0.0189\n",
      "Epoch 8/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0226 - logloss: 0.0195\n",
      "Epoch 00008: val_logloss improved from 0.01894 to 0.01866, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0226 - logloss: 0.0195 - val_loss: 0.0219 - val_logloss: 0.0187\n",
      "Epoch 9/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0223 - logloss: 0.0191\n",
      "Epoch 00009: val_logloss improved from 0.01866 to 0.01837, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0224 - logloss: 0.0191 - val_loss: 0.0216 - val_logloss: 0.0184\n",
      "Epoch 10/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0220 - logloss: 0.0188\n",
      "Epoch 00010: val_logloss improved from 0.01837 to 0.01812, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0220 - logloss: 0.0187 - val_loss: 0.0214 - val_logloss: 0.0181\n",
      "Epoch 11/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0216 - logloss: 0.0184\n",
      "Epoch 00011: val_logloss improved from 0.01812 to 0.01800, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0216 - logloss: 0.0184 - val_loss: 0.0212 - val_logloss: 0.0180\n",
      "Epoch 12/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0214 - logloss: 0.0182\n",
      "Epoch 00012: val_logloss improved from 0.01800 to 0.01781, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0214 - logloss: 0.0182 - val_loss: 0.0211 - val_logloss: 0.0178\n",
      "Epoch 13/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0212 - logloss: 0.0180\n",
      "Epoch 00013: val_logloss improved from 0.01781 to 0.01767, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0212 - logloss: 0.0180 - val_loss: 0.0209 - val_logloss: 0.0177\n",
      "Epoch 14/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0213 - logloss: 0.0181\n",
      "Epoch 00014: val_logloss did not improve from 0.01767\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0212 - logloss: 0.0180 - val_loss: 0.0210 - val_logloss: 0.0177\n",
      "Epoch 15/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0210 - logloss: 0.0177\n",
      "Epoch 00015: val_logloss improved from 0.01767 to 0.01744, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0210 - logloss: 0.0177 - val_loss: 0.0208 - val_logloss: 0.0174\n",
      "Epoch 16/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0207 - logloss: 0.0174\n",
      "Epoch 00016: val_logloss improved from 0.01744 to 0.01733, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0207 - logloss: 0.0174 - val_loss: 0.0207 - val_logloss: 0.0173\n",
      "Epoch 17/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0206 - logloss: 0.0173\n",
      "Epoch 00017: val_logloss improved from 0.01733 to 0.01724, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0205 - logloss: 0.0173 - val_loss: 0.0206 - val_logloss: 0.0172\n",
      "Epoch 18/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0204 - logloss: 0.0172\n",
      "Epoch 00018: val_logloss did not improve from 0.01724\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0204 - logloss: 0.0172 - val_loss: 0.0208 - val_logloss: 0.0174\n",
      "Epoch 19/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0205 - logloss: 0.0172\n",
      "Epoch 00019: val_logloss improved from 0.01724 to 0.01712, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0205 - logloss: 0.0171 - val_loss: 0.0204 - val_logloss: 0.0171\n",
      "Epoch 20/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0200 - logloss: 0.0167\n",
      "Epoch 00020: val_logloss improved from 0.01712 to 0.01701, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0201 - logloss: 0.0168 - val_loss: 0.0204 - val_logloss: 0.0170\n",
      "Epoch 21/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0198 - logloss: 0.0166\n",
      "Epoch 00021: val_logloss improved from 0.01701 to 0.01688, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0199 - logloss: 0.0166 - val_loss: 0.0202 - val_logloss: 0.0169\n",
      "Epoch 22/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0198 - logloss: 0.0166\n",
      "Epoch 00022: val_logloss did not improve from 0.01688\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0198 - logloss: 0.0166 - val_loss: 0.0206 - val_logloss: 0.0173\n",
      "Epoch 23/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0197 - logloss: 0.0164\n",
      "Epoch 00023: val_logloss improved from 0.01688 to 0.01688, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0197 - logloss: 0.0164 - val_loss: 0.0203 - val_logloss: 0.0169\n",
      "Epoch 24/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0194 - logloss: 0.0162\n",
      "Epoch 00024: val_logloss improved from 0.01688 to 0.01673, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0201 - val_logloss: 0.0167\n",
      "Epoch 25/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0195 - logloss: 0.0163\n",
      "Epoch 00025: val_logloss did not improve from 0.01673\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0195 - logloss: 0.0163 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 26/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0193 - logloss: 0.0160\n",
      "Epoch 00026: val_logloss improved from 0.01673 to 0.01671, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0193 - logloss: 0.0160 - val_loss: 0.0200 - val_logloss: 0.0167\n",
      "Epoch 27/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0190 - logloss: 0.0158\n",
      "Epoch 00027: val_logloss did not improve from 0.01671\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0191 - logloss: 0.0159 - val_loss: 0.0203 - val_logloss: 0.0168\n",
      "Epoch 28/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0187 - logloss: 0.0155\n",
      "Epoch 00028: val_logloss improved from 0.01671 to 0.01660, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0187 - logloss: 0.0155 - val_loss: 0.0200 - val_logloss: 0.0166\n",
      "Epoch 29/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0186 - logloss: 0.0153\n",
      "Epoch 00029: val_logloss improved from 0.01660 to 0.01655, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0186 - logloss: 0.0153 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 30/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0152\n",
      "Epoch 00030: val_logloss improved from 0.01655 to 0.01652, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 31/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0152\n",
      "Epoch 00031: val_logloss improved from 0.01652 to 0.01650, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0185 - logloss: 0.0152 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 32/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0184 - logloss: 0.0151\n",
      "Epoch 00032: val_logloss improved from 0.01650 to 0.01650, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0184 - logloss: 0.0151 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 33/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0184 - logloss: 0.0151\n",
      "Epoch 00033: val_logloss did not improve from 0.01650\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0184 - logloss: 0.0151 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 34/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0184 - logloss: 0.0151\n",
      "Epoch 00034: val_logloss improved from 0.01650 to 0.01649, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0184 - logloss: 0.0151 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 35/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0183 - logloss: 0.0150\n",
      "Epoch 00035: val_logloss improved from 0.01649 to 0.01649, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0183 - logloss: 0.0150 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 36/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0183 - logloss: 0.0151\n",
      "Epoch 00036: val_logloss improved from 0.01649 to 0.01648, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0183 - logloss: 0.0151 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 37/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0183 - logloss: 0.0151\n",
      "Epoch 00037: val_logloss improved from 0.01648 to 0.01648, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0183 - logloss: 0.0150 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 38/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0183 - logloss: 0.0151\n",
      "Epoch 00038: val_logloss improved from 0.01648 to 0.01648, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0183 - logloss: 0.0151 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 39/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0183 - logloss: 0.0150\n",
      "Epoch 00039: val_logloss did not improve from 0.01648\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0183 - logloss: 0.0151 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 40/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0183 - logloss: 0.0150\n",
      "Epoch 00040: val_logloss improved from 0.01648 to 0.01648, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0183 - logloss: 0.0150 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Fold 1 log loss: 0.016453102652094397\n",
      "Fold 2\n",
      "Epoch 1/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.4949 - logloss: 0.4944\n",
      "Epoch 00001: val_logloss improved from inf to 0.10329, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.4757 - logloss: 0.4730 - val_loss: 0.1046 - val_logloss: 0.1033\n",
      "Epoch 2/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0559 - logloss: 0.0541\n",
      "Epoch 00002: val_logloss improved from 0.10329 to 0.02976, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0552 - logloss: 0.0533 - val_loss: 0.0321 - val_logloss: 0.0298\n",
      "Epoch 3/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0291 - logloss: 0.0266\n",
      "Epoch 00003: val_logloss improved from 0.02976 to 0.02226, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0290 - logloss: 0.0265 - val_loss: 0.0249 - val_logloss: 0.0223\n",
      "Epoch 4/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0259 - logloss: 0.0231\n",
      "Epoch 00004: val_logloss improved from 0.02226 to 0.02075, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0258 - logloss: 0.0230 - val_loss: 0.0236 - val_logloss: 0.0208\n",
      "Epoch 5/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0243 - logloss: 0.0214\n",
      "Epoch 00005: val_logloss improved from 0.02075 to 0.01998, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0243 - logloss: 0.0213 - val_loss: 0.0230 - val_logloss: 0.0200\n",
      "Epoch 6/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0234 - logloss: 0.0203\n",
      "Epoch 00006: val_logloss improved from 0.01998 to 0.01920, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0234 - logloss: 0.0203 - val_loss: 0.0222 - val_logloss: 0.0192\n",
      "Epoch 7/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0230 - logloss: 0.0199\n",
      "Epoch 00007: val_logloss improved from 0.01920 to 0.01889, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0230 - logloss: 0.0199 - val_loss: 0.0220 - val_logloss: 0.0189\n",
      "Epoch 8/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0225 - logloss: 0.0194\n",
      "Epoch 00008: val_logloss improved from 0.01889 to 0.01861, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0225 - logloss: 0.0193 - val_loss: 0.0218 - val_logloss: 0.0186\n",
      "Epoch 9/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0222 - logloss: 0.0190\n",
      "Epoch 00009: val_logloss improved from 0.01861 to 0.01823, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0222 - logloss: 0.0190 - val_loss: 0.0214 - val_logloss: 0.0182\n",
      "Epoch 10/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0219 - logloss: 0.0187\n",
      "Epoch 00010: val_logloss improved from 0.01823 to 0.01797, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0219 - logloss: 0.0187 - val_loss: 0.0211 - val_logloss: 0.0180\n",
      "Epoch 11/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0217 - logloss: 0.0185\n",
      "Epoch 00011: val_logloss did not improve from 0.01797\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0217 - logloss: 0.0185 - val_loss: 0.0212 - val_logloss: 0.0180\n",
      "Epoch 12/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0214 - logloss: 0.0182\n",
      "Epoch 00012: val_logloss improved from 0.01797 to 0.01761, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0214 - logloss: 0.0182 - val_loss: 0.0208 - val_logloss: 0.0176\n",
      "Epoch 13/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0214 - logloss: 0.0181\n",
      "Epoch 00013: val_logloss improved from 0.01761 to 0.01755, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0213 - logloss: 0.0181 - val_loss: 0.0208 - val_logloss: 0.0176\n",
      "Epoch 14/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0210 - logloss: 0.0179\n",
      "Epoch 00014: val_logloss improved from 0.01755 to 0.01740, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0210 - logloss: 0.0179 - val_loss: 0.0207 - val_logloss: 0.0174\n",
      "Epoch 15/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0209 - logloss: 0.0176\n",
      "Epoch 00015: val_logloss improved from 0.01740 to 0.01725, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0209 - logloss: 0.0177 - val_loss: 0.0205 - val_logloss: 0.0172\n",
      "Epoch 16/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0206 - logloss: 0.0174\n",
      "Epoch 00016: val_logloss did not improve from 0.01725\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0206 - logloss: 0.0175 - val_loss: 0.0207 - val_logloss: 0.0175\n",
      "Epoch 17/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0206 - logloss: 0.0173\n",
      "Epoch 00017: val_logloss improved from 0.01725 to 0.01706, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0205 - logloss: 0.0173 - val_loss: 0.0203 - val_logloss: 0.0171\n",
      "Epoch 18/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0204 - logloss: 0.0171\n",
      "Epoch 00018: val_logloss improved from 0.01706 to 0.01704, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0204 - logloss: 0.0171 - val_loss: 0.0203 - val_logloss: 0.0170\n",
      "Epoch 19/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0201 - logloss: 0.0169\n",
      "Epoch 00019: val_logloss improved from 0.01704 to 0.01700, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0201 - logloss: 0.0169 - val_loss: 0.0203 - val_logloss: 0.0170\n",
      "Epoch 20/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0199 - logloss: 0.0167\n",
      "Epoch 00020: val_logloss improved from 0.01700 to 0.01686, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0199 - logloss: 0.0167 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 21/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0198 - logloss: 0.0165\n",
      "Epoch 00021: val_logloss improved from 0.01686 to 0.01681, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0198 - logloss: 0.0166 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 22/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0198 - logloss: 0.0165\n",
      "Epoch 00022: val_logloss improved from 0.01681 to 0.01677, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0198 - logloss: 0.0165 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 23/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0195 - logloss: 0.0162\n",
      "Epoch 00023: val_logloss did not improve from 0.01677\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0195 - logloss: 0.0162 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 24/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0191 - logloss: 0.0158\n",
      "Epoch 00024: val_logloss improved from 0.01677 to 0.01664, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0191 - logloss: 0.0158 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 25/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0189 - logloss: 0.0157\n",
      "Epoch 00025: val_logloss improved from 0.01664 to 0.01659, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0190 - logloss: 0.0157 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 26/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0189 - logloss: 0.0157\n",
      "Epoch 00026: val_logloss improved from 0.01659 to 0.01656, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0189 - logloss: 0.0157 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 27/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0189 - logloss: 0.0156\n",
      "Epoch 00027: val_logloss improved from 0.01656 to 0.01656, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0188 - logloss: 0.0156 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 28/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0188 - logloss: 0.0156\n",
      "Epoch 00028: val_logloss improved from 0.01656 to 0.01655, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0188 - logloss: 0.0156 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 29/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0188 - logloss: 0.0155\n",
      "Epoch 00029: val_logloss improved from 0.01655 to 0.01654, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0188 - logloss: 0.0156 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 30/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0188 - logloss: 0.0156\n",
      "Epoch 00030: val_logloss did not improve from 0.01654\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0188 - logloss: 0.0156 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 31/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0188 - logloss: 0.0155\n",
      "Epoch 00031: val_logloss improved from 0.01654 to 0.01653, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0187 - logloss: 0.0155 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 32/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0187 - logloss: 0.0155\n",
      "Epoch 00032: val_logloss improved from 0.01653 to 0.01653, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0187 - logloss: 0.0155 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 33/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0188 - logloss: 0.0156\n",
      "Epoch 00033: val_logloss improved from 0.01653 to 0.01652, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0188 - logloss: 0.0156 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 34/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0187 - logloss: 0.0155\n",
      "Epoch 00034: val_logloss improved from 0.01652 to 0.01652, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0187 - logloss: 0.0155 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 35/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0188 - logloss: 0.0155\n",
      "Epoch 00035: val_logloss did not improve from 0.01652\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0187 - logloss: 0.0155 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 36/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0188 - logloss: 0.0156\n",
      "Epoch 00036: val_logloss improved from 0.01652 to 0.01652, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0188 - logloss: 0.0155 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 37/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0186 - logloss: 0.0154\n",
      "Epoch 00037: val_logloss improved from 0.01652 to 0.01652, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 38/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0187 - logloss: 0.0155\n",
      "Epoch 00038: val_logloss improved from 0.01652 to 0.01651, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0187 - logloss: 0.0155 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 39/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0187 - logloss: 0.0155\n",
      "Epoch 00039: val_logloss improved from 0.01651 to 0.01651, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0188 - logloss: 0.0155 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 40/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0187 - logloss: 0.0155\n",
      "Epoch 00040: val_logloss did not improve from 0.01651\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0187 - logloss: 0.0154 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Fold 2 log loss: 0.016405001898573676\n",
      "Fold 3\n",
      "Epoch 1/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.4833 - logloss: 0.4828\n",
      "Epoch 00001: val_logloss improved from inf to 0.10249, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.4776 - logloss: 0.4750 - val_loss: 0.1037 - val_logloss: 0.1025\n",
      "Epoch 2/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0565 - logloss: 0.0546\n",
      "Epoch 00002: val_logloss improved from 0.10249 to 0.02916, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0555 - logloss: 0.0535 - val_loss: 0.0314 - val_logloss: 0.0292\n",
      "Epoch 3/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0293 - logloss: 0.0268\n",
      "Epoch 00003: val_logloss improved from 0.02916 to 0.02300, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0293 - logloss: 0.0268 - val_loss: 0.0256 - val_logloss: 0.0230\n",
      "Epoch 4/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0258 - logloss: 0.0230\n",
      "Epoch 00004: val_logloss improved from 0.02300 to 0.02122, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0258 - logloss: 0.0230 - val_loss: 0.0241 - val_logloss: 0.0212\n",
      "Epoch 5/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0242 - logloss: 0.0212\n",
      "Epoch 00005: val_logloss improved from 0.02122 to 0.01981, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0242 - logloss: 0.0212 - val_loss: 0.0228 - val_logloss: 0.0198\n",
      "Epoch 6/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0233 - logloss: 0.0203\n",
      "Epoch 00006: val_logloss improved from 0.01981 to 0.01913, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0233 - logloss: 0.0203 - val_loss: 0.0221 - val_logloss: 0.0191\n",
      "Epoch 7/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0230 - logloss: 0.0199\n",
      "Epoch 00007: val_logloss improved from 0.01913 to 0.01872, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0230 - logloss: 0.0199 - val_loss: 0.0218 - val_logloss: 0.0187\n",
      "Epoch 8/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0224 - logloss: 0.0193\n",
      "Epoch 00008: val_logloss improved from 0.01872 to 0.01844, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0225 - logloss: 0.0194 - val_loss: 0.0216 - val_logloss: 0.0184\n",
      "Epoch 9/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0220 - logloss: 0.0189\n",
      "Epoch 00009: val_logloss improved from 0.01844 to 0.01818, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0220 - logloss: 0.0189 - val_loss: 0.0213 - val_logloss: 0.0182\n",
      "Epoch 10/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0218 - logloss: 0.0186\n",
      "Epoch 00010: val_logloss improved from 0.01818 to 0.01815, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0218 - logloss: 0.0186 - val_loss: 0.0213 - val_logloss: 0.0182\n",
      "Epoch 11/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0215 - logloss: 0.0184\n",
      "Epoch 00011: val_logloss improved from 0.01815 to 0.01776, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0215 - logloss: 0.0184 - val_loss: 0.0209 - val_logloss: 0.0178\n",
      "Epoch 12/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0213 - logloss: 0.0181\n",
      "Epoch 00012: val_logloss improved from 0.01776 to 0.01769, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0213 - logloss: 0.0181 - val_loss: 0.0208 - val_logloss: 0.0177\n",
      "Epoch 13/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0212 - logloss: 0.0180\n",
      "Epoch 00013: val_logloss improved from 0.01769 to 0.01759, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0212 - logloss: 0.0180 - val_loss: 0.0207 - val_logloss: 0.0176\n",
      "Epoch 14/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0210 - logloss: 0.0178\n",
      "Epoch 00014: val_logloss improved from 0.01759 to 0.01743, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0210 - logloss: 0.0178 - val_loss: 0.0207 - val_logloss: 0.0174\n",
      "Epoch 15/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0209 - logloss: 0.0177\n",
      "Epoch 00015: val_logloss improved from 0.01743 to 0.01734, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0209 - logloss: 0.0177 - val_loss: 0.0205 - val_logloss: 0.0173\n",
      "Epoch 16/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0207 - logloss: 0.0174\n",
      "Epoch 00016: val_logloss improved from 0.01734 to 0.01718, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0207 - logloss: 0.0175 - val_loss: 0.0204 - val_logloss: 0.0172\n",
      "Epoch 17/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0205 - logloss: 0.0172\n",
      "Epoch 00017: val_logloss improved from 0.01718 to 0.01704, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0205 - logloss: 0.0172 - val_loss: 0.0202 - val_logloss: 0.0170\n",
      "Epoch 18/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0202 - logloss: 0.0170\n",
      "Epoch 00018: val_logloss improved from 0.01704 to 0.01701, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0202 - logloss: 0.0171 - val_loss: 0.0201 - val_logloss: 0.0170\n",
      "Epoch 19/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0204 - logloss: 0.0171\n",
      "Epoch 00019: val_logloss did not improve from 0.01701\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0203 - logloss: 0.0171 - val_loss: 0.0203 - val_logloss: 0.0172\n",
      "Epoch 20/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0200 - logloss: 0.0168\n",
      "Epoch 00020: val_logloss improved from 0.01701 to 0.01691, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0200 - logloss: 0.0168 - val_loss: 0.0202 - val_logloss: 0.0169\n",
      "Epoch 21/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0199 - logloss: 0.0166\n",
      "Epoch 00021: val_logloss improved from 0.01691 to 0.01682, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0198 - logloss: 0.0166 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 22/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0197 - logloss: 0.0164\n",
      "Epoch 00022: val_logloss improved from 0.01682 to 0.01674, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0197 - logloss: 0.0165 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 23/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0196 - logloss: 0.0163\n",
      "Epoch 00023: val_logloss improved from 0.01674 to 0.01666, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0195 - logloss: 0.0164 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 24/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00024: val_logloss improved from 0.01666 to 0.01664, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0193 - logloss: 0.0161 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 25/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0191 - logloss: 0.0159\n",
      "Epoch 00025: val_logloss improved from 0.01664 to 0.01663, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0191 - logloss: 0.0159 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 26/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0189 - logloss: 0.0157\n",
      "Epoch 00026: val_logloss improved from 0.01663 to 0.01648, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0189 - logloss: 0.0157 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 27/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0188 - logloss: 0.0155\n",
      "Epoch 00027: val_logloss improved from 0.01648 to 0.01645, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0188 - logloss: 0.0156 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 28/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0186 - logloss: 0.0153\n",
      "Epoch 00028: val_logloss did not improve from 0.01645\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 29/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0189 - logloss: 0.0156\n",
      "Epoch 00029: val_logloss did not improve from 0.01645\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0189 - logloss: 0.0155 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 30/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0181 - logloss: 0.0149\n",
      "Epoch 00030: val_logloss improved from 0.01645 to 0.01642, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0182 - logloss: 0.0149 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 31/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0181 - logloss: 0.0148\n",
      "Epoch 00031: val_logloss improved from 0.01642 to 0.01638, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0181 - logloss: 0.0148 - val_loss: 0.0196 - val_logloss: 0.0164\n",
      "Epoch 32/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0180 - logloss: 0.0147\n",
      "Epoch 00032: val_logloss improved from 0.01638 to 0.01635, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0180 - logloss: 0.0147 - val_loss: 0.0196 - val_logloss: 0.0164\n",
      "Epoch 33/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0179 - logloss: 0.0146\n",
      "Epoch 00033: val_logloss improved from 0.01635 to 0.01633, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0179 - logloss: 0.0146 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 34/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0178 - logloss: 0.0145\n",
      "Epoch 00034: val_logloss improved from 0.01633 to 0.01633, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0178 - logloss: 0.0145 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 35/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0177 - logloss: 0.0144\n",
      "Epoch 00035: val_logloss improved from 0.01633 to 0.01632, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0177 - logloss: 0.0145 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 36/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0177 - logloss: 0.0145\n",
      "Epoch 00036: val_logloss did not improve from 0.01632\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0177 - logloss: 0.0145 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 37/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0177 - logloss: 0.0145\n",
      "Epoch 00037: val_logloss did not improve from 0.01632\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0178 - logloss: 0.0145 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 38/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0177 - logloss: 0.0145\n",
      "Epoch 00038: val_logloss did not improve from 0.01632\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0177 - logloss: 0.0145 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 39/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0177 - logloss: 0.0144\n",
      "Epoch 00039: val_logloss did not improve from 0.01632\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0177 - logloss: 0.0144 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 40/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0177 - logloss: 0.0144\n",
      "Epoch 00040: val_logloss improved from 0.01632 to 0.01632, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0177 - logloss: 0.0144 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Fold 3 log loss: 0.01615376901156271\n",
      "Fold 4\n",
      "Epoch 1/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.4761 - logloss: 0.4734\n",
      "Epoch 00001: val_logloss improved from inf to 0.10808, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.4761 - logloss: 0.4734 - val_loss: 0.1092 - val_logloss: 0.1081\n",
      "Epoch 2/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0564 - logloss: 0.0545\n",
      "Epoch 00002: val_logloss improved from 0.10808 to 0.02838, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0562 - logloss: 0.0542 - val_loss: 0.0306 - val_logloss: 0.0284\n",
      "Epoch 3/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0295 - logloss: 0.0270\n",
      "Epoch 00003: val_logloss improved from 0.02838 to 0.02324, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0295 - logloss: 0.0270 - val_loss: 0.0259 - val_logloss: 0.0232\n",
      "Epoch 4/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0256 - logloss: 0.0228\n",
      "Epoch 00004: val_logloss improved from 0.02324 to 0.02058, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0256 - logloss: 0.0228 - val_loss: 0.0234 - val_logloss: 0.0206\n",
      "Epoch 5/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0243 - logloss: 0.0214\n",
      "Epoch 00005: val_logloss improved from 0.02058 to 0.01991, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0243 - logloss: 0.0214 - val_loss: 0.0228 - val_logloss: 0.0199\n",
      "Epoch 6/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0235 - logloss: 0.0205\n",
      "Epoch 00006: val_logloss improved from 0.01991 to 0.01907, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0235 - logloss: 0.0204 - val_loss: 0.0222 - val_logloss: 0.0191\n",
      "Epoch 7/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0230 - logloss: 0.0199\n",
      "Epoch 00007: val_logloss improved from 0.01907 to 0.01869, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0230 - logloss: 0.0199 - val_loss: 0.0218 - val_logloss: 0.0187\n",
      "Epoch 8/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0225 - logloss: 0.0193\n",
      "Epoch 00008: val_logloss improved from 0.01869 to 0.01826, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0225 - logloss: 0.0194 - val_loss: 0.0214 - val_logloss: 0.0183\n",
      "Epoch 9/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0223 - logloss: 0.0191\n",
      "Epoch 00009: val_logloss did not improve from 0.01826\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0224 - logloss: 0.0192 - val_loss: 0.0217 - val_logloss: 0.0186\n",
      "Epoch 10/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0222 - logloss: 0.0189\n",
      "Epoch 00010: val_logloss improved from 0.01826 to 0.01784, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0222 - logloss: 0.0190 - val_loss: 0.0211 - val_logloss: 0.0178\n",
      "Epoch 11/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0217 - logloss: 0.0185\n",
      "Epoch 00011: val_logloss improved from 0.01784 to 0.01763, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0217 - logloss: 0.0185 - val_loss: 0.0209 - val_logloss: 0.0176\n",
      "Epoch 12/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0213 - logloss: 0.0181\n",
      "Epoch 00012: val_logloss improved from 0.01763 to 0.01751, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0214 - logloss: 0.0182 - val_loss: 0.0207 - val_logloss: 0.0175\n",
      "Epoch 13/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0211 - logloss: 0.0179\n",
      "Epoch 00013: val_logloss improved from 0.01751 to 0.01729, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0211 - logloss: 0.0179 - val_loss: 0.0205 - val_logloss: 0.0173\n",
      "Epoch 14/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0211 - logloss: 0.0179\n",
      "Epoch 00014: val_logloss did not improve from 0.01729\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0211 - logloss: 0.0179 - val_loss: 0.0208 - val_logloss: 0.0175\n",
      "Epoch 15/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0208 - logloss: 0.0176\n",
      "Epoch 00015: val_logloss improved from 0.01729 to 0.01713, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0208 - logloss: 0.0176 - val_loss: 0.0204 - val_logloss: 0.0171\n",
      "Epoch 16/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0208 - logloss: 0.0175\n",
      "Epoch 00016: val_logloss improved from 0.01713 to 0.01711, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0208 - logloss: 0.0175 - val_loss: 0.0203 - val_logloss: 0.0171\n",
      "Epoch 17/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0205 - logloss: 0.0173\n",
      "Epoch 00017: val_logloss improved from 0.01711 to 0.01694, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0205 - logloss: 0.0173 - val_loss: 0.0202 - val_logloss: 0.0169\n",
      "Epoch 18/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0205 - logloss: 0.0172\n",
      "Epoch 00018: val_logloss improved from 0.01694 to 0.01687, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0205 - logloss: 0.0173 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 19/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0203 - logloss: 0.0170\n",
      "Epoch 00019: val_logloss improved from 0.01687 to 0.01681, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0203 - logloss: 0.0170 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 20/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0201 - logloss: 0.0169\n",
      "Epoch 00020: val_logloss did not improve from 0.01681\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0201 - logloss: 0.0169 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 21/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0199 - logloss: 0.0166\n",
      "Epoch 00021: val_logloss improved from 0.01681 to 0.01669, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0198 - logloss: 0.0166 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 22/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0197 - logloss: 0.0164\n",
      "Epoch 00022: val_logloss improved from 0.01669 to 0.01662, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0197 - logloss: 0.0165 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 23/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0195 - logloss: 0.0162\n",
      "Epoch 00023: val_logloss improved from 0.01662 to 0.01655, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0195 - logloss: 0.0163 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 24/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00024: val_logloss improved from 0.01655 to 0.01652, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0194 - logloss: 0.0161 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 25/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0192 - logloss: 0.0159\n",
      "Epoch 00025: val_logloss improved from 0.01652 to 0.01647, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0192 - logloss: 0.0160 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 26/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0192 - logloss: 0.0159\n",
      "Epoch 00026: val_logloss did not improve from 0.01647\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0192 - logloss: 0.0159 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 27/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0188 - logloss: 0.0155\n",
      "Epoch 00027: val_logloss improved from 0.01647 to 0.01641, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0188 - logloss: 0.0155 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 28/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0188 - logloss: 0.0155\n",
      "Epoch 00028: val_logloss improved from 0.01641 to 0.01637, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0188 - logloss: 0.0155 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 29/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00029: val_logloss improved from 0.01637 to 0.01635, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0197 - val_logloss: 0.0163\n",
      "Epoch 30/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0185 - logloss: 0.0152\n",
      "Epoch 00030: val_logloss improved from 0.01635 to 0.01632, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 31/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0184 - logloss: 0.0152\n",
      "Epoch 00031: val_logloss improved from 0.01632 to 0.01632, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0184 - logloss: 0.0152 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 32/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0152\n",
      "Epoch 00032: val_logloss improved from 0.01632 to 0.01631, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0184 - logloss: 0.0151 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 33/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0184 - logloss: 0.0152\n",
      "Epoch 00033: val_logloss improved from 0.01631 to 0.01631, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0184 - logloss: 0.0152 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 34/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0184 - logloss: 0.0152\n",
      "Epoch 00034: val_logloss did not improve from 0.01631\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0184 - logloss: 0.0152 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 35/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0183 - logloss: 0.0151\n",
      "Epoch 00035: val_logloss improved from 0.01631 to 0.01630, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0183 - logloss: 0.0151 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 36/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0184 - logloss: 0.0151\n",
      "Epoch 00036: val_logloss improved from 0.01630 to 0.01630, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0184 - logloss: 0.0151 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 37/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0183 - logloss: 0.0150\n",
      "Epoch 00037: val_logloss improved from 0.01630 to 0.01630, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0183 - logloss: 0.0151 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 38/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0183 - logloss: 0.0151\n",
      "Epoch 00038: val_logloss did not improve from 0.01630\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0183 - logloss: 0.0151 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 39/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0183 - logloss: 0.0151\n",
      "Epoch 00039: val_logloss improved from 0.01630 to 0.01630, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0183 - logloss: 0.0150 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 40/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0183 - logloss: 0.0151\n",
      "Epoch 00040: val_logloss improved from 0.01630 to 0.01630, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0183 - logloss: 0.0151 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Fold 4 log loss: 0.016188936295008883\n",
      "Fold 5\n",
      "Epoch 1/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.4889 - logloss: 0.4884\n",
      "Epoch 00001: val_logloss improved from inf to 0.10866, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.4779 - logloss: 0.4753 - val_loss: 0.1098 - val_logloss: 0.1087\n",
      "Epoch 2/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0558 - logloss: 0.0540\n",
      "Epoch 00002: val_logloss improved from 0.10866 to 0.02907, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0551 - logloss: 0.0531 - val_loss: 0.0312 - val_logloss: 0.0291\n",
      "Epoch 3/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0303 - logloss: 0.0277\n",
      "Epoch 00003: val_logloss improved from 0.02907 to 0.02352, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0301 - logloss: 0.0276 - val_loss: 0.0261 - val_logloss: 0.0235\n",
      "Epoch 4/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0256 - logloss: 0.0228\n",
      "Epoch 00004: val_logloss improved from 0.02352 to 0.02094, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0256 - logloss: 0.0228 - val_loss: 0.0237 - val_logloss: 0.0209\n",
      "Epoch 5/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0245 - logloss: 0.0216\n",
      "Epoch 00005: val_logloss improved from 0.02094 to 0.02045, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0245 - logloss: 0.0216 - val_loss: 0.0233 - val_logloss: 0.0205\n",
      "Epoch 6/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0235 - logloss: 0.0204\n",
      "Epoch 00006: val_logloss improved from 0.02045 to 0.01933, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0235 - logloss: 0.0204 - val_loss: 0.0223 - val_logloss: 0.0193\n",
      "Epoch 7/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0228 - logloss: 0.0197\n",
      "Epoch 00007: val_logloss improved from 0.01933 to 0.01898, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0228 - logloss: 0.0198 - val_loss: 0.0220 - val_logloss: 0.0190\n",
      "Epoch 8/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0224 - logloss: 0.0193\n",
      "Epoch 00008: val_logloss improved from 0.01898 to 0.01866, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0224 - logloss: 0.0193 - val_loss: 0.0217 - val_logloss: 0.0187\n",
      "Epoch 9/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0225 - logloss: 0.0193\n",
      "Epoch 00009: val_logloss improved from 0.01866 to 0.01842, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0225 - logloss: 0.0193 - val_loss: 0.0215 - val_logloss: 0.0184\n",
      "Epoch 10/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0222 - logloss: 0.0191\n",
      "Epoch 00010: val_logloss improved from 0.01842 to 0.01842, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0222 - logloss: 0.0191 - val_loss: 0.0216 - val_logloss: 0.0184\n",
      "Epoch 11/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0222 - logloss: 0.0189\n",
      "Epoch 00011: val_logloss improved from 0.01842 to 0.01806, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0222 - logloss: 0.0189 - val_loss: 0.0212 - val_logloss: 0.0181\n",
      "Epoch 12/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0216 - logloss: 0.0184\n",
      "Epoch 00012: val_logloss improved from 0.01806 to 0.01787, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0216 - logloss: 0.0183 - val_loss: 0.0210 - val_logloss: 0.0179\n",
      "Epoch 13/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0213 - logloss: 0.0182\n",
      "Epoch 00013: val_logloss improved from 0.01787 to 0.01781, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0213 - logloss: 0.0182 - val_loss: 0.0209 - val_logloss: 0.0178\n",
      "Epoch 14/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0213 - logloss: 0.0181\n",
      "Epoch 00014: val_logloss improved from 0.01781 to 0.01771, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0213 - logloss: 0.0181 - val_loss: 0.0208 - val_logloss: 0.0177\n",
      "Epoch 15/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0210 - logloss: 0.0177\n",
      "Epoch 00015: val_logloss improved from 0.01771 to 0.01757, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0210 - logloss: 0.0178 - val_loss: 0.0207 - val_logloss: 0.0176\n",
      "Epoch 16/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0208 - logloss: 0.0176\n",
      "Epoch 00016: val_logloss improved from 0.01757 to 0.01737, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0208 - logloss: 0.0176 - val_loss: 0.0205 - val_logloss: 0.0174\n",
      "Epoch 17/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0207 - logloss: 0.0174\n",
      "Epoch 00017: val_logloss improved from 0.01737 to 0.01732, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0206 - logloss: 0.0174 - val_loss: 0.0205 - val_logloss: 0.0173\n",
      "Epoch 18/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0204 - logloss: 0.0172\n",
      "Epoch 00018: val_logloss improved from 0.01732 to 0.01727, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0204 - logloss: 0.0172 - val_loss: 0.0205 - val_logloss: 0.0173\n",
      "Epoch 19/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0202 - logloss: 0.0170\n",
      "Epoch 00019: val_logloss improved from 0.01727 to 0.01724, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0202 - logloss: 0.0170 - val_loss: 0.0204 - val_logloss: 0.0172\n",
      "Epoch 20/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0201 - logloss: 0.0168\n",
      "Epoch 00020: val_logloss improved from 0.01724 to 0.01706, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0201 - logloss: 0.0169 - val_loss: 0.0202 - val_logloss: 0.0171\n",
      "Epoch 21/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0199 - logloss: 0.0167\n",
      "Epoch 00021: val_logloss improved from 0.01706 to 0.01700, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0199 - logloss: 0.0168 - val_loss: 0.0201 - val_logloss: 0.0170\n",
      "Epoch 22/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0198 - logloss: 0.0166\n",
      "Epoch 00022: val_logloss improved from 0.01700 to 0.01693, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0198 - logloss: 0.0166 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 23/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0197 - logloss: 0.0164\n",
      "Epoch 00023: val_logloss did not improve from 0.01693\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0197 - logloss: 0.0164 - val_loss: 0.0201 - val_logloss: 0.0170\n",
      "Epoch 24/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0194 - logloss: 0.0162\n",
      "Epoch 00024: val_logloss improved from 0.01693 to 0.01689, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 25/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00025: val_logloss improved from 0.01689 to 0.01683, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0193 - logloss: 0.0161 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 26/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0190 - logloss: 0.0158\n",
      "Epoch 00026: val_logloss improved from 0.01683 to 0.01676, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0190 - logloss: 0.0157 - val_loss: 0.0199 - val_logloss: 0.0168\n",
      "Epoch 27/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0188 - logloss: 0.0155\n",
      "Epoch 00027: val_logloss improved from 0.01676 to 0.01672, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0188 - logloss: 0.0156 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 28/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0187 - logloss: 0.0155\n",
      "Epoch 00028: val_logloss improved from 0.01672 to 0.01670, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0187 - logloss: 0.0155 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 29/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0186 - logloss: 0.0154\n",
      "Epoch 00029: val_logloss improved from 0.01670 to 0.01668, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0187 - logloss: 0.0155 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 30/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0187 - logloss: 0.0154\n",
      "Epoch 00030: val_logloss did not improve from 0.01668\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 31/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0186 - logloss: 0.0154\n",
      "Epoch 00031: val_logloss improved from 0.01668 to 0.01668, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 32/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0187 - logloss: 0.0154\n",
      "Epoch 00032: val_logloss did not improve from 0.01668\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 33/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0186 - logloss: 0.0154\n",
      "Epoch 00033: val_logloss improved from 0.01668 to 0.01668, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 34/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0186 - logloss: 0.0154\n",
      "Epoch 00034: val_logloss improved from 0.01668 to 0.01667, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 35/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0186 - logloss: 0.0154\n",
      "Epoch 00035: val_logloss improved from 0.01667 to 0.01667, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 36/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0186 - logloss: 0.0154\n",
      "Epoch 00036: val_logloss did not improve from 0.01667\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 37/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00037: val_logloss improved from 0.01667 to 0.01667, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 38/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00038: val_logloss improved from 0.01667 to 0.01667, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 39/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00039: val_logloss improved from 0.01667 to 0.01666, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 40/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0186 - logloss: 0.0154\n",
      "Epoch 00040: val_logloss improved from 0.01666 to 0.01666, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Fold 5 log loss: 0.016495648324555405\n",
      "Seed 0\n",
      "Fold 1 log loss: 0.016453102652094397\n",
      "Fold 2 log loss: 0.016405001898573676\n",
      "Fold 3 log loss: 0.01615376901156271\n",
      "Fold 4 log loss: 0.016188936295008883\n",
      "Fold 5 log loss: 0.016495648324555405\n",
      "Std of log loss: 0.00014053011975417005\n",
      "Total log loss: 0.016339281518491764\n",
      "Fold 1\n",
      "Epoch 1/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.4941 - logloss: 0.4936\n",
      "Epoch 00001: val_logloss improved from inf to 0.10973, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.4829 - logloss: 0.4803 - val_loss: 0.1113 - val_logloss: 0.1097\n",
      "Epoch 2/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0556 - logloss: 0.0537\n",
      "Epoch 00002: val_logloss improved from 0.10973 to 0.02922, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0555 - logloss: 0.0536 - val_loss: 0.0317 - val_logloss: 0.0292\n",
      "Epoch 3/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0291 - logloss: 0.0266\n",
      "Epoch 00003: val_logloss improved from 0.02922 to 0.02316, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0290 - logloss: 0.0266 - val_loss: 0.0259 - val_logloss: 0.0232\n",
      "Epoch 4/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0261 - logloss: 0.0233\n",
      "Epoch 00004: val_logloss improved from 0.02316 to 0.02174, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0260 - logloss: 0.0232 - val_loss: 0.0247 - val_logloss: 0.0217\n",
      "Epoch 5/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0241 - logloss: 0.0212\n",
      "Epoch 00005: val_logloss improved from 0.02174 to 0.01976, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 0.0241 - logloss: 0.0212 - val_loss: 0.0227 - val_logloss: 0.0198\n",
      "Epoch 6/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0235 - logloss: 0.0204\n",
      "Epoch 00006: val_logloss improved from 0.01976 to 0.01933, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0235 - logloss: 0.0204 - val_loss: 0.0224 - val_logloss: 0.0193\n",
      "Epoch 7/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0228 - logloss: 0.0198\n",
      "Epoch 00007: val_logloss improved from 0.01933 to 0.01887, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0228 - logloss: 0.0198 - val_loss: 0.0220 - val_logloss: 0.0189\n",
      "Epoch 8/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0225 - logloss: 0.0193\n",
      "Epoch 00008: val_logloss improved from 0.01887 to 0.01876, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0224 - logloss: 0.0193 - val_loss: 0.0220 - val_logloss: 0.0188\n",
      "Epoch 9/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0221 - logloss: 0.0190\n",
      "Epoch 00009: val_logloss improved from 0.01876 to 0.01832, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0221 - logloss: 0.0190 - val_loss: 0.0215 - val_logloss: 0.0183\n",
      "Epoch 10/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0218 - logloss: 0.0187\n",
      "Epoch 00010: val_logloss improved from 0.01832 to 0.01818, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0218 - logloss: 0.0186 - val_loss: 0.0214 - val_logloss: 0.0182\n",
      "Epoch 11/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0217 - logloss: 0.0185\n",
      "Epoch 00011: val_logloss improved from 0.01818 to 0.01804, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0217 - logloss: 0.0185 - val_loss: 0.0214 - val_logloss: 0.0180\n",
      "Epoch 12/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0215 - logloss: 0.0183\n",
      "Epoch 00012: val_logloss improved from 0.01804 to 0.01785, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0215 - logloss: 0.0183 - val_loss: 0.0211 - val_logloss: 0.0179\n",
      "Epoch 13/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0213 - logloss: 0.0181\n",
      "Epoch 00013: val_logloss improved from 0.01785 to 0.01765, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0213 - logloss: 0.0180 - val_loss: 0.0210 - val_logloss: 0.0177\n",
      "Epoch 14/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0210 - logloss: 0.0178\n",
      "Epoch 00014: val_logloss improved from 0.01765 to 0.01745, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0210 - logloss: 0.0178 - val_loss: 0.0207 - val_logloss: 0.0175\n",
      "Epoch 15/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0207 - logloss: 0.0175\n",
      "Epoch 00015: val_logloss improved from 0.01745 to 0.01734, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0207 - logloss: 0.0175 - val_loss: 0.0206 - val_logloss: 0.0173\n",
      "Epoch 16/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0205 - logloss: 0.0173\n",
      "Epoch 00016: val_logloss improved from 0.01734 to 0.01723, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0205 - logloss: 0.0173 - val_loss: 0.0205 - val_logloss: 0.0172\n",
      "Epoch 17/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0204 - logloss: 0.0172\n",
      "Epoch 00017: val_logloss did not improve from 0.01723\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0204 - logloss: 0.0172 - val_loss: 0.0205 - val_logloss: 0.0173\n",
      "Epoch 18/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0202 - logloss: 0.0170\n",
      "Epoch 00018: val_logloss did not improve from 0.01723\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0203 - logloss: 0.0171 - val_loss: 0.0207 - val_logloss: 0.0173\n",
      "Epoch 19/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0201 - logloss: 0.0169\n",
      "Epoch 00019: val_logloss improved from 0.01723 to 0.01700, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0201 - logloss: 0.0169 - val_loss: 0.0203 - val_logloss: 0.0170\n",
      "Epoch 20/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0200 - logloss: 0.0168\n",
      "Epoch 00020: val_logloss did not improve from 0.01700\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0200 - logloss: 0.0168 - val_loss: 0.0205 - val_logloss: 0.0173\n",
      "Epoch 21/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0199 - logloss: 0.0166\n",
      "Epoch 00021: val_logloss improved from 0.01700 to 0.01692, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0199 - logloss: 0.0167 - val_loss: 0.0203 - val_logloss: 0.0169\n",
      "Epoch 22/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0198 - logloss: 0.0165\n",
      "Epoch 00022: val_logloss improved from 0.01692 to 0.01684, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0198 - logloss: 0.0165 - val_loss: 0.0202 - val_logloss: 0.0168\n",
      "Epoch 23/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0195 - logloss: 0.0162\n",
      "Epoch 00023: val_logloss did not improve from 0.01684\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0195 - logloss: 0.0162 - val_loss: 0.0205 - val_logloss: 0.0169\n",
      "Epoch 24/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00024: val_logloss improved from 0.01684 to 0.01676, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0194 - logloss: 0.0161 - val_loss: 0.0202 - val_logloss: 0.0168\n",
      "Epoch 25/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0192 - logloss: 0.0160\n",
      "Epoch 00025: val_logloss improved from 0.01676 to 0.01672, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0192 - logloss: 0.0160 - val_loss: 0.0200 - val_logloss: 0.0167\n",
      "Epoch 26/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0190 - logloss: 0.0158\n",
      "Epoch 00026: val_logloss improved from 0.01672 to 0.01671, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0190 - logloss: 0.0157 - val_loss: 0.0201 - val_logloss: 0.0167\n",
      "Epoch 27/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0189 - logloss: 0.0156\n",
      "Epoch 00027: val_logloss did not improve from 0.01671\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0189 - logloss: 0.0156 - val_loss: 0.0202 - val_logloss: 0.0168\n",
      "Epoch 28/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0188 - logloss: 0.0155\n",
      "Epoch 00028: val_logloss improved from 0.01671 to 0.01662, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0188 - logloss: 0.0155 - val_loss: 0.0200 - val_logloss: 0.0166\n",
      "Epoch 29/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00029: val_logloss did not improve from 0.01662\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0185 - logloss: 0.0152 - val_loss: 0.0200 - val_logloss: 0.0166\n",
      "Epoch 30/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0182 - logloss: 0.0150\n",
      "Epoch 00030: val_logloss improved from 0.01662 to 0.01657, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0183 - logloss: 0.0150 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 31/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0181 - logloss: 0.0148\n",
      "Epoch 00031: val_logloss improved from 0.01657 to 0.01657, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0181 - logloss: 0.0149 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 32/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0177 - logloss: 0.0144\n",
      "Epoch 00032: val_logloss improved from 0.01657 to 0.01649, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0177 - logloss: 0.0144 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 33/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0176 - logloss: 0.0143\n",
      "Epoch 00033: val_logloss improved from 0.01649 to 0.01647, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0176 - logloss: 0.0143 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 34/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0174 - logloss: 0.0142\n",
      "Epoch 00034: val_logloss improved from 0.01647 to 0.01646, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0174 - logloss: 0.0142 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 35/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0174 - logloss: 0.0141\n",
      "Epoch 00035: val_logloss improved from 0.01646 to 0.01643, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0174 - logloss: 0.0141 - val_loss: 0.0198 - val_logloss: 0.0164\n",
      "Epoch 36/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0173 - logloss: 0.0140\n",
      "Epoch 00036: val_logloss did not improve from 0.01643\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0173 - logloss: 0.0140 - val_loss: 0.0198 - val_logloss: 0.0164\n",
      "Epoch 37/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0173 - logloss: 0.0140\n",
      "Epoch 00037: val_logloss improved from 0.01643 to 0.01643, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0173 - logloss: 0.0141 - val_loss: 0.0198 - val_logloss: 0.0164\n",
      "Epoch 38/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0173 - logloss: 0.0140\n",
      "Epoch 00038: val_logloss improved from 0.01643 to 0.01643, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0173 - logloss: 0.0140 - val_loss: 0.0198 - val_logloss: 0.0164\n",
      "Epoch 39/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0173 - logloss: 0.0140\n",
      "Epoch 00039: val_logloss did not improve from 0.01643\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0173 - logloss: 0.0140 - val_loss: 0.0198 - val_logloss: 0.0164\n",
      "Epoch 40/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0172 - logloss: 0.0140\n",
      "Epoch 00040: val_logloss improved from 0.01643 to 0.01643, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0173 - logloss: 0.0140 - val_loss: 0.0198 - val_logloss: 0.0164\n",
      "Fold 1 log loss: 0.016353566543988285\n",
      "Fold 2\n",
      "Epoch 1/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.4859 - logloss: 0.4854\n",
      "Epoch 00001: val_logloss improved from inf to 0.10671, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.4776 - logloss: 0.4750 - val_loss: 0.1081 - val_logloss: 0.1067\n",
      "Epoch 2/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0558 - logloss: 0.0540\n",
      "Epoch 00002: val_logloss improved from 0.10671 to 0.02825, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0553 - logloss: 0.0534 - val_loss: 0.0305 - val_logloss: 0.0283\n",
      "Epoch 3/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0292 - logloss: 0.0268\n",
      "Epoch 00003: val_logloss improved from 0.02825 to 0.02262, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0292 - logloss: 0.0268 - val_loss: 0.0253 - val_logloss: 0.0226\n",
      "Epoch 4/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0257 - logloss: 0.0229\n",
      "Epoch 00004: val_logloss improved from 0.02262 to 0.02069, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0257 - logloss: 0.0229 - val_loss: 0.0235 - val_logloss: 0.0207\n",
      "Epoch 5/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0242 - logloss: 0.0212\n",
      "Epoch 00005: val_logloss improved from 0.02069 to 0.01981, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0242 - logloss: 0.0212 - val_loss: 0.0228 - val_logloss: 0.0198\n",
      "Epoch 6/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0235 - logloss: 0.0205\n",
      "Epoch 00006: val_logloss improved from 0.01981 to 0.01951, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0235 - logloss: 0.0205 - val_loss: 0.0225 - val_logloss: 0.0195\n",
      "Epoch 7/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0230 - logloss: 0.0199\n",
      "Epoch 00007: val_logloss improved from 0.01951 to 0.01894, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0230 - logloss: 0.0200 - val_loss: 0.0220 - val_logloss: 0.0189\n",
      "Epoch 8/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0227 - logloss: 0.0195\n",
      "Epoch 00008: val_logloss improved from 0.01894 to 0.01853, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0227 - logloss: 0.0195 - val_loss: 0.0217 - val_logloss: 0.0185\n",
      "Epoch 9/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0222 - logloss: 0.0190\n",
      "Epoch 00009: val_logloss improved from 0.01853 to 0.01829, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0222 - logloss: 0.0191 - val_loss: 0.0215 - val_logloss: 0.0183\n",
      "Epoch 10/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0219 - logloss: 0.0187\n",
      "Epoch 00010: val_logloss improved from 0.01829 to 0.01806, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0219 - logloss: 0.0187 - val_loss: 0.0212 - val_logloss: 0.0181\n",
      "Epoch 11/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0216 - logloss: 0.0184\n",
      "Epoch 00011: val_logloss improved from 0.01806 to 0.01779, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0216 - logloss: 0.0184 - val_loss: 0.0209 - val_logloss: 0.0178\n",
      "Epoch 12/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0213 - logloss: 0.0182\n",
      "Epoch 00012: val_logloss improved from 0.01779 to 0.01760, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0213 - logloss: 0.0182 - val_loss: 0.0208 - val_logloss: 0.0176\n",
      "Epoch 13/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0213 - logloss: 0.0181\n",
      "Epoch 00013: val_logloss did not improve from 0.01760\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0213 - logloss: 0.0181 - val_loss: 0.0208 - val_logloss: 0.0176\n",
      "Epoch 14/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0210 - logloss: 0.0178\n",
      "Epoch 00014: val_logloss improved from 0.01760 to 0.01738, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0210 - logloss: 0.0178 - val_loss: 0.0206 - val_logloss: 0.0174\n",
      "Epoch 15/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0208 - logloss: 0.0176\n",
      "Epoch 00015: val_logloss improved from 0.01738 to 0.01735, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0207 - logloss: 0.0175 - val_loss: 0.0206 - val_logloss: 0.0173\n",
      "Epoch 16/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0206 - logloss: 0.0174\n",
      "Epoch 00016: val_logloss improved from 0.01735 to 0.01716, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0206 - logloss: 0.0174 - val_loss: 0.0203 - val_logloss: 0.0172\n",
      "Epoch 17/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0205 - logloss: 0.0172\n",
      "Epoch 00017: val_logloss improved from 0.01716 to 0.01712, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0205 - logloss: 0.0172 - val_loss: 0.0204 - val_logloss: 0.0171\n",
      "Epoch 18/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0202 - logloss: 0.0170\n",
      "Epoch 00018: val_logloss improved from 0.01712 to 0.01699, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0202 - logloss: 0.0170 - val_loss: 0.0202 - val_logloss: 0.0170\n",
      "Epoch 19/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0200 - logloss: 0.0168\n",
      "Epoch 00019: val_logloss improved from 0.01699 to 0.01688, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0200 - logloss: 0.0168 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 20/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0198 - logloss: 0.0166\n",
      "Epoch 00020: val_logloss improved from 0.01688 to 0.01688, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0198 - logloss: 0.0166 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 21/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0197 - logloss: 0.0165\n",
      "Epoch 00021: val_logloss improved from 0.01688 to 0.01687, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0197 - logloss: 0.0165 - val_loss: 0.0202 - val_logloss: 0.0169\n",
      "Epoch 22/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0196 - logloss: 0.0164\n",
      "Epoch 00022: val_logloss improved from 0.01687 to 0.01684, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0196 - logloss: 0.0164 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 23/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0191 - logloss: 0.0159\n",
      "Epoch 00023: val_logloss improved from 0.01684 to 0.01670, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0192 - logloss: 0.0160 - val_loss: 0.0200 - val_logloss: 0.0167\n",
      "Epoch 24/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0191 - logloss: 0.0158\n",
      "Epoch 00024: val_logloss improved from 0.01670 to 0.01665, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0191 - logloss: 0.0159 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 25/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0191 - logloss: 0.0158\n",
      "Epoch 00025: val_logloss improved from 0.01665 to 0.01663, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0191 - logloss: 0.0158 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 26/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0189 - logloss: 0.0157\n",
      "Epoch 00026: val_logloss improved from 0.01663 to 0.01660, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0189 - logloss: 0.0157 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 27/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0189 - logloss: 0.0157\n",
      "Epoch 00027: val_logloss improved from 0.01660 to 0.01660, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0189 - logloss: 0.0157 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 28/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0189 - logloss: 0.0156\n",
      "Epoch 00028: val_logloss improved from 0.01660 to 0.01660, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0189 - logloss: 0.0156 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 29/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0189 - logloss: 0.0157\n",
      "Epoch 00029: val_logloss improved from 0.01660 to 0.01659, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0189 - logloss: 0.0157 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 30/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0189 - logloss: 0.0157\n",
      "Epoch 00030: val_logloss improved from 0.01659 to 0.01659, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0189 - logloss: 0.0157 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 31/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0189 - logloss: 0.0156\n",
      "Epoch 00031: val_logloss improved from 0.01659 to 0.01659, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0189 - logloss: 0.0157 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 32/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0189 - logloss: 0.0156\n",
      "Epoch 00032: val_logloss improved from 0.01659 to 0.01659, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0189 - logloss: 0.0157 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 33/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0189 - logloss: 0.0157\n",
      "Epoch 00033: val_logloss improved from 0.01659 to 0.01658, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0189 - logloss: 0.0157 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 34/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0189 - logloss: 0.0156\n",
      "Epoch 00034: val_logloss improved from 0.01658 to 0.01658, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0189 - logloss: 0.0156 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 35/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0188 - logloss: 0.0156\n",
      "Epoch 00035: val_logloss improved from 0.01658 to 0.01658, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0188 - logloss: 0.0156 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 36/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0189 - logloss: 0.0156\n",
      "Epoch 00036: val_logloss did not improve from 0.01658\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0189 - logloss: 0.0156 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 37/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0188 - logloss: 0.0156\n",
      "Epoch 00037: val_logloss improved from 0.01658 to 0.01658, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0188 - logloss: 0.0156 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 38/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0188 - logloss: 0.0156\n",
      "Epoch 00038: val_logloss did not improve from 0.01658\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0188 - logloss: 0.0156 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 39/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0188 - logloss: 0.0156\n",
      "Epoch 00039: val_logloss improved from 0.01658 to 0.01657, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0188 - logloss: 0.0156 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 40/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0188 - logloss: 0.0156\n",
      "Epoch 00040: val_logloss improved from 0.01657 to 0.01657, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0188 - logloss: 0.0156 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Fold 2 log loss: 0.016466788356703628\n",
      "Fold 3\n",
      "Epoch 1/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.4864 - logloss: 0.4859\n",
      "Epoch 00001: val_logloss improved from inf to 0.10187, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 18ms/step - loss: 0.4780 - logloss: 0.4753 - val_loss: 0.1031 - val_logloss: 0.1019\n",
      "Epoch 2/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0555 - logloss: 0.0537\n",
      "Epoch 00002: val_logloss improved from 0.10187 to 0.02935, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0550 - logloss: 0.0531 - val_loss: 0.0316 - val_logloss: 0.0293\n",
      "Epoch 3/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0297 - logloss: 0.0273\n",
      "Epoch 00003: val_logloss improved from 0.02935 to 0.02298, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0296 - logloss: 0.0272 - val_loss: 0.0256 - val_logloss: 0.0230\n",
      "Epoch 4/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0256 - logloss: 0.0229\n",
      "Epoch 00004: val_logloss improved from 0.02298 to 0.02099, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0256 - logloss: 0.0228 - val_loss: 0.0238 - val_logloss: 0.0210\n",
      "Epoch 5/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0243 - logloss: 0.0214\n",
      "Epoch 00005: val_logloss improved from 0.02099 to 0.02000, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0244 - logloss: 0.0215 - val_loss: 0.0229 - val_logloss: 0.0200\n",
      "Epoch 6/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0236 - logloss: 0.0205\n",
      "Epoch 00006: val_logloss improved from 0.02000 to 0.01974, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0236 - logloss: 0.0205 - val_loss: 0.0227 - val_logloss: 0.0197\n",
      "Epoch 7/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0229 - logloss: 0.0198\n",
      "Epoch 00007: val_logloss improved from 0.01974 to 0.01884, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0229 - logloss: 0.0199 - val_loss: 0.0219 - val_logloss: 0.0188\n",
      "Epoch 8/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0224 - logloss: 0.0193\n",
      "Epoch 00008: val_logloss improved from 0.01884 to 0.01852, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0224 - logloss: 0.0194 - val_loss: 0.0216 - val_logloss: 0.0185\n",
      "Epoch 9/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0223 - logloss: 0.0191\n",
      "Epoch 00009: val_logloss improved from 0.01852 to 0.01832, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0223 - logloss: 0.0191 - val_loss: 0.0215 - val_logloss: 0.0183\n",
      "Epoch 10/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0220 - logloss: 0.0188\n",
      "Epoch 00010: val_logloss improved from 0.01832 to 0.01801, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0219 - logloss: 0.0188 - val_loss: 0.0211 - val_logloss: 0.0180\n",
      "Epoch 11/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0217 - logloss: 0.0185\n",
      "Epoch 00011: val_logloss improved from 0.01801 to 0.01779, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0216 - logloss: 0.0184 - val_loss: 0.0209 - val_logloss: 0.0178\n",
      "Epoch 12/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0214 - logloss: 0.0182\n",
      "Epoch 00012: val_logloss improved from 0.01779 to 0.01767, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0213 - logloss: 0.0181 - val_loss: 0.0208 - val_logloss: 0.0177\n",
      "Epoch 13/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0212 - logloss: 0.0180\n",
      "Epoch 00013: val_logloss improved from 0.01767 to 0.01742, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0212 - logloss: 0.0180 - val_loss: 0.0206 - val_logloss: 0.0174\n",
      "Epoch 14/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0209 - logloss: 0.0177\n",
      "Epoch 00014: val_logloss improved from 0.01742 to 0.01732, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0209 - logloss: 0.0177 - val_loss: 0.0205 - val_logloss: 0.0173\n",
      "Epoch 15/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0207 - logloss: 0.0175\n",
      "Epoch 00015: val_logloss improved from 0.01732 to 0.01720, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0207 - logloss: 0.0175 - val_loss: 0.0204 - val_logloss: 0.0172\n",
      "Epoch 16/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0208 - logloss: 0.0175\n",
      "Epoch 00016: val_logloss did not improve from 0.01720\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0208 - logloss: 0.0175 - val_loss: 0.0206 - val_logloss: 0.0172\n",
      "Epoch 17/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0204 - logloss: 0.0172\n",
      "Epoch 00017: val_logloss improved from 0.01720 to 0.01704, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0204 - logloss: 0.0172 - val_loss: 0.0202 - val_logloss: 0.0170\n",
      "Epoch 18/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0202 - logloss: 0.0170\n",
      "Epoch 00018: val_logloss improved from 0.01704 to 0.01699, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0202 - logloss: 0.0170 - val_loss: 0.0201 - val_logloss: 0.0170\n",
      "Epoch 19/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0202 - logloss: 0.0169\n",
      "Epoch 00019: val_logloss did not improve from 0.01699\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0202 - logloss: 0.0169 - val_loss: 0.0202 - val_logloss: 0.0170\n",
      "Epoch 20/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0199 - logloss: 0.0167\n",
      "Epoch 00020: val_logloss improved from 0.01699 to 0.01699, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0199 - logloss: 0.0167 - val_loss: 0.0203 - val_logloss: 0.0170\n",
      "Epoch 21/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0196 - logloss: 0.0163\n",
      "Epoch 00021: val_logloss improved from 0.01699 to 0.01677, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0196 - logloss: 0.0164 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 22/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0195 - logloss: 0.0163\n",
      "Epoch 00022: val_logloss improved from 0.01677 to 0.01673, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0196 - logloss: 0.0163 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 23/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0195 - logloss: 0.0163\n",
      "Epoch 00023: val_logloss did not improve from 0.01673\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0195 - logloss: 0.0163 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 24/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00024: val_logloss improved from 0.01673 to 0.01669, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0193 - logloss: 0.0162 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 25/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00025: val_logloss improved from 0.01669 to 0.01669, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 26/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0194 - logloss: 0.0161\n",
      "Epoch 00026: val_logloss improved from 0.01669 to 0.01669, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0194 - logloss: 0.0161 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 27/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0192 - logloss: 0.0160\n",
      "Epoch 00027: val_logloss improved from 0.01669 to 0.01668, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0192 - logloss: 0.0161 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 28/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0194 - logloss: 0.0162\n",
      "Epoch 00028: val_logloss did not improve from 0.01668\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0193 - logloss: 0.0161 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 29/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00029: val_logloss improved from 0.01668 to 0.01668, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0193 - logloss: 0.0161 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 30/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0192 - logloss: 0.0160\n",
      "Epoch 00030: val_logloss improved from 0.01668 to 0.01667, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0192 - logloss: 0.0160 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 31/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00031: val_logloss improved from 0.01667 to 0.01667, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0193 - logloss: 0.0161 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 32/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0192 - logloss: 0.0160\n",
      "Epoch 00032: val_logloss improved from 0.01667 to 0.01667, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0193 - logloss: 0.0160 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 33/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0192 - logloss: 0.0160\n",
      "Epoch 00033: val_logloss improved from 0.01667 to 0.01667, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0193 - logloss: 0.0161 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 34/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0192 - logloss: 0.0160\n",
      "Epoch 00034: val_logloss improved from 0.01667 to 0.01666, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0192 - logloss: 0.0160 - val_loss: 0.0198 - val_logloss: 0.0167\n",
      "Epoch 35/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0192 - logloss: 0.0160\n",
      "Epoch 00035: val_logloss improved from 0.01666 to 0.01666, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0192 - logloss: 0.0161 - val_loss: 0.0198 - val_logloss: 0.0167\n",
      "Epoch 36/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0192 - logloss: 0.0160\n",
      "Epoch 00036: val_logloss improved from 0.01666 to 0.01665, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0192 - logloss: 0.0160 - val_loss: 0.0198 - val_logloss: 0.0167\n",
      "Epoch 37/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00037: val_logloss improved from 0.01665 to 0.01665, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0192 - logloss: 0.0160 - val_loss: 0.0198 - val_logloss: 0.0167\n",
      "Epoch 38/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0192 - logloss: 0.0160\n",
      "Epoch 00038: val_logloss improved from 0.01665 to 0.01665, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0192 - logloss: 0.0161 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 39/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0192 - logloss: 0.0160\n",
      "Epoch 00039: val_logloss improved from 0.01665 to 0.01665, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0192 - logloss: 0.0160 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 40/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0191 - logloss: 0.0159\n",
      "Epoch 00040: val_logloss did not improve from 0.01665\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0192 - logloss: 0.0160 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Fold 3 log loss: 0.016508977584970583\n",
      "Fold 4\n",
      "Epoch 1/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.4878 - logloss: 0.4872\n",
      "Epoch 00001: val_logloss improved from inf to 0.10717, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.4794 - logloss: 0.4768 - val_loss: 0.1084 - val_logloss: 0.1072\n",
      "Epoch 2/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0557 - logloss: 0.0538\n",
      "Epoch 00002: val_logloss improved from 0.10717 to 0.02931, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0553 - logloss: 0.0533 - val_loss: 0.0315 - val_logloss: 0.0293\n",
      "Epoch 3/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0300 - logloss: 0.0275\n",
      "Epoch 00003: val_logloss improved from 0.02931 to 0.02411, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0299 - logloss: 0.0274 - val_loss: 0.0267 - val_logloss: 0.0241\n",
      "Epoch 4/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0257 - logloss: 0.0229\n",
      "Epoch 00004: val_logloss improved from 0.02411 to 0.02092, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0257 - logloss: 0.0229 - val_loss: 0.0238 - val_logloss: 0.0209\n",
      "Epoch 5/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0242 - logloss: 0.0213\n",
      "Epoch 00005: val_logloss improved from 0.02092 to 0.01973, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0242 - logloss: 0.0213 - val_loss: 0.0226 - val_logloss: 0.0197\n",
      "Epoch 6/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0235 - logloss: 0.0205\n",
      "Epoch 00006: val_logloss improved from 0.01973 to 0.01921, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0235 - logloss: 0.0205 - val_loss: 0.0222 - val_logloss: 0.0192\n",
      "Epoch 7/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0230 - logloss: 0.0199\n",
      "Epoch 00007: val_logloss improved from 0.01921 to 0.01870, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0231 - logloss: 0.0199 - val_loss: 0.0218 - val_logloss: 0.0187\n",
      "Epoch 8/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0227 - logloss: 0.0196\n",
      "Epoch 00008: val_logloss improved from 0.01870 to 0.01863, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0228 - logloss: 0.0196 - val_loss: 0.0217 - val_logloss: 0.0186\n",
      "Epoch 9/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0223 - logloss: 0.0191\n",
      "Epoch 00009: val_logloss improved from 0.01863 to 0.01805, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0223 - logloss: 0.0191 - val_loss: 0.0212 - val_logloss: 0.0180\n",
      "Epoch 10/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0221 - logloss: 0.0189\n",
      "Epoch 00010: val_logloss did not improve from 0.01805\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0221 - logloss: 0.0188 - val_loss: 0.0215 - val_logloss: 0.0184\n",
      "Epoch 11/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0218 - logloss: 0.0186\n",
      "Epoch 00011: val_logloss improved from 0.01805 to 0.01773, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0218 - logloss: 0.0186 - val_loss: 0.0210 - val_logloss: 0.0177\n",
      "Epoch 12/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0215 - logloss: 0.0183\n",
      "Epoch 00012: val_logloss improved from 0.01773 to 0.01762, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0215 - logloss: 0.0184 - val_loss: 0.0208 - val_logloss: 0.0176\n",
      "Epoch 13/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0215 - logloss: 0.0182\n",
      "Epoch 00013: val_logloss improved from 0.01762 to 0.01736, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0214 - logloss: 0.0182 - val_loss: 0.0206 - val_logloss: 0.0174\n",
      "Epoch 14/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0212 - logloss: 0.0180\n",
      "Epoch 00014: val_logloss improved from 0.01736 to 0.01728, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0212 - logloss: 0.0179 - val_loss: 0.0205 - val_logloss: 0.0173\n",
      "Epoch 15/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0210 - logloss: 0.0178\n",
      "Epoch 00015: val_logloss improved from 0.01728 to 0.01717, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0210 - logloss: 0.0178 - val_loss: 0.0204 - val_logloss: 0.0172\n",
      "Epoch 16/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0210 - logloss: 0.0177\n",
      "Epoch 00016: val_logloss did not improve from 0.01717\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0210 - logloss: 0.0177 - val_loss: 0.0209 - val_logloss: 0.0176\n",
      "Epoch 17/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0209 - logloss: 0.0176\n",
      "Epoch 00017: val_logloss did not improve from 0.01717\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0209 - logloss: 0.0176 - val_loss: 0.0207 - val_logloss: 0.0173\n",
      "Epoch 18/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0205 - logloss: 0.0173\n",
      "Epoch 00018: val_logloss improved from 0.01717 to 0.01696, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0205 - logloss: 0.0173 - val_loss: 0.0202 - val_logloss: 0.0170\n",
      "Epoch 19/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0203 - logloss: 0.0170\n",
      "Epoch 00019: val_logloss improved from 0.01696 to 0.01695, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0203 - logloss: 0.0171 - val_loss: 0.0202 - val_logloss: 0.0170\n",
      "Epoch 20/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0202 - logloss: 0.0169\n",
      "Epoch 00020: val_logloss improved from 0.01695 to 0.01683, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0202 - logloss: 0.0169 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 21/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0199 - logloss: 0.0167\n",
      "Epoch 00021: val_logloss improved from 0.01683 to 0.01668, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0199 - logloss: 0.0167 - val_loss: 0.0200 - val_logloss: 0.0167\n",
      "Epoch 22/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0198 - logloss: 0.0166\n",
      "Epoch 00022: val_logloss improved from 0.01668 to 0.01667, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0198 - logloss: 0.0165 - val_loss: 0.0200 - val_logloss: 0.0167\n",
      "Epoch 23/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0197 - logloss: 0.0164\n",
      "Epoch 00023: val_logloss improved from 0.01667 to 0.01665, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0196 - logloss: 0.0164 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 24/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00024: val_logloss did not improve from 0.01665\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0193 - logloss: 0.0161 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 25/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0191 - logloss: 0.0158\n",
      "Epoch 00025: val_logloss improved from 0.01665 to 0.01651, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0191 - logloss: 0.0158 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 26/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0190 - logloss: 0.0158\n",
      "Epoch 00026: val_logloss improved from 0.01651 to 0.01646, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0190 - logloss: 0.0157 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 27/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0188 - logloss: 0.0156\n",
      "Epoch 00027: val_logloss improved from 0.01646 to 0.01642, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0189 - logloss: 0.0156 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 28/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0188 - logloss: 0.0156\n",
      "Epoch 00028: val_logloss improved from 0.01642 to 0.01641, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0188 - logloss: 0.0156 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 29/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0187 - logloss: 0.0155\n",
      "Epoch 00029: val_logloss improved from 0.01641 to 0.01638, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0187 - logloss: 0.0155 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 30/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0187 - logloss: 0.0155\n",
      "Epoch 00030: val_logloss improved from 0.01638 to 0.01637, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0187 - logloss: 0.0155 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 31/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0186 - logloss: 0.0154\n",
      "Epoch 00031: val_logloss improved from 0.01637 to 0.01636, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0196 - val_logloss: 0.0164\n",
      "Epoch 32/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0186 - logloss: 0.0153\n",
      "Epoch 00032: val_logloss improved from 0.01636 to 0.01635, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0186 - logloss: 0.0153 - val_loss: 0.0196 - val_logloss: 0.0164\n",
      "Epoch 33/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00033: val_logloss improved from 0.01635 to 0.01635, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0196 - val_logloss: 0.0164\n",
      "Epoch 34/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00034: val_logloss improved from 0.01635 to 0.01635, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 35/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0152\n",
      "Epoch 00035: val_logloss improved from 0.01635 to 0.01635, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0185 - logloss: 0.0152 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 36/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00036: val_logloss did not improve from 0.01635\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 37/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00037: val_logloss improved from 0.01635 to 0.01635, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 38/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0186 - logloss: 0.0154\n",
      "Epoch 00038: val_logloss improved from 0.01635 to 0.01634, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 39/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00039: val_logloss improved from 0.01634 to 0.01634, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 40/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0187 - logloss: 0.0155\n",
      "Epoch 00040: val_logloss improved from 0.01634 to 0.01634, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0187 - logloss: 0.0155 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Fold 4 log loss: 0.016234661459945003\n",
      "Fold 5\n",
      "Epoch 1/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.4978 - logloss: 0.4973\n",
      "Epoch 00001: val_logloss improved from inf to 0.09773, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.4813 - logloss: 0.4786 - val_loss: 0.0989 - val_logloss: 0.0977\n",
      "Epoch 2/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0569 - logloss: 0.0551\n",
      "Epoch 00002: val_logloss improved from 0.09773 to 0.02996, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0558 - logloss: 0.0539 - val_loss: 0.0321 - val_logloss: 0.0300\n",
      "Epoch 3/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0296 - logloss: 0.0271\n",
      "Epoch 00003: val_logloss improved from 0.02996 to 0.02382, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0295 - logloss: 0.0270 - val_loss: 0.0264 - val_logloss: 0.0238\n",
      "Epoch 4/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0256 - logloss: 0.0228\n",
      "Epoch 00004: val_logloss improved from 0.02382 to 0.02127, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0256 - logloss: 0.0229 - val_loss: 0.0240 - val_logloss: 0.0213\n",
      "Epoch 5/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0242 - logloss: 0.0212\n",
      "Epoch 00005: val_logloss improved from 0.02127 to 0.02000, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0242 - logloss: 0.0213 - val_loss: 0.0229 - val_logloss: 0.0200\n",
      "Epoch 6/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0236 - logloss: 0.0205\n",
      "Epoch 00006: val_logloss improved from 0.02000 to 0.01944, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0235 - logloss: 0.0205 - val_loss: 0.0224 - val_logloss: 0.0194\n",
      "Epoch 7/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0229 - logloss: 0.0197\n",
      "Epoch 00007: val_logloss improved from 0.01944 to 0.01893, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0229 - logloss: 0.0198 - val_loss: 0.0219 - val_logloss: 0.0189\n",
      "Epoch 8/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0226 - logloss: 0.0195\n",
      "Epoch 00008: val_logloss improved from 0.01893 to 0.01869, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0226 - logloss: 0.0194 - val_loss: 0.0217 - val_logloss: 0.0187\n",
      "Epoch 9/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0222 - logloss: 0.0191\n",
      "Epoch 00009: val_logloss improved from 0.01869 to 0.01839, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0223 - logloss: 0.0191 - val_loss: 0.0215 - val_logloss: 0.0184\n",
      "Epoch 10/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0218 - logloss: 0.0186\n",
      "Epoch 00010: val_logloss improved from 0.01839 to 0.01819, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0218 - logloss: 0.0187 - val_loss: 0.0212 - val_logloss: 0.0182\n",
      "Epoch 11/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0216 - logloss: 0.0184\n",
      "Epoch 00011: val_logloss improved from 0.01819 to 0.01794, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0216 - logloss: 0.0184 - val_loss: 0.0210 - val_logloss: 0.0179\n",
      "Epoch 12/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0214 - logloss: 0.0182\n",
      "Epoch 00012: val_logloss did not improve from 0.01794\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0215 - logloss: 0.0183 - val_loss: 0.0212 - val_logloss: 0.0180\n",
      "Epoch 13/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0212 - logloss: 0.0179\n",
      "Epoch 00013: val_logloss improved from 0.01794 to 0.01778, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0212 - logloss: 0.0179 - val_loss: 0.0210 - val_logloss: 0.0178\n",
      "Epoch 14/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0210 - logloss: 0.0177\n",
      "Epoch 00014: val_logloss improved from 0.01778 to 0.01754, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0210 - logloss: 0.0177 - val_loss: 0.0207 - val_logloss: 0.0175\n",
      "Epoch 15/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0208 - logloss: 0.0175\n",
      "Epoch 00015: val_logloss improved from 0.01754 to 0.01745, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0208 - logloss: 0.0175 - val_loss: 0.0206 - val_logloss: 0.0174\n",
      "Epoch 16/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0207 - logloss: 0.0174\n",
      "Epoch 00016: val_logloss improved from 0.01745 to 0.01729, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0206 - logloss: 0.0174 - val_loss: 0.0204 - val_logloss: 0.0173\n",
      "Epoch 17/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0204 - logloss: 0.0171\n",
      "Epoch 00017: val_logloss improved from 0.01729 to 0.01721, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0204 - logloss: 0.0172 - val_loss: 0.0203 - val_logloss: 0.0172\n",
      "Epoch 18/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0204 - logloss: 0.0171\n",
      "Epoch 00018: val_logloss improved from 0.01721 to 0.01718, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0204 - logloss: 0.0171 - val_loss: 0.0203 - val_logloss: 0.0172\n",
      "Epoch 19/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0201 - logloss: 0.0169\n",
      "Epoch 00019: val_logloss improved from 0.01718 to 0.01701, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0201 - logloss: 0.0169 - val_loss: 0.0201 - val_logloss: 0.0170\n",
      "Epoch 20/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0200 - logloss: 0.0168\n",
      "Epoch 00020: val_logloss improved from 0.01701 to 0.01699, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0200 - logloss: 0.0168 - val_loss: 0.0202 - val_logloss: 0.0170\n",
      "Epoch 21/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0198 - logloss: 0.0166\n",
      "Epoch 00021: val_logloss improved from 0.01699 to 0.01692, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0198 - logloss: 0.0166 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 22/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0198 - logloss: 0.0165\n",
      "Epoch 00022: val_logloss improved from 0.01692 to 0.01689, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0198 - logloss: 0.0165 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 23/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0196 - logloss: 0.0163\n",
      "Epoch 00023: val_logloss improved from 0.01689 to 0.01683, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0196 - logloss: 0.0163 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 24/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0195 - logloss: 0.0162\n",
      "Epoch 00024: val_logloss did not improve from 0.01683\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0195 - logloss: 0.0162 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 25/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0192 - logloss: 0.0160\n",
      "Epoch 00025: val_logloss improved from 0.01683 to 0.01680, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0192 - logloss: 0.0160 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 26/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0188 - logloss: 0.0156\n",
      "Epoch 00026: val_logloss improved from 0.01680 to 0.01667, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0188 - logloss: 0.0156 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 27/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0188 - logloss: 0.0155\n",
      "Epoch 00027: val_logloss improved from 0.01667 to 0.01665, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0188 - logloss: 0.0155 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 28/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0187 - logloss: 0.0154\n",
      "Epoch 00028: val_logloss improved from 0.01665 to 0.01663, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0187 - logloss: 0.0154 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 29/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0186 - logloss: 0.0154\n",
      "Epoch 00029: val_logloss improved from 0.01663 to 0.01661, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 30/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00030: val_logloss improved from 0.01661 to 0.01660, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0186 - logloss: 0.0153 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 31/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00031: val_logloss did not improve from 0.01660\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 32/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00032: val_logloss improved from 0.01660 to 0.01660, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 33/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00033: val_logloss did not improve from 0.01660\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 34/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00034: val_logloss did not improve from 0.01660\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 35/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0184 - logloss: 0.0152\n",
      "Epoch 00035: val_logloss improved from 0.01660 to 0.01659, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 36/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0184 - logloss: 0.0152\n",
      "Epoch 00036: val_logloss improved from 0.01659 to 0.01659, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0184 - logloss: 0.0152 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 37/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0185 - logloss: 0.0152\n",
      "Epoch 00037: val_logloss improved from 0.01659 to 0.01659, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 38/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0184 - logloss: 0.0152\n",
      "Epoch 00038: val_logloss improved from 0.01659 to 0.01659, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0184 - logloss: 0.0152 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 39/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0184 - logloss: 0.0152\n",
      "Epoch 00039: val_logloss improved from 0.01659 to 0.01658, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0184 - logloss: 0.0152 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 40/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0185 - logloss: 0.0152\n",
      "Epoch 00040: val_logloss improved from 0.01658 to 0.01658, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0185 - logloss: 0.0152 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Fold 5 log loss: 0.016419607504577764\n",
      "Seed 1\n",
      "Fold 1 log loss: 0.016353566543988285\n",
      "Fold 2 log loss: 0.016466788356703628\n",
      "Fold 3 log loss: 0.016508977584970583\n",
      "Fold 4 log loss: 0.016234661459945003\n",
      "Fold 5 log loss: 0.016419607504577764\n",
      "Std of log loss: 9.608368126842688e-05\n",
      "Total log loss: 0.016396716054786403\n",
      "Fold 1\n",
      "Epoch 1/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.4920 - logloss: 0.4915\n",
      "Epoch 00001: val_logloss improved from inf to 0.10107, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.4808 - logloss: 0.4781 - val_loss: 0.1025 - val_logloss: 0.1011\n",
      "Epoch 2/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0561 - logloss: 0.0543\n",
      "Epoch 00002: val_logloss improved from 0.10107 to 0.03018, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0559 - logloss: 0.0540 - val_loss: 0.0325 - val_logloss: 0.0302\n",
      "Epoch 3/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0293 - logloss: 0.0268\n",
      "Epoch 00003: val_logloss improved from 0.03018 to 0.02292, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0292 - logloss: 0.0268 - val_loss: 0.0256 - val_logloss: 0.0229\n",
      "Epoch 4/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0255 - logloss: 0.0227\n",
      "Epoch 00004: val_logloss improved from 0.02292 to 0.02103, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0255 - logloss: 0.0227 - val_loss: 0.0242 - val_logloss: 0.0210\n",
      "Epoch 5/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0241 - logloss: 0.0212\n",
      "Epoch 00005: val_logloss improved from 0.02103 to 0.01994, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0241 - logloss: 0.0212 - val_loss: 0.0230 - val_logloss: 0.0199\n",
      "Epoch 6/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0235 - logloss: 0.0205\n",
      "Epoch 00006: val_logloss improved from 0.01994 to 0.01937, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0235 - logloss: 0.0204 - val_loss: 0.0225 - val_logloss: 0.0194\n",
      "Epoch 7/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0227 - logloss: 0.0196\n",
      "Epoch 00007: val_logloss improved from 0.01937 to 0.01879, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0227 - logloss: 0.0196 - val_loss: 0.0219 - val_logloss: 0.0188\n",
      "Epoch 8/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0223 - logloss: 0.0192\n",
      "Epoch 00008: val_logloss improved from 0.01879 to 0.01847, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0223 - logloss: 0.0193 - val_loss: 0.0217 - val_logloss: 0.0185\n",
      "Epoch 9/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0221 - logloss: 0.0189\n",
      "Epoch 00009: val_logloss improved from 0.01847 to 0.01813, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0221 - logloss: 0.0189 - val_loss: 0.0213 - val_logloss: 0.0181\n",
      "Epoch 10/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0219 - logloss: 0.0187\n",
      "Epoch 00010: val_logloss improved from 0.01813 to 0.01809, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0219 - logloss: 0.0187 - val_loss: 0.0214 - val_logloss: 0.0181\n",
      "Epoch 11/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0215 - logloss: 0.0183\n",
      "Epoch 00011: val_logloss improved from 0.01809 to 0.01782, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0215 - logloss: 0.0183 - val_loss: 0.0211 - val_logloss: 0.0178\n",
      "Epoch 12/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0213 - logloss: 0.0182\n",
      "Epoch 00012: val_logloss improved from 0.01782 to 0.01775, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0213 - logloss: 0.0182 - val_loss: 0.0211 - val_logloss: 0.0177\n",
      "Epoch 13/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0211 - logloss: 0.0179\n",
      "Epoch 00013: val_logloss improved from 0.01775 to 0.01758, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0211 - logloss: 0.0179 - val_loss: 0.0208 - val_logloss: 0.0176\n",
      "Epoch 14/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0208 - logloss: 0.0176\n",
      "Epoch 00014: val_logloss improved from 0.01758 to 0.01741, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0208 - logloss: 0.0177 - val_loss: 0.0207 - val_logloss: 0.0174\n",
      "Epoch 15/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0206 - logloss: 0.0175\n",
      "Epoch 00015: val_logloss improved from 0.01741 to 0.01727, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0206 - logloss: 0.0174 - val_loss: 0.0205 - val_logloss: 0.0173\n",
      "Epoch 16/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0205 - logloss: 0.0173\n",
      "Epoch 00016: val_logloss improved from 0.01727 to 0.01727, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0205 - logloss: 0.0173 - val_loss: 0.0205 - val_logloss: 0.0173\n",
      "Epoch 17/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0203 - logloss: 0.0171\n",
      "Epoch 00017: val_logloss did not improve from 0.01727\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0203 - logloss: 0.0171 - val_loss: 0.0207 - val_logloss: 0.0173\n",
      "Epoch 18/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0202 - logloss: 0.0169\n",
      "Epoch 00018: val_logloss improved from 0.01727 to 0.01708, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0202 - logloss: 0.0170 - val_loss: 0.0203 - val_logloss: 0.0171\n",
      "Epoch 19/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0200 - logloss: 0.0168\n",
      "Epoch 00019: val_logloss improved from 0.01708 to 0.01704, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0200 - logloss: 0.0168 - val_loss: 0.0204 - val_logloss: 0.0170\n",
      "Epoch 20/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0198 - logloss: 0.0166\n",
      "Epoch 00020: val_logloss improved from 0.01704 to 0.01697, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0198 - logloss: 0.0167 - val_loss: 0.0204 - val_logloss: 0.0170\n",
      "Epoch 21/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0197 - logloss: 0.0165\n",
      "Epoch 00021: val_logloss improved from 0.01697 to 0.01689, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0197 - logloss: 0.0165 - val_loss: 0.0203 - val_logloss: 0.0169\n",
      "Epoch 22/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0196 - logloss: 0.0164\n",
      "Epoch 00022: val_logloss improved from 0.01689 to 0.01681, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0196 - logloss: 0.0163 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 23/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0198 - logloss: 0.0165\n",
      "Epoch 00023: val_logloss did not improve from 0.01681\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0198 - logloss: 0.0165 - val_loss: 0.0203 - val_logloss: 0.0168\n",
      "Epoch 24/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0194 - logloss: 0.0161\n",
      "Epoch 00024: val_logloss improved from 0.01681 to 0.01679, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0194 - logloss: 0.0161 - val_loss: 0.0202 - val_logloss: 0.0168\n",
      "Epoch 25/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0192 - logloss: 0.0159\n",
      "Epoch 00025: val_logloss improved from 0.01679 to 0.01674, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0192 - logloss: 0.0159 - val_loss: 0.0202 - val_logloss: 0.0167\n",
      "Epoch 26/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0188 - logloss: 0.0155\n",
      "Epoch 00026: val_logloss improved from 0.01674 to 0.01661, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0188 - logloss: 0.0155 - val_loss: 0.0200 - val_logloss: 0.0166\n",
      "Epoch 27/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0187 - logloss: 0.0154\n",
      "Epoch 00027: val_logloss improved from 0.01661 to 0.01658, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0187 - logloss: 0.0154 - val_loss: 0.0200 - val_logloss: 0.0166\n",
      "Epoch 28/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0186 - logloss: 0.0153\n",
      "Epoch 00028: val_logloss improved from 0.01658 to 0.01656, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0186 - logloss: 0.0153 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 29/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00029: val_logloss improved from 0.01656 to 0.01654, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 30/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0186 - logloss: 0.0153\n",
      "Epoch 00030: val_logloss improved from 0.01654 to 0.01654, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0186 - logloss: 0.0153 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 31/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00031: val_logloss did not improve from 0.01654\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 32/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0184 - logloss: 0.0152\n",
      "Epoch 00032: val_logloss improved from 0.01654 to 0.01654, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0184 - logloss: 0.0151 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 33/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0184 - logloss: 0.0151\n",
      "Epoch 00033: val_logloss improved from 0.01654 to 0.01653, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0184 - logloss: 0.0151 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 34/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0184 - logloss: 0.0152\n",
      "Epoch 00034: val_logloss did not improve from 0.01653\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0184 - logloss: 0.0152 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 35/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0184 - logloss: 0.0152\n",
      "Epoch 00035: val_logloss improved from 0.01653 to 0.01653, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0184 - logloss: 0.0152 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 36/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0184 - logloss: 0.0151\n",
      "Epoch 00036: val_logloss did not improve from 0.01653\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0184 - logloss: 0.0152 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 37/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0183 - logloss: 0.0151\n",
      "Epoch 00037: val_logloss did not improve from 0.01653\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0184 - logloss: 0.0151 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 38/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0184 - logloss: 0.0151\n",
      "Epoch 00038: val_logloss improved from 0.01653 to 0.01652, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0184 - logloss: 0.0152 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 39/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0184 - logloss: 0.0151\n",
      "Epoch 00039: val_logloss improved from 0.01652 to 0.01652, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0184 - logloss: 0.0151 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 40/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0184 - logloss: 0.0151\n",
      "Epoch 00040: val_logloss improved from 0.01652 to 0.01652, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0184 - logloss: 0.0151 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Fold 1 log loss: 0.016486778139495662\n",
      "Fold 2\n",
      "Epoch 1/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.4980 - logloss: 0.4974\n",
      "Epoch 00001: val_logloss improved from inf to 0.10351, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.4788 - logloss: 0.4760 - val_loss: 0.1049 - val_logloss: 0.1035\n",
      "Epoch 2/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0564 - logloss: 0.0546\n",
      "Epoch 00002: val_logloss improved from 0.10351 to 0.02885, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0561 - logloss: 0.0541 - val_loss: 0.0311 - val_logloss: 0.0288\n",
      "Epoch 3/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0297 - logloss: 0.0272\n",
      "Epoch 00003: val_logloss improved from 0.02885 to 0.02250, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0296 - logloss: 0.0271 - val_loss: 0.0251 - val_logloss: 0.0225\n",
      "Epoch 4/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0258 - logloss: 0.0230\n",
      "Epoch 00004: val_logloss improved from 0.02250 to 0.02101, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0258 - logloss: 0.0230 - val_loss: 0.0239 - val_logloss: 0.0210\n",
      "Epoch 5/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0243 - logloss: 0.0214\n",
      "Epoch 00005: val_logloss improved from 0.02101 to 0.01993, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0243 - logloss: 0.0214 - val_loss: 0.0229 - val_logloss: 0.0199\n",
      "Epoch 6/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0235 - logloss: 0.0205\n",
      "Epoch 00006: val_logloss improved from 0.01993 to 0.01928, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0235 - logloss: 0.0205 - val_loss: 0.0225 - val_logloss: 0.0193\n",
      "Epoch 7/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0229 - logloss: 0.0198\n",
      "Epoch 00007: val_logloss improved from 0.01928 to 0.01896, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0229 - logloss: 0.0198 - val_loss: 0.0221 - val_logloss: 0.0190\n",
      "Epoch 8/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0226 - logloss: 0.0195\n",
      "Epoch 00008: val_logloss improved from 0.01896 to 0.01862, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0226 - logloss: 0.0195 - val_loss: 0.0217 - val_logloss: 0.0186\n",
      "Epoch 9/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0223 - logloss: 0.0192\n",
      "Epoch 00009: val_logloss improved from 0.01862 to 0.01853, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0223 - logloss: 0.0192 - val_loss: 0.0218 - val_logloss: 0.0185\n",
      "Epoch 10/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0220 - logloss: 0.0188\n",
      "Epoch 00010: val_logloss improved from 0.01853 to 0.01808, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0220 - logloss: 0.0188 - val_loss: 0.0213 - val_logloss: 0.0181\n",
      "Epoch 11/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0218 - logloss: 0.0186\n",
      "Epoch 00011: val_logloss improved from 0.01808 to 0.01787, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0218 - logloss: 0.0186 - val_loss: 0.0212 - val_logloss: 0.0179\n",
      "Epoch 12/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0216 - logloss: 0.0184\n",
      "Epoch 00012: val_logloss did not improve from 0.01787\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0216 - logloss: 0.0185 - val_loss: 0.0214 - val_logloss: 0.0180\n",
      "Epoch 13/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0215 - logloss: 0.0182\n",
      "Epoch 00013: val_logloss improved from 0.01787 to 0.01765, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0215 - logloss: 0.0182 - val_loss: 0.0210 - val_logloss: 0.0176\n",
      "Epoch 14/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0212 - logloss: 0.0179\n",
      "Epoch 00014: val_logloss improved from 0.01765 to 0.01738, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0211 - logloss: 0.0179 - val_loss: 0.0206 - val_logloss: 0.0174\n",
      "Epoch 15/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0209 - logloss: 0.0177\n",
      "Epoch 00015: val_logloss did not improve from 0.01738\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0209 - logloss: 0.0177 - val_loss: 0.0206 - val_logloss: 0.0174\n",
      "Epoch 16/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0208 - logloss: 0.0175\n",
      "Epoch 00016: val_logloss improved from 0.01738 to 0.01719, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0208 - logloss: 0.0175 - val_loss: 0.0204 - val_logloss: 0.0172\n",
      "Epoch 17/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0206 - logloss: 0.0173\n",
      "Epoch 00017: val_logloss did not improve from 0.01719\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0206 - logloss: 0.0173 - val_loss: 0.0207 - val_logloss: 0.0174\n",
      "Epoch 18/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0205 - logloss: 0.0172\n",
      "Epoch 00018: val_logloss improved from 0.01719 to 0.01717, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0205 - logloss: 0.0172 - val_loss: 0.0205 - val_logloss: 0.0172\n",
      "Epoch 19/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0202 - logloss: 0.0170\n",
      "Epoch 00019: val_logloss improved from 0.01717 to 0.01696, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0202 - logloss: 0.0169 - val_loss: 0.0202 - val_logloss: 0.0170\n",
      "Epoch 20/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0201 - logloss: 0.0168\n",
      "Epoch 00020: val_logloss improved from 0.01696 to 0.01693, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0201 - logloss: 0.0168 - val_loss: 0.0202 - val_logloss: 0.0169\n",
      "Epoch 21/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0198 - logloss: 0.0166\n",
      "Epoch 00021: val_logloss improved from 0.01693 to 0.01687, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0198 - logloss: 0.0166 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 22/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0196 - logloss: 0.0164\n",
      "Epoch 00022: val_logloss improved from 0.01687 to 0.01678, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0196 - logloss: 0.0164 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 23/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0197 - logloss: 0.0164\n",
      "Epoch 00023: val_logloss did not improve from 0.01678\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0197 - logloss: 0.0164 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 24/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0195 - logloss: 0.0162\n",
      "Epoch 00024: val_logloss did not improve from 0.01678\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0195 - logloss: 0.0162 - val_loss: 0.0202 - val_logloss: 0.0168\n",
      "Epoch 25/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0193 - logloss: 0.0160\n",
      "Epoch 00025: val_logloss improved from 0.01678 to 0.01663, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0193 - logloss: 0.0161 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 26/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0191 - logloss: 0.0159\n",
      "Epoch 00026: val_logloss did not improve from 0.01663\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0191 - logloss: 0.0159 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 27/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0191 - logloss: 0.0158\n",
      "Epoch 00027: val_logloss did not improve from 0.01663\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0191 - logloss: 0.0158 - val_loss: 0.0200 - val_logloss: 0.0166\n",
      "Epoch 28/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0188 - logloss: 0.0155\n",
      "Epoch 00028: val_logloss improved from 0.01663 to 0.01655, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0188 - logloss: 0.0155 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 29/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0184 - logloss: 0.0152\n",
      "Epoch 00029: val_logloss improved from 0.01655 to 0.01647, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0184 - logloss: 0.0151 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 30/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0183 - logloss: 0.0150\n",
      "Epoch 00030: val_logloss improved from 0.01647 to 0.01644, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0183 - logloss: 0.0151 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 31/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0182 - logloss: 0.0149\n",
      "Epoch 00031: val_logloss improved from 0.01644 to 0.01642, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0182 - logloss: 0.0149 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 32/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0181 - logloss: 0.0149\n",
      "Epoch 00032: val_logloss did not improve from 0.01642\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0181 - logloss: 0.0149 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 33/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0180 - logloss: 0.0147\n",
      "Epoch 00033: val_logloss improved from 0.01642 to 0.01641, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0180 - logloss: 0.0147 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 34/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0180 - logloss: 0.0148\n",
      "Epoch 00034: val_logloss improved from 0.01641 to 0.01641, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0180 - logloss: 0.0148 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 35/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0180 - logloss: 0.0148\n",
      "Epoch 00035: val_logloss did not improve from 0.01641\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0180 - logloss: 0.0148 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 36/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0180 - logloss: 0.0147\n",
      "Epoch 00036: val_logloss did not improve from 0.01641\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0180 - logloss: 0.0148 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 37/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0179 - logloss: 0.0147\n",
      "Epoch 00037: val_logloss improved from 0.01641 to 0.01641, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0179 - logloss: 0.0147 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 38/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0180 - logloss: 0.0147\n",
      "Epoch 00038: val_logloss improved from 0.01641 to 0.01641, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0180 - logloss: 0.0147 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 39/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0180 - logloss: 0.0148\n",
      "Epoch 00039: val_logloss improved from 0.01641 to 0.01640, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0180 - logloss: 0.0148 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 40/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0179 - logloss: 0.0147\n",
      "Epoch 00040: val_logloss did not improve from 0.01640\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0179 - logloss: 0.0147 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Fold 2 log loss: 0.016289456121394905\n",
      "Fold 3\n",
      "Epoch 1/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.4884 - logloss: 0.4880\n",
      "Epoch 00001: val_logloss improved from inf to 0.10312, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.4773 - logloss: 0.4746 - val_loss: 0.1043 - val_logloss: 0.1031\n",
      "Epoch 2/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0561 - logloss: 0.0543\n",
      "Epoch 00002: val_logloss improved from 0.10312 to 0.02948, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0554 - logloss: 0.0534 - val_loss: 0.0317 - val_logloss: 0.0295\n",
      "Epoch 3/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0295 - logloss: 0.0271\n",
      "Epoch 00003: val_logloss improved from 0.02948 to 0.02237, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0295 - logloss: 0.0270 - val_loss: 0.0250 - val_logloss: 0.0224\n",
      "Epoch 4/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0261 - logloss: 0.0234\n",
      "Epoch 00004: val_logloss improved from 0.02237 to 0.02073, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0261 - logloss: 0.0233 - val_loss: 0.0235 - val_logloss: 0.0207\n",
      "Epoch 5/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0243 - logloss: 0.0213\n",
      "Epoch 00005: val_logloss improved from 0.02073 to 0.01984, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0243 - logloss: 0.0213 - val_loss: 0.0228 - val_logloss: 0.0198\n",
      "Epoch 6/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0235 - logloss: 0.0204\n",
      "Epoch 00006: val_logloss improved from 0.01984 to 0.01913, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0234 - logloss: 0.0204 - val_loss: 0.0221 - val_logloss: 0.0191\n",
      "Epoch 7/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0229 - logloss: 0.0198\n",
      "Epoch 00007: val_logloss improved from 0.01913 to 0.01884, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0229 - logloss: 0.0198 - val_loss: 0.0220 - val_logloss: 0.0188\n",
      "Epoch 8/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0226 - logloss: 0.0195\n",
      "Epoch 00008: val_logloss improved from 0.01884 to 0.01876, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0226 - logloss: 0.0195 - val_loss: 0.0220 - val_logloss: 0.0188\n",
      "Epoch 9/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0222 - logloss: 0.0190\n",
      "Epoch 00009: val_logloss improved from 0.01876 to 0.01840, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0223 - logloss: 0.0191 - val_loss: 0.0216 - val_logloss: 0.0184\n",
      "Epoch 10/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0220 - logloss: 0.0188\n",
      "Epoch 00010: val_logloss improved from 0.01840 to 0.01807, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0220 - logloss: 0.0188 - val_loss: 0.0213 - val_logloss: 0.0181\n",
      "Epoch 11/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0216 - logloss: 0.0185\n",
      "Epoch 00011: val_logloss improved from 0.01807 to 0.01781, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0216 - logloss: 0.0185 - val_loss: 0.0210 - val_logloss: 0.0178\n",
      "Epoch 12/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0214 - logloss: 0.0182\n",
      "Epoch 00012: val_logloss did not improve from 0.01781\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0215 - logloss: 0.0183 - val_loss: 0.0211 - val_logloss: 0.0179\n",
      "Epoch 13/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0213 - logloss: 0.0181\n",
      "Epoch 00013: val_logloss improved from 0.01781 to 0.01750, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0213 - logloss: 0.0181 - val_loss: 0.0207 - val_logloss: 0.0175\n",
      "Epoch 14/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0210 - logloss: 0.0178\n",
      "Epoch 00014: val_logloss improved from 0.01750 to 0.01743, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0210 - logloss: 0.0178 - val_loss: 0.0206 - val_logloss: 0.0174\n",
      "Epoch 15/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0208 - logloss: 0.0176\n",
      "Epoch 00015: val_logloss improved from 0.01743 to 0.01726, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0208 - logloss: 0.0176 - val_loss: 0.0204 - val_logloss: 0.0173\n",
      "Epoch 16/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0206 - logloss: 0.0174\n",
      "Epoch 00016: val_logloss did not improve from 0.01726\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0206 - logloss: 0.0174 - val_loss: 0.0207 - val_logloss: 0.0174\n",
      "Epoch 17/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0206 - logloss: 0.0174\n",
      "Epoch 00017: val_logloss improved from 0.01726 to 0.01709, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0206 - logloss: 0.0174 - val_loss: 0.0203 - val_logloss: 0.0171\n",
      "Epoch 18/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0203 - logloss: 0.0171\n",
      "Epoch 00018: val_logloss improved from 0.01709 to 0.01698, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0203 - logloss: 0.0171 - val_loss: 0.0202 - val_logloss: 0.0170\n",
      "Epoch 19/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0202 - logloss: 0.0170\n",
      "Epoch 00019: val_logloss improved from 0.01698 to 0.01692, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0202 - logloss: 0.0170 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 20/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0201 - logloss: 0.0169\n",
      "Epoch 00020: val_logloss improved from 0.01692 to 0.01689, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0202 - logloss: 0.0169 - val_loss: 0.0202 - val_logloss: 0.0169\n",
      "Epoch 21/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0199 - logloss: 0.0166\n",
      "Epoch 00021: val_logloss improved from 0.01689 to 0.01679, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0199 - logloss: 0.0167 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 22/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0197 - logloss: 0.0164\n",
      "Epoch 00022: val_logloss improved from 0.01679 to 0.01673, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0196 - logloss: 0.0165 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 23/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0196 - logloss: 0.0163\n",
      "Epoch 00023: val_logloss improved from 0.01673 to 0.01669, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0196 - logloss: 0.0164 - val_loss: 0.0200 - val_logloss: 0.0167\n",
      "Epoch 24/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0194 - logloss: 0.0162\n",
      "Epoch 00024: val_logloss did not improve from 0.01669\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 25/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0192 - logloss: 0.0160\n",
      "Epoch 00025: val_logloss improved from 0.01669 to 0.01655, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0192 - logloss: 0.0159 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 26/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0190 - logloss: 0.0158\n",
      "Epoch 00026: val_logloss improved from 0.01655 to 0.01654, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0190 - logloss: 0.0158 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 27/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0190 - logloss: 0.0157\n",
      "Epoch 00027: val_logloss improved from 0.01654 to 0.01653, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0190 - logloss: 0.0157 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 28/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0188 - logloss: 0.0155\n",
      "Epoch 00028: val_logloss improved from 0.01653 to 0.01649, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0187 - logloss: 0.0154 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 29/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0183 - logloss: 0.0150\n",
      "Epoch 00029: val_logloss improved from 0.01649 to 0.01641, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0183 - logloss: 0.0150 - val_loss: 0.0196 - val_logloss: 0.0164\n",
      "Epoch 30/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0182 - logloss: 0.0149\n",
      "Epoch 00030: val_logloss improved from 0.01641 to 0.01639, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0182 - logloss: 0.0150 - val_loss: 0.0196 - val_logloss: 0.0164\n",
      "Epoch 31/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0181 - logloss: 0.0149\n",
      "Epoch 00031: val_logloss improved from 0.01639 to 0.01636, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0181 - logloss: 0.0148 - val_loss: 0.0196 - val_logloss: 0.0164\n",
      "Epoch 32/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0180 - logloss: 0.0148\n",
      "Epoch 00032: val_logloss improved from 0.01636 to 0.01635, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0180 - logloss: 0.0148 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 33/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0181 - logloss: 0.0148\n",
      "Epoch 00033: val_logloss improved from 0.01635 to 0.01635, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0181 - logloss: 0.0149 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 34/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0180 - logloss: 0.0148\n",
      "Epoch 00034: val_logloss did not improve from 0.01635\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0180 - logloss: 0.0147 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 35/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0179 - logloss: 0.0147\n",
      "Epoch 00035: val_logloss did not improve from 0.01635\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0179 - logloss: 0.0147 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 36/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0179 - logloss: 0.0147\n",
      "Epoch 00036: val_logloss did not improve from 0.01635\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0179 - logloss: 0.0147 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 37/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0179 - logloss: 0.0146\n",
      "Epoch 00037: val_logloss improved from 0.01635 to 0.01634, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0179 - logloss: 0.0146 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 38/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0179 - logloss: 0.0147\n",
      "Epoch 00038: val_logloss improved from 0.01634 to 0.01634, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0179 - logloss: 0.0147 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 39/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0179 - logloss: 0.0146\n",
      "Epoch 00039: val_logloss improved from 0.01634 to 0.01634, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0179 - logloss: 0.0146 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 40/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0179 - logloss: 0.0147\n",
      "Epoch 00040: val_logloss improved from 0.01634 to 0.01634, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0179 - logloss: 0.0147 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Fold 3 log loss: 0.016161759585242463\n",
      "Fold 4\n",
      "Epoch 1/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.4850 - logloss: 0.4844\n",
      "Epoch 00001: val_logloss improved from inf to 0.10763, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.4818 - logloss: 0.4791 - val_loss: 0.1093 - val_logloss: 0.1076\n",
      "Epoch 2/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0565 - logloss: 0.0547\n",
      "Epoch 00002: val_logloss improved from 0.10763 to 0.02938, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0561 - logloss: 0.0542 - val_loss: 0.0316 - val_logloss: 0.0294\n",
      "Epoch 3/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0293 - logloss: 0.0268\n",
      "Epoch 00003: val_logloss improved from 0.02938 to 0.02333, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0293 - logloss: 0.0268 - val_loss: 0.0260 - val_logloss: 0.0233\n",
      "Epoch 4/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0255 - logloss: 0.0227\n",
      "Epoch 00004: val_logloss improved from 0.02333 to 0.02062, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0254 - logloss: 0.0227 - val_loss: 0.0234 - val_logloss: 0.0206\n",
      "Epoch 5/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0241 - logloss: 0.0212\n",
      "Epoch 00005: val_logloss improved from 0.02062 to 0.01976, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0241 - logloss: 0.0212 - val_loss: 0.0227 - val_logloss: 0.0198\n",
      "Epoch 6/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0233 - logloss: 0.0203\n",
      "Epoch 00006: val_logloss improved from 0.01976 to 0.01900, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0233 - logloss: 0.0203 - val_loss: 0.0220 - val_logloss: 0.0190\n",
      "Epoch 7/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0230 - logloss: 0.0199\n",
      "Epoch 00007: val_logloss improved from 0.01900 to 0.01858, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0230 - logloss: 0.0199 - val_loss: 0.0216 - val_logloss: 0.0186\n",
      "Epoch 8/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0225 - logloss: 0.0194\n",
      "Epoch 00008: val_logloss improved from 0.01858 to 0.01847, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 0.0224 - logloss: 0.0193 - val_loss: 0.0216 - val_logloss: 0.0185\n",
      "Epoch 9/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0221 - logloss: 0.0190\n",
      "Epoch 00009: val_logloss improved from 0.01847 to 0.01797, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0221 - logloss: 0.0190 - val_loss: 0.0211 - val_logloss: 0.0180\n",
      "Epoch 10/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0218 - logloss: 0.0187\n",
      "Epoch 00010: val_logloss improved from 0.01797 to 0.01778, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0218 - logloss: 0.0186 - val_loss: 0.0209 - val_logloss: 0.0178\n",
      "Epoch 11/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0220 - logloss: 0.0187\n",
      "Epoch 00011: val_logloss improved from 0.01778 to 0.01777, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0220 - logloss: 0.0188 - val_loss: 0.0210 - val_logloss: 0.0178\n",
      "Epoch 12/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0215 - logloss: 0.0182\n",
      "Epoch 00012: val_logloss improved from 0.01777 to 0.01747, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0215 - logloss: 0.0183 - val_loss: 0.0207 - val_logloss: 0.0175\n",
      "Epoch 13/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0212 - logloss: 0.0180\n",
      "Epoch 00013: val_logloss improved from 0.01747 to 0.01738, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0212 - logloss: 0.0180 - val_loss: 0.0206 - val_logloss: 0.0174\n",
      "Epoch 14/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0210 - logloss: 0.0178\n",
      "Epoch 00014: val_logloss improved from 0.01738 to 0.01732, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0210 - logloss: 0.0178 - val_loss: 0.0205 - val_logloss: 0.0173\n",
      "Epoch 15/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0207 - logloss: 0.0175\n",
      "Epoch 00015: val_logloss improved from 0.01732 to 0.01715, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0207 - logloss: 0.0176 - val_loss: 0.0204 - val_logloss: 0.0172\n",
      "Epoch 16/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0206 - logloss: 0.0173\n",
      "Epoch 00016: val_logloss improved from 0.01715 to 0.01704, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0205 - logloss: 0.0173 - val_loss: 0.0202 - val_logloss: 0.0170\n",
      "Epoch 17/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0204 - logloss: 0.0172\n",
      "Epoch 00017: val_logloss improved from 0.01704 to 0.01690, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0204 - logloss: 0.0172 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 18/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0203 - logloss: 0.0171\n",
      "Epoch 00018: val_logloss improved from 0.01690 to 0.01688, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0203 - logloss: 0.0171 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 19/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0202 - logloss: 0.0169\n",
      "Epoch 00019: val_logloss improved from 0.01688 to 0.01679, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0202 - logloss: 0.0169 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 20/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0201 - logloss: 0.0168\n",
      "Epoch 00020: val_logloss did not improve from 0.01679\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0201 - logloss: 0.0169 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 21/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0198 - logloss: 0.0166\n",
      "Epoch 00021: val_logloss improved from 0.01679 to 0.01676, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0198 - logloss: 0.0166 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 22/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0196 - logloss: 0.0164\n",
      "Epoch 00022: val_logloss improved from 0.01676 to 0.01663, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0196 - logloss: 0.0164 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 23/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0194 - logloss: 0.0162\n",
      "Epoch 00023: val_logloss improved from 0.01663 to 0.01654, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 24/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00024: val_logloss improved from 0.01654 to 0.01652, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0193 - logloss: 0.0161 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 25/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0191 - logloss: 0.0158\n",
      "Epoch 00025: val_logloss improved from 0.01652 to 0.01648, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0191 - logloss: 0.0159 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 26/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0190 - logloss: 0.0158\n",
      "Epoch 00026: val_logloss did not improve from 0.01648\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0190 - logloss: 0.0158 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 27/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0189 - logloss: 0.0156\n",
      "Epoch 00027: val_logloss did not improve from 0.01648\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0189 - logloss: 0.0157 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 28/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0184 - logloss: 0.0151\n",
      "Epoch 00028: val_logloss improved from 0.01648 to 0.01634, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0184 - logloss: 0.0152 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 29/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0183 - logloss: 0.0150\n",
      "Epoch 00029: val_logloss improved from 0.01634 to 0.01630, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0183 - logloss: 0.0150 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 30/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0182 - logloss: 0.0150\n",
      "Epoch 00030: val_logloss improved from 0.01630 to 0.01629, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0182 - logloss: 0.0150 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 31/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0181 - logloss: 0.0149\n",
      "Epoch 00031: val_logloss improved from 0.01629 to 0.01627, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0181 - logloss: 0.0149 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 32/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0180 - logloss: 0.0148\n",
      "Epoch 00032: val_logloss improved from 0.01627 to 0.01627, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 0.0180 - logloss: 0.0148 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 33/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0180 - logloss: 0.0148\n",
      "Epoch 00033: val_logloss improved from 0.01627 to 0.01627, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0180 - logloss: 0.0148 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 34/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0180 - logloss: 0.0148\n",
      "Epoch 00034: val_logloss improved from 0.01627 to 0.01627, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0180 - logloss: 0.0148 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 35/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0180 - logloss: 0.0148\n",
      "Epoch 00035: val_logloss improved from 0.01627 to 0.01626, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0180 - logloss: 0.0148 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 36/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0180 - logloss: 0.0147\n",
      "Epoch 00036: val_logloss improved from 0.01626 to 0.01626, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0180 - logloss: 0.0147 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 37/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0180 - logloss: 0.0147\n",
      "Epoch 00037: val_logloss improved from 0.01626 to 0.01626, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0180 - logloss: 0.0148 - val_loss: 0.0195 - val_logloss: 0.0163\n",
      "Epoch 38/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0180 - logloss: 0.0147\n",
      "Epoch 00038: val_logloss improved from 0.01626 to 0.01626, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0180 - logloss: 0.0147 - val_loss: 0.0195 - val_logloss: 0.0163\n",
      "Epoch 39/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0180 - logloss: 0.0147\n",
      "Epoch 00039: val_logloss improved from 0.01626 to 0.01626, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0180 - logloss: 0.0148 - val_loss: 0.0195 - val_logloss: 0.0163\n",
      "Epoch 40/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0179 - logloss: 0.0147\n",
      "Epoch 00040: val_logloss improved from 0.01626 to 0.01625, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0179 - logloss: 0.0147 - val_loss: 0.0195 - val_logloss: 0.0163\n",
      "Fold 4 log loss: 0.01613781438497169\n",
      "Fold 5\n",
      "Epoch 1/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.4799 - logloss: 0.4775\n",
      "Epoch 00001: val_logloss improved from inf to 0.09800, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.4799 - logloss: 0.4775 - val_loss: 0.0992 - val_logloss: 0.0980\n",
      "Epoch 2/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0568 - logloss: 0.0550\n",
      "Epoch 00002: val_logloss improved from 0.09800 to 0.02886, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0560 - logloss: 0.0540 - val_loss: 0.0311 - val_logloss: 0.0289\n",
      "Epoch 3/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0292 - logloss: 0.0268\n",
      "Epoch 00003: val_logloss improved from 0.02886 to 0.02298, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0292 - logloss: 0.0267 - val_loss: 0.0255 - val_logloss: 0.0230\n",
      "Epoch 4/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0256 - logloss: 0.0229\n",
      "Epoch 00004: val_logloss improved from 0.02298 to 0.02120, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0256 - logloss: 0.0229 - val_loss: 0.0240 - val_logloss: 0.0212\n",
      "Epoch 5/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0246 - logloss: 0.0216\n",
      "Epoch 00005: val_logloss improved from 0.02120 to 0.02007, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0246 - logloss: 0.0217 - val_loss: 0.0230 - val_logloss: 0.0201\n",
      "Epoch 6/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0234 - logloss: 0.0203\n",
      "Epoch 00006: val_logloss improved from 0.02007 to 0.01931, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0233 - logloss: 0.0203 - val_loss: 0.0223 - val_logloss: 0.0193\n",
      "Epoch 7/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0229 - logloss: 0.0198\n",
      "Epoch 00007: val_logloss improved from 0.01931 to 0.01903, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0229 - logloss: 0.0199 - val_loss: 0.0220 - val_logloss: 0.0190\n",
      "Epoch 8/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0226 - logloss: 0.0194\n",
      "Epoch 00008: val_logloss improved from 0.01903 to 0.01877, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0226 - logloss: 0.0195 - val_loss: 0.0218 - val_logloss: 0.0188\n",
      "Epoch 9/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0223 - logloss: 0.0191\n",
      "Epoch 00009: val_logloss improved from 0.01877 to 0.01833, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0223 - logloss: 0.0191 - val_loss: 0.0214 - val_logloss: 0.0183\n",
      "Epoch 10/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0220 - logloss: 0.0188\n",
      "Epoch 00010: val_logloss improved from 0.01833 to 0.01832, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0220 - logloss: 0.0189 - val_loss: 0.0214 - val_logloss: 0.0183\n",
      "Epoch 11/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0218 - logloss: 0.0185\n",
      "Epoch 00011: val_logloss improved from 0.01832 to 0.01793, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0218 - logloss: 0.0186 - val_loss: 0.0210 - val_logloss: 0.0179\n",
      "Epoch 12/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0214 - logloss: 0.0182\n",
      "Epoch 00012: val_logloss improved from 0.01793 to 0.01782, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0214 - logloss: 0.0182 - val_loss: 0.0209 - val_logloss: 0.0178\n",
      "Epoch 13/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0212 - logloss: 0.0180\n",
      "Epoch 00013: val_logloss improved from 0.01782 to 0.01761, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0212 - logloss: 0.0180 - val_loss: 0.0207 - val_logloss: 0.0176\n",
      "Epoch 14/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0209 - logloss: 0.0177\n",
      "Epoch 00014: val_logloss improved from 0.01761 to 0.01757, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0209 - logloss: 0.0177 - val_loss: 0.0207 - val_logloss: 0.0176\n",
      "Epoch 15/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0208 - logloss: 0.0176\n",
      "Epoch 00015: val_logloss improved from 0.01757 to 0.01742, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0208 - logloss: 0.0176 - val_loss: 0.0205 - val_logloss: 0.0174\n",
      "Epoch 16/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0205 - logloss: 0.0173\n",
      "Epoch 00016: val_logloss improved from 0.01742 to 0.01732, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0205 - logloss: 0.0173 - val_loss: 0.0205 - val_logloss: 0.0173\n",
      "Epoch 17/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0205 - logloss: 0.0173\n",
      "Epoch 00017: val_logloss improved from 0.01732 to 0.01719, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0205 - logloss: 0.0172 - val_loss: 0.0204 - val_logloss: 0.0172\n",
      "Epoch 18/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0202 - logloss: 0.0170\n",
      "Epoch 00018: val_logloss improved from 0.01719 to 0.01714, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0202 - logloss: 0.0170 - val_loss: 0.0203 - val_logloss: 0.0171\n",
      "Epoch 19/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0200 - logloss: 0.0168\n",
      "Epoch 00019: val_logloss improved from 0.01714 to 0.01708, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0201 - logloss: 0.0168 - val_loss: 0.0202 - val_logloss: 0.0171\n",
      "Epoch 20/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0199 - logloss: 0.0167\n",
      "Epoch 00020: val_logloss did not improve from 0.01708\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0200 - logloss: 0.0167 - val_loss: 0.0203 - val_logloss: 0.0171\n",
      "Epoch 21/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0199 - logloss: 0.0166\n",
      "Epoch 00021: val_logloss improved from 0.01708 to 0.01694, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0199 - logloss: 0.0166 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 22/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0197 - logloss: 0.0164\n",
      "Epoch 00022: val_logloss did not improve from 0.01694\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0197 - logloss: 0.0164 - val_loss: 0.0202 - val_logloss: 0.0169\n",
      "Epoch 23/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0195 - logloss: 0.0162\n",
      "Epoch 00023: val_logloss improved from 0.01694 to 0.01687, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 24/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0195 - logloss: 0.0162\n",
      "Epoch 00024: val_logloss improved from 0.01687 to 0.01682, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0195 - logloss: 0.0162 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 25/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0192 - logloss: 0.0159\n",
      "Epoch 00025: val_logloss improved from 0.01682 to 0.01677, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0192 - logloss: 0.0159 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 26/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0190 - logloss: 0.0157\n",
      "Epoch 00026: val_logloss did not improve from 0.01677\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0191 - logloss: 0.0157 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 27/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0188 - logloss: 0.0155\n",
      "Epoch 00027: val_logloss improved from 0.01677 to 0.01666, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0188 - logloss: 0.0155 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 28/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0187 - logloss: 0.0154\n",
      "Epoch 00028: val_logloss did not improve from 0.01666\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0187 - logloss: 0.0154 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 29/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0187 - logloss: 0.0154\n",
      "Epoch 00029: val_logloss did not improve from 0.01666\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0187 - logloss: 0.0154 - val_loss: 0.0202 - val_logloss: 0.0168\n",
      "Epoch 30/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0184 - logloss: 0.0151\n",
      "Epoch 00030: val_logloss improved from 0.01666 to 0.01662, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0184 - logloss: 0.0151 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 31/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0178 - logloss: 0.0146\n",
      "Epoch 00031: val_logloss improved from 0.01662 to 0.01658, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0179 - logloss: 0.0146 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 32/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0177 - logloss: 0.0145\n",
      "Epoch 00032: val_logloss improved from 0.01658 to 0.01655, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0177 - logloss: 0.0145 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 33/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0177 - logloss: 0.0144\n",
      "Epoch 00033: val_logloss improved from 0.01655 to 0.01653, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0176 - logloss: 0.0144 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 34/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0176 - logloss: 0.0144\n",
      "Epoch 00034: val_logloss improved from 0.01653 to 0.01652, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0176 - logloss: 0.0144 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 35/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0175 - logloss: 0.0142\n",
      "Epoch 00035: val_logloss did not improve from 0.01652\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0175 - logloss: 0.0143 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 36/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0175 - logloss: 0.0142\n",
      "Epoch 00036: val_logloss improved from 0.01652 to 0.01652, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0175 - logloss: 0.0143 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 37/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0175 - logloss: 0.0142\n",
      "Epoch 00037: val_logloss improved from 0.01652 to 0.01651, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0175 - logloss: 0.0142 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 38/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0174 - logloss: 0.0141\n",
      "Epoch 00038: val_logloss improved from 0.01651 to 0.01651, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0174 - logloss: 0.0142 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 39/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0174 - logloss: 0.0141\n",
      "Epoch 00039: val_logloss improved from 0.01651 to 0.01651, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0174 - logloss: 0.0141 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 40/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0175 - logloss: 0.0142\n",
      "Epoch 00040: val_logloss improved from 0.01651 to 0.01650, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0175 - logloss: 0.0142 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Fold 5 log loss: 0.01634728317865069\n",
      "Seed 2\n",
      "Fold 1 log loss: 0.016486778139495662\n",
      "Fold 2 log loss: 0.016289456121394905\n",
      "Fold 3 log loss: 0.016161759585242463\n",
      "Fold 4 log loss: 0.01613781438497169\n",
      "Fold 5 log loss: 0.01634728317865069\n",
      "Std of log loss: 0.00012764368021690514\n",
      "Total log loss: 0.01628461520637535\n",
      "Total log loss in targets: 0.016238036992865218\n"
     ]
    }
   ],
   "source": [
    "seeds = [0,1,2]\n",
    "\n",
    "target_oof = np.zeros([len(fn_train),fn_targets.shape[1]])\n",
    "target_pred = np.zeros([len(fn_test),fn_targets.shape[1]])\n",
    "\n",
    "nontarget_oof = np.zeros([len(fn_train),fn_nontargets.shape[1]])\n",
    "nontarget_pred = np.zeros([len(fn_test),fn_nontargets.shape[1]])\n",
    "\n",
    "for seed_ in seeds:\n",
    "    oof, keras_pred = modelling_keras(fn_train, fn_targets, fn_test, fn_train.shape[1], fn_targets.shape[1], seed_)\n",
    "    target_oof += oof / len(seeds)\n",
    "    target_pred += keras_pred / len(seeds)\n",
    "print(\"Total log loss in targets: {}\".format(mean_log_loss(fn_targets, target_oof)))\n",
    "\n",
    "#for seed_ in seeds:\n",
    "#    oof, keras_pred = modelling_keras(fn_train, fn_nontargets, fn_test, fn_train.shape[1], fn_nontargets.shape[1], seed_)\n",
    "#    nontarget_oof += oof / len(seeds)\n",
    "#    nontarget_pred += keras_pred / len(seeds)\n",
    "#print(\"Total log loss in Non targets: {}\".format(mean_log_loss(oof_targets, nontarget_oof)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 4.07769,
     "end_time": "2020-10-12T11:17:02.392759",
     "exception": false,
     "start_time": "2020-10-12T11:16:58.315069",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T11:17:10.809607Z",
     "iopub.status.busy": "2020-10-12T11:17:10.807616Z",
     "iopub.status.idle": "2020-10-12T11:17:10.810302Z",
     "shell.execute_reply": "2020-10-12T11:17:10.810780Z"
    },
    "papermill": {
     "duration": 4.086946,
     "end_time": "2020-10-12T11:17:10.810904",
     "exception": false,
     "start_time": "2020-10-12T11:17:06.723958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#n_train = f_train.copy()\n",
    "#n_test = f_test.copy()\n",
    "\n",
    "#n_train[\"target_sum\"] = target_oof.sum(axis=1)\n",
    "#n_train[\"nontarget_sum\"] = nontarget_oof.sum(axis=1)\n",
    "#n_test[\"target_sum\"] = target_pred.sum(axis=1)\n",
    "#n_test.loc[noncons_test_index, \"target_sum\"] = 0\n",
    "#n_test[\"nontarget_sum\"] = nontarget_pred.sum(axis=1)\n",
    "#n_test.loc[noncons_test_index, \"nontarget_sum\"] = 0\n",
    "\n",
    "#n_train = n_train.to_numpy()\n",
    "#n_test = n_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T11:17:19.118735Z",
     "iopub.status.busy": "2020-10-12T11:17:19.116845Z",
     "iopub.status.idle": "2020-10-12T11:17:19.119424Z",
     "shell.execute_reply": "2020-10-12T11:17:19.119910Z"
    },
    "papermill": {
     "duration": 4.058054,
     "end_time": "2020-10-12T11:17:19.120037",
     "exception": false,
     "start_time": "2020-10-12T11:17:15.061983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#oof_final = np.zeros([len(n_train),fn_targets.shape[1]])\n",
    "#pred_final = np.zeros([len(n_test),fn_targets.shape[1]])\n",
    "\n",
    "#seeds = [10,40]\n",
    "#for seed_ in seeds:\n",
    "#    oof, keras_pred = modelling_keras(n_train, fn_targets, n_test, n_train.shape[1], fn_targets.shape[1], seed_)\n",
    "#    oof_final += oof / len(seeds)\n",
    "#    pred_final += keras_pred / len(seeds)\n",
    "#print(\"Total log loss: {}\".format(mean_log_loss(fn_targets, oof_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T11:17:27.837292Z",
     "iopub.status.busy": "2020-10-12T11:17:27.836434Z",
     "iopub.status.idle": "2020-10-12T11:17:33.548470Z",
     "shell.execute_reply": "2020-10-12T11:17:33.548964Z"
    },
    "papermill": {
     "duration": 10.014445,
     "end_time": "2020-10-12T11:17:33.549098",
     "exception": false,
     "start_time": "2020-10-12T11:17:23.534653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF log loss:  0.015114910729546308\n"
     ]
    }
   ],
   "source": [
    "t = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "checkscore = t.copy()\n",
    "checkscore.loc[checkscore.index.isin(cons_train_index),target_feats] = np.clip(target_oof, p_min, p_max)\n",
    "checkscore.loc[checkscore.index.isin(noncons_train_index),target_feats] = 0\n",
    "t.drop(\"sig_id\", axis=1, inplace=True)\n",
    "print('OOF log loss: ', log_loss(np.ravel(t), np.ravel(np.array(checkscore.iloc[:,1:]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 4.088313,
     "end_time": "2020-10-12T11:17:41.946674",
     "exception": false,
     "start_time": "2020-10-12T11:17:37.858361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T11:17:50.912737Z",
     "iopub.status.busy": "2020-10-12T11:17:50.911761Z",
     "iopub.status.idle": "2020-10-12T11:17:53.395352Z",
     "shell.execute_reply": "2020-10-12T11:17:53.394066Z"
    },
    "papermill": {
     "duration": 7.093418,
     "end_time": "2020-10-12T11:17:53.395499",
     "exception": false,
     "start_time": "2020-10-12T11:17:46.302081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub[target_feats] = np.clip(target_pred,p_min,p_max) #label smoothing\n",
    "sub.loc[noncons_test_index,target_feats] = 0\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 4.281987,
     "end_time": "2020-10-12T11:18:01.835492",
     "exception": false,
     "start_time": "2020-10-12T11:17:57.553505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 920.547628,
   "end_time": "2020-10-12T11:18:07.457366",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-12T11:02:46.909738",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
