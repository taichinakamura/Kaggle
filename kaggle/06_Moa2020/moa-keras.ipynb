{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01551,
     "end_time": "2020-10-13T01:50:35.795559",
     "exception": false,
     "start_time": "2020-10-13T01:50:35.780049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- fix seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-13T01:50:35.834094Z",
     "iopub.status.busy": "2020-10-13T01:50:35.833315Z",
     "iopub.status.idle": "2020-10-13T01:50:41.861837Z",
     "shell.execute_reply": "2020-10-13T01:50:41.860455Z"
    },
    "papermill": {
     "duration": 6.051765,
     "end_time": "2020-10-13T01:50:41.861982",
     "exception": false,
     "start_time": "2020-10-13T01:50:35.810217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "sys.path.append('../input/multilabelstraifier/')\n",
    "from ml_stratifiers import MultilabelStratifiedKFold\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tensorflow.keras import layers,regularizers,Sequential,backend,callbacks,optimizers,metrics,losses\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-10-13T01:50:41.899438Z",
     "iopub.status.busy": "2020-10-13T01:50:41.898723Z",
     "iopub.status.idle": "2020-10-13T01:50:48.397266Z",
     "shell.execute_reply": "2020-10-13T01:50:48.395613Z"
    },
    "papermill": {
     "duration": 6.520857,
     "end_time": "2020-10-13T01:50:48.397406",
     "exception": false,
     "start_time": "2020-10-13T01:50:41.876549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/lish-moa/'\n",
    "train = pd.read_csv(DATA_DIR + 'train_features.csv')\n",
    "targets = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "non_targets = pd.read_csv(DATA_DIR + 'train_targets_nonscored.csv')\n",
    "test = pd.read_csv(DATA_DIR + 'test_features.csv')\n",
    "sub = pd.read_csv(DATA_DIR + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T01:50:48.437685Z",
     "iopub.status.busy": "2020-10-13T01:50:48.435666Z",
     "iopub.status.idle": "2020-10-13T01:50:48.438447Z",
     "shell.execute_reply": "2020-10-13T01:50:48.439013Z"
    },
    "papermill": {
     "duration": 0.025922,
     "end_time": "2020-10-13T01:50:48.439169",
     "exception": false,
     "start_time": "2020-10-13T01:50:48.413247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_feats = [ i for i in targets.columns if i != \"sig_id\"]\n",
    "g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "c_feats = [i for i in train.columns if \"c-\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T01:50:48.480061Z",
     "iopub.status.busy": "2020-10-13T01:50:48.479179Z",
     "iopub.status.idle": "2020-10-13T01:50:48.584091Z",
     "shell.execute_reply": "2020-10-13T01:50:48.583523Z"
    },
    "papermill": {
     "duration": 0.130054,
     "end_time": "2020-10-13T01:50:48.584220",
     "exception": false,
     "start_time": "2020-10-13T01:50:48.454166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "noncons_train_index = train[train.cp_type==\"ctl_vehicle\"].index\n",
    "cons_train_index = train[train.cp_type!=\"ctl_vehicle\"].index\n",
    "noncons_test_index = test[test.cp_type==\"ctl_vehicle\"].index\n",
    "cons_test_index = test[test.cp_type!=\"ctl_vehicle\"].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016064,
     "end_time": "2020-10-13T01:50:48.616741",
     "exception": false,
     "start_time": "2020-10-13T01:50:48.600677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T01:50:48.662840Z",
     "iopub.status.busy": "2020-10-13T01:50:48.661784Z",
     "iopub.status.idle": "2020-10-13T01:50:48.980851Z",
     "shell.execute_reply": "2020-10-13T01:50:48.979838Z"
    },
    "papermill": {
     "duration": 0.348666,
     "end_time": "2020-10-13T01:50:48.980996",
     "exception": false,
     "start_time": "2020-10-13T01:50:48.632330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train[train.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "targets = targets[targets.index.isin(cons_train_index)].copy().reset_index(drop=True)\n",
    "non_targets = non_targets[non_targets.index.isin(cons_train_index)].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T01:50:49.047399Z",
     "iopub.status.busy": "2020-10-13T01:50:49.046384Z",
     "iopub.status.idle": "2020-10-13T01:50:49.060722Z",
     "shell.execute_reply": "2020-10-13T01:50:49.060136Z"
    },
    "papermill": {
     "duration": 0.064316,
     "end_time": "2020-10-13T01:50:49.060850",
     "exception": false,
     "start_time": "2020-10-13T01:50:48.996534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "non_target_feats = [i for i in non_targets.columns if i != \"sig_id\"]\n",
    "nontarget_dists = pd.DataFrame(np.sum(non_targets[non_target_feats])).reset_index(drop=False)\n",
    "nontarget_dists.columns = [\"target\", \"number\"]\n",
    "nontarget_dists = nontarget_dists.sort_values(\"number\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T01:50:49.100040Z",
     "iopub.status.busy": "2020-10-13T01:50:49.099073Z",
     "iopub.status.idle": "2020-10-13T01:50:49.143654Z",
     "shell.execute_reply": "2020-10-13T01:50:49.144196Z"
    },
    "papermill": {
     "duration": 0.067106,
     "end_time": "2020-10-13T01:50:49.144418",
     "exception": false,
     "start_time": "2020-10-13T01:50:49.077312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first drop 71\n",
      "shape after 1st drop: (21948, 332)\n"
     ]
    }
   ],
   "source": [
    "drop_list1 = list(nontarget_dists[nontarget_dists.number==0][\"target\"].values)\n",
    "print(\"first drop\", len(drop_list1))\n",
    "non_targets.drop(drop_list1, axis=1, inplace=True)\n",
    "print(\"shape after 1st drop:\", non_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T01:50:49.196151Z",
     "iopub.status.busy": "2020-10-13T01:50:49.191325Z",
     "iopub.status.idle": "2020-10-13T01:50:54.619619Z",
     "shell.execute_reply": "2020-10-13T01:50:54.620404Z"
    },
    "papermill": {
     "duration": 5.458856,
     "end_time": "2020-10-13T01:50:54.620570",
     "exception": false,
     "start_time": "2020-10-13T01:50:49.161714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 889) (3982, 889)\n"
     ]
    }
   ],
   "source": [
    "def fe(df):\n",
    "    tmp = df.copy()\n",
    "    tmp.loc[:, 'cp_type'] = tmp.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    tmp.loc[:, 'cp_dose'] = tmp.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "    tmp['g_sum'] = tmp[g_feats].sum(axis = 1)\n",
    "    tmp['g_mean'] = tmp[g_feats].mean(axis = 1)\n",
    "    tmp['g_std'] = tmp[g_feats].std(axis = 1)\n",
    "    tmp['g_kurt'] = tmp[g_feats].kurtosis(axis = 1)\n",
    "    tmp['g_skew'] = tmp[g_feats].skew(axis = 1)\n",
    "    tmp['c_sum'] = tmp[c_feats].sum(axis = 1)\n",
    "    tmp['c_mean'] = tmp[c_feats].mean(axis = 1)\n",
    "    tmp['c_std'] = tmp[c_feats].std(axis = 1)\n",
    "    tmp['c_kurt'] = tmp[c_feats].kurtosis(axis = 1)\n",
    "    tmp['c_skew'] = tmp[c_feats].skew(axis = 1)\n",
    "    tmp['gc_sum'] = tmp[c_feats + g_feats].sum(axis = 1)\n",
    "    tmp['gc_mean'] = tmp[c_feats + g_feats].mean(axis = 1)\n",
    "    tmp['gc_std'] = tmp[c_feats + g_feats].std(axis = 1)\n",
    "    tmp['gc_kurt'] = tmp[c_feats + g_feats].kurtosis(axis = 1)\n",
    "    tmp['gc_skew'] = tmp[c_feats + g_feats].skew(axis = 1)\n",
    "        \n",
    "    tmp.drop([\"cp_type\", \"sig_id\"], axis=1, inplace=True)\n",
    "    return tmp\n",
    "\n",
    "f_train = fe(train)\n",
    "f_test = fe(test)\n",
    "\n",
    "print(f_train.shape, f_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T01:50:54.664347Z",
     "iopub.status.busy": "2020-10-13T01:50:54.663289Z",
     "iopub.status.idle": "2020-10-13T01:50:55.944523Z",
     "shell.execute_reply": "2020-10-13T01:50:55.943850Z"
    },
    "papermill": {
     "duration": 1.303457,
     "end_time": "2020-10-13T01:50:55.944643",
     "exception": false,
     "start_time": "2020-10-13T01:50:54.641186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fn_train = f_train.copy().to_numpy()\n",
    "fn_test = f_test.copy().to_numpy()\n",
    "\n",
    "ss = preprocessing.RobustScaler()\n",
    "fn_train= ss.fit_transform(fn_train)\n",
    "fn_test = ss.transform(fn_test)\n",
    "\n",
    "fn_nontargets = non_targets.drop(\"sig_id\", axis=1).copy().to_numpy()\n",
    "fn_targets = targets.drop(\"sig_id\", axis=1).copy().to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018119,
     "end_time": "2020-10-13T01:50:55.980542",
     "exception": false,
     "start_time": "2020-10-13T01:50:55.962423",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T01:50:56.055014Z",
     "iopub.status.busy": "2020-10-13T01:50:56.046531Z",
     "iopub.status.idle": "2020-10-13T01:50:56.057265Z",
     "shell.execute_reply": "2020-10-13T01:50:56.057740Z"
    },
    "papermill": {
     "duration": 0.05965,
     "end_time": "2020-10-13T01:50:56.057902",
     "exception": false,
     "start_time": "2020-10-13T01:50:55.998252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prediction Clipping Thresholds\n",
    "p_min = 0.001\n",
    "p_max = 0.999\n",
    "\n",
    "n_folds = 5\n",
    "\n",
    "def mean_log_loss(y_true, y_pred):\n",
    "    metrics = []\n",
    "    for i, target in enumerate(target_feats):\n",
    "        metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float), labels=[0,1]))\n",
    "    return np.mean(metrics)\n",
    "\n",
    "# Evaluation Metric with clipping and no label smoothing\n",
    "def logloss(y_true, y_pred):\n",
    "    y_pred = tf.clip_by_value(y_pred,p_min,p_max)\n",
    "    return -backend.mean(y_true*backend.log(y_pred) + (1-y_true)*backend.log(1-y_pred))\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    session_conf = tf.compat.v1.ConfigProto(\n",
    "        intra_op_parallelism_threads=1,\n",
    "        inter_op_parallelism_threads=1\n",
    "    )\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "    \n",
    "def create_model(shape):\n",
    "    inp = tf.keras.layers.Input(shape = (shape))\n",
    "    x = tf.keras.layers.BatchNormalization()(inp)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tfa.layers.WeightNormalization(tf.keras.layers.Dense(2048, activation = 'relu'))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.6)(x)\n",
    "    x = tfa.layers.WeightNormalization(tf.keras.layers.Dense(1048, activation = 'relu'))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.6)(x)\n",
    "    out = tfa.layers.WeightNormalization(tf.keras.layers.Dense(206, activation = 'sigmoid'))(x)\n",
    "    model = tf.keras.models.Model(inputs = inp, outputs = out)\n",
    "    return model\n",
    "    \n",
    "def modelling_keras(X_train, y_train, X_test, input_features, output_features, sample_seed):\n",
    "    seed_everything(seed=sample_seed) \n",
    "    oof = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    pred_value = np.zeros([X_test.shape[0], y_train.shape[1]])\n",
    "    \n",
    "    scores = []\n",
    "    mskf=MultilabelStratifiedKFold(n_splits = n_folds, shuffle=True, random_state=2)\n",
    "    for i , (train_index, val_index) in enumerate(mskf.split(X_train, y_train)):   \n",
    "        print(\"Fold \"+str(i+1))\n",
    "        X_train2 = X_train[train_index,:]\n",
    "        y_train2 = y_train[train_index,:]\n",
    "    \n",
    "        X_test2 = X_train[val_index,:]\n",
    "        y_test2 = y_train[val_index,:] \n",
    "        \n",
    "        model = create_model(input_features)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "                      loss=losses.BinaryCrossentropy(label_smoothing=0.001), metrics=logloss)\n",
    "        reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_logloss', factor=0.1, patience=3, mode='min', min_lr=1E-5)\n",
    "        #early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_logloss', min_delta=1E-5, \n",
    "        #                                                  patience=10, mode='min',restore_best_weights=True)\n",
    "        save_best = tf.keras.callbacks.ModelCheckpoint('./nn_model.h5', save_best_only=True, monitor=\"val_logloss\", verbose=1)\n",
    "        \n",
    "        model.fit(X_train2, y_train2, validation_data=(X_test2, y_test2),batch_size=128, \n",
    "                epochs=40,callbacks=[reduce_lr, save_best]) \n",
    "\n",
    "        model.load_weights('./nn_model.h5')\n",
    "        valid = np.array(model.predict(X_test2))\n",
    "        oof[val_index,:] = valid\n",
    "        pred_value += model.predict(X_test)/ n_folds\n",
    "        print(\"Fold {} log loss: {}\".format(i+1, mean_log_loss(y_train[val_index,:], valid)))\n",
    "        scores.append(mean_log_loss(y_train[val_index,:], valid))\n",
    "    \n",
    "    print(\"Seed {}\".format(seed_))\n",
    "    for i, ele in enumerate(scores):\n",
    "        print(\"Fold {} log loss: {}\".format(i+1, scores[i]))\n",
    "    print(\"Std of log loss: {}\".format(np.std(scores)))\n",
    "        \n",
    "    print(\"Total log loss: {}\".format(mean_log_loss(y_train, oof)))\n",
    "\n",
    "    return oof, pred_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017531,
     "end_time": "2020-10-13T01:50:56.094624",
     "exception": false,
     "start_time": "2020-10-13T01:50:56.077093",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# non-targets, targets separate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T01:50:56.143420Z",
     "iopub.status.busy": "2020-10-13T01:50:56.141980Z",
     "iopub.status.idle": "2020-10-13T02:05:11.503172Z",
     "shell.execute_reply": "2020-10-13T02:05:11.502593Z"
    },
    "papermill": {
     "duration": 855.39074,
     "end_time": "2020-10-13T02:05:11.503292",
     "exception": false,
     "start_time": "2020-10-13T01:50:56.112552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.4911 - logloss: 0.4905\n",
      "Epoch 00001: val_logloss improved from inf to 0.10609, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.4775 - logloss: 0.4748 - val_loss: 0.1076 - val_logloss: 0.1061\n",
      "Epoch 2/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0562 - logloss: 0.0544\n",
      "Epoch 00002: val_logloss improved from 0.10609 to 0.02946, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0557 - logloss: 0.0537 - val_loss: 0.0318 - val_logloss: 0.0295\n",
      "Epoch 3/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0292 - logloss: 0.0267\n",
      "Epoch 00003: val_logloss improved from 0.02946 to 0.02249, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0291 - logloss: 0.0266 - val_loss: 0.0251 - val_logloss: 0.0225\n",
      "Epoch 4/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0257 - logloss: 0.0229\n",
      "Epoch 00004: val_logloss improved from 0.02249 to 0.02111, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0257 - logloss: 0.0230 - val_loss: 0.0240 - val_logloss: 0.0211\n",
      "Epoch 5/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0242 - logloss: 0.0213\n",
      "Epoch 00005: val_logloss improved from 0.02111 to 0.02010, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0241 - logloss: 0.0212 - val_loss: 0.0231 - val_logloss: 0.0201\n",
      "Epoch 6/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0232 - logloss: 0.0203\n",
      "Epoch 00006: val_logloss improved from 0.02010 to 0.01928, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0232 - logloss: 0.0203 - val_loss: 0.0224 - val_logloss: 0.0193\n",
      "Epoch 7/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0229 - logloss: 0.0199\n",
      "Epoch 00007: val_logloss improved from 0.01928 to 0.01893, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0229 - logloss: 0.0199 - val_loss: 0.0220 - val_logloss: 0.0189\n",
      "Epoch 8/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0226 - logloss: 0.0194\n",
      "Epoch 00008: val_logloss improved from 0.01893 to 0.01870, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0226 - logloss: 0.0195 - val_loss: 0.0220 - val_logloss: 0.0187\n",
      "Epoch 9/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0222 - logloss: 0.0190\n",
      "Epoch 00009: val_logloss improved from 0.01870 to 0.01832, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0222 - logloss: 0.0190 - val_loss: 0.0216 - val_logloss: 0.0183\n",
      "Epoch 10/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0219 - logloss: 0.0188\n",
      "Epoch 00010: val_logloss improved from 0.01832 to 0.01807, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0219 - logloss: 0.0187 - val_loss: 0.0213 - val_logloss: 0.0181\n",
      "Epoch 11/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0215 - logloss: 0.0184\n",
      "Epoch 00011: val_logloss improved from 0.01807 to 0.01796, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0215 - logloss: 0.0184 - val_loss: 0.0212 - val_logloss: 0.0180\n",
      "Epoch 12/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0213 - logloss: 0.0182\n",
      "Epoch 00012: val_logloss improved from 0.01796 to 0.01775, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0213 - logloss: 0.0182 - val_loss: 0.0210 - val_logloss: 0.0177\n",
      "Epoch 13/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0211 - logloss: 0.0179\n",
      "Epoch 00013: val_logloss improved from 0.01775 to 0.01759, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0211 - logloss: 0.0179 - val_loss: 0.0208 - val_logloss: 0.0176\n",
      "Epoch 14/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0210 - logloss: 0.0178\n",
      "Epoch 00014: val_logloss did not improve from 0.01759\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0210 - logloss: 0.0178 - val_loss: 0.0210 - val_logloss: 0.0176\n",
      "Epoch 15/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0208 - logloss: 0.0176\n",
      "Epoch 00015: val_logloss improved from 0.01759 to 0.01738, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0208 - logloss: 0.0176 - val_loss: 0.0207 - val_logloss: 0.0174\n",
      "Epoch 16/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0206 - logloss: 0.0174\n",
      "Epoch 00016: val_logloss improved from 0.01738 to 0.01730, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0206 - logloss: 0.0174 - val_loss: 0.0206 - val_logloss: 0.0173\n",
      "Epoch 17/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0204 - logloss: 0.0172\n",
      "Epoch 00017: val_logloss improved from 0.01730 to 0.01711, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0204 - logloss: 0.0171 - val_loss: 0.0204 - val_logloss: 0.0171\n",
      "Epoch 18/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0203 - logloss: 0.0171\n",
      "Epoch 00018: val_logloss did not improve from 0.01711\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0203 - logloss: 0.0171 - val_loss: 0.0207 - val_logloss: 0.0173\n",
      "Epoch 19/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0204 - logloss: 0.0171\n",
      "Epoch 00019: val_logloss did not improve from 0.01711\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0204 - logloss: 0.0171 - val_loss: 0.0204 - val_logloss: 0.0171\n",
      "Epoch 20/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0200 - logloss: 0.0167\n",
      "Epoch 00020: val_logloss improved from 0.01711 to 0.01709, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0200 - logloss: 0.0167 - val_loss: 0.0205 - val_logloss: 0.0171\n",
      "Epoch 21/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0196 - logloss: 0.0164\n",
      "Epoch 00021: val_logloss improved from 0.01709 to 0.01692, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0196 - logloss: 0.0164 - val_loss: 0.0202 - val_logloss: 0.0169\n",
      "Epoch 22/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0196 - logloss: 0.0163\n",
      "Epoch 00022: val_logloss improved from 0.01692 to 0.01686, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0195 - logloss: 0.0163 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 23/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0195 - logloss: 0.0163\n",
      "Epoch 00023: val_logloss improved from 0.01686 to 0.01685, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0195 - logloss: 0.0162 - val_loss: 0.0202 - val_logloss: 0.0169\n",
      "Epoch 24/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0194 - logloss: 0.0162\n",
      "Epoch 00024: val_logloss improved from 0.01685 to 0.01683, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 25/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0194 - logloss: 0.0162\n",
      "Epoch 00025: val_logloss improved from 0.01683 to 0.01682, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0193 - logloss: 0.0161 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 26/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0194 - logloss: 0.0161\n",
      "Epoch 00026: val_logloss improved from 0.01682 to 0.01681, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 27/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00027: val_logloss did not improve from 0.01681\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0193 - logloss: 0.0162 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 28/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0194 - logloss: 0.0161\n",
      "Epoch 00028: val_logloss improved from 0.01681 to 0.01681, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 29/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00029: val_logloss improved from 0.01681 to 0.01681, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0193 - logloss: 0.0161 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 30/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0194 - logloss: 0.0162\n",
      "Epoch 00030: val_logloss improved from 0.01681 to 0.01681, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 31/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00031: val_logloss improved from 0.01681 to 0.01680, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0193 - logloss: 0.0161 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 32/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00032: val_logloss did not improve from 0.01680\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0193 - logloss: 0.0161 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 33/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00033: val_logloss improved from 0.01680 to 0.01680, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0193 - logloss: 0.0161 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 34/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0194 - logloss: 0.0162\n",
      "Epoch 00034: val_logloss improved from 0.01680 to 0.01680, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 35/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0193 - logloss: 0.0160\n",
      "Epoch 00035: val_logloss improved from 0.01680 to 0.01679, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0193 - logloss: 0.0160 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 36/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00036: val_logloss improved from 0.01679 to 0.01679, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0193 - logloss: 0.0161 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 37/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0192 - logloss: 0.0160\n",
      "Epoch 00037: val_logloss improved from 0.01679 to 0.01678, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0192 - logloss: 0.0160 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 38/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00038: val_logloss did not improve from 0.01678\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0193 - logloss: 0.0161 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 39/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0192 - logloss: 0.0160\n",
      "Epoch 00039: val_logloss did not improve from 0.01678\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0192 - logloss: 0.0161 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 40/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00040: val_logloss improved from 0.01678 to 0.01678, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0193 - logloss: 0.0161 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Fold 1 log loss: 0.01675673448994976\n",
      "Fold 2\n",
      "Epoch 1/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.4762 - logloss: 0.4756\n",
      "Epoch 00001: val_logloss improved from inf to 0.10169, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.4757 - logloss: 0.4731 - val_loss: 0.1030 - val_logloss: 0.1017\n",
      "Epoch 2/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0552 - logloss: 0.0532\n",
      "Epoch 00002: val_logloss improved from 0.10169 to 0.02897, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0552 - logloss: 0.0532 - val_loss: 0.0314 - val_logloss: 0.0290\n",
      "Epoch 3/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0293 - logloss: 0.0268\n",
      "Epoch 00003: val_logloss improved from 0.02897 to 0.02251, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0294 - logloss: 0.0269 - val_loss: 0.0252 - val_logloss: 0.0225\n",
      "Epoch 4/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0258 - logloss: 0.0230\n",
      "Epoch 00004: val_logloss improved from 0.02251 to 0.02071, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0258 - logloss: 0.0230 - val_loss: 0.0236 - val_logloss: 0.0207\n",
      "Epoch 5/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0242 - logloss: 0.0212\n",
      "Epoch 00005: val_logloss improved from 0.02071 to 0.01997, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0242 - logloss: 0.0212 - val_loss: 0.0231 - val_logloss: 0.0200\n",
      "Epoch 6/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0234 - logloss: 0.0204\n",
      "Epoch 00006: val_logloss improved from 0.01997 to 0.01926, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0234 - logloss: 0.0203 - val_loss: 0.0223 - val_logloss: 0.0193\n",
      "Epoch 7/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0229 - logloss: 0.0198\n",
      "Epoch 00007: val_logloss improved from 0.01926 to 0.01879, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0229 - logloss: 0.0198 - val_loss: 0.0219 - val_logloss: 0.0188\n",
      "Epoch 8/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0226 - logloss: 0.0195\n",
      "Epoch 00008: val_logloss improved from 0.01879 to 0.01845, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0226 - logloss: 0.0195 - val_loss: 0.0216 - val_logloss: 0.0185\n",
      "Epoch 9/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0223 - logloss: 0.0191\n",
      "Epoch 00009: val_logloss improved from 0.01845 to 0.01827, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0223 - logloss: 0.0191 - val_loss: 0.0214 - val_logloss: 0.0183\n",
      "Epoch 10/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0219 - logloss: 0.0187\n",
      "Epoch 00010: val_logloss improved from 0.01827 to 0.01793, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0219 - logloss: 0.0187 - val_loss: 0.0211 - val_logloss: 0.0179\n",
      "Epoch 11/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0217 - logloss: 0.0185\n",
      "Epoch 00011: val_logloss did not improve from 0.01793\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0217 - logloss: 0.0185 - val_loss: 0.0211 - val_logloss: 0.0179\n",
      "Epoch 12/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0215 - logloss: 0.0183\n",
      "Epoch 00012: val_logloss improved from 0.01793 to 0.01772, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0215 - logloss: 0.0183 - val_loss: 0.0209 - val_logloss: 0.0177\n",
      "Epoch 13/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0216 - logloss: 0.0183\n",
      "Epoch 00013: val_logloss improved from 0.01772 to 0.01758, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0216 - logloss: 0.0183 - val_loss: 0.0208 - val_logloss: 0.0176\n",
      "Epoch 14/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0211 - logloss: 0.0178\n",
      "Epoch 00014: val_logloss improved from 0.01758 to 0.01738, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0211 - logloss: 0.0179 - val_loss: 0.0206 - val_logloss: 0.0174\n",
      "Epoch 15/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0208 - logloss: 0.0176\n",
      "Epoch 00015: val_logloss improved from 0.01738 to 0.01724, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0208 - logloss: 0.0176 - val_loss: 0.0204 - val_logloss: 0.0172\n",
      "Epoch 16/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0206 - logloss: 0.0174\n",
      "Epoch 00016: val_logloss did not improve from 0.01724\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0206 - logloss: 0.0174 - val_loss: 0.0204 - val_logloss: 0.0172\n",
      "Epoch 17/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0205 - logloss: 0.0173\n",
      "Epoch 00017: val_logloss improved from 0.01724 to 0.01710, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0205 - logloss: 0.0172 - val_loss: 0.0204 - val_logloss: 0.0171\n",
      "Epoch 18/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0202 - logloss: 0.0170\n",
      "Epoch 00018: val_logloss improved from 0.01710 to 0.01697, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0203 - logloss: 0.0170 - val_loss: 0.0202 - val_logloss: 0.0170\n",
      "Epoch 19/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0202 - logloss: 0.0169\n",
      "Epoch 00019: val_logloss did not improve from 0.01697\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0202 - logloss: 0.0170 - val_loss: 0.0202 - val_logloss: 0.0170\n",
      "Epoch 20/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0201 - logloss: 0.0168\n",
      "Epoch 00020: val_logloss improved from 0.01697 to 0.01694, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0201 - logloss: 0.0169 - val_loss: 0.0202 - val_logloss: 0.0169\n",
      "Epoch 21/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0199 - logloss: 0.0166\n",
      "Epoch 00021: val_logloss improved from 0.01694 to 0.01684, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0199 - logloss: 0.0166 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 22/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0199 - logloss: 0.0166\n",
      "Epoch 00022: val_logloss improved from 0.01684 to 0.01677, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 0.0199 - logloss: 0.0166 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 23/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0196 - logloss: 0.0163\n",
      "Epoch 00023: val_logloss did not improve from 0.01677\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0196 - logloss: 0.0163 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 24/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0193 - logloss: 0.0160\n",
      "Epoch 00024: val_logloss did not improve from 0.01677\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0195 - logloss: 0.0162 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 25/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0191 - logloss: 0.0158\n",
      "Epoch 00025: val_logloss improved from 0.01677 to 0.01666, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0191 - logloss: 0.0158 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 26/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0190 - logloss: 0.0157\n",
      "Epoch 00026: val_logloss improved from 0.01666 to 0.01660, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0190 - logloss: 0.0157 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 27/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0189 - logloss: 0.0157\n",
      "Epoch 00027: val_logloss improved from 0.01660 to 0.01656, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0189 - logloss: 0.0156 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 28/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0188 - logloss: 0.0155\n",
      "Epoch 00028: val_logloss improved from 0.01656 to 0.01652, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0188 - logloss: 0.0155 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 29/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0187 - logloss: 0.0155\n",
      "Epoch 00029: val_logloss improved from 0.01652 to 0.01650, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0188 - logloss: 0.0155 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 30/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0187 - logloss: 0.0154\n",
      "Epoch 00030: val_logloss improved from 0.01650 to 0.01650, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0187 - logloss: 0.0155 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 31/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0186 - logloss: 0.0153\n",
      "Epoch 00031: val_logloss improved from 0.01650 to 0.01647, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0186 - logloss: 0.0153 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 32/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00032: val_logloss improved from 0.01647 to 0.01647, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 33/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00033: val_logloss improved from 0.01647 to 0.01647, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 34/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00034: val_logloss did not improve from 0.01647\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0185 - logloss: 0.0152 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 35/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0186 - logloss: 0.0153\n",
      "Epoch 00035: val_logloss improved from 0.01647 to 0.01647, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 36/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0186 - logloss: 0.0153\n",
      "Epoch 00036: val_logloss did not improve from 0.01647\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0186 - logloss: 0.0153 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 37/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0184 - logloss: 0.0152\n",
      "Epoch 00037: val_logloss improved from 0.01647 to 0.01646, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0184 - logloss: 0.0152 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 38/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0184 - logloss: 0.0152\n",
      "Epoch 00038: val_logloss improved from 0.01646 to 0.01646, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0184 - logloss: 0.0152 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 39/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0186 - logloss: 0.0153\n",
      "Epoch 00039: val_logloss improved from 0.01646 to 0.01646, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0186 - logloss: 0.0153 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 40/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00040: val_logloss did not improve from 0.01646\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0185 - logloss: 0.0152 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Fold 2 log loss: 0.016351628973125303\n",
      "Fold 3\n",
      "Epoch 1/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.4863 - logloss: 0.4858\n",
      "Epoch 00001: val_logloss improved from inf to 0.10468, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.4779 - logloss: 0.4753 - val_loss: 0.1059 - val_logloss: 0.1047\n",
      "Epoch 2/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0561 - logloss: 0.0543\n",
      "Epoch 00002: val_logloss improved from 0.10468 to 0.02979, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0557 - logloss: 0.0537 - val_loss: 0.0321 - val_logloss: 0.0298\n",
      "Epoch 3/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0293 - logloss: 0.0269\n",
      "Epoch 00003: val_logloss improved from 0.02979 to 0.02282, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0293 - logloss: 0.0269 - val_loss: 0.0255 - val_logloss: 0.0228\n",
      "Epoch 4/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0257 - logloss: 0.0229\n",
      "Epoch 00004: val_logloss improved from 0.02282 to 0.02125, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0256 - logloss: 0.0229 - val_loss: 0.0241 - val_logloss: 0.0213\n",
      "Epoch 5/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0242 - logloss: 0.0213\n",
      "Epoch 00005: val_logloss improved from 0.02125 to 0.01984, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0242 - logloss: 0.0213 - val_loss: 0.0228 - val_logloss: 0.0198\n",
      "Epoch 6/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0233 - logloss: 0.0203\n",
      "Epoch 00006: val_logloss improved from 0.01984 to 0.01913, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0233 - logloss: 0.0203 - val_loss: 0.0221 - val_logloss: 0.0191\n",
      "Epoch 7/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0229 - logloss: 0.0198\n",
      "Epoch 00007: val_logloss improved from 0.01913 to 0.01875, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0229 - logloss: 0.0198 - val_loss: 0.0218 - val_logloss: 0.0188\n",
      "Epoch 8/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0224 - logloss: 0.0193\n",
      "Epoch 00008: val_logloss improved from 0.01875 to 0.01848, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0224 - logloss: 0.0193 - val_loss: 0.0216 - val_logloss: 0.0185\n",
      "Epoch 9/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0220 - logloss: 0.0189\n",
      "Epoch 00009: val_logloss improved from 0.01848 to 0.01818, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0220 - logloss: 0.0189 - val_loss: 0.0212 - val_logloss: 0.0182\n",
      "Epoch 10/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0218 - logloss: 0.0187\n",
      "Epoch 00010: val_logloss did not improve from 0.01818\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0218 - logloss: 0.0187 - val_loss: 0.0214 - val_logloss: 0.0182\n",
      "Epoch 11/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0216 - logloss: 0.0184\n",
      "Epoch 00011: val_logloss improved from 0.01818 to 0.01781, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0216 - logloss: 0.0184 - val_loss: 0.0209 - val_logloss: 0.0178\n",
      "Epoch 12/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0214 - logloss: 0.0182\n",
      "Epoch 00012: val_logloss improved from 0.01781 to 0.01767, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0214 - logloss: 0.0182 - val_loss: 0.0208 - val_logloss: 0.0177\n",
      "Epoch 13/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0212 - logloss: 0.0180\n",
      "Epoch 00013: val_logloss improved from 0.01767 to 0.01756, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0212 - logloss: 0.0180 - val_loss: 0.0207 - val_logloss: 0.0176\n",
      "Epoch 14/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0210 - logloss: 0.0178\n",
      "Epoch 00014: val_logloss improved from 0.01756 to 0.01754, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0210 - logloss: 0.0178 - val_loss: 0.0210 - val_logloss: 0.0175\n",
      "Epoch 15/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0208 - logloss: 0.0176\n",
      "Epoch 00015: val_logloss improved from 0.01754 to 0.01728, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0208 - logloss: 0.0177 - val_loss: 0.0204 - val_logloss: 0.0173\n",
      "Epoch 16/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0206 - logloss: 0.0174\n",
      "Epoch 00016: val_logloss improved from 0.01728 to 0.01719, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0207 - logloss: 0.0174 - val_loss: 0.0204 - val_logloss: 0.0172\n",
      "Epoch 17/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0206 - logloss: 0.0174\n",
      "Epoch 00017: val_logloss improved from 0.01719 to 0.01704, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0206 - logloss: 0.0174 - val_loss: 0.0202 - val_logloss: 0.0170\n",
      "Epoch 18/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0204 - logloss: 0.0171\n",
      "Epoch 00018: val_logloss did not improve from 0.01704\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0204 - logloss: 0.0172 - val_loss: 0.0205 - val_logloss: 0.0173\n",
      "Epoch 19/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0205 - logloss: 0.0172\n",
      "Epoch 00019: val_logloss did not improve from 0.01704\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0205 - logloss: 0.0172 - val_loss: 0.0203 - val_logloss: 0.0171\n",
      "Epoch 20/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0200 - logloss: 0.0168\n",
      "Epoch 00020: val_logloss improved from 0.01704 to 0.01698, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0200 - logloss: 0.0168 - val_loss: 0.0203 - val_logloss: 0.0170\n",
      "Epoch 21/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0198 - logloss: 0.0165\n",
      "Epoch 00021: val_logloss improved from 0.01698 to 0.01682, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0197 - logloss: 0.0165 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 22/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0196 - logloss: 0.0164\n",
      "Epoch 00022: val_logloss improved from 0.01682 to 0.01677, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0196 - logloss: 0.0164 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 23/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0196 - logloss: 0.0164\n",
      "Epoch 00023: val_logloss improved from 0.01677 to 0.01675, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0196 - logloss: 0.0164 - val_loss: 0.0199 - val_logloss: 0.0168\n",
      "Epoch 24/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0196 - logloss: 0.0164\n",
      "Epoch 00024: val_logloss improved from 0.01675 to 0.01673, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0196 - logloss: 0.0164 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 25/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0195 - logloss: 0.0162\n",
      "Epoch 00025: val_logloss improved from 0.01673 to 0.01673, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 26/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0194 - logloss: 0.0162\n",
      "Epoch 00026: val_logloss improved from 0.01673 to 0.01672, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 27/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0195 - logloss: 0.0163\n",
      "Epoch 00027: val_logloss improved from 0.01672 to 0.01672, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0195 - logloss: 0.0163 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 28/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0194 - logloss: 0.0162\n",
      "Epoch 00028: val_logloss improved from 0.01672 to 0.01672, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 29/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0194 - logloss: 0.0162\n",
      "Epoch 00029: val_logloss improved from 0.01672 to 0.01671, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 30/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0194 - logloss: 0.0162\n",
      "Epoch 00030: val_logloss improved from 0.01671 to 0.01671, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 31/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0194 - logloss: 0.0162\n",
      "Epoch 00031: val_logloss improved from 0.01671 to 0.01670, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 32/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00032: val_logloss improved from 0.01670 to 0.01670, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 33/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0194 - logloss: 0.0161\n",
      "Epoch 00033: val_logloss improved from 0.01670 to 0.01670, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 34/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0194 - logloss: 0.0162\n",
      "Epoch 00034: val_logloss did not improve from 0.01670\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 35/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0194 - logloss: 0.0162\n",
      "Epoch 00035: val_logloss improved from 0.01670 to 0.01670, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 36/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0194 - logloss: 0.0161\n",
      "Epoch 00036: val_logloss did not improve from 0.01670\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 37/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00037: val_logloss improved from 0.01670 to 0.01669, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 38/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00038: val_logloss improved from 0.01669 to 0.01669, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0193 - logloss: 0.0161 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 39/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00039: val_logloss improved from 0.01669 to 0.01669, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0193 - logloss: 0.0161 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 40/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00040: val_logloss improved from 0.01669 to 0.01668, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0193 - logloss: 0.0161 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Fold 3 log loss: 0.01655961723187355\n",
      "Fold 4\n",
      "Epoch 1/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.4925 - logloss: 0.4920\n",
      "Epoch 00001: val_logloss improved from inf to 0.10762, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.4761 - logloss: 0.4734 - val_loss: 0.1087 - val_logloss: 0.1076\n",
      "Epoch 2/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0567 - logloss: 0.0549\n",
      "Epoch 00002: val_logloss improved from 0.10762 to 0.02876, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0562 - logloss: 0.0542 - val_loss: 0.0310 - val_logloss: 0.0288\n",
      "Epoch 3/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0296 - logloss: 0.0271\n",
      "Epoch 00003: val_logloss improved from 0.02876 to 0.02287, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0295 - logloss: 0.0270 - val_loss: 0.0256 - val_logloss: 0.0229\n",
      "Epoch 4/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0255 - logloss: 0.0227\n",
      "Epoch 00004: val_logloss improved from 0.02287 to 0.02056, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0255 - logloss: 0.0228 - val_loss: 0.0234 - val_logloss: 0.0206\n",
      "Epoch 5/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0245 - logloss: 0.0215\n",
      "Epoch 00005: val_logloss improved from 0.02056 to 0.01995, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0245 - logloss: 0.0215 - val_loss: 0.0229 - val_logloss: 0.0199\n",
      "Epoch 6/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0236 - logloss: 0.0205\n",
      "Epoch 00006: val_logloss improved from 0.01995 to 0.01912, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0236 - logloss: 0.0204 - val_loss: 0.0222 - val_logloss: 0.0191\n",
      "Epoch 7/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0231 - logloss: 0.0200\n",
      "Epoch 00007: val_logloss improved from 0.01912 to 0.01880, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0231 - logloss: 0.0200 - val_loss: 0.0219 - val_logloss: 0.0188\n",
      "Epoch 8/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0225 - logloss: 0.0193\n",
      "Epoch 00008: val_logloss improved from 0.01880 to 0.01824, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0225 - logloss: 0.0194 - val_loss: 0.0214 - val_logloss: 0.0182\n",
      "Epoch 9/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0223 - logloss: 0.0191\n",
      "Epoch 00009: val_logloss did not improve from 0.01824\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0223 - logloss: 0.0191 - val_loss: 0.0216 - val_logloss: 0.0184\n",
      "Epoch 10/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0220 - logloss: 0.0188\n",
      "Epoch 00010: val_logloss improved from 0.01824 to 0.01789, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0220 - logloss: 0.0188 - val_loss: 0.0211 - val_logloss: 0.0179\n",
      "Epoch 11/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0217 - logloss: 0.0185\n",
      "Epoch 00011: val_logloss improved from 0.01789 to 0.01766, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0217 - logloss: 0.0185 - val_loss: 0.0209 - val_logloss: 0.0177\n",
      "Epoch 12/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0215 - logloss: 0.0182\n",
      "Epoch 00012: val_logloss improved from 0.01766 to 0.01753, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0215 - logloss: 0.0182 - val_loss: 0.0207 - val_logloss: 0.0175\n",
      "Epoch 13/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0213 - logloss: 0.0181\n",
      "Epoch 00013: val_logloss improved from 0.01753 to 0.01737, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0213 - logloss: 0.0181 - val_loss: 0.0206 - val_logloss: 0.0174\n",
      "Epoch 14/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0210 - logloss: 0.0178\n",
      "Epoch 00014: val_logloss improved from 0.01737 to 0.01728, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0210 - logloss: 0.0178 - val_loss: 0.0205 - val_logloss: 0.0173\n",
      "Epoch 15/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0208 - logloss: 0.0176\n",
      "Epoch 00015: val_logloss improved from 0.01728 to 0.01715, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0208 - logloss: 0.0176 - val_loss: 0.0204 - val_logloss: 0.0171\n",
      "Epoch 16/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0208 - logloss: 0.0175\n",
      "Epoch 00016: val_logloss did not improve from 0.01715\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0208 - logloss: 0.0175 - val_loss: 0.0205 - val_logloss: 0.0173\n",
      "Epoch 17/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0204 - logloss: 0.0172\n",
      "Epoch 00017: val_logloss improved from 0.01715 to 0.01692, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0205 - logloss: 0.0172 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 18/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0206 - logloss: 0.0173\n",
      "Epoch 00018: val_logloss improved from 0.01692 to 0.01691, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0206 - logloss: 0.0173 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 19/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0203 - logloss: 0.0170\n",
      "Epoch 00019: val_logloss improved from 0.01691 to 0.01690, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0203 - logloss: 0.0170 - val_loss: 0.0203 - val_logloss: 0.0169\n",
      "Epoch 20/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0200 - logloss: 0.0168\n",
      "Epoch 00020: val_logloss improved from 0.01690 to 0.01677, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0200 - logloss: 0.0168 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 21/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0198 - logloss: 0.0166\n",
      "Epoch 00021: val_logloss improved from 0.01677 to 0.01677, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0198 - logloss: 0.0165 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 22/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0196 - logloss: 0.0164\n",
      "Epoch 00022: val_logloss improved from 0.01677 to 0.01667, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0196 - logloss: 0.0164 - val_loss: 0.0200 - val_logloss: 0.0167\n",
      "Epoch 23/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0195 - logloss: 0.0163\n",
      "Epoch 00023: val_logloss improved from 0.01667 to 0.01661, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0195 - logloss: 0.0163 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 24/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00024: val_logloss improved from 0.01661 to 0.01650, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0193 - logloss: 0.0161 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 25/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0191 - logloss: 0.0159\n",
      "Epoch 00025: val_logloss did not improve from 0.01650\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0191 - logloss: 0.0159 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 26/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0190 - logloss: 0.0157\n",
      "Epoch 00026: val_logloss improved from 0.01650 to 0.01642, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0190 - logloss: 0.0157 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 27/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0188 - logloss: 0.0156\n",
      "Epoch 00027: val_logloss did not improve from 0.01642\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0189 - logloss: 0.0156 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 28/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0152\n",
      "Epoch 00028: val_logloss improved from 0.01642 to 0.01635, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0185 - logloss: 0.0152 - val_loss: 0.0197 - val_logloss: 0.0163\n",
      "Epoch 29/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0183 - logloss: 0.0150\n",
      "Epoch 00029: val_logloss improved from 0.01635 to 0.01631, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0183 - logloss: 0.0151 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 30/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0183 - logloss: 0.0150\n",
      "Epoch 00030: val_logloss improved from 0.01631 to 0.01628, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0183 - logloss: 0.0150 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 31/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0182 - logloss: 0.0150\n",
      "Epoch 00031: val_logloss improved from 0.01628 to 0.01626, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0182 - logloss: 0.0150 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 32/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0181 - logloss: 0.0148\n",
      "Epoch 00032: val_logloss improved from 0.01626 to 0.01626, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0181 - logloss: 0.0148 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 33/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0182 - logloss: 0.0149\n",
      "Epoch 00033: val_logloss improved from 0.01626 to 0.01625, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0181 - logloss: 0.0148 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 34/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0181 - logloss: 0.0148\n",
      "Epoch 00034: val_logloss improved from 0.01625 to 0.01625, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0181 - logloss: 0.0149 - val_loss: 0.0196 - val_logloss: 0.0163\n",
      "Epoch 35/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0181 - logloss: 0.0148\n",
      "Epoch 00035: val_logloss improved from 0.01625 to 0.01625, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0181 - logloss: 0.0148 - val_loss: 0.0196 - val_logloss: 0.0162\n",
      "Epoch 36/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0181 - logloss: 0.0148\n",
      "Epoch 00036: val_logloss improved from 0.01625 to 0.01625, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0181 - logloss: 0.0148 - val_loss: 0.0196 - val_logloss: 0.0162\n",
      "Epoch 37/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0181 - logloss: 0.0148\n",
      "Epoch 00037: val_logloss improved from 0.01625 to 0.01624, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0181 - logloss: 0.0148 - val_loss: 0.0196 - val_logloss: 0.0162\n",
      "Epoch 38/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0180 - logloss: 0.0148\n",
      "Epoch 00038: val_logloss improved from 0.01624 to 0.01624, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0180 - logloss: 0.0148 - val_loss: 0.0196 - val_logloss: 0.0162\n",
      "Epoch 39/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0180 - logloss: 0.0148\n",
      "Epoch 00039: val_logloss did not improve from 0.01624\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0180 - logloss: 0.0147 - val_loss: 0.0196 - val_logloss: 0.0162\n",
      "Epoch 40/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0181 - logloss: 0.0148\n",
      "Epoch 00040: val_logloss improved from 0.01624 to 0.01624, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0181 - logloss: 0.0148 - val_loss: 0.0196 - val_logloss: 0.0162\n",
      "Fold 4 log loss: 0.01613183973492526\n",
      "Fold 5\n",
      "Epoch 1/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.4806 - logloss: 0.4801\n",
      "Epoch 00001: val_logloss improved from inf to 0.10422, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.4775 - logloss: 0.4748 - val_loss: 0.1054 - val_logloss: 0.1042\n",
      "Epoch 2/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0552 - logloss: 0.0532\n",
      "Epoch 00002: val_logloss improved from 0.10422 to 0.02839, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0552 - logloss: 0.0532 - val_loss: 0.0306 - val_logloss: 0.0284\n",
      "Epoch 3/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0300 - logloss: 0.0274\n",
      "Epoch 00003: val_logloss improved from 0.02839 to 0.02349, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0300 - logloss: 0.0274 - val_loss: 0.0261 - val_logloss: 0.0235\n",
      "Epoch 4/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0258 - logloss: 0.0230\n",
      "Epoch 00004: val_logloss improved from 0.02349 to 0.02097, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0257 - logloss: 0.0229 - val_loss: 0.0238 - val_logloss: 0.0210\n",
      "Epoch 5/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0243 - logloss: 0.0213\n",
      "Epoch 00005: val_logloss improved from 0.02097 to 0.02001, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0242 - logloss: 0.0213 - val_loss: 0.0229 - val_logloss: 0.0200\n",
      "Epoch 6/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0237 - logloss: 0.0206\n",
      "Epoch 00006: val_logloss improved from 0.02001 to 0.01970, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0237 - logloss: 0.0206 - val_loss: 0.0227 - val_logloss: 0.0197\n",
      "Epoch 7/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0229 - logloss: 0.0198\n",
      "Epoch 00007: val_logloss improved from 0.01970 to 0.01891, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0229 - logloss: 0.0198 - val_loss: 0.0220 - val_logloss: 0.0189\n",
      "Epoch 8/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0225 - logloss: 0.0194\n",
      "Epoch 00008: val_logloss improved from 0.01891 to 0.01876, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0225 - logloss: 0.0193 - val_loss: 0.0218 - val_logloss: 0.0188\n",
      "Epoch 9/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0223 - logloss: 0.0191\n",
      "Epoch 00009: val_logloss improved from 0.01876 to 0.01845, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0223 - logloss: 0.0191 - val_loss: 0.0216 - val_logloss: 0.0185\n",
      "Epoch 10/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0220 - logloss: 0.0190\n",
      "Epoch 00010: val_logloss improved from 0.01845 to 0.01823, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0220 - logloss: 0.0190 - val_loss: 0.0213 - val_logloss: 0.0182\n",
      "Epoch 11/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0220 - logloss: 0.0188\n",
      "Epoch 00011: val_logloss improved from 0.01823 to 0.01812, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0220 - logloss: 0.0188 - val_loss: 0.0214 - val_logloss: 0.0181\n",
      "Epoch 12/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0216 - logloss: 0.0184\n",
      "Epoch 00012: val_logloss improved from 0.01812 to 0.01783, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0216 - logloss: 0.0183 - val_loss: 0.0209 - val_logloss: 0.0178\n",
      "Epoch 13/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0212 - logloss: 0.0180\n",
      "Epoch 00013: val_logloss improved from 0.01783 to 0.01765, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0212 - logloss: 0.0180 - val_loss: 0.0207 - val_logloss: 0.0176\n",
      "Epoch 14/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0212 - logloss: 0.0179\n",
      "Epoch 00014: val_logloss improved from 0.01765 to 0.01764, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0212 - logloss: 0.0180 - val_loss: 0.0208 - val_logloss: 0.0176\n",
      "Epoch 15/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0210 - logloss: 0.0178\n",
      "Epoch 00015: val_logloss improved from 0.01764 to 0.01754, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0210 - logloss: 0.0178 - val_loss: 0.0207 - val_logloss: 0.0175\n",
      "Epoch 16/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0208 - logloss: 0.0176\n",
      "Epoch 00016: val_logloss improved from 0.01754 to 0.01737, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0208 - logloss: 0.0176 - val_loss: 0.0205 - val_logloss: 0.0174\n",
      "Epoch 17/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0206 - logloss: 0.0174\n",
      "Epoch 00017: val_logloss improved from 0.01737 to 0.01725, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0206 - logloss: 0.0174 - val_loss: 0.0204 - val_logloss: 0.0172\n",
      "Epoch 18/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0204 - logloss: 0.0172\n",
      "Epoch 00018: val_logloss improved from 0.01725 to 0.01718, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0204 - logloss: 0.0172 - val_loss: 0.0204 - val_logloss: 0.0172\n",
      "Epoch 19/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0201 - logloss: 0.0170\n",
      "Epoch 00019: val_logloss improved from 0.01718 to 0.01711, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0201 - logloss: 0.0169 - val_loss: 0.0203 - val_logloss: 0.0171\n",
      "Epoch 20/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0201 - logloss: 0.0169\n",
      "Epoch 00020: val_logloss improved from 0.01711 to 0.01701, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0201 - logloss: 0.0169 - val_loss: 0.0202 - val_logloss: 0.0170\n",
      "Epoch 21/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0199 - logloss: 0.0167\n",
      "Epoch 00021: val_logloss did not improve from 0.01701\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0199 - logloss: 0.0168 - val_loss: 0.0202 - val_logloss: 0.0170\n",
      "Epoch 22/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0199 - logloss: 0.0167\n",
      "Epoch 00022: val_logloss improved from 0.01701 to 0.01698, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0199 - logloss: 0.0167 - val_loss: 0.0202 - val_logloss: 0.0170\n",
      "Epoch 23/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0197 - logloss: 0.0164\n",
      "Epoch 00023: val_logloss improved from 0.01698 to 0.01687, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0197 - logloss: 0.0164 - val_loss: 0.0200 - val_logloss: 0.0169\n",
      "Epoch 24/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0196 - logloss: 0.0163\n",
      "Epoch 00024: val_logloss did not improve from 0.01687\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0196 - logloss: 0.0163 - val_loss: 0.0202 - val_logloss: 0.0169\n",
      "Epoch 25/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0194 - logloss: 0.0161\n",
      "Epoch 00025: val_logloss improved from 0.01687 to 0.01680, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0194 - logloss: 0.0161 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 26/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0196 - logloss: 0.0163\n",
      "Epoch 00026: val_logloss did not improve from 0.01680\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0196 - logloss: 0.0162 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 27/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0192 - logloss: 0.0159\n",
      "Epoch 00027: val_logloss improved from 0.01680 to 0.01677, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0192 - logloss: 0.0159 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 28/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0190 - logloss: 0.0157\n",
      "Epoch 00028: val_logloss improved from 0.01677 to 0.01672, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0189 - logloss: 0.0156 - val_loss: 0.0200 - val_logloss: 0.0167\n",
      "Epoch 29/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0189 - logloss: 0.0156\n",
      "Epoch 00029: val_logloss improved from 0.01672 to 0.01668, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0189 - logloss: 0.0156 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 30/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0188 - logloss: 0.0155\n",
      "Epoch 00030: val_logloss improved from 0.01668 to 0.01666, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0188 - logloss: 0.0155 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 31/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0187 - logloss: 0.0155\n",
      "Epoch 00031: val_logloss improved from 0.01666 to 0.01664, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0187 - logloss: 0.0154 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 32/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0188 - logloss: 0.0155\n",
      "Epoch 00032: val_logloss did not improve from 0.01664\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0188 - logloss: 0.0154 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 33/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0187 - logloss: 0.0154\n",
      "Epoch 00033: val_logloss improved from 0.01664 to 0.01662, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0187 - logloss: 0.0154 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 34/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0186 - logloss: 0.0153\n",
      "Epoch 00034: val_logloss improved from 0.01662 to 0.01661, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0186 - logloss: 0.0153 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 35/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0152\n",
      "Epoch 00035: val_logloss improved from 0.01661 to 0.01661, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 36/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0186 - logloss: 0.0153\n",
      "Epoch 00036: val_logloss did not improve from 0.01661\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0186 - logloss: 0.0153 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 37/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0186 - logloss: 0.0153\n",
      "Epoch 00037: val_logloss did not improve from 0.01661\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0186 - logloss: 0.0153 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 38/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0185 - logloss: 0.0152\n",
      "Epoch 00038: val_logloss did not improve from 0.01661\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0185 - logloss: 0.0152 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 39/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0185 - logloss: 0.0152\n",
      "Epoch 00039: val_logloss did not improve from 0.01661\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0185 - logloss: 0.0152 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 40/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0184 - logloss: 0.0152\n",
      "Epoch 00040: val_logloss improved from 0.01661 to 0.01660, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Fold 5 log loss: 0.016451601610396945\n",
      "Seed 0\n",
      "Fold 1 log loss: 0.01675673448994976\n",
      "Fold 2 log loss: 0.016351628973125303\n",
      "Fold 3 log loss: 0.01655961723187355\n",
      "Fold 4 log loss: 0.01613183973492526\n",
      "Fold 5 log loss: 0.016451601610396945\n",
      "Std of log loss: 0.00020833000684746628\n",
      "Total log loss: 0.016450288843001884\n",
      "Fold 1\n",
      "Epoch 1/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.4833 - logloss: 0.4828\n",
      "Epoch 00001: val_logloss improved from inf to 0.11088, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.4829 - logloss: 0.4803 - val_loss: 0.1124 - val_logloss: 0.1109\n",
      "Epoch 2/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0561 - logloss: 0.0543\n",
      "Epoch 00002: val_logloss improved from 0.11088 to 0.02887, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0555 - logloss: 0.0535 - val_loss: 0.0313 - val_logloss: 0.0289\n",
      "Epoch 3/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0291 - logloss: 0.0266\n",
      "Epoch 00003: val_logloss improved from 0.02887 to 0.02326, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0291 - logloss: 0.0266 - val_loss: 0.0259 - val_logloss: 0.0233\n",
      "Epoch 4/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0259 - logloss: 0.0231\n",
      "Epoch 00004: val_logloss improved from 0.02326 to 0.02174, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0259 - logloss: 0.0231 - val_loss: 0.0247 - val_logloss: 0.0217\n",
      "Epoch 5/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0241 - logloss: 0.0212\n",
      "Epoch 00005: val_logloss improved from 0.02174 to 0.01980, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0241 - logloss: 0.0212 - val_loss: 0.0228 - val_logloss: 0.0198\n",
      "Epoch 6/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0234 - logloss: 0.0204\n",
      "Epoch 00006: val_logloss improved from 0.01980 to 0.01934, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0234 - logloss: 0.0204 - val_loss: 0.0224 - val_logloss: 0.0193\n",
      "Epoch 7/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0228 - logloss: 0.0197\n",
      "Epoch 00007: val_logloss improved from 0.01934 to 0.01882, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0228 - logloss: 0.0197 - val_loss: 0.0220 - val_logloss: 0.0188\n",
      "Epoch 8/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0224 - logloss: 0.0192\n",
      "Epoch 00008: val_logloss improved from 0.01882 to 0.01867, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0224 - logloss: 0.0192 - val_loss: 0.0219 - val_logloss: 0.0187\n",
      "Epoch 9/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0222 - logloss: 0.0190\n",
      "Epoch 00009: val_logloss improved from 0.01867 to 0.01838, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0222 - logloss: 0.0190 - val_loss: 0.0216 - val_logloss: 0.0184\n",
      "Epoch 10/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0218 - logloss: 0.0187\n",
      "Epoch 00010: val_logloss improved from 0.01838 to 0.01810, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0218 - logloss: 0.0186 - val_loss: 0.0213 - val_logloss: 0.0181\n",
      "Epoch 11/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0218 - logloss: 0.0186\n",
      "Epoch 00011: val_logloss improved from 0.01810 to 0.01805, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0218 - logloss: 0.0186 - val_loss: 0.0213 - val_logloss: 0.0181\n",
      "Epoch 12/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0214 - logloss: 0.0182\n",
      "Epoch 00012: val_logloss improved from 0.01805 to 0.01777, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0214 - logloss: 0.0182 - val_loss: 0.0211 - val_logloss: 0.0178\n",
      "Epoch 13/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0212 - logloss: 0.0180\n",
      "Epoch 00013: val_logloss did not improve from 0.01777\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0213 - logloss: 0.0181 - val_loss: 0.0211 - val_logloss: 0.0178\n",
      "Epoch 14/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0211 - logloss: 0.0178\n",
      "Epoch 00014: val_logloss improved from 0.01777 to 0.01756, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0211 - logloss: 0.0179 - val_loss: 0.0210 - val_logloss: 0.0176\n",
      "Epoch 15/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0209 - logloss: 0.0177\n",
      "Epoch 00015: val_logloss did not improve from 0.01756\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0209 - logloss: 0.0177 - val_loss: 0.0210 - val_logloss: 0.0177\n",
      "Epoch 16/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0207 - logloss: 0.0174\n",
      "Epoch 00016: val_logloss improved from 0.01756 to 0.01730, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0207 - logloss: 0.0174 - val_loss: 0.0207 - val_logloss: 0.0173\n",
      "Epoch 17/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0205 - logloss: 0.0172\n",
      "Epoch 00017: val_logloss improved from 0.01730 to 0.01718, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0205 - logloss: 0.0173 - val_loss: 0.0205 - val_logloss: 0.0172\n",
      "Epoch 18/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0203 - logloss: 0.0171\n",
      "Epoch 00018: val_logloss improved from 0.01718 to 0.01716, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0203 - logloss: 0.0171 - val_loss: 0.0204 - val_logloss: 0.0172\n",
      "Epoch 19/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0203 - logloss: 0.0170\n",
      "Epoch 00019: val_logloss improved from 0.01716 to 0.01705, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0203 - logloss: 0.0170 - val_loss: 0.0203 - val_logloss: 0.0170\n",
      "Epoch 20/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0199 - logloss: 0.0167\n",
      "Epoch 00020: val_logloss did not improve from 0.01705\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0199 - logloss: 0.0167 - val_loss: 0.0205 - val_logloss: 0.0171\n",
      "Epoch 21/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0198 - logloss: 0.0166\n",
      "Epoch 00021: val_logloss improved from 0.01705 to 0.01690, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0198 - logloss: 0.0166 - val_loss: 0.0202 - val_logloss: 0.0169\n",
      "Epoch 22/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0196 - logloss: 0.0164\n",
      "Epoch 00022: val_logloss improved from 0.01690 to 0.01686, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0196 - logloss: 0.0164 - val_loss: 0.0202 - val_logloss: 0.0169\n",
      "Epoch 23/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0195 - logloss: 0.0162\n",
      "Epoch 00023: val_logloss improved from 0.01686 to 0.01681, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0195 - logloss: 0.0162 - val_loss: 0.0202 - val_logloss: 0.0168\n",
      "Epoch 24/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0192 - logloss: 0.0160\n",
      "Epoch 00024: val_logloss improved from 0.01681 to 0.01671, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0192 - logloss: 0.0160 - val_loss: 0.0201 - val_logloss: 0.0167\n",
      "Epoch 25/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0191 - logloss: 0.0158\n",
      "Epoch 00025: val_logloss improved from 0.01671 to 0.01668, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0191 - logloss: 0.0158 - val_loss: 0.0200 - val_logloss: 0.0167\n",
      "Epoch 26/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0189 - logloss: 0.0157\n",
      "Epoch 00026: val_logloss did not improve from 0.01668\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0189 - logloss: 0.0156 - val_loss: 0.0201 - val_logloss: 0.0167\n",
      "Epoch 27/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0188 - logloss: 0.0155\n",
      "Epoch 00027: val_logloss improved from 0.01668 to 0.01667, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0188 - logloss: 0.0155 - val_loss: 0.0201 - val_logloss: 0.0167\n",
      "Epoch 28/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0183 - logloss: 0.0151\n",
      "Epoch 00028: val_logloss improved from 0.01667 to 0.01657, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 0.0183 - logloss: 0.0151 - val_loss: 0.0200 - val_logloss: 0.0166\n",
      "Epoch 29/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0183 - logloss: 0.0150\n",
      "Epoch 00029: val_logloss improved from 0.01657 to 0.01653, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0182 - logloss: 0.0150 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 30/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0181 - logloss: 0.0149\n",
      "Epoch 00030: val_logloss improved from 0.01653 to 0.01652, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0181 - logloss: 0.0149 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 31/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0181 - logloss: 0.0149\n",
      "Epoch 00031: val_logloss improved from 0.01652 to 0.01650, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0181 - logloss: 0.0149 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 32/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0181 - logloss: 0.0148\n",
      "Epoch 00032: val_logloss improved from 0.01650 to 0.01649, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0180 - logloss: 0.0148 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 33/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0180 - logloss: 0.0148\n",
      "Epoch 00033: val_logloss improved from 0.01649 to 0.01649, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0180 - logloss: 0.0148 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 34/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0180 - logloss: 0.0147\n",
      "Epoch 00034: val_logloss improved from 0.01649 to 0.01649, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0180 - logloss: 0.0147 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 35/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0180 - logloss: 0.0147\n",
      "Epoch 00035: val_logloss improved from 0.01649 to 0.01648, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0180 - logloss: 0.0147 - val_loss: 0.0199 - val_logloss: 0.0165\n",
      "Epoch 36/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0179 - logloss: 0.0147\n",
      "Epoch 00036: val_logloss improved from 0.01648 to 0.01648, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0179 - logloss: 0.0147 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 37/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0180 - logloss: 0.0147\n",
      "Epoch 00037: val_logloss improved from 0.01648 to 0.01648, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0180 - logloss: 0.0148 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 38/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0180 - logloss: 0.0147\n",
      "Epoch 00038: val_logloss improved from 0.01648 to 0.01648, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0180 - logloss: 0.0147 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 39/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0179 - logloss: 0.0146\n",
      "Epoch 00039: val_logloss improved from 0.01648 to 0.01647, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0179 - logloss: 0.0147 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 40/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0179 - logloss: 0.0147\n",
      "Epoch 00040: val_logloss improved from 0.01647 to 0.01647, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0179 - logloss: 0.0147 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Fold 1 log loss: 0.016423752166919454\n",
      "Fold 2\n",
      "Epoch 1/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.4780 - logloss: 0.4775\n",
      "Epoch 00001: val_logloss improved from inf to 0.10528, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.4775 - logloss: 0.4749 - val_loss: 0.1066 - val_logloss: 0.1053\n",
      "Epoch 2/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0560 - logloss: 0.0542\n",
      "Epoch 00002: val_logloss improved from 0.10528 to 0.02782, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0553 - logloss: 0.0533 - val_loss: 0.0301 - val_logloss: 0.0278\n",
      "Epoch 3/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0295 - logloss: 0.0271\n",
      "Epoch 00003: val_logloss improved from 0.02782 to 0.02288, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0294 - logloss: 0.0269 - val_loss: 0.0257 - val_logloss: 0.0229\n",
      "Epoch 4/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0256 - logloss: 0.0228\n",
      "Epoch 00004: val_logloss improved from 0.02288 to 0.02063, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0255 - logloss: 0.0228 - val_loss: 0.0235 - val_logloss: 0.0206\n",
      "Epoch 5/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0242 - logloss: 0.0213\n",
      "Epoch 00005: val_logloss improved from 0.02063 to 0.01987, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0242 - logloss: 0.0213 - val_loss: 0.0229 - val_logloss: 0.0199\n",
      "Epoch 6/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0236 - logloss: 0.0206\n",
      "Epoch 00006: val_logloss improved from 0.01987 to 0.01956, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0236 - logloss: 0.0206 - val_loss: 0.0226 - val_logloss: 0.0196\n",
      "Epoch 7/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0231 - logloss: 0.0200\n",
      "Epoch 00007: val_logloss improved from 0.01956 to 0.01889, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0231 - logloss: 0.0200 - val_loss: 0.0220 - val_logloss: 0.0189\n",
      "Epoch 8/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0226 - logloss: 0.0195\n",
      "Epoch 00008: val_logloss improved from 0.01889 to 0.01858, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0226 - logloss: 0.0195 - val_loss: 0.0217 - val_logloss: 0.0186\n",
      "Epoch 9/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0222 - logloss: 0.0191\n",
      "Epoch 00009: val_logloss improved from 0.01858 to 0.01826, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0222 - logloss: 0.0191 - val_loss: 0.0214 - val_logloss: 0.0183\n",
      "Epoch 10/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0219 - logloss: 0.0188\n",
      "Epoch 00010: val_logloss improved from 0.01826 to 0.01805, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 0.0219 - logloss: 0.0188 - val_loss: 0.0212 - val_logloss: 0.0180\n",
      "Epoch 11/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0216 - logloss: 0.0184\n",
      "Epoch 00011: val_logloss improved from 0.01805 to 0.01781, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0216 - logloss: 0.0185 - val_loss: 0.0210 - val_logloss: 0.0178\n",
      "Epoch 12/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0214 - logloss: 0.0182\n",
      "Epoch 00012: val_logloss improved from 0.01781 to 0.01761, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0214 - logloss: 0.0182 - val_loss: 0.0208 - val_logloss: 0.0176\n",
      "Epoch 13/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0213 - logloss: 0.0181\n",
      "Epoch 00013: val_logloss improved from 0.01761 to 0.01757, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0213 - logloss: 0.0181 - val_loss: 0.0208 - val_logloss: 0.0176\n",
      "Epoch 14/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0210 - logloss: 0.0178\n",
      "Epoch 00014: val_logloss improved from 0.01757 to 0.01739, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0210 - logloss: 0.0178 - val_loss: 0.0206 - val_logloss: 0.0174\n",
      "Epoch 15/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0208 - logloss: 0.0176\n",
      "Epoch 00015: val_logloss improved from 0.01739 to 0.01734, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0208 - logloss: 0.0176 - val_loss: 0.0206 - val_logloss: 0.0173\n",
      "Epoch 16/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0206 - logloss: 0.0174\n",
      "Epoch 00016: val_logloss improved from 0.01734 to 0.01733, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0206 - logloss: 0.0174 - val_loss: 0.0207 - val_logloss: 0.0173\n",
      "Epoch 17/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0206 - logloss: 0.0173\n",
      "Epoch 00017: val_logloss improved from 0.01733 to 0.01712, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0206 - logloss: 0.0173 - val_loss: 0.0203 - val_logloss: 0.0171\n",
      "Epoch 18/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0203 - logloss: 0.0171\n",
      "Epoch 00018: val_logloss improved from 0.01712 to 0.01706, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0203 - logloss: 0.0171 - val_loss: 0.0203 - val_logloss: 0.0171\n",
      "Epoch 19/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0201 - logloss: 0.0169\n",
      "Epoch 00019: val_logloss improved from 0.01706 to 0.01692, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0201 - logloss: 0.0168 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 20/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0199 - logloss: 0.0167\n",
      "Epoch 00020: val_logloss improved from 0.01692 to 0.01682, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0199 - logloss: 0.0167 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 21/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0197 - logloss: 0.0165\n",
      "Epoch 00021: val_logloss improved from 0.01682 to 0.01681, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0197 - logloss: 0.0165 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 22/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0197 - logloss: 0.0164\n",
      "Epoch 00022: val_logloss improved from 0.01681 to 0.01677, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0197 - logloss: 0.0164 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 23/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0194 - logloss: 0.0162\n",
      "Epoch 00023: val_logloss did not improve from 0.01677\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0195 - logloss: 0.0162 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 24/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0193 - logloss: 0.0160\n",
      "Epoch 00024: val_logloss improved from 0.01677 to 0.01674, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0193 - logloss: 0.0161 - val_loss: 0.0201 - val_logloss: 0.0167\n",
      "Epoch 25/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0188 - logloss: 0.0156\n",
      "Epoch 00025: val_logloss improved from 0.01674 to 0.01658, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0188 - logloss: 0.0156 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 26/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0187 - logloss: 0.0155\n",
      "Epoch 00026: val_logloss improved from 0.01658 to 0.01655, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0187 - logloss: 0.0155 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 27/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0187 - logloss: 0.0155\n",
      "Epoch 00027: val_logloss improved from 0.01655 to 0.01653, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0187 - logloss: 0.0155 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 28/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0187 - logloss: 0.0154\n",
      "Epoch 00028: val_logloss improved from 0.01653 to 0.01652, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0187 - logloss: 0.0154 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 29/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00029: val_logloss improved from 0.01652 to 0.01651, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 30/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00030: val_logloss improved from 0.01651 to 0.01650, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 31/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00031: val_logloss improved from 0.01650 to 0.01649, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 32/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00032: val_logloss improved from 0.01649 to 0.01649, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 33/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0152\n",
      "Epoch 00033: val_logloss improved from 0.01649 to 0.01649, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 34/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0185 - logloss: 0.0152\n",
      "Epoch 00034: val_logloss improved from 0.01649 to 0.01648, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0185 - logloss: 0.0152 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 35/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00035: val_logloss improved from 0.01648 to 0.01648, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0185 - logloss: 0.0152 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 36/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0185 - logloss: 0.0152\n",
      "Epoch 00036: val_logloss improved from 0.01648 to 0.01648, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 37/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0152\n",
      "Epoch 00037: val_logloss improved from 0.01648 to 0.01648, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 0.0185 - logloss: 0.0152 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 38/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0152\n",
      "Epoch 00038: val_logloss improved from 0.01648 to 0.01648, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 39/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00039: val_logloss improved from 0.01648 to 0.01647, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 40/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0152\n",
      "Epoch 00040: val_logloss improved from 0.01647 to 0.01647, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Fold 2 log loss: 0.016365402477321732\n",
      "Fold 3\n",
      "Epoch 1/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.4816 - logloss: 0.4811\n",
      "Epoch 00001: val_logloss improved from inf to 0.10157, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.4785 - logloss: 0.4758 - val_loss: 0.1028 - val_logloss: 0.1016\n",
      "Epoch 2/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0554 - logloss: 0.0536\n",
      "Epoch 00002: val_logloss improved from 0.10157 to 0.02914, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0552 - logloss: 0.0532 - val_loss: 0.0314 - val_logloss: 0.0291\n",
      "Epoch 3/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0294 - logloss: 0.0269\n",
      "Epoch 00003: val_logloss improved from 0.02914 to 0.02337, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0293 - logloss: 0.0268 - val_loss: 0.0259 - val_logloss: 0.0234\n",
      "Epoch 4/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0256 - logloss: 0.0229\n",
      "Epoch 00004: val_logloss improved from 0.02337 to 0.02113, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0256 - logloss: 0.0229 - val_loss: 0.0239 - val_logloss: 0.0211\n",
      "Epoch 5/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0243 - logloss: 0.0213\n",
      "Epoch 00005: val_logloss improved from 0.02113 to 0.01981, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0243 - logloss: 0.0214 - val_loss: 0.0228 - val_logloss: 0.0198\n",
      "Epoch 6/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0234 - logloss: 0.0204\n",
      "Epoch 00006: val_logloss improved from 0.01981 to 0.01925, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0234 - logloss: 0.0204 - val_loss: 0.0223 - val_logloss: 0.0192\n",
      "Epoch 7/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0227 - logloss: 0.0197\n",
      "Epoch 00007: val_logloss improved from 0.01925 to 0.01891, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0227 - logloss: 0.0197 - val_loss: 0.0220 - val_logloss: 0.0189\n",
      "Epoch 8/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0225 - logloss: 0.0194\n",
      "Epoch 00008: val_logloss improved from 0.01891 to 0.01855, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0225 - logloss: 0.0194 - val_loss: 0.0217 - val_logloss: 0.0186\n",
      "Epoch 9/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0224 - logloss: 0.0192\n",
      "Epoch 00009: val_logloss improved from 0.01855 to 0.01844, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0223 - logloss: 0.0192 - val_loss: 0.0215 - val_logloss: 0.0184\n",
      "Epoch 10/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0220 - logloss: 0.0188\n",
      "Epoch 00010: val_logloss improved from 0.01844 to 0.01796, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0219 - logloss: 0.0187 - val_loss: 0.0211 - val_logloss: 0.0180\n",
      "Epoch 11/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0216 - logloss: 0.0184\n",
      "Epoch 00011: val_logloss improved from 0.01796 to 0.01769, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0216 - logloss: 0.0184 - val_loss: 0.0208 - val_logloss: 0.0177\n",
      "Epoch 12/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0213 - logloss: 0.0181\n",
      "Epoch 00012: val_logloss did not improve from 0.01769\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0213 - logloss: 0.0182 - val_loss: 0.0209 - val_logloss: 0.0177\n",
      "Epoch 13/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0211 - logloss: 0.0179\n",
      "Epoch 00013: val_logloss improved from 0.01769 to 0.01743, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0212 - logloss: 0.0180 - val_loss: 0.0206 - val_logloss: 0.0174\n",
      "Epoch 14/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0209 - logloss: 0.0177\n",
      "Epoch 00014: val_logloss improved from 0.01743 to 0.01730, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0209 - logloss: 0.0177 - val_loss: 0.0204 - val_logloss: 0.0173\n",
      "Epoch 15/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0208 - logloss: 0.0176\n",
      "Epoch 00015: val_logloss did not improve from 0.01730\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0207 - logloss: 0.0176 - val_loss: 0.0208 - val_logloss: 0.0176\n",
      "Epoch 16/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0206 - logloss: 0.0174\n",
      "Epoch 00016: val_logloss did not improve from 0.01730\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0207 - logloss: 0.0175 - val_loss: 0.0208 - val_logloss: 0.0174\n",
      "Epoch 17/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0205 - logloss: 0.0173\n",
      "Epoch 00017: val_logloss improved from 0.01730 to 0.01708, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0205 - logloss: 0.0172 - val_loss: 0.0203 - val_logloss: 0.0171\n",
      "Epoch 18/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0202 - logloss: 0.0170\n",
      "Epoch 00018: val_logloss improved from 0.01708 to 0.01699, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0202 - logloss: 0.0170 - val_loss: 0.0201 - val_logloss: 0.0170\n",
      "Epoch 19/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0201 - logloss: 0.0169\n",
      "Epoch 00019: val_logloss improved from 0.01699 to 0.01688, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0201 - logloss: 0.0168 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 20/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0199 - logloss: 0.0167\n",
      "Epoch 00020: val_logloss did not improve from 0.01688\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0199 - logloss: 0.0167 - val_loss: 0.0202 - val_logloss: 0.0170\n",
      "Epoch 21/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0197 - logloss: 0.0164\n",
      "Epoch 00021: val_logloss improved from 0.01688 to 0.01681, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0197 - logloss: 0.0165 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 22/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0198 - logloss: 0.0166\n",
      "Epoch 00022: val_logloss improved from 0.01681 to 0.01679, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0198 - logloss: 0.0166 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 23/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00023: val_logloss improved from 0.01679 to 0.01670, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0193 - logloss: 0.0161 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 24/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0191 - logloss: 0.0159\n",
      "Epoch 00024: val_logloss improved from 0.01670 to 0.01663, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0192 - logloss: 0.0160 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 25/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0192 - logloss: 0.0160\n",
      "Epoch 00025: val_logloss improved from 0.01663 to 0.01661, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0192 - logloss: 0.0160 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 26/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0191 - logloss: 0.0159\n",
      "Epoch 00026: val_logloss improved from 0.01661 to 0.01657, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0191 - logloss: 0.0158 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 27/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0190 - logloss: 0.0158\n",
      "Epoch 00027: val_logloss improved from 0.01657 to 0.01657, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0190 - logloss: 0.0158 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 28/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0189 - logloss: 0.0157\n",
      "Epoch 00028: val_logloss improved from 0.01657 to 0.01654, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0189 - logloss: 0.0157 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 29/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0189 - logloss: 0.0157\n",
      "Epoch 00029: val_logloss improved from 0.01654 to 0.01654, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0189 - logloss: 0.0157 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 30/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0188 - logloss: 0.0156\n",
      "Epoch 00030: val_logloss improved from 0.01654 to 0.01653, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0188 - logloss: 0.0156 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 31/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0188 - logloss: 0.0156\n",
      "Epoch 00031: val_logloss improved from 0.01653 to 0.01653, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0189 - logloss: 0.0157 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 32/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0188 - logloss: 0.0156\n",
      "Epoch 00032: val_logloss improved from 0.01653 to 0.01653, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0189 - logloss: 0.0156 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 33/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0188 - logloss: 0.0156\n",
      "Epoch 00033: val_logloss improved from 0.01653 to 0.01653, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0188 - logloss: 0.0156 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 34/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0188 - logloss: 0.0156\n",
      "Epoch 00034: val_logloss improved from 0.01653 to 0.01652, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0188 - logloss: 0.0156 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 35/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0188 - logloss: 0.0156\n",
      "Epoch 00035: val_logloss improved from 0.01652 to 0.01652, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0188 - logloss: 0.0156 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 36/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0187 - logloss: 0.0155\n",
      "Epoch 00036: val_logloss improved from 0.01652 to 0.01652, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0187 - logloss: 0.0155 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 37/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0188 - logloss: 0.0156\n",
      "Epoch 00037: val_logloss did not improve from 0.01652\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0188 - logloss: 0.0156 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 38/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0187 - logloss: 0.0155\n",
      "Epoch 00038: val_logloss improved from 0.01652 to 0.01651, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0187 - logloss: 0.0155 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 39/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0188 - logloss: 0.0155\n",
      "Epoch 00039: val_logloss improved from 0.01651 to 0.01651, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0187 - logloss: 0.0155 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 40/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0188 - logloss: 0.0156\n",
      "Epoch 00040: val_logloss did not improve from 0.01651\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0188 - logloss: 0.0156 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Fold 3 log loss: 0.016361370641274707\n",
      "Fold 4\n",
      "Epoch 1/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.4797 - logloss: 0.4791\n",
      "Epoch 00001: val_logloss improved from inf to 0.10265, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.4792 - logloss: 0.4766 - val_loss: 0.1039 - val_logloss: 0.1026\n",
      "Epoch 2/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0556 - logloss: 0.0538\n",
      "Epoch 00002: val_logloss improved from 0.10265 to 0.02992, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0556 - logloss: 0.0537 - val_loss: 0.0322 - val_logloss: 0.0299\n",
      "Epoch 3/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0300 - logloss: 0.0274\n",
      "Epoch 00003: val_logloss improved from 0.02992 to 0.02377, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0300 - logloss: 0.0274 - val_loss: 0.0263 - val_logloss: 0.0238\n",
      "Epoch 4/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0257 - logloss: 0.0229\n",
      "Epoch 00004: val_logloss improved from 0.02377 to 0.02092, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0257 - logloss: 0.0229 - val_loss: 0.0238 - val_logloss: 0.0209\n",
      "Epoch 5/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0242 - logloss: 0.0212\n",
      "Epoch 00005: val_logloss improved from 0.02092 to 0.01966, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0242 - logloss: 0.0212 - val_loss: 0.0226 - val_logloss: 0.0197\n",
      "Epoch 6/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0234 - logloss: 0.0204\n",
      "Epoch 00006: val_logloss improved from 0.01966 to 0.01926, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0234 - logloss: 0.0204 - val_loss: 0.0223 - val_logloss: 0.0193\n",
      "Epoch 7/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0230 - logloss: 0.0199\n",
      "Epoch 00007: val_logloss improved from 0.01926 to 0.01880, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0230 - logloss: 0.0199 - val_loss: 0.0219 - val_logloss: 0.0188\n",
      "Epoch 8/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0225 - logloss: 0.0194\n",
      "Epoch 00008: val_logloss improved from 0.01880 to 0.01840, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0225 - logloss: 0.0194 - val_loss: 0.0215 - val_logloss: 0.0184\n",
      "Epoch 9/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0222 - logloss: 0.0190\n",
      "Epoch 00009: val_logloss improved from 0.01840 to 0.01801, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0222 - logloss: 0.0190 - val_loss: 0.0212 - val_logloss: 0.0180\n",
      "Epoch 10/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0220 - logloss: 0.0188\n",
      "Epoch 00010: val_logloss improved from 0.01801 to 0.01800, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0220 - logloss: 0.0188 - val_loss: 0.0212 - val_logloss: 0.0180\n",
      "Epoch 11/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0217 - logloss: 0.0185\n",
      "Epoch 00011: val_logloss improved from 0.01800 to 0.01774, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0217 - logloss: 0.0185 - val_loss: 0.0210 - val_logloss: 0.0177\n",
      "Epoch 12/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0214 - logloss: 0.0182\n",
      "Epoch 00012: val_logloss improved from 0.01774 to 0.01747, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0214 - logloss: 0.0183 - val_loss: 0.0206 - val_logloss: 0.0175\n",
      "Epoch 13/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0213 - logloss: 0.0181\n",
      "Epoch 00013: val_logloss improved from 0.01747 to 0.01735, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0213 - logloss: 0.0181 - val_loss: 0.0206 - val_logloss: 0.0174\n",
      "Epoch 14/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0211 - logloss: 0.0179\n",
      "Epoch 00014: val_logloss improved from 0.01735 to 0.01723, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0211 - logloss: 0.0179 - val_loss: 0.0204 - val_logloss: 0.0172\n",
      "Epoch 15/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0209 - logloss: 0.0176\n",
      "Epoch 00015: val_logloss improved from 0.01723 to 0.01716, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0208 - logloss: 0.0177 - val_loss: 0.0204 - val_logloss: 0.0172\n",
      "Epoch 16/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0208 - logloss: 0.0175\n",
      "Epoch 00016: val_logloss improved from 0.01716 to 0.01715, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0208 - logloss: 0.0175 - val_loss: 0.0205 - val_logloss: 0.0172\n",
      "Epoch 17/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0206 - logloss: 0.0174\n",
      "Epoch 00017: val_logloss improved from 0.01715 to 0.01703, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0206 - logloss: 0.0174 - val_loss: 0.0203 - val_logloss: 0.0170\n",
      "Epoch 18/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0205 - logloss: 0.0172\n",
      "Epoch 00018: val_logloss improved from 0.01703 to 0.01691, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0205 - logloss: 0.0173 - val_loss: 0.0202 - val_logloss: 0.0169\n",
      "Epoch 19/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0203 - logloss: 0.0170\n",
      "Epoch 00019: val_logloss improved from 0.01691 to 0.01684, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0203 - logloss: 0.0170 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 20/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0200 - logloss: 0.0168\n",
      "Epoch 00020: val_logloss improved from 0.01684 to 0.01680, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0201 - logloss: 0.0168 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 21/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0199 - logloss: 0.0166\n",
      "Epoch 00021: val_logloss improved from 0.01680 to 0.01667, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0198 - logloss: 0.0166 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 22/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0200 - logloss: 0.0167\n",
      "Epoch 00022: val_logloss did not improve from 0.01667\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0200 - logloss: 0.0167 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 23/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0198 - logloss: 0.0165\n",
      "Epoch 00023: val_logloss did not improve from 0.01667\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0198 - logloss: 0.0164 - val_loss: 0.0200 - val_logloss: 0.0167\n",
      "Epoch 24/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0194 - logloss: 0.0161\n",
      "Epoch 00024: val_logloss improved from 0.01667 to 0.01658, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 25/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0190 - logloss: 0.0158\n",
      "Epoch 00025: val_logloss improved from 0.01658 to 0.01647, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0190 - logloss: 0.0158 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 26/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0190 - logloss: 0.0157\n",
      "Epoch 00026: val_logloss improved from 0.01647 to 0.01643, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0190 - logloss: 0.0158 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 27/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0189 - logloss: 0.0156\n",
      "Epoch 00027: val_logloss improved from 0.01643 to 0.01641, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0189 - logloss: 0.0157 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 28/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0188 - logloss: 0.0156\n",
      "Epoch 00028: val_logloss improved from 0.01641 to 0.01639, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0188 - logloss: 0.0156 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 29/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0187 - logloss: 0.0155\n",
      "Epoch 00029: val_logloss improved from 0.01639 to 0.01638, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0187 - logloss: 0.0155 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 30/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0187 - logloss: 0.0155\n",
      "Epoch 00030: val_logloss improved from 0.01638 to 0.01638, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0187 - logloss: 0.0155 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 31/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0187 - logloss: 0.0154\n",
      "Epoch 00031: val_logloss did not improve from 0.01638\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0187 - logloss: 0.0155 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 32/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0187 - logloss: 0.0155\n",
      "Epoch 00032: val_logloss improved from 0.01638 to 0.01637, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0187 - logloss: 0.0155 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 33/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0187 - logloss: 0.0154\n",
      "Epoch 00033: val_logloss improved from 0.01637 to 0.01637, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0187 - logloss: 0.0155 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 34/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0187 - logloss: 0.0155\n",
      "Epoch 00034: val_logloss improved from 0.01637 to 0.01637, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0187 - logloss: 0.0155 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 35/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0186 - logloss: 0.0154\n",
      "Epoch 00035: val_logloss improved from 0.01637 to 0.01636, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 36/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0187 - logloss: 0.0155\n",
      "Epoch 00036: val_logloss did not improve from 0.01636\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0187 - logloss: 0.0155 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 37/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0186 - logloss: 0.0154\n",
      "Epoch 00037: val_logloss improved from 0.01636 to 0.01636, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 38/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0187 - logloss: 0.0154\n",
      "Epoch 00038: val_logloss did not improve from 0.01636\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0187 - logloss: 0.0154 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 39/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0186 - logloss: 0.0154\n",
      "Epoch 00039: val_logloss improved from 0.01636 to 0.01635, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0196 - val_logloss: 0.0164\n",
      "Epoch 40/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0187 - logloss: 0.0154\n",
      "Epoch 00040: val_logloss improved from 0.01635 to 0.01635, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0187 - logloss: 0.0154 - val_loss: 0.0196 - val_logloss: 0.0164\n",
      "Fold 4 log loss: 0.016249688355943034\n",
      "Fold 5\n",
      "Epoch 1/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.4815 - logloss: 0.4809\n",
      "Epoch 00001: val_logloss improved from inf to 0.09520, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 0.4810 - logloss: 0.4784 - val_loss: 0.0965 - val_logloss: 0.0952\n",
      "Epoch 2/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0568 - logloss: 0.0550\n",
      "Epoch 00002: val_logloss improved from 0.09520 to 0.02977, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0561 - logloss: 0.0541 - val_loss: 0.0319 - val_logloss: 0.0298\n",
      "Epoch 3/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0295 - logloss: 0.0270\n",
      "Epoch 00003: val_logloss improved from 0.02977 to 0.02438, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0295 - logloss: 0.0270 - val_loss: 0.0269 - val_logloss: 0.0244\n",
      "Epoch 4/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0256 - logloss: 0.0229\n",
      "Epoch 00004: val_logloss improved from 0.02438 to 0.02112, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0256 - logloss: 0.0229 - val_loss: 0.0238 - val_logloss: 0.0211\n",
      "Epoch 5/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0242 - logloss: 0.0213\n",
      "Epoch 00005: val_logloss improved from 0.02112 to 0.01997, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0242 - logloss: 0.0213 - val_loss: 0.0228 - val_logloss: 0.0200\n",
      "Epoch 6/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0235 - logloss: 0.0205\n",
      "Epoch 00006: val_logloss improved from 0.01997 to 0.01955, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0235 - logloss: 0.0205 - val_loss: 0.0225 - val_logloss: 0.0196\n",
      "Epoch 7/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0229 - logloss: 0.0197\n",
      "Epoch 00007: val_logloss improved from 0.01955 to 0.01890, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0229 - logloss: 0.0198 - val_loss: 0.0219 - val_logloss: 0.0189\n",
      "Epoch 8/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0225 - logloss: 0.0193\n",
      "Epoch 00008: val_logloss improved from 0.01890 to 0.01870, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0225 - logloss: 0.0193 - val_loss: 0.0217 - val_logloss: 0.0187\n",
      "Epoch 9/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0223 - logloss: 0.0191\n",
      "Epoch 00009: val_logloss improved from 0.01870 to 0.01849, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0222 - logloss: 0.0191 - val_loss: 0.0216 - val_logloss: 0.0185\n",
      "Epoch 10/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0219 - logloss: 0.0187\n",
      "Epoch 00010: val_logloss improved from 0.01849 to 0.01823, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0219 - logloss: 0.0188 - val_loss: 0.0213 - val_logloss: 0.0182\n",
      "Epoch 11/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0217 - logloss: 0.0185\n",
      "Epoch 00011: val_logloss improved from 0.01823 to 0.01790, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0217 - logloss: 0.0185 - val_loss: 0.0210 - val_logloss: 0.0179\n",
      "Epoch 12/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0215 - logloss: 0.0183\n",
      "Epoch 00012: val_logloss improved from 0.01790 to 0.01787, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0215 - logloss: 0.0183 - val_loss: 0.0210 - val_logloss: 0.0179\n",
      "Epoch 13/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0211 - logloss: 0.0179\n",
      "Epoch 00013: val_logloss improved from 0.01787 to 0.01763, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0211 - logloss: 0.0179 - val_loss: 0.0208 - val_logloss: 0.0176\n",
      "Epoch 14/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0210 - logloss: 0.0177\n",
      "Epoch 00014: val_logloss improved from 0.01763 to 0.01750, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0210 - logloss: 0.0178 - val_loss: 0.0206 - val_logloss: 0.0175\n",
      "Epoch 15/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0208 - logloss: 0.0176\n",
      "Epoch 00015: val_logloss improved from 0.01750 to 0.01743, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0208 - logloss: 0.0175 - val_loss: 0.0205 - val_logloss: 0.0174\n",
      "Epoch 16/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0206 - logloss: 0.0174\n",
      "Epoch 00016: val_logloss improved from 0.01743 to 0.01735, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0206 - logloss: 0.0174 - val_loss: 0.0205 - val_logloss: 0.0173\n",
      "Epoch 17/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0204 - logloss: 0.0172\n",
      "Epoch 00017: val_logloss improved from 0.01735 to 0.01719, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0204 - logloss: 0.0172 - val_loss: 0.0203 - val_logloss: 0.0172\n",
      "Epoch 18/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0205 - logloss: 0.0172\n",
      "Epoch 00018: val_logloss did not improve from 0.01719\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0204 - logloss: 0.0172 - val_loss: 0.0203 - val_logloss: 0.0172\n",
      "Epoch 19/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0202 - logloss: 0.0169\n",
      "Epoch 00019: val_logloss improved from 0.01719 to 0.01705, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0202 - logloss: 0.0170 - val_loss: 0.0202 - val_logloss: 0.0171\n",
      "Epoch 20/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0202 - logloss: 0.0169\n",
      "Epoch 00020: val_logloss did not improve from 0.01705\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0202 - logloss: 0.0170 - val_loss: 0.0203 - val_logloss: 0.0171\n",
      "Epoch 21/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0199 - logloss: 0.0167\n",
      "Epoch 00021: val_logloss improved from 0.01705 to 0.01695, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0199 - logloss: 0.0167 - val_loss: 0.0202 - val_logloss: 0.0170\n",
      "Epoch 22/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0197 - logloss: 0.0165\n",
      "Epoch 00022: val_logloss did not improve from 0.01695\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0197 - logloss: 0.0165 - val_loss: 0.0202 - val_logloss: 0.0170\n",
      "Epoch 23/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0196 - logloss: 0.0163\n",
      "Epoch 00023: val_logloss improved from 0.01695 to 0.01683, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0196 - logloss: 0.0163 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 24/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00024: val_logloss improved from 0.01683 to 0.01683, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0193 - logloss: 0.0161 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 25/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0192 - logloss: 0.0159\n",
      "Epoch 00025: val_logloss did not improve from 0.01683\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0192 - logloss: 0.0160 - val_loss: 0.0202 - val_logloss: 0.0169\n",
      "Epoch 26/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0194 - logloss: 0.0161\n",
      "Epoch 00026: val_logloss improved from 0.01683 to 0.01677, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 27/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0187 - logloss: 0.0154\n",
      "Epoch 00027: val_logloss improved from 0.01677 to 0.01667, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0187 - logloss: 0.0154 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 28/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0187 - logloss: 0.0154\n",
      "Epoch 00028: val_logloss improved from 0.01667 to 0.01663, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0187 - logloss: 0.0154 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 29/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0187 - logloss: 0.0154\n",
      "Epoch 00029: val_logloss improved from 0.01663 to 0.01661, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 30/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00030: val_logloss improved from 0.01661 to 0.01659, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 31/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0184 - logloss: 0.0151\n",
      "Epoch 00031: val_logloss improved from 0.01659 to 0.01659, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0184 - logloss: 0.0151 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 32/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0184 - logloss: 0.0152\n",
      "Epoch 00032: val_logloss improved from 0.01659 to 0.01658, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0184 - logloss: 0.0152 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 33/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0184 - logloss: 0.0151\n",
      "Epoch 00033: val_logloss did not improve from 0.01658\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0183 - logloss: 0.0151 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 34/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0184 - logloss: 0.0151\n",
      "Epoch 00034: val_logloss improved from 0.01658 to 0.01658, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0184 - logloss: 0.0152 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 35/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0184 - logloss: 0.0151\n",
      "Epoch 00035: val_logloss improved from 0.01658 to 0.01658, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0184 - logloss: 0.0152 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 36/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0184 - logloss: 0.0151\n",
      "Epoch 00036: val_logloss did not improve from 0.01658\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0184 - logloss: 0.0151 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 37/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0184 - logloss: 0.0151\n",
      "Epoch 00037: val_logloss improved from 0.01658 to 0.01658, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0184 - logloss: 0.0151 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 38/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0184 - logloss: 0.0152\n",
      "Epoch 00038: val_logloss improved from 0.01658 to 0.01657, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0184 - logloss: 0.0152 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 39/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0184 - logloss: 0.0151\n",
      "Epoch 00039: val_logloss improved from 0.01657 to 0.01657, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0184 - logloss: 0.0151 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 40/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0184 - logloss: 0.0151\n",
      "Epoch 00040: val_logloss did not improve from 0.01657\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0184 - logloss: 0.0151 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Fold 5 log loss: 0.016403303184304698\n",
      "Seed 1\n",
      "Fold 1 log loss: 0.016423752166919454\n",
      "Fold 2 log loss: 0.016365402477321732\n",
      "Fold 3 log loss: 0.016361370641274707\n",
      "Fold 4 log loss: 0.016249688355943034\n",
      "Fold 5 log loss: 0.016403303184304698\n",
      "Std of log loss: 6.022749401797943e-05\n",
      "Total log loss: 0.016360701210107558\n",
      "Fold 1\n",
      "Epoch 1/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.4865 - logloss: 0.4860\n",
      "Epoch 00001: val_logloss improved from inf to 0.10466, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 0.4808 - logloss: 0.4781 - val_loss: 0.1062 - val_logloss: 0.1047\n",
      "Epoch 2/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0559 - logloss: 0.0540\n",
      "Epoch 00002: val_logloss improved from 0.10466 to 0.03016, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0559 - logloss: 0.0540 - val_loss: 0.0324 - val_logloss: 0.0302\n",
      "Epoch 3/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0292 - logloss: 0.0268\n",
      "Epoch 00003: val_logloss improved from 0.03016 to 0.02268, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0292 - logloss: 0.0268 - val_loss: 0.0254 - val_logloss: 0.0227\n",
      "Epoch 4/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0255 - logloss: 0.0228\n",
      "Epoch 00004: val_logloss improved from 0.02268 to 0.02089, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0255 - logloss: 0.0228 - val_loss: 0.0238 - val_logloss: 0.0209\n",
      "Epoch 5/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0242 - logloss: 0.0213\n",
      "Epoch 00005: val_logloss improved from 0.02089 to 0.01991, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0242 - logloss: 0.0213 - val_loss: 0.0229 - val_logloss: 0.0199\n",
      "Epoch 6/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0235 - logloss: 0.0204\n",
      "Epoch 00006: val_logloss improved from 0.01991 to 0.01926, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0234 - logloss: 0.0204 - val_loss: 0.0223 - val_logloss: 0.0193\n",
      "Epoch 7/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0227 - logloss: 0.0196\n",
      "Epoch 00007: val_logloss improved from 0.01926 to 0.01878, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0227 - logloss: 0.0196 - val_loss: 0.0219 - val_logloss: 0.0188\n",
      "Epoch 8/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0223 - logloss: 0.0192\n",
      "Epoch 00008: val_logloss improved from 0.01878 to 0.01848, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0223 - logloss: 0.0192 - val_loss: 0.0216 - val_logloss: 0.0185\n",
      "Epoch 9/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0221 - logloss: 0.0189\n",
      "Epoch 00009: val_logloss improved from 0.01848 to 0.01823, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0220 - logloss: 0.0189 - val_loss: 0.0215 - val_logloss: 0.0182\n",
      "Epoch 10/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0219 - logloss: 0.0187\n",
      "Epoch 00010: val_logloss improved from 0.01823 to 0.01811, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0219 - logloss: 0.0187 - val_loss: 0.0214 - val_logloss: 0.0181\n",
      "Epoch 11/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0215 - logloss: 0.0183\n",
      "Epoch 00011: val_logloss improved from 0.01811 to 0.01792, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0215 - logloss: 0.0183 - val_loss: 0.0212 - val_logloss: 0.0179\n",
      "Epoch 12/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0214 - logloss: 0.0182\n",
      "Epoch 00012: val_logloss improved from 0.01792 to 0.01773, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0214 - logloss: 0.0182 - val_loss: 0.0210 - val_logloss: 0.0177\n",
      "Epoch 13/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0211 - logloss: 0.0179\n",
      "Epoch 00013: val_logloss improved from 0.01773 to 0.01764, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0211 - logloss: 0.0179 - val_loss: 0.0210 - val_logloss: 0.0176\n",
      "Epoch 14/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0209 - logloss: 0.0177\n",
      "Epoch 00014: val_logloss improved from 0.01764 to 0.01738, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0209 - logloss: 0.0178 - val_loss: 0.0206 - val_logloss: 0.0174\n",
      "Epoch 15/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0207 - logloss: 0.0175\n",
      "Epoch 00015: val_logloss improved from 0.01738 to 0.01729, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0206 - logloss: 0.0175 - val_loss: 0.0205 - val_logloss: 0.0173\n",
      "Epoch 16/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0207 - logloss: 0.0175\n",
      "Epoch 00016: val_logloss improved from 0.01729 to 0.01725, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0208 - logloss: 0.0175 - val_loss: 0.0206 - val_logloss: 0.0172\n",
      "Epoch 17/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0204 - logloss: 0.0172\n",
      "Epoch 00017: val_logloss improved from 0.01725 to 0.01709, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0204 - logloss: 0.0171 - val_loss: 0.0204 - val_logloss: 0.0171\n",
      "Epoch 18/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0203 - logloss: 0.0170\n",
      "Epoch 00018: val_logloss did not improve from 0.01709\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0203 - logloss: 0.0171 - val_loss: 0.0204 - val_logloss: 0.0171\n",
      "Epoch 19/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0203 - logloss: 0.0170\n",
      "Epoch 00019: val_logloss did not improve from 0.01709\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0202 - logloss: 0.0170 - val_loss: 0.0205 - val_logloss: 0.0171\n",
      "Epoch 20/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0200 - logloss: 0.0167\n",
      "Epoch 00020: val_logloss improved from 0.01709 to 0.01698, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0200 - logloss: 0.0167 - val_loss: 0.0203 - val_logloss: 0.0170\n",
      "Epoch 21/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0199 - logloss: 0.0167\n",
      "Epoch 00021: val_logloss did not improve from 0.01698\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0199 - logloss: 0.0167 - val_loss: 0.0204 - val_logloss: 0.0170\n",
      "Epoch 22/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0197 - logloss: 0.0164\n",
      "Epoch 00022: val_logloss improved from 0.01698 to 0.01683, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0197 - logloss: 0.0164 - val_loss: 0.0202 - val_logloss: 0.0168\n",
      "Epoch 23/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0197 - logloss: 0.0164\n",
      "Epoch 00023: val_logloss did not improve from 0.01683\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0196 - logloss: 0.0164 - val_loss: 0.0203 - val_logloss: 0.0169\n",
      "Epoch 24/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0194 - logloss: 0.0161\n",
      "Epoch 00024: val_logloss improved from 0.01683 to 0.01680, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0194 - logloss: 0.0161 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 25/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0193 - logloss: 0.0160\n",
      "Epoch 00025: val_logloss improved from 0.01680 to 0.01678, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0193 - logloss: 0.0160 - val_loss: 0.0203 - val_logloss: 0.0168\n",
      "Epoch 26/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0188 - logloss: 0.0155\n",
      "Epoch 00026: val_logloss improved from 0.01678 to 0.01665, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0188 - logloss: 0.0155 - val_loss: 0.0200 - val_logloss: 0.0166\n",
      "Epoch 27/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0188 - logloss: 0.0155\n",
      "Epoch 00027: val_logloss improved from 0.01665 to 0.01661, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0187 - logloss: 0.0154 - val_loss: 0.0200 - val_logloss: 0.0166\n",
      "Epoch 28/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0186 - logloss: 0.0154\n",
      "Epoch 00028: val_logloss improved from 0.01661 to 0.01658, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 29/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0186 - logloss: 0.0153\n",
      "Epoch 00029: val_logloss improved from 0.01658 to 0.01658, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0200 - val_logloss: 0.0166\n",
      "Epoch 30/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0184 - logloss: 0.0152\n",
      "Epoch 00030: val_logloss improved from 0.01658 to 0.01657, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0184 - logloss: 0.0152 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 31/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0152\n",
      "Epoch 00031: val_logloss improved from 0.01657 to 0.01657, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 32/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0185 - logloss: 0.0153\n",
      "Epoch 00032: val_logloss did not improve from 0.01657\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0185 - logloss: 0.0153 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 33/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0184 - logloss: 0.0152\n",
      "Epoch 00033: val_logloss improved from 0.01657 to 0.01656, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0184 - logloss: 0.0152 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 34/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0152\n",
      "Epoch 00034: val_logloss improved from 0.01656 to 0.01656, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0185 - logloss: 0.0152 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 35/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0185 - logloss: 0.0152\n",
      "Epoch 00035: val_logloss improved from 0.01656 to 0.01656, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0185 - logloss: 0.0152 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 36/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0184 - logloss: 0.0152\n",
      "Epoch 00036: val_logloss improved from 0.01656 to 0.01656, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0184 - logloss: 0.0151 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 37/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0152\n",
      "Epoch 00037: val_logloss did not improve from 0.01656\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0185 - logloss: 0.0152 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 38/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0152\n",
      "Epoch 00038: val_logloss improved from 0.01656 to 0.01655, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0185 - logloss: 0.0152 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 39/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0185 - logloss: 0.0152\n",
      "Epoch 00039: val_logloss improved from 0.01655 to 0.01655, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0185 - logloss: 0.0152 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 40/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0184 - logloss: 0.0152\n",
      "Epoch 00040: val_logloss improved from 0.01655 to 0.01655, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0184 - logloss: 0.0152 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Fold 1 log loss: 0.016513292365669324\n",
      "Fold 2\n",
      "Epoch 1/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.4817 - logloss: 0.4811\n",
      "Epoch 00001: val_logloss improved from inf to 0.10226, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.4786 - logloss: 0.4759 - val_loss: 0.1037 - val_logloss: 0.1023\n",
      "Epoch 2/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0562 - logloss: 0.0543\n",
      "Epoch 00002: val_logloss improved from 0.10226 to 0.02884, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0561 - logloss: 0.0542 - val_loss: 0.0311 - val_logloss: 0.0288\n",
      "Epoch 3/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0293 - logloss: 0.0268\n",
      "Epoch 00003: val_logloss improved from 0.02884 to 0.02249, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0292 - logloss: 0.0268 - val_loss: 0.0251 - val_logloss: 0.0225\n",
      "Epoch 4/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0258 - logloss: 0.0230\n",
      "Epoch 00004: val_logloss improved from 0.02249 to 0.02095, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0258 - logloss: 0.0230 - val_loss: 0.0238 - val_logloss: 0.0210\n",
      "Epoch 5/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0243 - logloss: 0.0214\n",
      "Epoch 00005: val_logloss improved from 0.02095 to 0.02020, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0243 - logloss: 0.0215 - val_loss: 0.0231 - val_logloss: 0.0202\n",
      "Epoch 6/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0235 - logloss: 0.0205\n",
      "Epoch 00006: val_logloss improved from 0.02020 to 0.01921, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0235 - logloss: 0.0205 - val_loss: 0.0223 - val_logloss: 0.0192\n",
      "Epoch 7/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0232 - logloss: 0.0201\n",
      "Epoch 00007: val_logloss did not improve from 0.01921\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0232 - logloss: 0.0201 - val_loss: 0.0229 - val_logloss: 0.0198\n",
      "Epoch 8/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0228 - logloss: 0.0196\n",
      "Epoch 00008: val_logloss improved from 0.01921 to 0.01866, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0228 - logloss: 0.0196 - val_loss: 0.0219 - val_logloss: 0.0187\n",
      "Epoch 9/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0224 - logloss: 0.0192\n",
      "Epoch 00009: val_logloss improved from 0.01866 to 0.01857, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0224 - logloss: 0.0192 - val_loss: 0.0219 - val_logloss: 0.0186\n",
      "Epoch 10/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0220 - logloss: 0.0188\n",
      "Epoch 00010: val_logloss improved from 0.01857 to 0.01804, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0220 - logloss: 0.0188 - val_loss: 0.0212 - val_logloss: 0.0180\n",
      "Epoch 11/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0219 - logloss: 0.0186\n",
      "Epoch 00011: val_logloss improved from 0.01804 to 0.01790, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0219 - logloss: 0.0186 - val_loss: 0.0212 - val_logloss: 0.0179\n",
      "Epoch 12/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0216 - logloss: 0.0183\n",
      "Epoch 00012: val_logloss improved from 0.01790 to 0.01775, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0216 - logloss: 0.0184 - val_loss: 0.0210 - val_logloss: 0.0177\n",
      "Epoch 13/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0216 - logloss: 0.0183\n",
      "Epoch 00013: val_logloss improved from 0.01775 to 0.01759, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0216 - logloss: 0.0183 - val_loss: 0.0209 - val_logloss: 0.0176\n",
      "Epoch 14/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0212 - logloss: 0.0180\n",
      "Epoch 00014: val_logloss improved from 0.01759 to 0.01749, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0212 - logloss: 0.0179 - val_loss: 0.0208 - val_logloss: 0.0175\n",
      "Epoch 15/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0209 - logloss: 0.0176\n",
      "Epoch 00015: val_logloss improved from 0.01749 to 0.01744, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0209 - logloss: 0.0177 - val_loss: 0.0208 - val_logloss: 0.0174\n",
      "Epoch 16/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0207 - logloss: 0.0175\n",
      "Epoch 00016: val_logloss improved from 0.01744 to 0.01730, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0207 - logloss: 0.0175 - val_loss: 0.0205 - val_logloss: 0.0173\n",
      "Epoch 17/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0206 - logloss: 0.0174\n",
      "Epoch 00017: val_logloss improved from 0.01730 to 0.01722, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0206 - logloss: 0.0174 - val_loss: 0.0205 - val_logloss: 0.0172\n",
      "Epoch 18/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0205 - logloss: 0.0173\n",
      "Epoch 00018: val_logloss improved from 0.01722 to 0.01715, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0205 - logloss: 0.0173 - val_loss: 0.0204 - val_logloss: 0.0172\n",
      "Epoch 19/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0202 - logloss: 0.0169\n",
      "Epoch 00019: val_logloss improved from 0.01715 to 0.01692, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0202 - logloss: 0.0169 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 20/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0200 - logloss: 0.0168\n",
      "Epoch 00020: val_logloss improved from 0.01692 to 0.01690, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0200 - logloss: 0.0168 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 21/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0198 - logloss: 0.0166\n",
      "Epoch 00021: val_logloss improved from 0.01690 to 0.01684, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0198 - logloss: 0.0166 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 22/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0197 - logloss: 0.0165\n",
      "Epoch 00022: val_logloss improved from 0.01684 to 0.01676, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0197 - logloss: 0.0165 - val_loss: 0.0200 - val_logloss: 0.0168\n",
      "Epoch 23/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0198 - logloss: 0.0165\n",
      "Epoch 00023: val_logloss did not improve from 0.01676\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0198 - logloss: 0.0166 - val_loss: 0.0202 - val_logloss: 0.0168\n",
      "Epoch 24/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0196 - logloss: 0.0163\n",
      "Epoch 00024: val_logloss did not improve from 0.01676\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0196 - logloss: 0.0163 - val_loss: 0.0202 - val_logloss: 0.0168\n",
      "Epoch 25/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0194 - logloss: 0.0161\n",
      "Epoch 00025: val_logloss improved from 0.01676 to 0.01665, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0194 - logloss: 0.0161 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 26/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0192 - logloss: 0.0159\n",
      "Epoch 00026: val_logloss improved from 0.01665 to 0.01659, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0192 - logloss: 0.0159 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 27/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0190 - logloss: 0.0158\n",
      "Epoch 00027: val_logloss did not improve from 0.01659\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0190 - logloss: 0.0158 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 28/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0189 - logloss: 0.0156\n",
      "Epoch 00028: val_logloss improved from 0.01659 to 0.01652, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0189 - logloss: 0.0156 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 29/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0189 - logloss: 0.0155\n",
      "Epoch 00029: val_logloss did not improve from 0.01652\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0189 - logloss: 0.0155 - val_loss: 0.0200 - val_logloss: 0.0166\n",
      "Epoch 30/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0188 - logloss: 0.0154\n",
      "Epoch 00030: val_logloss did not improve from 0.01652\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0188 - logloss: 0.0155 - val_loss: 0.0200 - val_logloss: 0.0166\n",
      "Epoch 31/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0185 - logloss: 0.0152\n",
      "Epoch 00031: val_logloss improved from 0.01652 to 0.01648, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0185 - logloss: 0.0152 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 32/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0180 - logloss: 0.0147\n",
      "Epoch 00032: val_logloss improved from 0.01648 to 0.01641, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0180 - logloss: 0.0147 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 33/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0178 - logloss: 0.0145\n",
      "Epoch 00033: val_logloss improved from 0.01641 to 0.01638, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0178 - logloss: 0.0146 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 34/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0178 - logloss: 0.0145\n",
      "Epoch 00034: val_logloss improved from 0.01638 to 0.01636, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0178 - logloss: 0.0145 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 35/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0178 - logloss: 0.0145\n",
      "Epoch 00035: val_logloss did not improve from 0.01636\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0178 - logloss: 0.0145 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 36/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0176 - logloss: 0.0144\n",
      "Epoch 00036: val_logloss did not improve from 0.01636\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0177 - logloss: 0.0144 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 37/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0176 - logloss: 0.0144\n",
      "Epoch 00037: val_logloss did not improve from 0.01636\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0176 - logloss: 0.0144 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 38/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0176 - logloss: 0.0143\n",
      "Epoch 00038: val_logloss did not improve from 0.01636\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0176 - logloss: 0.0143 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 39/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0176 - logloss: 0.0143\n",
      "Epoch 00039: val_logloss improved from 0.01636 to 0.01636, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0176 - logloss: 0.0143 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 40/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0176 - logloss: 0.0143\n",
      "Epoch 00040: val_logloss improved from 0.01636 to 0.01636, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0176 - logloss: 0.0143 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Fold 2 log loss: 0.01624315331939081\n",
      "Fold 3\n",
      "Epoch 1/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.4832 - logloss: 0.4827\n",
      "Epoch 00001: val_logloss improved from inf to 0.10389, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.4773 - logloss: 0.4746 - val_loss: 0.1051 - val_logloss: 0.1039\n",
      "Epoch 2/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0564 - logloss: 0.0546\n",
      "Epoch 00002: val_logloss improved from 0.10389 to 0.02988, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0554 - logloss: 0.0534 - val_loss: 0.0321 - val_logloss: 0.0299\n",
      "Epoch 3/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0293 - logloss: 0.0268\n",
      "Epoch 00003: val_logloss improved from 0.02988 to 0.02250, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0293 - logloss: 0.0268 - val_loss: 0.0251 - val_logloss: 0.0225\n",
      "Epoch 4/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0258 - logloss: 0.0230\n",
      "Epoch 00004: val_logloss improved from 0.02250 to 0.02063, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0258 - logloss: 0.0230 - val_loss: 0.0234 - val_logloss: 0.0206\n",
      "Epoch 5/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0243 - logloss: 0.0213\n",
      "Epoch 00005: val_logloss improved from 0.02063 to 0.01986, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0243 - logloss: 0.0213 - val_loss: 0.0229 - val_logloss: 0.0199\n",
      "Epoch 6/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0234 - logloss: 0.0204\n",
      "Epoch 00006: val_logloss improved from 0.01986 to 0.01914, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0234 - logloss: 0.0204 - val_loss: 0.0222 - val_logloss: 0.0191\n",
      "Epoch 7/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0228 - logloss: 0.0197\n",
      "Epoch 00007: val_logloss improved from 0.01914 to 0.01870, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0228 - logloss: 0.0198 - val_loss: 0.0217 - val_logloss: 0.0187\n",
      "Epoch 8/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0225 - logloss: 0.0194\n",
      "Epoch 00008: val_logloss improved from 0.01870 to 0.01851, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0225 - logloss: 0.0194 - val_loss: 0.0216 - val_logloss: 0.0185\n",
      "Epoch 9/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0221 - logloss: 0.0190\n",
      "Epoch 00009: val_logloss improved from 0.01851 to 0.01829, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0222 - logloss: 0.0190 - val_loss: 0.0214 - val_logloss: 0.0183\n",
      "Epoch 10/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0219 - logloss: 0.0187\n",
      "Epoch 00010: val_logloss improved from 0.01829 to 0.01805, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0219 - logloss: 0.0187 - val_loss: 0.0212 - val_logloss: 0.0180\n",
      "Epoch 11/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0215 - logloss: 0.0184\n",
      "Epoch 00011: val_logloss improved from 0.01805 to 0.01779, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0215 - logloss: 0.0184 - val_loss: 0.0209 - val_logloss: 0.0178\n",
      "Epoch 12/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0213 - logloss: 0.0181\n",
      "Epoch 00012: val_logloss improved from 0.01779 to 0.01765, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0213 - logloss: 0.0181 - val_loss: 0.0209 - val_logloss: 0.0177\n",
      "Epoch 13/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0211 - logloss: 0.0180\n",
      "Epoch 00013: val_logloss improved from 0.01765 to 0.01753, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0211 - logloss: 0.0180 - val_loss: 0.0207 - val_logloss: 0.0175\n",
      "Epoch 14/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0210 - logloss: 0.0178\n",
      "Epoch 00014: val_logloss improved from 0.01753 to 0.01739, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0210 - logloss: 0.0177 - val_loss: 0.0206 - val_logloss: 0.0174\n",
      "Epoch 15/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0209 - logloss: 0.0176\n",
      "Epoch 00015: val_logloss improved from 0.01739 to 0.01729, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0209 - logloss: 0.0177 - val_loss: 0.0205 - val_logloss: 0.0173\n",
      "Epoch 16/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0207 - logloss: 0.0175\n",
      "Epoch 00016: val_logloss improved from 0.01729 to 0.01719, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0207 - logloss: 0.0175 - val_loss: 0.0203 - val_logloss: 0.0172\n",
      "Epoch 17/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0210 - logloss: 0.0177\n",
      "Epoch 00017: val_logloss did not improve from 0.01719\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0210 - logloss: 0.0177 - val_loss: 0.0207 - val_logloss: 0.0174\n",
      "Epoch 18/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0206 - logloss: 0.0173\n",
      "Epoch 00018: val_logloss improved from 0.01719 to 0.01709, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0206 - logloss: 0.0173 - val_loss: 0.0203 - val_logloss: 0.0171\n",
      "Epoch 19/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0203 - logloss: 0.0170\n",
      "Epoch 00019: val_logloss improved from 0.01709 to 0.01701, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0203 - logloss: 0.0171 - val_loss: 0.0202 - val_logloss: 0.0170\n",
      "Epoch 20/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0202 - logloss: 0.0169\n",
      "Epoch 00020: val_logloss improved from 0.01701 to 0.01698, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0202 - logloss: 0.0169 - val_loss: 0.0203 - val_logloss: 0.0170\n",
      "Epoch 21/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0200 - logloss: 0.0167\n",
      "Epoch 00021: val_logloss improved from 0.01698 to 0.01693, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0200 - logloss: 0.0168 - val_loss: 0.0202 - val_logloss: 0.0169\n",
      "Epoch 22/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0198 - logloss: 0.0165\n",
      "Epoch 00022: val_logloss improved from 0.01693 to 0.01676, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0198 - logloss: 0.0165 - val_loss: 0.0199 - val_logloss: 0.0168\n",
      "Epoch 23/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0196 - logloss: 0.0163\n",
      "Epoch 00023: val_logloss improved from 0.01676 to 0.01671, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0196 - logloss: 0.0163 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 24/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0194 - logloss: 0.0162\n",
      "Epoch 00024: val_logloss did not improve from 0.01671\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0194 - logloss: 0.0163 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 25/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0194 - logloss: 0.0161\n",
      "Epoch 00025: val_logloss improved from 0.01671 to 0.01660, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0194 - logloss: 0.0161 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 26/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0192 - logloss: 0.0159\n",
      "Epoch 00026: val_logloss did not improve from 0.01660\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0192 - logloss: 0.0160 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 27/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0190 - logloss: 0.0157\n",
      "Epoch 00027: val_logloss improved from 0.01660 to 0.01659, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0190 - logloss: 0.0158 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 28/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0190 - logloss: 0.0157\n",
      "Epoch 00028: val_logloss improved from 0.01659 to 0.01654, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0189 - logloss: 0.0156 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 29/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0185 - logloss: 0.0152\n",
      "Epoch 00029: val_logloss improved from 0.01654 to 0.01645, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0185 - logloss: 0.0152 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 30/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0184 - logloss: 0.0152\n",
      "Epoch 00030: val_logloss improved from 0.01645 to 0.01643, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0184 - logloss: 0.0152 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 31/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0183 - logloss: 0.0150\n",
      "Epoch 00031: val_logloss improved from 0.01643 to 0.01641, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0182 - logloss: 0.0150 - val_loss: 0.0197 - val_logloss: 0.0164\n",
      "Epoch 32/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0182 - logloss: 0.0150\n",
      "Epoch 00032: val_logloss improved from 0.01641 to 0.01639, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0182 - logloss: 0.0150 - val_loss: 0.0196 - val_logloss: 0.0164\n",
      "Epoch 33/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0182 - logloss: 0.0149\n",
      "Epoch 00033: val_logloss improved from 0.01639 to 0.01639, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0182 - logloss: 0.0149 - val_loss: 0.0196 - val_logloss: 0.0164\n",
      "Epoch 34/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0182 - logloss: 0.0149\n",
      "Epoch 00034: val_logloss did not improve from 0.01639\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0182 - logloss: 0.0149 - val_loss: 0.0196 - val_logloss: 0.0164\n",
      "Epoch 35/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0182 - logloss: 0.0149\n",
      "Epoch 00035: val_logloss did not improve from 0.01639\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0182 - logloss: 0.0149 - val_loss: 0.0196 - val_logloss: 0.0164\n",
      "Epoch 36/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0181 - logloss: 0.0148\n",
      "Epoch 00036: val_logloss improved from 0.01639 to 0.01639, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0181 - logloss: 0.0148 - val_loss: 0.0196 - val_logloss: 0.0164\n",
      "Epoch 37/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0181 - logloss: 0.0148\n",
      "Epoch 00037: val_logloss improved from 0.01639 to 0.01638, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0181 - logloss: 0.0148 - val_loss: 0.0196 - val_logloss: 0.0164\n",
      "Epoch 38/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0181 - logloss: 0.0148\n",
      "Epoch 00038: val_logloss did not improve from 0.01638\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0180 - logloss: 0.0148 - val_loss: 0.0196 - val_logloss: 0.0164\n",
      "Epoch 39/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0181 - logloss: 0.0148\n",
      "Epoch 00039: val_logloss improved from 0.01638 to 0.01638, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0181 - logloss: 0.0149 - val_loss: 0.0196 - val_logloss: 0.0164\n",
      "Epoch 40/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0181 - logloss: 0.0148\n",
      "Epoch 00040: val_logloss improved from 0.01638 to 0.01637, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0181 - logloss: 0.0148 - val_loss: 0.0196 - val_logloss: 0.0164\n",
      "Fold 3 log loss: 0.01619888078304292\n",
      "Fold 4\n",
      "Epoch 1/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.4822 - logloss: 0.4816\n",
      "Epoch 00001: val_logloss improved from inf to 0.10465, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.4817 - logloss: 0.4790 - val_loss: 0.1063 - val_logloss: 0.1046\n",
      "Epoch 2/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0558 - logloss: 0.0540\n",
      "Epoch 00002: val_logloss improved from 0.10465 to 0.02936, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0558 - logloss: 0.0539 - val_loss: 0.0316 - val_logloss: 0.0294\n",
      "Epoch 3/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0292 - logloss: 0.0267\n",
      "Epoch 00003: val_logloss improved from 0.02936 to 0.02300, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0292 - logloss: 0.0267 - val_loss: 0.0257 - val_logloss: 0.0230\n",
      "Epoch 4/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0253 - logloss: 0.0226\n",
      "Epoch 00004: val_logloss improved from 0.02300 to 0.02057, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0253 - logloss: 0.0225 - val_loss: 0.0234 - val_logloss: 0.0206\n",
      "Epoch 5/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0242 - logloss: 0.0212\n",
      "Epoch 00005: val_logloss improved from 0.02057 to 0.01969, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 0.0242 - logloss: 0.0212 - val_loss: 0.0226 - val_logloss: 0.0197\n",
      "Epoch 6/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0233 - logloss: 0.0203\n",
      "Epoch 00006: val_logloss improved from 0.01969 to 0.01896, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 0.0233 - logloss: 0.0203 - val_loss: 0.0220 - val_logloss: 0.0190\n",
      "Epoch 7/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0229 - logloss: 0.0198\n",
      "Epoch 00007: val_logloss improved from 0.01896 to 0.01863, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0229 - logloss: 0.0198 - val_loss: 0.0217 - val_logloss: 0.0186\n",
      "Epoch 8/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0224 - logloss: 0.0193\n",
      "Epoch 00008: val_logloss improved from 0.01863 to 0.01841, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0224 - logloss: 0.0193 - val_loss: 0.0216 - val_logloss: 0.0184\n",
      "Epoch 9/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0222 - logloss: 0.0190\n",
      "Epoch 00009: val_logloss improved from 0.01841 to 0.01801, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0222 - logloss: 0.0190 - val_loss: 0.0211 - val_logloss: 0.0180\n",
      "Epoch 10/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0221 - logloss: 0.0189\n",
      "Epoch 00010: val_logloss improved from 0.01801 to 0.01782, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0221 - logloss: 0.0188 - val_loss: 0.0210 - val_logloss: 0.0178\n",
      "Epoch 11/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0216 - logloss: 0.0184\n",
      "Epoch 00011: val_logloss improved from 0.01782 to 0.01762, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0216 - logloss: 0.0184 - val_loss: 0.0208 - val_logloss: 0.0176\n",
      "Epoch 12/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0214 - logloss: 0.0181\n",
      "Epoch 00012: val_logloss improved from 0.01762 to 0.01748, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0214 - logloss: 0.0182 - val_loss: 0.0207 - val_logloss: 0.0175\n",
      "Epoch 13/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0211 - logloss: 0.0179\n",
      "Epoch 00013: val_logloss improved from 0.01748 to 0.01746, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0211 - logloss: 0.0179 - val_loss: 0.0207 - val_logloss: 0.0175\n",
      "Epoch 14/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0209 - logloss: 0.0177\n",
      "Epoch 00014: val_logloss improved from 0.01746 to 0.01725, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0209 - logloss: 0.0178 - val_loss: 0.0205 - val_logloss: 0.0172\n",
      "Epoch 15/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0208 - logloss: 0.0176\n",
      "Epoch 00015: val_logloss did not improve from 0.01725\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0208 - logloss: 0.0177 - val_loss: 0.0207 - val_logloss: 0.0175\n",
      "Epoch 16/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0206 - logloss: 0.0174\n",
      "Epoch 00016: val_logloss improved from 0.01725 to 0.01701, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0206 - logloss: 0.0174 - val_loss: 0.0202 - val_logloss: 0.0170\n",
      "Epoch 17/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0205 - logloss: 0.0172\n",
      "Epoch 00017: val_logloss improved from 0.01701 to 0.01695, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0204 - logloss: 0.0172 - val_loss: 0.0202 - val_logloss: 0.0170\n",
      "Epoch 18/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0202 - logloss: 0.0170\n",
      "Epoch 00018: val_logloss improved from 0.01695 to 0.01680, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0202 - logloss: 0.0170 - val_loss: 0.0201 - val_logloss: 0.0168\n",
      "Epoch 19/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0203 - logloss: 0.0171\n",
      "Epoch 00019: val_logloss did not improve from 0.01680\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0203 - logloss: 0.0170 - val_loss: 0.0202 - val_logloss: 0.0169\n",
      "Epoch 20/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0201 - logloss: 0.0168\n",
      "Epoch 00020: val_logloss improved from 0.01680 to 0.01675, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0201 - logloss: 0.0168 - val_loss: 0.0200 - val_logloss: 0.0167\n",
      "Epoch 21/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0197 - logloss: 0.0165\n",
      "Epoch 00021: val_logloss improved from 0.01675 to 0.01673, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0197 - logloss: 0.0165 - val_loss: 0.0200 - val_logloss: 0.0167\n",
      "Epoch 22/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0194 - logloss: 0.0162\n",
      "Epoch 00022: val_logloss improved from 0.01673 to 0.01660, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 23/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0194 - logloss: 0.0162\n",
      "Epoch 00023: val_logloss improved from 0.01660 to 0.01658, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 24/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0193 - logloss: 0.0161\n",
      "Epoch 00024: val_logloss improved from 0.01658 to 0.01656, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0193 - logloss: 0.0161 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 25/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0191 - logloss: 0.0159\n",
      "Epoch 00025: val_logloss improved from 0.01656 to 0.01652, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0191 - logloss: 0.0159 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 26/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0192 - logloss: 0.0159\n",
      "Epoch 00026: val_logloss did not improve from 0.01652\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0192 - logloss: 0.0159 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 27/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0191 - logloss: 0.0159\n",
      "Epoch 00027: val_logloss did not improve from 0.01652\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0191 - logloss: 0.0159 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 28/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0191 - logloss: 0.0159\n",
      "Epoch 00028: val_logloss improved from 0.01652 to 0.01652, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0192 - logloss: 0.0160 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 29/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0191 - logloss: 0.0159\n",
      "Epoch 00029: val_logloss improved from 0.01652 to 0.01651, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0191 - logloss: 0.0159 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 30/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0191 - logloss: 0.0159\n",
      "Epoch 00030: val_logloss improved from 0.01651 to 0.01651, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0191 - logloss: 0.0159 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 31/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0191 - logloss: 0.0159\n",
      "Epoch 00031: val_logloss improved from 0.01651 to 0.01651, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0191 - logloss: 0.0159 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 32/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0191 - logloss: 0.0159\n",
      "Epoch 00032: val_logloss improved from 0.01651 to 0.01651, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0191 - logloss: 0.0159 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 33/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0192 - logloss: 0.0160\n",
      "Epoch 00033: val_logloss improved from 0.01651 to 0.01651, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0192 - logloss: 0.0159 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 34/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0191 - logloss: 0.0159\n",
      "Epoch 00034: val_logloss improved from 0.01651 to 0.01650, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0191 - logloss: 0.0158 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 35/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0191 - logloss: 0.0158\n",
      "Epoch 00035: val_logloss improved from 0.01650 to 0.01649, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0191 - logloss: 0.0159 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 36/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0190 - logloss: 0.0158\n",
      "Epoch 00036: val_logloss improved from 0.01649 to 0.01649, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0190 - logloss: 0.0158 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 37/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0190 - logloss: 0.0158\n",
      "Epoch 00037: val_logloss improved from 0.01649 to 0.01649, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0190 - logloss: 0.0158 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 38/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0191 - logloss: 0.0159\n",
      "Epoch 00038: val_logloss improved from 0.01649 to 0.01649, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0191 - logloss: 0.0158 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Epoch 39/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0191 - logloss: 0.0158\n",
      "Epoch 00039: val_logloss did not improve from 0.01649\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0191 - logloss: 0.0159 - val_loss: 0.0198 - val_logloss: 0.0165\n",
      "Epoch 40/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0190 - logloss: 0.0157\n",
      "Epoch 00040: val_logloss improved from 0.01649 to 0.01649, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0190 - logloss: 0.0157 - val_loss: 0.0197 - val_logloss: 0.0165\n",
      "Fold 4 log loss: 0.016395145717847177\n",
      "Fold 5\n",
      "Epoch 1/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.4803 - logloss: 0.4798\n",
      "Epoch 00001: val_logloss improved from inf to 0.09890, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.4799 - logloss: 0.4775 - val_loss: 0.1001 - val_logloss: 0.0989\n",
      "Epoch 2/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0562 - logloss: 0.0543\n",
      "Epoch 00002: val_logloss improved from 0.09890 to 0.02868, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0560 - logloss: 0.0540 - val_loss: 0.0308 - val_logloss: 0.0287\n",
      "Epoch 3/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0292 - logloss: 0.0267\n",
      "Epoch 00003: val_logloss improved from 0.02868 to 0.02296, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0292 - logloss: 0.0267 - val_loss: 0.0255 - val_logloss: 0.0230\n",
      "Epoch 4/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0257 - logloss: 0.0229\n",
      "Epoch 00004: val_logloss improved from 0.02296 to 0.02095, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0257 - logloss: 0.0229 - val_loss: 0.0237 - val_logloss: 0.0210\n",
      "Epoch 5/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0244 - logloss: 0.0215\n",
      "Epoch 00005: val_logloss improved from 0.02095 to 0.01997, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0244 - logloss: 0.0215 - val_loss: 0.0228 - val_logloss: 0.0200\n",
      "Epoch 6/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0234 - logloss: 0.0203\n",
      "Epoch 00006: val_logloss improved from 0.01997 to 0.01927, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0234 - logloss: 0.0203 - val_loss: 0.0222 - val_logloss: 0.0193\n",
      "Epoch 7/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0228 - logloss: 0.0197\n",
      "Epoch 00007: val_logloss improved from 0.01927 to 0.01890, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0228 - logloss: 0.0198 - val_loss: 0.0219 - val_logloss: 0.0189\n",
      "Epoch 8/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0225 - logloss: 0.0193\n",
      "Epoch 00008: val_logloss improved from 0.01890 to 0.01864, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0225 - logloss: 0.0194 - val_loss: 0.0216 - val_logloss: 0.0186\n",
      "Epoch 9/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0224 - logloss: 0.0192\n",
      "Epoch 00009: val_logloss improved from 0.01864 to 0.01835, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0224 - logloss: 0.0192 - val_loss: 0.0214 - val_logloss: 0.0184\n",
      "Epoch 10/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0219 - logloss: 0.0187\n",
      "Epoch 00010: val_logloss improved from 0.01835 to 0.01819, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0219 - logloss: 0.0188 - val_loss: 0.0213 - val_logloss: 0.0182\n",
      "Epoch 11/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0218 - logloss: 0.0186\n",
      "Epoch 00011: val_logloss improved from 0.01819 to 0.01789, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0218 - logloss: 0.0186 - val_loss: 0.0210 - val_logloss: 0.0179\n",
      "Epoch 12/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0214 - logloss: 0.0182\n",
      "Epoch 00012: val_logloss did not improve from 0.01789\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0215 - logloss: 0.0182 - val_loss: 0.0211 - val_logloss: 0.0179\n",
      "Epoch 13/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0213 - logloss: 0.0181\n",
      "Epoch 00013: val_logloss improved from 0.01789 to 0.01761, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0213 - logloss: 0.0181 - val_loss: 0.0207 - val_logloss: 0.0176\n",
      "Epoch 14/40\n",
      "134/138 [============================>.] - ETA: 0s - loss: 0.0210 - logloss: 0.0178\n",
      "Epoch 00014: val_logloss improved from 0.01761 to 0.01755, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0210 - logloss: 0.0178 - val_loss: 0.0207 - val_logloss: 0.0176\n",
      "Epoch 15/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0208 - logloss: 0.0176\n",
      "Epoch 00015: val_logloss improved from 0.01755 to 0.01749, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 0.0208 - logloss: 0.0176 - val_loss: 0.0206 - val_logloss: 0.0175\n",
      "Epoch 16/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0206 - logloss: 0.0173\n",
      "Epoch 00016: val_logloss improved from 0.01749 to 0.01736, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0206 - logloss: 0.0174 - val_loss: 0.0205 - val_logloss: 0.0174\n",
      "Epoch 17/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0208 - logloss: 0.0175\n",
      "Epoch 00017: val_logloss improved from 0.01736 to 0.01725, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0208 - logloss: 0.0175 - val_loss: 0.0204 - val_logloss: 0.0173\n",
      "Epoch 18/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0204 - logloss: 0.0172\n",
      "Epoch 00018: val_logloss improved from 0.01725 to 0.01721, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0204 - logloss: 0.0172 - val_loss: 0.0205 - val_logloss: 0.0172\n",
      "Epoch 19/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0201 - logloss: 0.0169\n",
      "Epoch 00019: val_logloss improved from 0.01721 to 0.01708, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0202 - logloss: 0.0169 - val_loss: 0.0203 - val_logloss: 0.0171\n",
      "Epoch 20/40\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.0200 - logloss: 0.0167\n",
      "Epoch 00020: val_logloss did not improve from 0.01708\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0200 - logloss: 0.0167 - val_loss: 0.0202 - val_logloss: 0.0171\n",
      "Epoch 21/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0198 - logloss: 0.0166\n",
      "Epoch 00021: val_logloss improved from 0.01708 to 0.01690, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0198 - logloss: 0.0166 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 22/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0197 - logloss: 0.0164\n",
      "Epoch 00022: val_logloss improved from 0.01690 to 0.01689, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0197 - logloss: 0.0164 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 23/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0195 - logloss: 0.0162\n",
      "Epoch 00023: val_logloss improved from 0.01689 to 0.01685, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0195 - logloss: 0.0163 - val_loss: 0.0200 - val_logloss: 0.0169\n",
      "Epoch 24/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0194 - logloss: 0.0162\n",
      "Epoch 00024: val_logloss improved from 0.01685 to 0.01685, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0194 - logloss: 0.0162 - val_loss: 0.0201 - val_logloss: 0.0169\n",
      "Epoch 25/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0190 - logloss: 0.0158\n",
      "Epoch 00025: val_logloss improved from 0.01685 to 0.01672, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0190 - logloss: 0.0157 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 26/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0189 - logloss: 0.0156\n",
      "Epoch 00026: val_logloss improved from 0.01672 to 0.01669, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0189 - logloss: 0.0156 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 27/40\n",
      "136/138 [============================>.] - ETA: 0s - loss: 0.0188 - logloss: 0.0156\n",
      "Epoch 00027: val_logloss improved from 0.01669 to 0.01668, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0188 - logloss: 0.0156 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 28/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0187 - logloss: 0.0155\n",
      "Epoch 00028: val_logloss improved from 0.01668 to 0.01666, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0188 - logloss: 0.0155 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 29/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0187 - logloss: 0.0154\n",
      "Epoch 00029: val_logloss improved from 0.01666 to 0.01665, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0187 - logloss: 0.0155 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 30/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0187 - logloss: 0.0154\n",
      "Epoch 00030: val_logloss improved from 0.01665 to 0.01665, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0199 - val_logloss: 0.0167\n",
      "Epoch 31/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0188 - logloss: 0.0155\n",
      "Epoch 00031: val_logloss improved from 0.01665 to 0.01665, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0188 - logloss: 0.0156 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 32/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0187 - logloss: 0.0154\n",
      "Epoch 00032: val_logloss improved from 0.01665 to 0.01665, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0187 - logloss: 0.0154 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 33/40\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 0.0186 - logloss: 0.0154\n",
      "Epoch 00033: val_logloss improved from 0.01665 to 0.01664, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 34/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0187 - logloss: 0.0155\n",
      "Epoch 00034: val_logloss did not improve from 0.01664\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0187 - logloss: 0.0155 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 35/40\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 0.0186 - logloss: 0.0154\n",
      "Epoch 00035: val_logloss did not improve from 0.01664\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0199 - val_logloss: 0.0166\n",
      "Epoch 36/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0186 - logloss: 0.0154\n",
      "Epoch 00036: val_logloss improved from 0.01664 to 0.01664, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 37/40\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 0.0187 - logloss: 0.0154\n",
      "Epoch 00037: val_logloss improved from 0.01664 to 0.01663, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 38/40\n",
      "137/138 [============================>.] - ETA: 0s - loss: 0.0186 - logloss: 0.0154\n",
      "Epoch 00038: val_logloss did not improve from 0.01663\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 39/40\n",
      "135/138 [============================>.] - ETA: 0s - loss: 0.0186 - logloss: 0.0153\n",
      "Epoch 00039: val_logloss did not improve from 0.01663\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Epoch 40/40\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 0.0186 - logloss: 0.0154\n",
      "Epoch 00040: val_logloss improved from 0.01663 to 0.01663, saving model to ./nn_model.h5\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0186 - logloss: 0.0154 - val_loss: 0.0198 - val_logloss: 0.0166\n",
      "Fold 5 log loss: 0.016470897354368304\n",
      "Seed 2\n",
      "Fold 1 log loss: 0.016513292365669324\n",
      "Fold 2 log loss: 0.01624315331939081\n",
      "Fold 3 log loss: 0.01619888078304292\n",
      "Fold 4 log loss: 0.016395145717847177\n",
      "Fold 5 log loss: 0.016470897354368304\n",
      "Std of log loss: 0.00012373618020041164\n",
      "Total log loss: 0.016364274568585954\n",
      "Total log loss in targets: 0.016298379118239677\n"
     ]
    }
   ],
   "source": [
    "seeds = [0,1,2]\n",
    "\n",
    "target_oof = np.zeros([len(fn_train),fn_targets.shape[1]])\n",
    "target_pred = np.zeros([len(fn_test),fn_targets.shape[1]])\n",
    "\n",
    "nontarget_oof = np.zeros([len(fn_train),fn_nontargets.shape[1]])\n",
    "nontarget_pred = np.zeros([len(fn_test),fn_nontargets.shape[1]])\n",
    "\n",
    "for seed_ in seeds:\n",
    "    oof, keras_pred = modelling_keras(fn_train, fn_targets, fn_test, fn_train.shape[1], fn_targets.shape[1], seed_)\n",
    "    target_oof += oof / len(seeds)\n",
    "    target_pred += keras_pred / len(seeds)\n",
    "print(\"Total log loss in targets: {}\".format(mean_log_loss(fn_targets, target_oof)))\n",
    "\n",
    "#for seed_ in seeds:\n",
    "#    oof, keras_pred = modelling_keras(fn_train, fn_nontargets, fn_test, fn_train.shape[1], fn_nontargets.shape[1], seed_)\n",
    "#    nontarget_oof += oof / len(seeds)\n",
    "#    nontarget_pred += keras_pred / len(seeds)\n",
    "#print(\"Total log loss in Non targets: {}\".format(mean_log_loss(oof_targets, nontarget_oof)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 4.660614,
     "end_time": "2020-10-13T02:05:20.714353",
     "exception": false,
     "start_time": "2020-10-13T02:05:16.053739",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T02:05:30.430755Z",
     "iopub.status.busy": "2020-10-13T02:05:30.429748Z",
     "iopub.status.idle": "2020-10-13T02:05:30.432853Z",
     "shell.execute_reply": "2020-10-13T02:05:30.431822Z"
    },
    "papermill": {
     "duration": 4.704103,
     "end_time": "2020-10-13T02:05:30.433049",
     "exception": false,
     "start_time": "2020-10-13T02:05:25.728946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#n_train = f_train.copy()\n",
    "#n_test = f_test.copy()\n",
    "\n",
    "#n_train[\"target_sum\"] = target_oof.sum(axis=1)\n",
    "#n_train[\"nontarget_sum\"] = nontarget_oof.sum(axis=1)\n",
    "#n_test[\"target_sum\"] = target_pred.sum(axis=1)\n",
    "#n_test.loc[noncons_test_index, \"target_sum\"] = 0\n",
    "#n_test[\"nontarget_sum\"] = nontarget_pred.sum(axis=1)\n",
    "#n_test.loc[noncons_test_index, \"nontarget_sum\"] = 0\n",
    "\n",
    "#n_train = n_train.to_numpy()\n",
    "#n_test = n_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T02:05:40.530779Z",
     "iopub.status.busy": "2020-10-13T02:05:40.529791Z",
     "iopub.status.idle": "2020-10-13T02:05:40.532069Z",
     "shell.execute_reply": "2020-10-13T02:05:40.531444Z"
    },
    "papermill": {
     "duration": 5.030533,
     "end_time": "2020-10-13T02:05:40.532184",
     "exception": false,
     "start_time": "2020-10-13T02:05:35.501651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#oof_final = np.zeros([len(n_train),fn_targets.shape[1]])\n",
    "#pred_final = np.zeros([len(n_test),fn_targets.shape[1]])\n",
    "\n",
    "#seeds = [10,40]\n",
    "#for seed_ in seeds:\n",
    "#    oof, keras_pred = modelling_keras(n_train, fn_targets, n_test, n_train.shape[1], fn_targets.shape[1], seed_)\n",
    "#    oof_final += oof / len(seeds)\n",
    "#    pred_final += keras_pred / len(seeds)\n",
    "#print(\"Total log loss: {}\".format(mean_log_loss(fn_targets, oof_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T02:05:49.837500Z",
     "iopub.status.busy": "2020-10-13T02:05:49.836538Z",
     "iopub.status.idle": "2020-10-13T02:05:56.393731Z",
     "shell.execute_reply": "2020-10-13T02:05:56.392820Z"
    },
    "papermill": {
     "duration": 11.05555,
     "end_time": "2020-10-13T02:05:56.393892",
     "exception": false,
     "start_time": "2020-10-13T02:05:45.338342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF log loss:  0.015163987055253063\n"
     ]
    }
   ],
   "source": [
    "t = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "checkscore = t.copy()\n",
    "checkscore.loc[checkscore.index.isin(cons_train_index),target_feats] = np.clip(target_oof, p_min, p_max)\n",
    "checkscore.loc[checkscore.index.isin(noncons_train_index),target_feats] = 0\n",
    "t.drop(\"sig_id\", axis=1, inplace=True)\n",
    "print('OOF log loss: ', log_loss(np.ravel(t), np.ravel(np.array(checkscore.iloc[:,1:]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 4.817449,
     "end_time": "2020-10-13T02:06:05.818694",
     "exception": false,
     "start_time": "2020-10-13T02:06:01.001245",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T02:06:15.517514Z",
     "iopub.status.busy": "2020-10-13T02:06:15.516397Z",
     "iopub.status.idle": "2020-10-13T02:06:18.028721Z",
     "shell.execute_reply": "2020-10-13T02:06:18.028114Z"
    },
    "papermill": {
     "duration": 7.541691,
     "end_time": "2020-10-13T02:06:18.029220",
     "exception": false,
     "start_time": "2020-10-13T02:06:10.487529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub[target_feats] = np.clip(target_pred,p_min,p_max) #label smoothing\n",
    "sub.loc[noncons_test_index,target_feats] = 0\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 5.106594,
     "end_time": "2020-10-13T02:06:27.744697",
     "exception": false,
     "start_time": "2020-10-13T02:06:22.638103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 962.648363,
   "end_time": "2020-10-13T02:06:34.117036",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-13T01:50:31.468673",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
