{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import datetime\n",
    "from time import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, log_loss, roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix, auc\n",
    "import lightgbm as lgb\n",
    "from functools import partial\n",
    "import copy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import random\n",
    "from hyperopt import hp, tpe, Trials, fmin, space_eval\n",
    "import cv2\n",
    "from catboost import CatBoost\n",
    "from catboost import Pool\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.max_rows\",1000)\n",
    "np.set_printoptions(precision=8)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../../../20200125atma/input/train.csv\")\n",
    "test = pd.read_csv(\"../../../20200125atma/input/test.csv\")\n",
    "userlog = pd.read_csv(\"../../../20200125atma/input/user_log.csv\")\n",
    "poi = pd.read_csv(\"../../../20200125atma/input/poi.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_y = []\n",
    "for i in range(13411):\n",
    "    img = cv2.imread('../../../20200125atma/input/images/'+str(i)+'.png')\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  # HSV 色空間に変換\n",
    "\n",
    "    red = cv2.inRange(hsv, np.array([145, 70, 0]), np.array([180, 255, 255]))\n",
    "    yellow = cv2.inRange(hsv, (15,0,0), (36, 255, 255))\n",
    "    green = cv2.inRange(hsv, np.array([30, 190, 0]), np.array([90, 255, 255]))\n",
    "    blue = cv2.inRange(hsv, np.array([108, 121, 0]), np.array([120, 255, 255]))\n",
    "    white = cv2.inRange(hsv, np.array([108, 21, 0]), np.array([255, 70, 255]))\n",
    "\n",
    "    # 白だけゴミがあるので、収縮演算\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    white = cv2.erode(yellow, kernel)\n",
    "\n",
    "    bin_imgs = {'red': red, 'yellow': yellow, 'green': green,\n",
    "            'blue': blue, 'white': white}\n",
    "\n",
    "    for label, bin_img in bin_imgs.items():\n",
    "        contours, _ = cv2.findContours(bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = list(filter(lambda cnt: len(cnt) > 30, contours))\n",
    "        count = len(contours)\n",
    "    \n",
    "        if label == \"yellow\":\n",
    "            list_y.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(train, test, userlog, poi):\n",
    "    userlog[\"sysname\"][userlog.sysname == \"ANDROID\"] = \"Android\"\n",
    "    userlog[\"lang\"][userlog.lang == \"ja_JP\"] = \"ja_JP\"\n",
    "    poi = poi.rename(columns={\"latitude\": \"store_lat\", \"longitude\": \"store_lon\"})\n",
    "    train = pd.merge(train, poi, on =\"pid\", how = \"left\")\n",
    "    test = pd.merge(test, poi, on =\"pid\", how = \"left\")\n",
    "    userlog = pd.merge(userlog, train[[\"session_id\", \"store_lat\", \"store_lon\", \"radius\", \"pid\"]], on=\"session_id\", how=\"left\")\n",
    "    userlog = pd.merge(userlog, test[[\"session_id\", \"store_lat\", \"store_lon\", \"radius\", \"pid\"]], on=\"session_id\", how=\"left\")\n",
    "    userlog[\"store_lat\"] = np.nanmax(userlog[[\"store_lat_x\", \"store_lat_y\"]], axis=1)\n",
    "    userlog[\"store_lon\"] = np.nanmax(userlog[[\"store_lon_x\", \"store_lon_y\"]], axis=1)\n",
    "    userlog[\"radius\"] = np.nanmax(userlog[[\"radius_x\", \"radius_y\"]], axis=1)\n",
    "    userlog[\"pid\"] = np.nanmax(userlog[[\"pid_x\", \"pid_y\"]], axis=1)\n",
    "    drop_features = [\"store_lat_x\", \"store_lat_y\", \"store_lon_x\", \"store_lon_y\", \"radius_x\", \"radius_y\", \"pid_x\", \"pid_y\"]\n",
    "    userlog.drop(drop_features, axis=1, inplace=True)\n",
    "    userlog[\"distance\"] = np.sqrt((userlog[\"latitude\"]- userlog[\"store_lat\"])**2 + (userlog[\"longitude\"]-userlog[\"store_lon\"])** 2 )\n",
    "    userlog[\"time\"] = userlog[\"hour\"].map(str) + str(\":\") + userlog[\"minute\"].map(str) + str(\":\") + userlog[\"second\"].map(str)\n",
    "    userlog[\"time\"] = pd.to_datetime(userlog['time'],format= '%H:%M:%S' )\n",
    "    userlog = userlog.sort_values([\"session_id\", \"hour\", \"minute\", \"second\"]).reset_index(drop=True)\n",
    "    userlog[\"virtual_dis\"] = 6370 * np.arccos(np.sin(userlog[\"latitude\"])*np.sin(userlog[\"store_lat\"]) + np.cos(userlog[\"latitude\"])*np.cos(userlog[\"store_lat\"])*np.cos(userlog[\"longitude\"]-userlog[\"store_lon\"]))\n",
    "    userlog[\"in_store\"] = userlog[\"virtual_dis\"] < userlog[\"radius\"]\n",
    "    unique_sess = pd.DataFrame(userlog.groupby(\"pid\")[\"session_id\"].nunique().copy().reset_index(drop=False))\n",
    "    unique_sess = unique_sess.rename(columns = {\"session_id\": \"uni_sess_per_pid\"})\n",
    "    userlog = pd.merge(userlog, unique_sess, on =\"pid\", how = \"left\")\n",
    "    return train, test, userlog, poi, unique_sess\n",
    "train, test, userlog, poi, unique_sess = preprocess(train, test, userlog, poi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(train, test, userlog):\n",
    "    os_list =  sorted(list(set(userlog['sysname'].unique())))\n",
    "    os_map = dict(zip(os_list, np.arange(len(os_list))))\n",
    "    userlog[\"sysname\"] = userlog[\"sysname\"].map(os_map)\n",
    "    \n",
    "    lang_list =  sorted(list(set(userlog['lang'].unique())))\n",
    "    lang_map = dict(zip(lang_list, np.arange(len(lang_list))))\n",
    "    userlog[\"lang\"] = userlog[\"lang\"].map(lang_map)\n",
    "    \n",
    "    timezone_list =  sorted(list(set(userlog['timezone'].unique())))\n",
    "    timezone_map = dict(zip(timezone_list, np.arange(len(timezone_list))))\n",
    "    userlog[\"timezone\"] = userlog[\"timezone\"].map(timezone_map)\n",
    "\n",
    "    return train, test, userlog\n",
    "train, test, userlog = encode(train, test, userlog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[train.session_id == \"0003f26df5d8b928b416fba58efd5c91\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#userlog[userlog.session_id == \"0003f26df5d8b928b416fba58efd5c91\"][\"pid\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>sysname</th>\n",
       "      <th>optout</th>\n",
       "      <th>lang</th>\n",
       "      <th>timezone</th>\n",
       "      <th>session_id</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>categorical_1</th>\n",
       "      <th>categorical_2</th>\n",
       "      <th>categorical_3</th>\n",
       "      <th>categorical_4</th>\n",
       "      <th>categorical_5</th>\n",
       "      <th>categorical_6</th>\n",
       "      <th>store_lat</th>\n",
       "      <th>store_lon</th>\n",
       "      <th>radius</th>\n",
       "      <th>pid</th>\n",
       "      <th>distance</th>\n",
       "      <th>time</th>\n",
       "      <th>virtual_dis</th>\n",
       "      <th>in_store</th>\n",
       "      <th>uni_sess_per_pid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.650300</td>\n",
       "      <td>46.780509</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0003f26df5d8b928b416fba58efd5c91</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>35.651739</td>\n",
       "      <td>46.776134</td>\n",
       "      <td>118.0</td>\n",
       "      <td>354655367.0</td>\n",
       "      <td>0.004606</td>\n",
       "      <td>1900-01-01 00:33:31</td>\n",
       "      <td>15.744307</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.650298</td>\n",
       "      <td>46.780512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0003f26df5d8b928b416fba58efd5c91</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>35.651739</td>\n",
       "      <td>46.776134</td>\n",
       "      <td>118.0</td>\n",
       "      <td>354655367.0</td>\n",
       "      <td>0.004609</td>\n",
       "      <td>1900-01-01 00:33:31</td>\n",
       "      <td>15.758882</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.650286</td>\n",
       "      <td>46.780524</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0003f26df5d8b928b416fba58efd5c91</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>35.651739</td>\n",
       "      <td>46.776134</td>\n",
       "      <td>118.0</td>\n",
       "      <td>354655367.0</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>1900-01-01 02:18:33</td>\n",
       "      <td>15.832117</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    latitude  longitude  sysname  optout  lang  timezone  \\\n",
       "0  35.650300  46.780509        0       0     9         1   \n",
       "1  35.650298  46.780512        0       0     9         1   \n",
       "2  35.650286  46.780524        0       0     9         1   \n",
       "\n",
       "                         session_id  hour  minute  second  day_of_week  \\\n",
       "0  0003f26df5d8b928b416fba58efd5c91     0      33      31            6   \n",
       "1  0003f26df5d8b928b416fba58efd5c91     0      33      31            6   \n",
       "2  0003f26df5d8b928b416fba58efd5c91     2      18      33            6   \n",
       "\n",
       "   categorical_1  categorical_2  categorical_3  categorical_4  categorical_5  \\\n",
       "0              4              0             44            1.0              1   \n",
       "1              4              1             44            1.0              1   \n",
       "2              4              2             44            1.0              1   \n",
       "\n",
       "   categorical_6  store_lat  store_lon  radius          pid  distance  \\\n",
       "0            187  35.651739  46.776134   118.0  354655367.0  0.004606   \n",
       "1            187  35.651739  46.776134   118.0  354655367.0  0.004609   \n",
       "2            187  35.651739  46.776134   118.0  354655367.0  0.004624   \n",
       "\n",
       "                 time  virtual_dis  in_store  uni_sess_per_pid  \n",
       "0 1900-01-01 00:33:31    15.744307      True                16  \n",
       "1 1900-01-01 00:33:31    15.758882      True                16  \n",
       "2 1900-01-01 02:18:33    15.832117      True                16  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userlog.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logdata(user_sample):\n",
    "    day_of_week_counts = {\"day\"+str(day) : 0 for day in range(7)}\n",
    "\n",
    "    all_results = []\n",
    "    features = {\"accumulated_actions\":0}\n",
    "    features[\"accumulated_actions\"] = user_sample.shape[0]\n",
    "    features[\"session_id\"] = user_sample.iloc[0][\"session_id\"]\n",
    "    features[\"OS\"] = user_sample.iloc[0][\"sysname\"]\n",
    "    features[\"lang\"] = user_sample.iloc[0][\"lang\"]\n",
    "    features[\"timezone\"] = user_sample.iloc[0][\"timezone\"]\n",
    "    features[\"optout_count\"] = np.sum(user_sample[\"optout\"])\n",
    "    distance = np.array(user_sample[\"distance\"])\n",
    "    features[\"max_dist\"] = np.nanmax(distance)\n",
    "    features[\"min_dist\"] = np.nanmin(distance)\n",
    "    features[\"std_dist\"] = np.nanstd(distance)\n",
    "    features[\"closest_lat\"] = user_sample[user_sample.distance == features[\"min_dist\"]].iloc[0][\"latitude\"]\n",
    "    features[\"closest_lon\"] = user_sample[user_sample.distance == features[\"min_dist\"]].iloc[0][\"longitude\"]\n",
    "    features[\"categorical_1\"] = user_sample[\"categorical_1\"].nunique()\n",
    "    features[\"categorical_2\"] = user_sample[\"categorical_2\"].nunique()\n",
    "    features[\"categorical_3\"] = user_sample[\"categorical_3\"].nunique()\n",
    "    features[\"categorical_4\"] = user_sample[\"categorical_4\"].nunique()\n",
    "    features[\"categorical_5\"] = user_sample[\"categorical_5\"].nunique()\n",
    "    features[\"categorical_6\"] = user_sample[\"categorical_6\"].nunique()\n",
    "    #features[\"cont_hour\"] = np.max(user_sample[\"hour\"]) - np.min(user_sample[\"hour\"])\n",
    "    #features[\"closest_min\"] = user_sample[user_sample.distance == features[\"min_dist\"]].iloc[0][\"minute\"]\n",
    "    #features[\"closest_second\"] = user_sample[user_sample.distance == features[\"min_dist\"]].iloc[0][\"second\"]\n",
    "    #instore_queue = np.array2string(np.array(user_sample[\"in_store\"].astype(int)), separator=',')\n",
    "    #features[\"exit_count\"] = instore_queue[1:-1].replace(',', '').count(\"10\")\n",
    "    #second_min_index = user_sample[\"distance\"].nsmallest(2).index[-1]\n",
    "    #features[\"2ndmin_dist\"] = user_sample.loc[second_min_index][\"distance\"] #直接indexを入れるときはloc\n",
    "    features[\"pid\"] = int(user_sample.iloc[0][\"pid\"])\n",
    "    \n",
    "    n_of_days = Counter(user_sample['day_of_week']) \n",
    "    for key in n_of_days.keys():\n",
    "        day_of_week_counts[\"day\"+str(key)] += n_of_days[key]\n",
    "    features.update(day_of_week_counts)\n",
    "    \n",
    "    features[\"in_store\"] = np.sum(user_sample[\"in_store\"])\n",
    "    \n",
    "    all_results.append(features)\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9263e7d0a53b44c88394fbd6e1ae87fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='session_id', max=5601, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_log_info(userlog):\n",
    "    compiled_log = []\n",
    "\n",
    "    for i, (ses_id, user_sample) in tqdm(enumerate(userlog.groupby(['session_id', 'pid'], sort=False)), total=userlog.session_id.nunique(), desc='session_id', position=0):\n",
    "        compiled_log += get_logdata(user_sample)\n",
    "    reduced_log = pd.DataFrame(compiled_log)\n",
    "    return reduced_log \n",
    "reduced_log = get_log_info(userlog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6612, 34) (6799, 33)\n"
     ]
    }
   ],
   "source": [
    "def postprocess(train, test, reduced_log, unique_sess):\n",
    "    drop_features = [\"imid\", \"pid\"]\n",
    "    new_train = pd.merge(train, reduced_log, on =[\"session_id\", \"pid\"], how = \"left\")\n",
    "    new_test = pd.merge(test, reduced_log, on =[\"session_id\", \"pid\"], how = \"left\")\n",
    "    new_train[\"yellow_in_pic\"] = list_y[:6612]\n",
    "    new_test[\"yellow_in_pic\"] = list_y[6612:]\n",
    "    pid_count_mean = train.groupby('pid').target.count()\n",
    "    new_train['pid_count_enc'] = new_train['pid'].map(pid_count_mean)\n",
    "    new_test['pid_count_enc'] = new_test['pid'].map(pid_count_mean)\n",
    "    new_train = pd.merge(new_train, unique_sess, on =\"pid\", how = \"left\")\n",
    "    new_test = pd.merge(new_test, unique_sess, on =\"pid\", how = \"left\")\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(new_train[\"session_id\"]))\n",
    "    new_train[\"session_id\"] = lbl.transform(list(new_train[\"session_id\"]))\n",
    "    new_train.drop(drop_features, axis=1, inplace=True)\n",
    "    new_test.drop(drop_features, axis=1, inplace=True)\n",
    "    print(new_train.shape, new_test.shape)\n",
    "    return new_train, new_test\n",
    "new_train, new_test = postprocess(train, test, reduced_log, unique_sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>session_id</th>\n",
       "      <th>store_lat</th>\n",
       "      <th>store_lon</th>\n",
       "      <th>radius</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>OS</th>\n",
       "      <th>accumulated_actions</th>\n",
       "      <th>categorical_1</th>\n",
       "      <th>categorical_2</th>\n",
       "      <th>categorical_3</th>\n",
       "      <th>categorical_4</th>\n",
       "      <th>categorical_5</th>\n",
       "      <th>categorical_6</th>\n",
       "      <th>closest_lat</th>\n",
       "      <th>closest_lon</th>\n",
       "      <th>day0</th>\n",
       "      <th>day1</th>\n",
       "      <th>day2</th>\n",
       "      <th>day3</th>\n",
       "      <th>day4</th>\n",
       "      <th>day5</th>\n",
       "      <th>day6</th>\n",
       "      <th>in_store</th>\n",
       "      <th>lang</th>\n",
       "      <th>max_dist</th>\n",
       "      <th>min_dist</th>\n",
       "      <th>optout_count</th>\n",
       "      <th>std_dist</th>\n",
       "      <th>timezone</th>\n",
       "      <th>yellow_in_pic</th>\n",
       "      <th>pid_count_enc</th>\n",
       "      <th>uni_sess_per_pid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2315</td>\n",
       "      <td>36.320751</td>\n",
       "      <td>46.104755</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>36.320923</td>\n",
       "      <td>46.104648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>7</td>\n",
       "      <td>0.072056</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014947</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2279</td>\n",
       "      <td>35.564913</td>\n",
       "      <td>46.744633</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>35.565118</td>\n",
       "      <td>46.743960</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "      <td>0.005153</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>959</td>\n",
       "      <td>35.693777</td>\n",
       "      <td>46.784288</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.693449</td>\n",
       "      <td>46.784401</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>131</td>\n",
       "      <td>9</td>\n",
       "      <td>0.012322</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003843</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  session_id  store_lat  store_lon  radius  type  name  OS  \\\n",
       "0       0        2315  36.320751  46.104755      25     2     0   1   \n",
       "1       0        2279  35.564913  46.744633      51     0     1   0   \n",
       "2       0         959  35.693777  46.784288     189     0     1   0   \n",
       "\n",
       "   accumulated_actions  categorical_1  categorical_2  categorical_3  \\\n",
       "0                  187              2              3              2   \n",
       "1                  111              1              3              1   \n",
       "2                  131              1              3              1   \n",
       "\n",
       "   categorical_4  categorical_5  categorical_6  closest_lat  closest_lon  \\\n",
       "0              1              4              7    36.320923    46.104648   \n",
       "1              1              2             18    35.565118    46.743960   \n",
       "2              0              3              1    35.693449    46.784401   \n",
       "\n",
       "   day0  day1  day2  day3  day4  day5  day6  in_store  lang  max_dist  \\\n",
       "0     0     0     0     0   187     0     0       149     7  0.072056   \n",
       "1   111     0     0     0     0     0     0       111     9  0.005153   \n",
       "2     0     0     0     0     0     0   131       131     9  0.012322   \n",
       "\n",
       "   min_dist  optout_count  std_dist  timezone  yellow_in_pic  pid_count_enc  \\\n",
       "0  0.000203             0  0.014947         1              4             15   \n",
       "1  0.000704             0  0.000580         1              3             18   \n",
       "2  0.000347             0  0.003843         1              1             11   \n",
       "\n",
       "   uni_sess_per_pid  \n",
       "0                26  \n",
       "1                37  \n",
       "2                21  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_train[\"session_id\"].value_counts()\n",
    "#new_train[new_train.session_id == 2792]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's auc: 0.975888\tvalid_1's auc: 0.876189\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[151]\ttraining's auc: 0.999681\tvalid_1's auc: 0.896895\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's auc: 0.976849\tvalid_1's auc: 0.883745\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[162]\ttraining's auc: 0.99913\tvalid_1's auc: 0.897243\n",
      "ROC = 0.8836396826299426\n",
      "[[6465   14]\n",
      " [ 120   13]]\n"
     ]
    }
   ],
   "source": [
    "categoricals = ['lang', 'OS']\n",
    "\n",
    "lgbm_params = {'objective': 'binary','eval_metric': 'auc','metric': 'auc', 'boosting_type': 'gbdt',\n",
    " 'tree_learner': 'serial','learning_rate': 0.017891320270412462,'max_depth': 5, 'random_seed':42}\n",
    "    \n",
    "lgbm_params2 = {'objective': 'binary','eval_metric': 'auc','metric': 'auc', 'boosting_type': 'gbdt',\n",
    " 'tree_learner': 'serial',   'learning_rate': 0.01861754102536491,'random_seed':43, 'max_depth': 4}\n",
    "\n",
    "lgbm_params3 = {'objective': 'binary','eval_metric': 'auc','metric': 'auc', 'boosting_type': 'gbdt',\n",
    " 'tree_learner': 'serial', 'learning_rate': 0.09982045811322946, 'random_seed':44,'max_depth': 3}\n",
    "\n",
    "def modelling(new_train, new_test, lgbm_params):\n",
    "    X_train = new_train.drop(['target'],axis=1).copy()\n",
    "    y_train = new_train.target.copy()\n",
    "    \n",
    "    remove_features = [\"session_id\", \"categorical_1\", \"categorical_2\", \"categorical_3\"]\n",
    "    for i in X_train.columns:\n",
    "        if (X_train[i].std() == 0) and i not in remove_features:\n",
    "            remove_features.append(i)\n",
    "    X_train = X_train.drop(remove_features, axis=1)\n",
    "    X_test = new_test.copy()\n",
    "    X_test = X_test.drop(remove_features, axis=1)\n",
    "\n",
    "    n_folds=4\n",
    "    skf=StratifiedKFold(n_splits = n_folds)\n",
    "    models = []\n",
    "    \n",
    "    valid = np.array([])\n",
    "    valid_lgb = pd.DataFrame(np.zeros([X_train.shape[0]]))\n",
    "    real = np.array([])\n",
    "    evals_result = {}\n",
    "    features_list = [i for i in X_train.columns]\n",
    "    feature_importance_df = pd.DataFrame(features_list, columns=[\"Feature\"])\n",
    "    initial = lgbm_params[\"random_seed\"]\n",
    "    for i , (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        print(\"Fold \"+str(i+1))\n",
    "        #lgbm_params[\"random_seed\"] = initial + i\n",
    "        X_train2 = X_train.iloc[train_index,:]\n",
    "        y_train2 = y_train.iloc[train_index]\n",
    "\n",
    "        X_test2 = X_train.iloc[test_index,:]\n",
    "        y_test2 = y_train.iloc[test_index]\n",
    "\n",
    "        lgb_train = lgb.Dataset(X_train2, y_train2)\n",
    "        lgb_eval = lgb.Dataset(X_test2, y_test2, reference=lgb_train)\n",
    "        clf = lgb.train(lgbm_params, lgb_train,valid_sets=[lgb_train, lgb_eval],\n",
    "           num_boost_round=10000,early_stopping_rounds=100,verbose_eval = 500, categorical_feature = categoricals)\n",
    "        #clf = lgb.train(lgbm_params, lgb_train,valid_sets=[lgb_train, lgb_eval],num_boost_round=350, categorical_feature = categoricals, verbose_eval = 100)\n",
    "        valid_predict = clf.predict(X_test2, num_iteration = clf.best_iteration)\n",
    "        valid = np.concatenate([valid, valid_predict])\n",
    "        valid_lgb.iloc[test_index]  = clf.predict(X_test2, num_iteration = clf.best_iteration).reshape(X_test2.shape[0], 1)\n",
    "        real = np.concatenate([real, y_test2])\n",
    "        feature_importance_df[\"Fold_\"+str(i+1)] = clf.feature_importance()\n",
    "\n",
    "        models.append(clf)\n",
    "        \n",
    "    feature_importance_df[\"Average\"] = np.mean(feature_importance_df.iloc[:,1:n_folds+1], axis=1)\n",
    "    feature_importance_df[\"Std\"] = np.std(feature_importance_df.iloc[:,1:n_folds+1], axis=1)\n",
    "    feature_importance_df[\"Cv\"] = feature_importance_df[\"Std\"] / feature_importance_df[\"Average\"]\n",
    "\n",
    "    roc = roc_auc_score(real, valid)\n",
    "    print(\"ROC = {}\".format(roc_auc_score(real, valid)))\n",
    "    print(confusion_matrix(real, np.round(valid)))\n",
    "    pred_value = np.zeros(X_test.shape[0])\n",
    "    for model in models:\n",
    "        pred_value += model.predict(X_test, num_iteration = model.best_iteration) / len(models)\n",
    "    return roc, pred_value, feature_importance_df, valid_lgb\n",
    "    \n",
    "#roc1, pred_value, _, _ = modelling(new_train, new_test, lgbm_params)\n",
    "#roc2, pred_value2, feature_importance_df, valid_lgb = modelling(new_train, new_test, lgbm_params2)\n",
    "roc3, pred_value3, feature_importance_df, _ = modelling(new_train, new_test, lgbm_params3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_group_k_fold(X, y, groups, k, seed=None):\n",
    "    labels_num = np.max(y) + 1\n",
    "    y_counts_per_group = defaultdict(lambda: np.zeros(labels_num))\n",
    "    y_distr = Counter()\n",
    "    for label, g in zip(y, groups):\n",
    "        y_counts_per_group[g][label] += 1\n",
    "        y_distr[label] += 1\n",
    "\n",
    "    y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num))\n",
    "    groups_per_fold = defaultdict(set)\n",
    "\n",
    "    def eval_y_counts_per_fold(y_counts, fold):\n",
    "        y_counts_per_fold[fold] += y_counts\n",
    "        std_per_label = []\n",
    "        for label in range(labels_num):\n",
    "            label_std = np.std([y_counts_per_fold[i][label] / y_distr[label] for i in range(k)])\n",
    "            std_per_label.append(label_std)\n",
    "        y_counts_per_fold[fold] -= y_counts\n",
    "        return np.mean(std_per_label)\n",
    "    \n",
    "    groups_and_y_counts = list(y_counts_per_group.items())\n",
    "    random.Random(seed).shuffle(groups_and_y_counts)\n",
    "\n",
    "    for g, y_counts in sorted(groups_and_y_counts, key=lambda x: -np.std(x[1])):\n",
    "        best_fold = None\n",
    "        min_eval = None\n",
    "        for i in range(k):\n",
    "            fold_eval = eval_y_counts_per_fold(y_counts, i)\n",
    "            if min_eval is None or fold_eval < min_eval:\n",
    "                min_eval = fold_eval\n",
    "                best_fold = i\n",
    "        y_counts_per_fold[best_fold] += y_counts\n",
    "        groups_per_fold[best_fold].add(g)\n",
    "\n",
    "    all_groups = set(groups)\n",
    "    for i in range(k):\n",
    "        train_groups = all_groups - groups_per_fold[i]\n",
    "        test_groups = groups_per_fold[i]\n",
    "\n",
    "        train_indices = [i for i, g in enumerate(groups) if g in train_groups]\n",
    "        test_indices = [i for i, g in enumerate(groups) if g in test_groups]\n",
    "\n",
    "        yield train_indices, test_indices\n",
    "        \n",
    "def modelling_sgk(new_train, new_test, lgbm_params):\n",
    "    X_train = new_train.drop(['target'],axis=1).copy()\n",
    "    y_train = new_train.target.copy()\n",
    "    \n",
    "    remove_features = []\n",
    "    for i in X_train.columns:\n",
    "        if (X_train[i].std() == 0) and i not in remove_features:\n",
    "            remove_features.append(i)\n",
    "    X_train = X_train.drop(remove_features, axis=1)\n",
    "    X_test = new_test.copy()\n",
    "    X_test = X_test.drop(remove_features, axis=1)\n",
    "    groups = np.array(X_train.session_id.values)\n",
    "    X_test = X_test.drop(\"session_id\", axis=1)\n",
    "    models = []\n",
    "    \n",
    "    n_folds = 5\n",
    "    valid = np.array([])\n",
    "    valid_lgb = pd.DataFrame(np.zeros([X_train.shape[0]]))\n",
    "    real = np.array([])\n",
    "    evals_result = {}\n",
    "    features_list = [i for i in X_train.columns if i != \"session_id\"]\n",
    "    feature_importance_df = pd.DataFrame(features_list, columns=[\"Feature\"])\n",
    "    for i, (train_index, test_index) in enumerate(stratified_group_k_fold(X_train, y_train, groups, k=n_folds, seed=12)):\n",
    "        print(\"Fold \"+str(i+1))\n",
    "        X_train2 = X_train.iloc[train_index,:]\n",
    "        y_train2 = y_train.iloc[train_index]\n",
    "        X_train2.drop(\"session_id\", axis=1, inplace=True)\n",
    "\n",
    "        X_test2 = X_train.iloc[test_index,:]\n",
    "        y_test2 = y_train.iloc[test_index]\n",
    "        X_test2.drop(\"session_id\", axis=1, inplace=True)\n",
    "\n",
    "        lgb_train = lgb.Dataset(X_train2, y_train2)\n",
    "        lgb_eval = lgb.Dataset(X_test2, y_test2, reference=lgb_train)\n",
    "        clf = lgb.train(lgbm_params, lgb_train,valid_sets=[lgb_train, lgb_eval],\n",
    "            num_boost_round=10000,early_stopping_rounds=100,verbose_eval = 500, categorical_feature = categoricals)\n",
    "        valid_predict = clf.predict(X_test2, num_iteration = clf.best_iteration)\n",
    "        valid = np.concatenate([valid, valid_predict])\n",
    "        valid_lgb.iloc[test_index]  = clf.predict(X_test2, num_iteration = clf.best_iteration)\n",
    "        real = np.concatenate([real, y_test2])\n",
    "        feature_importance_df[\"Fold_\"+str(i+1)] = clf.feature_importance()\n",
    "\n",
    "        models.append(clf)\n",
    "        \n",
    "    feature_importance_df[\"Average\"] = np.mean(feature_importance_df.iloc[:,1:n_folds+1], axis=1)\n",
    "    feature_importance_df[\"Std\"] = np.std(feature_importance_df.iloc[:,1:n_folds+1], axis=1)\n",
    "    feature_importance_df[\"Cv\"] = feature_importance_df[\"Std\"] / feature_importance_df[\"Average\"]\n",
    "\n",
    "    roc = roc_auc_score(real, valid)\n",
    "    print(\"ROC = {}\".format(roc_auc_score(real, valid)))\n",
    "    print(confusion_matrix(real, np.round(valid)))\n",
    "    pred_value = np.zeros(X_test.shape[0])\n",
    "    for model in models:\n",
    "        pred_value += model.predict(X_test, num_iteration = model.best_iteration) / len(models)\n",
    "    return roc, pred_value, feature_importance_df, valid\n",
    "    \n",
    "#roc_sgk1, pred_value, _, valid1 = modelling_sgk(new_train, new_test, lgbm_params)\n",
    "#roc_sgk2, pred_value2, _, valid2 = modelling_sgk(new_train, new_test, lgbm_params2)\n",
    "#roc_sgk3, pred_value3, _, valid3 = modelling_sgk(new_train, new_test, lgbm_params3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Fold_1</th>\n",
       "      <th>Fold_2</th>\n",
       "      <th>Fold_3</th>\n",
       "      <th>Fold_4</th>\n",
       "      <th>Average</th>\n",
       "      <th>Std</th>\n",
       "      <th>Cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>min_dist</td>\n",
       "      <td>74</td>\n",
       "      <td>215</td>\n",
       "      <td>87</td>\n",
       "      <td>181</td>\n",
       "      <td>139.25</td>\n",
       "      <td>60.143059</td>\n",
       "      <td>0.431907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>radius</td>\n",
       "      <td>25</td>\n",
       "      <td>162</td>\n",
       "      <td>36</td>\n",
       "      <td>155</td>\n",
       "      <td>94.50</td>\n",
       "      <td>64.165801</td>\n",
       "      <td>0.679003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uni_sess_per_pid</td>\n",
       "      <td>40</td>\n",
       "      <td>100</td>\n",
       "      <td>39</td>\n",
       "      <td>126</td>\n",
       "      <td>76.25</td>\n",
       "      <td>37.883869</td>\n",
       "      <td>0.496838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accumulated_actions</td>\n",
       "      <td>29</td>\n",
       "      <td>99</td>\n",
       "      <td>40</td>\n",
       "      <td>99</td>\n",
       "      <td>66.75</td>\n",
       "      <td>32.483650</td>\n",
       "      <td>0.486646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max_dist</td>\n",
       "      <td>33</td>\n",
       "      <td>108</td>\n",
       "      <td>30</td>\n",
       "      <td>91</td>\n",
       "      <td>65.50</td>\n",
       "      <td>34.543451</td>\n",
       "      <td>0.527381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>std_dist</td>\n",
       "      <td>18</td>\n",
       "      <td>71</td>\n",
       "      <td>31</td>\n",
       "      <td>70</td>\n",
       "      <td>47.50</td>\n",
       "      <td>23.457408</td>\n",
       "      <td>0.493840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>store_lat</td>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>103</td>\n",
       "      <td>47.25</td>\n",
       "      <td>38.886855</td>\n",
       "      <td>0.823002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>store_lon</td>\n",
       "      <td>13</td>\n",
       "      <td>73</td>\n",
       "      <td>13</td>\n",
       "      <td>80</td>\n",
       "      <td>44.75</td>\n",
       "      <td>31.846311</td>\n",
       "      <td>0.711649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>in_store</td>\n",
       "      <td>15</td>\n",
       "      <td>48</td>\n",
       "      <td>28</td>\n",
       "      <td>68</td>\n",
       "      <td>39.75</td>\n",
       "      <td>20.104415</td>\n",
       "      <td>0.505771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pid_count_enc</td>\n",
       "      <td>20</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>55</td>\n",
       "      <td>33.00</td>\n",
       "      <td>13.729530</td>\n",
       "      <td>0.416046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>categorical_6</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>29.75</td>\n",
       "      <td>20.861148</td>\n",
       "      <td>0.701215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>closest_lon</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>44</td>\n",
       "      <td>26.75</td>\n",
       "      <td>12.028612</td>\n",
       "      <td>0.449668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>closest_lat</td>\n",
       "      <td>6</td>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>26.25</td>\n",
       "      <td>19.498397</td>\n",
       "      <td>0.742796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>day6</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "      <td>39</td>\n",
       "      <td>25.00</td>\n",
       "      <td>18.041619</td>\n",
       "      <td>0.721665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>yellow_in_pic</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>20.50</td>\n",
       "      <td>16.515145</td>\n",
       "      <td>0.805617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>day3</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>19.25</td>\n",
       "      <td>10.207228</td>\n",
       "      <td>0.530246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>day2</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>17.00</td>\n",
       "      <td>11.789826</td>\n",
       "      <td>0.693519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>day1</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>14.00</td>\n",
       "      <td>15.297059</td>\n",
       "      <td>1.092647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>categorical_5</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>13.50</td>\n",
       "      <td>11.412712</td>\n",
       "      <td>0.845386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>day5</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>12.50</td>\n",
       "      <td>13.200379</td>\n",
       "      <td>1.056030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>day4</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>12.50</td>\n",
       "      <td>10.428327</td>\n",
       "      <td>0.834266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>name</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>11.00</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>type</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>11.00</td>\n",
       "      <td>1.870829</td>\n",
       "      <td>0.170075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>day0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>10.25</td>\n",
       "      <td>10.544548</td>\n",
       "      <td>1.028736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>OS</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>6.75</td>\n",
       "      <td>4.866981</td>\n",
       "      <td>0.721034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>categorical_4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4.25</td>\n",
       "      <td>3.631460</td>\n",
       "      <td>0.854461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>optout_count</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>lang</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>timezone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Feature  Fold_1  Fold_2  Fold_3  Fold_4  Average        Std  \\\n",
       "0              min_dist      74     215      87     181   139.25  60.143059   \n",
       "1                radius      25     162      36     155    94.50  64.165801   \n",
       "2      uni_sess_per_pid      40     100      39     126    76.25  37.883869   \n",
       "3   accumulated_actions      29      99      40      99    66.75  32.483650   \n",
       "4              max_dist      33     108      30      91    65.50  34.543451   \n",
       "5              std_dist      18      71      31      70    47.50  23.457408   \n",
       "6             store_lat       7      64      15     103    47.25  38.886855   \n",
       "7             store_lon      13      73      13      80    44.75  31.846311   \n",
       "8              in_store      15      48      28      68    39.75  20.104415   \n",
       "9         pid_count_enc      20      34      23      55    33.00  13.729530   \n",
       "10        categorical_6       6      50      12      51    29.75  20.861148   \n",
       "11          closest_lon      10      27      26      44    26.75  12.028612   \n",
       "12          closest_lat       6      56      12      31    26.25  19.498397   \n",
       "13                 day6       0      45      16      39    25.00  18.041619   \n",
       "14        yellow_in_pic       4      46       8      24    20.50  16.515145   \n",
       "15                 day3      13      21       8      35    19.25  10.207228   \n",
       "16                 day2       4      16      12      36    17.00  11.789826   \n",
       "17                 day1       4      40       2      10    14.00  15.297059   \n",
       "18        categorical_5       0      28       5      21    13.50  11.412712   \n",
       "19                 day5       0      19       0      31    12.50  13.200379   \n",
       "20                 day4       2      28       4      16    12.50  10.428327   \n",
       "21                 name       4      18       4      18    11.00   7.000000   \n",
       "22                 type       9      14      11      10    11.00   1.870829   \n",
       "23                 day0       1       8       4      28    10.25  10.544548   \n",
       "24                   OS       2      10       2      13     6.75   4.866981   \n",
       "25        categorical_4       4       3       0      10     4.25   3.631460   \n",
       "26         optout_count       0       1       0       1     0.50   0.500000   \n",
       "27                 lang       0       0       0       0     0.00   0.000000   \n",
       "28             timezone       0       0       0       0     0.00   0.000000   \n",
       "\n",
       "          Cv  \n",
       "0   0.431907  \n",
       "1   0.679003  \n",
       "2   0.496838  \n",
       "3   0.486646  \n",
       "4   0.527381  \n",
       "5   0.493840  \n",
       "6   0.823002  \n",
       "7   0.711649  \n",
       "8   0.505771  \n",
       "9   0.416046  \n",
       "10  0.701215  \n",
       "11  0.449668  \n",
       "12  0.742796  \n",
       "13  0.721665  \n",
       "14  0.805617  \n",
       "15  0.530246  \n",
       "16  0.693519  \n",
       "17  1.092647  \n",
       "18  0.845386  \n",
       "19  1.056030  \n",
       "20  0.834266  \n",
       "21  0.636364  \n",
       "22  0.170075  \n",
       "23  1.028736  \n",
       "24  0.721034  \n",
       "25  0.854461  \n",
       "26  1.000000  \n",
       "27       NaN  \n",
       "28       NaN  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df.sort_values(\"Average\", ascending = False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = ['lang', 'OS']\n",
    "\n",
    "cat_params = {\n",
    "    'loss_function': 'Logloss',\n",
    "    'depth': 3,\n",
    "    \"num_boost_round\":100000,\n",
    "    'learning_rate': 0.01,\n",
    "    \"early_stopping_rounds\":10,\n",
    "    \"eval_metrics\": 'AUC',\n",
    "    \"metrics\": 'AUC'}\n",
    "\n",
    "def modelling_cat(new_train, new_test, cat_params):\n",
    "    X_train = new_train.drop(['target'],axis=1).copy()\n",
    "    y_train = new_train.target.copy()\n",
    "    \n",
    "    remove_features = [\"session_id\", \"categorical_1\", \"categorical_2\", \"categorical_3\"]\n",
    "    for i in X_train.columns:\n",
    "        if (X_train[i].std() == 0) and i not in remove_features:\n",
    "            remove_features.append(i)\n",
    "    X_train = X_train.drop(remove_features, axis=1)\n",
    "    X_test = new_test.copy()\n",
    "    X_test = X_test.drop(remove_features, axis=1)\n",
    "\n",
    "    n_folds=5\n",
    "    skf=StratifiedKFold(n_splits = n_folds)\n",
    "    models = []\n",
    "    \n",
    "    valid = pd.DataFrame(np.zeros([X_train.shape[0]]))\n",
    "    evals_result = {}\n",
    "    features_list = [i for i in X_train.columns]\n",
    "    feature_importance_df = pd.DataFrame(features_list, columns=[\"Feature\"])\n",
    "    for i , (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        print(\"Fold \"+str(i+1))\n",
    "        X_train2 = X_train.iloc[train_index,:]\n",
    "        y_train2 = y_train.iloc[train_index]\n",
    "\n",
    "        X_test2 = X_train.iloc[test_index,:]\n",
    "        y_test2 = y_train.iloc[test_index]\n",
    "\n",
    "        train_pool = Pool(X_train2, label=y_train2)\n",
    "        test_pool = Pool(X_test2, label=y_test2)\n",
    "        clf = CatBoost(cat_params)\n",
    "        clf.fit(train_pool, eval_set=[train_pool, test_pool], use_best_model=True, verbose_eval = 300)\n",
    "        \n",
    "        valid.iloc[test_index]  = clf.predict(X_test2, prediction_type = \"Probability\")[:,1].reshape(X_test2.shape[0], 1)\n",
    "        #feature_importance_df[\"Fold_\"+str(i+1)] = clf.get_feature_importance()\n",
    "\n",
    "        models.append(clf)\n",
    "        \n",
    "    #feature_importance_df[\"Average\"] = np.mean(feature_importance_df.iloc[:,1:n_folds+1], axis=1)\n",
    "    #feature_importance_df[\"Std\"] = np.std(feature_importance_df.iloc[:,1:n_folds+1], axis=1)\n",
    "    #feature_importance_df[\"Cv\"] = feature_importance_df[\"Std\"] / feature_importance_df[\"Average\"]\n",
    "\n",
    "    roc = roc_auc_score(y_train, valid)\n",
    "    print(\"ROC = {}\".format(roc_auc_score(y_train, valid)))\n",
    "    print(confusion_matrix(y_train, np.round(valid)))\n",
    "    pred_value = np.zeros(X_test.shape[0])\n",
    "    for model in models:\n",
    "        pred_value += model.predict(X_test, prediction_type = \"Probability\")[:,1] / len(models)\n",
    "    return roc, pred_value, valid\n",
    "    \n",
    "#roc_cat, pred_value_cat, valid_cat = modelling_cat(new_train, new_test, cat_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['target', 'session_id', 'store_lat', 'store_lon', 'radius', 'type',\n",
      "       'name', 'OS', 'accumulated_actions', 'categorical_1', 'categorical_2',\n",
      "       'categorical_3', 'categorical_4', 'categorical_5', 'categorical_6',\n",
      "       'closest_lat', 'closest_lon', 'day0', 'day1', 'day2', 'day3', 'day4',\n",
      "       'day5', 'day6', 'in_store', 'lang', 'max_dist', 'min_dist',\n",
      "       'optout_count', 'std_dist', 'timezone', 'yellow_in_pic',\n",
      "       'pid_count_enc', 'uni_sess_per_pid'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(new_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = pred_value3\n",
    "roc = roc3\n",
    "sample_submission = pd.read_csv(\"../../../20200125atma/input/atmacup3_sample_submission.csv\")\n",
    "sample_submission[\"target\"] = final_pred\n",
    "sample_submission.to_csv(\"../../../20200125atma/result/atmacup3_sample_submission\"+str(roc)+\".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
