{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import datetime\n",
    "from time import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, log_loss, roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import lightgbm as lgb\n",
    "from functools import partial\n",
    "import copy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "from hyperopt import hp, tpe, Trials, fmin, space_eval\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.max_rows\",1000)\n",
    "np.set_printoptions(precision=8)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../../../20200125atma/input/train.csv\")\n",
    "test = pd.read_csv(\"../../../20200125atma/input/test.csv\")\n",
    "userlog = pd.read_csv(\"../../../20200125atma/input/user_log.csv\")\n",
    "poi = pd.read_csv(\"../../../20200125atma/input/poi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_y = []\n",
    "for i in range(13411):\n",
    "    img = cv2.imread('../../../20200125atma/input/images/'+str(i)+'.png')\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  # HSV 色空間に変換\n",
    "\n",
    "    red = cv2.inRange(hsv, np.array([145, 70, 0]), np.array([180, 255, 255]))\n",
    "    yellow = cv2.inRange(hsv, (15,0,0), (36, 255, 255))\n",
    "    green = cv2.inRange(hsv, np.array([30, 190, 0]), np.array([90, 255, 255]))\n",
    "    blue = cv2.inRange(hsv, np.array([108, 121, 0]), np.array([120, 255, 255]))\n",
    "    white = cv2.inRange(hsv, np.array([108, 21, 0]), np.array([255, 70, 255]))\n",
    "\n",
    "    # 白だけゴミがあるので、収縮演算\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    white = cv2.erode(yellow, kernel)\n",
    "\n",
    "    bin_imgs = {'red': red, 'yellow': yellow, 'green': green,\n",
    "            'blue': blue, 'white': white}\n",
    "\n",
    "    for label, bin_img in bin_imgs.items():\n",
    "        contours, _ = cv2.findContours(bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = list(filter(lambda cnt: len(cnt) > 30, contours))\n",
    "        count = len(contours)\n",
    "    \n",
    "        if label == \"yellow\":\n",
    "            list_y.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(train, test, userlog, poi):\n",
    "    userlog[\"sysname\"][userlog.sysname == \"ANDROID\"] = \"Android\"\n",
    "    userlog[\"lang\"][userlog.lang == \"ja_JP\"] = \"ja_JP\"\n",
    "    poi = poi.rename(columns={\"latitude\": \"store_lat\", \"longitude\": \"store_lon\"})\n",
    "    train = pd.merge(train, poi, on =\"pid\", how = \"left\")\n",
    "    test = pd.merge(test, poi, on =\"pid\", how = \"left\")\n",
    "    userlog = pd.merge(userlog, train[[\"session_id\", \"store_lat\", \"store_lon\", \"radius\", \"pid\"]], on=\"session_id\", how=\"left\")\n",
    "    userlog = pd.merge(userlog, test[[\"session_id\", \"store_lat\", \"store_lon\", \"radius\", \"pid\"]], on=\"session_id\", how=\"left\")\n",
    "    userlog[\"store_lat\"] = np.nanmax(userlog[[\"store_lat_x\", \"store_lat_y\"]], axis=1)\n",
    "    userlog[\"store_lon\"] = np.nanmax(userlog[[\"store_lon_x\", \"store_lon_y\"]], axis=1)\n",
    "    userlog[\"radius\"] = np.nanmax(userlog[[\"radius_x\", \"radius_y\"]], axis=1)\n",
    "    userlog[\"pid\"] = np.nanmax(userlog[[\"pid_x\", \"pid_y\"]], axis=1)\n",
    "    drop_features = [\"store_lat_x\", \"store_lat_y\", \"store_lon_x\", \"store_lon_y\", \"radius_x\", \"radius_y\", \"pid_x\", \"pid_y\"]\n",
    "    userlog.drop(drop_features, axis=1, inplace=True)\n",
    "    userlog[\"distance\"] = np.sqrt((userlog[\"latitude\"]- userlog[\"store_lat\"])**2 + (userlog[\"longitude\"]-userlog[\"store_lon\"])** 2 )\n",
    "    userlog[\"time\"] = userlog[\"hour\"].map(str) + str(\":\") + userlog[\"minute\"].map(str) + str(\":\") + userlog[\"second\"].map(str)\n",
    "    userlog[\"time\"] = pd.to_datetime(userlog['time'],format= '%H:%M:%S' )\n",
    "    userlog = userlog.sort_values([\"session_id\", \"hour\", \"minute\", \"second\"]).reset_index(drop=True)\n",
    "    userlog[\"virtual_dis\"] = 6370 * np.arccos(np.sin(userlog[\"latitude\"])*np.sin(userlog[\"store_lat\"]) + np.cos(userlog[\"latitude\"])*np.cos(userlog[\"store_lat\"])*np.cos(userlog[\"longitude\"]-userlog[\"store_lon\"]))\n",
    "    userlog[\"in_store\"] = userlog[\"virtual_dis\"] < userlog[\"radius\"]\n",
    "    unique_sess = pd.DataFrame(userlog.groupby(\"pid\")[\"session_id\"].nunique().copy().reset_index(drop=False))\n",
    "    unique_sess = unique_sess.rename(columns = {\"session_id\": \"uni_sess_per_pid\"})\n",
    "    userlog = pd.merge(userlog, unique_sess, on =\"pid\", how = \"left\")\n",
    "    return train, test, userlog, poi, unique_sess\n",
    "train, test, userlog, poi, unique_sess = preprocess(train, test, userlog, poi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(train, test, userlog):\n",
    "    os_list =  sorted(list(set(userlog['sysname'].unique())))\n",
    "    os_map = dict(zip(os_list, np.arange(len(os_list))))\n",
    "    userlog[\"sysname\"] = userlog[\"sysname\"].map(os_map)\n",
    "    \n",
    "    lang_list =  sorted(list(set(userlog['lang'].unique())))\n",
    "    lang_map = dict(zip(lang_list, np.arange(len(lang_list))))\n",
    "    userlog[\"lang\"] = userlog[\"lang\"].map(lang_map)\n",
    "    \n",
    "    timezone_list =  sorted(list(set(userlog['timezone'].unique())))\n",
    "    timezone_map = dict(zip(timezone_list, np.arange(len(timezone_list))))\n",
    "    userlog[\"timezone\"] = userlog[\"timezone\"].map(timezone_map)\n",
    "\n",
    "    return train, test, userlog\n",
    "train, test, userlog = encode(train, test, userlog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>sysname</th>\n",
       "      <th>optout</th>\n",
       "      <th>lang</th>\n",
       "      <th>timezone</th>\n",
       "      <th>session_id</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>categorical_1</th>\n",
       "      <th>categorical_2</th>\n",
       "      <th>categorical_3</th>\n",
       "      <th>categorical_4</th>\n",
       "      <th>categorical_5</th>\n",
       "      <th>categorical_6</th>\n",
       "      <th>store_lat</th>\n",
       "      <th>store_lon</th>\n",
       "      <th>radius</th>\n",
       "      <th>pid</th>\n",
       "      <th>distance</th>\n",
       "      <th>time</th>\n",
       "      <th>virtual_dis</th>\n",
       "      <th>in_store</th>\n",
       "      <th>uni_sess_per_pid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.650300</td>\n",
       "      <td>46.780509</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0003f26df5d8b928b416fba58efd5c91</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>35.651739</td>\n",
       "      <td>46.776134</td>\n",
       "      <td>118.0</td>\n",
       "      <td>354655367.0</td>\n",
       "      <td>0.004606</td>\n",
       "      <td>1900-01-01 00:33:31</td>\n",
       "      <td>15.744307</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.650298</td>\n",
       "      <td>46.780512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0003f26df5d8b928b416fba58efd5c91</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>35.651739</td>\n",
       "      <td>46.776134</td>\n",
       "      <td>118.0</td>\n",
       "      <td>354655367.0</td>\n",
       "      <td>0.004609</td>\n",
       "      <td>1900-01-01 00:33:31</td>\n",
       "      <td>15.758882</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.650286</td>\n",
       "      <td>46.780524</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0003f26df5d8b928b416fba58efd5c91</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>35.651739</td>\n",
       "      <td>46.776134</td>\n",
       "      <td>118.0</td>\n",
       "      <td>354655367.0</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>1900-01-01 02:18:33</td>\n",
       "      <td>15.832117</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    latitude  longitude  sysname  optout  lang  timezone  \\\n",
       "0  35.650300  46.780509        0       0     9         1   \n",
       "1  35.650298  46.780512        0       0     9         1   \n",
       "2  35.650286  46.780524        0       0     9         1   \n",
       "\n",
       "                         session_id  hour  minute  second  day_of_week  \\\n",
       "0  0003f26df5d8b928b416fba58efd5c91     0      33      31            6   \n",
       "1  0003f26df5d8b928b416fba58efd5c91     0      33      31            6   \n",
       "2  0003f26df5d8b928b416fba58efd5c91     2      18      33            6   \n",
       "\n",
       "   categorical_1  categorical_2  categorical_3  categorical_4  categorical_5  \\\n",
       "0              4              0             44            1.0              1   \n",
       "1              4              1             44            1.0              1   \n",
       "2              4              2             44            1.0              1   \n",
       "\n",
       "   categorical_6  store_lat  store_lon  radius          pid  distance  \\\n",
       "0            187  35.651739  46.776134   118.0  354655367.0  0.004606   \n",
       "1            187  35.651739  46.776134   118.0  354655367.0  0.004609   \n",
       "2            187  35.651739  46.776134   118.0  354655367.0  0.004624   \n",
       "\n",
       "                 time  virtual_dis  in_store  uni_sess_per_pid  \n",
       "0 1900-01-01 00:33:31    15.744307      True                16  \n",
       "1 1900-01-01 00:33:31    15.758882      True                16  \n",
       "2 1900-01-01 02:18:33    15.832117      True                16  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userlog.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logdata(user_sample):\n",
    "    day_of_week_counts = {\"day\"+str(day) : 0 for day in range(7)}\n",
    "\n",
    "    all_results = []\n",
    "    features = {\"accumulated_actions\":0}\n",
    "    features[\"accumulated_actions\"] = user_sample.shape[0]\n",
    "    features[\"session_id\"] = user_sample.iloc[0][\"session_id\"]\n",
    "    features[\"OS\"] = user_sample.iloc[0][\"sysname\"]\n",
    "    features[\"lang\"] = user_sample.iloc[0][\"lang\"]\n",
    "    features[\"timezone\"] = user_sample.iloc[0][\"timezone\"]\n",
    "    features[\"optout_count\"] = np.sum(user_sample[\"optout\"])\n",
    "    distance = np.array(user_sample[\"distance\"])\n",
    "    features[\"max_dist\"] = np.nanmax(distance)\n",
    "    features[\"min_dist\"] = np.nanmin(distance)\n",
    "    features[\"std_dist\"] = np.nanstd(distance)\n",
    "    \n",
    "    n_of_days = Counter(user_sample['day_of_week']) \n",
    "    for key in n_of_days.keys():\n",
    "        day_of_week_counts[\"day\"+str(key)] += n_of_days[key]\n",
    "    features.update(day_of_week_counts)\n",
    "    \n",
    "    features[\"in_store\"] = np.sum(user_sample[\"in_store\"])\n",
    "    \n",
    "    all_results.append(features)\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd255c3889cf41e98cd097b7ab01b587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='session_id', max=5601, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_log_info(userlog):\n",
    "    compiled_log = []\n",
    "\n",
    "    for i, (ses_id, user_sample) in tqdm(enumerate(userlog.groupby('session_id', sort=False)), total=userlog.session_id.nunique(), desc='session_id', position=0):\n",
    "        compiled_log += get_logdata(user_sample)\n",
    "        reduced_log = pd.DataFrame(compiled_log)\n",
    "    return reduced_log \n",
    "reduced_log = get_log_info(userlog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6612, 25) (6799, 24)\n"
     ]
    }
   ],
   "source": [
    "def postprocess(train, test, reduced_log, unique_sess):\n",
    "    drop_features = [\"imid\", \"pid\", \"session_id\"]\n",
    "    new_train = pd.merge(train, reduced_log, on =\"session_id\", how = \"left\")\n",
    "    new_test = pd.merge(test, reduced_log, on =\"session_id\", how = \"left\")\n",
    "    new_train[\"yellow_in_pic\"] = list_y[:6612]\n",
    "    new_test[\"yellow_in_pic\"] = list_y[6612:]\n",
    "    pid_count_mean = train.groupby('pid').target.count()\n",
    "    new_train['pid_count_enc'] = new_train['pid'].map(pid_count_mean)\n",
    "    new_test['pid_count_enc'] = new_test['pid'].map(pid_count_mean)\n",
    "    new_train = pd.merge(new_train, unique_sess, on =\"pid\", how = \"left\")\n",
    "    new_test = pd.merge(new_test, unique_sess, on =\"pid\", how = \"left\")\n",
    "    new_train.drop(drop_features, axis=1, inplace=True)\n",
    "    new_test.drop(drop_features, axis=1, inplace=True)\n",
    "    print(new_train.shape, new_test.shape)\n",
    "    return new_train, new_test\n",
    "new_train, new_test = postprocess(train, test, reduced_log, unique_sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>store_lat</th>\n",
       "      <th>store_lon</th>\n",
       "      <th>radius</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>OS</th>\n",
       "      <th>accumulated_actions</th>\n",
       "      <th>day0</th>\n",
       "      <th>day1</th>\n",
       "      <th>day2</th>\n",
       "      <th>day3</th>\n",
       "      <th>day4</th>\n",
       "      <th>day5</th>\n",
       "      <th>day6</th>\n",
       "      <th>in_store</th>\n",
       "      <th>lang</th>\n",
       "      <th>max_dist</th>\n",
       "      <th>min_dist</th>\n",
       "      <th>optout_count</th>\n",
       "      <th>std_dist</th>\n",
       "      <th>timezone</th>\n",
       "      <th>yellow_in_pic</th>\n",
       "      <th>pid_count_enc</th>\n",
       "      <th>uni_sess_per_pid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>36.320751</td>\n",
       "      <td>46.104755</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>7</td>\n",
       "      <td>0.072056</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014947</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>35.564913</td>\n",
       "      <td>46.744633</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "      <td>0.005153</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>35.693777</td>\n",
       "      <td>46.784288</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>262</td>\n",
       "      <td>262</td>\n",
       "      <td>9</td>\n",
       "      <td>0.014393</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004819</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  store_lat  store_lon  radius  type  name  OS  accumulated_actions  \\\n",
       "0       0  36.320751  46.104755      25     2     0   1                  187   \n",
       "1       0  35.564913  46.744633      51     0     1   0                  111   \n",
       "2       0  35.693777  46.784288     189     0     1   0                  262   \n",
       "\n",
       "   day0  day1  day2  day3  day4  day5  day6  in_store  lang  max_dist  \\\n",
       "0     0     0     0     0   187     0     0       149     7  0.072056   \n",
       "1   111     0     0     0     0     0     0       111     9  0.005153   \n",
       "2     0     0     0     0     0     0   262       262     9  0.014393   \n",
       "\n",
       "   min_dist  optout_count  std_dist  timezone  yellow_in_pic  pid_count_enc  \\\n",
       "0  0.000203             0  0.014947         1              4             15   \n",
       "1  0.000704             0  0.000580         1              3             18   \n",
       "2  0.000347             0  0.004819         1              1             11   \n",
       "\n",
       "   uni_sess_per_pid  \n",
       "0                26  \n",
       "1                37  \n",
       "2                21  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's auc: 0.952375\tvalid_1's auc: 0.873485\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's auc: 0.940766\tvalid_1's auc: 0.849866\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\ttraining's auc: 0.999954\tvalid_1's auc: 0.852395\n",
      "Early stopping, best iteration is:\n",
      "[640]\ttraining's auc: 1\tvalid_1's auc: 0.857024\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's auc: 0.986047\tvalid_1's auc: 0.820839\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[314]\ttraining's auc: 0.998785\tvalid_1's auc: 0.852539\n",
      "ROC = 0.8187928147270476\n",
      "[[6474    5]\n",
      " [ 130    3]]\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's auc: 0.970007\tvalid_1's auc: 0.856153\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[238]\ttraining's auc: 0.995129\tvalid_1's auc: 0.870485\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[280]\ttraining's auc: 0.998872\tvalid_1's auc: 0.848737\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[206]\ttraining's auc: 0.997357\tvalid_1's auc: 0.854938\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[232]\ttraining's auc: 0.994973\tvalid_1's auc: 0.862548\n",
      "ROC = 0.8508338681245482\n",
      "[[6471    8]\n",
      " [ 123   10]]\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's auc: 0.939347\tvalid_1's auc: 0.90182\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[129]\ttraining's auc: 0.992991\tvalid_1's auc: 0.89329\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[188]\ttraining's auc: 0.999414\tvalid_1's auc: 0.85028\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's auc: 0.984756\tvalid_1's auc: 0.867967\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[129]\ttraining's auc: 0.993927\tvalid_1's auc: 0.862355\n",
      "ROC = 0.8595868433237749\n",
      "[[6469   10]\n",
      " [ 121   12]]\n"
     ]
    }
   ],
   "source": [
    "categoricals = ['lang', 'OS']\n",
    "\n",
    "lgbm_params = {'objective': 'binary','eval_metric': 'auc','metric': 'auc', 'boosting_type': 'gbdt',\n",
    " 'tree_learner': 'serial','learning_rate': 0.017891320270412462,'max_depth': 5, 'random_seed':42}\n",
    "    \n",
    "lgbm_params2 = {'objective': 'binary','eval_metric': 'auc','metric': 'auc', 'boosting_type': 'gbdt',\n",
    " 'tree_learner': 'serial',   'learning_rate': 0.02861754102536491,'random_seed':43, 'max_depth': 4}\n",
    "\n",
    "lgbm_params3 = {'objective': 'binary','eval_metric': 'auc','metric': 'auc', 'boosting_type': 'gbdt',\n",
    " 'tree_learner': 'serial', 'learning_rate': 0.09482045811322946, 'random_seed':44,'max_depth': 3}\n",
    "\n",
    "def modelling(new_train, new_test, lgbm_params):\n",
    "    X_train = new_train.drop(['target'],axis=1).copy()\n",
    "    y_train = new_train.target.copy()\n",
    "    \n",
    "    remove_features = []\n",
    "    for i in X_train.columns:\n",
    "        if (X_train[i].std() == 0) and i not in remove_features:\n",
    "            remove_features.append(i)\n",
    "    X_train = X_train.drop(remove_features, axis=1)\n",
    "    X_test = new_test.copy()\n",
    "    X_test = X_test.drop(remove_features, axis=1)\n",
    "\n",
    "    n_folds=5\n",
    "    skf=StratifiedKFold(n_splits = n_folds)\n",
    "    models = []\n",
    "    \n",
    "    valid = np.array([])\n",
    "    real = np.array([])\n",
    "    evals_result = {}\n",
    "    features_list = [i for i in X_train.columns]\n",
    "    feature_importance_df = pd.DataFrame(features_list, columns=[\"Feature\"])\n",
    "    for i , (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        print(\"Fold \"+str(i+1))\n",
    "        X_train2 = X_train.iloc[train_index,:]\n",
    "        y_train2 = y_train.iloc[train_index]\n",
    "\n",
    "        X_test2 = X_train.iloc[test_index,:]\n",
    "        y_test2 = y_train.iloc[test_index]\n",
    "\n",
    "        lgb_train = lgb.Dataset(X_train2, y_train2)\n",
    "        lgb_eval = lgb.Dataset(X_test2, y_test2, reference=lgb_train)\n",
    "        clf = lgb.train(lgbm_params, lgb_train,valid_sets=[lgb_train, lgb_eval],\n",
    "            num_boost_round=10000,early_stopping_rounds=100,verbose_eval = 500, categorical_feature = categoricals)\n",
    "        valid_predict = clf.predict(X_test2, num_iteration = clf.best_iteration)\n",
    "        valid = np.concatenate([valid, valid_predict])\n",
    "        real = np.concatenate([real, y_test2])\n",
    "        feature_importance_df[\"Fold_\"+str(i+1)] = clf.feature_importance()\n",
    "\n",
    "        models.append(clf)\n",
    "        \n",
    "    feature_importance_df[\"Average\"] = np.mean(feature_importance_df.iloc[:,1:n_folds+1], axis=1)\n",
    "    feature_importance_df[\"Std\"] = np.std(feature_importance_df.iloc[:,1:n_folds+1], axis=1)\n",
    "    feature_importance_df[\"Cv\"] = feature_importance_df[\"Std\"] / feature_importance_df[\"Average\"]\n",
    "\n",
    "    roc = roc_auc_score(real, valid)\n",
    "    print(\"ROC = {}\".format(roc_auc_score(real, valid)))\n",
    "    print(confusion_matrix(real, np.round(valid)))\n",
    "    pred_value = np.zeros(X_test.shape[0])\n",
    "    for model in models:\n",
    "        pred_value += model.predict(X_test, num_iteration = model.best_iteration) / len(models)\n",
    "    return roc, pred_value, feature_importance_df\n",
    "    \n",
    "roc, pred_value, _ = modelling(new_train, new_test, lgbm_params)\n",
    "roc, pred_value2, feature_importance_df = modelling(new_train, new_test, lgbm_params2)\n",
    "roc, pred_value3, _ = modelling(new_train, new_test, lgbm_params3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Fold_1</th>\n",
       "      <th>Fold_2</th>\n",
       "      <th>Fold_3</th>\n",
       "      <th>Fold_4</th>\n",
       "      <th>Fold_5</th>\n",
       "      <th>Average</th>\n",
       "      <th>Std</th>\n",
       "      <th>Cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>day3</td>\n",
       "      <td>49</td>\n",
       "      <td>62</td>\n",
       "      <td>96</td>\n",
       "      <td>55</td>\n",
       "      <td>100</td>\n",
       "      <td>72.4</td>\n",
       "      <td>21.341040</td>\n",
       "      <td>0.294766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pid_count_enc</td>\n",
       "      <td>54</td>\n",
       "      <td>163</td>\n",
       "      <td>130</td>\n",
       "      <td>122</td>\n",
       "      <td>109</td>\n",
       "      <td>115.6</td>\n",
       "      <td>35.589886</td>\n",
       "      <td>0.307871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in_store</td>\n",
       "      <td>56</td>\n",
       "      <td>159</td>\n",
       "      <td>176</td>\n",
       "      <td>170</td>\n",
       "      <td>177</td>\n",
       "      <td>147.6</td>\n",
       "      <td>46.245432</td>\n",
       "      <td>0.313316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accumulated_actions</td>\n",
       "      <td>68</td>\n",
       "      <td>190</td>\n",
       "      <td>237</td>\n",
       "      <td>226</td>\n",
       "      <td>238</td>\n",
       "      <td>191.8</td>\n",
       "      <td>64.306765</td>\n",
       "      <td>0.335280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>min_dist</td>\n",
       "      <td>123</td>\n",
       "      <td>430</td>\n",
       "      <td>394</td>\n",
       "      <td>288</td>\n",
       "      <td>438</td>\n",
       "      <td>334.6</td>\n",
       "      <td>118.547206</td>\n",
       "      <td>0.354295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>day1</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>54</td>\n",
       "      <td>37.6</td>\n",
       "      <td>14.122323</td>\n",
       "      <td>0.375594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>uni_sess_per_pid</td>\n",
       "      <td>70</td>\n",
       "      <td>334</td>\n",
       "      <td>297</td>\n",
       "      <td>386</td>\n",
       "      <td>274</td>\n",
       "      <td>272.2</td>\n",
       "      <td>107.956287</td>\n",
       "      <td>0.396606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>yellow_in_pic</td>\n",
       "      <td>23</td>\n",
       "      <td>75</td>\n",
       "      <td>122</td>\n",
       "      <td>87</td>\n",
       "      <td>111</td>\n",
       "      <td>83.6</td>\n",
       "      <td>34.592485</td>\n",
       "      <td>0.413786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>day5</td>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>22.8</td>\n",
       "      <td>9.703608</td>\n",
       "      <td>0.425597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>store_lat</td>\n",
       "      <td>39</td>\n",
       "      <td>212</td>\n",
       "      <td>297</td>\n",
       "      <td>236</td>\n",
       "      <td>250</td>\n",
       "      <td>206.8</td>\n",
       "      <td>88.361530</td>\n",
       "      <td>0.427280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>std_dist</td>\n",
       "      <td>35</td>\n",
       "      <td>204</td>\n",
       "      <td>252</td>\n",
       "      <td>206</td>\n",
       "      <td>145</td>\n",
       "      <td>168.4</td>\n",
       "      <td>74.850785</td>\n",
       "      <td>0.444482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max_dist</td>\n",
       "      <td>62</td>\n",
       "      <td>281</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>178</td>\n",
       "      <td>181.0</td>\n",
       "      <td>80.751471</td>\n",
       "      <td>0.446141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>radius</td>\n",
       "      <td>53</td>\n",
       "      <td>222</td>\n",
       "      <td>381</td>\n",
       "      <td>201</td>\n",
       "      <td>279</td>\n",
       "      <td>227.2</td>\n",
       "      <td>107.141775</td>\n",
       "      <td>0.471575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>type</td>\n",
       "      <td>7</td>\n",
       "      <td>67</td>\n",
       "      <td>66</td>\n",
       "      <td>49</td>\n",
       "      <td>39</td>\n",
       "      <td>45.6</td>\n",
       "      <td>21.996363</td>\n",
       "      <td>0.482376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>day2</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>55</td>\n",
       "      <td>46</td>\n",
       "      <td>39</td>\n",
       "      <td>41.8</td>\n",
       "      <td>20.232647</td>\n",
       "      <td>0.484035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>store_lon</td>\n",
       "      <td>50</td>\n",
       "      <td>213</td>\n",
       "      <td>255</td>\n",
       "      <td>96</td>\n",
       "      <td>152</td>\n",
       "      <td>153.2</td>\n",
       "      <td>74.649581</td>\n",
       "      <td>0.487269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>day6</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>116</td>\n",
       "      <td>71</td>\n",
       "      <td>89</td>\n",
       "      <td>70.8</td>\n",
       "      <td>37.004865</td>\n",
       "      <td>0.522668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>day4</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "      <td>42</td>\n",
       "      <td>30.4</td>\n",
       "      <td>16.304601</td>\n",
       "      <td>0.536336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>name</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>36</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>21.0</td>\n",
       "      <td>12.116105</td>\n",
       "      <td>0.576957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>OS</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>43</td>\n",
       "      <td>20.6</td>\n",
       "      <td>14.150618</td>\n",
       "      <td>0.686923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>day0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>35</td>\n",
       "      <td>83</td>\n",
       "      <td>15</td>\n",
       "      <td>34.2</td>\n",
       "      <td>27.787767</td>\n",
       "      <td>0.812508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>optout_count</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>lang</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>timezone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Feature  Fold_1  Fold_2  Fold_3  Fold_4  Fold_5  Average  \\\n",
       "0                  day3      49      62      96      55     100     72.4   \n",
       "1         pid_count_enc      54     163     130     122     109    115.6   \n",
       "2              in_store      56     159     176     170     177    147.6   \n",
       "3   accumulated_actions      68     190     237     226     238    191.8   \n",
       "4              min_dist     123     430     394     288     438    334.6   \n",
       "5                  day1      12      46      37      39      54     37.6   \n",
       "6      uni_sess_per_pid      70     334     297     386     274    272.2   \n",
       "7         yellow_in_pic      23      75     122      87     111     83.6   \n",
       "8                  day5      14      35      28      28       9     22.8   \n",
       "9             store_lat      39     212     297     236     250    206.8   \n",
       "10             std_dist      35     204     252     206     145    168.4   \n",
       "11             max_dist      62     281     256     128     178    181.0   \n",
       "12               radius      53     222     381     201     279    227.2   \n",
       "13                 type       7      67      66      49      39     45.6   \n",
       "14                 day2       5      64      55      46      39     41.8   \n",
       "15            store_lon      50     213     255      96     152    153.2   \n",
       "16                 day6       4      74     116      71      89     70.8   \n",
       "17                 day4       1      46      38      25      42     30.4   \n",
       "18                 name       5      24      36      31       9     21.0   \n",
       "19                   OS       2      10      27      21      43     20.6   \n",
       "20                 day0       1      37      35      83      15     34.2   \n",
       "21         optout_count       0       1       2       0       0      0.6   \n",
       "22                 lang       0       0       0       0       0      0.0   \n",
       "23             timezone       0       0       0       0       0      0.0   \n",
       "\n",
       "           Std        Cv  \n",
       "0    21.341040  0.294766  \n",
       "1    35.589886  0.307871  \n",
       "2    46.245432  0.313316  \n",
       "3    64.306765  0.335280  \n",
       "4   118.547206  0.354295  \n",
       "5    14.122323  0.375594  \n",
       "6   107.956287  0.396606  \n",
       "7    34.592485  0.413786  \n",
       "8     9.703608  0.425597  \n",
       "9    88.361530  0.427280  \n",
       "10   74.850785  0.444482  \n",
       "11   80.751471  0.446141  \n",
       "12  107.141775  0.471575  \n",
       "13   21.996363  0.482376  \n",
       "14   20.232647  0.484035  \n",
       "15   74.649581  0.487269  \n",
       "16   37.004865  0.522668  \n",
       "17   16.304601  0.536336  \n",
       "18   12.116105  0.576957  \n",
       "19   14.150618  0.686923  \n",
       "20   27.787767  0.812508  \n",
       "21    0.800000  1.333333  \n",
       "22    0.000000       NaN  \n",
       "23    0.000000       NaN  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df.sort_values(\"Cv\", ascending = True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "code_folding": [
     15
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:                  \n",
      "[20]\ttraining's auc: 0.949795\tvalid_1's auc: 0.895562\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[300]\ttraining's auc: 0.999607\tvalid_1's auc: 0.877086\n",
      "Early stopping, best iteration is:                  \n",
      "[235]\ttraining's auc: 0.998937\tvalid_1's auc: 0.883659\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:                  \n",
      "[143]\ttraining's auc: 0.997618\tvalid_1's auc: 0.84545\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[300]\ttraining's auc: 0.999942\tvalid_1's auc: 0.849507\n",
      "Early stopping, best iteration is:                  \n",
      "[218]\ttraining's auc: 0.999583\tvalid_1's auc: 0.855116\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:                  \n",
      "[134]\ttraining's auc: 0.994666\tvalid_1's auc: 0.861435\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Early stopping, best iteration is:                                            \n",
      "[40]\ttraining's auc: 0.873073\tvalid_1's auc: 0.876372\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Early stopping, best iteration is:                                            \n",
      "[27]\ttraining's auc: 0.872991\tvalid_1's auc: 0.883173\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "[300]\ttraining's auc: 0.940058\tvalid_1's auc: 0.805027                        \n",
      "[600]\ttraining's auc: 0.969009\tvalid_1's auc: 0.823317                        \n",
      "[900]\ttraining's auc: 0.979739\tvalid_1's auc: 0.831533                        \n",
      "[1200]\ttraining's auc: 0.985855\tvalid_1's auc: 0.833991                       \n",
      "Early stopping, best iteration is:                                            \n",
      "[1263]\ttraining's auc: 0.986837\tvalid_1's auc: 0.834619\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Early stopping, best iteration is:                                            \n",
      "[12]\ttraining's auc: 0.871283\tvalid_1's auc: 0.846124\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Early stopping, best iteration is:                                            \n",
      "[20]\ttraining's auc: 0.88113\tvalid_1's auc: 0.818622\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Early stopping, best iteration is:                                            \n",
      "[17]\ttraining's auc: 0.940215\tvalid_1's auc: 0.895376\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "[300]\ttraining's auc: 0.999685\tvalid_1's auc: 0.877429                        \n",
      "Early stopping, best iteration is:                                            \n",
      "[209]\ttraining's auc: 0.996163\tvalid_1's auc: 0.88343\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "[300]\ttraining's auc: 0.999995\tvalid_1's auc: 0.859082                        \n",
      "Early stopping, best iteration is:                                            \n",
      "[305]\ttraining's auc: 0.999996\tvalid_1's auc: 0.860139\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Early stopping, best iteration is:                                            \n",
      "[54]\ttraining's auc: 0.981472\tvalid_1's auc: 0.860636\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "[300]\ttraining's auc: 0.999863\tvalid_1's auc: 0.854113                        \n",
      "Early stopping, best iteration is:                                            \n",
      "[253]\ttraining's auc: 0.999632\tvalid_1's auc: 0.85738\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Early stopping, best iteration is:                                           \n",
      "[34]\ttraining's auc: 0.877014\tvalid_1's auc: 0.876357\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Early stopping, best iteration is:                                           \n",
      "[22]\ttraining's auc: 0.872937\tvalid_1's auc: 0.884574\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "[300]\ttraining's auc: 0.951572\tvalid_1's auc: 0.815729                       \n",
      "[600]\ttraining's auc: 0.976781\tvalid_1's auc: 0.831962                       \n",
      "[900]\ttraining's auc: 0.98569\tvalid_1's auc: 0.836477                        \n",
      "[1200]\ttraining's auc: 0.99136\tvalid_1's auc: 0.838906                       \n",
      "[1500]\ttraining's auc: 0.994215\tvalid_1's auc: 0.841992                      \n",
      "[1800]\ttraining's auc: 0.99636\tvalid_1's auc: 0.846165                       \n",
      "Early stopping, best iteration is:                                           \n",
      "[1987]\ttraining's auc: 0.997346\tvalid_1's auc: 0.85008\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Early stopping, best iteration is:                                           \n",
      "[11]\ttraining's auc: 0.871258\tvalid_1's auc: 0.846213\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Early stopping, best iteration is:                                           \n",
      "[15]\ttraining's auc: 0.88179\tvalid_1's auc: 0.818563\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Early stopping, best iteration is:                                           \n",
      "[87]\ttraining's auc: 0.947691\tvalid_1's auc: 0.889003\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Early stopping, best iteration is:                                           \n",
      "[8]\ttraining's auc: 0.874722\tvalid_1's auc: 0.877758\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "[300]\ttraining's auc: 0.983791\tvalid_1's auc: 0.834048                       \n",
      "[600]\ttraining's auc: 0.995622\tvalid_1's auc: 0.841592                       \n",
      "[900]\ttraining's auc: 0.999126\tvalid_1's auc: 0.851109                       \n",
      "Early stopping, best iteration is:                                           \n",
      "[1023]\ttraining's auc: 0.999698\tvalid_1's auc: 0.856767\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Early stopping, best iteration is:                                           \n",
      "[6]\ttraining's auc: 0.873505\tvalid_1's auc: 0.842949\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "[300]\ttraining's auc: 0.979833\tvalid_1's auc: 0.852628                       \n",
      "[600]\ttraining's auc: 0.993123\tvalid_1's auc: 0.855509                       \n",
      "Early stopping, best iteration is:                                           \n",
      "[514]\ttraining's auc: 0.990789\tvalid_1's auc: 0.858153\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Early stopping, best iteration is:                                           \n",
      "[38]\ttraining's auc: 0.945907\tvalid_1's auc: 0.894419\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Early stopping, best iteration is:                                           \n",
      "[4]\ttraining's auc: 0.870985\tvalid_1's auc: 0.879315\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "[300]\ttraining's auc: 0.997419\tvalid_1's auc: 0.841249                       \n",
      "Early stopping, best iteration is:                                           \n",
      "[314]\ttraining's auc: 0.997752\tvalid_1's auc: 0.847394\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "[300]\ttraining's auc: 0.997139\tvalid_1's auc: 0.839862                       \n",
      "Early stopping, best iteration is:                                           \n",
      "[238]\ttraining's auc: 0.995289\tvalid_1's auc: 0.841168\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Early stopping, best iteration is:                                           \n",
      "[168]\ttraining's auc: 0.985063\tvalid_1's auc: 0.857143\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Early stopping, best iteration is:                                           \n",
      "[63]\ttraining's auc: 0.876327\tvalid_1's auc: 0.875943\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Early stopping, best iteration is:                                           \n",
      "[34]\ttraining's auc: 0.873043\tvalid_1's auc: 0.883702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.               \n",
      "[300]\ttraining's auc: 0.929031\tvalid_1's auc: 0.801155                       \n",
      "[600]\ttraining's auc: 0.954608\tvalid_1's auc: 0.819287                       \n",
      "[900]\ttraining's auc: 0.971131\tvalid_1's auc: 0.827232                       \n",
      "[1200]\ttraining's auc: 0.978543\tvalid_1's auc: 0.834648                      \n",
      "[1500]\ttraining's auc: 0.983332\tvalid_1's auc: 0.837334                      \n",
      "Early stopping, best iteration is:                                           \n",
      "[1675]\ttraining's auc: 0.985568\tvalid_1's auc: 0.838363\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Early stopping, best iteration is:                                           \n",
      "[15]\ttraining's auc: 0.871743\tvalid_1's auc: 0.847163\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Early stopping, best iteration is:                                           \n",
      "[27]\ttraining's auc: 0.88209\tvalid_1's auc: 0.818622\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Early stopping, best iteration is:                                           \n",
      "[15]\ttraining's auc: 0.94403\tvalid_1's auc: 0.901192\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "[300]\ttraining's auc: 0.999829\tvalid_1's auc: 0.88163                        \n",
      "Early stopping, best iteration is:                                           \n",
      "[415]\ttraining's auc: 1\tvalid_1's auc: 0.888317\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "[300]\ttraining's auc: 0.999998\tvalid_1's auc: 0.848965                       \n",
      "Early stopping, best iteration is:                                           \n",
      "[245]\ttraining's auc: 0.999991\tvalid_1's auc: 0.852509\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Early stopping, best iteration is:                                           \n",
      "[46]\ttraining's auc: 0.979792\tvalid_1's auc: 0.847519\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "[300]\ttraining's auc: 0.999942\tvalid_1's auc: 0.86439                        \n",
      "Early stopping, best iteration is:                                           \n",
      "[285]\ttraining's auc: 0.999917\tvalid_1's auc: 0.866231\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Early stopping, best iteration is:                                           \n",
      "[49]\ttraining's auc: 0.87672\tvalid_1's auc: 0.878044\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Early stopping, best iteration is:                                           \n",
      "[27]\ttraining's auc: 0.872566\tvalid_1's auc: 0.883502\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "[300]\ttraining's auc: 0.938166\tvalid_1's auc: 0.805413                       \n",
      "[600]\ttraining's auc: 0.965534\tvalid_1's auc: 0.82556                        \n",
      "[900]\ttraining's auc: 0.977687\tvalid_1's auc: 0.833491                       \n",
      "[1200]\ttraining's auc: 0.984011\tvalid_1's auc: 0.836806                      \n",
      "[1500]\ttraining's auc: 0.988251\tvalid_1's auc: 0.840078                      \n",
      "[1800]\ttraining's auc: 0.991212\tvalid_1's auc: 0.842707                      \n",
      "Early stopping, best iteration is:                                           \n",
      "[1904]\ttraining's auc: 0.991951\tvalid_1's auc: 0.843078\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Early stopping, best iteration is:                                           \n",
      "[14]\ttraining's auc: 0.871153\tvalid_1's auc: 0.84654\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Early stopping, best iteration is:                                           \n",
      "[22]\ttraining's auc: 0.88209\tvalid_1's auc: 0.818622\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Early stopping, best iteration is:                                           \n",
      "[20]\ttraining's auc: 0.945048\tvalid_1's auc: 0.90022\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Early stopping, best iteration is:                                           \n",
      "[152]\ttraining's auc: 0.993005\tvalid_1's auc: 0.891861\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "[300]\ttraining's auc: 0.999996\tvalid_1's auc: 0.849108                       \n",
      "Early stopping, best iteration is:                                           \n",
      "[281]\ttraining's auc: 0.999969\tvalid_1's auc: 0.852738\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Early stopping, best iteration is:                                           \n",
      "[173]\ttraining's auc: 0.998462\tvalid_1's auc: 0.862832\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Early stopping, best iteration is:                                           \n",
      "[105]\ttraining's auc: 0.987172\tvalid_1's auc: 0.856296\n",
      "100%|██████████| 10/10 [00:28<00:00,  2.69s/it, best loss: -0.8538110982039139]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.08355638517641092}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_hyperopt(X, Y):\n",
    "    def para_tuning_obj(params):\n",
    "        params = {\n",
    "        'boosting_type': 'gbdt', \n",
    "        'metric': 'auc', \n",
    "        'objective': 'binary', \n",
    "        'eval_metric': 'auc', \n",
    "        \"tree_learner\": \"serial\",\n",
    "        'max_depth': 3,\n",
    "        'learning_rate': float(params['learning_rate']),\n",
    "}\n",
    "    \n",
    "        real = np.array([])\n",
    "        pred = np.array([])\n",
    "        skf = StratifiedKFold(n_splits=5)\n",
    "        for trn_idx, val_idx in skf.split(X, Y):\n",
    "            x_train, x_val = X.iloc[trn_idx, :], X.iloc[val_idx, :]\n",
    "            y_train, y_val = Y.iloc[trn_idx], Y.iloc[val_idx]\n",
    "            train_set = lgb.Dataset(x_train, y_train)\n",
    "            val_set = lgb.Dataset(x_val, y_val)\n",
    "        \n",
    "            clf = lgb.train(params, train_set, num_boost_round = 100000, early_stopping_rounds = 100, \n",
    "                         valid_sets = [train_set, val_set], verbose_eval = 300)\n",
    "            pred = np.concatenate((pred, np.array(clf.predict(x_val, num_iteration = clf.best_iteration))), axis=0) \n",
    "            real = np.concatenate((real, np.array(y_val)), axis=0) \n",
    "        score = roc_auc_score(real, pred)\n",
    "    \n",
    "        return -score\n",
    "\n",
    "    trials = Trials()\n",
    "\n",
    "    space ={\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.001, 0.1),\n",
    "    }\n",
    "\n",
    "    best = fmin(para_tuning_obj, space = space, algo=tpe.suggest, max_evals=10, trials=trials, verbose=1)\n",
    "\n",
    "    best_params = space_eval(space, best)\n",
    "    return best_params\n",
    "\n",
    "#X = new_train.drop(['target'],axis=1).copy()\n",
    "#Y = new_train.target.copy()\n",
    "#my_hyperopt(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['target', 'store_lat', 'store_lon', 'radius', 'type', 'name', 'OS',\n",
      "       'accumulated_actions', 'day0', 'day1', 'day2', 'day3', 'day4', 'day5',\n",
      "       'day6', 'in_store', 'lang', 'max_dist', 'min_dist', 'optout_count',\n",
      "       'std_dist', 'timezone', 'yellow_in_pic', 'pid_count_enc',\n",
      "       'uni_sess_per_pid'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(new_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred =pred_value3\n",
    "sample_submission = pd.read_csv(\"../../../20200125atma/input/atmacup3_sample_submission.csv\")\n",
    "sample_submission[\"target\"] = final_pred\n",
    "sample_submission.to_csv(\"../../../20200125atma/result/atmacup3_sample_submission\"+str(roc)+\".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
