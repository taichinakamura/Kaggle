{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36acf24f",
   "metadata": {
    "papermill": {
     "duration": 0.030642,
     "end_time": "2021-07-22T09:11:54.923871",
     "exception": false,
     "start_time": "2021-07-22T09:11:54.893229",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- cancel semi-supervised learning\n",
    "- add TTA\n",
    "- n_epochs 200\n",
    "- cancel color jitter params for data augmentation\n",
    "- cancel classification types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82e500d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T09:11:54.989393Z",
     "iopub.status.busy": "2021-07-22T09:11:54.987220Z",
     "iopub.status.idle": "2021-07-22T09:12:05.844310Z",
     "shell.execute_reply": "2021-07-22T09:12:05.843409Z",
     "shell.execute_reply.started": "2021-07-22T08:23:37.819716Z"
    },
    "papermill": {
     "duration": 10.891855,
     "end_time": "2021-07-22T09:12:05.844516",
     "exception": false,
     "start_time": "2021-07-22T09:11:54.952661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\r\n",
      "  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 376 kB 868 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.8.1)\r\n",
      "Requirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from timm) (1.7.0)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (0.18.2)\r\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (3.7.4.3)\r\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (0.6)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (1.19.5)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (8.2.0)\r\n",
      "Installing collected packages: timm\r\n",
      "Successfully installed timm-0.4.12\r\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fb03bd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T09:12:05.921899Z",
     "iopub.status.busy": "2021-07-22T09:12:05.920955Z",
     "iopub.status.idle": "2021-07-22T09:12:15.431120Z",
     "shell.execute_reply": "2021-07-22T09:12:15.429991Z",
     "shell.execute_reply.started": "2021-07-22T08:23:46.229234Z"
    },
    "papermill": {
     "duration": 9.550708,
     "end_time": "2021-07-22T09:12:15.431277",
     "exception": false,
     "start_time": "2021-07-22T09:12:05.880569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ttach\r\n",
      "  Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\r\n",
      "Installing collected packages: ttach\r\n",
      "Successfully installed ttach-0.0.3\r\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ttach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f83c128e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T09:12:15.510099Z",
     "iopub.status.busy": "2021-07-22T09:12:15.504619Z",
     "iopub.status.idle": "2021-07-22T09:12:28.416417Z",
     "shell.execute_reply": "2021-07-22T09:12:28.415819Z",
     "shell.execute_reply.started": "2021-07-22T08:23:53.004895Z"
    },
    "papermill": {
     "duration": 12.950762,
     "end_time": "2021-07-22T09:12:28.416566",
     "exception": false,
     "start_time": "2021-07-22T09:12:15.465804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightly\r\n",
      "  Downloading lightly-1.1.15-py3-none-any.whl (240 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 240 kB 879 kB/s \r\n",
      "\u001b[?25hCollecting hydra-core>=1.0.0\r\n",
      "  Downloading hydra_core-1.1.0-py3-none-any.whl (144 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 144 kB 3.7 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.7/site-packages (from lightly) (2.8.1)\r\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /opt/conda/lib/python3.7/site-packages (from lightly) (1.26.5)\r\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.7/site-packages (from lightly) (1.15.0)\r\n",
      "Requirement already satisfied: certifi>=14.05.14 in /opt/conda/lib/python3.7/site-packages (from lightly) (2021.5.30)\r\n",
      "Collecting lightly-utils==0.0.1\r\n",
      "  Downloading lightly_utils-0.0.1-py3-none-any.whl (6.3 kB)\r\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /opt/conda/lib/python3.7/site-packages (from lightly) (49.6.0.post20210108)\r\n",
      "Requirement already satisfied: pytorch-lightning>=1.0.4 in /opt/conda/lib/python3.7/site-packages (from lightly) (1.3.8)\r\n",
      "Requirement already satisfied: tqdm>=4.44 in /opt/conda/lib/python3.7/site-packages (from lightly) (4.61.1)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from lightly) (0.8.1)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.7/site-packages (from lightly) (2.25.1)\r\n",
      "Requirement already satisfied: numpy>=1.18.1 in /opt/conda/lib/python3.7/site-packages (from lightly) (1.19.5)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from lightly-utils==0.0.1->lightly) (8.2.0)\r\n",
      "Collecting antlr4-python3-runtime==4.8\r\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 112 kB 3.9 MB/s \r\n",
      "\u001b[?25hCollecting omegaconf==2.1.*\r\n",
      "  Downloading omegaconf-2.1.0-py3-none-any.whl (74 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 74 kB 1.5 MB/s \r\n",
      "\u001b[?25hCollecting importlib-resources\r\n",
      "  Downloading importlib_resources-5.2.0-py3-none-any.whl (27 kB)\r\n",
      "Requirement already satisfied: PyYAML>=5.1.* in /opt/conda/lib/python3.7/site-packages (from omegaconf==2.1.*->hydra-core>=1.0.0->lightly) (5.4.1)\r\n",
      "Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.0.4->lightly) (2.4.1)\r\n",
      "Requirement already satisfied: pyDeprecate==0.3.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.0.4->lightly) (0.3.0)\r\n",
      "Requirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.0.4->lightly) (1.7.0)\r\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.0.4->lightly) (20.9)\r\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.0.4->lightly) (2021.6.1)\r\n",
      "Requirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.0.4->lightly) (0.18.2)\r\n",
      "Requirement already satisfied: torchmetrics>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.0.4->lightly) (0.4.1)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.0.4->lightly) (3.7.4.post0)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=17.0->pytorch-lightning>=1.0.4->lightly) (2.4.7)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.23.0->lightly) (2.10)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.23.0->lightly) (4.0.0)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (1.30.2)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (0.4.4)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (2.0.1)\r\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (1.32.0)\r\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (3.17.3)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (1.8.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (3.3.4)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (0.12.0)\r\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (0.36.2)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (4.7.2)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (4.2.2)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (0.2.7)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (1.3.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (3.4.0)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (3.1.1)\r\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->pytorch-lightning>=1.0.4->lightly) (3.7.4.3)\r\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->pytorch-lightning>=1.0.4->lightly) (0.6)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.0.4->lightly) (21.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.0.4->lightly) (5.1.0)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.0.4->lightly) (1.6.3)\r\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.0.4->lightly) (3.0.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (3.4.1)\r\n",
      "Building wheels for collected packages: antlr4-python3-runtime\r\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=c6140a2b05e664c0645f78d102ba5823c972fc26a8c4a1e13f67c1aa7dbbb997\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\r\n",
      "Successfully built antlr4-python3-runtime\r\n",
      "Installing collected packages: antlr4-python3-runtime, omegaconf, importlib-resources, lightly-utils, hydra-core, lightly\r\n",
      "Successfully installed antlr4-python3-runtime-4.8 hydra-core-1.1.0 importlib-resources-5.2.0 lightly-1.1.15 lightly-utils-0.0.1 omegaconf-2.1.0\r\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install lightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e594465",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T09:12:28.518047Z",
     "iopub.status.busy": "2021-07-22T09:12:28.517014Z",
     "iopub.status.idle": "2021-07-22T09:12:38.801296Z",
     "shell.execute_reply": "2021-07-22T09:12:38.800628Z",
     "shell.execute_reply.started": "2021-07-22T08:24:03.717135Z"
    },
    "papermill": {
     "duration": 10.338637,
     "end_time": "2021-07-22T09:12:38.801472",
     "exception": false,
     "start_time": "2021-07-22T09:12:28.462835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import tensorflow as tf\n",
    "from torch.optim import Adam\n",
    "from torch.utils import data\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.optim import lr_scheduler\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# various models can be selected: https://pytorch.org/vision/stable/models.html\n",
    "from torchvision.models import resnet34, resnet18\n",
    "from torchvision import transforms as T\n",
    "import torchvision\n",
    "\n",
    "import ttach as tta\n",
    "import lightly\n",
    "import math\n",
    "\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c977730",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T09:12:38.951431Z",
     "iopub.status.busy": "2021-07-22T09:12:38.950360Z",
     "iopub.status.idle": "2021-07-22T09:12:38.954736Z",
     "shell.execute_reply": "2021-07-22T09:12:38.953707Z",
     "shell.execute_reply.started": "2021-07-22T08:24:13.912218Z"
    },
    "papermill": {
     "duration": 0.106821,
     "end_time": "2021-07-22T09:12:38.954901",
     "exception": false,
     "start_time": "2021-07-22T09:12:38.848080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "photo_dir = \"../input/atma11-dataset/photos/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27cb456",
   "metadata": {
    "papermill": {
     "duration": 0.044934,
     "end_time": "2021-07-22T09:12:39.046039",
     "exception": false,
     "start_time": "2021-07-22T09:12:39.001105",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05218d7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T09:12:39.142447Z",
     "iopub.status.busy": "2021-07-22T09:12:39.141743Z",
     "iopub.status.idle": "2021-07-22T09:12:39.186428Z",
     "shell.execute_reply": "2021-07-22T09:12:39.187062Z",
     "shell.execute_reply.started": "2021-07-22T08:24:13.965161Z"
    },
    "papermill": {
     "duration": 0.095893,
     "end_time": "2021-07-22T09:12:39.187242",
     "exception": false,
     "start_time": "2021-07-22T09:12:39.091349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/atma11-dataset/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/atma11-dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb98b37",
   "metadata": {
    "papermill": {
     "duration": 0.046492,
     "end_time": "2021-07-22T09:12:39.281062",
     "exception": false,
     "start_time": "2021-07-22T09:12:39.234570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c11aea50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T09:12:39.383006Z",
     "iopub.status.busy": "2021-07-22T09:12:39.381828Z",
     "iopub.status.idle": "2021-07-22T09:12:39.385120Z",
     "shell.execute_reply": "2021-07-22T09:12:39.384509Z",
     "shell.execute_reply.started": "2021-07-22T08:24:14.008247Z"
    },
    "papermill": {
     "duration": 0.058229,
     "end_time": "2021-07-22T09:12:39.385253",
     "exception": false,
     "start_time": "2021-07-22T09:12:39.327024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_img_path(object_id):\n",
    "    return os.path.join(photo_dir, f'{object_id}.jpg')\n",
    "\n",
    "def read_image(object_id):\n",
    "    return Image.open(to_img_path(object_id))\n",
    "\n",
    "def calculate_metrics(y_true, y_pred) -> dict:\n",
    "    return {'rmse': mean_squared_error(y_true, y_pred) ** .5}\n",
    "\n",
    "def create_metadata(input_df):\n",
    "    out_df = input_df[['object_id']].copy()\n",
    "    out_df['object_path'] = input_df['object_id'].map(to_img_path)\n",
    "\n",
    "    if \"target\" in input_df:\n",
    "        out_df[\"target\"] = input_df[\"target\"] \n",
    "\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f7f4f21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T09:12:39.489743Z",
     "iopub.status.busy": "2021-07-22T09:12:39.488611Z",
     "iopub.status.idle": "2021-07-22T09:12:39.492107Z",
     "shell.execute_reply": "2021-07-22T09:12:39.491535Z",
     "shell.execute_reply.started": "2021-07-22T08:24:14.018828Z"
    },
    "papermill": {
     "duration": 0.061679,
     "end_time": "2021-07-22T09:12:39.492312",
     "exception": false,
     "start_time": "2021-07-22T09:12:39.430633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stratified_group_k_fold(X, y, groups, k, seed=None):\n",
    "    labels_num = np.max(y) + 1\n",
    "    y_counts_per_group = defaultdict(lambda: np.zeros(labels_num))\n",
    "    y_distr = Counter()\n",
    "    for label, g in zip(y, groups):\n",
    "        y_counts_per_group[g][label] += 1\n",
    "        y_distr[label] += 1\n",
    "\n",
    "    y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num))\n",
    "    groups_per_fold = defaultdict(set)\n",
    "\n",
    "    def eval_y_counts_per_fold(y_counts, fold):\n",
    "        y_counts_per_fold[fold] += y_counts\n",
    "        std_per_label = []\n",
    "        for label in range(labels_num):\n",
    "            label_std = np.std([y_counts_per_fold[i][label] / y_distr[label] for i in range(k)])\n",
    "            std_per_label.append(label_std)\n",
    "        y_counts_per_fold[fold] -= y_counts\n",
    "        return np.mean(std_per_label)\n",
    "    \n",
    "    groups_and_y_counts = list(y_counts_per_group.items())\n",
    "    random.Random(seed).shuffle(groups_and_y_counts)\n",
    "\n",
    "    for g, y_counts in sorted(groups_and_y_counts, key=lambda x: -np.std(x[1])):\n",
    "        best_fold = None\n",
    "        min_eval = None\n",
    "        for i in range(k):\n",
    "            fold_eval = eval_y_counts_per_fold(y_counts, i)\n",
    "            if min_eval is None or fold_eval < min_eval:\n",
    "                min_eval = fold_eval\n",
    "                best_fold = i\n",
    "        y_counts_per_fold[best_fold] += y_counts\n",
    "        groups_per_fold[best_fold].add(g)\n",
    "\n",
    "    all_groups = set(groups)\n",
    "    for i in range(k):\n",
    "        train_groups = all_groups - groups_per_fold[i]\n",
    "        test_groups = groups_per_fold[i]\n",
    "\n",
    "        train_indices = [i for i, g in enumerate(groups) if g in train_groups]\n",
    "        test_indices = [i for i, g in enumerate(groups) if g in test_groups]\n",
    "\n",
    "        yield train_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c68bf6d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T09:12:39.595961Z",
     "iopub.status.busy": "2021-07-22T09:12:39.595006Z",
     "iopub.status.idle": "2021-07-22T09:12:39.598885Z",
     "shell.execute_reply": "2021-07-22T09:12:39.598281Z",
     "shell.execute_reply.started": "2021-07-22T08:24:14.038295Z"
    },
    "papermill": {
     "duration": 0.062349,
     "end_time": "2021-07-22T09:12:39.599022",
     "exception": false,
     "start_time": "2021-07-22T09:12:39.536673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "IMG_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "class AtmaDataset(data.Dataset):\n",
    "    \"\"\"atmaCup用にデータ読み込み等を行なうデータ・セット\"\"\"\n",
    "    object_path_key = \"object_path\"\n",
    "    label_key = \"target\"\n",
    "\n",
    "    @property\n",
    "    def meta_keys(self):\n",
    "        retval = [self.object_path_key]\n",
    "\n",
    "        if self.is_train:\n",
    "            retval += [self.label_key]\n",
    "\n",
    "        return retval\n",
    "\n",
    "    def __init__(self, meta_df: pd.DataFrame, is_train=True):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            meta_df: \n",
    "                画像へのパスと label 情報が含まれている dataframe\n",
    "                必ず object_path に画像へのパス, target に正解ラベルが入っている必要があります\n",
    "\n",
    "            is_train:\n",
    "                True のとき学習用のデータ拡張を適用します.\n",
    "                False の時は単に size にリサイズを行います\n",
    "        \"\"\"\n",
    "\n",
    "        self.is_train = is_train\n",
    "        for k in self.meta_keys:\n",
    "            if k not in meta_df:\n",
    "                raise ValueError(\"meta df must have {}\".format(k))\n",
    "\n",
    "        self.meta_df = meta_df.reset_index(drop=True)\n",
    "        self.index_to_data = self.meta_df.to_dict(orient=\"index\")\n",
    "\n",
    "        size = (224, 224)\n",
    "\n",
    "        additional_items = (\n",
    "            [T.Resize(size)]\n",
    "            if not is_train\n",
    "            else [\n",
    "                T.RandomGrayscale(p=0.2),\n",
    "                T.RandomVerticalFlip(),\n",
    "                T.RandomHorizontalFlip(),\n",
    "                #T.RandomRotation(90),\n",
    "                #T.ColorJitter(\n",
    "                #    brightness=0.1,\n",
    "                #    contrast=0.1,\n",
    "                #),\n",
    "                T.RandomResizedCrop(size),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.transformer = T.Compose(\n",
    "            [*additional_items, T.ToTensor(), T.Normalize(mean=IMG_MEAN, std=IMG_STD)]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.index_to_data[index]\n",
    "\n",
    "        obj_path, label = data.get(self.object_path_key), data.get(self.label_key, -1)\n",
    "        img = Image.open(obj_path)\n",
    "        img = self.transformer(img)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.meta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef757b0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T09:12:39.777623Z",
     "iopub.status.busy": "2021-07-22T09:12:39.776287Z",
     "iopub.status.idle": "2021-07-22T09:12:39.785013Z",
     "shell.execute_reply": "2021-07-22T09:12:39.790386Z",
     "shell.execute_reply.started": "2021-07-22T08:24:14.065742Z"
    },
    "papermill": {
     "duration": 0.12347,
     "end_time": "2021-07-22T09:12:39.790728",
     "exception": false,
     "start_time": "2021-07-22T09:12:39.667258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    optimizer: Optimizer,\n",
    "    scheduler: lr_scheduler,\n",
    "    train_loader: data.DataLoader\n",
    ")-> pd.Series:\n",
    "    model.train()\n",
    "    \n",
    "    criterion = nn.MSELoss() \n",
    "    \n",
    "    metrics = defaultdict(float)\n",
    "    n_iters = len(train_loader)\n",
    "    \n",
    "    for i, (x_i, y_i) in enumerate(train_loader):\n",
    "        x_i = x_i.to(device)\n",
    "        y_i = y_i.to(device).reshape(-1,1).float()\n",
    "        \n",
    "        output = model(x_i)\n",
    "        loss = criterion(output, y_i)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        metric_i = {\n",
    "            \"loss\": loss.item()\n",
    "        }\n",
    "        for k, v in metric_i.items():\n",
    "            metrics[k] /= n_iters\n",
    "            \n",
    "    return pd.Series(metrics).add_prefix(\"train_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30823dde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T09:12:39.960965Z",
     "iopub.status.busy": "2021-07-22T09:12:39.959922Z",
     "iopub.status.idle": "2021-07-22T09:12:39.966925Z",
     "shell.execute_reply": "2021-07-22T09:12:39.968152Z",
     "shell.execute_reply.started": "2021-07-22T08:24:14.078774Z"
    },
    "papermill": {
     "duration": 0.098334,
     "end_time": "2021-07-22T09:12:39.968414",
     "exception": false,
     "start_time": "2021-07-22T09:12:39.870080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid_predict(model: nn.Module, loader: data.DataLoader) -> np.ndarray:\n",
    "    model.eval()\n",
    "    predicts = []\n",
    "    \n",
    "    for x_i, y_i in loader:\n",
    "        with torch.no_grad():\n",
    "            output = model(x_i.to(device))\n",
    "        \n",
    "        predicts.extend(output.data.cpu().numpy())\n",
    "        \n",
    "    pred = np.array(predicts).reshape(-1)\n",
    "        \n",
    "    return pred\n",
    "\n",
    "transforms = tta.Compose(\n",
    "    [\n",
    "        tta.HorizontalFlip(),\n",
    "        tta.VerticalFlip(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# prediction with test time augmentation\n",
    "def predict(model: nn.Module, loader: data.DataLoader) -> np.ndarray:\n",
    "    model.eval()\n",
    "    predicts = []\n",
    "    tta_model = tta.ClassificationTTAWrapper(model, transforms)\n",
    "    \n",
    "    for x_i, y_i in loader:\n",
    "        with torch.no_grad():\n",
    "            output = tta_model(x_i.to(device))\n",
    "        \n",
    "        predicts.extend(output.data.cpu().numpy())\n",
    "        \n",
    "    pred = np.array(predicts).reshape(-1)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36702f1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T09:12:40.135481Z",
     "iopub.status.busy": "2021-07-22T09:12:40.134406Z",
     "iopub.status.idle": "2021-07-22T09:12:40.142001Z",
     "shell.execute_reply": "2021-07-22T09:12:40.142794Z",
     "shell.execute_reply.started": "2021-07-22T08:24:14.091433Z"
    },
    "papermill": {
     "duration": 0.095077,
     "end_time": "2021-07-22T09:12:40.143031",
     "exception": false,
     "start_time": "2021-07-22T09:12:40.047954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid(\n",
    "    model: nn.Module,\n",
    "    y_valid: np.ndarray,\n",
    "    valid_loader: data.DataLoader\n",
    ") -> pd.Series:\n",
    "    pred = valid_predict(model, valid_loader)\n",
    "    score = calculate_metrics(y_valid, pred)\n",
    "    \n",
    "    valid_score = pd.Series(score)\n",
    "    \n",
    "    return valid_score.add_prefix(\"valid_\"), pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e26a718",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T09:12:40.313595Z",
     "iopub.status.busy": "2021-07-22T09:12:40.312660Z",
     "iopub.status.idle": "2021-07-22T09:12:40.317037Z",
     "shell.execute_reply": "2021-07-22T09:12:40.316453Z",
     "shell.execute_reply.started": "2021-07-22T08:24:14.104997Z"
    },
    "papermill": {
     "duration": 0.092805,
     "end_time": "2021-07-22T09:12:40.317177",
     "exception": false,
     "start_time": "2021-07-22T09:12:40.224372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_fold(\n",
    "    model: nn.Module,\n",
    "    train_df: pd.DataFrame,\n",
    "    valid_df: pd.DataFrame,\n",
    "    y_valid: np.ndarray,\n",
    "    n_epochs = 30,\n",
    "    n_fold = 1\n",
    "   ) -> np.ndarray:\n",
    "    optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    train_dataset = AtmaDataset(meta_df = train_df)\n",
    "    valid_dataset = AtmaDataset(meta_df = valid_df, is_train=False)\n",
    "    \n",
    "    train_loader = data.DataLoader(\n",
    "        train_dataset, batch_size=64, shuffle=True, drop_last=True, num_workers=4\n",
    "    )\n",
    "    valid_loader = data.DataLoader(valid_dataset, batch_size=256, num_workers=4)\n",
    "\n",
    "    scheduler = lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=n_epochs, steps_per_epoch=len(train_loader))\n",
    "    \n",
    "    score_df = pd.DataFrame()\n",
    "    valid_score = np.inf\n",
    "    valid_score_key = \"valid_rmse\"\n",
    "    valid_best_pred = None\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        print(f\"start {epoch}\")\n",
    "        score_train = train(model, optimizer, scheduler, train_loader)\n",
    "        score_valid, y_valid_pred = valid(model=model, valid_loader=valid_loader, y_valid = y_valid)\n",
    "        \n",
    "        # --- 学習のロスと検証スコアの値をデータフレームに追加\n",
    "        row = pd.concat([score_train, score_valid])\n",
    "        row[\"epoch\"] = epoch\n",
    "        row = pd.DataFrame([row])\n",
    "        score_df = pd.concat([score_df, row], ignore_index=True)\n",
    "        # ---\n",
    "        \n",
    "        current_score = score_valid[valid_score_key]\n",
    "        if current_score < valid_score:\n",
    "            print(tabulate(row, headers=row.columns))\n",
    "            print(f'validation score is improved!! {valid_score:.4f} -> {current_score:.4f}')\n",
    "            torch.save(model.state_dict(), \"model_best\"+str(n_fold)+\".pth\")\n",
    "            valid_score = current_score\n",
    "            valid_best_pred = y_valid_pred\n",
    "            \n",
    "    score_df.to_csv('score_'+str(n_fold)+'.csv', index=False)\n",
    "    return valid_best_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f20846e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T09:12:40.418192Z",
     "iopub.status.busy": "2021-07-22T09:12:40.417249Z",
     "iopub.status.idle": "2021-07-22T09:12:40.424329Z",
     "shell.execute_reply": "2021-07-22T09:12:40.423680Z",
     "shell.execute_reply.started": "2021-07-22T08:24:14.123690Z"
    },
    "papermill": {
     "duration": 0.060323,
     "end_time": "2021-07-22T09:12:40.424479",
     "exception": false,
     "start_time": "2021-07-22T09:12:40.364156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42): \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072e4ce4",
   "metadata": {
    "papermill": {
     "duration": 0.04651,
     "end_time": "2021-07-22T09:12:40.517563",
     "exception": false,
     "start_time": "2021-07-22T09:12:40.471053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# simsiam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c91de666",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T09:12:40.615442Z",
     "iopub.status.busy": "2021-07-22T09:12:40.614623Z",
     "iopub.status.idle": "2021-07-22T09:12:40.618447Z",
     "shell.execute_reply": "2021-07-22T09:12:40.618955Z",
     "shell.execute_reply.started": "2021-07-22T08:24:14.143155Z"
    },
    "papermill": {
     "duration": 0.055681,
     "end_time": "2021-07-22T09:12:40.619137",
     "exception": false,
     "start_time": "2021-07-22T09:12:40.563456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_workers = 2\n",
    "batch_size = 128\n",
    "seed = 1\n",
    "epochs = 10\n",
    "input_size = 224\n",
    "\n",
    "# dimension of the embeddings\n",
    "num_ftrs = 512\n",
    "# dimension of the output of the prediction and projection heads\n",
    "out_dim = proj_hidden_dim = 512\n",
    "# the prediction head uses a bottleneck architecture\n",
    "pred_hidden_dim = 128\n",
    "# use 2 layers in the projection head\n",
    "num_mlp_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cca52105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T09:12:40.721512Z",
     "iopub.status.busy": "2021-07-22T09:12:40.720826Z",
     "iopub.status.idle": "2021-07-22T09:12:55.672137Z",
     "shell.execute_reply": "2021-07-22T09:12:55.671466Z",
     "shell.execute_reply.started": "2021-07-22T08:24:14.152612Z"
    },
    "papermill": {
     "duration": 15.007113,
     "end_time": "2021-07-22T09:12:55.672307",
     "exception": false,
     "start_time": "2021-07-22T09:12:40.665194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the augmentations for self-supervised learning\n",
    "collate_fn = lightly.data.ImageCollateFunction(\n",
    "    input_size=input_size,\n",
    "    # require invariance to flips and rotations\n",
    "    hf_prob=0.5,\n",
    "    vf_prob=0.5,\n",
    "    rr_prob=0.5,\n",
    "    # satellite images are all taken from the same height\n",
    "    # so we use only slight random cropping\n",
    "    min_scale=0.5,\n",
    "    # use a weak color jitter for invariance w.r.t small color changes\n",
    "    # 元々の学習でいらないaugmentationなので、simsiamにおいても不要？\n",
    "    #cj_prob=0.2,\n",
    "    #cj_bright=0.1,\n",
    "    #cj_contrast=0.1,\n",
    "    #cj_hue=0.1,\n",
    "    #cj_sat=0.1,\n",
    "    # addtional items\n",
    "    gaussian_blur=0.2,\n",
    "    random_gray_scale=0.2\n",
    ")\n",
    "\n",
    "# create a lightly dataset for training, since the augmentations are handled\n",
    "# by the collate function, there is no need to apply additional ones here\n",
    "dataset_train_simsiam = lightly.data.LightlyDataset(\n",
    "    input_dir=\"../input/atma11-dataset/photos/\"\n",
    ")\n",
    "\n",
    "# create a dataloader for training\n",
    "dataloader_train_simsiam = torch.utils.data.DataLoader(\n",
    "    dataset_train_simsiam,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "# create a torchvision transformation for embedding the dataset after training\n",
    "# here, we resize the images to match the input size during training and apply\n",
    "# a normalization of the color channel based on statistics from imagenet\n",
    "test_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((input_size, input_size)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(\n",
    "        mean=lightly.data.collate.imagenet_normalize['mean'],\n",
    "        std=lightly.data.collate.imagenet_normalize['std'],\n",
    "    )\n",
    "])\n",
    "\n",
    "# create a lightly dataset for embedding\n",
    "dataset_test = lightly.data.LightlyDataset(\n",
    "    input_dir=\"../input/atma11-dataset/photos/\",\n",
    "    transform=test_transforms\n",
    ")\n",
    "\n",
    "# create a dataloader for embedding\n",
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbff08af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T09:12:55.772208Z",
     "iopub.status.busy": "2021-07-22T09:12:55.771248Z",
     "iopub.status.idle": "2021-07-22T09:12:56.087124Z",
     "shell.execute_reply": "2021-07-22T09:12:56.086468Z",
     "shell.execute_reply.started": "2021-07-22T08:24:22.884708Z"
    },
    "papermill": {
     "duration": 0.368231,
     "end_time": "2021-07-22T09:12:56.087298",
     "exception": false,
     "start_time": "2021-07-22T09:12:55.719067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we use a pretrained resnet for this tutorial to speed\n",
    "# up training time but you can also train one from scratch\n",
    "# Do not use pretrained Model\n",
    "resnet = torchvision.models.resnet18(pretrained=False)\n",
    "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "#vit = timm.create_model('vit_tiny_r_s16_p8_224', pretrained=False)\n",
    "#backbone = nn.Sequential(*list(vit.children())[:-1])\n",
    "\n",
    "# create the SimSiam model using the backbone from above\n",
    "model = lightly.models.SimSiam(\n",
    "    backbone,\n",
    "    num_ftrs=num_ftrs,\n",
    "    proj_hidden_dim=pred_hidden_dim,\n",
    "    pred_hidden_dim=pred_hidden_dim,\n",
    "    out_dim=out_dim,\n",
    "    num_mlp_layers=num_mlp_layers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c8b34b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T09:12:56.190000Z",
     "iopub.status.busy": "2021-07-22T09:12:56.188752Z",
     "iopub.status.idle": "2021-07-22T09:12:56.192007Z",
     "shell.execute_reply": "2021-07-22T09:12:56.192599Z",
     "shell.execute_reply.started": "2021-07-22T08:24:23.152449Z"
    },
    "papermill": {
     "duration": 0.059282,
     "end_time": "2021-07-22T09:12:56.192808",
     "exception": false,
     "start_time": "2021-07-22T09:12:56.133526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SimSiam uses a symmetric negative cosine similarity loss\n",
    "criterion = lightly.loss.SymNegCosineSimilarityLoss()\n",
    "\n",
    "# scale the learning rate\n",
    "lr = 0.05 * batch_size / 256\n",
    "# use SGD with momentum and weight decay\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=lr,\n",
    "    momentum=0.9,\n",
    "    weight_decay=5e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03cfc53f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T09:12:56.294417Z",
     "iopub.status.busy": "2021-07-22T09:12:56.293324Z",
     "iopub.status.idle": "2021-07-22T09:12:56.296432Z",
     "shell.execute_reply": "2021-07-22T09:12:56.296971Z",
     "shell.execute_reply.started": "2021-07-22T08:24:23.160538Z"
    },
    "papermill": {
     "duration": 0.055286,
     "end_time": "2021-07-22T09:12:56.297146",
     "exception": false,
     "start_time": "2021-07-22T09:12:56.241860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.to(device)\n",
    "\n",
    "# avg_loss = 0.\n",
    "# avg_output_std = 0.\n",
    "# for e in range(epochs):\n",
    "\n",
    "#     for (x0, x1), _, _ in dataloader_train_simsiam:\n",
    "\n",
    "#         # move images to the gpu\n",
    "#         x0 = x0.to(device)\n",
    "#         x1 = x1.to(device)\n",
    "\n",
    "#         # run the model on both transforms of the images\n",
    "#         # the output of the simsiam model is a y containing the predictions\n",
    "#         # and projections for each input x\n",
    "#         y0, y1 = model(x0, x1)\n",
    "\n",
    "#         # backpropagation\n",
    "#         loss = criterion(y0, y1)\n",
    "#         loss.backward()\n",
    "\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # calculate the per-dimension standard deviation of the outputs\n",
    "#         # we can use this later to check whether the embeddings are collapsing\n",
    "#         output, _ = y0\n",
    "#         output = output.detach()\n",
    "#         output = torch.nn.functional.normalize(output, dim=1)\n",
    "\n",
    "#         output_std = torch.std(output, 0)\n",
    "#         output_std = output_std.mean()\n",
    "\n",
    "#         # want to minimize\n",
    "#         # use moving averages to track the loss and standard deviation\n",
    "#         w = 0.9\n",
    "#         avg_loss = w * avg_loss + (1 - w) * loss.item()\n",
    "#         avg_output_std = w * avg_output_std + (1 - w) * output_std.item()\n",
    "\n",
    "#     # the level of collapse is large if the standard deviation of the l2\n",
    "#     # normalized output is much smaller than 1 / sqrt(dim)\n",
    "#     collapse_level = max(0., 1 - math.sqrt(out_dim) * avg_output_std)\n",
    "#     # print intermediate results\n",
    "#     print(f'[Epoch {e:3d}] '\n",
    "#         f'Loss = {avg_loss:.2f} | '\n",
    "#         f'Collapse Level: {collapse_level:.2f} / 1.00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b50aaef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T09:12:56.393820Z",
     "iopub.status.busy": "2021-07-22T09:12:56.392724Z",
     "iopub.status.idle": "2021-07-22T09:12:56.396496Z",
     "shell.execute_reply": "2021-07-22T09:12:56.395962Z",
     "shell.execute_reply.started": "2021-07-22T08:24:23.171810Z"
    },
    "papermill": {
     "duration": 0.054209,
     "end_time": "2021-07-22T09:12:56.396659",
     "exception": false,
     "start_time": "2021-07-22T09:12:56.342450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.save(model.backbone.state_dict(), \"ssl.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c14442",
   "metadata": {
    "papermill": {
     "duration": 0.045713,
     "end_time": "2021-07-22T09:12:56.487117",
     "exception": false,
     "start_time": "2021-07-22T09:12:56.441404",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# main training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edacd992",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T09:12:56.583718Z",
     "iopub.status.busy": "2021-07-22T09:12:56.582628Z",
     "iopub.status.idle": "2021-07-22T09:12:56.841719Z",
     "shell.execute_reply": "2021-07-22T09:12:56.841143Z",
     "shell.execute_reply.started": "2021-07-22T08:24:23.185425Z"
    },
    "papermill": {
     "duration": 0.309434,
     "end_time": "2021-07-22T09:12:56.841913",
     "exception": false,
     "start_time": "2021-07-22T09:12:56.532479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    return resnet18(pretrained=False)\n",
    "model = make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eabe9d7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T09:12:56.939287Z",
     "iopub.status.busy": "2021-07-22T09:12:56.938251Z",
     "iopub.status.idle": "2021-07-22T09:12:56.943926Z",
     "shell.execute_reply": "2021-07-22T09:12:56.944501Z",
     "shell.execute_reply.started": "2021-07-22T08:24:23.410166Z"
    },
    "papermill": {
     "duration": 0.056585,
     "end_time": "2021-07-22T09:12:56.944654",
     "exception": false,
     "start_time": "2021-07-22T09:12:56.888069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d235c4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T09:12:57.062825Z",
     "iopub.status.busy": "2021-07-22T09:12:57.052271Z",
     "iopub.status.idle": "2021-07-22T09:12:57.085760Z",
     "shell.execute_reply": "2021-07-22T09:12:57.085236Z",
     "shell.execute_reply.started": "2021-07-22T08:24:23.417470Z"
    },
    "papermill": {
     "duration": 0.095652,
     "end_time": "2021-07-22T09:12:57.085901",
     "exception": false,
     "start_time": "2021-07-22T09:12:56.990249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_meta_df = train_df[['target', 'object_id']].copy()\n",
    "train_meta_df['object_path'] = train_meta_df['object_id'].map(to_img_path)\n",
    "\n",
    "dataset = AtmaDataset(meta_df=train_meta_df)\n",
    "loader = data.DataLoader(dataset=dataset, batch_size=54, num_workers=4)\n",
    "\n",
    "groups = train_df[\"art_series_id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43acf175",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T09:12:57.211758Z",
     "iopub.status.busy": "2021-07-22T09:12:57.201343Z",
     "iopub.status.idle": "2021-07-22T13:59:46.454289Z",
     "shell.execute_reply": "2021-07-22T13:59:46.453670Z",
     "shell.execute_reply.started": "2021-07-22T08:24:23.465278Z"
    },
    "papermill": {
     "duration": 17209.322731,
     "end_time": "2021-07-22T13:59:46.454437",
     "exception": false,
     "start_time": "2021-07-22T09:12:57.131706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold0\n",
      "start 1\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0       1.02513        1\n",
      "validation score is improved!! inf -> 1.0251\n",
      "start 2\n",
      "start 3\n",
      "start 4\n",
      "start 5\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0       1.00099        5\n",
      "validation score is improved!! 1.0251 -> 1.0010\n",
      "start 6\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0       1.00033        6\n",
      "validation score is improved!! 1.0010 -> 1.0003\n",
      "start 7\n",
      "start 8\n",
      "start 9\n",
      "start 10\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.946789       10\n",
      "validation score is improved!! 1.0003 -> 0.9468\n",
      "start 11\n",
      "start 12\n",
      "start 13\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.917269       13\n",
      "validation score is improved!! 0.9468 -> 0.9173\n",
      "start 14\n",
      "start 15\n",
      "start 16\n",
      "start 17\n",
      "start 18\n",
      "start 19\n",
      "start 20\n",
      "start 21\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.902945       21\n",
      "validation score is improved!! 0.9173 -> 0.9029\n",
      "start 22\n",
      "start 23\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.865154       23\n",
      "validation score is improved!! 0.9029 -> 0.8652\n",
      "start 24\n",
      "start 25\n",
      "start 26\n",
      "start 27\n",
      "start 28\n",
      "start 29\n",
      "start 30\n",
      "start 31\n",
      "start 32\n",
      "start 33\n",
      "start 34\n",
      "start 35\n",
      "start 36\n",
      "start 37\n",
      "start 38\n",
      "start 39\n",
      "start 40\n",
      "start 41\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.863186       41\n",
      "validation score is improved!! 0.8652 -> 0.8632\n",
      "start 42\n",
      "start 43\n",
      "start 44\n",
      "start 45\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0       0.84866       45\n",
      "validation score is improved!! 0.8632 -> 0.8487\n",
      "start 46\n",
      "start 47\n",
      "start 48\n",
      "start 49\n",
      "start 50\n",
      "start 51\n",
      "start 52\n",
      "start 53\n",
      "start 54\n",
      "start 55\n",
      "start 56\n",
      "start 57\n",
      "start 58\n",
      "start 59\n",
      "start 60\n",
      "start 61\n",
      "start 62\n",
      "start 63\n",
      "start 64\n",
      "start 65\n",
      "start 66\n",
      "start 67\n",
      "start 68\n",
      "start 69\n",
      "start 70\n",
      "start 71\n",
      "start 72\n",
      "start 73\n",
      "start 74\n",
      "start 75\n",
      "start 76\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.826363       76\n",
      "validation score is improved!! 0.8487 -> 0.8264\n",
      "start 77\n",
      "start 78\n",
      "start 79\n",
      "start 80\n",
      "start 81\n",
      "start 82\n",
      "start 83\n",
      "start 84\n",
      "start 85\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.824688       85\n",
      "validation score is improved!! 0.8264 -> 0.8247\n",
      "start 86\n",
      "start 87\n",
      "start 88\n",
      "start 89\n",
      "start 90\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0       0.81485       90\n",
      "validation score is improved!! 0.8247 -> 0.8148\n",
      "start 91\n",
      "start 92\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.802271       92\n",
      "validation score is improved!! 0.8148 -> 0.8023\n",
      "start 93\n",
      "start 94\n",
      "start 95\n",
      "start 96\n",
      "start 97\n",
      "start 98\n",
      "start 99\n",
      "start 100\n",
      "start 101\n",
      "start 102\n",
      "start 103\n",
      "start 104\n",
      "start 105\n",
      "start 106\n",
      "start 107\n",
      "start 108\n",
      "start 109\n",
      "start 110\n",
      "start 111\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.796477      111\n",
      "validation score is improved!! 0.8023 -> 0.7965\n",
      "start 112\n",
      "start 113\n",
      "start 114\n",
      "start 115\n",
      "start 116\n",
      "start 117\n",
      "start 118\n",
      "start 119\n",
      "start 120\n",
      "start 121\n",
      "start 122\n",
      "start 123\n",
      "start 124\n",
      "start 125\n",
      "start 126\n",
      "start 127\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.794865      127\n",
      "validation score is improved!! 0.7965 -> 0.7949\n",
      "start 128\n",
      "start 129\n",
      "start 130\n",
      "start 131\n",
      "start 132\n",
      "start 133\n",
      "start 134\n",
      "start 135\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.783586      135\n",
      "validation score is improved!! 0.7949 -> 0.7836\n",
      "start 136\n",
      "start 137\n",
      "start 138\n",
      "start 139\n",
      "start 140\n",
      "start 141\n",
      "start 142\n",
      "start 143\n",
      "start 144\n",
      "start 145\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0       0.76232      145\n",
      "validation score is improved!! 0.7836 -> 0.7623\n",
      "start 146\n",
      "start 147\n",
      "start 148\n",
      "start 149\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.746301      149\n",
      "validation score is improved!! 0.7623 -> 0.7463\n",
      "start 150\n",
      "start 151\n",
      "start 152\n",
      "start 153\n",
      "start 154\n",
      "start 155\n",
      "start 156\n",
      "start 157\n",
      "start 158\n",
      "start 159\n",
      "start 160\n",
      "start 161\n",
      "start 162\n",
      "start 163\n",
      "start 164\n",
      "start 165\n",
      "start 166\n",
      "start 167\n",
      "start 168\n",
      "start 169\n",
      "start 170\n",
      "start 171\n",
      "start 172\n",
      "start 173\n",
      "start 174\n",
      "start 175\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.734568      175\n",
      "validation score is improved!! 0.7463 -> 0.7346\n",
      "start 176\n",
      "start 177\n",
      "start 178\n",
      "start 179\n",
      "start 180\n",
      "start 181\n",
      "start 182\n",
      "start 183\n",
      "start 184\n",
      "start 185\n",
      "start 186\n",
      "start 187\n",
      "start 188\n",
      "start 189\n",
      "start 190\n",
      "start 191\n",
      "start 192\n",
      "start 193\n",
      "start 194\n",
      "start 195\n",
      "start 196\n",
      "start 197\n",
      "start 198\n",
      "start 199\n",
      "start 200\n",
      "fold1\n",
      "start 1\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0       1.91479        1\n",
      "validation score is improved!! inf -> 1.9148\n",
      "start 2\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0       1.74865        2\n",
      "validation score is improved!! 1.9148 -> 1.7486\n",
      "start 3\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0       1.13173        3\n",
      "validation score is improved!! 1.7486 -> 1.1317\n",
      "start 4\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0        1.0461        4\n",
      "validation score is improved!! 1.1317 -> 1.0461\n",
      "start 5\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.954586        5\n",
      "validation score is improved!! 1.0461 -> 0.9546\n",
      "start 6\n",
      "start 7\n",
      "start 8\n",
      "start 9\n",
      "start 10\n",
      "start 11\n",
      "start 12\n",
      "start 13\n",
      "start 14\n",
      "start 15\n",
      "start 16\n",
      "start 17\n",
      "start 18\n",
      "start 19\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.925027       19\n",
      "validation score is improved!! 0.9546 -> 0.9250\n",
      "start 20\n",
      "start 21\n",
      "start 22\n",
      "start 23\n",
      "start 24\n",
      "start 25\n",
      "start 26\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.924479       26\n",
      "validation score is improved!! 0.9250 -> 0.9245\n",
      "start 27\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.893754       27\n",
      "validation score is improved!! 0.9245 -> 0.8938\n",
      "start 28\n",
      "start 29\n",
      "start 30\n",
      "start 31\n",
      "start 32\n",
      "start 33\n",
      "start 34\n",
      "start 35\n",
      "start 36\n",
      "start 37\n",
      "start 38\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.886619       38\n",
      "validation score is improved!! 0.8938 -> 0.8866\n",
      "start 39\n",
      "start 40\n",
      "start 41\n",
      "start 42\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.885792       42\n",
      "validation score is improved!! 0.8866 -> 0.8858\n",
      "start 43\n",
      "start 44\n",
      "start 45\n",
      "start 46\n",
      "start 47\n",
      "start 48\n",
      "start 49\n",
      "start 50\n",
      "start 51\n",
      "start 52\n",
      "start 53\n",
      "start 54\n",
      "start 55\n",
      "start 56\n",
      "start 57\n",
      "start 58\n",
      "start 59\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.882959       59\n",
      "validation score is improved!! 0.8858 -> 0.8830\n",
      "start 60\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.879272       60\n",
      "validation score is improved!! 0.8830 -> 0.8793\n",
      "start 61\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.870388       61\n",
      "validation score is improved!! 0.8793 -> 0.8704\n",
      "start 62\n",
      "start 63\n",
      "start 64\n",
      "start 65\n",
      "start 66\n",
      "start 67\n",
      "start 68\n",
      "start 69\n",
      "start 70\n",
      "start 71\n",
      "start 72\n",
      "start 73\n",
      "start 74\n",
      "start 75\n",
      "start 76\n",
      "start 77\n",
      "start 78\n",
      "start 79\n",
      "start 80\n",
      "start 81\n",
      "start 82\n",
      "start 83\n",
      "start 84\n",
      "start 85\n",
      "start 86\n",
      "start 87\n",
      "start 88\n",
      "start 89\n",
      "start 90\n",
      "start 91\n",
      "start 92\n",
      "start 93\n",
      "start 94\n",
      "start 95\n",
      "start 96\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.862988       96\n",
      "validation score is improved!! 0.8704 -> 0.8630\n",
      "start 97\n",
      "start 98\n",
      "start 99\n",
      "start 100\n",
      "start 101\n",
      "start 102\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.856313      102\n",
      "validation score is improved!! 0.8630 -> 0.8563\n",
      "start 103\n",
      "start 104\n",
      "start 105\n",
      "start 106\n",
      "start 107\n",
      "start 108\n",
      "start 109\n",
      "start 110\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.842899      110\n",
      "validation score is improved!! 0.8563 -> 0.8429\n",
      "start 111\n",
      "start 112\n",
      "start 113\n",
      "start 114\n",
      "start 115\n",
      "start 116\n",
      "start 117\n",
      "start 118\n",
      "start 119\n",
      "start 120\n",
      "start 121\n",
      "start 122\n",
      "start 123\n",
      "start 124\n",
      "start 125\n",
      "start 126\n",
      "start 127\n",
      "start 128\n",
      "start 129\n",
      "start 130\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.831461      130\n",
      "validation score is improved!! 0.8429 -> 0.8315\n",
      "start 131\n",
      "start 132\n",
      "start 133\n",
      "start 134\n",
      "start 135\n",
      "start 136\n",
      "start 137\n",
      "start 138\n",
      "start 139\n",
      "start 140\n",
      "start 141\n",
      "start 142\n",
      "start 143\n",
      "start 144\n",
      "start 145\n",
      "start 146\n",
      "start 147\n",
      "start 148\n",
      "start 149\n",
      "start 150\n",
      "start 151\n",
      "start 152\n",
      "start 153\n",
      "start 154\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.828746      154\n",
      "validation score is improved!! 0.8315 -> 0.8287\n",
      "start 155\n",
      "start 156\n",
      "start 157\n",
      "start 158\n",
      "start 159\n",
      "start 160\n",
      "start 161\n",
      "start 162\n",
      "start 163\n",
      "start 164\n",
      "start 165\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.820544      165\n",
      "validation score is improved!! 0.8287 -> 0.8205\n",
      "start 166\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.819027      166\n",
      "validation score is improved!! 0.8205 -> 0.8190\n",
      "start 167\n",
      "start 168\n",
      "start 169\n",
      "start 170\n",
      "start 171\n",
      "start 172\n",
      "start 173\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.818882      173\n",
      "validation score is improved!! 0.8190 -> 0.8189\n",
      "start 174\n",
      "start 175\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.811684      175\n",
      "validation score is improved!! 0.8189 -> 0.8117\n",
      "start 176\n",
      "start 177\n",
      "start 178\n",
      "start 179\n",
      "start 180\n",
      "start 181\n",
      "start 182\n",
      "start 183\n",
      "start 184\n",
      "start 185\n",
      "start 186\n",
      "start 187\n",
      "start 188\n",
      "start 189\n",
      "start 190\n",
      "start 191\n",
      "start 192\n",
      "start 193\n",
      "start 194\n",
      "start 195\n",
      "start 196\n",
      "start 197\n",
      "start 198\n",
      "start 199\n",
      "start 200\n",
      "fold2\n",
      "start 1\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0       1.35521        1\n",
      "validation score is improved!! inf -> 1.3552\n",
      "start 2\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.906222        2\n",
      "validation score is improved!! 1.3552 -> 0.9062\n",
      "start 3\n",
      "start 4\n",
      "start 5\n",
      "start 6\n",
      "start 7\n",
      "start 8\n",
      "start 9\n",
      "start 10\n",
      "start 11\n",
      "start 12\n",
      "start 13\n",
      "start 14\n",
      "start 15\n",
      "start 16\n",
      "start 17\n",
      "start 18\n",
      "start 19\n",
      "start 20\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.879112       20\n",
      "validation score is improved!! 0.9062 -> 0.8791\n",
      "start 21\n",
      "start 22\n",
      "start 23\n",
      "start 24\n",
      "start 25\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.877417       25\n",
      "validation score is improved!! 0.8791 -> 0.8774\n",
      "start 26\n",
      "start 27\n",
      "start 28\n",
      "start 29\n",
      "start 30\n",
      "start 31\n",
      "start 32\n",
      "start 33\n",
      "start 34\n",
      "start 35\n",
      "start 36\n",
      "start 37\n",
      "start 38\n",
      "start 39\n",
      "start 40\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.871809       40\n",
      "validation score is improved!! 0.8774 -> 0.8718\n",
      "start 41\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.851775       41\n",
      "validation score is improved!! 0.8718 -> 0.8518\n",
      "start 42\n",
      "start 43\n",
      "start 44\n",
      "start 45\n",
      "start 46\n",
      "start 47\n",
      "start 48\n",
      "start 49\n",
      "start 50\n",
      "start 51\n",
      "start 52\n",
      "start 53\n",
      "start 54\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.849711       54\n",
      "validation score is improved!! 0.8518 -> 0.8497\n",
      "start 55\n",
      "start 56\n",
      "start 57\n",
      "start 58\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.838018       58\n",
      "validation score is improved!! 0.8497 -> 0.8380\n",
      "start 59\n",
      "start 60\n",
      "start 61\n",
      "start 62\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.833314       62\n",
      "validation score is improved!! 0.8380 -> 0.8333\n",
      "start 63\n",
      "start 64\n",
      "start 65\n",
      "start 66\n",
      "start 67\n",
      "start 68\n",
      "start 69\n",
      "start 70\n",
      "start 71\n",
      "start 72\n",
      "start 73\n",
      "start 74\n",
      "start 75\n",
      "start 76\n",
      "start 77\n",
      "start 78\n",
      "start 79\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.825572       79\n",
      "validation score is improved!! 0.8333 -> 0.8256\n",
      "start 80\n",
      "start 81\n",
      "start 82\n",
      "start 83\n",
      "start 84\n",
      "start 85\n",
      "start 86\n",
      "start 87\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.821532       87\n",
      "validation score is improved!! 0.8256 -> 0.8215\n",
      "start 88\n",
      "start 89\n",
      "start 90\n",
      "start 91\n",
      "start 92\n",
      "start 93\n",
      "start 94\n",
      "start 95\n",
      "start 96\n",
      "start 97\n",
      "start 98\n",
      "start 99\n",
      "start 100\n",
      "start 101\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.815577      101\n",
      "validation score is improved!! 0.8215 -> 0.8156\n",
      "start 102\n",
      "start 103\n",
      "start 104\n",
      "start 105\n",
      "start 106\n",
      "start 107\n",
      "start 108\n",
      "start 109\n",
      "start 110\n",
      "start 111\n",
      "start 112\n",
      "start 113\n",
      "start 114\n",
      "start 115\n",
      "start 116\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.807075      116\n",
      "validation score is improved!! 0.8156 -> 0.8071\n",
      "start 117\n",
      "start 118\n",
      "start 119\n",
      "start 120\n",
      "start 121\n",
      "start 122\n",
      "start 123\n",
      "start 124\n",
      "start 125\n",
      "start 126\n",
      "start 127\n",
      "start 128\n",
      "start 129\n",
      "start 130\n",
      "start 131\n",
      "start 132\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.798206      132\n",
      "validation score is improved!! 0.8071 -> 0.7982\n",
      "start 133\n",
      "start 134\n",
      "start 135\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.797495      135\n",
      "validation score is improved!! 0.7982 -> 0.7975\n",
      "start 136\n",
      "start 137\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.787372      137\n",
      "validation score is improved!! 0.7975 -> 0.7874\n",
      "start 138\n",
      "start 139\n",
      "start 140\n",
      "start 141\n",
      "start 142\n",
      "start 143\n",
      "start 144\n",
      "start 145\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.783839      145\n",
      "validation score is improved!! 0.7874 -> 0.7838\n",
      "start 146\n",
      "start 147\n",
      "start 148\n",
      "start 149\n",
      "start 150\n",
      "start 151\n",
      "start 152\n",
      "start 153\n",
      "start 154\n",
      "start 155\n",
      "start 156\n",
      "start 157\n",
      "start 158\n",
      "start 159\n",
      "start 160\n",
      "start 161\n",
      "start 162\n",
      "start 163\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.783413      163\n",
      "validation score is improved!! 0.7838 -> 0.7834\n",
      "start 164\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.781413      164\n",
      "validation score is improved!! 0.7834 -> 0.7814\n",
      "start 165\n",
      "start 166\n",
      "start 167\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.773384      167\n",
      "validation score is improved!! 0.7814 -> 0.7734\n",
      "start 168\n",
      "start 169\n",
      "start 170\n",
      "start 171\n",
      "start 172\n",
      "start 173\n",
      "start 174\n",
      "start 175\n",
      "start 176\n",
      "start 177\n",
      "start 178\n",
      "start 179\n",
      "start 180\n",
      "start 181\n",
      "start 182\n",
      "start 183\n",
      "start 184\n",
      "start 185\n",
      "start 186\n",
      "start 187\n",
      "start 188\n",
      "start 189\n",
      "start 190\n",
      "start 191\n",
      "start 192\n",
      "start 193\n",
      "start 194\n",
      "start 195\n",
      "start 196\n",
      "start 197\n",
      "start 198\n",
      "start 199\n",
      "start 200\n",
      "fold3\n",
      "start 1\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0       1.62261        1\n",
      "validation score is improved!! inf -> 1.6226\n",
      "start 2\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0       1.36918        2\n",
      "validation score is improved!! 1.6226 -> 1.3692\n",
      "start 3\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0        1.0008        3\n",
      "validation score is improved!! 1.3692 -> 1.0008\n",
      "start 4\n",
      "start 5\n",
      "start 6\n",
      "start 7\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.930588        7\n",
      "validation score is improved!! 1.0008 -> 0.9306\n",
      "start 8\n",
      "start 9\n",
      "start 10\n",
      "start 11\n",
      "start 12\n",
      "start 13\n",
      "start 14\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.914948       14\n",
      "validation score is improved!! 0.9306 -> 0.9149\n",
      "start 15\n",
      "start 16\n",
      "start 17\n",
      "start 18\n",
      "start 19\n",
      "start 20\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.908948       20\n",
      "validation score is improved!! 0.9149 -> 0.9089\n",
      "start 21\n",
      "start 22\n",
      "start 23\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.878478       23\n",
      "validation score is improved!! 0.9089 -> 0.8785\n",
      "start 24\n",
      "start 25\n",
      "start 26\n",
      "start 27\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.870487       27\n",
      "validation score is improved!! 0.8785 -> 0.8705\n",
      "start 28\n",
      "start 29\n",
      "start 30\n",
      "start 31\n",
      "start 32\n",
      "start 33\n",
      "start 34\n",
      "start 35\n",
      "start 36\n",
      "start 37\n",
      "start 38\n",
      "start 39\n",
      "start 40\n",
      "start 41\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.850331       41\n",
      "validation score is improved!! 0.8705 -> 0.8503\n",
      "start 42\n",
      "start 43\n",
      "start 44\n",
      "start 45\n",
      "start 46\n",
      "start 47\n",
      "start 48\n",
      "start 49\n",
      "start 50\n",
      "start 51\n",
      "start 52\n",
      "start 53\n",
      "start 54\n",
      "start 55\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.840316       55\n",
      "validation score is improved!! 0.8503 -> 0.8403\n",
      "start 56\n",
      "start 57\n",
      "start 58\n",
      "start 59\n",
      "start 60\n",
      "start 61\n",
      "start 62\n",
      "start 63\n",
      "start 64\n",
      "start 65\n",
      "start 66\n",
      "start 67\n",
      "start 68\n",
      "start 69\n",
      "start 70\n",
      "start 71\n",
      "start 72\n",
      "start 73\n",
      "start 74\n",
      "start 75\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.822531       75\n",
      "validation score is improved!! 0.8403 -> 0.8225\n",
      "start 76\n",
      "start 77\n",
      "start 78\n",
      "start 79\n",
      "start 80\n",
      "start 81\n",
      "start 82\n",
      "start 83\n",
      "start 84\n",
      "start 85\n",
      "start 86\n",
      "start 87\n",
      "start 88\n",
      "start 89\n",
      "start 90\n",
      "start 91\n",
      "start 92\n",
      "start 93\n",
      "start 94\n",
      "start 95\n",
      "start 96\n",
      "start 97\n",
      "start 98\n",
      "start 99\n",
      "start 100\n",
      "start 101\n",
      "start 102\n",
      "start 103\n",
      "start 104\n",
      "start 105\n",
      "start 106\n",
      "start 107\n",
      "start 108\n",
      "start 109\n",
      "start 110\n",
      "start 111\n",
      "start 112\n",
      "start 113\n",
      "start 114\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.805078      114\n",
      "validation score is improved!! 0.8225 -> 0.8051\n",
      "start 115\n",
      "start 116\n",
      "start 117\n",
      "start 118\n",
      "start 119\n",
      "start 120\n",
      "start 121\n",
      "start 122\n",
      "start 123\n",
      "start 124\n",
      "start 125\n",
      "start 126\n",
      "start 127\n",
      "start 128\n",
      "start 129\n",
      "start 130\n",
      "start 131\n",
      "start 132\n",
      "start 133\n",
      "start 134\n",
      "start 135\n",
      "start 136\n",
      "start 137\n",
      "start 138\n",
      "start 139\n",
      "start 140\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.798773      140\n",
      "validation score is improved!! 0.8051 -> 0.7988\n",
      "start 141\n",
      "start 142\n",
      "start 143\n",
      "start 144\n",
      "start 145\n",
      "start 146\n",
      "start 147\n",
      "start 148\n",
      "start 149\n",
      "start 150\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.793027      150\n",
      "validation score is improved!! 0.7988 -> 0.7930\n",
      "start 151\n",
      "start 152\n",
      "start 153\n",
      "start 154\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.786549      154\n",
      "validation score is improved!! 0.7930 -> 0.7865\n",
      "start 155\n",
      "start 156\n",
      "start 157\n",
      "start 158\n",
      "start 159\n",
      "start 160\n",
      "start 161\n",
      "start 162\n",
      "start 163\n",
      "start 164\n",
      "start 165\n",
      "start 166\n",
      "start 167\n",
      "start 168\n",
      "start 169\n",
      "start 170\n",
      "start 171\n",
      "start 172\n",
      "start 173\n",
      "start 174\n",
      "start 175\n",
      "start 176\n",
      "start 177\n",
      "start 178\n",
      "start 179\n",
      "start 180\n",
      "start 181\n",
      "start 182\n",
      "start 183\n",
      "start 184\n",
      "start 185\n",
      "start 186\n",
      "start 187\n",
      "start 188\n",
      "start 189\n",
      "start 190\n",
      "start 191\n",
      "start 192\n",
      "start 193\n",
      "start 194\n",
      "start 195\n",
      "start 196\n",
      "start 197\n",
      "start 198\n",
      "start 199\n",
      "start 200\n",
      "fold4\n",
      "start 1\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.981754        1\n",
      "validation score is improved!! inf -> 0.9818\n",
      "start 2\n",
      "start 3\n",
      "start 4\n",
      "start 5\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.920903        5\n",
      "validation score is improved!! 0.9818 -> 0.9209\n",
      "start 6\n",
      "start 7\n",
      "start 8\n",
      "start 9\n",
      "start 10\n",
      "start 11\n",
      "start 12\n",
      "start 13\n",
      "start 14\n",
      "start 15\n",
      "start 16\n",
      "start 17\n",
      "start 18\n",
      "start 19\n",
      "start 20\n",
      "start 21\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.888199       21\n",
      "validation score is improved!! 0.9209 -> 0.8882\n",
      "start 22\n",
      "start 23\n",
      "start 24\n",
      "start 25\n",
      "start 26\n",
      "start 27\n",
      "start 28\n",
      "start 29\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.864885       29\n",
      "validation score is improved!! 0.8882 -> 0.8649\n",
      "start 30\n",
      "start 31\n",
      "start 32\n",
      "start 33\n",
      "start 34\n",
      "start 35\n",
      "start 36\n",
      "start 37\n",
      "start 38\n",
      "start 39\n",
      "start 40\n",
      "start 41\n",
      "start 42\n",
      "start 43\n",
      "start 44\n",
      "start 45\n",
      "start 46\n",
      "start 47\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.851664       47\n",
      "validation score is improved!! 0.8649 -> 0.8517\n",
      "start 48\n",
      "start 49\n",
      "start 50\n",
      "start 51\n",
      "start 52\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.851494       52\n",
      "validation score is improved!! 0.8517 -> 0.8515\n",
      "start 53\n",
      "start 54\n",
      "start 55\n",
      "start 56\n",
      "start 57\n",
      "start 58\n",
      "start 59\n",
      "start 60\n",
      "start 61\n",
      "start 62\n",
      "start 63\n",
      "start 64\n",
      "start 65\n",
      "start 66\n",
      "start 67\n",
      "start 68\n",
      "start 69\n",
      "start 70\n",
      "start 71\n",
      "start 72\n",
      "start 73\n",
      "start 74\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0        0.8435       74\n",
      "validation score is improved!! 0.8515 -> 0.8435\n",
      "start 75\n",
      "start 76\n",
      "start 77\n",
      "start 78\n",
      "start 79\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.832368       79\n",
      "validation score is improved!! 0.8435 -> 0.8324\n",
      "start 80\n",
      "start 81\n",
      "start 82\n",
      "start 83\n",
      "start 84\n",
      "start 85\n",
      "start 86\n",
      "start 87\n",
      "start 88\n",
      "start 89\n",
      "start 90\n",
      "start 91\n",
      "start 92\n",
      "start 93\n",
      "start 94\n",
      "start 95\n",
      "start 96\n",
      "start 97\n",
      "start 98\n",
      "start 99\n",
      "start 100\n",
      "start 101\n",
      "start 102\n",
      "start 103\n",
      "start 104\n",
      "start 105\n",
      "start 106\n",
      "start 107\n",
      "start 108\n",
      "start 109\n",
      "start 110\n",
      "start 111\n",
      "start 112\n",
      "start 113\n",
      "start 114\n",
      "start 115\n",
      "start 116\n",
      "start 117\n",
      "start 118\n",
      "start 119\n",
      "start 120\n",
      "start 121\n",
      "start 122\n",
      "start 123\n",
      "start 124\n",
      "start 125\n",
      "start 126\n",
      "start 127\n",
      "start 128\n",
      "start 129\n",
      "start 130\n",
      "start 131\n",
      "start 132\n",
      "start 133\n",
      "start 134\n",
      "start 135\n",
      "start 136\n",
      "start 137\n",
      "start 138\n",
      "start 139\n",
      "start 140\n",
      "start 141\n",
      "start 142\n",
      "start 143\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.815291      143\n",
      "validation score is improved!! 0.8324 -> 0.8153\n",
      "start 144\n",
      "start 145\n",
      "start 146\n",
      "start 147\n",
      "start 148\n",
      "start 149\n",
      "start 150\n",
      "start 151\n",
      "start 152\n",
      "start 153\n",
      "start 154\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.804888      154\n",
      "validation score is improved!! 0.8153 -> 0.8049\n",
      "start 155\n",
      "start 156\n",
      "start 157\n",
      "start 158\n",
      "start 159\n",
      "start 160\n",
      "start 161\n",
      "start 162\n",
      "start 163\n",
      "start 164\n",
      "start 165\n",
      "start 166\n",
      "start 167\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.801806      167\n",
      "validation score is improved!! 0.8049 -> 0.8018\n",
      "start 168\n",
      "start 169\n",
      "start 170\n",
      "start 171\n",
      "start 172\n",
      "start 173\n",
      "start 174\n",
      "start 175\n",
      "start 176\n",
      "start 177\n",
      "start 178\n",
      "start 179\n",
      "start 180\n",
      "start 181\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0             0      0.798873      181\n",
      "validation score is improved!! 0.8018 -> 0.7989\n",
      "start 182\n",
      "start 183\n",
      "start 184\n",
      "start 185\n",
      "start 186\n",
      "start 187\n",
      "start 188\n",
      "start 189\n",
      "start 190\n",
      "start 191\n",
      "start 192\n",
      "start 193\n",
      "start 194\n",
      "start 195\n",
      "start 196\n",
      "start 197\n",
      "start 198\n",
      "start 199\n",
      "start 200\n"
     ]
    }
   ],
   "source": [
    "fold = stratified_group_k_fold(train_df, train_df['target'], groups, k=n_folds, seed=12)\n",
    "oof = np.zeros((len(train_df), ), dtype=np.float32)\n",
    "\n",
    "for i, (idx_tr, idx_valid) in enumerate(fold):\n",
    "    print(f\"fold{i}\")\n",
    "    model = make_model()\n",
    "    #nn.Sequential(*list(model.children())[:-1]).load_state_dict(torch.load(\"ssl.pth\"))\n",
    "    \n",
    "    model.fc = nn.Linear(in_features=512, out_features=1, bias=True)\n",
    "    \n",
    "    model.to(device)\n",
    "\n",
    "    oof_i = run_fold(\n",
    "        model=model, \n",
    "        train_df=train_meta_df.iloc[idx_tr], \n",
    "        valid_df=train_meta_df.iloc[idx_valid], \n",
    "        y_valid=train_meta_df['target'].values[idx_valid],\n",
    "        n_epochs=200,\n",
    "        n_fold = i\n",
    "    )\n",
    "\n",
    "    oof[idx_valid] = oof_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27b25990",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T13:59:47.228255Z",
     "iopub.status.busy": "2021-07-22T13:59:47.222343Z",
     "iopub.status.idle": "2021-07-22T13:59:47.232202Z",
     "shell.execute_reply": "2021-07-22T13:59:47.232753Z"
    },
    "papermill": {
     "duration": 0.40064,
     "end_time": "2021-07-22T13:59:47.232923",
     "exception": false,
     "start_time": "2021-07-22T13:59:46.832283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6106440034798106"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(train_df['target'], oof)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e11c767",
   "metadata": {
    "papermill": {
     "duration": 0.388912,
     "end_time": "2021-07-22T13:59:48.009697",
     "exception": false,
     "start_time": "2021-07-22T13:59:47.620785",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8438db36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T13:59:49.104048Z",
     "iopub.status.busy": "2021-07-22T13:59:49.102848Z",
     "iopub.status.idle": "2021-07-22T14:01:35.923498Z",
     "shell.execute_reply": "2021-07-22T14:01:35.926002Z"
    },
    "papermill": {
     "duration": 107.523435,
     "end_time": "2021-07-22T14:01:35.926703",
     "exception": false,
     "start_time": "2021-07-22T13:59:48.403268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train と似たようなことをするので、次回から楽したいとおもって `create_metadata` という関数を作りました\n",
    "test_meta_df = create_metadata(test_df)\n",
    "\n",
    "# 学習時のデータ拡張はオフにしたいので is_train=False としている\n",
    "test_dataset = AtmaDataset(meta_df=test_meta_df, is_train=False)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, batch_size=128, drop_last=False, num_workers=4)\n",
    "\n",
    "test_predictions = []\n",
    "\n",
    "for i in range(n_folds):\n",
    "    model = make_model()\n",
    "    \n",
    "    model.fc = nn.Linear(in_features=512, out_features=1, bias=True)\n",
    "\n",
    "    # 最も良かった重みを読みだす\n",
    "    # https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "    model.load_state_dict(torch.load('model_best'+str(i)+'.pth'))\n",
    "\n",
    "    # GPU環境で予測するため `to` で変換\n",
    "    model.to(device)\n",
    "\n",
    "    y_pred_i = predict(model, loader=test_loader)\n",
    "\n",
    "    test_predictions.append(y_pred_i)\n",
    "    \n",
    "pred_mean = np.array(test_predictions).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a50da9a",
   "metadata": {
    "papermill": {
     "duration": 0.403148,
     "end_time": "2021-07-22T14:01:36.994293",
     "exception": false,
     "start_time": "2021-07-22T14:01:36.591145",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c024b3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T14:01:37.807035Z",
     "iopub.status.busy": "2021-07-22T14:01:37.806097Z",
     "iopub.status.idle": "2021-07-22T14:01:37.826143Z",
     "shell.execute_reply": "2021-07-22T14:01:37.825584Z"
    },
    "papermill": {
     "duration": 0.42729,
     "end_time": "2021-07-22T14:01:37.826276",
     "exception": false,
     "start_time": "2021-07-22T14:01:37.398986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\"target\": pred_mean}).to_csv(\"submission\"+str(oof)+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f60f7a",
   "metadata": {
    "papermill": {
     "duration": 0.396782,
     "end_time": "2021-07-22T14:01:38.622661",
     "exception": false,
     "start_time": "2021-07-22T14:01:38.225879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17395.981469,
   "end_time": "2021-07-22T14:01:42.349813",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-07-22T09:11:46.368344",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
